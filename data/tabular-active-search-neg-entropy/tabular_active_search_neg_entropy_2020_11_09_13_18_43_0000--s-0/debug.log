2020-11-09 13:19:32.591417 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 0 finished
----------------------------------  ---------------
replay_buffer/size                   4000
trainer/num train calls              1000
trainer/QF1 Loss                       18.5153
trainer/QF2 Loss                       18.5146
trainer/Policy Loss                    -1.36027
trainer/Q1 Predictions Mean             0.00020093
trainer/Q1 Predictions Std              0.000143908
trainer/Q1 Predictions Max              0.000533564
trainer/Q1 Predictions Min             -4.34813e-05
trainer/Q2 Predictions Mean             0.000116562
trainer/Q2 Predictions Std              7.13854e-05
trainer/Q2 Predictions Max              0.000336601
trainer/Q2 Predictions Min              3.95373e-06
trainer/Q Targets Mean                 -4.25165
trainer/Q Targets Std                   0.661136
trainer/Q Targets Max                  -1.24601
trainer/Q Targets Min                  -5.47238
trainer/Log Pis Mean                   -1.36016
trainer/Log Pis Std                     0.308058
trainer/Log Pis Max                    -0.533046
trainer/Log Pis Min                    -1.85782
trainer/policy/mean Mean               -1.76723e-06
trainer/policy/mean Std                 5.44486e-06
trainer/policy/mean Max                 1.52083e-05
trainer/policy/mean Min                -1.47866e-05
trainer/policy/normal/std Mean          0.999987
trainer/policy/normal/std Std           0.000163651
trainer/policy/normal/std Max           1.00018
trainer/policy/normal/std Min           0.999807
trainer/policy/normal/log_std Mean     -1.30722e-05
trainer/policy/normal/log_std Std       0.000163653
trainer/policy/normal/log_std Max       0.000177487
trainer/policy/normal/log_std Min      -0.000192601
trainer/Alpha                           1
trainer/Alpha Loss                     -0
exploration/num steps total          4000
exploration/num paths total            20
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.51401
exploration/Rewards Std                 0.668494
exploration/Rewards Max                -2.85949
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1102.8
exploration/Returns Std               108.047
exploration/Returns Max              -796.391
exploration/Returns Min             -1187.36
exploration/Actions Mean                0.00698439
exploration/Actions Std                 0.625107
exploration/Actions Max                 0.998149
exploration/Actions Min                -0.996853
exploration/Num Paths                  10
exploration/Average Returns         -1102.8
evaluation/num steps total           4824
evaluation/num paths total             24
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.07278
evaluation/Rewards Std                  0.10015
evaluation/Rewards Max                 -5.44127
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1220.63
evaluation/Returns Std                 14.8367
evaluation/Returns Max              -1156.49
evaluation/Returns Min              -1231.89
evaluation/Actions Mean                -3.18525e-06
evaluation/Actions Std                  3.92977e-06
evaluation/Actions Max                  1.13446e-06
evaluation/Actions Min                 -1.26467e-05
evaluation/Num Paths                   24
evaluation/Average Returns          -1220.63
time/data storing (s)                   0.0298112
time/evaluation sampling (s)           17.2574
time/exploration sampling (s)           7.10686
time/logging (s)                        0.0219557
time/sac training (s)                  14.0103
time/saving (s)                         0.0303957
time/training (s)                       0.000119737
time/epoch (s)                         38.4568
time/total (s)                         49.1965
Epoch                                   0
----------------------------------  ---------------
2020-11-09 13:20:13.279138 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 1 finished
----------------------------------  ---------------
replay_buffer/size                   6000
trainer/num train calls              2000
trainer/QF1 Loss                       13.2013
trainer/QF2 Loss                       13.323
trainer/Policy Loss                     0.186838
trainer/Q1 Predictions Mean            -1.43905
trainer/Q1 Predictions Std              0.134163
trainer/Q1 Predictions Max             -1.23645
trainer/Q1 Predictions Min             -1.86143
trainer/Q2 Predictions Mean            -1.42558
trainer/Q2 Predictions Std              0.180984
trainer/Q2 Predictions Max             -1.1555
trainer/Q2 Predictions Min             -1.85847
trainer/Q Targets Mean                 -5.01345
trainer/Q Targets Std                   0.636754
trainer/Q Targets Max                  -2.43309
trainer/Q Targets Min                  -5.83979
trainer/Log Pis Mean                   -1.36436
trainer/Log Pis Std                     0.19262
trainer/Log Pis Max                    -1.09392
trainer/Log Pis Min                    -3.29399
trainer/policy/mean Mean               -0.0391718
trainer/policy/mean Std                 0.0161221
trainer/policy/mean Max                -0.0201205
trainer/policy/mean Min                -0.05668
trainer/policy/normal/std Mean          0.830508
trainer/policy/normal/std Std           0.00391436
trainer/policy/normal/std Max           0.852472
trainer/policy/normal/std Min           0.825358
trainer/policy/normal/log_std Mean     -0.185729
trainer/policy/normal/log_std Std       0.00467889
trainer/policy/normal/log_std Max      -0.159615
trainer/policy/normal/log_std Min      -0.191938
trainer/Alpha                           0.97039
trainer/Alpha Loss                     -0.101124
exploration/num steps total          6000
exploration/num paths total            30
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.58793
exploration/Rewards Std                 0.584849
exploration/Rewards Max                -3.12035
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1117.59
exploration/Returns Std                71.1407
exploration/Returns Max              -975.084
exploration/Returns Min             -1175.09
exploration/Actions Mean               -0.0279981
exploration/Actions Std                 0.570415
exploration/Actions Max                 0.995653
exploration/Actions Min                -0.994968
exploration/Num Paths                  10
exploration/Average Returns         -1117.59
evaluation/num steps total           9648
evaluation/num paths total             48
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.04134
evaluation/Rewards Std                  0.118675
evaluation/Rewards Max                 -5.49916
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1214.31
evaluation/Returns Std                 15.2766
evaluation/Returns Max              -1179.3
evaluation/Returns Min              -1231.2
evaluation/Actions Mean                -0.0392268
evaluation/Actions Std                  0.0161161
evaluation/Actions Max                 -0.0230018
evaluation/Actions Min                 -0.0564545
evaluation/Num Paths                   24
evaluation/Average Returns          -1214.31
time/data storing (s)                   0.0325271
time/evaluation sampling (s)           17.5337
time/exploration sampling (s)           7.13666
time/logging (s)                        0.0216538
time/sac training (s)                  14.7306
time/saving (s)                         0.0275883
time/training (s)                       0.000120636
time/epoch (s)                         39.4828
time/total (s)                         89.8605
Epoch                                   1
----------------------------------  ---------------
2020-11-09 13:20:52.825092 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 2 finished
----------------------------------  ---------------
replay_buffer/size                   8000
trainer/num train calls              3000
trainer/QF1 Loss                        5.90667
trainer/QF2 Loss                        5.9755
trainer/Policy Loss                     7.53248
trainer/Q1 Predictions Mean            -8.76686
trainer/Q1 Predictions Std              0.285218
trainer/Q1 Predictions Max             -8.30976
trainer/Q1 Predictions Min             -9.71683
trainer/Q2 Predictions Mean            -8.74552
trainer/Q2 Predictions Std              0.235309
trainer/Q2 Predictions Max             -8.3364
trainer/Q2 Predictions Min             -9.40789
trainer/Q Targets Mean                -11.1233
trainer/Q Targets Std                   0.519488
trainer/Q Targets Max                  -8.53738
trainer/Q Targets Min                 -12.2239
trainer/Log Pis Mean                   -1.33393
trainer/Log Pis Std                     0.277539
trainer/Log Pis Max                    -0.863894
trainer/Log Pis Min                    -3.39342
trainer/policy/mean Mean               -0.113151
trainer/policy/mean Std                 0.0267884
trainer/policy/mean Max                -0.0787934
trainer/policy/mean Min                -0.14297
trainer/policy/normal/std Mean          0.802045
trainer/policy/normal/std Std           0.0130566
trainer/policy/normal/std Max           0.830242
trainer/policy/normal/std Min           0.78499
trainer/policy/normal/log_std Mean     -0.220723
trainer/policy/normal/log_std Std       0.0162799
trainer/policy/normal/log_std Max      -0.186039
trainer/policy/normal/log_std Min      -0.242084
trainer/Alpha                           0.94181
trainer/Alpha Loss                     -0.199874
exploration/num steps total          8000
exploration/num paths total            40
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.61848
exploration/Rewards Std                 0.467973
exploration/Rewards Max                -3.84334
exploration/Rewards Min                -6.14204
exploration/Returns Mean            -1123.7
exploration/Returns Std                40.7407
exploration/Returns Max             -1028.22
exploration/Returns Min             -1184.46
exploration/Actions Mean               -0.0918986
exploration/Actions Std                 0.554927
exploration/Actions Max                 0.997491
exploration/Actions Min                -0.995713
exploration/Num Paths                  10
exploration/Average Returns         -1123.7
evaluation/num steps total          14472
evaluation/num paths total             72
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.04967
evaluation/Rewards Std                  0.105719
evaluation/Rewards Max                 -5.24231
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1215.98
evaluation/Returns Std                 15.0028
evaluation/Returns Max              -1171.56
evaluation/Returns Min              -1230.59
evaluation/Actions Mean                -0.113249
evaluation/Actions Std                  0.0267824
evaluation/Actions Max                 -0.0860977
evaluation/Actions Min                 -0.141607
evaluation/Num Paths                   24
evaluation/Average Returns          -1215.98
time/data storing (s)                   0.0317475
time/evaluation sampling (s)           17.1496
time/exploration sampling (s)           7.14373
time/logging (s)                        0.0281426
time/sac training (s)                  13.991
time/saving (s)                         0.0270808
time/training (s)                       0.000144109
time/epoch (s)                         38.3715
time/total (s)                        129.39
Epoch                                   2
----------------------------------  ---------------
2020-11-09 13:21:32.120930 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 3 finished
----------------------------------  ---------------
replay_buffer/size                  10000
trainer/num train calls              4000
trainer/QF1 Loss                        4.08073
trainer/QF2 Loss                        4.13004
trainer/Policy Loss                    20.2972
trainer/Q1 Predictions Mean           -21.5551
trainer/Q1 Predictions Std              0.206856
trainer/Q1 Predictions Max            -20.6056
trainer/Q1 Predictions Min            -22.4205
trainer/Q2 Predictions Mean           -21.5363
trainer/Q2 Predictions Std              0.171719
trainer/Q2 Predictions Max            -20.7398
trainer/Q2 Predictions Min            -22.0333
trainer/Q Targets Mean                -22.7572
trainer/Q Targets Std                   1.63986
trainer/Q Targets Max                  -5.44634
trainer/Q Targets Min                 -23.7892
trainer/Log Pis Mean                   -1.39113
trainer/Log Pis Std                     0.23905
trainer/Log Pis Max                    -1.11861
trainer/Log Pis Min                    -3.16565
trainer/policy/mean Mean                0.0268326
trainer/policy/mean Std                 0.0053178
trainer/policy/mean Max                 0.0325223
trainer/policy/mean Min                 0.0206511
trainer/policy/normal/std Mean          0.82028
trainer/policy/normal/std Std           0.00173731
trainer/policy/normal/std Max           0.828384
trainer/policy/normal/std Min           0.816959
trainer/policy/normal/log_std Mean     -0.198112
trainer/policy/normal/log_std Std       0.00211465
trainer/policy/normal/log_std Max      -0.188278
trainer/policy/normal/log_std Min      -0.202167
trainer/Alpha                           0.913909
trainer/Alpha Loss                     -0.305282
exploration/num steps total         10000
exploration/num paths total            50
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.63095
exploration/Rewards Std                 0.334647
exploration/Rewards Max                -4.87012
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1126.19
exploration/Returns Std                26.1959
exploration/Returns Max             -1082.9
exploration/Returns Min             -1168.18
exploration/Actions Mean                0.0247199
exploration/Actions Std                 0.559801
exploration/Actions Max                 0.992982
exploration/Actions Min                -0.998031
exploration/Num Paths                  10
exploration/Average Returns         -1126.19
evaluation/num steps total          19296
evaluation/num paths total             96
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.08023
evaluation/Rewards Std                  0.0810725
evaluation/Rewards Max                 -5.59696
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1222.13
evaluation/Returns Std                  9.52596
evaluation/Returns Max              -1194.29
evaluation/Returns Min              -1231.73
evaluation/Actions Mean                 0.0268691
evaluation/Actions Std                  0.00531757
evaluation/Actions Max                  0.0323828
evaluation/Actions Min                  0.0215081
evaluation/Num Paths                   24
evaluation/Average Returns          -1222.13
time/data storing (s)                   0.0287757
time/evaluation sampling (s)           17.0853
time/exploration sampling (s)           7.09639
time/logging (s)                        0.02174
time/sac training (s)                  13.8492
time/saving (s)                         0.0270866
time/training (s)                       0.000146135
time/epoch (s)                         38.1086
time/total (s)                        168.656
Epoch                                   3
----------------------------------  ---------------
2020-11-09 13:22:11.468975 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 4 finished
----------------------------------  ---------------
replay_buffer/size                  12000
trainer/num train calls              5000
trainer/QF1 Loss                        0.900792
trainer/QF2 Loss                        0.9271
trainer/Policy Loss                    36.4276
trainer/Q1 Predictions Mean           -37.6155
trainer/Q1 Predictions Std              0.433153
trainer/Q1 Predictions Max            -34.2577
trainer/Q1 Predictions Min            -38.1029
trainer/Q2 Predictions Mean           -37.6003
trainer/Q2 Predictions Std              0.403754
trainer/Q2 Predictions Max            -34.7387
trainer/Q2 Predictions Min            -38.1018
trainer/Q Targets Mean                -38.4495
trainer/Q Targets Std                   0.749403
trainer/Q Targets Max                 -33.5546
trainer/Q Targets Min                 -39.3217
trainer/Log Pis Mean                   -1.3593
trainer/Log Pis Std                     0.138359
trainer/Log Pis Max                    -1.11019
trainer/Log Pis Min                    -2.47593
trainer/policy/mean Mean                0.0119181
trainer/policy/mean Std                 0.0104747
trainer/policy/mean Max                 0.0231512
trainer/policy/mean Min                 0.00130103
trainer/policy/normal/std Mean          0.847387
trainer/policy/normal/std Std           0.00170706
trainer/policy/normal/std Max           0.853502
trainer/policy/normal/std Min           0.841124
trainer/policy/normal/log_std Mean     -0.1656
trainer/policy/normal/log_std Std       0.00201405
trainer/policy/normal/log_std Max      -0.158408
trainer/policy/normal/log_std Min      -0.173016
trainer/Alpha                           0.886849
trainer/Alpha Loss                     -0.403387
exploration/num steps total         12000
exploration/num paths total            60
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.71745
exploration/Rewards Std                 0.331202
exploration/Rewards Max                -3.96483
exploration/Rewards Min                -6.14202
exploration/Returns Mean            -1143.49
exploration/Returns Std                34.9078
exploration/Returns Max             -1087.21
exploration/Returns Min             -1187.37
exploration/Actions Mean                0.0130615
exploration/Actions Std                 0.585026
exploration/Actions Max                 0.9989
exploration/Actions Min                -0.993661
exploration/Num Paths                  10
exploration/Average Returns         -1143.49
evaluation/num steps total          24120
evaluation/num paths total            120
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.99564
evaluation/Rewards Std                  0.166782
evaluation/Rewards Max                 -5.3165
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1205.12
evaluation/Returns Std                 22.6073
evaluation/Returns Max              -1158.05
evaluation/Returns Min              -1231.54
evaluation/Actions Mean                 0.0119273
evaluation/Actions Std                  0.0104945
evaluation/Actions Max                  0.0226826
evaluation/Actions Min                  0.00137845
evaluation/Num Paths                   24
evaluation/Average Returns          -1205.12
time/data storing (s)                   0.0333359
time/evaluation sampling (s)           17.1033
time/exploration sampling (s)           7.06028
time/logging (s)                        0.0287804
time/sac training (s)                  13.9131
time/saving (s)                         0.0263338
time/training (s)                       0.000148002
time/epoch (s)                         38.1653
time/total (s)                        207.989
Epoch                                   4
----------------------------------  ---------------
2020-11-09 13:26:07.469393 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 5 finished
----------------------------------  ---------------
replay_buffer/size                  14000
trainer/num train calls              6000
trainer/QF1 Loss                       20.0234
trainer/QF2 Loss                       20.1584
trainer/Policy Loss                    54.0888
trainer/Q1 Predictions Mean           -55.2516
trainer/Q1 Predictions Std              0.886538
trainer/Q1 Predictions Max            -47.7043
trainer/Q1 Predictions Min            -56.2087
trainer/Q2 Predictions Mean           -55.2361
trainer/Q2 Predictions Std              0.875214
trainer/Q2 Predictions Max            -48.101
trainer/Q2 Predictions Min            -55.8666
trainer/Q Targets Mean                -55.3729
trainer/Q Targets Std                   4.58972
trainer/Q Targets Max                  -4.97072
trainer/Q Targets Min                 -56.7486
trainer/Log Pis Mean                   -1.38357
trainer/Log Pis Std                     0.184505
trainer/Log Pis Max                    -1.0228
trainer/Log Pis Min                    -2.80259
trainer/policy/mean Mean                0.00657395
trainer/policy/mean Std                 0.0344963
trainer/policy/mean Max                 0.0419753
trainer/policy/mean Min                -0.0286834
trainer/policy/normal/std Mean          0.860049
trainer/policy/normal/std Std           0.00149892
trainer/policy/normal/std Max           0.865455
trainer/policy/normal/std Min           0.855854
trainer/policy/normal/log_std Mean     -0.150767
trainer/policy/normal/log_std Std       0.0017424
trainer/policy/normal/log_std Max      -0.1445
trainer/policy/normal/log_std Min      -0.155655
trainer/Alpha                           0.860617
trainer/Alpha Loss                     -0.507895
exploration/num steps total         14000
exploration/num paths total            70
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.49029
exploration/Rewards Std                 0.620645
exploration/Rewards Max                -3.34102
exploration/Rewards Min                -6.142
exploration/Returns Mean            -1098.06
exploration/Returns Std                52.3136
exploration/Returns Max             -1019.18
exploration/Returns Min             -1187.84
exploration/Actions Mean                0.0032318
exploration/Actions Std                 0.582216
exploration/Actions Max                 0.992668
exploration/Actions Min                -0.996832
exploration/Num Paths                  10
exploration/Average Returns         -1098.06
evaluation/num steps total          28944
evaluation/num paths total            144
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.06508
evaluation/Rewards Std                  0.0829911
evaluation/Rewards Max                 -5.70387
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1219.08
evaluation/Returns Std                 10.3976
evaluation/Returns Max              -1196.48
evaluation/Returns Min              -1231.34
evaluation/Actions Mean                 0.00657084
evaluation/Actions Std                  0.0344708
evaluation/Actions Max                  0.041524
evaluation/Actions Min                 -0.0282941
evaluation/Num Paths                   24
evaluation/Average Returns          -1219.08
time/data storing (s)                   0.0316984
time/evaluation sampling (s)           17.9061
time/exploration sampling (s)           6.74851
time/logging (s)                        0.0286506
time/sac training (s)                  21.1703
time/saving (s)                         0.0763994
time/training (s)                       0.000143273
time/epoch (s)                         45.9618
time/total (s)                        255.199
Epoch                                   5
----------------------------------  ---------------
2020-11-09 13:26:54.347836 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 6 finished
----------------------------------  --------------
replay_buffer/size                  16000
trainer/num train calls              7000
trainer/QF1 Loss                       73.7292
trainer/QF2 Loss                       73.7188
trainer/Policy Loss                    72.0573
trainer/Q1 Predictions Mean           -73.1573
trainer/Q1 Predictions Std              1.40493
trainer/Q1 Predictions Max            -62.3132
trainer/Q1 Predictions Min            -74.1596
trainer/Q2 Predictions Mean           -73.1593
trainer/Q2 Predictions Std              1.36138
trainer/Q2 Predictions Max            -62.7528
trainer/Q2 Predictions Min            -74.2104
trainer/Q Targets Mean                -72.6698
trainer/Q Targets Std                   8.62666
trainer/Q Targets Max                  -5.06182
trainer/Q Targets Min                 -74.7623
trainer/Log Pis Mean                   -1.35353
trainer/Log Pis Std                     0.150037
trainer/Log Pis Max                    -1.00178
trainer/Log Pis Min                    -2.10782
trainer/policy/mean Mean                0.00889294
trainer/policy/mean Std                 0.0312479
trainer/policy/mean Max                 0.0415395
trainer/policy/mean Min                -0.0233115
trainer/policy/normal/std Mean          0.867324
trainer/policy/normal/std Std           0.00178963
trainer/policy/normal/std Max           0.874077
trainer/policy/normal/std Min           0.861339
trainer/policy/normal/log_std Mean     -0.142345
trainer/policy/normal/log_std Std       0.00206378
trainer/policy/normal/log_std Max      -0.134587
trainer/policy/normal/log_std Min      -0.149267
trainer/Alpha                           0.835172
trainer/Alpha Loss                     -0.604028
exploration/num steps total         16000
exploration/num paths total            80
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.69096
exploration/Rewards Std                 0.370837
exploration/Rewards Max                -4.13836
exploration/Rewards Min                -6.14201
exploration/Returns Mean            -1138.19
exploration/Returns Std                42.0327
exploration/Returns Max             -1022.93
exploration/Returns Min             -1174.34
exploration/Actions Mean                0.0169911
exploration/Actions Std                 0.581716
exploration/Actions Max                 0.994399
exploration/Actions Min                -0.997735
exploration/Num Paths                  10
exploration/Average Returns         -1138.19
evaluation/num steps total          33768
evaluation/num paths total            168
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05387
evaluation/Rewards Std                  0.146852
evaluation/Rewards Max                 -5.26354
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1216.83
evaluation/Returns Std                 21.1401
evaluation/Returns Max              -1145.93
evaluation/Returns Min              -1231.39
evaluation/Actions Mean                 0.00889424
evaluation/Actions Std                  0.0312645
evaluation/Actions Max                  0.0411459
evaluation/Actions Min                 -0.0230624
evaluation/Num Paths                   24
evaluation/Average Returns          -1216.83
time/data storing (s)                   0.0302341
time/evaluation sampling (s)           19.5737
time/exploration sampling (s)           9.82837
time/logging (s)                        0.0216657
time/sac training (s)                  16.0719
time/saving (s)                         0.0282023
time/training (s)                       0.00014124
time/epoch (s)                         45.5542
time/total (s)                        302.045
Epoch                                   6
----------------------------------  --------------
2020-11-09 13:27:33.392818 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 7 finished
----------------------------------  ---------------
replay_buffer/size                  18000
trainer/num train calls              8000
trainer/QF1 Loss                       87.2052
trainer/QF2 Loss                       87.3038
trainer/Policy Loss                    89.5894
trainer/Q1 Predictions Mean           -90.6594
trainer/Q1 Predictions Std              2.43636
trainer/Q1 Predictions Max            -72.958
trainer/Q1 Predictions Min            -92.4011
trainer/Q2 Predictions Mean           -90.6712
trainer/Q2 Predictions Std              2.42697
trainer/Q2 Predictions Max            -73.4292
trainer/Q2 Predictions Min            -92.5345
trainer/Q Targets Mean                -90.3261
trainer/Q Targets Std                   9.60887
trainer/Q Targets Max                  -5.41524
trainer/Q Targets Min                 -92.9174
trainer/Log Pis Mean                   -1.36912
trainer/Log Pis Std                     0.173262
trainer/Log Pis Max                    -0.898463
trainer/Log Pis Min                    -2.13639
trainer/policy/mean Mean                0.0248351
trainer/policy/mean Std                 0.0537689
trainer/policy/mean Max                 0.0826622
trainer/policy/mean Min                -0.0307849
trainer/policy/normal/std Mean          0.869933
trainer/policy/normal/std Std           0.00157183
trainer/policy/normal/std Max           0.87604
trainer/policy/normal/std Min           0.862211
trainer/policy/normal/log_std Mean     -0.13934
trainer/policy/normal/log_std Std       0.00180825
trainer/policy/normal/log_std Max      -0.132344
trainer/policy/normal/log_std Min      -0.148255
trainer/Alpha                           0.81049
trainer/Alpha Loss                     -0.707905
exploration/num steps total         18000
exploration/num paths total            90
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.74314
exploration/Rewards Std                 0.27728
exploration/Rewards Max                -4.88821
exploration/Rewards Min                -6.14202
exploration/Returns Mean            -1148.63
exploration/Returns Std                27.2793
exploration/Returns Max             -1091.32
exploration/Returns Min             -1178.38
exploration/Actions Mean                0.0077684
exploration/Actions Std                 0.587592
exploration/Actions Max                 0.99427
exploration/Actions Min                -0.996237
exploration/Num Paths                  10
exploration/Average Returns         -1148.63
evaluation/num steps total          38592
evaluation/num paths total            192
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05467
evaluation/Rewards Std                  0.105846
evaluation/Rewards Max                 -5.5377
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1216.99
evaluation/Returns Std                 11.4633
evaluation/Returns Max              -1194.83
evaluation/Returns Min              -1231.07
evaluation/Actions Mean                 0.0248611
evaluation/Actions Std                  0.0538359
evaluation/Actions Max                  0.0799368
evaluation/Actions Min                 -0.0295252
evaluation/Num Paths                   24
evaluation/Average Returns          -1216.99
time/data storing (s)                   0.0277137
time/evaluation sampling (s)           16.1333
time/exploration sampling (s)           6.72198
time/logging (s)                        0.0237327
time/sac training (s)                  14.9102
time/saving (s)                         0.0302377
time/training (s)                       0.000130005
time/epoch (s)                         37.8473
time/total (s)                        341.067
Epoch                                   7
----------------------------------  ---------------
2020-11-09 13:28:13.620778 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 8 finished
----------------------------------  ---------------
replay_buffer/size                  20000
trainer/num train calls              9000
trainer/QF1 Loss                        0.535117
trainer/QF2 Loss                        0.511035
trainer/Policy Loss                   107.383
trainer/Q1 Predictions Mean          -108.434
trainer/Q1 Predictions Std              2.4132
trainer/Q1 Predictions Max            -89.2099
trainer/Q1 Predictions Min           -110.577
trainer/Q2 Predictions Mean          -108.446
trainer/Q2 Predictions Std              2.42663
trainer/Q2 Predictions Max            -89.5693
trainer/Q2 Predictions Min           -110.647
trainer/Q Targets Mean               -109.007
trainer/Q Targets Std                   2.60551
trainer/Q Targets Max                 -88.6294
trainer/Q Targets Min                -111.13
trainer/Log Pis Mean                   -1.34374
trainer/Log Pis Std                     0.234131
trainer/Log Pis Max                    -0.852324
trainer/Log Pis Min                    -2.70057
trainer/policy/mean Mean                0.0206913
trainer/policy/mean Std                 0.0674092
trainer/policy/mean Max                 0.0920752
trainer/policy/mean Min                -0.0491799
trainer/policy/normal/std Mean          0.866744
trainer/policy/normal/std Std           0.00170716
trainer/policy/normal/std Max           0.873025
trainer/policy/normal/std Min           0.859315
trainer/policy/normal/log_std Mean     -0.143014
trainer/policy/normal/log_std Std       0.00197053
trainer/policy/normal/log_std Max      -0.135791
trainer/policy/normal/log_std Min      -0.15162
trainer/Alpha                           0.786541
trainer/Alpha Loss                     -0.802867
exploration/num steps total         20000
exploration/num paths total           100
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.73041
exploration/Rewards Std                 0.373969
exploration/Rewards Max                -4.26377
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1146.08
exploration/Returns Std                46.4023
exploration/Returns Max             -1028.86
exploration/Returns Min             -1190.28
exploration/Actions Mean                0.0283364
exploration/Actions Std                 0.589981
exploration/Actions Max                 0.991758
exploration/Actions Min                -0.9953
exploration/Num Paths                  10
exploration/Average Returns         -1146.08
evaluation/num steps total          43416
evaluation/num paths total            216
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05916
evaluation/Rewards Std                  0.0988646
evaluation/Rewards Max                 -5.59473
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1217.89
evaluation/Returns Std                 12.8323
evaluation/Returns Max              -1188.95
evaluation/Returns Min              -1231.5
evaluation/Actions Mean                 0.0207101
evaluation/Actions Std                  0.0674926
evaluation/Actions Max                  0.0898661
evaluation/Actions Min                 -0.0477801
evaluation/Num Paths                   24
evaluation/Average Returns          -1217.89
time/data storing (s)                   0.0327355
time/evaluation sampling (s)           15.9599
time/exploration sampling (s)           7.36525
time/logging (s)                        0.0231108
time/sac training (s)                  15.5386
time/saving (s)                         0.0259664
time/training (s)                       0.000136269
time/epoch (s)                         38.9457
time/total (s)                        381.27
Epoch                                   8
----------------------------------  ---------------
2020-11-09 13:28:46.415645 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 9 finished
----------------------------------  --------------
replay_buffer/size                  22000
trainer/num train calls             10000
trainer/QF1 Loss                       54.9453
trainer/QF2 Loss                       54.9459
trainer/Policy Loss                   124.022
trainer/Q1 Predictions Mean          -125.031
trainer/Q1 Predictions Std              2.27263
trainer/Q1 Predictions Max           -102.89
trainer/Q1 Predictions Min           -127.87
trainer/Q2 Predictions Mean          -125.019
trainer/Q2 Predictions Std              2.29275
trainer/Q2 Predictions Max           -102.447
trainer/Q2 Predictions Min           -127.924
trainer/Q Targets Mean               -125.42
trainer/Q Targets Std                   7.84094
trainer/Q Targets Max                  -5.90691
trainer/Q Targets Min                -128.675
trainer/Log Pis Mean                   -1.37449
trainer/Log Pis Std                     0.177725
trainer/Log Pis Max                    -0.965791
trainer/Log Pis Min                    -2.37075
trainer/policy/mean Mean                0.0172532
trainer/policy/mean Std                 0.0330889
trainer/policy/mean Max                 0.0528956
trainer/policy/mean Min                -0.0169566
trainer/policy/normal/std Mean          0.87044
trainer/policy/normal/std Std           0.00144218
trainer/policy/normal/std Max           0.876654
trainer/policy/normal/std Min           0.862754
trainer/policy/normal/log_std Mean     -0.138758
trainer/policy/normal/log_std Std       0.00165772
trainer/policy/normal/log_std Max      -0.131643
trainer/policy/normal/log_std Min      -0.147625
trainer/Alpha                           0.763294
trainer/Alpha Loss                     -0.911487
exploration/num steps total         22000
exploration/num paths total           110
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.69986
exploration/Rewards Std                 0.317851
exploration/Rewards Max                -4.51783
exploration/Rewards Min                -6.14202
exploration/Returns Mean            -1139.97
exploration/Returns Std                36.8381
exploration/Returns Max             -1088.65
exploration/Returns Min             -1191.43
exploration/Actions Mean                0.00283234
exploration/Actions Std                 0.584215
exploration/Actions Max                 0.999137
exploration/Actions Min                -0.996377
exploration/Num Paths                  10
exploration/Average Returns         -1139.97
evaluation/num steps total          48240
evaluation/num paths total            240
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.02357
evaluation/Rewards Std                  0.183789
evaluation/Rewards Max                 -5.11234
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1210.74
evaluation/Returns Std                 25.5418
evaluation/Returns Max              -1132.35
evaluation/Returns Min              -1231.36
evaluation/Actions Mean                 0.0172871
evaluation/Actions Std                  0.0331766
evaluation/Actions Max                  0.0515274
evaluation/Actions Min                 -0.0163235
evaluation/Num Paths                   24
evaluation/Average Returns          -1210.74
time/data storing (s)                   0.0234481
time/evaluation sampling (s)           15.1598
time/exploration sampling (s)           5.25876
time/logging (s)                        0.0163578
time/sac training (s)                  11.2698
time/saving (s)                         0.0195181
time/training (s)                       0.00010939
time/epoch (s)                         31.7478
time/total (s)                        414.037
Epoch                                   9
----------------------------------  --------------
2020-11-09 13:29:16.906138 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 10 finished
----------------------------------  --------------
replay_buffer/size                  24000
trainer/num train calls             11000
trainer/QF1 Loss                       75.2161
trainer/QF2 Loss                       75.126
trainer/Policy Loss                   139.697
trainer/Q1 Predictions Mean          -140.686
trainer/Q1 Predictions Std              3.64494
trainer/Q1 Predictions Max           -113.125
trainer/Q1 Predictions Min           -145.439
trainer/Q2 Predictions Mean          -140.673
trainer/Q2 Predictions Std              3.64897
trainer/Q2 Predictions Max           -113.388
trainer/Q2 Predictions Min           -145.527
trainer/Q Targets Mean               -140.961
trainer/Q Targets Std                   9.32176
trainer/Q Targets Max                  -5.42129
trainer/Q Targets Min                -145.689
trainer/Log Pis Mean                   -1.36899
trainer/Log Pis Std                     0.175218
trainer/Log Pis Max                    -0.904366
trainer/Log Pis Min                    -2.17997
trainer/policy/mean Mean                0.0265216
trainer/policy/mean Std                 0.0451606
trainer/policy/mean Max                 0.0762457
trainer/policy/mean Min                -0.0201944
trainer/policy/normal/std Mean          0.876042
trainer/policy/normal/std Std           0.00218818
trainer/policy/normal/std Max           0.882335
trainer/policy/normal/std Min           0.866016
trainer/policy/normal/log_std Mean     -0.132344
trainer/policy/normal/log_std Std       0.00249922
trainer/policy/normal/log_std Max      -0.125184
trainer/policy/normal/log_std Min      -0.143852
trainer/Alpha                           0.740738
trainer/Alpha Loss                     -1.01106
exploration/num steps total         24000
exploration/num paths total           120
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.54937
exploration/Rewards Std                 0.513311
exploration/Rewards Max                -3.8014
exploration/Rewards Min                -6.14204
exploration/Returns Mean            -1109.87
exploration/Returns Std                58.1672
exploration/Returns Max              -998.529
exploration/Returns Min             -1177.99
exploration/Actions Mean                0.0131707
exploration/Actions Std                 0.582486
exploration/Actions Max                 0.992554
exploration/Actions Min                -0.996181
exploration/Num Paths                  10
exploration/Average Returns         -1109.87
evaluation/num steps total          53064
evaluation/num paths total            264
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.08353
evaluation/Rewards Std                  0.0849713
evaluation/Rewards Max                 -5.50905
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1222.79
evaluation/Returns Std                 11.4486
evaluation/Returns Max              -1174.7
evaluation/Returns Min              -1232.05
evaluation/Actions Mean                 0.0264919
evaluation/Actions Std                  0.0451001
evaluation/Actions Max                  0.0729985
evaluation/Actions Min                 -0.0190755
evaluation/Num Paths                   24
evaluation/Average Returns          -1222.79
time/data storing (s)                   0.0238245
time/evaluation sampling (s)           12.6779
time/exploration sampling (s)           5.30307
time/logging (s)                        0.0168504
time/sac training (s)                  11.4093
time/saving (s)                         0.0226411
time/training (s)                       0.00012272
time/epoch (s)                         29.4537
time/total (s)                        444.508
Epoch                                  10
----------------------------------  --------------
2020-11-09 13:29:47.064840 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 11 finished
----------------------------------  ---------------
replay_buffer/size                  26000
trainer/num train calls             12000
trainer/QF1 Loss                        1.13367
trainer/QF2 Loss                        1.13138
trainer/Policy Loss                   154.765
trainer/Q1 Predictions Mean          -155.719
trainer/Q1 Predictions Std              4.89111
trainer/Q1 Predictions Max           -122.321
trainer/Q1 Predictions Min           -160.796
trainer/Q2 Predictions Mean          -155.708
trainer/Q2 Predictions Std              4.89897
trainer/Q2 Predictions Max           -122.76
trainer/Q2 Predictions Min           -160.815
trainer/Q Targets Mean               -156.637
trainer/Q Targets Std                   5.14837
trainer/Q Targets Max                -120.709
trainer/Q Targets Min                -161.304
trainer/Log Pis Mean                   -1.36876
trainer/Log Pis Std                     0.142797
trainer/Log Pis Max                    -1.00747
trainer/Log Pis Min                    -2.01787
trainer/policy/mean Mean                0.0167763
trainer/policy/mean Std                 0.0128456
trainer/policy/mean Max                 0.0312888
trainer/policy/mean Min                 0.00378588
trainer/policy/normal/std Mean          0.878419
trainer/policy/normal/std Std           0.00162868
trainer/policy/normal/std Max           0.883887
trainer/policy/normal/std Min           0.870805
trainer/policy/normal/log_std Mean     -0.129633
trainer/policy/normal/log_std Std       0.00185781
trainer/policy/normal/log_std Max      -0.123426
trainer/policy/normal/log_std Min      -0.138337
trainer/Alpha                           0.71884
trainer/Alpha Loss                     -1.11208
exploration/num steps total         26000
exploration/num paths total           130
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.71853
exploration/Rewards Std                 0.369915
exploration/Rewards Max                -3.68617
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1143.71
exploration/Returns Std                39.5319
exploration/Returns Max             -1048.86
exploration/Returns Min             -1178.95
exploration/Actions Mean                0.00973831
exploration/Actions Std                 0.590301
exploration/Actions Max                 0.997933
exploration/Actions Min                -0.994057
exploration/Num Paths                  10
exploration/Average Returns         -1143.71
evaluation/num steps total          57888
evaluation/num paths total            288
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.0074
evaluation/Rewards Std                  0.175513
evaluation/Rewards Max                 -4.98483
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1207.49
evaluation/Returns Std                 23.459
evaluation/Returns Max              -1124.69
evaluation/Returns Min              -1231.58
evaluation/Actions Mean                 0.0167846
evaluation/Actions Std                  0.0128539
evaluation/Actions Max                  0.0300791
evaluation/Actions Min                  0.00391198
evaluation/Num Paths                   24
evaluation/Average Returns          -1207.49
time/data storing (s)                   0.0239703
time/evaluation sampling (s)           12.7312
time/exploration sampling (s)           5.27528
time/logging (s)                        0.0189384
time/sac training (s)                  11.0739
time/saving (s)                         0.0224053
time/training (s)                       0.000108309
time/epoch (s)                         29.1458
time/total (s)                        474.648
Epoch                                  11
----------------------------------  ---------------
2020-11-09 13:30:16.949374 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 12 finished
----------------------------------  ---------------
replay_buffer/size                  28000
trainer/num train calls             13000
trainer/QF1 Loss                      217.341
trainer/QF2 Loss                      218.095
trainer/Policy Loss                   170.234
trainer/Q1 Predictions Mean          -171.161
trainer/Q1 Predictions Std              4.2024
trainer/Q1 Predictions Max           -144.881
trainer/Q1 Predictions Min           -176.992
trainer/Q2 Predictions Mean          -171.167
trainer/Q2 Predictions Std              4.19215
trainer/Q2 Predictions Max           -144.845
trainer/Q2 Predictions Min           -176.901
trainer/Q Targets Mean               -170.892
trainer/Q Targets Std                  15.3465
trainer/Q Targets Max                  -4.77472
trainer/Q Targets Min                -177.817
trainer/Log Pis Mean                   -1.37679
trainer/Log Pis Std                     0.166478
trainer/Log Pis Max                    -0.99419
trainer/Log Pis Min                    -2.36471
trainer/policy/mean Mean                0.0105362
trainer/policy/mean Std                 0.0378814
trainer/policy/mean Max                 0.0507677
trainer/policy/mean Min                -0.0289817
trainer/policy/normal/std Mean          0.874854
trainer/policy/normal/std Std           0.00149896
trainer/policy/normal/std Max           0.879833
trainer/policy/normal/std Min           0.867844
trainer/policy/normal/log_std Mean     -0.1337
trainer/policy/normal/log_std Std       0.00171416
trainer/policy/normal/log_std Max      -0.128023
trainer/policy/normal/log_std Min      -0.141744
trainer/Alpha                           0.697596
trainer/Alpha Loss                     -1.21603
exploration/num steps total         28000
exploration/num paths total           140
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.54785
exploration/Rewards Std                 0.413589
exploration/Rewards Max                -4.25136
exploration/Rewards Min                -6.142
exploration/Returns Mean            -1109.57
exploration/Returns Std                45.2086
exploration/Returns Max              -986.675
exploration/Returns Min             -1156.1
exploration/Actions Mean               -0.000109644
exploration/Actions Std                 0.593501
exploration/Actions Max                 0.997294
exploration/Actions Min                -0.99543
exploration/Num Paths                  10
exploration/Average Returns         -1109.57
evaluation/num steps total          62712
evaluation/num paths total            312
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.07779
evaluation/Rewards Std                  0.0761402
evaluation/Rewards Max                 -5.66115
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1221.64
evaluation/Returns Std                 10.3416
evaluation/Returns Max              -1182.88
evaluation/Returns Min              -1231.86
evaluation/Actions Mean                 0.0105296
evaluation/Actions Std                  0.037839
evaluation/Actions Max                  0.0487692
evaluation/Actions Min                 -0.0275687
evaluation/Num Paths                   24
evaluation/Average Returns          -1221.64
time/data storing (s)                   0.024292
time/evaluation sampling (s)           12.6375
time/exploration sampling (s)           5.30861
time/logging (s)                        0.0165132
time/sac training (s)                  10.8579
time/saving (s)                         0.0222504
time/training (s)                       8.9939e-05
time/epoch (s)                         28.8671
time/total (s)                        504.51
Epoch                                  12
----------------------------------  ---------------
2020-11-09 13:30:47.077193 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 13 finished
----------------------------------  --------------
replay_buffer/size                  30000
trainer/num train calls             14000
trainer/QF1 Loss                      257.619
trainer/QF2 Loss                      257.163
trainer/Policy Loss                   184.948
trainer/Q1 Predictions Mean          -185.842
trainer/Q1 Predictions Std              4.34569
trainer/Q1 Predictions Max           -149.77
trainer/Q1 Predictions Min           -193.298
trainer/Q2 Predictions Mean          -185.846
trainer/Q2 Predictions Std              4.34833
trainer/Q2 Predictions Max           -149.296
trainer/Q2 Predictions Min           -193.11
trainer/Q Targets Mean               -185.504
trainer/Q Targets Std                  16.6188
trainer/Q Targets Max                  -5.25431
trainer/Q Targets Min                -193.62
trainer/Log Pis Mean                   -1.37376
trainer/Log Pis Std                     0.164638
trainer/Log Pis Max                    -1.04016
trainer/Log Pis Min                    -2.35904
trainer/policy/mean Mean                0.0234628
trainer/policy/mean Std                 0.0177372
trainer/policy/mean Max                 0.0424895
trainer/policy/mean Min                 0.00556208
trainer/policy/normal/std Mean          0.873642
trainer/policy/normal/std Std           0.00107093
trainer/policy/normal/std Max           0.877159
trainer/policy/normal/std Min           0.868759
trainer/policy/normal/log_std Mean     -0.135085
trainer/policy/normal/log_std Std       0.00122621
trainer/policy/normal/log_std Max      -0.131067
trainer/policy/normal/log_std Min      -0.140689
trainer/Alpha                           0.676975
trainer/Alpha Loss                     -1.31617
exploration/num steps total         30000
exploration/num paths total           150
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.44102
exploration/Rewards Std                 0.724837
exploration/Rewards Max                -3.25214
exploration/Rewards Min                -6.14196
exploration/Returns Mean            -1088.2
exploration/Returns Std               103.961
exploration/Returns Max              -871.737
exploration/Returns Min             -1159.98
exploration/Actions Mean                0.0102169
exploration/Actions Std                 0.596328
exploration/Actions Max                 0.997275
exploration/Actions Min                -0.995841
exploration/Num Paths                  10
exploration/Average Returns         -1088.2
evaluation/num steps total          67536
evaluation/num paths total            336
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05758
evaluation/Rewards Std                  0.114334
evaluation/Rewards Max                 -5.37816
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1217.57
evaluation/Returns Std                 13.6721
evaluation/Returns Max              -1176.67
evaluation/Returns Min              -1231.12
evaluation/Actions Mean                 0.0234978
evaluation/Actions Std                  0.0177645
evaluation/Actions Max                  0.0417171
evaluation/Actions Min                  0.0057171
evaluation/Num Paths                   24
evaluation/Average Returns          -1217.57
time/data storing (s)                   0.0248319
time/evaluation sampling (s)           12.6408
time/exploration sampling (s)           5.26013
time/logging (s)                        0.0189346
time/sac training (s)                  11.1384
time/saving (s)                         0.0189442
time/training (s)                       8.9987e-05
time/epoch (s)                         29.1021
time/total (s)                        534.619
Epoch                                  13
----------------------------------  --------------
2020-11-09 13:31:17.140184 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 14 finished
----------------------------------  ---------------
replay_buffer/size                  32000
trainer/num train calls             15000
trainer/QF1 Loss                      148.312
trainer/QF2 Loss                      148.448
trainer/Policy Loss                   199.375
trainer/Q1 Predictions Mean          -200.234
trainer/Q1 Predictions Std              4.10593
trainer/Q1 Predictions Max           -168.337
trainer/Q1 Predictions Min           -208.814
trainer/Q2 Predictions Mean          -200.239
trainer/Q2 Predictions Std              4.106
trainer/Q2 Predictions Max           -168.34
trainer/Q2 Predictions Min           -208.589
trainer/Q Targets Mean               -200.285
trainer/Q Targets Std                  12.9022
trainer/Q Targets Max                  -5.61585
trainer/Q Targets Min                -208.999
trainer/Log Pis Mean                   -1.3662
trainer/Log Pis Std                     0.165695
trainer/Log Pis Max                    -0.984889
trainer/Log Pis Min                    -2.60332
trainer/policy/mean Mean                0.00201414
trainer/policy/mean Std                 0.0293164
trainer/policy/mean Max                 0.0322863
trainer/policy/mean Min                -0.0283346
trainer/policy/normal/std Mean          0.873523
trainer/policy/normal/std Std           0.00181357
trainer/policy/normal/std Max           0.879166
trainer/policy/normal/std Min           0.867766
trainer/policy/normal/log_std Mean     -0.135223
trainer/policy/normal/log_std Std       0.00207609
trainer/policy/normal/log_std Max      -0.128781
trainer/policy/normal/log_std Min      -0.141833
trainer/Alpha                           0.656964
trainer/Alpha Loss                     -1.41423
exploration/num steps total         32000
exploration/num paths total           160
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.75563
exploration/Rewards Std                 0.242866
exploration/Rewards Max                -4.84784
exploration/Rewards Min                -6.14204
exploration/Returns Mean            -1151.13
exploration/Returns Std                27.5412
exploration/Returns Max             -1082.15
exploration/Returns Min             -1179.59
exploration/Actions Mean               -0.00232776
exploration/Actions Std                 0.591561
exploration/Actions Max                 0.992944
exploration/Actions Min                -0.997999
exploration/Num Paths                  10
exploration/Average Returns         -1151.13
evaluation/num steps total          72360
evaluation/num paths total            360
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05861
evaluation/Rewards Std                  0.139187
evaluation/Rewards Max                 -5.18233
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1217.78
evaluation/Returns Std                 19.8443
evaluation/Returns Max              -1155.04
evaluation/Returns Min              -1230.66
evaluation/Actions Mean                 0.00201429
evaluation/Actions Std                  0.0293189
evaluation/Actions Max                  0.0318473
evaluation/Actions Min                 -0.0278367
evaluation/Num Paths                   24
evaluation/Average Returns          -1217.78
time/data storing (s)                   0.0229894
time/evaluation sampling (s)           12.5977
time/exploration sampling (s)           5.24848
time/logging (s)                        0.0189225
time/sac training (s)                  11.1236
time/saving (s)                         0.0201496
time/training (s)                       0.000111347
time/epoch (s)                         29.0319
time/total (s)                        564.662
Epoch                                  14
----------------------------------  ---------------
2020-11-09 13:31:47.290560 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 15 finished
----------------------------------  ---------------
replay_buffer/size                  34000
trainer/num train calls             16000
trainer/QF1 Loss                      172.291
trainer/QF2 Loss                      172.138
trainer/Policy Loss                   212.309
trainer/Q1 Predictions Mean          -213.159
trainer/Q1 Predictions Std              5.7058
trainer/Q1 Predictions Max           -170.52
trainer/Q1 Predictions Min           -219.929
trainer/Q2 Predictions Mean          -213.166
trainer/Q2 Predictions Std              5.67298
trainer/Q2 Predictions Max           -170.868
trainer/Q2 Predictions Min           -219.874
trainer/Q Targets Mean               -213.433
trainer/Q Targets Std                  14.2926
trainer/Q Targets Max                  -5.16937
trainer/Q Targets Min                -220.913
trainer/Log Pis Mean                   -1.33166
trainer/Log Pis Std                     0.190746
trainer/Log Pis Max                    -0.790407
trainer/Log Pis Min                    -1.93064
trainer/policy/mean Mean               -0.0146741
trainer/policy/mean Std                 0.0832171
trainer/policy/mean Max                 0.0700507
trainer/policy/mean Min                -0.100312
trainer/policy/normal/std Mean          0.869775
trainer/policy/normal/std Std           0.00142934
trainer/policy/normal/std Max           0.875457
trainer/policy/normal/std Min           0.865617
trainer/policy/normal/log_std Mean     -0.139522
trainer/policy/normal/log_std Std       0.00164313
trainer/policy/normal/log_std Max      -0.133009
trainer/policy/normal/log_std Min      -0.144313
trainer/Alpha                           0.63757
trainer/Alpha Loss                     -1.49955
exploration/num steps total         34000
exploration/num paths total           170
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.63508
exploration/Rewards Std                 0.444803
exploration/Rewards Max                -3.3332
exploration/Rewards Min                -6.14189
exploration/Returns Mean            -1127.02
exploration/Returns Std                45.7663
exploration/Returns Max             -1036.9
exploration/Returns Min             -1178.68
exploration/Actions Mean               -0.00314133
exploration/Actions Std                 0.585124
exploration/Actions Max                 0.996181
exploration/Actions Min                -0.998758
exploration/Num Paths                  10
exploration/Average Returns         -1127.02
evaluation/num steps total          77184
evaluation/num paths total            384
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05432
evaluation/Rewards Std                  0.125929
evaluation/Rewards Max                 -5.42913
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1216.92
evaluation/Returns Std                 19.2352
evaluation/Returns Max              -1148.98
evaluation/Returns Min              -1231.23
evaluation/Actions Mean                -0.0146776
evaluation/Actions Std                  0.0832304
evaluation/Actions Max                  0.0690213
evaluation/Actions Min                 -0.0986657
evaluation/Num Paths                   24
evaluation/Average Returns          -1216.92
time/data storing (s)                   0.0246329
time/evaluation sampling (s)           12.6646
time/exploration sampling (s)           5.25628
time/logging (s)                        0.0181665
time/sac training (s)                  11.1322
time/saving (s)                         0.0224307
time/training (s)                       0.000105681
time/epoch (s)                         29.1184
time/total (s)                        594.791
Epoch                                  15
----------------------------------  ---------------
2020-11-09 13:32:17.921827 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 16 finished
----------------------------------  --------------
replay_buffer/size                  36000
trainer/num train calls             17000
trainer/QF1 Loss                        1.18233
trainer/QF2 Loss                        1.19499
trainer/Policy Loss                   225.281
trainer/Q1 Predictions Mean          -226.092
trainer/Q1 Predictions Std              4.64986
trainer/Q1 Predictions Max           -204.758
trainer/Q1 Predictions Min           -235.454
trainer/Q2 Predictions Mean          -226.083
trainer/Q2 Predictions Std              4.6751
trainer/Q2 Predictions Max           -204.406
trainer/Q2 Predictions Min           -235.375
trainer/Q Targets Mean               -227.014
trainer/Q Targets Std                   4.82001
trainer/Q Targets Max                -203.087
trainer/Q Targets Min                -235.783
trainer/Log Pis Mean                   -1.35669
trainer/Log Pis Std                     0.161657
trainer/Log Pis Max                    -0.867205
trainer/Log Pis Min                    -1.9899
trainer/policy/mean Mean               -0.00290767
trainer/policy/mean Std                 0.0414027
trainer/policy/mean Max                 0.0393907
trainer/policy/mean Min                -0.0455457
trainer/policy/normal/std Mean          0.892434
trainer/policy/normal/std Std           0.00133048
trainer/policy/normal/std Max           0.895782
trainer/policy/normal/std Min           0.888724
trainer/policy/normal/log_std Mean     -0.113804
trainer/policy/normal/log_std Std       0.00149091
trainer/policy/normal/log_std Max      -0.110058
trainer/policy/normal/log_std Min      -0.117968
trainer/Alpha                           0.618741
trainer/Alpha Loss                     -1.61144
exploration/num steps total         36000
exploration/num paths total           180
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.51294
exploration/Rewards Std                 0.525308
exploration/Rewards Max                -3.28063
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1102.59
exploration/Returns Std                68.1938
exploration/Returns Max              -952.825
exploration/Returns Min             -1169.46
exploration/Actions Mean                0.0147018
exploration/Actions Std                 0.590152
exploration/Actions Max                 0.994845
exploration/Actions Min                -0.998958
exploration/Num Paths                  10
exploration/Average Returns         -1102.59
evaluation/num steps total          82008
evaluation/num paths total            408
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.03804
evaluation/Rewards Std                  0.141637
evaluation/Rewards Max                 -5.40257
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1213.65
evaluation/Returns Std                 19.8743
evaluation/Returns Max              -1151.56
evaluation/Returns Min              -1230.9
evaluation/Actions Mean                -0.00291331
evaluation/Actions Std                  0.0414373
evaluation/Actions Max                  0.0389693
evaluation/Actions Min                 -0.0449109
evaluation/Num Paths                   24
evaluation/Average Returns          -1213.65
time/data storing (s)                   0.0242913
time/evaluation sampling (s)           12.8085
time/exploration sampling (s)           5.47113
time/logging (s)                        0.0190745
time/sac training (s)                  11.253
time/saving (s)                         0.0216918
time/training (s)                       9.2518e-05
time/epoch (s)                         29.5978
time/total (s)                        625.403
Epoch                                  16
----------------------------------  --------------
2020-11-09 13:32:47.730264 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 17 finished
----------------------------------  ---------------
replay_buffer/size                  38000
trainer/num train calls             18000
trainer/QF1 Loss                      221.344
trainer/QF2 Loss                      221.414
trainer/Policy Loss                   237.126
trainer/Q1 Predictions Mean          -237.907
trainer/Q1 Predictions Std              6.97312
trainer/Q1 Predictions Max           -190.869
trainer/Q1 Predictions Min           -248.273
trainer/Q2 Predictions Mean          -237.905
trainer/Q2 Predictions Std              6.99144
trainer/Q2 Predictions Max           -190.554
trainer/Q2 Predictions Min           -247.99
trainer/Q Targets Mean               -238.287
trainer/Q Targets Std                  16.2217
trainer/Q Targets Max                  -5.11854
trainer/Q Targets Min                -249.053
trainer/Log Pis Mean                   -1.35292
trainer/Log Pis Std                     0.206704
trainer/Log Pis Max                    -0.791774
trainer/Log Pis Min                    -2.44457
trainer/policy/mean Mean               -0.0364541
trainer/policy/mean Std                 0.0907804
trainer/policy/mean Max                 0.0555521
trainer/policy/mean Min                -0.130219
trainer/policy/normal/std Mean          0.865341
trainer/policy/normal/std Std           0.00151185
trainer/policy/normal/std Max           0.873499
trainer/policy/normal/std Min           0.861454
trainer/policy/normal/log_std Mean     -0.144633
trainer/policy/normal/log_std Std       0.001746
trainer/policy/normal/log_std Max      -0.135249
trainer/policy/normal/log_std Min      -0.149134
trainer/Alpha                           0.600447
trainer/Alpha Loss                     -1.71026
exploration/num steps total         38000
exploration/num paths total           190
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.6241
exploration/Rewards Std                 0.458955
exploration/Rewards Max                -3.80984
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1124.82
exploration/Returns Std                50.6925
exploration/Returns Max             -1017.57
exploration/Returns Min             -1174.18
exploration/Actions Mean               -0.0138554
exploration/Actions Std                 0.586278
exploration/Actions Max                 0.993427
exploration/Actions Min                -0.995669
exploration/Num Paths                  10
exploration/Average Returns         -1124.82
evaluation/num steps total          86832
evaluation/num paths total            432
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.05292
evaluation/Rewards Std                  0.106772
evaluation/Rewards Max                 -5.45109
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1216.64
evaluation/Returns Std                 14.8347
evaluation/Returns Max              -1167.26
evaluation/Returns Min              -1231.41
evaluation/Actions Mean                -0.0364637
evaluation/Actions Std                  0.0908004
evaluation/Actions Max                  0.0547994
evaluation/Actions Min                 -0.128392
evaluation/Num Paths                   24
evaluation/Average Returns          -1216.64
time/data storing (s)                   0.0243901
time/evaluation sampling (s)           12.6597
time/exploration sampling (s)           5.23246
time/logging (s)                        0.0194627
time/sac training (s)                  10.8216
time/saving (s)                         0.0196445
time/training (s)                       0.000113115
time/epoch (s)                         28.7774
time/total (s)                        655.191
Epoch                                  17
----------------------------------  ---------------
2020-11-09 13:33:18.097374 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 18 finished
----------------------------------  --------------
replay_buffer/size                  40000
trainer/num train calls             19000
trainer/QF1 Loss                      240.09
trainer/QF2 Loss                      240.436
trainer/Policy Loss                   248.83
trainer/Q1 Predictions Mean          -249.583
trainer/Q1 Predictions Std              7.21633
trainer/Q1 Predictions Max           -200.696
trainer/Q1 Predictions Min           -260.77
trainer/Q2 Predictions Mean          -249.576
trainer/Q2 Predictions Std              7.24289
trainer/Q2 Predictions Max           -200.253
trainer/Q2 Predictions Min           -260.554
trainer/Q Targets Mean               -249.967
trainer/Q Targets Std                  17.0144
trainer/Q Targets Max                  -5.64667
trainer/Q Targets Min                -261.343
trainer/Log Pis Mean                   -1.3591
trainer/Log Pis Std                     0.145897
trainer/Log Pis Max                    -0.975137
trainer/Log Pis Min                    -1.89474
trainer/policy/mean Mean                0.00987538
trainer/policy/mean Std                 0.0356499
trainer/policy/mean Max                 0.0465463
trainer/policy/mean Min                -0.0265593
trainer/policy/normal/std Mean          0.869994
trainer/policy/normal/std Std           0.00205791
trainer/policy/normal/std Max           0.876637
trainer/policy/normal/std Min           0.86556
trainer/policy/normal/log_std Mean     -0.139272
trainer/policy/normal/log_std Std       0.00236524
trainer/policy/normal/log_std Max      -0.131662
trainer/policy/normal/log_std Min      -0.144378
trainer/Alpha                           0.582696
trainer/Alpha Loss                     -1.81422
exploration/num steps total         40000
exploration/num paths total           200
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.71718
exploration/Rewards Std                 0.25017
exploration/Rewards Max                -4.98026
exploration/Rewards Min                -6.14202
exploration/Returns Mean            -1143.44
exploration/Returns Std                29.1251
exploration/Returns Max             -1071.98
exploration/Returns Min             -1178
exploration/Actions Mean                0.00413107
exploration/Actions Std                 0.586361
exploration/Actions Max                 0.995387
exploration/Actions Min                -0.990442
exploration/Num Paths                  10
exploration/Average Returns         -1143.44
evaluation/num steps total          91656
evaluation/num paths total            456
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.02392
evaluation/Rewards Std                  0.172857
evaluation/Rewards Max                 -5.2414
evaluation/Rewards Min                 -6.14203
evaluation/Returns Mean             -1210.81
evaluation/Returns Std                 27.062
evaluation/Returns Max              -1121.58
evaluation/Returns Min              -1231.09
evaluation/Actions Mean                 0.00987177
evaluation/Actions Std                  0.0356293
evaluation/Actions Max                  0.0462012
evaluation/Actions Min                 -0.026267
evaluation/Num Paths                   24
evaluation/Average Returns          -1210.81
time/data storing (s)                   0.0235518
time/evaluation sampling (s)           12.9806
time/exploration sampling (s)           5.27707
time/logging (s)                        0.019052
time/sac training (s)                  11.0351
time/saving (s)                         0.0206455
time/training (s)                       9.3453e-05
time/epoch (s)                         29.3561
time/total (s)                        685.537
Epoch                                  18
----------------------------------  --------------
2020-11-09 13:33:47.876365 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 19 finished
----------------------------------  ---------------
replay_buffer/size                  42000
trainer/num train calls             20000
trainer/QF1 Loss                      269.91
trainer/QF2 Loss                      269.537
trainer/Policy Loss                   260.786
trainer/Q1 Predictions Mean          -261.523
trainer/Q1 Predictions Std              7.43357
trainer/Q1 Predictions Max           -210.442
trainer/Q1 Predictions Min           -274.071
trainer/Q2 Predictions Mean          -261.531
trainer/Q2 Predictions Std              7.43294
trainer/Q2 Predictions Max           -210.102
trainer/Q2 Predictions Min           -273.903
trainer/Q Targets Mean               -261.799
trainer/Q Targets Std                  17.7711
trainer/Q Targets Max                  -5.46575
trainer/Q Targets Min                -274.867
trainer/Log Pis Mean                   -1.37198
trainer/Log Pis Std                     0.191016
trainer/Log Pis Max                    -0.845149
trainer/Log Pis Min                    -2.13957
trainer/policy/mean Mean                0.0377261
trainer/policy/mean Std                 0.0683738
trainer/policy/mean Max                 0.109564
trainer/policy/mean Min                -0.0319723
trainer/policy/normal/std Mean          0.86798
trainer/policy/normal/std Std           0.00127404
trainer/policy/normal/std Max           0.873709
trainer/policy/normal/std Min           0.863215
trainer/policy/normal/log_std Mean     -0.141587
trainer/policy/normal/log_std Std       0.00146731
trainer/policy/normal/log_std Max      -0.135007
trainer/policy/normal/log_std Min      -0.147091
trainer/Alpha                           0.565483
trainer/Alpha Loss                     -1.92228
exploration/num steps total         42000
exploration/num paths total           210
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -5.60005
exploration/Rewards Std                 0.470096
exploration/Rewards Max                -3.83623
exploration/Rewards Min                -6.14203
exploration/Returns Mean            -1120.01
exploration/Returns Std                54.256
exploration/Returns Max              -982.15
exploration/Returns Min             -1181.21
exploration/Actions Mean                0.021502
exploration/Actions Std                 0.576887
exploration/Actions Max                 0.997653
exploration/Actions Min                -0.994035
exploration/Num Paths                  10
exploration/Average Returns         -1120.01
evaluation/num steps total          96480
evaluation/num paths total            480
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -6.08448
evaluation/Rewards Std                  0.0804338
evaluation/Rewards Max                 -5.53051
evaluation/Rewards Min                 -6.14204
evaluation/Returns Mean             -1222.98
evaluation/Returns Std                  9.38721
evaluation/Returns Max              -1195.94
evaluation/Returns Min              -1231.91
evaluation/Actions Mean                 0.0376951
evaluation/Actions Std                  0.0683038
evaluation/Actions Max                  0.107321
evaluation/Actions Min                 -0.0311318
evaluation/Num Paths                   24
evaluation/Average Returns          -1222.98
time/data storing (s)                   0.0235315
time/evaluation sampling (s)           12.6095
time/exploration sampling (s)           5.2429
time/logging (s)                        0.0200061
time/sac training (s)                  10.842
time/saving (s)                         0.0194479
time/training (s)                       0.000108575
time/epoch (s)                         28.7575
time/total (s)                        715.296
Epoch                                  19
----------------------------------  ---------------
2020-11-09 13:34:18.510141 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 20 finished
----------------------------------  ----------------
replay_buffer/size                   44000
trainer/num train calls              21000
trainer/QF1 Loss                       555.523
trainer/QF2 Loss                       555.406
trainer/Policy Loss                    271.52
trainer/Q1 Predictions Mean           -272.232
trainer/Q1 Predictions Std               7.97634
trainer/Q1 Predictions Max            -207.601
trainer/Q1 Predictions Min            -283.845
trainer/Q2 Predictions Mean           -272.23
trainer/Q2 Predictions Std               7.95902
trainer/Q2 Predictions Max            -208.116
trainer/Q2 Predictions Min            -283.733
trainer/Q Targets Mean                -271.671
trainer/Q Targets Std                   24.9716
trainer/Q Targets Max                   -5.46787
trainer/Q Targets Min                 -285.348
trainer/Log Pis Mean                    -1.35988
trainer/Log Pis Std                      0.19867
trainer/Log Pis Max                     -0.785012
trainer/Log Pis Min                     -2.1494
trainer/policy/mean Mean                -0.00064307
trainer/policy/mean Std                  0.0711669
trainer/policy/mean Max                  0.0735655
trainer/policy/mean Min                 -0.0751784
trainer/policy/normal/std Mean           0.885871
trainer/policy/normal/std Std            0.000992668
trainer/policy/normal/std Max            0.890189
trainer/policy/normal/std Min            0.881364
trainer/policy/normal/log_std Mean      -0.121185
trainer/policy/normal/log_std Std        0.00112042
trainer/policy/normal/log_std Max       -0.116321
trainer/policy/normal/log_std Min       -0.126285
trainer/Alpha                            0.548788
trainer/Alpha Loss                      -2.01607
exploration/num steps total          44000
exploration/num paths total            220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.75857
exploration/Rewards Std                  0.26846
exploration/Rewards Max                 -4.53483
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1151.71
exploration/Returns Std                 25.2865
exploration/Returns Max              -1090.99
exploration/Returns Min              -1180.98
exploration/Actions Mean                 0.0111289
exploration/Actions Std                  0.590762
exploration/Actions Max                  0.995865
exploration/Actions Min                 -0.99628
exploration/Num Paths                   10
exploration/Average Returns          -1151.71
evaluation/num steps total          101304
evaluation/num paths total             504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03664
evaluation/Rewards Std                   0.127468
evaluation/Rewards Max                  -5.48975
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1213.37
evaluation/Returns Std                  15.7238
evaluation/Returns Max               -1182.82
evaluation/Returns Min               -1231.42
evaluation/Actions Mean                 -0.000643137
evaluation/Actions Std                   0.0711479
evaluation/Actions Max                   0.0718158
evaluation/Actions Min                  -0.0732755
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.37
time/data storing (s)                    0.0240922
time/evaluation sampling (s)            12.5794
time/exploration sampling (s)            5.67156
time/logging (s)                         0.0181295
time/sac training (s)                   11.235
time/saving (s)                          0.0214738
time/training (s)                        0.000122083
time/epoch (s)                          29.5498
time/total (s)                         745.907
Epoch                                   20
----------------------------------  ----------------
2020-11-09 13:34:49.407027 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 21 finished
----------------------------------  ----------------
replay_buffer/size                   46000
trainer/num train calls              22000
trainer/QF1 Loss                       605.147
trainer/QF2 Loss                       604.332
trainer/Policy Loss                    283.097
trainer/Q1 Predictions Mean           -283.756
trainer/Q1 Predictions Std               6.35618
trainer/Q1 Predictions Max            -218.88
trainer/Q1 Predictions Min            -293.36
trainer/Q2 Predictions Mean           -283.751
trainer/Q2 Predictions Std               6.35478
trainer/Q2 Predictions Max            -219.293
trainer/Q2 Predictions Min            -293.289
trainer/Q Targets Mean                -283.368
trainer/Q Targets Std                   25.5417
trainer/Q Targets Max                   -5.05923
trainer/Q Targets Min                 -295.07
trainer/Log Pis Mean                    -1.33363
trainer/Log Pis Std                      0.286686
trainer/Log Pis Max                     -0.59447
trainer/Log Pis Min                     -2.28507
trainer/policy/mean Mean                -0.0293626
trainer/policy/mean Std                  0.127382
trainer/policy/mean Max                  0.100694
trainer/policy/mean Min                 -0.161313
trainer/policy/normal/std Mean           0.88474
trainer/policy/normal/std Std            0.0033964
trainer/policy/normal/std Max            0.891686
trainer/policy/normal/std Min            0.878499
trainer/policy/normal/log_std Mean      -0.122469
trainer/policy/normal/log_std Std        0.00383892
trainer/policy/normal/log_std Max       -0.114641
trainer/policy/normal/log_std Min       -0.129541
trainer/Alpha                            0.532615
trainer/Alpha Loss                      -2.10005
exploration/num steps total          46000
exploration/num paths total            230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.81181
exploration/Rewards Std                  0.239101
exploration/Rewards Max                 -4.87611
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1162.36
exploration/Returns Std                 22.2761
exploration/Returns Max              -1117.28
exploration/Returns Min              -1182.28
exploration/Actions Mean                -0.0166564
exploration/Actions Std                  0.59932
exploration/Actions Max                  0.998903
exploration/Actions Min                 -0.995397
exploration/Num Paths                   10
exploration/Average Returns          -1162.36
evaluation/num steps total          106128
evaluation/num paths total             528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03699
evaluation/Rewards Std                   0.148749
evaluation/Rewards Max                  -5.36172
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1213.43
evaluation/Returns Std                  21.7051
evaluation/Returns Max               -1159.97
evaluation/Returns Min               -1230.93
evaluation/Actions Mean                 -0.0292934
evaluation/Actions Std                   0.127112
evaluation/Actions Max                   0.0988197
evaluation/Actions Min                  -0.158091
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.43
time/data storing (s)                    0.0226176
time/evaluation sampling (s)            13.803
time/exploration sampling (s)            5.23318
time/logging (s)                         0.0164136
time/sac training (s)                   10.7769
time/saving (s)                          0.0200413
time/training (s)                        0.000111815
time/epoch (s)                          29.8723
time/total (s)                         776.782
Epoch                                   21
----------------------------------  ----------------
2020-11-09 13:35:17.675549 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 22 finished
----------------------------------  ---------------
replay_buffer/size                   48000
trainer/num train calls              23000
trainer/QF1 Loss                       980.834
trainer/QF2 Loss                       981.137
trainer/Policy Loss                    293.088
trainer/Q1 Predictions Mean           -293.744
trainer/Q1 Predictions Std               8.49399
trainer/Q1 Predictions Max            -247.245
trainer/Q1 Predictions Min            -308.743
trainer/Q2 Predictions Mean           -293.752
trainer/Q2 Predictions Std               8.47798
trainer/Q2 Predictions Max            -247.175
trainer/Q2 Predictions Min            -308.626
trainer/Q Targets Mean                -291.975
trainer/Q Targets Std                   32.3922
trainer/Q Targets Max                   -4.67965
trainer/Q Targets Min                 -309.891
trainer/Log Pis Mean                    -1.3687
trainer/Log Pis Std                      0.248284
trainer/Log Pis Max                     -0.799187
trainer/Log Pis Min                     -3.05955
trainer/policy/mean Mean                 0.035012
trainer/policy/mean Std                  0.088363
trainer/policy/mean Max                  0.127114
trainer/policy/mean Min                 -0.0552894
trainer/policy/normal/std Mean           0.86101
trainer/policy/normal/std Std            0.00186928
trainer/policy/normal/std Max            0.867909
trainer/policy/normal/std Min            0.855722
trainer/policy/normal/log_std Mean      -0.149651
trainer/policy/normal/log_std Std        0.00217082
trainer/policy/normal/log_std Max       -0.141669
trainer/policy/normal/log_std Min       -0.15581
trainer/Alpha                            0.516847
trainer/Alpha Loss                      -2.22337
exploration/num steps total          48000
exploration/num paths total            240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.6446
exploration/Rewards Std                  0.401822
exploration/Rewards Max                 -4.03677
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1128.92
exploration/Returns Std                 42.4646
exploration/Returns Max              -1055.35
exploration/Returns Min              -1184.36
exploration/Actions Mean                 0.0288438
exploration/Actions Std                  0.58412
exploration/Actions Max                  0.993298
exploration/Actions Min                 -0.998009
exploration/Num Paths                   10
exploration/Average Returns          -1128.92
evaluation/num steps total          110952
evaluation/num paths total             552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0582
evaluation/Rewards Std                   0.133751
evaluation/Rewards Max                  -5.39828
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1217.7
evaluation/Returns Std                  17.7529
evaluation/Returns Max               -1157.82
evaluation/Returns Min               -1230.9
evaluation/Actions Mean                  0.034945
evaluation/Actions Std                   0.0881216
evaluation/Actions Max                   0.125436
evaluation/Actions Min                  -0.0545211
evaluation/Num Paths                    24
evaluation/Average Returns           -1217.7
time/data storing (s)                    0.0196859
time/evaluation sampling (s)            12.1597
time/exploration sampling (s)            4.2626
time/logging (s)                         0.018877
time/sac training (s)                   10.764
time/saving (s)                          0.0225611
time/training (s)                        0.00010659
time/epoch (s)                          27.2475
time/total (s)                         805.032
Epoch                                   22
----------------------------------  ---------------
2020-11-09 13:35:43.884352 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 23 finished
----------------------------------  ---------------
replay_buffer/size                   50000
trainer/num train calls              24000
trainer/QF1 Loss                       636.223
trainer/QF2 Loss                       636.657
trainer/Policy Loss                    303.081
trainer/Q1 Predictions Mean           -303.74
trainer/Q1 Predictions Std               7.64184
trainer/Q1 Predictions Max            -262.209
trainer/Q1 Predictions Min            -319.034
trainer/Q2 Predictions Mean           -303.75
trainer/Q2 Predictions Std               7.64184
trainer/Q2 Predictions Max            -262.548
trainer/Q2 Predictions Min            -318.955
trainer/Q Targets Mean                -303.111
trainer/Q Targets Std                   27.5375
trainer/Q Targets Max                   -3.68617
trainer/Q Targets Min                 -320.525
trainer/Log Pis Mean                    -1.35097
trainer/Log Pis Std                      0.220742
trainer/Log Pis Max                     -0.73714
trainer/Log Pis Min                     -2.34876
trainer/policy/mean Mean                -0.00529837
trainer/policy/mean Std                  0.104399
trainer/policy/mean Max                  0.102013
trainer/policy/mean Min                 -0.113255
trainer/policy/normal/std Mean           0.866905
trainer/policy/normal/std Std            0.00266877
trainer/policy/normal/std Max            0.874476
trainer/policy/normal/std Min            0.860921
trainer/policy/normal/log_std Mean      -0.142831
trainer/policy/normal/log_std Std        0.00307821
trainer/policy/normal/log_std Max       -0.134131
trainer/policy/normal/log_std Min       -0.149753
trainer/Alpha                            0.50159
trainer/Alpha Loss                      -2.31208
exploration/num steps total          50000
exploration/num paths total            250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.66009
exploration/Rewards Std                  0.397399
exploration/Rewards Max                 -3.63674
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1132.02
exploration/Returns Std                 29.7053
exploration/Returns Max              -1070.04
exploration/Returns Min              -1172.06
exploration/Actions Mean                -0.0203245
exploration/Actions Std                  0.594711
exploration/Actions Max                  0.995743
exploration/Actions Min                 -0.997349
exploration/Num Paths                   10
exploration/Average Returns          -1132.02
evaluation/num steps total          115776
evaluation/num paths total             576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03918
evaluation/Rewards Std                   0.118829
evaluation/Rewards Max                  -5.41274
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1213.87
evaluation/Returns Std                  15.9091
evaluation/Returns Max               -1173.86
evaluation/Returns Min               -1230.69
evaluation/Actions Mean                 -0.00529071
evaluation/Actions Std                   0.10434
evaluation/Actions Max                   0.100595
evaluation/Actions Min                  -0.111514
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.87
time/data storing (s)                    0.0195812
time/evaluation sampling (s)            10.2203
time/exploration sampling (s)            4.20125
time/logging (s)                         0.0168434
time/sac training (s)                   10.7043
time/saving (s)                          0.0225677
time/training (s)                        9.6299e-05
time/epoch (s)                          25.185
time/total (s)                         831.218
Epoch                                   23
----------------------------------  ---------------
2020-11-09 13:36:10.120398 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 24 finished
----------------------------------  ----------------
replay_buffer/size                   52000
trainer/num train calls              25000
trainer/QF1 Loss                       739.421
trainer/QF2 Loss                       738.679
trainer/Policy Loss                    313.072
trainer/Q1 Predictions Mean           -313.723
trainer/Q1 Predictions Std               8.11576
trainer/Q1 Predictions Max            -271.516
trainer/Q1 Predictions Min            -329.393
trainer/Q2 Predictions Mean           -313.731
trainer/Q2 Predictions Std               8.12147
trainer/Q2 Predictions Max            -270.27
trainer/Q2 Predictions Min            -329.212
trainer/Q Targets Mean                -312.532
trainer/Q Targets Std                   28.4498
trainer/Q Targets Max                   -5.42626
trainer/Q Targets Min                 -330.581
trainer/Log Pis Mean                    -1.34562
trainer/Log Pis Std                      0.337061
trainer/Log Pis Max                     -0.720235
trainer/Log Pis Min                     -4.33201
trainer/policy/mean Mean                -0.0830731
trainer/policy/mean Std                  0.144866
trainer/policy/mean Max                  0.0638086
trainer/policy/mean Min                 -0.235335
trainer/policy/normal/std Mean           0.849734
trainer/policy/normal/std Std            0.00766789
trainer/policy/normal/std Max            0.866456
trainer/policy/normal/std Min            0.837763
trainer/policy/normal/log_std Mean      -0.162873
trainer/policy/normal/log_std Std        0.00902378
trainer/policy/normal/log_std Max       -0.143344
trainer/policy/normal/log_std Min       -0.17702
trainer/Alpha                            0.486766
trainer/Alpha Loss                      -2.40876
exploration/num steps total          52000
exploration/num paths total            260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.79101
exploration/Rewards Std                  0.22248
exploration/Rewards Max                 -4.73163
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1158.2
exploration/Returns Std                 20.936
exploration/Returns Max              -1104.38
exploration/Returns Min              -1182.28
exploration/Actions Mean                -0.0702928
exploration/Actions Std                  0.576448
exploration/Actions Max                  0.992603
exploration/Actions Min                 -0.995512
exploration/Num Paths                   10
exploration/Average Returns          -1158.2
evaluation/num steps total          120600
evaluation/num paths total             600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.02526
evaluation/Rewards Std                   0.162628
evaluation/Rewards Max                  -5.24031
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1211.08
evaluation/Returns Std                  21.5452
evaluation/Returns Max               -1154.2
evaluation/Returns Min               -1230.89
evaluation/Actions Mean                 -0.0830813
evaluation/Actions Std                   0.144866
evaluation/Actions Max                   0.0621047
evaluation/Actions Min                  -0.228978
evaluation/Num Paths                    24
evaluation/Average Returns           -1211.08
time/data storing (s)                    0.0198793
time/evaluation sampling (s)            10.2632
time/exploration sampling (s)            4.22558
time/logging (s)                         0.0167047
time/sac training (s)                   10.6342
time/saving (s)                          0.0202245
time/training (s)                        0.000114643
time/epoch (s)                          25.1799
time/total (s)                         857.434
Epoch                                   24
----------------------------------  ----------------
2020-11-09 13:36:36.520763 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 25 finished
----------------------------------  ----------------
replay_buffer/size                   54000
trainer/num train calls              26000
trainer/QF1 Loss                       827.062
trainer/QF2 Loss                       827.224
trainer/Policy Loss                    322.156
trainer/Q1 Predictions Mean           -322.761
trainer/Q1 Predictions Std               9.29846
trainer/Q1 Predictions Max            -260.338
trainer/Q1 Predictions Min            -336.455
trainer/Q2 Predictions Mean           -322.774
trainer/Q2 Predictions Std               9.28179
trainer/Q2 Predictions Max            -260.154
trainer/Q2 Predictions Min            -336.094
trainer/Q Targets Mean                -322.023
trainer/Q Targets Std                   29.6328
trainer/Q Targets Max                   -5.22749
trainer/Q Targets Min                 -337.635
trainer/Log Pis Mean                    -1.37663
trainer/Log Pis Std                      0.180587
trainer/Log Pis Max                     -0.788312
trainer/Log Pis Min                     -1.99539
trainer/policy/mean Mean                -0.00779516
trainer/policy/mean Std                  0.0583263
trainer/policy/mean Max                  0.0520217
trainer/policy/mean Min                 -0.0685136
trainer/policy/normal/std Mean           0.895365
trainer/policy/normal/std Std            0.0014734
trainer/policy/normal/std Max            0.9024
trainer/policy/normal/std Min            0.892358
trainer/policy/normal/log_std Mean      -0.110525
trainer/policy/normal/log_std Std        0.00164389
trainer/policy/normal/log_std Max       -0.102697
trainer/policy/normal/log_std Min       -0.113887
trainer/Alpha                            0.472388
trainer/Alpha Loss                      -2.53232
exploration/num steps total          54000
exploration/num paths total            270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.49565
exploration/Rewards Std                  0.761698
exploration/Rewards Max                 -2.20702
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1099.13
exploration/Returns Std                 95.6525
exploration/Returns Max               -907.857
exploration/Returns Min              -1184.91
exploration/Actions Mean                 0.00161242
exploration/Actions Std                  0.598137
exploration/Actions Max                  0.995804
exploration/Actions Min                 -0.995859
exploration/Num Paths                   10
exploration/Average Returns          -1099.13
evaluation/num steps total          125424
evaluation/num paths total             624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07151
evaluation/Rewards Std                   0.0904497
evaluation/Rewards Max                  -5.60083
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1220.37
evaluation/Returns Std                  10.2994
evaluation/Returns Max               -1199.04
evaluation/Returns Min               -1231.57
evaluation/Actions Mean                 -0.00777994
evaluation/Actions Std                   0.0582415
evaluation/Actions Max                   0.0512884
evaluation/Actions Min                  -0.067327
evaluation/Num Paths                    24
evaluation/Average Returns           -1220.37
time/data storing (s)                    0.0192469
time/evaluation sampling (s)            10.3347
time/exploration sampling (s)            4.30971
time/logging (s)                         0.0191043
time/sac training (s)                   10.6528
time/saving (s)                          0.0222156
time/training (s)                        0.000111657
time/epoch (s)                          25.3579
time/total (s)                         883.816
Epoch                                   25
----------------------------------  ----------------
2020-11-09 13:37:02.867444 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 26 finished
----------------------------------  ----------------
replay_buffer/size                   56000
trainer/num train calls              27000
trainer/QF1 Loss                       351.58
trainer/QF2 Loss                       353.015
trainer/Policy Loss                    331.526
trainer/Q1 Predictions Mean           -332.109
trainer/Q1 Predictions Std               9.80448
trainer/Q1 Predictions Max            -275.129
trainer/Q1 Predictions Min            -349.181
trainer/Q2 Predictions Mean           -332.101
trainer/Q2 Predictions Std               9.81688
trainer/Q2 Predictions Max            -275.037
trainer/Q2 Predictions Min            -348.996
trainer/Q Targets Mean                -332.552
trainer/Q Targets Std                   22.7499
trainer/Q Targets Max                   -4.29691
trainer/Q Targets Min                 -350.438
trainer/Log Pis Mean                    -1.35514
trainer/Log Pis Std                      0.223104
trainer/Log Pis Max                     -0.83516
trainer/Log Pis Min                     -2.40055
trainer/policy/mean Mean                 0.0458424
trainer/policy/mean Std                  0.0840021
trainer/policy/mean Max                  0.134001
trainer/policy/mean Min                 -0.0400143
trainer/policy/normal/std Mean           0.857095
trainer/policy/normal/std Std            0.00236452
trainer/policy/normal/std Max            0.866318
trainer/policy/normal/std Min            0.85141
trainer/policy/normal/log_std Mean      -0.15421
trainer/policy/normal/log_std Std        0.00275654
trainer/policy/normal/log_std Max       -0.143503
trainer/policy/normal/log_std Min       -0.160862
trainer/Alpha                            0.45839
trainer/Alpha Loss                      -2.61713
exploration/num steps total          56000
exploration/num paths total            280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.70356
exploration/Rewards Std                  0.377167
exploration/Rewards Max                 -4.47117
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1140.71
exploration/Returns Std                 51.2649
exploration/Returns Max              -1036.17
exploration/Returns Min              -1193.68
exploration/Actions Mean                 0.0274002
exploration/Actions Std                  0.585469
exploration/Actions Max                  0.99707
exploration/Actions Min                 -0.998177
exploration/Num Paths                   10
exploration/Average Returns          -1140.71
evaluation/num steps total          130248
evaluation/num paths total             648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04057
evaluation/Rewards Std                   0.137177
evaluation/Rewards Max                  -5.4023
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1214.15
evaluation/Returns Std                  18.9497
evaluation/Returns Max               -1170.57
evaluation/Returns Min               -1232.14
evaluation/Actions Mean                  0.0458272
evaluation/Actions Std                   0.0839509
evaluation/Actions Max                   0.133335
evaluation/Actions Min                  -0.0397971
evaluation/Num Paths                    24
evaluation/Average Returns           -1214.15
time/data storing (s)                    0.0201776
time/evaluation sampling (s)            10.2163
time/exploration sampling (s)            4.28114
time/logging (s)                         0.0175441
time/sac training (s)                   10.7415
time/saving (s)                          0.0227935
time/training (s)                        0.000106554
time/epoch (s)                          25.2995
time/total (s)                         910.141
Epoch                                   26
----------------------------------  ----------------
2020-11-09 13:37:29.136145 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 27 finished
----------------------------------  ----------------
replay_buffer/size                   58000
trainer/num train calls              28000
trainer/QF1 Loss                         3.89931
trainer/QF2 Loss                         3.86656
trainer/Policy Loss                    340.983
trainer/Q1 Predictions Mean           -341.535
trainer/Q1 Predictions Std               9.24739
trainer/Q1 Predictions Max            -290.399
trainer/Q1 Predictions Min            -356.474
trainer/Q2 Predictions Mean           -341.536
trainer/Q2 Predictions Std               9.2408
trainer/Q2 Predictions Max            -290.084
trainer/Q2 Predictions Min            -356.514
trainer/Q Targets Mean                -343.352
trainer/Q Targets Std                    9.40329
trainer/Q Targets Max                 -290.206
trainer/Q Targets Min                 -358.281
trainer/Log Pis Mean                    -1.36108
trainer/Log Pis Std                      0.199477
trainer/Log Pis Max                     -0.822175
trainer/Log Pis Min                     -2.10754
trainer/policy/mean Mean                -0.0250414
trainer/policy/mean Std                  0.058252
trainer/policy/mean Max                  0.0342567
trainer/policy/mean Min                 -0.0870121
trainer/policy/normal/std Mean           0.887491
trainer/policy/normal/std Std            0.00254937
trainer/policy/normal/std Max            0.897331
trainer/policy/normal/std Min            0.882017
trainer/policy/normal/log_std Mean      -0.119362
trainer/policy/normal/log_std Std        0.00287097
trainer/policy/normal/log_std Max       -0.108331
trainer/policy/normal/log_std Min       -0.125544
trainer/Alpha                            0.444844
trainer/Alpha Loss                      -2.72259
exploration/num steps total          58000
exploration/num paths total            290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.56497
exploration/Rewards Std                  0.512703
exploration/Rewards Max                 -3.53136
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1112.99
exploration/Returns Std                 56.078
exploration/Returns Max               -977.963
exploration/Returns Min              -1178.44
exploration/Actions Mean                -0.0311796
exploration/Actions Std                  0.588453
exploration/Actions Max                  0.996177
exploration/Actions Min                 -0.995934
exploration/Num Paths                   10
exploration/Average Returns          -1112.99
evaluation/num steps total          135072
evaluation/num paths total             672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.99024
evaluation/Rewards Std                   0.189466
evaluation/Rewards Max                  -5.27906
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1204.04
evaluation/Returns Std                  26.689
evaluation/Returns Max               -1140.24
evaluation/Returns Min               -1229.76
evaluation/Actions Mean                 -0.0249717
evaluation/Actions Std                   0.0581183
evaluation/Actions Max                   0.0335928
evaluation/Actions Min                  -0.0845591
evaluation/Num Paths                    24
evaluation/Average Returns           -1204.04
time/data storing (s)                    0.0199986
time/evaluation sampling (s)            10.3248
time/exploration sampling (s)            4.28219
time/logging (s)                         0.0177347
time/sac training (s)                   10.5815
time/saving (s)                          0.0224154
time/training (s)                        0.000109068
time/epoch (s)                          25.2488
time/total (s)                         936.389
Epoch                                   27
----------------------------------  ----------------
2020-11-09 13:37:55.768763 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 28 finished
----------------------------------  ----------------
replay_buffer/size                   60000
trainer/num train calls              29000
trainer/QF1 Loss                       477.818
trainer/QF2 Loss                       477.914
trainer/Policy Loss                    347.87
trainer/Q1 Predictions Mean           -348.405
trainer/Q1 Predictions Std              11.3739
trainer/Q1 Predictions Max            -287.496
trainer/Q1 Predictions Min            -366.098
trainer/Q2 Predictions Mean           -348.406
trainer/Q2 Predictions Std              11.3724
trainer/Q2 Predictions Max            -286.947
trainer/Q2 Predictions Min            -366.053
trainer/Q Targets Mean                -348.644
trainer/Q Targets Std                   24.4584
trainer/Q Targets Max                   -5.50953
trainer/Q Targets Min                 -368.185
trainer/Log Pis Mean                    -1.36779
trainer/Log Pis Std                      0.193544
trainer/Log Pis Max                     -0.839729
trainer/Log Pis Min                     -1.98307
trainer/policy/mean Mean                -0.00258856
trainer/policy/mean Std                  0.0653451
trainer/policy/mean Max                  0.0650702
trainer/policy/mean Min                 -0.071551
trainer/policy/normal/std Mean           0.902164
trainer/policy/normal/std Std            0.00333197
trainer/policy/normal/std Max            0.911248
trainer/policy/normal/std Min            0.895836
trainer/policy/normal/log_std Mean      -0.102966
trainer/policy/normal/log_std Std        0.00369305
trainer/policy/normal/log_std Max       -0.0929404
trainer/policy/normal/log_std Min       -0.109998
trainer/Alpha                            0.431723
trainer/Alpha Loss                      -2.82884
exploration/num steps total          60000
exploration/num paths total            300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.47358
exploration/Rewards Std                  0.620761
exploration/Rewards Max                 -2.7883
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1094.72
exploration/Returns Std                 83.8569
exploration/Returns Max               -873.139
exploration/Returns Min              -1178.16
exploration/Actions Mean                -0.00171629
exploration/Actions Std                  0.588393
exploration/Actions Max                  0.996122
exploration/Actions Min                 -0.996413
exploration/Num Paths                   10
exploration/Average Returns          -1094.72
evaluation/num steps total          139896
evaluation/num paths total             696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.00755
evaluation/Rewards Std                   0.175994
evaluation/Rewards Max                  -5.19134
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1207.52
evaluation/Returns Std                  23.998
evaluation/Returns Max               -1129.09
evaluation/Returns Min               -1231.26
evaluation/Actions Mean                 -0.00259847
evaluation/Actions Std                   0.0653776
evaluation/Actions Max                   0.0635178
evaluation/Actions Min                  -0.0690777
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.52
time/data storing (s)                    0.0203203
time/evaluation sampling (s)            10.2158
time/exploration sampling (s)            4.30188
time/logging (s)                         0.0176021
time/sac training (s)                   10.9944
time/saving (s)                          0.0279198
time/training (s)                        0.000124278
time/epoch (s)                          25.578
time/total (s)                         962.999
Epoch                                   28
----------------------------------  ----------------
2020-11-09 13:38:30.509611 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 29 finished
----------------------------------  ----------------
replay_buffer/size                   62000
trainer/num train calls              30000
trainer/QF1 Loss                       473.398
trainer/QF2 Loss                       473.001
trainer/Policy Loss                    357.028
trainer/Q1 Predictions Mean           -357.544
trainer/Q1 Predictions Std              10.0131
trainer/Q1 Predictions Max            -295.324
trainer/Q1 Predictions Min            -375.338
trainer/Q2 Predictions Mean           -357.542
trainer/Q2 Predictions Std              10.0096
trainer/Q2 Predictions Max            -295.031
trainer/Q2 Predictions Min            -375.242
trainer/Q Targets Mean                -357.872
trainer/Q Targets Std                   24.2501
trainer/Q Targets Max                   -5.75225
trainer/Q Targets Min                 -377.089
trainer/Log Pis Mean                    -1.34105
trainer/Log Pis Std                      0.259211
trainer/Log Pis Max                     -0.794948
trainer/Log Pis Min                     -3.31038
trainer/policy/mean Mean                 0.087823
trainer/policy/mean Std                  0.0801519
trainer/policy/mean Max                  0.174859
trainer/policy/mean Min                  0.00698372
trainer/policy/normal/std Mean           0.871438
trainer/policy/normal/std Std            0.00378602
trainer/policy/normal/std Max            0.880862
trainer/policy/normal/std Min            0.863103
trainer/policy/normal/log_std Mean      -0.137621
trainer/policy/normal/log_std Std        0.00434441
trainer/policy/normal/log_std Max       -0.126854
trainer/policy/normal/log_std Min       -0.147221
trainer/Alpha                            0.418964
trainer/Alpha Loss                      -2.90661
exploration/num steps total          62000
exploration/num paths total            310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.73329
exploration/Rewards Std                  0.318522
exploration/Rewards Max                 -4.26329
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1146.66
exploration/Returns Std                 34.9484
exploration/Returns Max              -1075.2
exploration/Returns Min              -1198.9
exploration/Actions Mean                 0.0670403
exploration/Actions Std                  0.586978
exploration/Actions Max                  0.999045
exploration/Actions Min                 -0.99326
exploration/Num Paths                   10
exploration/Average Returns          -1146.66
evaluation/num steps total          144720
evaluation/num paths total             720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04366
evaluation/Rewards Std                   0.14071
evaluation/Rewards Max                  -5.32145
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1214.78
evaluation/Returns Std                  19.7695
evaluation/Returns Max               -1160.69
evaluation/Returns Min               -1231.21
evaluation/Actions Mean                  0.0877411
evaluation/Actions Std                   0.0800379
evaluation/Actions Max                   0.172259
evaluation/Actions Min                   0.00725071
evaluation/Num Paths                    24
evaluation/Average Returns           -1214.78
time/data storing (s)                    0.0227484
time/evaluation sampling (s)            13.6518
time/exploration sampling (s)            6.13608
time/logging (s)                         0.0197935
time/sac training (s)                   13.6624
time/saving (s)                          0.0216376
time/training (s)                        0.000117118
time/epoch (s)                          33.5146
time/total (s)                         997.718
Epoch                                   29
----------------------------------  ----------------
2020-11-09 13:39:02.412826 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 30 finished
----------------------------------  ---------------
replay_buffer/size                   64000
trainer/num train calls              31000
trainer/QF1 Loss                       475.92
trainer/QF2 Loss                       475.825
trainer/Policy Loss                    363.903
trainer/Q1 Predictions Mean           -364.438
trainer/Q1 Predictions Std              11.1758
trainer/Q1 Predictions Max            -302.354
trainer/Q1 Predictions Min            -380.118
trainer/Q2 Predictions Mean           -364.453
trainer/Q2 Predictions Std              11.1671
trainer/Q2 Predictions Max            -301.711
trainer/Q2 Predictions Min            -380.402
trainer/Q Targets Mean                -364.484
trainer/Q Targets Std                   25.164
trainer/Q Targets Max                   -5.63165
trainer/Q Targets Min                 -381.328
trainer/Log Pis Mean                    -1.39009
trainer/Log Pis Std                      0.210461
trainer/Log Pis Max                     -0.973248
trainer/Log Pis Min                     -2.88282
trainer/policy/mean Mean                 0.0427152
trainer/policy/mean Std                  0.0235159
trainer/policy/mean Max                  0.0686347
trainer/policy/mean Min                  0.0176524
trainer/policy/normal/std Mean           0.886397
trainer/policy/normal/std Std            0.00328826
trainer/policy/normal/std Max            0.894289
trainer/policy/normal/std Min            0.877372
trainer/policy/normal/log_std Mean      -0.120597
trainer/policy/normal/log_std Std        0.00370986
trainer/policy/normal/log_std Max       -0.111726
trainer/policy/normal/log_std Min       -0.130824
trainer/Alpha                            0.406561
trainer/Alpha Loss                      -3.05115
exploration/num steps total          64000
exploration/num paths total            320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.55623
exploration/Rewards Std                  0.60774
exploration/Rewards Max                 -3.52426
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1111.25
exploration/Returns Std                108.67
exploration/Returns Max               -795.366
exploration/Returns Min              -1185.97
exploration/Actions Mean                 0.0326418
exploration/Actions Std                  0.593076
exploration/Actions Max                  0.997574
exploration/Actions Min                 -0.996665
exploration/Num Paths                   10
exploration/Average Returns          -1111.25
evaluation/num steps total          149544
evaluation/num paths total             744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04479
evaluation/Rewards Std                   0.122459
evaluation/Rewards Max                  -5.45413
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1215
evaluation/Returns Std                  16.9644
evaluation/Returns Max               -1173.03
evaluation/Returns Min               -1231.49
evaluation/Actions Mean                  0.0426157
evaluation/Actions Std                   0.0235203
evaluation/Actions Max                   0.0671471
evaluation/Actions Min                   0.0189048
evaluation/Num Paths                    24
evaluation/Average Returns           -1215
time/data storing (s)                    0.0251143
time/evaluation sampling (s)            12.6116
time/exploration sampling (s)            5.89156
time/logging (s)                         0.0245947
time/sac training (s)                   12.2214
time/saving (s)                          0.0238199
time/training (s)                        8.9683e-05
time/epoch (s)                          30.7982
time/total (s)                        1029.6
Epoch                                   30
----------------------------------  ---------------
2020-11-09 13:39:30.627755 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 31 finished
----------------------------------  ----------------
replay_buffer/size                   66000
trainer/num train calls              32000
trainer/QF1 Loss                       524.319
trainer/QF2 Loss                       524.304
trainer/Policy Loss                    370.71
trainer/Q1 Predictions Mean           -371.203
trainer/Q1 Predictions Std              12.4127
trainer/Q1 Predictions Max            -292.54
trainer/Q1 Predictions Min            -388.605
trainer/Q2 Predictions Mean           -371.191
trainer/Q2 Predictions Std              12.4152
trainer/Q2 Predictions Max            -292.307
trainer/Q2 Predictions Min            -388.678
trainer/Q Targets Mean                -371.226
trainer/Q Targets Std                   26.1884
trainer/Q Targets Max                   -5.45965
trainer/Q Targets Min                 -389.781
trainer/Log Pis Mean                    -1.35432
trainer/Log Pis Std                      0.154128
trainer/Log Pis Max                     -1.01356
trainer/Log Pis Min                     -2.04413
trainer/policy/mean Mean                 0.0345031
trainer/policy/mean Std                  0.00574257
trainer/policy/mean Max                  0.0406717
trainer/policy/mean Min                  0.027192
trainer/policy/normal/std Mean           0.870328
trainer/policy/normal/std Std            0.00167249
trainer/policy/normal/std Max            0.875621
trainer/policy/normal/std Min            0.865919
trainer/policy/normal/log_std Mean      -0.138887
trainer/policy/normal/log_std Std        0.00192162
trainer/policy/normal/log_std Max       -0.132822
trainer/policy/normal/log_std Min       -0.143964
trainer/Alpha                            0.394526
trainer/Alpha Loss                      -3.11975
exploration/num steps total          66000
exploration/num paths total            330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.43844
exploration/Rewards Std                  0.904822
exploration/Rewards Max                 -2.07202
exploration/Rewards Min                 -6.14191
exploration/Returns Mean             -1087.69
exploration/Returns Std                119.052
exploration/Returns Max               -794.452
exploration/Returns Min              -1188.63
exploration/Actions Mean                 0.021388
exploration/Actions Std                  0.583649
exploration/Actions Max                  0.996848
exploration/Actions Min                 -0.998197
exploration/Num Paths                   10
exploration/Average Returns          -1087.69
evaluation/num steps total          154368
evaluation/num paths total             768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05615
evaluation/Rewards Std                   0.123308
evaluation/Rewards Max                  -5.26811
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1217.29
evaluation/Returns Std                  14.7625
evaluation/Returns Max               -1165.82
evaluation/Returns Min               -1231.36
evaluation/Actions Mean                  0.0344963
evaluation/Actions Std                   0.00573983
evaluation/Actions Max                   0.0405128
evaluation/Actions Min                   0.0285165
evaluation/Num Paths                    24
evaluation/Average Returns           -1217.29
time/data storing (s)                    0.0206195
time/evaluation sampling (s)            11.6526
time/exploration sampling (s)            4.37161
time/logging (s)                         0.01765
time/sac training (s)                   11.0589
time/saving (s)                          0.0232359
time/training (s)                        0.000109878
time/epoch (s)                          27.1447
time/total (s)                        1057.79
Epoch                                   31
----------------------------------  ----------------
2020-11-09 13:40:00.456807 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 32 finished
----------------------------------  ---------------
replay_buffer/size                   68000
trainer/num train calls              33000
trainer/QF1 Loss                       569.009
trainer/QF2 Loss                       568.489
trainer/Policy Loss                    380.443
trainer/Q1 Predictions Mean           -380.905
trainer/Q1 Predictions Std              10.0015
trainer/Q1 Predictions Max            -330.076
trainer/Q1 Predictions Min            -400.453
trainer/Q2 Predictions Mean           -380.923
trainer/Q2 Predictions Std               9.98491
trainer/Q2 Predictions Max            -330.905
trainer/Q2 Predictions Min            -400.641
trainer/Q Targets Mean                -381.294
trainer/Q Targets Std                   25.6071
trainer/Q Targets Max                   -5.58115
trainer/Q Targets Min                 -401.383
trainer/Log Pis Mean                    -1.33989
trainer/Log Pis Std                      0.238808
trainer/Log Pis Max                     -0.671905
trainer/Log Pis Min                     -2.21117
trainer/policy/mean Mean                 0.120278
trainer/policy/mean Std                  0.013263
trainer/policy/mean Max                  0.136433
trainer/policy/mean Min                  0.102107
trainer/policy/normal/std Mean           0.87049
trainer/policy/normal/std Std            0.00105969
trainer/policy/normal/std Max            0.874826
trainer/policy/normal/std Min            0.867449
trainer/policy/normal/log_std Mean      -0.1387
trainer/policy/normal/log_std Std        0.00121691
trainer/policy/normal/log_std Max       -0.13373
trainer/policy/normal/log_std Min       -0.142198
trainer/Alpha                            0.382898
trainer/Alpha Loss                      -3.20625
exploration/num steps total          68000
exploration/num paths total            340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.66004
exploration/Rewards Std                  0.411481
exploration/Rewards Max                 -3.49016
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1132.01
exploration/Returns Std                 34.4516
exploration/Returns Max              -1042.68
exploration/Returns Min              -1175.93
exploration/Actions Mean                 0.0767149
exploration/Actions Std                  0.58318
exploration/Actions Max                  0.996537
exploration/Actions Min                 -0.99492
exploration/Num Paths                   10
exploration/Average Returns          -1132.01
evaluation/num steps total          159192
evaluation/num paths total             792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05095
evaluation/Rewards Std                   0.115267
evaluation/Rewards Max                  -5.28724
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1216.24
evaluation/Returns Std                  15.3875
evaluation/Returns Max               -1167.08
evaluation/Returns Min               -1229.79
evaluation/Actions Mean                  0.120157
evaluation/Actions Std                   0.0132317
evaluation/Actions Max                   0.134992
evaluation/Actions Min                   0.106064
evaluation/Num Paths                    24
evaluation/Average Returns           -1216.24
time/data storing (s)                    0.0198068
time/evaluation sampling (s)            11.7069
time/exploration sampling (s)            4.71633
time/logging (s)                         0.0207972
time/sac training (s)                   12.1737
time/saving (s)                          0.0215746
time/training (s)                        0.00011498
time/epoch (s)                          28.6592
time/total (s)                        1087.6
Epoch                                   32
----------------------------------  ---------------
2020-11-09 13:40:32.913088 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 33 finished
----------------------------------  ---------------
replay_buffer/size                   70000
trainer/num train calls              34000
trainer/QF1 Loss                         4.8938
trainer/QF2 Loss                         4.84944
trainer/Policy Loss                    386.433
trainer/Q1 Predictions Mean           -386.888
trainer/Q1 Predictions Std              12.8958
trainer/Q1 Predictions Max            -312.557
trainer/Q1 Predictions Min            -406.329
trainer/Q2 Predictions Mean           -386.897
trainer/Q2 Predictions Std              12.8882
trainer/Q2 Predictions Max            -312.122
trainer/Q2 Predictions Min            -406.178
trainer/Q Targets Mean                -388.923
trainer/Q Targets Std                   13.1483
trainer/Q Targets Max                 -312.634
trainer/Q Targets Min                 -407.777
trainer/Log Pis Mean                    -1.34676
trainer/Log Pis Std                      0.210846
trainer/Log Pis Max                     -0.802958
trainer/Log Pis Min                     -2.07978
trainer/policy/mean Mean                 0.0289583
trainer/policy/mean Std                  0.04504
trainer/policy/mean Max                  0.0793464
trainer/policy/mean Min                 -0.0164248
trainer/policy/normal/std Mean           0.907335
trainer/policy/normal/std Std            0.00331962
trainer/policy/normal/std Max            0.91463
trainer/policy/normal/std Min            0.896881
trainer/policy/normal/log_std Mean      -0.0972497
trainer/policy/normal/log_std Std        0.0036591
trainer/policy/normal/log_std Max       -0.0892352
trainer/policy/normal/log_std Min       -0.108832
trainer/Alpha                            0.371581
trainer/Alpha Loss                      -3.31326
exploration/num steps total          70000
exploration/num paths total            350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.54854
exploration/Rewards Std                  0.448814
exploration/Rewards Max                 -4.28831
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1109.71
exploration/Returns Std                 59.9363
exploration/Returns Max               -966.616
exploration/Returns Min              -1166.44
exploration/Actions Mean                 0.0273898
exploration/Actions Std                  0.60147
exploration/Actions Max                  0.996984
exploration/Actions Min                 -0.99856
exploration/Num Paths                   10
exploration/Average Returns          -1109.71
evaluation/num steps total          164016
evaluation/num paths total             816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.01487
evaluation/Rewards Std                   0.170184
evaluation/Rewards Max                  -5.12417
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1208.99
evaluation/Returns Std                  25.1117
evaluation/Returns Max               -1109.43
evaluation/Returns Min               -1229.76
evaluation/Actions Mean                  0.0289166
evaluation/Actions Std                   0.0450389
evaluation/Actions Max                   0.0749852
evaluation/Actions Min                  -0.0161805
evaluation/Num Paths                    24
evaluation/Average Returns           -1208.99
time/data storing (s)                    0.0228568
time/evaluation sampling (s)            13.1054
time/exploration sampling (s)            5.21035
time/logging (s)                         0.0193881
time/sac training (s)                   12.8597
time/saving (s)                          0.0231369
time/training (s)                        0.00011584
time/epoch (s)                          31.241
time/total (s)                        1120.03
Epoch                                   33
----------------------------------  ---------------
2020-11-09 13:41:03.421294 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 34 finished
----------------------------------  ----------------
replay_buffer/size                   72000
trainer/num train calls              35000
trainer/QF1 Loss                       605.218
trainer/QF2 Loss                       605.803
trainer/Policy Loss                    393.2
trainer/Q1 Predictions Mean           -393.629
trainer/Q1 Predictions Std              14.4086
trainer/Q1 Predictions Max            -297.79
trainer/Q1 Predictions Min            -417.423
trainer/Q2 Predictions Mean           -393.636
trainer/Q2 Predictions Std              14.4085
trainer/Q2 Predictions Max            -297.427
trainer/Q2 Predictions Min            -417.255
trainer/Q Targets Mean                -394.039
trainer/Q Targets Std                   28.4141
trainer/Q Targets Max                   -5.22749
trainer/Q Targets Min                 -418.862
trainer/Log Pis Mean                    -1.34911
trainer/Log Pis Std                      0.22919
trainer/Log Pis Max                     -0.861524
trainer/Log Pis Min                     -2.36417
trainer/policy/mean Mean                -0.0493584
trainer/policy/mean Std                  0.0778022
trainer/policy/mean Max                  0.0309322
trainer/policy/mean Min                 -0.135296
trainer/policy/normal/std Mean           0.882321
trainer/policy/normal/std Std            0.00234413
trainer/policy/normal/std Max            0.88756
trainer/policy/normal/std Min            0.871571
trainer/policy/normal/log_std Mean      -0.125203
trainer/policy/normal/log_std Std        0.00265785
trainer/policy/normal/log_std Max       -0.119279
trainer/policy/normal/log_std Min       -0.137458
trainer/Alpha                            0.36061
trainer/Alpha Loss                      -3.41596
exploration/num steps total          72000
exploration/num paths total            360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.58689
exploration/Rewards Std                  0.324028
exploration/Rewards Max                 -4.787
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1117.38
exploration/Returns Std                 32.0329
exploration/Returns Max              -1041.89
exploration/Returns Min              -1153.2
exploration/Actions Mean                -0.00503768
exploration/Actions Std                  0.590345
exploration/Actions Max                  0.993528
exploration/Actions Min                 -0.997814
exploration/Num Paths                   10
exploration/Average Returns          -1117.38
evaluation/num steps total          168840
evaluation/num paths total             840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.01955
evaluation/Rewards Std                   0.137715
evaluation/Rewards Max                  -5.36803
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1209.93
evaluation/Returns Std                  18.1648
evaluation/Returns Max               -1171.01
evaluation/Returns Min               -1230.03
evaluation/Actions Mean                 -0.0494021
evaluation/Actions Std                   0.0778118
evaluation/Actions Max                   0.0286462
evaluation/Actions Min                  -0.127721
evaluation/Num Paths                    24
evaluation/Average Returns           -1209.93
time/data storing (s)                    0.0214329
time/evaluation sampling (s)            12.9779
time/exploration sampling (s)            4.8362
time/logging (s)                         0.0177062
time/sac training (s)                   11.5261
time/saving (s)                          0.0179645
time/training (s)                        0.000121126
time/epoch (s)                          29.3974
time/total (s)                        1150.51
Epoch                                   34
----------------------------------  ----------------
2020-11-09 13:41:32.930311 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 35 finished
----------------------------------  ----------------
replay_buffer/size                   74000
trainer/num train calls              36000
trainer/QF1 Loss                      1843.13
trainer/QF2 Loss                      1842.88
trainer/Policy Loss                    399.806
trainer/Q1 Predictions Mean           -400.214
trainer/Q1 Predictions Std              14.3321
trainer/Q1 Predictions Max            -323.58
trainer/Q1 Predictions Min            -446.989
trainer/Q2 Predictions Mean           -400.226
trainer/Q2 Predictions Std              14.296
trainer/Q2 Predictions Max            -323.817
trainer/Q2 Predictions Min            -447.431
trainer/Q Targets Mean                -397.291
trainer/Q Targets Std                   45.0688
trainer/Q Targets Max                   -5.21441
trainer/Q Targets Min                 -446.661
trainer/Log Pis Mean                    -1.35992
trainer/Log Pis Std                      0.142892
trainer/Log Pis Max                     -0.977816
trainer/Log Pis Min                     -1.8657
trainer/policy/mean Mean                -0.0109345
trainer/policy/mean Std                  0.0339594
trainer/policy/mean Max                  0.0248539
trainer/policy/mean Min                 -0.0497283
trainer/policy/normal/std Mean           0.880021
trainer/policy/normal/std Std            0.0041469
trainer/policy/normal/std Max            0.888453
trainer/policy/normal/std Min            0.863004
trainer/policy/normal/log_std Mean      -0.12782
trainer/policy/normal/log_std Std        0.00471605
trainer/policy/normal/log_std Max       -0.118273
trainer/policy/normal/log_std Min       -0.147336
trainer/Alpha                            0.349931
trainer/Alpha Loss                      -3.52798
exploration/num steps total          74000
exploration/num paths total            370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5902
exploration/Rewards Std                  0.508749
exploration/Rewards Max                 -2.70819
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1118.04
exploration/Returns Std                 48.8596
exploration/Returns Max               -998.674
exploration/Returns Min              -1188.8
exploration/Actions Mean                -0.0263417
exploration/Actions Std                  0.588969
exploration/Actions Max                  0.997665
exploration/Actions Min                 -0.997653
exploration/Num Paths                   10
exploration/Average Returns          -1118.04
evaluation/num steps total          173664
evaluation/num paths total             864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.98776
evaluation/Rewards Std                   0.191415
evaluation/Rewards Max                  -5.16309
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1203.54
evaluation/Returns Std                  28.2477
evaluation/Returns Max               -1120.21
evaluation/Returns Min               -1230.03
evaluation/Actions Mean                 -0.0109422
evaluation/Actions Std                   0.0339382
evaluation/Actions Max                   0.0233842
evaluation/Actions Min                  -0.045402
evaluation/Num Paths                    24
evaluation/Average Returns           -1203.54
time/data storing (s)                    0.0221863
time/evaluation sampling (s)            11.0762
time/exploration sampling (s)            4.54982
time/logging (s)                         0.0188785
time/sac training (s)                   12.5745
time/saving (s)                          0.0222594
time/training (s)                        0.000130268
time/epoch (s)                          28.264
time/total (s)                        1180
Epoch                                   35
----------------------------------  ----------------
2020-11-09 13:42:00.703133 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 36 finished
----------------------------------  ----------------
replay_buffer/size                   76000
trainer/num train calls              37000
trainer/QF1 Loss                      1169.51
trainer/QF2 Loss                      1169.99
trainer/Policy Loss                    405.854
trainer/Q1 Predictions Mean           -406.295
trainer/Q1 Predictions Std              13.4484
trainer/Q1 Predictions Max            -310.011
trainer/Q1 Predictions Min            -427.046
trainer/Q2 Predictions Mean           -406.296
trainer/Q2 Predictions Std              13.4821
trainer/Q2 Predictions Max            -309.553
trainer/Q2 Predictions Min            -427.018
trainer/Q Targets Mean                -405.443
trainer/Q Targets Std                   38.0777
trainer/Q Targets Max                   -4.03588
trainer/Q Targets Min                 -430.078
trainer/Log Pis Mean                    -1.36801
trainer/Log Pis Std                      0.309461
trainer/Log Pis Max                     -0.795981
trainer/Log Pis Min                     -4.44761
trainer/policy/mean Mean                 0.0395897
trainer/policy/mean Std                  0.113871
trainer/policy/mean Max                  0.159525
trainer/policy/mean Min                 -0.0793178
trainer/policy/normal/std Mean           0.835006
trainer/policy/normal/std Std            0.00655698
trainer/policy/normal/std Max            0.846585
trainer/policy/normal/std Min            0.821014
trainer/policy/normal/log_std Mean      -0.180347
trainer/policy/normal/log_std Std        0.00785329
trainer/policy/normal/log_std Max       -0.166544
trainer/policy/normal/log_std Min       -0.197215
trainer/Alpha                            0.339581
trainer/Alpha Loss                      -3.63759
exploration/num steps total          76000
exploration/num paths total            380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.49058
exploration/Rewards Std                  0.58519
exploration/Rewards Max                 -2.7784
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1098.12
exploration/Returns Std                 83.6514
exploration/Returns Max               -894.473
exploration/Returns Min              -1182.77
exploration/Actions Mean                 0.038873
exploration/Actions Std                  0.571778
exploration/Actions Max                  0.99447
exploration/Actions Min                 -0.995934
exploration/Num Paths                   10
exploration/Average Returns          -1098.12
evaluation/num steps total          178488
evaluation/num paths total             888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0157
evaluation/Rewards Std                   0.153068
evaluation/Rewards Max                  -5.25598
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1209.16
evaluation/Returns Std                  20.6356
evaluation/Returns Max               -1143.52
evaluation/Returns Min               -1230.06
evaluation/Actions Mean                  0.0396053
evaluation/Actions Std                   0.113986
evaluation/Actions Max                   0.155328
evaluation/Actions Min                  -0.0754779
evaluation/Num Paths                    24
evaluation/Average Returns           -1209.16
time/data storing (s)                    0.0197966
time/evaluation sampling (s)            10.7055
time/exploration sampling (s)            4.60331
time/logging (s)                         0.0193918
time/sac training (s)                   11.2792
time/saving (s)                          0.0256773
time/training (s)                        0.000110467
time/epoch (s)                          26.653
time/total (s)                        1207.75
Epoch                                   36
----------------------------------  ----------------
2020-11-09 13:42:31.437707 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 37 finished
----------------------------------  ---------------
replay_buffer/size                   78000
trainer/num train calls              38000
trainer/QF1 Loss                       654.654
trainer/QF2 Loss                       653.835
trainer/Policy Loss                    412.466
trainer/Q1 Predictions Mean           -412.827
trainer/Q1 Predictions Std              14.0182
trainer/Q1 Predictions Max            -339.8
trainer/Q1 Predictions Min            -451.525
trainer/Q2 Predictions Mean           -412.848
trainer/Q2 Predictions Std              14.0545
trainer/Q2 Predictions Max            -339.627
trainer/Q2 Predictions Min            -454.128
trainer/Q Targets Mean                -413.17
trainer/Q Targets Std                   29.3473
trainer/Q Targets Max                   -5.21659
trainer/Q Targets Min                 -454.157
trainer/Log Pis Mean                    -1.34813
trainer/Log Pis Std                      0.172925
trainer/Log Pis Max                     -0.857155
trainer/Log Pis Min                     -1.91233
trainer/policy/mean Mean                 0.0424088
trainer/policy/mean Std                  0.0315191
trainer/policy/mean Max                  0.0777669
trainer/policy/mean Min                  0.00961578
trainer/policy/normal/std Mean           0.895782
trainer/policy/normal/std Std            0.00264559
trainer/policy/normal/std Max            0.901159
trainer/policy/normal/std Min            0.889774
trainer/policy/normal/log_std Mean      -0.110063
trainer/policy/normal/log_std Std        0.00295367
trainer/policy/normal/log_std Max       -0.104073
trainer/policy/normal/log_std Min       -0.116788
trainer/Alpha                            0.329612
trainer/Alpha Loss                      -3.71589
exploration/num steps total          78000
exploration/num paths total            390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.72545
exploration/Rewards Std                  0.316053
exploration/Rewards Max                 -4.38667
exploration/Rewards Min                 -6.14184
exploration/Returns Mean             -1145.09
exploration/Returns Std                 29.4948
exploration/Returns Max              -1098.26
exploration/Returns Min              -1186.17
exploration/Actions Mean                 0.0113642
exploration/Actions Std                  0.590059
exploration/Actions Max                  0.998112
exploration/Actions Min                 -0.997808
exploration/Num Paths                   10
exploration/Average Returns          -1145.09
evaluation/num steps total          183312
evaluation/num paths total             912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05574
evaluation/Rewards Std                   0.113267
evaluation/Rewards Max                  -5.53652
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1217.2
evaluation/Returns Std                  12.3125
evaluation/Returns Max               -1187.22
evaluation/Returns Min               -1230.63
evaluation/Actions Mean                  0.0423384
evaluation/Actions Std                   0.031495
evaluation/Actions Max                   0.0745452
evaluation/Actions Min                   0.0106015
evaluation/Num Paths                    24
evaluation/Average Returns           -1217.2
time/data storing (s)                    0.0220763
time/evaluation sampling (s)            13.6108
time/exploration sampling (s)            4.78606
time/logging (s)                         0.0183503
time/sac training (s)                   11.1825
time/saving (s)                          0.022335
time/training (s)                        9.5648e-05
time/epoch (s)                          29.6421
time/total (s)                        1238.46
Epoch                                   37
----------------------------------  ---------------
2020-11-09 13:43:00.195616 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 38 finished
----------------------------------  ----------------
replay_buffer/size                   80000
trainer/num train calls              39000
trainer/QF1 Loss                      1389.31
trainer/QF2 Loss                      1387.33
trainer/Policy Loss                    419.762
trainer/Q1 Predictions Mean           -420.125
trainer/Q1 Predictions Std              12.684
trainer/Q1 Predictions Max            -345.454
trainer/Q1 Predictions Min            -465.294
trainer/Q2 Predictions Mean           -420.129
trainer/Q2 Predictions Std              12.7048
trainer/Q2 Predictions Max            -345.405
trainer/Q2 Predictions Min            -467.288
trainer/Q Targets Mean                -418.707
trainer/Q Targets Std                   38.7488
trainer/Q Targets Max                   -5.07532
trainer/Q Targets Min                 -466.933
trainer/Log Pis Mean                    -1.35265
trainer/Log Pis Std                      0.229211
trainer/Log Pis Max                     -0.855213
trainer/Log Pis Min                     -2.5978
trainer/policy/mean Mean                 0.0718258
trainer/policy/mean Std                  0.0750443
trainer/policy/mean Max                  0.15056
trainer/policy/mean Min                 -0.00507138
trainer/policy/normal/std Mean           0.85621
trainer/policy/normal/std Std            0.00670915
trainer/policy/normal/std Max            0.867104
trainer/policy/normal/std Min            0.84646
trainer/policy/normal/log_std Mean      -0.15527
trainer/policy/normal/log_std Std        0.00783616
trainer/policy/normal/log_std Max       -0.142596
trainer/policy/normal/log_std Min       -0.166693
trainer/Alpha                            0.319831
trainer/Alpha Loss                      -3.8219
exploration/num steps total          80000
exploration/num paths total            400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.53004
exploration/Rewards Std                  0.544698
exploration/Rewards Max                 -3.80117
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1106.01
exploration/Returns Std                 56.9781
exploration/Returns Max               -989.158
exploration/Returns Min              -1185.64
exploration/Actions Mean                 0.0534678
exploration/Actions Std                  0.58423
exploration/Actions Max                  0.995093
exploration/Actions Min                 -0.993877
exploration/Num Paths                   10
exploration/Average Returns          -1106.01
evaluation/num steps total          188136
evaluation/num paths total             936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04237
evaluation/Rewards Std                   0.132157
evaluation/Rewards Max                  -5.38003
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1214.52
evaluation/Returns Std                  17.2299
evaluation/Returns Max               -1162.21
evaluation/Returns Min               -1229.89
evaluation/Actions Mean                  0.0717648
evaluation/Actions Std                   0.075048
evaluation/Actions Max                   0.148978
evaluation/Actions Min                  -0.00367271
evaluation/Num Paths                    24
evaluation/Average Returns           -1214.52
time/data storing (s)                    0.0254126
time/evaluation sampling (s)            11.5556
time/exploration sampling (s)            4.37215
time/logging (s)                         0.0160008
time/sac training (s)                   11.6084
time/saving (s)                          0.0218654
time/training (s)                        0.000111219
time/epoch (s)                          27.5996
time/total (s)                        1267.19
Epoch                                   38
----------------------------------  ----------------
2020-11-09 13:43:27.413306 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 39 finished
----------------------------------  ----------------
replay_buffer/size                   82000
trainer/num train calls              40000
trainer/QF1 Loss                      2068.09
trainer/QF2 Loss                      2066.98
trainer/Policy Loss                    426.442
trainer/Q1 Predictions Mean           -426.819
trainer/Q1 Predictions Std              13.6969
trainer/Q1 Predictions Max            -341.849
trainer/Q1 Predictions Min            -461.343
trainer/Q2 Predictions Mean           -426.813
trainer/Q2 Predictions Std              13.682
trainer/Q2 Predictions Max            -341.892
trainer/Q2 Predictions Min            -461.953
trainer/Q Targets Mean                -423.735
trainer/Q Targets Std                   47.638
trainer/Q Targets Max                   -4.46029
trainer/Q Targets Min                 -462.991
trainer/Log Pis Mean                    -1.35622
trainer/Log Pis Std                      0.239466
trainer/Log Pis Max                     -0.77728
trainer/Log Pis Min                     -2.80819
trainer/policy/mean Mean                 0.0366047
trainer/policy/mean Std                  0.0905286
trainer/policy/mean Max                  0.134949
trainer/policy/mean Min                 -0.0557962
trainer/policy/normal/std Mean           0.865604
trainer/policy/normal/std Std            0.00312951
trainer/policy/normal/std Max            0.872289
trainer/policy/normal/std Min            0.857929
trainer/policy/normal/log_std Mean      -0.144334
trainer/policy/normal/log_std Std        0.00361556
trainer/policy/normal/log_std Max       -0.136635
trainer/policy/normal/log_std Min       -0.153233
trainer/Alpha                            0.31037
trainer/Alpha Loss                      -3.92674
exploration/num steps total          82000
exploration/num paths total            410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.57618
exploration/Rewards Std                  0.504767
exploration/Rewards Max                 -3.77706
exploration/Rewards Min                 -6.1418
exploration/Returns Mean             -1115.24
exploration/Returns Std                 47.7534
exploration/Returns Max              -1016.3
exploration/Returns Min              -1167.77
exploration/Actions Mean                 0.0197875
exploration/Actions Std                  0.585385
exploration/Actions Max                  0.998419
exploration/Actions Min                 -0.99541
exploration/Num Paths                   10
exploration/Average Returns          -1115.24
evaluation/num steps total          192960
evaluation/num paths total             960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03509
evaluation/Rewards Std                   0.139218
evaluation/Rewards Max                  -5.3792
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1213.05
evaluation/Returns Std                  17.3083
evaluation/Returns Max               -1165.02
evaluation/Returns Min               -1230.39
evaluation/Actions Mean                  0.0366394
evaluation/Actions Std                   0.0906017
evaluation/Actions Max                   0.129418
evaluation/Actions Min                  -0.0543971
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.05
time/data storing (s)                    0.0198936
time/evaluation sampling (s)            10.7667
time/exploration sampling (s)            4.34495
time/logging (s)                         0.019168
time/sac training (s)                   10.9638
time/saving (s)                          0.0184482
time/training (s)                        0.000115265
time/epoch (s)                          26.1331
time/total (s)                        1294.39
Epoch                                   39
----------------------------------  ----------------
2020-11-09 13:43:58.779137 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 40 finished
----------------------------------  ----------------
replay_buffer/size                   84000
trainer/num train calls              41000
trainer/QF1 Loss                         6.79649
trainer/QF2 Loss                         6.81137
trainer/Policy Loss                    431.547
trainer/Q1 Predictions Mean           -431.889
trainer/Q1 Predictions Std              13.0137
trainer/Q1 Predictions Max            -351.08
trainer/Q1 Predictions Min            -457.841
trainer/Q2 Predictions Mean           -431.889
trainer/Q2 Predictions Std              13.0008
trainer/Q2 Predictions Max            -350.507
trainer/Q2 Predictions Min            -457.592
trainer/Q Targets Mean                -434.159
trainer/Q Targets Std                   13.0848
trainer/Q Targets Max                 -350.645
trainer/Q Targets Min                 -459.706
trainer/Log Pis Mean                    -1.35553
trainer/Log Pis Std                      0.158429
trainer/Log Pis Max                     -0.96894
trainer/Log Pis Min                     -1.98064
trainer/policy/mean Mean                 0.00197458
trainer/policy/mean Std                  0.0126956
trainer/policy/mean Max                  0.0174001
trainer/policy/mean Min                 -0.0123011
trainer/policy/normal/std Mean           0.893338
trainer/policy/normal/std Std            0.00166321
trainer/policy/normal/std Max            0.898665
trainer/policy/normal/std Min            0.888096
trainer/policy/normal/log_std Mean      -0.112792
trainer/policy/normal/log_std Std        0.001862
trainer/policy/normal/log_std Max       -0.106845
trainer/policy/normal/log_std Min       -0.118675
trainer/Alpha                            0.301201
trainer/Alpha Loss                      -4.02656
exploration/num steps total          84000
exploration/num paths total            420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.40367
exploration/Rewards Std                  0.647386
exploration/Rewards Max                 -2.71532
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1080.73
exploration/Returns Std                 53.9003
exploration/Returns Max              -1011.69
exploration/Returns Min              -1152.38
exploration/Actions Mean                 0.00359443
exploration/Actions Std                  0.59397
exploration/Actions Max                  0.992897
exploration/Actions Min                 -0.993955
exploration/Num Paths                   10
exploration/Average Returns          -1080.73
evaluation/num steps total          197784
evaluation/num paths total             984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04528
evaluation/Rewards Std                   0.122667
evaluation/Rewards Max                  -5.49208
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1215.1
evaluation/Returns Std                  17.3571
evaluation/Returns Max               -1168.58
evaluation/Returns Min               -1231.73
evaluation/Actions Mean                  0.00195617
evaluation/Actions Std                   0.0126385
evaluation/Actions Max                   0.0153422
evaluation/Actions Min                  -0.0110864
evaluation/Num Paths                    24
evaluation/Average Returns           -1215.1
time/data storing (s)                    0.021089
time/evaluation sampling (s)            10.58
time/exploration sampling (s)            4.31718
time/logging (s)                         0.0289985
time/sac training (s)                   15.0992
time/saving (s)                          0.0300847
time/training (s)                        0.000153436
time/epoch (s)                          30.0768
time/total (s)                        1325.74
Epoch                                   40
----------------------------------  ----------------
2020-11-09 13:44:45.796900 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 41 finished
----------------------------------  ----------------
replay_buffer/size                   86000
trainer/num train calls              42000
trainer/QF1 Loss                      1493.1
trainer/QF2 Loss                      1494.27
trainer/Policy Loss                    434.734
trainer/Q1 Predictions Mean           -435.052
trainer/Q1 Predictions Std              16.7232
trainer/Q1 Predictions Max            -327.688
trainer/Q1 Predictions Min            -487.443
trainer/Q2 Predictions Mean           -435.065
trainer/Q2 Predictions Std              16.7228
trainer/Q2 Predictions Max            -327.888
trainer/Q2 Predictions Min            -487.719
trainer/Q Targets Mean                -433.672
trainer/Q Targets Std                   41.6343
trainer/Q Targets Max                   -5.2262
trainer/Q Targets Min                 -488.707
trainer/Log Pis Mean                    -1.36284
trainer/Log Pis Std                      0.175578
trainer/Log Pis Max                     -1.00072
trainer/Log Pis Min                     -2.61012
trainer/policy/mean Mean                -0.0130417
trainer/policy/mean Std                  0.0339754
trainer/policy/mean Max                  0.0273755
trainer/policy/mean Min                 -0.0537324
trainer/policy/normal/std Mean           0.872649
trainer/policy/normal/std Std            0.00304405
trainer/policy/normal/std Max            0.878392
trainer/policy/normal/std Min            0.859472
trainer/policy/normal/log_std Mean      -0.136228
trainer/policy/normal/log_std Std        0.00348989
trainer/policy/normal/log_std Max       -0.129662
trainer/policy/normal/log_std Min       -0.151437
trainer/Alpha                            0.292283
trainer/Alpha Loss                      -4.1364
exploration/num steps total          86000
exploration/num paths total            430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.47595
exploration/Rewards Std                  0.630015
exploration/Rewards Max                 -2.5627
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1095.19
exploration/Returns Std                 89.8106
exploration/Returns Max               -855.447
exploration/Returns Min              -1179.01
exploration/Actions Mean                -0.00245379
exploration/Actions Std                  0.593735
exploration/Actions Max                  0.99825
exploration/Actions Min                 -0.993366
exploration/Num Paths                   10
exploration/Average Returns          -1095.19
evaluation/num steps total          202608
evaluation/num paths total            1008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05414
evaluation/Rewards Std                   0.131394
evaluation/Rewards Max                  -5.18104
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1216.88
evaluation/Returns Std                  16.9357
evaluation/Returns Max               -1160.02
evaluation/Returns Min               -1230.6
evaluation/Actions Mean                 -0.0131235
evaluation/Actions Std                   0.0337825
evaluation/Actions Max                   0.021309
evaluation/Actions Min                  -0.0476554
evaluation/Num Paths                    24
evaluation/Average Returns           -1216.88
time/data storing (s)                    0.0260604
time/evaluation sampling (s)            24.4481
time/exploration sampling (s)            7.30291
time/logging (s)                         0.0328608
time/sac training (s)                   13.9048
time/saving (s)                          0.0202979
time/training (s)                        0.000111195
time/epoch (s)                          45.7352
time/total (s)                        1372.74
Epoch                                   41
----------------------------------  ----------------
2020-11-09 13:45:16.470402 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 42 finished
----------------------------------  ----------------
replay_buffer/size                   88000
trainer/num train calls              43000
trainer/QF1 Loss                      1585.85
trainer/QF2 Loss                      1586.64
trainer/Policy Loss                    441.7
trainer/Q1 Predictions Mean           -442.031
trainer/Q1 Predictions Std              13.841
trainer/Q1 Predictions Max            -358.27
trainer/Q1 Predictions Min            -465.789
trainer/Q2 Predictions Mean           -442.019
trainer/Q2 Predictions Std              13.821
trainer/Q2 Predictions Max            -358.311
trainer/Q2 Predictions Min            -465.658
trainer/Q Targets Mean                -440.151
trainer/Q Targets Std                   41.0682
trainer/Q Targets Max                   -4.95268
trainer/Q Targets Min                 -467.457
trainer/Log Pis Mean                    -1.3816
trainer/Log Pis Std                      0.170537
trainer/Log Pis Max                     -0.936203
trainer/Log Pis Min                     -2.42248
trainer/policy/mean Mean                -0.00214682
trainer/policy/mean Std                  0.0432709
trainer/policy/mean Max                  0.0424558
trainer/policy/mean Min                 -0.0478531
trainer/policy/normal/std Mean           0.881766
trainer/policy/normal/std Std            0.00181717
trainer/policy/normal/std Max            0.885789
trainer/policy/normal/std Min            0.875706
trainer/policy/normal/log_std Mean      -0.12583
trainer/policy/normal/log_std Std        0.0020612
trainer/policy/normal/log_std Max       -0.121276
trainer/policy/normal/log_std Min       -0.132725
trainer/Alpha                            0.283638
trainer/Alpha Loss                      -4.261
exploration/num steps total          88000
exploration/num paths total            440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.59985
exploration/Rewards Std                  0.481187
exploration/Rewards Max                 -3.91617
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1119.97
exploration/Returns Std                 56.4578
exploration/Returns Max               -994.032
exploration/Returns Min              -1180.32
exploration/Actions Mean                -0.0255978
exploration/Actions Std                  0.590522
exploration/Actions Max                  0.994562
exploration/Actions Min                 -0.993976
exploration/Num Paths                   10
exploration/Average Returns          -1119.97
evaluation/num steps total          207432
evaluation/num paths total            1032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03763
evaluation/Rewards Std                   0.161394
evaluation/Rewards Max                  -4.93643
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1213.56
evaluation/Returns Std                  22.0411
evaluation/Returns Max               -1138.25
evaluation/Returns Min               -1231.09
evaluation/Actions Mean                 -0.00218579
evaluation/Actions Std                   0.0433577
evaluation/Actions Max                   0.0412025
evaluation/Actions Min                  -0.0456722
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.56
time/data storing (s)                    0.0204363
time/evaluation sampling (s)            12.2196
time/exploration sampling (s)            4.90337
time/logging (s)                         0.0212788
time/sac training (s)                   12.2893
time/saving (s)                          0.0221632
time/training (s)                        0.000117045
time/epoch (s)                          29.4763
time/total (s)                        1403.38
Epoch                                   42
----------------------------------  ----------------
2020-11-09 13:45:44.223119 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 43 finished
----------------------------------  ---------------
replay_buffer/size                   90000
trainer/num train calls              44000
trainer/QF1 Loss                      1475.24
trainer/QF2 Loss                      1477.72
trainer/Policy Loss                    446.966
trainer/Q1 Predictions Mean           -447.317
trainer/Q1 Predictions Std              14.8276
trainer/Q1 Predictions Max            -364.472
trainer/Q1 Predictions Min            -494.238
trainer/Q2 Predictions Mean           -447.315
trainer/Q2 Predictions Std              14.8915
trainer/Q2 Predictions Max            -363.962
trainer/Q2 Predictions Min            -495.007
trainer/Q Targets Mean                -446.005
trainer/Q Targets Std                   41.8911
trainer/Q Targets Max                   -4.77472
trainer/Q Targets Min                 -495.527
trainer/Log Pis Mean                    -1.28784
trainer/Log Pis Std                      0.406794
trainer/Log Pis Max                     -0.389652
trainer/Log Pis Min                     -2.69057
trainer/policy/mean Mean                 0.204135
trainer/policy/mean Std                  0.106161
trainer/policy/mean Max                  0.321617
trainer/policy/mean Min                  0.0929796
trainer/policy/normal/std Mean           0.857339
trainer/policy/normal/std Std            0.0212501
trainer/policy/normal/std Max            0.882104
trainer/policy/normal/std Min            0.832275
trainer/policy/normal/log_std Mean      -0.154229
trainer/policy/normal/log_std Std        0.0247915
trainer/policy/normal/log_std Max       -0.125446
trainer/policy/normal/log_std Min       -0.183592
trainer/Alpha                            0.275287
trainer/Alpha Loss                      -4.24111
exploration/num steps total          90000
exploration/num paths total            450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.4871
exploration/Rewards Std                  0.616551
exploration/Rewards Max                 -3.21399
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1097.42
exploration/Returns Std                 85.4697
exploration/Returns Max               -902.449
exploration/Returns Min              -1180.89
exploration/Actions Mean                 0.141926
exploration/Actions Std                  0.584992
exploration/Actions Max                  0.996764
exploration/Actions Min                 -0.998797
exploration/Num Paths                   10
exploration/Average Returns          -1097.42
evaluation/num steps total          212256
evaluation/num paths total            1056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.01325
evaluation/Rewards Std                   0.159341
evaluation/Rewards Max                  -4.9674
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1208.66
evaluation/Returns Std                  20.2764
evaluation/Returns Max               -1133.25
evaluation/Returns Min               -1227.77
evaluation/Actions Mean                  0.203919
evaluation/Actions Std                   0.105981
evaluation/Actions Max                   0.311348
evaluation/Actions Min                   0.0974586
evaluation/Num Paths                    24
evaluation/Average Returns           -1208.66
time/data storing (s)                    0.0222417
time/evaluation sampling (s)            10.8566
time/exploration sampling (s)            4.50638
time/logging (s)                         0.0160028
time/sac training (s)                   11.2299
time/saving (s)                          0.0220321
time/training (s)                        9.4354e-05
time/epoch (s)                          26.6533
time/total (s)                        1431.1
Epoch                                   43
----------------------------------  ---------------
2020-11-09 13:46:11.415156 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 44 finished
----------------------------------  ----------------
replay_buffer/size                   92000
trainer/num train calls              45000
trainer/QF1 Loss                      1601.5
trainer/QF2 Loss                      1602.39
trainer/Policy Loss                    451.393
trainer/Q1 Predictions Mean           -451.683
trainer/Q1 Predictions Std              14.8081
trainer/Q1 Predictions Max            -362.535
trainer/Q1 Predictions Min            -477.855
trainer/Q2 Predictions Mean           -451.676
trainer/Q2 Predictions Std              14.8232
trainer/Q2 Predictions Max            -363.007
trainer/Q2 Predictions Min            -477.786
trainer/Q Targets Mean                -450.089
trainer/Q Targets Std                   42.3628
trainer/Q Targets Max                   -4.53065
trainer/Q Targets Min                 -479.401
trainer/Log Pis Mean                    -1.19344
trainer/Log Pis Std                      0.509416
trainer/Log Pis Max                     -0.128517
trainer/Log Pis Min                     -2.41226
trainer/policy/mean Mean                 0.14956
trainer/policy/mean Std                  0.269013
trainer/policy/mean Max                  0.431897
trainer/policy/mean Min                 -0.123111
trainer/policy/normal/std Mean           0.852438
trainer/policy/normal/std Std            0.0172782
trainer/policy/normal/std Max            0.872079
trainer/policy/normal/std Min            0.83213
trainer/policy/normal/log_std Mean      -0.159861
trainer/policy/normal/log_std Std        0.0202722
trainer/policy/normal/log_std Max       -0.136875
trainer/policy/normal/log_std Min       -0.183767
trainer/Alpha                            0.267303
trainer/Alpha Loss                      -4.21335
exploration/num steps total          92000
exploration/num paths total            460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.45834
exploration/Rewards Std                  0.70576
exploration/Rewards Max                 -3.07576
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1091.67
exploration/Returns Std                102.002
exploration/Returns Max               -830.608
exploration/Returns Min              -1174.21
exploration/Actions Mean                 0.106037
exploration/Actions Std                  0.588055
exploration/Actions Max                  0.994525
exploration/Actions Min                 -0.998073
exploration/Num Paths                   10
exploration/Average Returns          -1091.67
evaluation/num steps total          217080
evaluation/num paths total            1080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.94908
evaluation/Rewards Std                   0.309351
evaluation/Rewards Max                  -3.73752
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1195.77
evaluation/Returns Std                  46.2456
evaluation/Returns Max                -985.096
evaluation/Returns Min               -1226.5
evaluation/Actions Mean                  0.149396
evaluation/Actions Std                   0.268733
evaluation/Actions Max                   0.421338
evaluation/Actions Min                  -0.120446
evaluation/Num Paths                    24
evaluation/Average Returns           -1195.77
time/data storing (s)                    0.0220025
time/evaluation sampling (s)            10.4782
time/exploration sampling (s)            4.44832
time/logging (s)                         0.0189978
time/sac training (s)                   11.1176
time/saving (s)                          0.0224825
time/training (s)                        0.000120093
time/epoch (s)                          26.1077
time/total (s)                        1458.28
Epoch                                   44
----------------------------------  ----------------
2020-11-09 13:46:38.456488 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 45 finished
----------------------------------  ---------------
replay_buffer/size                   94000
trainer/num train calls              46000
trainer/QF1 Loss                      2444.76
trainer/QF2 Loss                      2443.88
trainer/Policy Loss                    454.51
trainer/Q1 Predictions Mean           -454.835
trainer/Q1 Predictions Std              16.4558
trainer/Q1 Predictions Max            -347.919
trainer/Q1 Predictions Min            -476.317
trainer/Q2 Predictions Mean           -454.824
trainer/Q2 Predictions Std              16.4723
trainer/Q2 Predictions Max            -347.822
trainer/Q2 Predictions Min            -476.599
trainer/Q Targets Mean                -451.96
trainer/Q Targets Std                   51.3877
trainer/Q Targets Max                   -5.12257
trainer/Q Targets Min                 -477.254
trainer/Log Pis Mean                    -1.33732
trainer/Log Pis Std                      0.191605
trainer/Log Pis Max                     -0.823922
trainer/Log Pis Min                     -1.79731
trainer/policy/mean Mean                 0.035162
trainer/policy/mean Std                  0.0726828
trainer/policy/mean Max                  0.124671
trainer/policy/mean Min                 -0.0442109
trainer/policy/normal/std Mean           0.872659
trainer/policy/normal/std Std            0.00372422
trainer/policy/normal/std Max            0.879038
trainer/policy/normal/std Min            0.864729
trainer/policy/normal/log_std Mean      -0.13622
trainer/policy/normal/log_std Std        0.00426796
trainer/policy/normal/log_std Max       -0.128927
trainer/policy/normal/log_std Min       -0.145339
trainer/Alpha                            0.259311
trainer/Alpha Loss                      -4.50447
exploration/num steps total          94000
exploration/num paths total            470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.39537
exploration/Rewards Std                  0.83558
exploration/Rewards Max                 -2.5264
exploration/Rewards Min                 -6.14196
exploration/Returns Mean             -1079.07
exploration/Returns Std                121.278
exploration/Returns Max               -751.507
exploration/Returns Min              -1177.96
exploration/Actions Mean                 0.0201624
exploration/Actions Std                  0.593893
exploration/Actions Max                  0.995422
exploration/Actions Min                 -0.994174
exploration/Num Paths                   10
exploration/Average Returns          -1079.07
evaluation/num steps total          221904
evaluation/num paths total            1104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.01721
evaluation/Rewards Std                   0.142042
evaluation/Rewards Max                  -5.36492
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1209.46
evaluation/Returns Std                  19.3101
evaluation/Returns Max               -1150.24
evaluation/Returns Min               -1229.42
evaluation/Actions Mean                  0.0351607
evaluation/Actions Std                   0.0726101
evaluation/Actions Max                   0.109301
evaluation/Actions Min                  -0.0382876
evaluation/Num Paths                    24
evaluation/Average Returns           -1209.46
time/data storing (s)                    0.0195765
time/evaluation sampling (s)            10.6339
time/exploration sampling (s)            4.37375
time/logging (s)                         0.0197837
time/sac training (s)                   10.9061
time/saving (s)                          0.0218122
time/training (s)                        0.0001221
time/epoch (s)                          25.9751
time/total (s)                        1485.3
Epoch                                   45
----------------------------------  ---------------
2020-11-09 13:47:06.010585 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 46 finished
----------------------------------  ----------------
replay_buffer/size                   96000
trainer/num train calls              47000
trainer/QF1 Loss                         5.8427
trainer/QF2 Loss                         5.85362
trainer/Policy Loss                    459.356
trainer/Q1 Predictions Mean           -459.607
trainer/Q1 Predictions Std              17.4058
trainer/Q1 Predictions Max            -386.643
trainer/Q1 Predictions Min            -495.725
trainer/Q2 Predictions Mean           -459.606
trainer/Q2 Predictions Std              17.4142
trainer/Q2 Predictions Max            -386.513
trainer/Q2 Predictions Min            -495.839
trainer/Q Targets Mean                -461.477
trainer/Q Targets Std                   17.8126
trainer/Q Targets Max                 -386.955
trainer/Q Targets Min                 -498.054
trainer/Log Pis Mean                    -1.33478
trainer/Log Pis Std                      0.323308
trainer/Log Pis Max                     -0.499635
trainer/Log Pis Min                     -2.59891
trainer/policy/mean Mean                 0.0824103
trainer/policy/mean Std                  0.143865
trainer/policy/mean Max                  0.253355
trainer/policy/mean Min                 -0.0707056
trainer/policy/normal/std Mean           0.888328
trainer/policy/normal/std Std            0.00134646
trainer/policy/normal/std Max            0.89179
trainer/policy/normal/std Min            0.881569
trainer/policy/normal/log_std Mean      -0.118416
trainer/policy/normal/log_std Std        0.00151724
trainer/policy/normal/log_std Max       -0.114524
trainer/policy/normal/log_std Min       -0.126052
trainer/Alpha                            0.251844
trainer/Alpha Loss                      -4.59848
exploration/num steps total          96000
exploration/num paths total            480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.51806
exploration/Rewards Std                  0.399021
exploration/Rewards Max                 -4.15111
exploration/Rewards Min                 -6.14196
exploration/Returns Mean             -1103.61
exploration/Returns Std                 38.005
exploration/Returns Max              -1038.11
exploration/Returns Min              -1171.51
exploration/Actions Mean                 0.0652941
exploration/Actions Std                  0.5904
exploration/Actions Max                  0.995962
exploration/Actions Min                 -0.99548
exploration/Num Paths                   10
exploration/Average Returns          -1103.61
evaluation/num steps total          226728
evaluation/num paths total            1128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03079
evaluation/Rewards Std                   0.131972
evaluation/Rewards Max                  -5.11919
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1212.19
evaluation/Returns Std                  17.3821
evaluation/Returns Max               -1164.31
evaluation/Returns Min               -1229.19
evaluation/Actions Mean                  0.0823394
evaluation/Actions Std                   0.143645
evaluation/Actions Max                   0.235147
evaluation/Actions Min                  -0.0651397
evaluation/Num Paths                    24
evaluation/Average Returns           -1212.19
time/data storing (s)                    0.0235531
time/evaluation sampling (s)            10.8412
time/exploration sampling (s)            4.4064
time/logging (s)                         0.0191432
time/sac training (s)                   11.1432
time/saving (s)                          0.0183252
time/training (s)                        0.000109887
time/epoch (s)                          26.4519
time/total (s)                        1512.83
Epoch                                   46
----------------------------------  ----------------
2020-11-09 13:47:33.205353 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 47 finished
----------------------------------  ----------------
replay_buffer/size                   98000
trainer/num train calls              48000
trainer/QF1 Loss                       820.817
trainer/QF2 Loss                       820.743
trainer/Policy Loss                    464.801
trainer/Q1 Predictions Mean           -465.056
trainer/Q1 Predictions Std              12.9354
trainer/Q1 Predictions Max            -395.219
trainer/Q1 Predictions Min            -487.706
trainer/Q2 Predictions Mean           -465.062
trainer/Q2 Predictions Std              12.9448
trainer/Q2 Predictions Max            -394.285
trainer/Q2 Predictions Min            -487.647
trainer/Q Targets Mean                -465.692
trainer/Q Targets Std                   31.7497
trainer/Q Targets Max                   -5.36225
trainer/Q Targets Min                 -487.266
trainer/Log Pis Mean                    -1.36114
trainer/Log Pis Std                      0.141295
trainer/Log Pis Max                     -0.942028
trainer/Log Pis Min                     -1.74566
trainer/policy/mean Mean                 0.0408274
trainer/policy/mean Std                  0.0103367
trainer/policy/mean Max                  0.0531421
trainer/policy/mean Min                  0.0239215
trainer/policy/normal/std Mean           0.880793
trainer/policy/normal/std Std            0.00187091
trainer/policy/normal/std Max            0.884849
trainer/policy/normal/std Min            0.870275
trainer/policy/normal/log_std Mean      -0.126934
trainer/policy/normal/log_std Std        0.00212818
trainer/policy/normal/log_std Max       -0.122339
trainer/policy/normal/log_std Min       -0.138945
trainer/Alpha                            0.244261
trainer/Alpha Loss                      -4.73759
exploration/num steps total          98000
exploration/num paths total            490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.68141
exploration/Rewards Std                  0.361368
exploration/Rewards Max                 -4.33072
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1136.28
exploration/Returns Std                 46.2843
exploration/Returns Max              -1035.36
exploration/Returns Min              -1185.46
exploration/Actions Mean                 0.0167169
exploration/Actions Std                  0.590061
exploration/Actions Max                  0.998419
exploration/Actions Min                 -0.994444
exploration/Num Paths                   10
exploration/Average Returns          -1136.28
evaluation/num steps total          231552
evaluation/num paths total            1152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05373
evaluation/Rewards Std                   0.119378
evaluation/Rewards Max                  -5.28511
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1216.8
evaluation/Returns Std                  14.1469
evaluation/Returns Max               -1183.91
evaluation/Returns Min               -1231.21
evaluation/Actions Mean                  0.0410031
evaluation/Actions Std                   0.00980253
evaluation/Actions Max                   0.0511406
evaluation/Actions Min                   0.0288782
evaluation/Num Paths                    24
evaluation/Average Returns           -1216.8
time/data storing (s)                    0.0196667
time/evaluation sampling (s)            10.5744
time/exploration sampling (s)            4.36993
time/logging (s)                         0.0179414
time/sac training (s)                   11.0861
time/saving (s)                          0.0225097
time/training (s)                        0.000111856
time/epoch (s)                          26.0906
time/total (s)                        1540
Epoch                                   47
----------------------------------  ----------------
2020-11-09 13:48:00.578545 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 48 finished
----------------------------------  ----------------
replay_buffer/size                  100000
trainer/num train calls              49000
trainer/QF1 Loss                      1700.02
trainer/QF2 Loss                      1700.21
trainer/Policy Loss                    469.672
trainer/Q1 Predictions Mean           -469.944
trainer/Q1 Predictions Std              14.7404
trainer/Q1 Predictions Max            -396.732
trainer/Q1 Predictions Min            -501.566
trainer/Q2 Predictions Mean           -469.93
trainer/Q2 Predictions Std              14.7476
trainer/Q2 Predictions Max            -396.045
trainer/Q2 Predictions Min            -501.326
trainer/Q Targets Mean                -468.163
trainer/Q Targets Std                   43.7579
trainer/Q Targets Max                   -5.11096
trainer/Q Targets Min                 -502.103
trainer/Log Pis Mean                    -1.28519
trainer/Log Pis Std                      0.377577
trainer/Log Pis Max                     -0.365928
trainer/Log Pis Min                     -2.3088
trainer/policy/mean Mean                 0.209491
trainer/policy/mean Std                  0.093954
trainer/policy/mean Max                  0.345577
trainer/policy/mean Min                  0.111667
trainer/policy/normal/std Mean           0.859487
trainer/policy/normal/std Std            0.0133722
trainer/policy/normal/std Max            0.875338
trainer/policy/normal/std Min            0.835775
trainer/policy/normal/log_std Mean      -0.15154
trainer/policy/normal/log_std Std        0.0155618
trainer/policy/normal/log_std Max       -0.133145
trainer/policy/normal/log_std Min       -0.179396
trainer/Alpha                            0.237014
trainer/Alpha Loss                      -4.72948
exploration/num steps total         100000
exploration/num paths total            500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.72113
exploration/Rewards Std                  0.354144
exploration/Rewards Max                 -4.2895
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1144.23
exploration/Returns Std                 41.2994
exploration/Returns Max              -1031.7
exploration/Returns Min              -1178.53
exploration/Actions Mean                 0.149668
exploration/Actions Std                  0.576039
exploration/Actions Max                  0.99941
exploration/Actions Min                 -0.993208
exploration/Num Paths                   10
exploration/Average Returns          -1144.23
evaluation/num steps total          236376
evaluation/num paths total            1176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9829
evaluation/Rewards Std                   0.178527
evaluation/Rewards Max                  -4.91824
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1202.56
evaluation/Returns Std                  26.5437
evaluation/Returns Max               -1099.16
evaluation/Returns Min               -1227.09
evaluation/Actions Mean                  0.208943
evaluation/Actions Std                   0.0933358
evaluation/Actions Max                   0.324223
evaluation/Actions Min                   0.114985
evaluation/Num Paths                    24
evaluation/Average Returns           -1202.56
time/data storing (s)                    0.0208405
time/evaluation sampling (s)            10.6489
time/exploration sampling (s)            4.37741
time/logging (s)                         0.018937
time/sac training (s)                   11.1913
time/saving (s)                          0.0201781
time/training (s)                        0.000113287
time/epoch (s)                          26.2777
time/total (s)                        1567.35
Epoch                                   48
----------------------------------  ----------------
2020-11-09 13:48:29.885045 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 49 finished
----------------------------------  ----------------
replay_buffer/size                  102000
trainer/num train calls              50000
trainer/QF1 Loss                      1839.5
trainer/QF2 Loss                      1835.51
trainer/Policy Loss                    472.782
trainer/Q1 Predictions Mean           -473.013
trainer/Q1 Predictions Std              15.9522
trainer/Q1 Predictions Max            -357.983
trainer/Q1 Predictions Min            -495.666
trainer/Q2 Predictions Mean           -472.986
trainer/Q2 Predictions Std              15.9439
trainer/Q2 Predictions Max            -357.758
trainer/Q2 Predictions Min            -495.781
trainer/Q Targets Mean                -471.834
trainer/Q Targets Std                   44.4175
trainer/Q Targets Max                   -5.01999
trainer/Q Targets Min                 -497.674
trainer/Log Pis Mean                    -1.30849
trainer/Log Pis Std                      0.285544
trainer/Log Pis Max                     -0.55978
trainer/Log Pis Min                     -2.03053
trainer/policy/mean Mean                 0.128133
trainer/policy/mean Std                  0.0617555
trainer/policy/mean Max                  0.228768
trainer/policy/mean Min                  0.0577151
trainer/policy/normal/std Mean           0.888281
trainer/policy/normal/std Std            0.00814427
trainer/policy/normal/std Max            0.899458
trainer/policy/normal/std Min            0.873847
trainer/policy/normal/log_std Mean      -0.118509
trainer/policy/normal/log_std Std        0.0091708
trainer/policy/normal/log_std Max       -0.105963
trainer/policy/normal/log_std Min       -0.13485
trainer/Alpha                            0.230073
trainer/Alpha Loss                      -4.86136
exploration/num steps total         102000
exploration/num paths total            510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.54701
exploration/Rewards Std                  0.5718
exploration/Rewards Max                 -3.55887
exploration/Rewards Min                 -6.14196
exploration/Returns Mean             -1109.4
exploration/Returns Std                 86.988
exploration/Returns Max               -891.622
exploration/Returns Min              -1177.53
exploration/Actions Mean                 0.0859422
exploration/Actions Std                  0.592219
exploration/Actions Max                  0.998897
exploration/Actions Min                 -0.994735
exploration/Num Paths                   10
exploration/Average Returns          -1109.4
evaluation/num steps total          241200
evaluation/num paths total            1200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.02593
evaluation/Rewards Std                   0.156299
evaluation/Rewards Max                  -5.00702
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1211.21
evaluation/Returns Std                  19.0935
evaluation/Returns Max               -1169.92
evaluation/Returns Min               -1230.26
evaluation/Actions Mean                  0.128589
evaluation/Actions Std                   0.0619663
evaluation/Actions Max                   0.213172
evaluation/Actions Min                   0.0636487
evaluation/Num Paths                    24
evaluation/Average Returns           -1211.21
time/data storing (s)                    0.0225664
time/evaluation sampling (s)            11.4094
time/exploration sampling (s)            5.12019
time/logging (s)                         0.0195104
time/sac training (s)                   11.5566
time/saving (s)                          0.0282471
time/training (s)                        0.000116395
time/epoch (s)                          28.1566
time/total (s)                        1596.63
Epoch                                   49
----------------------------------  ----------------
2020-11-09 13:49:00.002724 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 50 finished
----------------------------------  ---------------
replay_buffer/size                  104000
trainer/num train calls              51000
trainer/QF1 Loss                       943.294
trainer/QF2 Loss                       943.018
trainer/Policy Loss                    477.507
trainer/Q1 Predictions Mean           -477.817
trainer/Q1 Predictions Std              17.3845
trainer/Q1 Predictions Max            -356.123
trainer/Q1 Predictions Min            -522.163
trainer/Q2 Predictions Mean           -477.821
trainer/Q2 Predictions Std              17.3861
trainer/Q2 Predictions Max            -356.188
trainer/Q2 Predictions Min            -524.113
trainer/Q Targets Mean                -477.936
trainer/Q Targets Std                   34.4124
trainer/Q Targets Max                   -5.66005
trainer/Q Targets Min                 -523.271
trainer/Log Pis Mean                    -1.27097
trainer/Log Pis Std                      0.479974
trainer/Log Pis Max                     -0.307475
trainer/Log Pis Min                     -2.91527
trainer/policy/mean Mean                 0.260669
trainer/policy/mean Std                  0.0701826
trainer/policy/mean Max                  0.382111
trainer/policy/mean Min                  0.181674
trainer/policy/normal/std Mean           0.825892
trainer/policy/normal/std Std            0.0110831
trainer/policy/normal/std Max            0.844428
trainer/policy/normal/std Min            0.804425
trainer/policy/normal/log_std Mean      -0.191381
trainer/policy/normal/log_std Std        0.0134239
trainer/policy/normal/log_std Max       -0.169095
trainer/policy/normal/log_std Min       -0.217627
trainer/Alpha                            0.223213
trainer/Alpha Loss                      -4.90525
exploration/num steps total         104000
exploration/num paths total            520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.47736
exploration/Rewards Std                  0.599259
exploration/Rewards Max                 -3.14593
exploration/Rewards Min                 -6.14189
exploration/Returns Mean             -1095.47
exploration/Returns Std                 88.9684
exploration/Returns Max               -849.061
exploration/Returns Min              -1167.05
exploration/Actions Mean                 0.175274
exploration/Actions Std                  0.554333
exploration/Actions Max                  0.997507
exploration/Actions Min                 -0.994043
exploration/Num Paths                   10
exploration/Average Returns          -1095.47
evaluation/num steps total          246024
evaluation/num paths total            1224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0087
evaluation/Rewards Std                   0.156591
evaluation/Rewards Max                  -5.09212
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1207.75
evaluation/Returns Std                  20.8909
evaluation/Returns Max               -1143.58
evaluation/Returns Min               -1227.38
evaluation/Actions Mean                  0.261577
evaluation/Actions Std                   0.0702772
evaluation/Actions Max                   0.359828
evaluation/Actions Min                   0.187243
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.75
time/data storing (s)                    0.0232752
time/evaluation sampling (s)            12.5017
time/exploration sampling (s)            5.54359
time/logging (s)                         0.0197069
time/sac training (s)                   10.9588
time/saving (s)                          0.0216149
time/training (s)                        0.00010844
time/epoch (s)                          29.0688
time/total (s)                        1626.73
Epoch                                   50
----------------------------------  ---------------
2020-11-09 13:49:29.332382 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 51 finished
----------------------------------  ----------------
replay_buffer/size                  106000
trainer/num train calls              52000
trainer/QF1 Loss                         5.70474
trainer/QF2 Loss                         5.70566
trainer/Policy Loss                    481.648
trainer/Q1 Predictions Mean           -481.845
trainer/Q1 Predictions Std              15.6172
trainer/Q1 Predictions Max            -388.82
trainer/Q1 Predictions Min            -507.982
trainer/Q2 Predictions Mean           -481.852
trainer/Q2 Predictions Std              15.636
trainer/Q2 Predictions Max            -388.913
trainer/Q2 Predictions Min            -507.948
trainer/Q Targets Mean                -483.525
trainer/Q Targets Std                   15.8075
trainer/Q Targets Max                 -389.633
trainer/Q Targets Min                 -509.704
trainer/Log Pis Mean                    -1.25731
trainer/Log Pis Std                      0.501547
trainer/Log Pis Max                     -0.310188
trainer/Log Pis Min                     -2.7746
trainer/policy/mean Mean                 0.187748
trainer/policy/mean Std                  0.187385
trainer/policy/mean Max                  0.445218
trainer/policy/mean Min                 -0.0154846
trainer/policy/normal/std Mean           0.865145
trainer/policy/normal/std Std            0.0163491
trainer/policy/normal/std Max            0.886196
trainer/policy/normal/std Min            0.836455
trainer/policy/normal/log_std Mean      -0.145037
trainer/policy/normal/log_std Std        0.018905
trainer/policy/normal/log_std Max       -0.120817
trainer/policy/normal/log_std Min       -0.178583
trainer/Alpha                            0.216741
trainer/Alpha Loss                      -4.9806
exploration/num steps total         106000
exploration/num paths total            530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.44584
exploration/Rewards Std                  0.699636
exploration/Rewards Max                 -3.08474
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1089.17
exploration/Returns Std                 79.8857
exploration/Returns Max               -908.987
exploration/Returns Min              -1159.38
exploration/Actions Mean                 0.135095
exploration/Actions Std                  0.586383
exploration/Actions Max                  0.997228
exploration/Actions Min                 -0.991305
exploration/Num Paths                   10
exploration/Average Returns          -1089.17
evaluation/num steps total          250848
evaluation/num paths total            1248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97082
evaluation/Rewards Std                   0.167821
evaluation/Rewards Max                  -5.31067
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1200.14
evaluation/Returns Std                  22.6703
evaluation/Returns Max               -1150.79
evaluation/Returns Min               -1227.01
evaluation/Actions Mean                  0.187934
evaluation/Actions Std                   0.187502
evaluation/Actions Max                   0.4089
evaluation/Actions Min                  -0.00783113
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.14
time/data storing (s)                    0.0242629
time/evaluation sampling (s)            12.3552
time/exploration sampling (s)            5.11761
time/logging (s)                         0.0148177
time/sac training (s)                   10.7609
time/saving (s)                          0.0216551
time/training (s)                        0.000109481
time/epoch (s)                          28.2946
time/total (s)                        1656.04
Epoch                                   51
----------------------------------  ----------------
2020-11-09 13:49:58.612766 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 52 finished
----------------------------------  ----------------
replay_buffer/size                  108000
trainer/num train calls              53000
trainer/QF1 Loss                       872.242
trainer/QF2 Loss                       873.192
trainer/Policy Loss                    485.615
trainer/Q1 Predictions Mean           -485.844
trainer/Q1 Predictions Std              16.4665
trainer/Q1 Predictions Max            -373.292
trainer/Q1 Predictions Min            -530.591
trainer/Q2 Predictions Mean           -485.839
trainer/Q2 Predictions Std              16.4831
trainer/Q2 Predictions Max            -373.468
trainer/Q2 Predictions Min            -532.603
trainer/Q Targets Mean                -486.328
trainer/Q Targets Std                   34.3217
trainer/Q Targets Max                   -5.10409
trainer/Q Targets Min                 -529.342
trainer/Log Pis Mean                    -1.36812
trainer/Log Pis Std                      0.25872
trainer/Log Pis Max                     -0.657554
trainer/Log Pis Min                     -2.11457
trainer/policy/mean Mean                 0.0185672
trainer/policy/mean Std                  0.121109
trainer/policy/mean Max                  0.196265
trainer/policy/mean Min                 -0.1507
trainer/policy/normal/std Mean           0.873757
trainer/policy/normal/std Std            0.00410338
trainer/policy/normal/std Max            0.881594
trainer/policy/normal/std Min            0.857334
trainer/policy/normal/log_std Mean      -0.134964
trainer/policy/normal/log_std Std        0.00470885
trainer/policy/normal/log_std Max       -0.126024
trainer/policy/normal/log_std Min       -0.153928
trainer/Alpha                            0.210238
trainer/Alpha Loss                      -5.25262
exploration/num steps total         108000
exploration/num paths total            540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5378
exploration/Rewards Std                  0.64231
exploration/Rewards Max                 -3.11099
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1107.56
exploration/Returns Std                 61.7982
exploration/Returns Max               -965.653
exploration/Returns Min              -1179.65
exploration/Actions Mean                 0.0121036
exploration/Actions Std                  0.593067
exploration/Actions Max                  0.996765
exploration/Actions Min                 -0.997228
exploration/Num Paths                   10
exploration/Average Returns          -1107.56
evaluation/num steps total          255672
evaluation/num paths total            1272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9906
evaluation/Rewards Std                   0.213318
evaluation/Rewards Max                  -4.92595
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1204.11
evaluation/Returns Std                  29.538
evaluation/Returns Max               -1123.91
evaluation/Returns Min               -1230.26
evaluation/Actions Mean                  0.0185302
evaluation/Actions Std                   0.120331
evaluation/Actions Max                   0.166596
evaluation/Actions Min                  -0.126067
evaluation/Num Paths                    24
evaluation/Average Returns           -1204.11
time/data storing (s)                    0.0229217
time/evaluation sampling (s)            12.2245
time/exploration sampling (s)            5.09292
time/logging (s)                         0.0167241
time/sac training (s)                   10.8658
time/saving (s)                          0.0224635
time/training (s)                        0.000115521
time/epoch (s)                          28.2454
time/total (s)                        1685.3
Epoch                                   52
----------------------------------  ----------------
2020-11-09 13:50:30.096437 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 53 finished
----------------------------------  ---------------
replay_buffer/size                  110000
trainer/num train calls              54000
trainer/QF1 Loss                      1004.86
trainer/QF2 Loss                      1004.62
trainer/Policy Loss                    485.642
trainer/Q1 Predictions Mean           -485.838
trainer/Q1 Predictions Std              21.6029
trainer/Q1 Predictions Max            -379.693
trainer/Q1 Predictions Min            -519.643
trainer/Q2 Predictions Mean           -485.825
trainer/Q2 Predictions Std              21.6006
trainer/Q2 Predictions Max            -379.145
trainer/Q2 Predictions Min            -519.211
trainer/Q Targets Mean                -485.584
trainer/Q Targets Std                   37.0604
trainer/Q Targets Max                   -5.44564
trainer/Q Targets Min                 -520.44
trainer/Log Pis Mean                    -1.00197
trainer/Log Pis Std                      0.818512
trainer/Log Pis Max                      0.71482
trainer/Log Pis Min                     -4.06504
trainer/policy/mean Mean                 0.0835767
trainer/policy/mean Std                  0.442153
trainer/policy/mean Max                  0.599264
trainer/policy/mean Min                 -0.420571
trainer/policy/normal/std Mean           0.837877
trainer/policy/normal/std Std            0.031645
trainer/policy/normal/std Max            0.874744
trainer/policy/normal/std Min            0.784479
trainer/policy/normal/log_std Mean      -0.177598
trainer/policy/normal/log_std Std        0.037818
trainer/policy/normal/log_std Max       -0.133824
trainer/policy/normal/log_std Min       -0.242736
trainer/Alpha                            0.204534
trainer/Alpha Loss                      -4.76418
exploration/num steps total         110000
exploration/num paths total            550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.46346
exploration/Rewards Std                  0.600802
exploration/Rewards Max                 -3.18083
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1092.69
exploration/Returns Std                 70.9298
exploration/Returns Max               -927.01
exploration/Returns Min              -1161.12
exploration/Actions Mean                 0.0717425
exploration/Actions Std                  0.617174
exploration/Actions Max                  0.998653
exploration/Actions Min                 -0.992965
exploration/Num Paths                   10
exploration/Average Returns          -1092.69
evaluation/num steps total          260496
evaluation/num paths total            1296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8842
evaluation/Rewards Std                   0.284865
evaluation/Rewards Max                  -3.63439
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1182.72
evaluation/Returns Std                  36.85
evaluation/Returns Max               -1058.27
evaluation/Returns Min               -1226.41
evaluation/Actions Mean                  0.0835073
evaluation/Actions Std                   0.441101
evaluation/Actions Max                   0.587252
evaluation/Actions Min                  -0.409978
evaluation/Num Paths                    24
evaluation/Average Returns           -1182.72
time/data storing (s)                    0.0250547
time/evaluation sampling (s)            12.3577
time/exploration sampling (s)            6.66447
time/logging (s)                         0.0173582
time/sac training (s)                   11.3262
time/saving (s)                          0.0217821
time/training (s)                        0.00010772
time/epoch (s)                          30.4126
time/total (s)                        1716.76
Epoch                                   53
----------------------------------  ---------------
2020-11-09 13:51:00.371232 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 54 finished
----------------------------------  ---------------
replay_buffer/size                  112000
trainer/num train calls              55000
trainer/QF1 Loss                         9.16089
trainer/QF2 Loss                         9.20785
trainer/Policy Loss                    491.345
trainer/Q1 Predictions Mean           -491.657
trainer/Q1 Predictions Std              16.8488
trainer/Q1 Predictions Max            -367.31
trainer/Q1 Predictions Min            -525.235
trainer/Q2 Predictions Mean           -491.658
trainer/Q2 Predictions Std              16.841
trainer/Q2 Predictions Max            -367.537
trainer/Q2 Predictions Min            -526.197
trainer/Q Targets Mean                -494.207
trainer/Q Targets Std                   17.4908
trainer/Q Targets Max                 -362.444
trainer/Q Targets Min                 -527.791
trainer/Log Pis Mean                    -1.11846
trainer/Log Pis Std                      0.676849
trainer/Log Pis Max                      0.117326
trainer/Log Pis Min                     -3.63029
trainer/policy/mean Mean                 0.178315
trainer/policy/mean Std                  0.346584
trainer/policy/mean Max                  0.597296
trainer/policy/mean Min                 -0.206395
trainer/policy/normal/std Mean           0.83664
trainer/policy/normal/std Std            0.0479535
trainer/policy/normal/std Max            0.889243
trainer/policy/normal/std Min            0.769842
trainer/policy/normal/log_std Mean      -0.180008
trainer/policy/normal/log_std Std        0.0574164
trainer/policy/normal/log_std Max       -0.117385
trainer/policy/normal/log_std Min       -0.26157
trainer/Alpha                            0.198529
trainer/Alpha Loss                      -5.04198
exploration/num steps total         112000
exploration/num paths total            560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.54506
exploration/Rewards Std                  0.550158
exploration/Rewards Max                 -3.37059
exploration/Rewards Min                 -6.14162
exploration/Returns Mean             -1109.01
exploration/Returns Std                 63.7348
exploration/Returns Max               -938.979
exploration/Returns Min              -1176.92
exploration/Actions Mean                 0.156391
exploration/Actions Std                  0.599101
exploration/Actions Max                  0.996859
exploration/Actions Min                 -0.997492
exploration/Num Paths                   10
exploration/Average Returns          -1109.01
evaluation/num steps total          265320
evaluation/num paths total            1320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.80789
evaluation/Rewards Std                   0.486308
evaluation/Rewards Max                  -3.23891
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1167.39
evaluation/Returns Std                  78.1039
evaluation/Returns Max                -895.741
evaluation/Returns Min               -1218.94
evaluation/Actions Mean                  0.180248
evaluation/Actions Std                   0.352764
evaluation/Actions Max                   0.600144
evaluation/Actions Min                  -0.20786
evaluation/Num Paths                    24
evaluation/Average Returns           -1167.39
time/data storing (s)                    0.0258844
time/evaluation sampling (s)            12.7979
time/exploration sampling (s)            5.17551
time/logging (s)                         0.0179513
time/sac training (s)                   11.1714
time/saving (s)                          0.0192367
time/training (s)                        9.0238e-05
time/epoch (s)                          29.208
time/total (s)                        1747.01
Epoch                                   54
----------------------------------  ---------------
2020-11-09 13:51:30.654243 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 55 finished
----------------------------------  ---------------
replay_buffer/size                  114000
trainer/num train calls              56000
trainer/QF1 Loss                      3576.75
trainer/QF2 Loss                      3580.26
trainer/Policy Loss                    494.344
trainer/Q1 Predictions Mean           -494.527
trainer/Q1 Predictions Std              17.2632
trainer/Q1 Predictions Max            -410.428
trainer/Q1 Predictions Min            -536.439
trainer/Q2 Predictions Mean           -494.524
trainer/Q2 Predictions Std              17.2102
trainer/Q2 Predictions Max            -410.581
trainer/Q2 Predictions Min            -536.59
trainer/Q Targets Mean                -489.504
trainer/Q Targets Std                   63.4337
trainer/Q Targets Max                   -3.7816
trainer/Q Targets Min                 -538.181
trainer/Log Pis Mean                    -1.19334
trainer/Log Pis Std                      0.49195
trainer/Log Pis Max                     -0.0720429
trainer/Log Pis Min                     -2.59246
trainer/policy/mean Mean                -0.0559724
trainer/policy/mean Std                  0.282789
trainer/policy/mean Max                  0.281667
trainer/policy/mean Min                 -0.406853
trainer/policy/normal/std Mean           0.859893
trainer/policy/normal/std Std            0.016351
trainer/policy/normal/std Max            0.880981
trainer/policy/normal/std Min            0.828108
trainer/policy/normal/log_std Mean      -0.151128
trainer/policy/normal/log_std Std        0.0190348
trainer/policy/normal/log_std Max       -0.126719
trainer/policy/normal/log_std Min       -0.188612
trainer/Alpha                            0.192481
trainer/Alpha Loss                      -5.26185
exploration/num steps total         114000
exploration/num paths total            570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.42147
exploration/Rewards Std                  0.574298
exploration/Rewards Max                 -3.63153
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1084.29
exploration/Returns Std                 64.1186
exploration/Returns Max               -923.531
exploration/Returns Min              -1148.68
exploration/Actions Mean                -0.0458657
exploration/Actions Std                  0.602897
exploration/Actions Max                  0.997535
exploration/Actions Min                 -0.997869
exploration/Num Paths                   10
exploration/Average Returns          -1084.29
evaluation/num steps total          270144
evaluation/num paths total            1344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95691
evaluation/Rewards Std                   0.290918
evaluation/Rewards Max                  -4.15519
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1197.34
evaluation/Returns Std                  47.2357
evaluation/Returns Max                -991.112
evaluation/Returns Min               -1226.74
evaluation/Actions Mean                 -0.0559063
evaluation/Actions Std                   0.28162
evaluation/Actions Max                   0.260799
evaluation/Actions Min                  -0.381874
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.34
time/data storing (s)                    0.0227168
time/evaluation sampling (s)            12.4508
time/exploration sampling (s)            5.17268
time/logging (s)                         0.020104
time/sac training (s)                   11.5212
time/saving (s)                          0.0195004
time/training (s)                        0.00011117
time/epoch (s)                          29.2071
time/total (s)                        1777.28
Epoch                                   55
----------------------------------  ---------------
2020-11-09 13:52:00.069913 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 56 finished
----------------------------------  ----------------
replay_buffer/size                  116000
trainer/num train calls              57000
trainer/QF1 Loss                       960.04
trainer/QF2 Loss                       959.863
trainer/Policy Loss                    497.318
trainer/Q1 Predictions Mean           -497.617
trainer/Q1 Predictions Std              17.6161
trainer/Q1 Predictions Max            -367.473
trainer/Q1 Predictions Min            -559.858
trainer/Q2 Predictions Mean           -497.621
trainer/Q2 Predictions Std              17.5938
trainer/Q2 Predictions Max            -367.493
trainer/Q2 Predictions Min            -560.477
trainer/Q Targets Mean                -497.901
trainer/Q Targets Std                   35.6564
trainer/Q Targets Max                   -4.97825
trainer/Q Targets Min                 -561.186
trainer/Log Pis Mean                    -0.617765
trainer/Log Pis Std                      1.03898
trainer/Log Pis Max                      1.16696
trainer/Log Pis Min                     -4.26982
trainer/policy/mean Mean                 0.0257205
trainer/policy/mean Std                  0.606382
trainer/policy/mean Max                  0.689828
trainer/policy/mean Min                 -0.635895
trainer/policy/normal/std Mean           0.75352
trainer/policy/normal/std Std            0.0066692
trainer/policy/normal/std Max            0.766936
trainer/policy/normal/std Min            0.732787
trainer/policy/normal/log_std Mean      -0.283039
trainer/policy/normal/log_std Std        0.00888723
trainer/policy/normal/log_std Max       -0.265352
trainer/policy/normal/log_std Min       -0.3109
trainer/Alpha                            0.186897
trainer/Alpha Loss                      -4.39051
exploration/num steps total         116000
exploration/num paths total            580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.17998
exploration/Rewards Std                  0.807084
exploration/Rewards Max                 -2.47603
exploration/Rewards Min                 -6.14187
exploration/Returns Mean             -1036
exploration/Returns Std                127.428
exploration/Returns Max               -681.39
exploration/Returns Min              -1132.39
exploration/Actions Mean                 0.0328041
exploration/Actions Std                  0.652567
exploration/Actions Max                  0.99606
exploration/Actions Min                 -0.998196
exploration/Num Paths                   10
exploration/Average Returns          -1036
evaluation/num steps total          274968
evaluation/num paths total            1368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7257
evaluation/Rewards Std                   0.734545
evaluation/Rewards Max                  -2.28794
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1150.87
evaluation/Returns Std                 123.096
evaluation/Returns Max                -618.836
evaluation/Returns Min               -1225.95
evaluation/Actions Mean                  0.0258344
evaluation/Actions Std                   0.613983
evaluation/Actions Max                   0.697589
evaluation/Actions Min                  -0.643121
evaluation/Num Paths                    24
evaluation/Average Returns           -1150.87
time/data storing (s)                    0.0230389
time/evaluation sampling (s)            12.121
time/exploration sampling (s)            5.1203
time/logging (s)                         0.0189403
time/sac training (s)                   11.0419
time/saving (s)                          0.0181582
time/training (s)                        0.000119201
time/epoch (s)                          28.3434
time/total (s)                        1806.67
Epoch                                   56
----------------------------------  ----------------
2020-11-09 13:52:30.430520 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 57 finished
----------------------------------  ---------------
replay_buffer/size                  118000
trainer/num train calls              58000
trainer/QF1 Loss                         5.26668
trainer/QF2 Loss                         5.39309
trainer/Policy Loss                    501.723
trainer/Q1 Predictions Mean           -501.887
trainer/Q1 Predictions Std              15.5117
trainer/Q1 Predictions Max            -412.499
trainer/Q1 Predictions Min            -536.426
trainer/Q2 Predictions Mean           -501.877
trainer/Q2 Predictions Std              15.525
trainer/Q2 Predictions Max            -412.216
trainer/Q2 Predictions Min            -536.209
trainer/Q Targets Mean                -503.599
trainer/Q Targets Std                   15.6884
trainer/Q Targets Max                 -410.13
trainer/Q Targets Min                 -537.341
trainer/Log Pis Mean                    -1.06603
trainer/Log Pis Std                      0.764487
trainer/Log Pis Max                      0.611998
trainer/Log Pis Min                     -2.85394
trainer/policy/mean Mean                -0.0213213
trainer/policy/mean Std                  0.447854
trainer/policy/mean Max                  0.486134
trainer/policy/mean Min                 -0.530654
trainer/policy/normal/std Mean           0.843244
trainer/policy/normal/std Std            0.0117861
trainer/policy/normal/std Max            0.859964
trainer/policy/normal/std Min            0.818069
trainer/policy/normal/log_std Mean      -0.170597
trainer/policy/normal/log_std Std        0.0139846
trainer/policy/normal/log_std Max       -0.150865
trainer/policy/normal/log_std Min       -0.200809
trainer/Alpha                            0.181748
trainer/Alpha Loss                      -5.22801
exploration/num steps total         118000
exploration/num paths total            590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.31306
exploration/Rewards Std                  0.725172
exploration/Rewards Max                 -3.14608
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1062.61
exploration/Returns Std                109.756
exploration/Returns Max               -758.898
exploration/Returns Min              -1154.57
exploration/Actions Mean                -0.0176654
exploration/Actions Std                  0.61961
exploration/Actions Max                  0.996302
exploration/Actions Min                 -0.996995
exploration/Num Paths                   10
exploration/Average Returns          -1062.61
evaluation/num steps total          279792
evaluation/num paths total            1392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9668
evaluation/Rewards Std                   0.163412
evaluation/Rewards Max                  -5.41473
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1199.33
evaluation/Returns Std                  20.9108
evaluation/Returns Max               -1153.27
evaluation/Returns Min               -1225.53
evaluation/Actions Mean                 -0.0212455
evaluation/Actions Std                   0.447324
evaluation/Actions Max                   0.450328
evaluation/Actions Min                  -0.494131
evaluation/Num Paths                    24
evaluation/Average Returns           -1199.33
time/data storing (s)                    0.0242491
time/evaluation sampling (s)            12.8989
time/exploration sampling (s)            5.16015
time/logging (s)                         0.0189389
time/sac training (s)                   11.1675
time/saving (s)                          0.0198817
time/training (s)                        9.2375e-05
time/epoch (s)                          29.2897
time/total (s)                        1837.01
Epoch                                   57
----------------------------------  ---------------
2020-11-09 13:53:00.815639 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 58 finished
----------------------------------  ---------------
replay_buffer/size                  120000
trainer/num train calls              59000
trainer/QF1 Loss                      1990.23
trainer/QF2 Loss                      1991.55
trainer/Policy Loss                    502.072
trainer/Q1 Predictions Mean           -502.216
trainer/Q1 Predictions Std              17.9923
trainer/Q1 Predictions Max            -427.558
trainer/Q1 Predictions Min            -541.984
trainer/Q2 Predictions Mean           -502.236
trainer/Q2 Predictions Std              17.9254
trainer/Q2 Predictions Max            -427.587
trainer/Q2 Predictions Min            -541.134
trainer/Q Targets Mean                -501.134
trainer/Q Targets Std                   47.5226
trainer/Q Targets Max                   -5.21224
trainer/Q Targets Min                 -542.688
trainer/Log Pis Mean                    -1.02332
trainer/Log Pis Std                      0.76863
trainer/Log Pis Max                      0.553256
trainer/Log Pis Min                     -3.76077
trainer/policy/mean Mean                -0.018037
trainer/policy/mean Std                  0.448306
trainer/policy/mean Max                  0.48273
trainer/policy/mean Min                 -0.517431
trainer/policy/normal/std Mean           0.826645
trainer/policy/normal/std Std            0.0126208
trainer/policy/normal/std Max            0.845568
trainer/policy/normal/std Min            0.801674
trainer/policy/normal/log_std Mean      -0.190497
trainer/policy/normal/log_std Std        0.015278
trainer/policy/normal/log_std Max       -0.167746
trainer/policy/normal/log_std Min       -0.221054
trainer/Alpha                            0.176182
trainer/Alpha Loss                      -5.24921
exploration/num steps total         120000
exploration/num paths total            600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.10803
exploration/Rewards Std                  0.898833
exploration/Rewards Max                 -2.82469
exploration/Rewards Min                 -6.14191
exploration/Returns Mean             -1021.61
exploration/Returns Std                111.673
exploration/Returns Max               -783.464
exploration/Returns Min              -1113.61
exploration/Actions Mean                -0.0166073
exploration/Actions Std                  0.612989
exploration/Actions Max                  0.993616
exploration/Actions Min                 -0.996135
exploration/Num Paths                   10
exploration/Average Returns          -1021.61
evaluation/num steps total          284616
evaluation/num paths total            1416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95407
evaluation/Rewards Std                   0.172403
evaluation/Rewards Max                  -5.36084
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1196.77
evaluation/Returns Std                  21.6358
evaluation/Returns Max               -1157.29
evaluation/Returns Min               -1222.7
evaluation/Actions Mean                 -0.0180428
evaluation/Actions Std                   0.443856
evaluation/Actions Max                   0.454882
evaluation/Actions Min                  -0.491596
evaluation/Num Paths                    24
evaluation/Average Returns           -1196.77
time/data storing (s)                    0.0228508
time/evaluation sampling (s)            12.7029
time/exploration sampling (s)            5.3687
time/logging (s)                         0.0192296
time/sac training (s)                   11.1733
time/saving (s)                          0.0181581
time/training (s)                        9.1752e-05
time/epoch (s)                          29.3052
time/total (s)                        1867.37
Epoch                                   58
----------------------------------  ---------------
2020-11-09 13:53:30.141781 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 59 finished
----------------------------------  ---------------
replay_buffer/size                  122000
trainer/num train calls              60000
trainer/QF1 Loss                      1017.23
trainer/QF2 Loss                      1015.96
trainer/Policy Loss                    506.072
trainer/Q1 Predictions Mean           -506.213
trainer/Q1 Predictions Std              17.3827
trainer/Q1 Predictions Max            -407.451
trainer/Q1 Predictions Min            -536.274
trainer/Q2 Predictions Mean           -506.217
trainer/Q2 Predictions Std              17.3822
trainer/Q2 Predictions Max            -407.248
trainer/Q2 Predictions Min            -535.901
trainer/Q Targets Mean                -506.397
trainer/Q Targets Std                   35.9749
trainer/Q Targets Max                   -5.43233
trainer/Q Targets Min                 -536.298
trainer/Log Pis Mean                    -1.36116
trainer/Log Pis Std                      0.276509
trainer/Log Pis Max                     -0.741683
trainer/Log Pis Min                     -3.36438
trainer/policy/mean Mean                 0.0346037
trainer/policy/mean Std                  0.0822055
trainer/policy/mean Max                  0.177581
trainer/policy/mean Min                 -0.082878
trainer/policy/normal/std Mean           0.8775
trainer/policy/normal/std Std            0.00542546
trainer/policy/normal/std Max            0.886505
trainer/policy/normal/std Min            0.861516
trainer/policy/normal/log_std Mean      -0.130697
trainer/policy/normal/log_std Std        0.00618842
trainer/policy/normal/log_std Max       -0.120468
trainer/policy/normal/log_std Min       -0.149062
trainer/Alpha                            0.170713
trainer/Alpha Loss                      -5.94178
exploration/num steps total         122000
exploration/num paths total            610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.47535
exploration/Rewards Std                  0.758696
exploration/Rewards Max                 -1.80708
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1095.07
exploration/Returns Std                 85.2742
exploration/Returns Max               -900.026
exploration/Returns Min              -1186.08
exploration/Actions Mean                 0.0114795
exploration/Actions Std                  0.58649
exploration/Actions Max                  0.99405
exploration/Actions Min                 -0.999274
exploration/Num Paths                   10
exploration/Average Returns          -1095.07
evaluation/num steps total          289440
evaluation/num paths total            1440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0249
evaluation/Rewards Std                   0.180674
evaluation/Rewards Max                  -5.14006
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1211
evaluation/Returns Std                  28.3813
evaluation/Returns Max               -1125.41
evaluation/Returns Min               -1231.31
evaluation/Actions Mean                  0.0347774
evaluation/Actions Std                   0.0823179
evaluation/Actions Max                   0.152383
evaluation/Actions Min                  -0.0700099
evaluation/Num Paths                    24
evaluation/Average Returns           -1211
time/data storing (s)                    0.0243242
time/evaluation sampling (s)            12.2089
time/exploration sampling (s)            5.12187
time/logging (s)                         0.0177065
time/sac training (s)                   10.8662
time/saving (s)                          0.0209226
time/training (s)                        9.1482e-05
time/epoch (s)                          28.2601
time/total (s)                        1896.68
Epoch                                   59
----------------------------------  ---------------
2020-11-09 13:54:00.550625 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 60 finished
----------------------------------  ----------------
replay_buffer/size                  124000
trainer/num train calls              61000
trainer/QF1 Loss                       994.882
trainer/QF2 Loss                       994.654
trainer/Policy Loss                    508.166
trainer/Q1 Predictions Mean           -508.362
trainer/Q1 Predictions Std              19.2026
trainer/Q1 Predictions Max            -419.323
trainer/Q1 Predictions Min            -539.29
trainer/Q2 Predictions Mean           -508.331
trainer/Q2 Predictions Std              19.213
trainer/Q2 Predictions Max            -419.522
trainer/Q2 Predictions Min            -539.247
trainer/Q Targets Mean                -508.484
trainer/Q Targets Std                   37.101
trainer/Q Targets Max                   -4.98026
trainer/Q Targets Min                 -541.094
trainer/Log Pis Mean                    -1.02064
trainer/Log Pis Std                      0.827035
trainer/Log Pis Max                      0.442287
trainer/Log Pis Min                     -3.57689
trainer/policy/mean Mean                 0.0884869
trainer/policy/mean Std                  0.457723
trainer/policy/mean Max                  0.61645
trainer/policy/mean Min                 -0.423854
trainer/policy/normal/std Mean           0.796126
trainer/policy/normal/std Std            0.0208494
trainer/policy/normal/std Max            0.825258
trainer/policy/normal/std Min            0.757732
trainer/policy/normal/log_std Mean      -0.228341
trainer/policy/normal/log_std Std        0.0262227
trainer/policy/normal/log_std Max       -0.192059
trainer/policy/normal/log_std Min       -0.277425
trainer/Alpha                            0.165578
trainer/Alpha Loss                      -5.43206
exploration/num steps total         124000
exploration/num paths total            620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.20266
exploration/Rewards Std                  0.920517
exploration/Rewards Max                 -2.34627
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1040.53
exploration/Returns Std                152.067
exploration/Returns Max               -729.902
exploration/Returns Min              -1187.25
exploration/Actions Mean                 0.0852912
exploration/Actions Std                  0.607191
exploration/Actions Max                  0.995781
exploration/Actions Min                 -0.997432
exploration/Num Paths                   10
exploration/Average Returns          -1040.53
evaluation/num steps total          294264
evaluation/num paths total            1464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82798
evaluation/Rewards Std                   0.438837
evaluation/Rewards Max                  -3.07038
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1171.42
evaluation/Returns Std                  70.1326
evaluation/Returns Max                -906.482
evaluation/Returns Min               -1225.21
evaluation/Actions Mean                  0.088685
evaluation/Actions Std                   0.459489
evaluation/Actions Max                   0.618353
evaluation/Actions Min                  -0.426824
evaluation/Num Paths                    24
evaluation/Average Returns           -1171.42
time/data storing (s)                    0.0202568
time/evaluation sampling (s)            12.9254
time/exploration sampling (s)            5.28086
time/logging (s)                         0.0191874
time/sac training (s)                   11.0542
time/saving (s)                          0.0222963
time/training (s)                        0.000115432
time/epoch (s)                          29.3222
time/total (s)                        1927.07
Epoch                                   60
----------------------------------  ----------------
2020-11-09 13:54:29.810609 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 61 finished
----------------------------------  ---------------
replay_buffer/size                  126000
trainer/num train calls              62000
trainer/QF1 Loss                      1995.01
trainer/QF2 Loss                      1995.52
trainer/Policy Loss                    511.994
trainer/Q1 Predictions Mean           -512.268
trainer/Q1 Predictions Std              16.2466
trainer/Q1 Predictions Max            -434.616
trainer/Q1 Predictions Min            -547.792
trainer/Q2 Predictions Mean           -512.28
trainer/Q2 Predictions Std              16.2631
trainer/Q2 Predictions Max            -434.299
trainer/Q2 Predictions Min            -548.68
trainer/Q Targets Mean                -510.784
trainer/Q Targets Std                   47.7939
trainer/Q Targets Max                   -5.01463
trainer/Q Targets Min                 -549.905
trainer/Log Pis Mean                    -1.08403
trainer/Log Pis Std                      0.675367
trainer/Log Pis Max                      0.0561006
trainer/Log Pis Min                     -3.86112
trainer/policy/mean Mean                 0.245817
trainer/policy/mean Std                  0.305843
trainer/policy/mean Max                  0.634488
trainer/policy/mean Min                 -0.0870124
trainer/policy/normal/std Mean           0.813378
trainer/policy/normal/std Std            0.0698193
trainer/policy/normal/std Max            0.886648
trainer/policy/normal/std Min            0.719175
trainer/policy/normal/log_std Mean      -0.210262
trainer/policy/normal/log_std Std        0.0861314
trainer/policy/normal/log_std Max       -0.120308
trainer/policy/normal/log_std Min       -0.32965
trainer/Alpha                            0.160757
trainer/Alpha Loss                      -5.63717
exploration/num steps total         126000
exploration/num paths total            630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.6772
exploration/Rewards Std                  0.300883
exploration/Rewards Max                 -3.89881
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1135.44
exploration/Returns Std                 30.3334
exploration/Returns Max              -1077.81
exploration/Returns Min              -1167.78
exploration/Actions Mean                 0.185225
exploration/Actions Std                  0.575833
exploration/Actions Max                  0.998072
exploration/Actions Min                 -0.992166
exploration/Num Paths                   10
exploration/Average Returns          -1135.44
evaluation/num steps total          299088
evaluation/num paths total            1488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.90854
evaluation/Rewards Std                   0.208631
evaluation/Rewards Max                  -4.7322
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1187.62
evaluation/Returns Std                  26.3047
evaluation/Returns Max               -1096.11
evaluation/Returns Min               -1219.31
evaluation/Actions Mean                  0.244057
evaluation/Actions Std                   0.302302
evaluation/Actions Max                   0.618875
evaluation/Actions Min                  -0.0817147
evaluation/Num Paths                    24
evaluation/Average Returns           -1187.62
time/data storing (s)                    0.024438
time/evaluation sampling (s)            12.1909
time/exploration sampling (s)            5.11106
time/logging (s)                         0.0189902
time/sac training (s)                   10.8346
time/saving (s)                          0.0206868
time/training (s)                        9.5036e-05
time/epoch (s)                          28.2008
time/total (s)                        1956.31
Epoch                                   61
----------------------------------  ---------------
2020-11-09 13:54:59.108817 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 62 finished
----------------------------------  ----------------
replay_buffer/size                  128000
trainer/num train calls              63000
trainer/QF1 Loss                      3138.15
trainer/QF2 Loss                      3139.56
trainer/Policy Loss                    513.063
trainer/Q1 Predictions Mean           -513.186
trainer/Q1 Predictions Std              18.9813
trainer/Q1 Predictions Max            -408.615
trainer/Q1 Predictions Min            -541.326
trainer/Q2 Predictions Mean           -513.193
trainer/Q2 Predictions Std              18.9659
trainer/Q2 Predictions Max            -408.864
trainer/Q2 Predictions Min            -540.951
trainer/Q Targets Mean                -509.661
trainer/Q Targets Std                   58.097
trainer/Q Targets Max                   -5.22348
trainer/Q Targets Min                 -541.98
trainer/Log Pis Mean                    -1.28238
trainer/Log Pis Std                      0.416296
trainer/Log Pis Max                     -0.0842767
trainer/Log Pis Min                     -2.21441
trainer/policy/mean Mean                 0.0535921
trainer/policy/mean Std                  0.241075
trainer/policy/mean Max                  0.383217
trainer/policy/mean Min                 -0.252084
trainer/policy/normal/std Mean           0.880589
trainer/policy/normal/std Std            0.0198137
trainer/policy/normal/std Max            0.906673
trainer/policy/normal/std Min            0.848422
trainer/policy/normal/log_std Mean      -0.127418
trainer/policy/normal/log_std Std        0.0225228
trainer/policy/normal/log_std Max       -0.0979736
trainer/policy/normal/log_std Min       -0.164377
trainer/Alpha                            0.156182
trainer/Alpha Loss                      -6.0945
exploration/num steps total         128000
exploration/num paths total            640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.31444
exploration/Rewards Std                  0.770984
exploration/Rewards Max                 -2.99868
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1062.89
exploration/Returns Std                117.629
exploration/Returns Max               -744.246
exploration/Returns Min              -1162.73
exploration/Actions Mean                 0.0325538
exploration/Actions Std                  0.603036
exploration/Actions Max                  0.997934
exploration/Actions Min                 -0.996288
exploration/Num Paths                   10
exploration/Average Returns          -1062.89
evaluation/num steps total          303912
evaluation/num paths total            1512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97903
evaluation/Rewards Std                   0.176771
evaluation/Rewards Max                  -4.98306
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1201.79
evaluation/Returns Std                  23.5812
evaluation/Returns Max               -1149.46
evaluation/Returns Min               -1228.47
evaluation/Actions Mean                  0.0525893
evaluation/Actions Std                   0.234036
evaluation/Actions Max                   0.368245
evaluation/Actions Min                  -0.241492
evaluation/Num Paths                    24
evaluation/Average Returns           -1201.79
time/data storing (s)                    0.024523
time/evaluation sampling (s)            12.167
time/exploration sampling (s)            5.11414
time/logging (s)                         0.0165698
time/sac training (s)                   10.8924
time/saving (s)                          0.0226338
time/training (s)                        0.000106135
time/epoch (s)                          28.2374
time/total (s)                        1985.58
Epoch                                   62
----------------------------------  ----------------
2020-11-09 13:55:28.505205 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 63 finished
----------------------------------  ----------------
replay_buffer/size                  130000
trainer/num train calls              64000
trainer/QF1 Loss                      1830.36
trainer/QF2 Loss                      1835.1
trainer/Policy Loss                    514.472
trainer/Q1 Predictions Mean           -514.68
trainer/Q1 Predictions Std              21.405
trainer/Q1 Predictions Max            -409.094
trainer/Q1 Predictions Min            -554.114
trainer/Q2 Predictions Mean           -514.696
trainer/Q2 Predictions Std              21.4061
trainer/Q2 Predictions Max            -409.243
trainer/Q2 Predictions Min            -553.626
trainer/Q Targets Mean                -512.863
trainer/Q Targets Std                   49.968
trainer/Q Targets Max                   -3.58316
trainer/Q Targets Min                 -555.226
trainer/Log Pis Mean                    -1.19299
trainer/Log Pis Std                      0.553058
trainer/Log Pis Max                      0.000485182
trainer/Log Pis Min                     -3.15468
trainer/policy/mean Mean                 0.14687
trainer/policy/mean Std                  0.281159
trainer/policy/mean Max                  0.551869
trainer/policy/mean Min                 -0.194288
trainer/policy/normal/std Mean           0.843691
trainer/policy/normal/std Std            0.0324523
trainer/policy/normal/std Max            0.880885
trainer/policy/normal/std Min            0.787945
trainer/policy/normal/log_std Mean      -0.170711
trainer/policy/normal/log_std Std        0.038542
trainer/policy/normal/log_std Max       -0.126828
trainer/policy/normal/log_std Min       -0.238326
trainer/Alpha                            0.151405
trainer/Alpha Loss                      -6.02772
exploration/num steps total         130000
exploration/num paths total            650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.53088
exploration/Rewards Std                  0.585254
exploration/Rewards Max                 -3.03558
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1106.18
exploration/Returns Std                 73.6853
exploration/Returns Max               -911.805
exploration/Returns Min              -1184.09
exploration/Actions Mean                 0.111816
exploration/Actions Std                  0.592629
exploration/Actions Max                  0.997688
exploration/Actions Min                 -0.997464
exploration/Num Paths                   10
exploration/Average Returns          -1106.18
evaluation/num steps total          308736
evaluation/num paths total            1536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.85829
evaluation/Rewards Std                   0.343924
evaluation/Rewards Max                  -4.29202
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1177.52
evaluation/Returns Std                  47.1756
evaluation/Returns Max               -1060.47
evaluation/Returns Min               -1224.49
evaluation/Actions Mean                  0.145672
evaluation/Actions Std                   0.278195
evaluation/Actions Max                   0.536367
evaluation/Actions Min                  -0.189165
evaluation/Num Paths                    24
evaluation/Average Returns           -1177.52
time/data storing (s)                    0.0231645
time/evaluation sampling (s)            12.2583
time/exploration sampling (s)            5.08797
time/logging (s)                         0.0191181
time/sac training (s)                   10.9182
time/saving (s)                          0.0201457
time/training (s)                        0.000113237
time/epoch (s)                          28.3269
time/total (s)                        2014.96
Epoch                                   63
----------------------------------  ----------------
2020-11-09 13:55:57.672067 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 64 finished
----------------------------------  ----------------
replay_buffer/size                  132000
trainer/num train calls              65000
trainer/QF1 Loss                       952.075
trainer/QF2 Loss                       951.669
trainer/Policy Loss                    517.075
trainer/Q1 Predictions Mean           -517.383
trainer/Q1 Predictions Std              19.0398
trainer/Q1 Predictions Max            -424.933
trainer/Q1 Predictions Min            -552.625
trainer/Q2 Predictions Mean           -517.39
trainer/Q2 Predictions Std              19.0313
trainer/Q2 Predictions Max            -424.52
trainer/Q2 Predictions Min            -552.856
trainer/Q Targets Mean                -518.062
trainer/Q Targets Std                   37.4473
trainer/Q Targets Max                   -5.63165
trainer/Q Targets Min                 -554.534
trainer/Log Pis Mean                    -0.374333
trainer/Log Pis Std                      1.17503
trainer/Log Pis Max                      1.72045
trainer/Log Pis Min                     -4.38568
trainer/policy/mean Mean                 0.0818787
trainer/policy/mean Std                  0.649123
trainer/policy/mean Max                  0.804022
trainer/policy/mean Min                 -0.648824
trainer/policy/normal/std Mean           0.764561
trainer/policy/normal/std Std            0.0186367
trainer/policy/normal/std Max            0.798592
trainer/policy/normal/std Min            0.722055
trainer/policy/normal/log_std Mean      -0.268751
trainer/policy/normal/log_std Std        0.024427
trainer/policy/normal/log_std Max       -0.224905
trainer/policy/normal/log_std Min       -0.325654
trainer/Alpha                            0.147528
trainer/Alpha Loss                      -4.54385
exploration/num steps total         132000
exploration/num paths total            660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.13001
exploration/Rewards Std                  0.899311
exploration/Rewards Max                 -2.99992
exploration/Rewards Min                 -6.1419
exploration/Returns Mean             -1026
exploration/Returns Std                134.467
exploration/Returns Max               -737.808
exploration/Returns Min              -1143.94
exploration/Actions Mean                 0.0812461
exploration/Actions Std                  0.683208
exploration/Actions Max                  0.997856
exploration/Actions Min                 -0.998382
exploration/Num Paths                   10
exploration/Average Returns          -1026
evaluation/num steps total          313560
evaluation/num paths total            1560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78577
evaluation/Rewards Std                   0.497671
evaluation/Rewards Max                  -2.56466
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1162.94
evaluation/Returns Std                  79.8116
evaluation/Returns Max                -850.049
evaluation/Returns Min               -1215.81
evaluation/Actions Mean                  0.0818526
evaluation/Actions Std                   0.648966
evaluation/Actions Max                   0.795843
evaluation/Actions Min                  -0.633623
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.94
time/data storing (s)                    0.0200027
time/evaluation sampling (s)            12.165
time/exploration sampling (s)            5.08515
time/logging (s)                         0.0153488
time/sac training (s)                   10.7898
time/saving (s)                          0.0221293
time/training (s)                        0.000107512
time/epoch (s)                          28.0975
time/total (s)                        2044.1
Epoch                                   64
----------------------------------  ----------------
2020-11-09 13:56:27.413663 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 65 finished
----------------------------------  ---------------
replay_buffer/size                  134000
trainer/num train calls              66000
trainer/QF1 Loss                       933.863
trainer/QF2 Loss                       929.411
trainer/Policy Loss                    520.911
trainer/Q1 Predictions Mean           -521.082
trainer/Q1 Predictions Std              19.4222
trainer/Q1 Predictions Max            -416.539
trainer/Q1 Predictions Min            -575.784
trainer/Q2 Predictions Mean           -521.076
trainer/Q2 Predictions Std              19.4503
trainer/Q2 Predictions Max            -416.529
trainer/Q2 Predictions Min            -576.741
trainer/Q Targets Mean                -521.354
trainer/Q Targets Std                   37.8275
trainer/Q Targets Max                   -4.50361
trainer/Q Targets Min                 -577.694
trainer/Log Pis Mean                    -0.955021
trainer/Log Pis Std                      0.775715
trainer/Log Pis Max                      0.695717
trainer/Log Pis Min                     -3.95473
trainer/policy/mean Mean                 0.247225
trainer/policy/mean Std                  0.384745
trainer/policy/mean Max                  0.751337
trainer/policy/mean Min                 -0.204246
trainer/policy/normal/std Mean           0.809378
trainer/policy/normal/std Std            0.0764025
trainer/policy/normal/std Max            0.889772
trainer/policy/normal/std Min            0.695105
trainer/policy/normal/log_std Mean      -0.215978
trainer/policy/normal/log_std Std        0.0948843
trainer/policy/normal/log_std Max       -0.116791
trainer/policy/normal/log_std Min       -0.363693
trainer/Alpha                            0.143022
trainer/Alpha Loss                      -5.74681
exploration/num steps total         134000
exploration/num paths total            670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5639
exploration/Rewards Std                  0.484863
exploration/Rewards Max                 -3.63794
exploration/Rewards Min                 -6.14179
exploration/Returns Mean             -1112.78
exploration/Returns Std                 65.4917
exploration/Returns Max               -944.51
exploration/Returns Min              -1163.04
exploration/Actions Mean                 0.209952
exploration/Actions Std                  0.592008
exploration/Actions Max                  0.995754
exploration/Actions Min                 -0.995959
exploration/Num Paths                   10
exploration/Average Returns          -1112.78
evaluation/num steps total          318384
evaluation/num paths total            1584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.92113
evaluation/Rewards Std                   0.208213
evaluation/Rewards Max                  -4.98556
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1190.15
evaluation/Returns Std                  26.5619
evaluation/Returns Max               -1111.54
evaluation/Returns Min               -1223.53
evaluation/Actions Mean                  0.245867
evaluation/Actions Std                   0.380124
evaluation/Actions Max                   0.715873
evaluation/Actions Min                  -0.182235
evaluation/Num Paths                    24
evaluation/Average Returns           -1190.15
time/data storing (s)                    0.0226851
time/evaluation sampling (s)            12.7673
time/exploration sampling (s)            5.1132
time/logging (s)                         0.0189874
time/sac training (s)                   10.7722
time/saving (s)                          0.0205264
time/training (s)                        9.1425e-05
time/epoch (s)                          28.715
time/total (s)                        2073.82
Epoch                                   65
----------------------------------  ---------------
2020-11-09 13:56:56.408383 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 66 finished
----------------------------------  ---------------
replay_buffer/size                  136000
trainer/num train calls              67000
trainer/QF1 Loss                      3004.56
trainer/QF2 Loss                      3005.63
trainer/Policy Loss                    522.393
trainer/Q1 Predictions Mean           -522.642
trainer/Q1 Predictions Std              19.2076
trainer/Q1 Predictions Max            -419.126
trainer/Q1 Predictions Min            -559.472
trainer/Q2 Predictions Mean           -522.63
trainer/Q2 Predictions Std              19.1511
trainer/Q2 Predictions Max            -420.019
trainer/Q2 Predictions Min            -559.186
trainer/Q Targets Mean                -519.046
trainer/Q Targets Std                   59.2263
trainer/Q Targets Max                   -4.23124
trainer/Q Targets Min                 -564.663
trainer/Log Pis Mean                    -0.577548
trainer/Log Pis Std                      1.12685
trainer/Log Pis Max                      1.25335
trainer/Log Pis Min                     -4.15867
trainer/policy/mean Mean                 0.538985
trainer/policy/mean Std                  0.233147
trainer/policy/mean Max                  0.858961
trainer/policy/mean Min                  0.288549
trainer/policy/normal/std Mean           0.738957
trainer/policy/normal/std Std            0.0617285
trainer/policy/normal/std Max            0.811986
trainer/policy/normal/std Min            0.641879
trainer/policy/normal/log_std Mean      -0.306025
trainer/policy/normal/log_std Std        0.0838751
trainer/policy/normal/log_std Max       -0.208272
trainer/policy/normal/log_std Min       -0.443355
trainer/Alpha                            0.139006
trainer/Alpha Loss                      -5.08612
exploration/num steps total         136000
exploration/num paths total            680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.65507
exploration/Rewards Std                  0.590494
exploration/Rewards Max                 -3.23731
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1131.01
exploration/Returns Std                 96.669
exploration/Returns Max               -871.655
exploration/Returns Min              -1198.18
exploration/Actions Mean                 0.444523
exploration/Actions Std                  0.491757
exploration/Actions Max                  0.999285
exploration/Actions Min                 -0.980657
exploration/Num Paths                   10
exploration/Average Returns          -1131.01
evaluation/num steps total          323208
evaluation/num paths total            1608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78471
evaluation/Rewards Std                   0.572925
evaluation/Rewards Max                  -3.4992
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1162.73
evaluation/Returns Std                  77.9598
evaluation/Returns Max                -888.657
evaluation/Returns Min               -1222.71
evaluation/Actions Mean                  0.537695
evaluation/Actions Std                   0.231751
evaluation/Actions Max                   0.848975
evaluation/Actions Min                   0.300133
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.73
time/data storing (s)                    0.0199074
time/evaluation sampling (s)            12.1984
time/exploration sampling (s)            5.10799
time/logging (s)                         0.0188307
time/sac training (s)                   10.6086
time/saving (s)                          0.0176566
time/training (s)                        9.0718e-05
time/epoch (s)                          27.9715
time/total (s)                        2102.8
Epoch                                   66
----------------------------------  ---------------
2020-11-09 13:57:26.816864 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 67 finished
----------------------------------  ---------------
replay_buffer/size                  138000
trainer/num train calls              68000
trainer/QF1 Loss                      5338.85
trainer/QF2 Loss                      5341.35
trainer/Policy Loss                    523.811
trainer/Q1 Predictions Mean           -523.992
trainer/Q1 Predictions Std              19.4326
trainer/Q1 Predictions Max            -444.718
trainer/Q1 Predictions Min            -579.533
trainer/Q2 Predictions Mean           -523.97
trainer/Q2 Predictions Std              19.4338
trainer/Q2 Predictions Max            -444.499
trainer/Q2 Predictions Min            -578.403
trainer/Q Targets Mean                -515.822
trainer/Q Targets Std                   74.7387
trainer/Q Targets Max                   -4.32082
trainer/Q Targets Min                 -583.212
trainer/Log Pis Mean                    -0.839507
trainer/Log Pis Std                      0.995131
trainer/Log Pis Max                      0.998435
trainer/Log Pis Min                     -4.77853
trainer/policy/mean Mean                 0.513134
trainer/policy/mean Std                  0.128621
trainer/policy/mean Max                  0.752153
trainer/policy/mean Min                  0.360328
trainer/policy/normal/std Mean           0.848075
trainer/policy/normal/std Std            0.0653057
trainer/policy/normal/std Max            0.925464
trainer/policy/normal/std Min            0.766095
trainer/policy/normal/log_std Mean      -0.167762
trainer/policy/normal/log_std Std        0.0771883
trainer/policy/normal/log_std Max       -0.0774601
trainer/policy/normal/log_std Min       -0.26645
trainer/Alpha                            0.135275
trainer/Alpha Loss                      -5.68028
exploration/num steps total         138000
exploration/num paths total            690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.80306
exploration/Rewards Std                  0.376631
exploration/Rewards Max                 -3.73498
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1160.61
exploration/Returns Std                 50.098
exploration/Returns Max              -1028.04
exploration/Returns Min              -1193.66
exploration/Actions Mean                 0.360705
exploration/Actions Std                  0.535879
exploration/Actions Max                  0.997617
exploration/Actions Min                 -0.991376
exploration/Num Paths                   10
exploration/Average Returns          -1160.61
evaluation/num steps total          328032
evaluation/num paths total            1632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81484
evaluation/Rewards Std                   0.390426
evaluation/Rewards Max                  -4.04737
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1168.78
evaluation/Returns Std                  60.6074
evaluation/Returns Max                -978.641
evaluation/Returns Min               -1223.97
evaluation/Actions Mean                  0.520325
evaluation/Actions Std                   0.132715
evaluation/Actions Max                   0.724011
evaluation/Actions Min                   0.372915
evaluation/Num Paths                    24
evaluation/Average Returns           -1168.78
time/data storing (s)                    0.0250385
time/evaluation sampling (s)            13.4503
time/exploration sampling (s)            5.25729
time/logging (s)                         0.0162129
time/sac training (s)                   10.6173
time/saving (s)                          0.0189097
time/training (s)                        8.9104e-05
time/epoch (s)                          29.3851
time/total (s)                        2133.18
Epoch                                   67
----------------------------------  ---------------
2020-11-09 13:57:56.352672 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 68 finished
----------------------------------  ---------------
replay_buffer/size                  140000
trainer/num train calls              69000
trainer/QF1 Loss                      3128.62
trainer/QF2 Loss                      3130.35
trainer/Policy Loss                    526.909
trainer/Q1 Predictions Mean           -526.989
trainer/Q1 Predictions Std              16.4317
trainer/Q1 Predictions Max            -445.72
trainer/Q1 Predictions Min            -589.496
trainer/Q2 Predictions Mean           -527.008
trainer/Q2 Predictions Std              16.4107
trainer/Q2 Predictions Max            -445.56
trainer/Q2 Predictions Min            -589.334
trainer/Q Targets Mean                -523.023
trainer/Q Targets Std                   58.6744
trainer/Q Targets Max                   -5.21988
trainer/Q Targets Min                 -589.622
trainer/Log Pis Mean                    -0.860598
trainer/Log Pis Std                      0.842773
trainer/Log Pis Max                      0.672192
trainer/Log Pis Min                     -3.51318
trainer/policy/mean Mean                 0.218176
trainer/policy/mean Std                  0.426403
trainer/policy/mean Max                  0.738249
trainer/policy/mean Min                 -0.28153
trainer/policy/normal/std Mean           0.8485
trainer/policy/normal/std Std            0.0191706
trainer/policy/normal/std Max            0.874577
trainer/policy/normal/std Min            0.817728
trainer/policy/normal/log_std Mean      -0.164541
trainer/policy/normal/log_std Std        0.0226074
trainer/policy/normal/log_std Max       -0.134015
trainer/policy/normal/log_std Min       -0.201226
trainer/Alpha                            0.131303
trainer/Alpha Loss                      -5.80772
exploration/num steps total         140000
exploration/num paths total            700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.27014
exploration/Rewards Std                  0.971399
exploration/Rewards Max                 -2.85172
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1054.03
exploration/Returns Std                157.92
exploration/Returns Max               -734.652
exploration/Returns Min              -1180
exploration/Actions Mean                 0.176786
exploration/Actions Std                  0.615146
exploration/Actions Max                  0.997928
exploration/Actions Min                 -0.997766
exploration/Num Paths                   10
exploration/Average Returns          -1054.03
evaluation/num steps total          332856
evaluation/num paths total            1656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81625
evaluation/Rewards Std                   0.366251
evaluation/Rewards Max                  -4.18815
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1169.07
evaluation/Returns Std                  50.9403
evaluation/Returns Max               -1056.82
evaluation/Returns Min               -1215.24
evaluation/Actions Mean                  0.218823
evaluation/Actions Std                   0.431272
evaluation/Actions Max                   0.724066
evaluation/Actions Min                  -0.267465
evaluation/Num Paths                    24
evaluation/Average Returns           -1169.07
time/data storing (s)                    0.0231682
time/evaluation sampling (s)            12.1169
time/exploration sampling (s)            5.09424
time/logging (s)                         0.0153133
time/sac training (s)                   11.1985
time/saving (s)                          0.0207046
time/training (s)                        9.5894e-05
time/epoch (s)                          28.4689
time/total (s)                        2162.7
Epoch                                   68
----------------------------------  ---------------
2020-11-09 13:58:31.835857 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 69 finished
----------------------------------  ----------------
replay_buffer/size                  142000
trainer/num train calls              70000
trainer/QF1 Loss                      1210.81
trainer/QF2 Loss                      1211.82
trainer/Policy Loss                    528.277
trainer/Q1 Predictions Mean           -528.374
trainer/Q1 Predictions Std              21.9147
trainer/Q1 Predictions Max            -425.628
trainer/Q1 Predictions Min            -586.675
trainer/Q2 Predictions Mean           -528.368
trainer/Q2 Predictions Std              21.8743
trainer/Q2 Predictions Max            -425.99
trainer/Q2 Predictions Min            -586.731
trainer/Q Targets Mean                -528.683
trainer/Q Targets Std                   39.4906
trainer/Q Targets Max                   -5.27482
trainer/Q Targets Min                 -587.717
trainer/Log Pis Mean                    -0.853596
trainer/Log Pis Std                      0.942432
trainer/Log Pis Max                      1.15867
trainer/Log Pis Min                     -4.66795
trainer/policy/mean Mean                 0.210767
trainer/policy/mean Std                  0.471026
trainer/policy/mean Max                  0.784277
trainer/policy/mean Min                 -0.346497
trainer/policy/normal/std Mean           0.79254
trainer/policy/normal/std Std            0.060907
trainer/policy/normal/std Max            0.860943
trainer/policy/normal/std Min            0.698934
trainer/policy/normal/log_std Mean      -0.235481
trainer/policy/normal/log_std Std        0.0771537
trainer/policy/normal/log_std Max       -0.149726
trainer/policy/normal/log_std Min       -0.358199
trainer/Alpha                            0.127059
trainer/Alpha Loss                      -5.88727
exploration/num steps total         142000
exploration/num paths total            710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.53997
exploration/Rewards Std                  0.572805
exploration/Rewards Max                 -3.43676
exploration/Rewards Min                 -6.14196
exploration/Returns Mean             -1107.99
exploration/Returns Std                 66.8924
exploration/Returns Max               -928.352
exploration/Returns Min              -1163.51
exploration/Actions Mean                 0.192344
exploration/Actions Std                  0.618834
exploration/Actions Max                  0.997189
exploration/Actions Min                 -0.998535
exploration/Num Paths                   10
exploration/Average Returns          -1107.99
evaluation/num steps total          337680
evaluation/num paths total            1680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6894
evaluation/Rewards Std                   0.705696
evaluation/Rewards Max                  -1.7961
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1143.57
evaluation/Returns Std                 117.391
evaluation/Returns Max                -638.291
evaluation/Returns Min               -1217.77
evaluation/Actions Mean                  0.210782
evaluation/Actions Std                   0.473715
evaluation/Actions Max                   0.770815
evaluation/Actions Min                  -0.334912
evaluation/Num Paths                    24
evaluation/Average Returns           -1143.57
time/data storing (s)                    0.0279488
time/evaluation sampling (s)            12.3351
time/exploration sampling (s)            5.42049
time/logging (s)                         0.0258194
time/sac training (s)                   16.0518
time/saving (s)                          0.038803
time/training (s)                        0.000204528
time/epoch (s)                          33.9002
time/total (s)                        2198.16
Epoch                                   69
----------------------------------  ----------------
2020-11-09 13:59:01.752039 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 70 finished
----------------------------------  ----------------
replay_buffer/size                  144000
trainer/num train calls              71000
trainer/QF1 Loss                      1139.8
trainer/QF2 Loss                      1139.77
trainer/Policy Loss                    530.111
trainer/Q1 Predictions Mean           -530.273
trainer/Q1 Predictions Std              21.0835
trainer/Q1 Predictions Max            -397.996
trainer/Q1 Predictions Min            -580.426
trainer/Q2 Predictions Mean           -530.299
trainer/Q2 Predictions Std              21.0709
trainer/Q2 Predictions Max            -398.139
trainer/Q2 Predictions Min            -581.407
trainer/Q Targets Mean                -530.954
trainer/Q Targets Std                   39.224
trainer/Q Targets Max                   -5.62899
trainer/Q Targets Min                 -587.66
trainer/Log Pis Mean                    -0.850356
trainer/Log Pis Std                      0.845232
trainer/Log Pis Max                      0.538391
trainer/Log Pis Min                     -4.37829
trainer/policy/mean Mean                 0.430531
trainer/policy/mean Std                  0.216572
trainer/policy/mean Max                  0.770883
trainer/policy/mean Min                  0.208514
trainer/policy/normal/std Mean           0.76938
trainer/policy/normal/std Std            0.0488048
trainer/policy/normal/std Max            0.828687
trainer/policy/normal/std Min            0.682112
trainer/policy/normal/log_std Mean      -0.264195
trainer/policy/normal/log_std Std        0.0637311
trainer/policy/normal/log_std Max       -0.187913
trainer/policy/normal/log_std Min       -0.382561
trainer/Alpha                            0.123205
trainer/Alpha Loss                      -5.96837
exploration/num steps total         144000
exploration/num paths total            720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.696
exploration/Rewards Std                  0.584227
exploration/Rewards Max                 -3.21779
exploration/Rewards Min                 -6.14177
exploration/Returns Mean             -1139.2
exploration/Returns Std                 83.1667
exploration/Returns Max               -905.578
exploration/Returns Min              -1188.87
exploration/Actions Mean                 0.326604
exploration/Actions Std                  0.531372
exploration/Actions Max                  0.998888
exploration/Actions Min                 -0.980167
exploration/Num Paths                   10
exploration/Average Returns          -1139.2
evaluation/num steps total          342504
evaluation/num paths total            1704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82797
evaluation/Rewards Std                   0.375709
evaluation/Rewards Max                  -4.26064
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1171.42
evaluation/Returns Std                  54.9533
evaluation/Returns Max                -999.674
evaluation/Returns Min               -1223.11
evaluation/Actions Mean                  0.433438
evaluation/Actions Std                   0.219623
evaluation/Actions Max                   0.757031
evaluation/Actions Min                   0.21463
evaluation/Num Paths                    24
evaluation/Average Returns           -1171.42
time/data storing (s)                    0.0230096
time/evaluation sampling (s)            12.9642
time/exploration sampling (s)            5.10185
time/logging (s)                         0.0191932
time/sac training (s)                   10.7206
time/saving (s)                          0.0192785
time/training (s)                        0.000108208
time/epoch (s)                          28.8482
time/total (s)                        2228.05
Epoch                                   70
----------------------------------  ----------------
2020-11-09 13:59:30.868530 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 71 finished
----------------------------------  ----------------
replay_buffer/size                  146000
trainer/num train calls              72000
trainer/QF1 Loss                      4465.14
trainer/QF2 Loss                      4466.27
trainer/Policy Loss                    532.146
trainer/Q1 Predictions Mean           -532.293
trainer/Q1 Predictions Std              19.4209
trainer/Q1 Predictions Max            -444.921
trainer/Q1 Predictions Min            -601.919
trainer/Q2 Predictions Mean           -532.286
trainer/Q2 Predictions Std              19.4418
trainer/Q2 Predictions Max            -445.263
trainer/Q2 Predictions Min            -603.056
trainer/Q Targets Mean                -526.398
trainer/Q Targets Std                   68.4922
trainer/Q Targets Max                   -5.25999
trainer/Q Targets Min                 -604.053
trainer/Log Pis Mean                    -1.04027
trainer/Log Pis Std                      0.807332
trainer/Log Pis Max                      0.57714
trainer/Log Pis Min                     -3.35157
trainer/policy/mean Mean                 0.380454
trainer/policy/mean Std                  0.219444
trainer/policy/mean Max                  0.743589
trainer/policy/mean Min                  0.15373
trainer/policy/normal/std Mean           0.853028
trainer/policy/normal/std Std            0.0497375
trainer/policy/normal/std Max            0.904901
trainer/policy/normal/std Min            0.779245
trainer/policy/normal/log_std Mean      -0.160669
trainer/policy/normal/log_std Std        0.0584569
trainer/policy/normal/log_std Max       -0.0999293
trainer/policy/normal/log_std Min       -0.24943
trainer/Alpha                            0.119785
trainer/Alpha Loss                      -6.45163
exploration/num steps total         146000
exploration/num paths total            730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.34212
exploration/Rewards Std                  0.852939
exploration/Rewards Max                 -3.03531
exploration/Rewards Min                 -6.14168
exploration/Returns Mean             -1068.42
exploration/Returns Std                136.952
exploration/Returns Max               -792.95
exploration/Returns Min              -1168.91
exploration/Actions Mean                 0.286274
exploration/Actions Std                  0.569354
exploration/Actions Max                  0.999402
exploration/Actions Min                 -0.995088
exploration/Num Paths                   10
exploration/Average Returns          -1068.42
evaluation/num steps total          347328
evaluation/num paths total            1728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82482
evaluation/Rewards Std                   0.431979
evaluation/Rewards Max                  -3.1036
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1170.79
evaluation/Returns Std                  68.546
evaluation/Returns Max                -894.446
evaluation/Returns Min               -1220.41
evaluation/Actions Mean                  0.380918
evaluation/Actions Std                   0.220294
evaluation/Actions Max                   0.721575
evaluation/Actions Min                   0.157499
evaluation/Num Paths                    24
evaluation/Average Returns           -1170.79
time/data storing (s)                    0.0242404
time/evaluation sampling (s)            12.2615
time/exploration sampling (s)            5.08694
time/logging (s)                         0.0189139
time/sac training (s)                   10.6569
time/saving (s)                          0.0228906
time/training (s)                        0.000111879
time/epoch (s)                          28.0715
time/total (s)                        2257.14
Epoch                                   71
----------------------------------  ----------------
2020-11-09 14:00:03.293660 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 72 finished
----------------------------------  ----------------
replay_buffer/size                  148000
trainer/num train calls              73000
trainer/QF1 Loss                      1067.23
trainer/QF2 Loss                      1067.65
trainer/Policy Loss                    532.081
trainer/Q1 Predictions Mean           -532.219
trainer/Q1 Predictions Std              20.2695
trainer/Q1 Predictions Max            -428.855
trainer/Q1 Predictions Min            -569.059
trainer/Q2 Predictions Mean           -532.202
trainer/Q2 Predictions Std              20.2403
trainer/Q2 Predictions Max            -429.413
trainer/Q2 Predictions Min            -568.816
trainer/Q Targets Mean                -532.498
trainer/Q Targets Std                   38.915
trainer/Q Targets Max                   -5.16732
trainer/Q Targets Min                 -570.311
trainer/Log Pis Mean                    -1.30685
trainer/Log Pis Std                      0.338365
trainer/Log Pis Max                     -0.416643
trainer/Log Pis Min                     -2.31353
trainer/policy/mean Mean                 0.173975
trainer/policy/mean Std                  0.0517079
trainer/policy/mean Max                  0.281614
trainer/policy/mean Min                  0.0568743
trainer/policy/normal/std Mean           0.863586
trainer/policy/normal/std Std            0.0142758
trainer/policy/normal/std Max            0.888348
trainer/policy/normal/std Min            0.828696
trainer/policy/normal/log_std Mean      -0.146799
trainer/policy/normal/log_std Std        0.0165867
trainer/policy/normal/log_std Max       -0.118392
trainer/policy/normal/log_std Min       -0.187902
trainer/Alpha                            0.115951
trainer/Alpha Loss                      -7.12489
exploration/num steps total         148000
exploration/num paths total            740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.60615
exploration/Rewards Std                  0.432288
exploration/Rewards Max                 -4.16514
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1121.23
exploration/Returns Std                 60.2034
exploration/Returns Max              -1003.33
exploration/Returns Min              -1192.12
exploration/Actions Mean                 0.109857
exploration/Actions Std                  0.579028
exploration/Actions Max                  0.999406
exploration/Actions Min                 -0.995737
exploration/Num Paths                   10
exploration/Average Returns          -1121.23
evaluation/num steps total          352152
evaluation/num paths total            1752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05307
evaluation/Rewards Std                   0.106657
evaluation/Rewards Max                  -5.4667
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1216.67
evaluation/Returns Std                  14.3344
evaluation/Returns Max               -1162.26
evaluation/Returns Min               -1230.05
evaluation/Actions Mean                  0.176504
evaluation/Actions Std                   0.043894
evaluation/Actions Max                   0.240587
evaluation/Actions Min                   0.0773257
evaluation/Num Paths                    24
evaluation/Average Returns           -1216.67
time/data storing (s)                    0.0225976
time/evaluation sampling (s)            12.1833
time/exploration sampling (s)            5.12242
time/logging (s)                         0.0186925
time/sac training (s)                   13.8876
time/saving (s)                          0.0210104
time/training (s)                        0.000138644
time/epoch (s)                          31.2557
time/total (s)                        2289.54
Epoch                                   72
----------------------------------  ----------------
2020-11-09 14:00:38.118192 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 73 finished
----------------------------------  ---------------
replay_buffer/size                  150000
trainer/num train calls              74000
trainer/QF1 Loss                      1022.32
trainer/QF2 Loss                      1021.3
trainer/Policy Loss                    534.653
trainer/Q1 Predictions Mean           -534.78
trainer/Q1 Predictions Std              22.2205
trainer/Q1 Predictions Max            -424.213
trainer/Q1 Predictions Min            -582.67
trainer/Q2 Predictions Mean           -534.78
trainer/Q2 Predictions Std              22.2111
trainer/Q2 Predictions Max            -424.3
trainer/Q2 Predictions Min            -582.044
trainer/Q Targets Mean                -534.853
trainer/Q Targets Std                   40.0626
trainer/Q Targets Max                   -5.16091
trainer/Q Targets Min                 -582.208
trainer/Log Pis Mean                    -1.17302
trainer/Log Pis Std                      0.65355
trainer/Log Pis Max                      0.0872755
trainer/Log Pis Min                     -3.47775
trainer/policy/mean Mean                 0.26269
trainer/policy/mean Std                  0.238193
trainer/policy/mean Max                  0.692112
trainer/policy/mean Min                 -0.0486678
trainer/policy/normal/std Mean           0.838754
trainer/policy/normal/std Std            0.0450002
trainer/policy/normal/std Max            0.886942
trainer/policy/normal/std Min            0.753824
trainer/policy/normal/log_std Mean      -0.177287
trainer/policy/normal/log_std Std        0.0539377
trainer/policy/normal/log_std Max       -0.119976
trainer/policy/normal/log_std Min       -0.282597
trainer/Alpha                            0.112413
trainer/Alpha Loss                      -6.93486
exploration/num steps total         150000
exploration/num paths total            750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.37896
exploration/Rewards Std                  0.726152
exploration/Rewards Max                 -3.13138
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1075.79
exploration/Returns Std                108.362
exploration/Returns Max               -761.124
exploration/Returns Min              -1143.33
exploration/Actions Mean                 0.180575
exploration/Actions Std                  0.583626
exploration/Actions Max                  0.997212
exploration/Actions Min                 -0.995883
exploration/Num Paths                   10
exploration/Average Returns          -1075.79
evaluation/num steps total          356976
evaluation/num paths total            1776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82705
evaluation/Rewards Std                   0.384197
evaluation/Rewards Max                  -3.99592
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1171.24
evaluation/Returns Std                  61.2404
evaluation/Returns Max                -931.614
evaluation/Returns Min               -1218.74
evaluation/Actions Mean                  0.262666
evaluation/Actions Std                   0.241491
evaluation/Actions Max                   0.693677
evaluation/Actions Min                  -0.0489203
evaluation/Num Paths                    24
evaluation/Average Returns           -1171.24
time/data storing (s)                    0.0206835
time/evaluation sampling (s)            15.0229
time/exploration sampling (s)            6.10457
time/logging (s)                         0.0259099
time/sac training (s)                   11.4536
time/saving (s)                          0.021559
time/training (s)                        9.5553e-05
time/epoch (s)                          32.6493
time/total (s)                        2324.35
Epoch                                   73
----------------------------------  ---------------
2020-11-09 14:01:10.758390 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 74 finished
----------------------------------  ----------------
replay_buffer/size                  152000
trainer/num train calls              75000
trainer/QF1 Loss                      1109.65
trainer/QF2 Loss                      1108.53
trainer/Policy Loss                    536.783
trainer/Q1 Predictions Mean           -536.979
trainer/Q1 Predictions Std              24.1546
trainer/Q1 Predictions Max            -395.769
trainer/Q1 Predictions Min            -583.389
trainer/Q2 Predictions Mean           -536.976
trainer/Q2 Predictions Std              24.1618
trainer/Q2 Predictions Max            -395.913
trainer/Q2 Predictions Min            -584.203
trainer/Q Targets Mean                -536.91
trainer/Q Targets Std                   41.346
trainer/Q Targets Max                   -5.37898
trainer/Q Targets Min                 -583.751
trainer/Log Pis Mean                    -0.84587
trainer/Log Pis Std                      0.997193
trainer/Log Pis Max                      1.38968
trainer/Log Pis Min                     -3.9988
trainer/policy/mean Mean                 0.502457
trainer/policy/mean Std                  0.191043
trainer/policy/mean Max                  0.85025
trainer/policy/mean Min                  0.298113
trainer/policy/normal/std Mean           0.809022
trainer/policy/normal/std Std            0.0713712
trainer/policy/normal/std Max            0.887046
trainer/policy/normal/std Min            0.690934
trainer/policy/normal/log_std Mean      -0.215857
trainer/policy/normal/log_std Std        0.0888166
trainer/policy/normal/log_std Max       -0.119858
trainer/policy/normal/log_std Min       -0.369711
trainer/Alpha                            0.10937
trainer/Alpha Loss                      -6.29796
exploration/num steps total         152000
exploration/num paths total            760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.4841
exploration/Rewards Std                  0.821943
exploration/Rewards Max                 -3.13696
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1096.82
exploration/Returns Std                125.465
exploration/Returns Max               -839.576
exploration/Returns Min              -1198.46
exploration/Actions Mean                 0.383661
exploration/Actions Std                  0.525638
exploration/Actions Max                  0.998579
exploration/Actions Min                 -0.990626
exploration/Num Paths                   10
exploration/Average Returns          -1096.82
evaluation/num steps total          361800
evaluation/num paths total            1800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60166
evaluation/Rewards Std                   1.01148
evaluation/Rewards Max                  -1.09865
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1125.93
evaluation/Returns Std                 164.708
evaluation/Returns Max                -590.765
evaluation/Returns Min               -1211.86
evaluation/Actions Mean                  0.495907
evaluation/Actions Std                   0.187791
evaluation/Actions Max                   0.839904
evaluation/Actions Min                   0.305885
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.93
time/data storing (s)                    0.022108
time/evaluation sampling (s)            11.1846
time/exploration sampling (s)            4.47637
time/logging (s)                         0.020716
time/sac training (s)                   15.6159
time/saving (s)                          0.0235628
time/training (s)                        0.000133418
time/epoch (s)                          31.3434
time/total (s)                        2356.96
Epoch                                   74
----------------------------------  ----------------
2020-11-09 14:01:49.978431 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 75 finished
----------------------------------  ---------------
replay_buffer/size                  154000
trainer/num train calls              76000
trainer/QF1 Loss                         7.45808
trainer/QF2 Loss                         7.47862
trainer/Policy Loss                    538.462
trainer/Q1 Predictions Mean           -538.52
trainer/Q1 Predictions Std              19.0237
trainer/Q1 Predictions Max            -448.547
trainer/Q1 Predictions Min            -582.72
trainer/Q2 Predictions Mean           -538.512
trainer/Q2 Predictions Std              19.0599
trainer/Q2 Predictions Max            -448.516
trainer/Q2 Predictions Min            -582.933
trainer/Q Targets Mean                -540.99
trainer/Q Targets Std                   19.1681
trainer/Q Targets Max                 -449.592
trainer/Q Targets Min                 -584.861
trainer/Log Pis Mean                    -1.2519
trainer/Log Pis Std                      0.483811
trainer/Log Pis Max                     -0.0406389
trainer/Log Pis Min                     -2.73133
trainer/policy/mean Mean                 0.165008
trainer/policy/mean Std                  0.193522
trainer/policy/mean Max                  0.567795
trainer/policy/mean Min                 -0.144677
trainer/policy/normal/std Mean           0.879682
trainer/policy/normal/std Std            0.0103261
trainer/policy/normal/std Max            0.894611
trainer/policy/normal/std Min            0.857796
trainer/policy/normal/log_std Mean      -0.128264
trainer/policy/normal/log_std Std        0.0117495
trainer/policy/normal/log_std Max       -0.111366
trainer/policy/normal/log_std Min       -0.153389
trainer/Alpha                            0.106143
trainer/Alpha Loss                      -7.29391
exploration/num steps total         154000
exploration/num paths total            770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.44996
exploration/Rewards Std                  0.630338
exploration/Rewards Max                 -3.20883
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1089.99
exploration/Returns Std                 77.7802
exploration/Returns Max               -961.331
exploration/Returns Min              -1178.92
exploration/Actions Mean                 0.10073
exploration/Actions Std                  0.590618
exploration/Actions Max                  0.996983
exploration/Actions Min                 -0.997327
exploration/Num Paths                   10
exploration/Average Returns          -1089.99
evaluation/num steps total          366624
evaluation/num paths total            1824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.92798
evaluation/Rewards Std                   0.309142
evaluation/Rewards Max                  -3.62948
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1191.52
evaluation/Returns Std                  47.7484
evaluation/Returns Max               -1033.4
evaluation/Returns Min               -1225.87
evaluation/Actions Mean                  0.166137
evaluation/Actions Std                   0.198388
evaluation/Actions Max                   0.572318
evaluation/Actions Min                  -0.151869
evaluation/Num Paths                    24
evaluation/Average Returns           -1191.52
time/data storing (s)                    0.0208531
time/evaluation sampling (s)            12.1051
time/exploration sampling (s)            5.97188
time/logging (s)                         0.019565
time/sac training (s)                   19.5712
time/saving (s)                          0.0259094
time/training (s)                        0.00010381
time/epoch (s)                          37.7146
time/total (s)                        2396.15
Epoch                                   75
----------------------------------  ---------------
2020-11-09 14:02:20.798937 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 76 finished
----------------------------------  ----------------
replay_buffer/size                  156000
trainer/num train calls              77000
trainer/QF1 Loss                       722.594
trainer/QF2 Loss                       720.76
trainer/Policy Loss                    540.629
trainer/Q1 Predictions Mean           -540.67
trainer/Q1 Predictions Std              21.0912
trainer/Q1 Predictions Max            -396.413
trainer/Q1 Predictions Min            -581.305
trainer/Q2 Predictions Mean           -540.651
trainer/Q2 Predictions Std              21.0687
trainer/Q2 Predictions Max            -396.685
trainer/Q2 Predictions Min            -581
trainer/Q Targets Mean                -541.38
trainer/Q Targets Std                   39.4137
trainer/Q Targets Max                   -1.91222
trainer/Q Targets Min                 -582.707
trainer/Log Pis Mean                    -0.825093
trainer/Log Pis Std                      0.902598
trainer/Log Pis Max                      1.03865
trainer/Log Pis Min                     -4.61181
trainer/policy/mean Mean                 0.469487
trainer/policy/mean Std                  0.180743
trainer/policy/mean Max                  0.829027
trainer/policy/mean Min                  0.255333
trainer/policy/normal/std Mean           0.789609
trainer/policy/normal/std Std            0.058251
trainer/policy/normal/std Max            0.854768
trainer/policy/normal/std Min            0.683809
trainer/policy/normal/log_std Mean      -0.238962
trainer/policy/normal/log_std Std        0.0742407
trainer/policy/normal/log_std Max       -0.156925
trainer/policy/normal/log_std Min       -0.380076
trainer/Alpha                            0.102918
trainer/Alpha Loss                      -6.42376
exploration/num steps total         156000
exploration/num paths total            780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.8383
exploration/Rewards Std                  0.162207
exploration/Rewards Max                 -5.42333
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1167.66
exploration/Returns Std                 18.1265
exploration/Returns Max              -1134.46
exploration/Returns Min              -1188.59
exploration/Actions Mean                 0.322988
exploration/Actions Std                  0.532478
exploration/Actions Max                  0.996519
exploration/Actions Min                 -0.988217
exploration/Num Paths                   10
exploration/Average Returns          -1167.66
evaluation/num steps total          371448
evaluation/num paths total            1848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.63979
evaluation/Rewards Std                   0.874311
evaluation/Rewards Max                  -1.10423
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1133.6
evaluation/Returns Std                 153.019
evaluation/Returns Max                -528.31
evaluation/Returns Min               -1220.8
evaluation/Actions Mean                  0.473681
evaluation/Actions Std                   0.190084
evaluation/Actions Max                   0.823009
evaluation/Actions Min                   0.262046
evaluation/Num Paths                    24
evaluation/Average Returns           -1133.6
time/data storing (s)                    0.0219627
time/evaluation sampling (s)            13.0619
time/exploration sampling (s)            4.6154
time/logging (s)                         0.018816
time/sac training (s)                   11.9304
time/saving (s)                          0.0244104
time/training (s)                        0.000113811
time/epoch (s)                          29.6729
time/total (s)                        2426.95
Epoch                                   76
----------------------------------  ----------------
2020-11-09 14:02:56.032373 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 77 finished
----------------------------------  ----------------
replay_buffer/size                  158000
trainer/num train calls              78000
trainer/QF1 Loss                      1091.86
trainer/QF2 Loss                      1091.88
trainer/Policy Loss                    540.673
trainer/Q1 Predictions Mean           -540.823
trainer/Q1 Predictions Std              21.8077
trainer/Q1 Predictions Max            -413.181
trainer/Q1 Predictions Min            -578.039
trainer/Q2 Predictions Mean           -540.831
trainer/Q2 Predictions Std              21.815
trainer/Q2 Predictions Max            -412.485
trainer/Q2 Predictions Min            -577.487
trainer/Q Targets Mean                -541.655
trainer/Q Targets Std                   40.1419
trainer/Q Targets Max                   -5.59902
trainer/Q Targets Min                 -582.41
trainer/Log Pis Mean                    -0.292493
trainer/Log Pis Std                      1.3546
trainer/Log Pis Max                      2.30315
trainer/Log Pis Min                     -5.82835
trainer/policy/mean Mean                 0.677256
trainer/policy/mean Std                  0.0983558
trainer/policy/mean Max                  0.895914
trainer/policy/mean Min                  0.534823
trainer/policy/normal/std Mean           0.727606
trainer/policy/normal/std Std            0.0554622
trainer/policy/normal/std Max            0.802286
trainer/policy/normal/std Min            0.620358
trainer/policy/normal/log_std Mean      -0.320933
trainer/policy/normal/log_std Std        0.0768355
trainer/policy/normal/log_std Max       -0.22029
trainer/policy/normal/log_std Min       -0.477458
trainer/Alpha                            0.100295
trainer/Alpha Loss                      -5.27191
exploration/num steps total         158000
exploration/num paths total            790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.71288
exploration/Rewards Std                  0.697823
exploration/Rewards Max                 -3.19859
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1142.58
exploration/Returns Std                112.785
exploration/Returns Max               -808.787
exploration/Returns Min              -1201.67
exploration/Actions Mean                 0.543298
exploration/Actions Std                  0.431272
exploration/Actions Max                  0.99795
exploration/Actions Min                 -0.956977
exploration/Num Paths                   10
exploration/Average Returns          -1142.58
evaluation/num steps total          376272
evaluation/num paths total            1872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6155
evaluation/Rewards Std                   0.669194
evaluation/Rewards Max                  -2.90655
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1128.72
evaluation/Returns Std                 119.091
evaluation/Returns Max                -787.678
evaluation/Returns Min               -1204.36
evaluation/Actions Mean                  0.675622
evaluation/Actions Std                   0.100067
evaluation/Actions Max                   0.89647
evaluation/Actions Min                   0.563566
evaluation/Num Paths                    24
evaluation/Average Returns           -1128.72
time/data storing (s)                    0.0276151
time/evaluation sampling (s)            14.2467
time/exploration sampling (s)            5.42423
time/logging (s)                         0.017224
time/sac training (s)                   14.1452
time/saving (s)                          0.0228907
time/training (s)                        0.000113706
time/epoch (s)                          33.884
time/total (s)                        2462.15
Epoch                                   77
----------------------------------  ----------------
2020-11-09 14:03:24.600203 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 78 finished
----------------------------------  ---------------
replay_buffer/size                  160000
trainer/num train calls              79000
trainer/QF1 Loss                      1164.54
trainer/QF2 Loss                      1163.89
trainer/Policy Loss                    540.725
trainer/Q1 Predictions Mean           -540.984
trainer/Q1 Predictions Std              23.722
trainer/Q1 Predictions Max            -400.39
trainer/Q1 Predictions Min            -573.734
trainer/Q2 Predictions Mean           -541.007
trainer/Q2 Predictions Std              23.7207
trainer/Q2 Predictions Max            -400.561
trainer/Q2 Predictions Min            -573.884
trainer/Q Targets Mean                -541.32
trainer/Q Targets Std                   41.4392
trainer/Q Targets Max                   -5.31849
trainer/Q Targets Min                 -576.596
trainer/Log Pis Mean                    -0.459645
trainer/Log Pis Std                      1.05305
trainer/Log Pis Max                      1.44304
trainer/Log Pis Min                     -4.06234
trainer/policy/mean Mean                 0.504451
trainer/policy/mean Std                  0.293709
trainer/policy/mean Max                  0.918398
trainer/policy/mean Min                  0.149134
trainer/policy/normal/std Mean           0.803592
trainer/policy/normal/std Std            0.125754
trainer/policy/normal/std Max            0.957687
trainer/policy/normal/std Min            0.617658
trainer/policy/normal/log_std Mean      -0.231131
trainer/policy/normal/log_std Std        0.15849
trainer/policy/normal/log_std Max       -0.0432339
trainer/policy/normal/log_std Min       -0.481821
trainer/Alpha                            0.0974912
trainer/Alpha Loss                      -5.72604
exploration/num steps total         160000
exploration/num paths total            800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.43748
exploration/Rewards Std                  0.896394
exploration/Rewards Max                 -2.68396
exploration/Rewards Min                 -6.14191
exploration/Returns Mean             -1087.5
exploration/Returns Std                156.63
exploration/Returns Max               -638.299
exploration/Returns Min              -1181.84
exploration/Actions Mean                 0.410087
exploration/Actions Std                  0.564069
exploration/Actions Max                  0.999549
exploration/Actions Min                 -0.998177
exploration/Num Paths                   10
exploration/Average Returns          -1087.5
evaluation/num steps total          381096
evaluation/num paths total            1896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67892
evaluation/Rewards Std                   0.54332
evaluation/Rewards Max                  -4.00613
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1141.46
evaluation/Returns Std                  83.2252
evaluation/Returns Max                -882.904
evaluation/Returns Min               -1211.1
evaluation/Actions Mean                  0.5062
evaluation/Actions Std                   0.296638
evaluation/Actions Max                   0.913706
evaluation/Actions Min                   0.157499
evaluation/Num Paths                    24
evaluation/Average Returns           -1141.46
time/data storing (s)                    0.0233565
time/evaluation sampling (s)            10.9982
time/exploration sampling (s)            5.10843
time/logging (s)                         0.0169474
time/sac training (s)                   11.3577
time/saving (s)                          0.0186155
time/training (s)                        9.4157e-05
time/epoch (s)                          27.5233
time/total (s)                        2490.7
Epoch                                   78
----------------------------------  ---------------
2020-11-09 14:03:53.613986 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 79 finished
----------------------------------  ---------------
replay_buffer/size                  162000
trainer/num train calls              80000
trainer/QF1 Loss                        11.2475
trainer/QF2 Loss                        11.1252
trainer/Policy Loss                    542.371
trainer/Q1 Predictions Mean           -542.59
trainer/Q1 Predictions Std              22.8822
trainer/Q1 Predictions Max            -436.682
trainer/Q1 Predictions Min            -597.241
trainer/Q2 Predictions Mean           -542.61
trainer/Q2 Predictions Std              22.8607
trainer/Q2 Predictions Max            -436.495
trainer/Q2 Predictions Min            -596.71
trainer/Q Targets Mean                -545.313
trainer/Q Targets Std                   23.2608
trainer/Q Targets Max                 -436.269
trainer/Q Targets Min                 -599.668
trainer/Log Pis Mean                    -0.172361
trainer/Log Pis Std                      1.18197
trainer/Log Pis Max                      1.75479
trainer/Log Pis Min                     -6.50533
trainer/policy/mean Mean                 0.519078
trainer/policy/mean Std                  0.338039
trainer/policy/mean Max                  0.938429
trainer/policy/mean Min                  0.115256
trainer/policy/normal/std Mean           0.746345
trainer/policy/normal/std Std            0.113844
trainer/policy/normal/std Max            0.865222
trainer/policy/normal/std Min            0.576277
trainer/policy/normal/log_std Mean      -0.304412
trainer/policy/normal/log_std Std        0.154489
trainer/policy/normal/log_std Max       -0.144769
trainer/policy/normal/log_std Min       -0.551166
trainer/Alpha                            0.0949057
trainer/Alpha Loss                      -5.11563
exploration/num steps total         162000
exploration/num paths total            810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.25141
exploration/Rewards Std                  1.05016
exploration/Rewards Max                 -2.94919
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1050.28
exploration/Returns Std                195.212
exploration/Returns Max               -686.025
exploration/Returns Min              -1198.93
exploration/Actions Mean                 0.437937
exploration/Actions Std                  0.561
exploration/Actions Max                  0.997794
exploration/Actions Min                 -0.988701
exploration/Num Paths                   10
exploration/Average Returns          -1050.28
evaluation/num steps total          385920
evaluation/num paths total            1920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.64547
evaluation/Rewards Std                   0.685235
evaluation/Rewards Max                  -4.02584
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1134.74
evaluation/Returns Std                 117.644
evaluation/Returns Max                -866.085
evaluation/Returns Min               -1203.18
evaluation/Actions Mean                  0.519659
evaluation/Actions Std                   0.341595
evaluation/Actions Max                   0.929127
evaluation/Actions Min                   0.122745
evaluation/Num Paths                    24
evaluation/Average Returns           -1134.74
time/data storing (s)                    0.020891
time/evaluation sampling (s)            12.2524
time/exploration sampling (s)            5.09319
time/logging (s)                         0.0164418
time/sac training (s)                   10.5793
time/saving (s)                          0.018509
time/training (s)                        9.2385e-05
time/epoch (s)                          27.9808
time/total (s)                        2519.69
Epoch                                   79
----------------------------------  ---------------
2020-11-09 14:04:25.036504 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 80 finished
----------------------------------  ----------------
replay_buffer/size                  164000
trainer/num train calls              81000
trainer/QF1 Loss                         7.892
trainer/QF2 Loss                         7.98373
trainer/Policy Loss                    544.696
trainer/Q1 Predictions Mean           -544.772
trainer/Q1 Predictions Std              21.885
trainer/Q1 Predictions Max            -427.024
trainer/Q1 Predictions Min            -589.259
trainer/Q2 Predictions Mean           -544.758
trainer/Q2 Predictions Std              21.9139
trainer/Q2 Predictions Max            -427.23
trainer/Q2 Predictions Min            -589.756
trainer/Q Targets Mean                -546.799
trainer/Q Targets Std                   22.0096
trainer/Q Targets Max                 -428.004
trainer/Q Targets Min                 -589.707
trainer/Log Pis Mean                    -0.936817
trainer/Log Pis Std                      0.996994
trainer/Log Pis Max                      1.09248
trainer/Log Pis Min                     -4.4098
trainer/policy/mean Mean                 0.467277
trainer/policy/mean Std                  0.177668
trainer/policy/mean Max                  0.798958
trainer/policy/mean Min                  0.252148
trainer/policy/normal/std Mean           0.849561
trainer/policy/normal/std Std            0.0729072
trainer/policy/normal/std Max            0.93486
trainer/policy/normal/std Min            0.737736
trainer/policy/normal/log_std Mean      -0.166744
trainer/policy/normal/log_std Std        0.086255
trainer/policy/normal/log_std Max       -0.0673581
trainer/policy/normal/log_std Min       -0.30417
trainer/Alpha                            0.0920426
trainer/Alpha Loss                      -7.00579
exploration/num steps total         164000
exploration/num paths total            820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5817
exploration/Rewards Std                  0.579856
exploration/Rewards Max                 -3.41067
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1116.34
exploration/Returns Std                106.462
exploration/Returns Max               -818.911
exploration/Returns Min              -1186.39
exploration/Actions Mean                 0.339911
exploration/Actions Std                  0.554702
exploration/Actions Max                  0.999267
exploration/Actions Min                 -0.994858
exploration/Num Paths                   10
exploration/Average Returns          -1116.34
evaluation/num steps total          390744
evaluation/num paths total            1944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78539
evaluation/Rewards Std                   0.374768
evaluation/Rewards Max                  -4.46324
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1162.86
evaluation/Returns Std                  55.5006
evaluation/Returns Max               -1022.7
evaluation/Returns Min               -1215.92
evaluation/Actions Mean                  0.463685
evaluation/Actions Std                   0.177106
evaluation/Actions Max                   0.795412
evaluation/Actions Min                   0.267959
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.86
time/data storing (s)                    0.020913
time/evaluation sampling (s)            13.3405
time/exploration sampling (s)            6.1475
time/logging (s)                         0.0188749
time/sac training (s)                   10.806
time/saving (s)                          0.0202555
time/training (s)                        0.000108079
time/epoch (s)                          30.3542
time/total (s)                        2551.09
Epoch                                   80
----------------------------------  ----------------
2020-11-09 14:04:54.164832 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 81 finished
----------------------------------  ---------------
replay_buffer/size                  166000
trainer/num train calls              82000
trainer/QF1 Loss                      1165.45
trainer/QF2 Loss                      1165.52
trainer/Policy Loss                    544.772
trainer/Q1 Predictions Mean           -544.852
trainer/Q1 Predictions Std              20.9189
trainer/Q1 Predictions Max            -456.322
trainer/Q1 Predictions Min            -583.414
trainer/Q2 Predictions Mean           -544.856
trainer/Q2 Predictions Std              20.9148
trainer/Q2 Predictions Max            -456.508
trainer/Q2 Predictions Min            -583.389
trainer/Q Targets Mean                -544.969
trainer/Q Targets Std                   39.8882
trainer/Q Targets Max                   -5.56727
trainer/Q Targets Min                 -586.883
trainer/Log Pis Mean                    -0.364195
trainer/Log Pis Std                      1.1275
trainer/Log Pis Max                      1.71597
trainer/Log Pis Min                     -4.12162
trainer/policy/mean Mean                 0.424158
trainer/policy/mean Std                  0.410748
trainer/policy/mean Max                  0.941358
trainer/policy/mean Min                 -0.118347
trainer/policy/normal/std Mean           0.776827
trainer/policy/normal/std Std            0.107274
trainer/policy/normal/std Max            0.891221
trainer/policy/normal/std Min            0.598031
trainer/policy/normal/log_std Mean      -0.262229
trainer/policy/normal/log_std Std        0.139702
trainer/policy/normal/log_std Max       -0.115163
trainer/policy/normal/log_std Min       -0.514113
trainer/Alpha                            0.0895028
trainer/Alpha Loss                      -5.70595
exploration/num steps total         166000
exploration/num paths total            830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.72564
exploration/Rewards Std                  0.312833
exploration/Rewards Max                 -4.81738
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1145.13
exploration/Returns Std                 40.2206
exploration/Returns Max              -1073.75
exploration/Returns Min              -1189.16
exploration/Actions Mean                 0.359265
exploration/Actions Std                  0.590971
exploration/Actions Max                  0.998615
exploration/Actions Min                 -0.991033
exploration/Num Paths                   10
exploration/Average Returns          -1145.13
evaluation/num steps total          395568
evaluation/num paths total            1968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78568
evaluation/Rewards Std                   0.49427
evaluation/Rewards Max                  -4.02411
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1162.92
evaluation/Returns Std                  78.6473
evaluation/Returns Max                -849.026
evaluation/Returns Min               -1207.94
evaluation/Actions Mean                  0.425396
evaluation/Actions Std                   0.408556
evaluation/Actions Max                   0.91627
evaluation/Actions Min                  -0.0829327
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.92
time/data storing (s)                    0.0204787
time/evaluation sampling (s)            12.1635
time/exploration sampling (s)            5.08142
time/logging (s)                         0.0179809
time/sac training (s)                   10.7589
time/saving (s)                          0.0190147
time/training (s)                        0.00011074
time/epoch (s)                          28.0613
time/total (s)                        2580.2
Epoch                                   81
----------------------------------  ---------------
2020-11-09 14:05:23.502427 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 82 finished
----------------------------------  ---------------
replay_buffer/size                  168000
trainer/num train calls              83000
trainer/QF1 Loss                      1106.68
trainer/QF2 Loss                      1108.51
trainer/Policy Loss                    544.643
trainer/Q1 Predictions Mean           -544.644
trainer/Q1 Predictions Std              24.3681
trainer/Q1 Predictions Max            -428.176
trainer/Q1 Predictions Min            -580.161
trainer/Q2 Predictions Mean           -544.665
trainer/Q2 Predictions Std              24.346
trainer/Q2 Predictions Max            -428.022
trainer/Q2 Predictions Min            -579.811
trainer/Q Targets Mean                -545.206
trainer/Q Targets Std                   41.9503
trainer/Q Targets Max                   -5.34108
trainer/Q Targets Min                 -582.657
trainer/Log Pis Mean                    -0.21177
trainer/Log Pis Std                      1.29677
trainer/Log Pis Max                      2.4044
trainer/Log Pis Min                     -5.07039
trainer/policy/mean Mean                 0.679162
trainer/policy/mean Std                  0.137662
trainer/policy/mean Max                  0.917352
trainer/policy/mean Min                  0.513905
trainer/policy/normal/std Mean           0.747666
trainer/policy/normal/std Std            0.0714085
trainer/policy/normal/std Max            0.836194
trainer/policy/normal/std Min            0.624567
trainer/policy/normal/log_std Mean      -0.295407
trainer/policy/normal/log_std Std        0.0962179
trainer/policy/normal/log_std Max       -0.178895
trainer/policy/normal/log_std Min       -0.470696
trainer/Alpha                            0.0870471
trainer/Alpha Loss                      -5.39961
exploration/num steps total         168000
exploration/num paths total            840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.8004
exploration/Rewards Std                  0.30209
exploration/Rewards Max                 -4.53026
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1160.08
exploration/Returns Std                 58.2085
exploration/Returns Max               -990.996
exploration/Returns Min              -1204.85
exploration/Actions Mean                 0.541364
exploration/Actions Std                  0.456671
exploration/Actions Max                  0.998325
exploration/Actions Min                 -0.992713
exploration/Num Paths                   10
exploration/Average Returns          -1160.08
evaluation/num steps total          400392
evaluation/num paths total            1992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79256
evaluation/Rewards Std                   0.495152
evaluation/Rewards Max                  -4.00683
evaluation/Rewards Min                  -6.14166
evaluation/Returns Mean              -1164.31
evaluation/Returns Std                  90.7385
evaluation/Returns Max                -853.92
evaluation/Returns Min               -1208.02
evaluation/Actions Mean                  0.67471
evaluation/Actions Std                   0.131493
evaluation/Actions Max                   0.903584
evaluation/Actions Min                   0.539565
evaluation/Num Paths                    24
evaluation/Average Returns           -1164.31
time/data storing (s)                    0.0243881
time/evaluation sampling (s)            12.2823
time/exploration sampling (s)            5.08501
time/logging (s)                         0.0163512
time/sac training (s)                   10.824
time/saving (s)                          0.0185776
time/training (s)                        8.9886e-05
time/epoch (s)                          28.2507
time/total (s)                        2609.51
Epoch                                   82
----------------------------------  ---------------
2020-11-09 14:05:52.679648 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 83 finished
----------------------------------  ----------------
replay_buffer/size                  170000
trainer/num train calls              84000
trainer/QF1 Loss                      1807.79
trainer/QF2 Loss                      1803.8
trainer/Policy Loss                    547.357
trainer/Q1 Predictions Mean           -547.471
trainer/Q1 Predictions Std              22.4164
trainer/Q1 Predictions Max            -452.885
trainer/Q1 Predictions Min            -612.328
trainer/Q2 Predictions Mean           -547.451
trainer/Q2 Predictions Std              22.4127
trainer/Q2 Predictions Max            -453.083
trainer/Q2 Predictions Min            -612.75
trainer/Q Targets Mean                -546.199
trainer/Q Targets Std                   52.9207
trainer/Q Targets Max                   -3.10086
trainer/Q Targets Min                 -613.814
trainer/Log Pis Mean                    -0.0967298
trainer/Log Pis Std                      1.25097
trainer/Log Pis Max                      2.14756
trainer/Log Pis Min                     -4.87645
trainer/policy/mean Mean                 0.680363
trainer/policy/mean Std                  0.156523
trainer/policy/mean Max                  0.931025
trainer/policy/mean Min                  0.508875
trainer/policy/normal/std Mean           0.740173
trainer/policy/normal/std Std            0.10225
trainer/policy/normal/std Max            0.851027
trainer/policy/normal/std Min            0.581314
trainer/policy/normal/log_std Mean      -0.310587
trainer/policy/normal/log_std Std        0.139948
trainer/policy/normal/log_std Max       -0.161311
trainer/policy/normal/log_std Min       -0.542465
trainer/Alpha                            0.0842969
trainer/Alpha Loss                      -5.18607
exploration/num steps total         170000
exploration/num paths total            850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.91361
exploration/Rewards Std                  0.106954
exploration/Rewards Max                 -5.49666
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1182.72
exploration/Returns Std                 19.1962
exploration/Returns Max              -1135.08
exploration/Returns Min              -1206.4
exploration/Actions Mean                 0.52195
exploration/Actions Std                  0.466887
exploration/Actions Max                  0.998655
exploration/Actions Min                 -0.997961
exploration/Num Paths                   10
exploration/Average Returns          -1182.72
evaluation/num steps total          405216
evaluation/num paths total            2016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.58173
evaluation/Rewards Std                   0.707653
evaluation/Rewards Max                  -4.03627
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1121.93
evaluation/Returns Std                 128.077
evaluation/Returns Max                -853.007
evaluation/Returns Min               -1205.3
evaluation/Actions Mean                  0.687149
evaluation/Actions Std                   0.162821
evaluation/Actions Max                   0.930091
evaluation/Actions Min                   0.520342
evaluation/Num Paths                    24
evaluation/Average Returns           -1121.93
time/data storing (s)                    0.0235261
time/evaluation sampling (s)            12.2969
time/exploration sampling (s)            5.10087
time/logging (s)                         0.0191236
time/sac training (s)                   10.6632
time/saving (s)                          0.0218206
time/training (s)                        0.000121762
time/epoch (s)                          28.1256
time/total (s)                        2638.67
Epoch                                   83
----------------------------------  ----------------
2020-11-09 14:06:21.868378 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 84 finished
----------------------------------  ----------------
replay_buffer/size                  172000
trainer/num train calls              85000
trainer/QF1 Loss                      1137.98
trainer/QF2 Loss                      1139.31
trainer/Policy Loss                    550.531
trainer/Q1 Predictions Mean           -550.672
trainer/Q1 Predictions Std              19.2618
trainer/Q1 Predictions Max            -463.889
trainer/Q1 Predictions Min            -585.213
trainer/Q2 Predictions Mean           -550.671
trainer/Q2 Predictions Std              19.276
trainer/Q2 Predictions Max            -464.453
trainer/Q2 Predictions Min            -585.762
trainer/Q Targets Mean                -551.338
trainer/Q Targets Std                   39.4772
trainer/Q Targets Max                   -5.60128
trainer/Q Targets Min                 -588.413
trainer/Log Pis Mean                    -0.971116
trainer/Log Pis Std                      0.84706
trainer/Log Pis Max                      0.74765
trainer/Log Pis Min                     -4.11093
trainer/policy/mean Mean                 0.328643
trainer/policy/mean Std                  0.286748
trainer/policy/mean Max                  0.83494
trainer/policy/mean Min                 -0.122992
trainer/policy/normal/std Mean           0.832906
trainer/policy/normal/std Std            0.0646313
trainer/policy/normal/std Max            0.900631
trainer/policy/normal/std Min            0.704632
trainer/policy/normal/log_std Mean      -0.185889
trainer/policy/normal/log_std Std        0.0784364
trainer/policy/normal/log_std Max       -0.10466
trainer/policy/normal/log_std Min       -0.35008
trainer/Alpha                            0.0814745
trainer/Alpha Loss                      -7.44997
exploration/num steps total         172000
exploration/num paths total            860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.27064
exploration/Rewards Std                  0.89841
exploration/Rewards Max                 -2.6489
exploration/Rewards Min                 -6.1419
exploration/Returns Mean             -1054.13
exploration/Returns Std                104.907
exploration/Returns Max               -792.954
exploration/Returns Min              -1160.62
exploration/Actions Mean                 0.28606
exploration/Actions Std                  0.588709
exploration/Actions Max                  0.998546
exploration/Actions Min                 -0.994172
exploration/Num Paths                   10
exploration/Average Returns          -1054.13
evaluation/num steps total          410040
evaluation/num paths total            2040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.86188
evaluation/Rewards Std                   0.372844
evaluation/Rewards Max                  -4.2548
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1178.24
evaluation/Returns Std                  58.9653
evaluation/Returns Max                -948.996
evaluation/Returns Min               -1217.48
evaluation/Actions Mean                  0.327175
evaluation/Actions Std                   0.283561
evaluation/Actions Max                   0.832605
evaluation/Actions Min                  -0.118728
evaluation/Num Paths                    24
evaluation/Average Returns           -1178.24
time/data storing (s)                    0.0214144
time/evaluation sampling (s)            12.1831
time/exploration sampling (s)            5.09406
time/logging (s)                         0.0169972
time/sac training (s)                   10.7855
time/saving (s)                          0.0225685
time/training (s)                        0.000110126
time/epoch (s)                          28.1237
time/total (s)                        2667.84
Epoch                                   84
----------------------------------  ----------------
2020-11-09 14:06:50.857011 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 85 finished
----------------------------------  ----------------
replay_buffer/size                  174000
trainer/num train calls              86000
trainer/QF1 Loss                      4567.73
trainer/QF2 Loss                      4567.83
trainer/Policy Loss                    548.9
trainer/Q1 Predictions Mean           -549.108
trainer/Q1 Predictions Std              22.7762
trainer/Q1 Predictions Max            -448.018
trainer/Q1 Predictions Min            -595.517
trainer/Q2 Predictions Mean           -549.109
trainer/Q2 Predictions Std              22.7561
trainer/Q2 Predictions Max            -448.263
trainer/Q2 Predictions Min            -595.387
trainer/Q Targets Mean                -543.591
trainer/Q Targets Std                   71.5775
trainer/Q Targets Max                   -4.8137
trainer/Q Targets Min                 -596.789
trainer/Log Pis Mean                    -0.316695
trainer/Log Pis Std                      1.15912
trainer/Log Pis Max                      1.78616
trainer/Log Pis Min                     -4.6695
trainer/policy/mean Mean                 0.589502
trainer/policy/mean Std                  0.201953
trainer/policy/mean Max                  0.933558
trainer/policy/mean Min                  0.343461
trainer/policy/normal/std Mean           0.705489
trainer/policy/normal/std Std            0.0678698
trainer/policy/normal/std Max            0.807191
trainer/policy/normal/std Min            0.552455
trainer/policy/normal/log_std Mean      -0.353621
trainer/policy/normal/log_std Std        0.098237
trainer/policy/normal/log_std Max       -0.214195
trainer/policy/normal/log_std Min       -0.593383
trainer/Alpha                            0.0791504
trainer/Alpha Loss                      -5.87608
exploration/num steps total         174000
exploration/num paths total            870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.38593
exploration/Rewards Std                  1.01544
exploration/Rewards Max                 -2.38378
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1077.19
exploration/Returns Std                193.086
exploration/Returns Max               -673.353
exploration/Returns Min              -1198.94
exploration/Actions Mean                 0.495114
exploration/Actions Std                  0.475253
exploration/Actions Max                  0.998101
exploration/Actions Min                 -0.95733
exploration/Num Paths                   10
exploration/Average Returns          -1077.19
evaluation/num steps total          414864
evaluation/num paths total            2064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.65359
evaluation/Rewards Std                   0.648291
evaluation/Rewards Max                  -4.00083
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1136.37
evaluation/Returns Std                 116.573
evaluation/Returns Max                -862.831
evaluation/Returns Min               -1208.55
evaluation/Actions Mean                  0.591997
evaluation/Actions Std                   0.205058
evaluation/Actions Max                   0.929315
evaluation/Actions Min                   0.353012
evaluation/Num Paths                    24
evaluation/Average Returns           -1136.37
time/data storing (s)                    0.0235929
time/evaluation sampling (s)            12.1449
time/exploration sampling (s)            5.07165
time/logging (s)                         0.0171272
time/sac training (s)                   10.6512
time/saving (s)                          0.018244
time/training (s)                        0.000115505
time/epoch (s)                          27.9269
time/total (s)                        2696.8
Epoch                                   85
----------------------------------  ----------------
2020-11-09 14:07:21.283953 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 86 finished
----------------------------------  ---------------
replay_buffer/size                  176000
trainer/num train calls              87000
trainer/QF1 Loss                      1146.98
trainer/QF2 Loss                      1147.61
trainer/Policy Loss                    551.51
trainer/Q1 Predictions Mean           -551.546
trainer/Q1 Predictions Std              21.9709
trainer/Q1 Predictions Max            -453.798
trainer/Q1 Predictions Min            -628.386
trainer/Q2 Predictions Mean           -551.514
trainer/Q2 Predictions Std              21.9849
trainer/Q2 Predictions Max            -453.883
trainer/Q2 Predictions Min            -628.876
trainer/Q Targets Mean                -551.869
trainer/Q Targets Std                   40.7635
trainer/Q Targets Max                   -5.16732
trainer/Q Targets Min                 -628.945
trainer/Log Pis Mean                    -1.16798
trainer/Log Pis Std                      0.787738
trainer/Log Pis Max                      0.597056
trainer/Log Pis Min                     -4.4344
trainer/policy/mean Mean                 0.383326
trainer/policy/mean Std                  0.144908
trainer/policy/mean Max                  0.759402
trainer/policy/mean Min                  0.165439
trainer/policy/normal/std Mean           0.877821
trainer/policy/normal/std Std            0.0456459
trainer/policy/normal/std Max            0.94971
trainer/policy/normal/std Min            0.794205
trainer/policy/normal/log_std Mean      -0.131674
trainer/policy/normal/log_std Std        0.0522624
trainer/policy/normal/log_std Max       -0.051599
trainer/policy/normal/log_std Min       -0.230414
trainer/Alpha                            0.0770283
trainer/Alpha Loss                      -8.12137
exploration/num steps total         176000
exploration/num paths total            880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.55976
exploration/Rewards Std                  0.708611
exploration/Rewards Max                 -2.82724
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1111.95
exploration/Returns Std                120.296
exploration/Returns Max               -776.563
exploration/Returns Min              -1195.16
exploration/Actions Mean                 0.255389
exploration/Actions Std                  0.568445
exploration/Actions Max                  0.997704
exploration/Actions Min                 -0.994139
exploration/Num Paths                   10
exploration/Average Returns          -1111.95
evaluation/num steps total          419688
evaluation/num paths total            2088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81319
evaluation/Rewards Std                   0.559896
evaluation/Rewards Max                  -2.2931
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1168.45
evaluation/Returns Std                  80.714
evaluation/Returns Max                -813.236
evaluation/Returns Min               -1219.44
evaluation/Actions Mean                  0.382488
evaluation/Actions Std                   0.155649
evaluation/Actions Max                   0.755206
evaluation/Actions Min                   0.163202
evaluation/Num Paths                    24
evaluation/Average Returns           -1168.45
time/data storing (s)                    0.0220714
time/evaluation sampling (s)            12.3489
time/exploration sampling (s)            5.12487
time/logging (s)                         0.0176169
time/sac training (s)                   11.7246
time/saving (s)                          0.0225623
time/training (s)                        0.00011027
time/epoch (s)                          29.2607
time/total (s)                        2727.21
Epoch                                   86
----------------------------------  ---------------
2020-11-09 14:07:55.008520 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 87 finished
----------------------------------  ----------------
replay_buffer/size                  178000
trainer/num train calls              88000
trainer/QF1 Loss                      1267.96
trainer/QF2 Loss                      1268.29
trainer/Policy Loss                    552.017
trainer/Q1 Predictions Mean           -552.101
trainer/Q1 Predictions Std              26.0512
trainer/Q1 Predictions Max            -409.502
trainer/Q1 Predictions Min            -589.57
trainer/Q2 Predictions Mean           -552.108
trainer/Q2 Predictions Std              26.0202
trainer/Q2 Predictions Max            -409.751
trainer/Q2 Predictions Min            -589.554
trainer/Q Targets Mean                -552.198
trainer/Q Targets Std                   43.2631
trainer/Q Targets Max                   -5.63521
trainer/Q Targets Min                 -592.98
trainer/Log Pis Mean                    -0.463056
trainer/Log Pis Std                      1.13374
trainer/Log Pis Max                      2.03115
trainer/Log Pis Min                     -5.70459
trainer/policy/mean Mean                 0.559641
trainer/policy/mean Std                  0.218668
trainer/policy/mean Max                  0.940616
trainer/policy/mean Min                  0.267837
trainer/policy/normal/std Mean           0.758997
trainer/policy/normal/std Std            0.101274
trainer/policy/normal/std Max            0.864089
trainer/policy/normal/std Min            0.551621
trainer/policy/normal/log_std Mean      -0.285024
trainer/policy/normal/log_std Std        0.137506
trainer/policy/normal/log_std Max       -0.146079
trainer/policy/normal/log_std Min       -0.594894
trainer/Alpha                            0.074595
trainer/Alpha Loss                      -6.39331
exploration/num steps total         178000
exploration/num paths total            890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.71926
exploration/Rewards Std                  0.518332
exploration/Rewards Max                 -3.31127
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1143.85
exploration/Returns Std                 63.3798
exploration/Returns Max              -1006.04
exploration/Returns Min              -1196.56
exploration/Actions Mean                 0.436184
exploration/Actions Std                  0.515958
exploration/Actions Max                  0.998597
exploration/Actions Min                 -0.993205
exploration/Num Paths                   10
exploration/Average Returns          -1143.85
evaluation/num steps total          424512
evaluation/num paths total            2112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.75898
evaluation/Rewards Std                   0.493333
evaluation/Rewards Max                  -4.0383
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1157.56
evaluation/Returns Std                  88.7891
evaluation/Returns Max                -835.165
evaluation/Returns Min               -1216.83
evaluation/Actions Mean                  0.557482
evaluation/Actions Std                   0.209677
evaluation/Actions Max                   0.932682
evaluation/Actions Min                   0.284248
evaluation/Num Paths                    24
evaluation/Average Returns           -1157.56
time/data storing (s)                    0.0203728
time/evaluation sampling (s)            14.3664
time/exploration sampling (s)            5.90072
time/logging (s)                         0.0195104
time/sac training (s)                   12.2579
time/saving (s)                          0.02286
time/training (s)                        0.000118294
time/epoch (s)                          32.5879
time/total (s)                        2760.91
Epoch                                   87
----------------------------------  ----------------
2020-11-09 14:08:39.262801 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 88 finished
----------------------------------  ----------------
replay_buffer/size                  180000
trainer/num train calls              89000
trainer/QF1 Loss                      2349.85
trainer/QF2 Loss                      2351.85
trainer/Policy Loss                    552.41
trainer/Q1 Predictions Mean           -552.437
trainer/Q1 Predictions Std              23.284
trainer/Q1 Predictions Max            -458.046
trainer/Q1 Predictions Min            -627.174
trainer/Q2 Predictions Mean           -552.436
trainer/Q2 Predictions Std              23.2883
trainer/Q2 Predictions Max            -457.995
trainer/Q2 Predictions Min            -628.468
trainer/Q Targets Mean                -550.404
trainer/Q Targets Std                   53.9643
trainer/Q Targets Max                   -5.2262
trainer/Q Targets Min                 -629.848
trainer/Log Pis Mean                    -0.658533
trainer/Log Pis Std                      1.10445
trainer/Log Pis Max                      1.47238
trainer/Log Pis Min                     -3.93248
trainer/policy/mean Mean                 0.484632
trainer/policy/mean Std                  0.263606
trainer/policy/mean Max                  0.929485
trainer/policy/mean Min                  0.10098
trainer/policy/normal/std Mean           0.793637
trainer/policy/normal/std Std            0.09278
trainer/policy/normal/std Max            0.892868
trainer/policy/normal/std Min            0.60445
trainer/policy/normal/log_std Mean      -0.238185
trainer/policy/normal/log_std Std        0.119742
trainer/policy/normal/log_std Max       -0.113317
trainer/policy/normal/log_std Min       -0.503437
trainer/Alpha                            0.0724424
trainer/Alpha Loss                      -6.97855
exploration/num steps total         180000
exploration/num paths total            900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.47645
exploration/Rewards Std                  0.820293
exploration/Rewards Max                 -3.2915
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1095.29
exploration/Returns Std                132.956
exploration/Returns Max               -774.721
exploration/Returns Min              -1190.55
exploration/Actions Mean                 0.409699
exploration/Actions Std                  0.542453
exploration/Actions Max                  0.998466
exploration/Actions Min                 -0.992104
exploration/Num Paths                   10
exploration/Average Returns          -1095.29
evaluation/num steps total          429336
evaluation/num paths total            2136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.77579
evaluation/Rewards Std                   0.352693
evaluation/Rewards Max                  -4.04264
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1160.93
evaluation/Returns Std                  51.6781
evaluation/Returns Max                -984.135
evaluation/Returns Min               -1205.14
evaluation/Actions Mean                  0.481682
evaluation/Actions Std                   0.250919
evaluation/Actions Max                   0.920513
evaluation/Actions Min                   0.107017
evaluation/Num Paths                    24
evaluation/Average Returns           -1160.93
time/data storing (s)                    0.0236878
time/evaluation sampling (s)            23.8835
time/exploration sampling (s)            5.0487
time/logging (s)                         0.0387085
time/sac training (s)                   13.6252
time/saving (s)                          0.0247324
time/training (s)                        0.000145154
time/epoch (s)                          42.6446
time/total (s)                        2805.16
Epoch                                   88
----------------------------------  ----------------
2020-11-09 14:09:09.258197 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 89 finished
----------------------------------  ----------------
replay_buffer/size                  182000
trainer/num train calls              90000
trainer/QF1 Loss                      1168.42
trainer/QF2 Loss                      1166.36
trainer/Policy Loss                    553.227
trainer/Q1 Predictions Mean           -553.34
trainer/Q1 Predictions Std              23.5651
trainer/Q1 Predictions Max            -445.477
trainer/Q1 Predictions Min            -631.815
trainer/Q2 Predictions Mean           -553.366
trainer/Q2 Predictions Std              23.5459
trainer/Q2 Predictions Max            -445.922
trainer/Q2 Predictions Min            -633.326
trainer/Q Targets Mean                -554.089
trainer/Q Targets Std                   41.8476
trainer/Q Targets Max                   -4.7614
trainer/Q Targets Min                 -634.219
trainer/Log Pis Mean                    -0.86048
trainer/Log Pis Std                      1.00677
trainer/Log Pis Max                      1.81834
trainer/Log Pis Min                     -4.00454
trainer/policy/mean Mean                 0.116765
trainer/policy/mean Std                  0.530122
trainer/policy/mean Max                  0.875151
trainer/policy/mean Min                 -0.726677
trainer/policy/normal/std Mean           0.815013
trainer/policy/normal/std Std            0.0494604
trainer/policy/normal/std Max            0.885489
trainer/policy/normal/std Min            0.694827
trainer/policy/normal/log_std Mean      -0.206425
trainer/policy/normal/log_std Std        0.0615059
trainer/policy/normal/log_std Max       -0.121616
trainer/policy/normal/log_std Min       -0.364092
trainer/Alpha                            0.07031
trainer/Alpha Loss                      -7.59412
exploration/num steps total         182000
exploration/num paths total            910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.30211
exploration/Rewards Std                  0.874053
exploration/Rewards Max                 -3.0544
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1060.42
exploration/Returns Std                139.247
exploration/Returns Max               -705.725
exploration/Returns Min              -1175.64
exploration/Actions Mean                 0.0864935
exploration/Actions Std                  0.637457
exploration/Actions Max                  0.999081
exploration/Actions Min                 -0.99877
exploration/Num Paths                   10
exploration/Average Returns          -1060.42
evaluation/num steps total          434160
evaluation/num paths total            2160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81654
evaluation/Rewards Std                   0.407324
evaluation/Rewards Max                  -4.26128
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1169.12
evaluation/Returns Std                  70.359
evaluation/Returns Max                -934.1
evaluation/Returns Min               -1220.49
evaluation/Actions Mean                  0.119493
evaluation/Actions Std                   0.498759
evaluation/Actions Max                   0.863664
evaluation/Actions Min                  -0.709223
evaluation/Num Paths                    24
evaluation/Average Returns           -1169.12
time/data storing (s)                    0.019869
time/evaluation sampling (s)            12.1195
time/exploration sampling (s)            4.35551
time/logging (s)                         0.0207474
time/sac training (s)                   12.0849
time/saving (s)                          0.0256392
time/training (s)                        0.000152825
time/epoch (s)                          28.6263
time/total (s)                        2835.11
Epoch                                   89
----------------------------------  ----------------
2020-11-09 14:09:40.286949 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 90 finished
----------------------------------  ----------------
replay_buffer/size                  184000
trainer/num train calls              91000
trainer/QF1 Loss                      2437.24
trainer/QF2 Loss                      2438.5
trainer/Policy Loss                    555
trainer/Q1 Predictions Mean           -555.021
trainer/Q1 Predictions Std              23.7486
trainer/Q1 Predictions Max            -450.713
trainer/Q1 Predictions Min            -624.775
trainer/Q2 Predictions Mean           -555.046
trainer/Q2 Predictions Std              23.7411
trainer/Q2 Predictions Max            -451.425
trainer/Q2 Predictions Min            -625.248
trainer/Q Targets Mean                -553.156
trainer/Q Targets Std                   53.9082
trainer/Q Targets Max                   -4.16925
trainer/Q Targets Min                 -602.409
trainer/Log Pis Mean                    -0.699137
trainer/Log Pis Std                      0.928312
trainer/Log Pis Max                      1.83183
trainer/Log Pis Min                     -3.19038
trainer/policy/mean Mean                 0.32592
trainer/policy/mean Std                  0.386973
trainer/policy/mean Max                  0.917792
trainer/policy/mean Min                 -0.32382
trainer/policy/normal/std Mean           0.816541
trainer/policy/normal/std Std            0.116513
trainer/policy/normal/std Max            0.959036
trainer/policy/normal/std Min            0.589359
trainer/policy/normal/log_std Mean      -0.213249
trainer/policy/normal/log_std Std        0.146765
trainer/policy/normal/log_std Max       -0.0418263
trainer/policy/normal/log_std Min       -0.52872
trainer/Alpha                            0.0682831
trainer/Alpha Loss                      -7.24474
exploration/num steps total         184000
exploration/num paths total            920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.65405
exploration/Rewards Std                  0.427126
exploration/Rewards Max                 -3.21623
exploration/Rewards Min                 -6.14135
exploration/Returns Mean             -1130.81
exploration/Returns Std                 43.7925
exploration/Returns Max              -1040.53
exploration/Returns Min              -1195.86
exploration/Actions Mean                 0.257086
exploration/Actions Std                  0.594154
exploration/Actions Max                  0.998767
exploration/Actions Min                 -0.992456
exploration/Num Paths                   10
exploration/Average Returns          -1130.81
evaluation/num steps total          438984
evaluation/num paths total            2184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83547
evaluation/Rewards Std                   0.29259
evaluation/Rewards Max                  -3.97942
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1172.93
evaluation/Returns Std                  30.6364
evaluation/Returns Max               -1047.53
evaluation/Returns Min               -1215.62
evaluation/Actions Mean                  0.319905
evaluation/Actions Std                   0.31465
evaluation/Actions Max                   0.914555
evaluation/Actions Min                  -0.323793
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.93
time/data storing (s)                    0.0204037
time/evaluation sampling (s)            11.3339
time/exploration sampling (s)            4.40538
time/logging (s)                         0.0193307
time/sac training (s)                   13.9978
time/saving (s)                          0.02456
time/training (s)                        0.000124145
time/epoch (s)                          29.8015
time/total (s)                        2866.12
Epoch                                   90
----------------------------------  ----------------
2020-11-09 14:10:19.847752 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 91 finished
----------------------------------  ---------------
replay_buffer/size                  186000
trainer/num train calls              92000
trainer/QF1 Loss                      1245.58
trainer/QF2 Loss                      1245.21
trainer/Policy Loss                    557.142
trainer/Q1 Predictions Mean           -557.267
trainer/Q1 Predictions Std              23.5166
trainer/Q1 Predictions Max            -453.93
trainer/Q1 Predictions Min            -631.213
trainer/Q2 Predictions Mean           -557.274
trainer/Q2 Predictions Std              23.5301
trainer/Q2 Predictions Max            -454.083
trainer/Q2 Predictions Min            -632.519
trainer/Q Targets Mean                -557.448
trainer/Q Targets Std                   41.7239
trainer/Q Targets Max                   -5.77705
trainer/Q Targets Min                 -632.918
trainer/Log Pis Mean                    -0.407736
trainer/Log Pis Std                      1.16736
trainer/Log Pis Max                      1.80654
trainer/Log Pis Min                     -4.38365
trainer/policy/mean Mean                 0.547998
trainer/policy/mean Std                  0.250362
trainer/policy/mean Max                  0.963358
trainer/policy/mean Min                  0.129311
trainer/policy/normal/std Mean           0.736054
trainer/policy/normal/std Std            0.109531
trainer/policy/normal/std Max            0.846907
trainer/policy/normal/std Min            0.489684
trainer/policy/normal/log_std Mean      -0.318154
trainer/policy/normal/log_std Std        0.155144
trainer/policy/normal/log_std Max       -0.166165
trainer/policy/normal/log_std Min       -0.713995
trainer/Alpha                            0.0661931
trainer/Alpha Loss                      -6.53743
exploration/num steps total         186000
exploration/num paths total            930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.88534
exploration/Rewards Std                  0.150231
exploration/Rewards Max                 -5.29356
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1177.07
exploration/Returns Std                 24.9607
exploration/Returns Max              -1115.05
exploration/Returns Min              -1199.54
exploration/Actions Mean                 0.442952
exploration/Actions Std                  0.509728
exploration/Actions Max                  0.997142
exploration/Actions Min                 -0.989228
exploration/Num Paths                   10
exploration/Average Returns          -1177.07
evaluation/num steps total          443808
evaluation/num paths total            2208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.53348
evaluation/Rewards Std                   0.729649
evaluation/Rewards Max                  -3.38499
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1112.23
evaluation/Returns Std                 132.843
evaluation/Returns Max                -728.17
evaluation/Returns Min               -1202.06
evaluation/Actions Mean                  0.549682
evaluation/Actions Std                   0.277857
evaluation/Actions Max                   0.951429
evaluation/Actions Min                   0.129782
evaluation/Num Paths                    24
evaluation/Average Returns           -1112.23
time/data storing (s)                    0.0213198
time/evaluation sampling (s)            17.4496
time/exploration sampling (s)            4.58173
time/logging (s)                         0.0241578
time/sac training (s)                   16.1384
time/saving (s)                          0.0205987
time/training (s)                        9.6007e-05
time/epoch (s)                          38.2359
time/total (s)                        2905.66
Epoch                                   91
----------------------------------  ---------------
2020-11-09 14:10:48.860863 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 92 finished
----------------------------------  ----------------
replay_buffer/size                  188000
trainer/num train calls              93000
trainer/QF1 Loss                      1302.91
trainer/QF2 Loss                      1301.56
trainer/Policy Loss                    559.171
trainer/Q1 Predictions Mean           -559.201
trainer/Q1 Predictions Std              22.9799
trainer/Q1 Predictions Max            -426.612
trainer/Q1 Predictions Min            -604.305
trainer/Q2 Predictions Mean           -559.201
trainer/Q2 Predictions Std              22.9636
trainer/Q2 Predictions Max            -426.808
trainer/Q2 Predictions Min            -604.181
trainer/Q Targets Mean                -558.887
trainer/Q Targets Std                   41.9666
trainer/Q Targets Max                   -4.76245
trainer/Q Targets Min                 -605.187
trainer/Log Pis Mean                    -1.28663
trainer/Log Pis Std                      0.415691
trainer/Log Pis Max                      0.219286
trainer/Log Pis Min                     -2.56594
trainer/policy/mean Mean                 0.117121
trainer/policy/mean Std                  0.192302
trainer/policy/mean Max                  0.632339
trainer/policy/mean Min                 -0.377331
trainer/policy/normal/std Mean           0.898044
trainer/policy/normal/std Std            0.0165653
trainer/policy/normal/std Max            0.930291
trainer/policy/normal/std Min            0.873707
trainer/policy/normal/log_std Mean      -0.107705
trainer/policy/normal/log_std Std        0.0183446
trainer/policy/normal/log_std Max       -0.0722577
trainer/policy/normal/log_std Min       -0.13501
trainer/Alpha                            0.0642032
trainer/Alpha Loss                      -9.02412
exploration/num steps total         188000
exploration/num paths total            940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.46726
exploration/Rewards Std                  0.743555
exploration/Rewards Max                 -2.21888
exploration/Rewards Min                 -6.14183
exploration/Returns Mean             -1093.45
exploration/Returns Std                100.121
exploration/Returns Max               -829.468
exploration/Returns Min              -1179.19
exploration/Actions Mean                 0.0660981
exploration/Actions Std                  0.609898
exploration/Actions Max                  0.998773
exploration/Actions Min                 -0.998541
exploration/Num Paths                   10
exploration/Average Returns          -1093.45
evaluation/num steps total          448632
evaluation/num paths total            2232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96081
evaluation/Rewards Std                   0.262449
evaluation/Rewards Max                  -4.15222
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1198.12
evaluation/Returns Std                  38.1054
evaluation/Returns Max               -1047.03
evaluation/Returns Min               -1226.52
evaluation/Actions Mean                  0.117162
evaluation/Actions Std                   0.198074
evaluation/Actions Max                   0.688776
evaluation/Actions Min                  -0.437748
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.12
time/data storing (s)                    0.020123
time/evaluation sampling (s)            10.9249
time/exploration sampling (s)            4.88499
time/logging (s)                         0.0224516
time/sac training (s)                   11.9238
time/saving (s)                          0.024248
time/training (s)                        0.000122257
time/epoch (s)                          27.8007
time/total (s)                        2934.65
Epoch                                   92
----------------------------------  ----------------
2020-11-09 14:11:20.955003 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 93 finished
----------------------------------  ----------------
replay_buffer/size                  190000
trainer/num train calls              94000
trainer/QF1 Loss                      2547.44
trainer/QF2 Loss                      2546.99
trainer/Policy Loss                    558.199
trainer/Q1 Predictions Mean           -558.237
trainer/Q1 Predictions Std              25.7515
trainer/Q1 Predictions Max            -447.038
trainer/Q1 Predictions Min            -638.761
trainer/Q2 Predictions Mean           -558.259
trainer/Q2 Predictions Std              25.7183
trainer/Q2 Predictions Max            -447.436
trainer/Q2 Predictions Min            -639.363
trainer/Q Targets Mean                -556.489
trainer/Q Targets Std                   55.2943
trainer/Q Targets Max                   -5.66307
trainer/Q Targets Min                 -640.624
trainer/Log Pis Mean                    -0.723893
trainer/Log Pis Std                      1.15186
trainer/Log Pis Max                      2.70925
trainer/Log Pis Min                     -4.92324
trainer/policy/mean Mean                 0.158237
trainer/policy/mean Std                  0.511782
trainer/policy/mean Max                  0.936914
trainer/policy/mean Min                 -0.711686
trainer/policy/normal/std Mean           0.825739
trainer/policy/normal/std Std            0.107249
trainer/policy/normal/std Max            0.96012
trainer/policy/normal/std Min            0.573915
trainer/policy/normal/log_std Mean      -0.200458
trainer/policy/normal/log_std Std        0.136226
trainer/policy/normal/log_std Max       -0.0406966
trainer/policy/normal/log_std Min       -0.555274
trainer/Alpha                            0.0624443
trainer/Alpha Loss                      -7.55466
exploration/num steps total         190000
exploration/num paths total            950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.34829
exploration/Rewards Std                  0.768383
exploration/Rewards Max                 -3.1238
exploration/Rewards Min                 -6.14169
exploration/Returns Mean             -1069.66
exploration/Returns Std                109.866
exploration/Returns Max               -749.588
exploration/Returns Min              -1155.19
exploration/Actions Mean                 0.152892
exploration/Actions Std                  0.641418
exploration/Actions Max                  0.998908
exploration/Actions Min                 -0.999096
exploration/Num Paths                   10
exploration/Average Returns          -1069.66
evaluation/num steps total          453456
evaluation/num paths total            2256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59251
evaluation/Rewards Std                   0.643062
evaluation/Rewards Max                  -3.29274
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1124.09
evaluation/Returns Std                  97.3449
evaluation/Returns Max                -842.398
evaluation/Returns Min               -1208.33
evaluation/Actions Mean                  0.152134
evaluation/Actions Std                   0.560152
evaluation/Actions Max                   0.944536
evaluation/Actions Min                  -0.731084
evaluation/Num Paths                    24
evaluation/Average Returns           -1124.09
time/data storing (s)                    0.0229872
time/evaluation sampling (s)            13.2028
time/exploration sampling (s)            4.75249
time/logging (s)                         0.0181608
time/sac training (s)                   12.7802
time/saving (s)                          0.0196961
time/training (s)                        0.000113938
time/epoch (s)                          30.7965
time/total (s)                        2966.71
Epoch                                   93
----------------------------------  ----------------
2020-11-09 14:11:50.783453 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 94 finished
----------------------------------  ----------------
replay_buffer/size                  192000
trainer/num train calls              95000
trainer/QF1 Loss                      1184.36
trainer/QF2 Loss                      1183.9
trainer/Policy Loss                    560.724
trainer/Q1 Predictions Mean           -560.792
trainer/Q1 Predictions Std              23.0499
trainer/Q1 Predictions Max            -430.665
trainer/Q1 Predictions Min            -625.169
trainer/Q2 Predictions Mean           -560.781
trainer/Q2 Predictions Std              23.0592
trainer/Q2 Predictions Max            -430.32
trainer/Q2 Predictions Min            -625.661
trainer/Q Targets Mean                -561.545
trainer/Q Targets Std                   41.7737
trainer/Q Targets Max                   -5.37594
trainer/Q Targets Min                 -627.509
trainer/Log Pis Mean                     0.746752
trainer/Log Pis Std                      1.75323
trainer/Log Pis Max                      5.26072
trainer/Log Pis Min                     -4.00616
trainer/policy/mean Mean                -0.0160739
trainer/policy/mean Std                  0.809286
trainer/policy/mean Max                  0.952198
trainer/policy/mean Min                 -0.966609
trainer/policy/normal/std Mean           0.652818
trainer/policy/normal/std Std            0.0726895
trainer/policy/normal/std Max            0.800983
trainer/policy/normal/std Min            0.471496
trainer/policy/normal/log_std Mean      -0.432824
trainer/policy/normal/log_std Std        0.113695
trainer/policy/normal/log_std Max       -0.221916
trainer/policy/normal/log_std Min       -0.751845
trainer/Alpha                            0.0610024
trainer/Alpha Loss                      -3.50514
exploration/num steps total         192000
exploration/num paths total            960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.25341
exploration/Rewards Std                  0.656754
exploration/Rewards Max                 -3.256
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1050.68
exploration/Returns Std                 79.5073
exploration/Returns Max               -876.487
exploration/Returns Min              -1158.55
exploration/Actions Mean                -0.0375928
exploration/Actions Std                  0.735635
exploration/Actions Max                  0.999285
exploration/Actions Min                 -0.995069
exploration/Num Paths                   10
exploration/Average Returns          -1050.68
evaluation/num steps total          458280
evaluation/num paths total            2280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8394
evaluation/Rewards Std                   0.30262
evaluation/Rewards Max                  -4.59332
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1173.72
evaluation/Returns Std                  56.9489
evaluation/Returns Max                -951.793
evaluation/Returns Min               -1211.24
evaluation/Actions Mean                 -0.0160421
evaluation/Actions Std                   0.826999
evaluation/Actions Max                   0.939406
evaluation/Actions Min                  -0.956167
evaluation/Num Paths                    24
evaluation/Average Returns           -1173.72
time/data storing (s)                    0.0201147
time/evaluation sampling (s)            11.0566
time/exploration sampling (s)            5.47448
time/logging (s)                         0.0166526
time/sac training (s)                   12.0771
time/saving (s)                          0.0214866
time/training (s)                        0.000109214
time/epoch (s)                          28.6665
time/total (s)                        2996.52
Epoch                                   94
----------------------------------  ----------------
2020-11-09 14:12:20.636838 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 95 finished
----------------------------------  ----------------
replay_buffer/size                  194000
trainer/num train calls              96000
trainer/QF1 Loss                        12.2418
trainer/QF2 Loss                        12.2802
trainer/Policy Loss                    562.829
trainer/Q1 Predictions Mean           -562.903
trainer/Q1 Predictions Std              19.4177
trainer/Q1 Predictions Max            -463.18
trainer/Q1 Predictions Min            -611.251
trainer/Q2 Predictions Mean           -562.919
trainer/Q2 Predictions Std              19.4456
trainer/Q2 Predictions Max            -462.31
trainer/Q2 Predictions Min            -611.282
trainer/Q Targets Mean                -565.469
trainer/Q Targets Std                   19.8354
trainer/Q Targets Max                 -464.259
trainer/Q Targets Min                 -617.559
trainer/Log Pis Mean                    -0.947031
trainer/Log Pis Std                      0.884001
trainer/Log Pis Max                      2.33363
trainer/Log Pis Min                     -3.3384
trainer/policy/mean Mean                 0.0274136
trainer/policy/mean Std                  0.44832
trainer/policy/mean Max                  0.847039
trainer/policy/mean Min                 -0.805672
trainer/policy/normal/std Mean           0.822426
trainer/policy/normal/std Std            0.0389928
trainer/policy/normal/std Max            0.907977
trainer/policy/normal/std Min            0.676771
trainer/policy/normal/log_std Mean      -0.196668
trainer/policy/normal/log_std Std        0.0489047
trainer/policy/normal/log_std Max       -0.0965359
trainer/policy/normal/log_std Min       -0.390422
trainer/Alpha                            0.0589358
trainer/Alpha Loss                      -8.34395
exploration/num steps total         194000
exploration/num paths total            970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.26076
exploration/Rewards Std                  0.624527
exploration/Rewards Max                 -3.13543
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1052.15
exploration/Returns Std                 79.2096
exploration/Returns Max               -890.513
exploration/Returns Min              -1119.59
exploration/Actions Mean                 0.0305897
exploration/Actions Std                  0.62641
exploration/Actions Max                  0.995907
exploration/Actions Min                 -0.99842
exploration/Num Paths                   10
exploration/Average Returns          -1052.15
evaluation/num steps total          463104
evaluation/num paths total            2304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84599
evaluation/Rewards Std                   0.433791
evaluation/Rewards Max                  -3.55905
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1175.04
evaluation/Returns Std                  60.5612
evaluation/Returns Max                -985.197
evaluation/Returns Min               -1218.12
evaluation/Actions Mean                  0.0276064
evaluation/Actions Std                   0.49069
evaluation/Actions Max                   0.857764
evaluation/Actions Min                  -0.817815
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.04
time/data storing (s)                    0.0200545
time/evaluation sampling (s)            11.4772
time/exploration sampling (s)            4.80026
time/logging (s)                         0.020786
time/sac training (s)                   12.3315
time/saving (s)                          0.0229583
time/training (s)                        0.000137432
time/epoch (s)                          28.6729
time/total (s)                        3026.35
Epoch                                   95
----------------------------------  ----------------
2020-11-09 14:12:49.509216 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 96 finished
----------------------------------  ----------------
replay_buffer/size                  196000
trainer/num train calls              97000
trainer/QF1 Loss                         9.92915
trainer/QF2 Loss                        10.0241
trainer/Policy Loss                    559.865
trainer/Q1 Predictions Mean           -559.995
trainer/Q1 Predictions Std              27.9528
trainer/Q1 Predictions Max            -399.519
trainer/Q1 Predictions Min            -640.878
trainer/Q2 Predictions Mean           -559.99
trainer/Q2 Predictions Std              27.9794
trainer/Q2 Predictions Max            -399.739
trainer/Q2 Predictions Min            -642.439
trainer/Q Targets Mean                -562.427
trainer/Q Targets Std                   28.3565
trainer/Q Targets Max                 -398.679
trainer/Q Targets Min                 -643.491
trainer/Log Pis Mean                    -0.16381
trainer/Log Pis Std                      1.32453
trainer/Log Pis Max                      3.33684
trainer/Log Pis Min                     -5.88848
trainer/policy/mean Mean                 0.187807
trainer/policy/mean Std                  0.603299
trainer/policy/mean Max                  0.978056
trainer/policy/mean Min                 -0.792297
trainer/policy/normal/std Mean           0.727064
trainer/policy/normal/std Std            0.110977
trainer/policy/normal/std Max            0.86114
trainer/policy/normal/std Min            0.436162
trainer/policy/normal/log_std Mean      -0.331437
trainer/policy/normal/log_std Std        0.162948
trainer/policy/normal/log_std Max       -0.149498
trainer/policy/normal/log_std Min       -0.829742
trainer/Alpha                            0.0571569
trainer/Alpha Loss                      -6.19273
exploration/num steps total         196000
exploration/num paths total            980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.40828
exploration/Rewards Std                  0.697565
exploration/Rewards Max                 -3.54635
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1081.66
exploration/Returns Std                108.801
exploration/Returns Max               -866.865
exploration/Returns Min              -1157.17
exploration/Actions Mean                 0.186842
exploration/Actions Std                  0.664002
exploration/Actions Max                  0.998405
exploration/Actions Min                 -0.997215
exploration/Num Paths                   10
exploration/Average Returns          -1081.66
evaluation/num steps total          467928
evaluation/num paths total            2328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7869
evaluation/Rewards Std                   0.461519
evaluation/Rewards Max                  -3.34131
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1163.17
evaluation/Returns Std                  74.4569
evaluation/Returns Max                -824.047
evaluation/Returns Min               -1204.93
evaluation/Actions Mean                  0.194864
evaluation/Actions Std                   0.581174
evaluation/Actions Max                   0.963515
evaluation/Actions Min                  -0.735955
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.17
time/data storing (s)                    0.0227667
time/evaluation sampling (s)            10.8111
time/exploration sampling (s)            4.69104
time/logging (s)                         0.0223984
time/sac training (s)                   12.1047
time/saving (s)                          0.0262631
time/training (s)                        0.000143918
time/epoch (s)                          27.6784
time/total (s)                        3055.2
Epoch                                   96
----------------------------------  ----------------
2020-11-09 14:13:20.003594 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 97 finished
----------------------------------  ---------------
replay_buffer/size                  198000
trainer/num train calls              98000
trainer/QF1 Loss                        14.3039
trainer/QF2 Loss                        14.3975
trainer/Policy Loss                    563.709
trainer/Q1 Predictions Mean           -563.82
trainer/Q1 Predictions Std              22.3181
trainer/Q1 Predictions Max            -443.18
trainer/Q1 Predictions Min            -615.922
trainer/Q2 Predictions Mean           -563.805
trainer/Q2 Predictions Std              22.2971
trainer/Q2 Predictions Max            -442.975
trainer/Q2 Predictions Min            -615.999
trainer/Q Targets Mean                -565.887
trainer/Q Targets Std                   23.5331
trainer/Q Targets Max                 -443.631
trainer/Q Targets Min                 -617.734
trainer/Log Pis Mean                     0.292869
trainer/Log Pis Std                      1.24627
trainer/Log Pis Max                      2.88863
trainer/Log Pis Min                     -5.27294
trainer/policy/mean Mean                 0.482033
trainer/policy/mean Std                  0.403941
trainer/policy/mean Max                  0.982497
trainer/policy/mean Min                 -0.156422
trainer/policy/normal/std Mean           0.745062
trainer/policy/normal/std Std            0.153395
trainer/policy/normal/std Max            0.907478
trainer/policy/normal/std Min            0.462702
trainer/policy/normal/log_std Mean      -0.31675
trainer/policy/normal/log_std Std        0.214953
trainer/policy/normal/log_std Max       -0.0970862
trainer/policy/normal/log_std Min       -0.770671
trainer/Alpha                            0.0558641
trainer/Alpha Loss                      -4.92479
exploration/num steps total         198000
exploration/num paths total            990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.78894
exploration/Rewards Std                  0.303682
exploration/Rewards Max                 -4.52008
exploration/Rewards Min                 -6.14176
exploration/Returns Mean             -1157.79
exploration/Returns Std                 39.6894
exploration/Returns Max              -1067.49
exploration/Returns Min              -1193.69
exploration/Actions Mean                 0.43032
exploration/Actions Std                  0.590289
exploration/Actions Max                  0.998164
exploration/Actions Min                 -0.98912
exploration/Num Paths                   10
exploration/Average Returns          -1157.79
evaluation/num steps total          472752
evaluation/num paths total            2352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.68947
evaluation/Rewards Std                   0.828038
evaluation/Rewards Max                  -3.36963
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1143.58
evaluation/Returns Std                 159.339
evaluation/Returns Max                -696.76
evaluation/Returns Min               -1215.14
evaluation/Actions Mean                  0.486154
evaluation/Actions Std                   0.413904
evaluation/Actions Max                   0.969802
evaluation/Actions Min                  -0.130472
evaluation/Num Paths                    24
evaluation/Average Returns           -1143.58
time/data storing (s)                    0.022093
time/evaluation sampling (s)            12.6675
time/exploration sampling (s)            4.88508
time/logging (s)                         0.020326
time/sac training (s)                   11.7399
time/saving (s)                          0.0288971
time/training (s)                        9.7361e-05
time/epoch (s)                          29.3639
time/total (s)                        3085.67
Epoch                                   97
----------------------------------  ---------------
2020-11-09 14:13:47.702467 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 98 finished
----------------------------------  ---------------
replay_buffer/size                  200000
trainer/num train calls              99000
trainer/QF1 Loss                       991.616
trainer/QF2 Loss                       991.369
trainer/Policy Loss                    563.964
trainer/Q1 Predictions Mean           -564.131
trainer/Q1 Predictions Std              22.7475
trainer/Q1 Predictions Max            -453.236
trainer/Q1 Predictions Min            -611.735
trainer/Q2 Predictions Mean           -564.136
trainer/Q2 Predictions Std              22.7174
trainer/Q2 Predictions Max            -453.326
trainer/Q2 Predictions Min            -611.043
trainer/Q Targets Mean                -564.991
trainer/Q Targets Std                   41.8224
trainer/Q Targets Max                   -4.23124
trainer/Q Targets Min                 -612.828
trainer/Log Pis Mean                     0.768275
trainer/Log Pis Std                      1.3579
trainer/Log Pis Max                      3.31155
trainer/Log Pis Min                     -3.97874
trainer/policy/mean Mean                 0.598722
trainer/policy/mean Std                  0.342782
trainer/policy/mean Max                  0.98959
trainer/policy/mean Min                  0.0629134
trainer/policy/normal/std Mean           0.709193
trainer/policy/normal/std Std            0.145765
trainer/policy/normal/std Max            0.864145
trainer/policy/normal/std Min            0.458247
trainer/policy/normal/log_std Mean      -0.36558
trainer/policy/normal/log_std Std        0.211315
trainer/policy/normal/log_std Max       -0.146015
trainer/policy/normal/log_std Min       -0.780346
trainer/Alpha                            0.0547403
trainer/Alpha Loss                      -3.57835
exploration/num steps total         200000
exploration/num paths total           1000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.87506
exploration/Rewards Std                  0.160046
exploration/Rewards Max                 -5.10567
exploration/Rewards Min                 -6.14124
exploration/Returns Mean             -1175.01
exploration/Returns Std                 27.3974
exploration/Returns Max              -1103.58
exploration/Returns Min              -1203.93
exploration/Actions Mean                 0.533473
exploration/Actions Std                  0.552804
exploration/Actions Max                  0.998441
exploration/Actions Min                 -0.99016
exploration/Num Paths                   10
exploration/Average Returns          -1175.01
evaluation/num steps total          477576
evaluation/num paths total            2376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.53807
evaluation/Rewards Std                   1.06662
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1113.15
evaluation/Returns Std                 210.813
evaluation/Returns Max                -690.445
evaluation/Returns Min               -1221.93
evaluation/Actions Mean                  0.590892
evaluation/Actions Std                   0.361306
evaluation/Actions Max                   0.97203
evaluation/Actions Min                   0.0866718
evaluation/Num Paths                    24
evaluation/Average Returns           -1113.15
time/data storing (s)                    0.0207767
time/evaluation sampling (s)            10.69
time/exploration sampling (s)            4.23855
time/logging (s)                         0.0168169
time/sac training (s)                   11.5702
time/saving (s)                          0.0209035
time/training (s)                        9.8018e-05
time/epoch (s)                          26.5574
time/total (s)                        3113.34
Epoch                                   98
----------------------------------  ---------------
2020-11-09 14:14:18.104651 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 99 finished
----------------------------------  ----------------
replay_buffer/size                  202000
trainer/num train calls             100000
trainer/QF1 Loss                      3290.21
trainer/QF2 Loss                      3294.86
trainer/Policy Loss                    562.067
trainer/Q1 Predictions Mean           -562.116
trainer/Q1 Predictions Std              24.2397
trainer/Q1 Predictions Max            -430.39
trainer/Q1 Predictions Min            -610.545
trainer/Q2 Predictions Mean           -562.132
trainer/Q2 Predictions Std              24.2091
trainer/Q2 Predictions Max            -430.497
trainer/Q2 Predictions Min            -610.264
trainer/Q Targets Mean                -558.871
trainer/Q Targets Std                   65.0166
trainer/Q Targets Max                   -3.23354
trainer/Q Targets Min                 -612.749
trainer/Log Pis Mean                    -0.483112
trainer/Log Pis Std                      1.20745
trainer/Log Pis Max                      1.9678
trainer/Log Pis Min                     -4.14789
trainer/policy/mean Mean                 0.657952
trainer/policy/mean Std                  0.0865936
trainer/policy/mean Max                  0.915443
trainer/policy/mean Min                  0.416096
trainer/policy/normal/std Mean           0.760362
trainer/policy/normal/std Std            0.0240102
trainer/policy/normal/std Max            0.822646
trainer/policy/normal/std Min            0.681969
trainer/policy/normal/log_std Mean      -0.274456
trainer/policy/normal/log_std Std        0.03143
trainer/policy/normal/log_std Max       -0.195229
trainer/policy/normal/log_std Min       -0.382771
trainer/Alpha                            0.0531487
trainer/Alpha Loss                      -7.28709
exploration/num steps total         202000
exploration/num paths total           1010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.63876
exploration/Rewards Std                  0.715088
exploration/Rewards Max                 -3.19124
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1127.75
exploration/Returns Std                118.801
exploration/Returns Max               -783.3
exploration/Returns Min              -1208.05
exploration/Actions Mean                 0.532815
exploration/Actions Std                  0.439821
exploration/Actions Max                  0.998979
exploration/Actions Min                 -0.969738
exploration/Num Paths                   10
exploration/Average Returns          -1127.75
evaluation/num steps total          482400
evaluation/num paths total            2400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81721
evaluation/Rewards Std                   0.331143
evaluation/Rewards Max                  -4.30663
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1169.26
evaluation/Returns Std                  55.1087
evaluation/Returns Max                -938.267
evaluation/Returns Min               -1214.43
evaluation/Actions Mean                  0.647278
evaluation/Actions Std                   0.0813614
evaluation/Actions Max                   0.883276
evaluation/Actions Min                   0.45881
evaluation/Num Paths                    24
evaluation/Average Returns           -1169.26
time/data storing (s)                    0.0210184
time/evaluation sampling (s)            10.6451
time/exploration sampling (s)            5.08631
time/logging (s)                         0.0194022
time/sac training (s)                   13.3648
time/saving (s)                          0.025058
time/training (s)                        0.000122856
time/epoch (s)                          29.1619
time/total (s)                        3143.72
Epoch                                   99
----------------------------------  ----------------
2020-11-09 14:14:47.515709 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 100 finished
----------------------------------  ----------------
replay_buffer/size                  204000
trainer/num train calls             101000
trainer/QF1 Loss                      1270.58
trainer/QF2 Loss                      1269.91
trainer/Policy Loss                    564.369
trainer/Q1 Predictions Mean           -564.458
trainer/Q1 Predictions Std              26.102
trainer/Q1 Predictions Max            -433.448
trainer/Q1 Predictions Min            -612.896
trainer/Q2 Predictions Mean           -564.475
trainer/Q2 Predictions Std              26.1268
trainer/Q2 Predictions Max            -432.988
trainer/Q2 Predictions Min            -612.961
trainer/Q Targets Mean                -564.634
trainer/Q Targets Std                   44.1727
trainer/Q Targets Max                   -5.10567
trainer/Q Targets Min                 -614.52
trainer/Log Pis Mean                     0.196773
trainer/Log Pis Std                      1.32244
trainer/Log Pis Max                      2.84221
trainer/Log Pis Min                     -5.09171
trainer/policy/mean Mean                 0.321698
trainer/policy/mean Std                  0.583799
trainer/policy/mean Max                  0.974049
trainer/policy/mean Min                 -0.554253
trainer/policy/normal/std Mean           0.736135
trainer/policy/normal/std Std            0.12714
trainer/policy/normal/std Max            0.883972
trainer/policy/normal/std Min            0.522692
trainer/policy/normal/log_std Mean      -0.321749
trainer/policy/normal/log_std Std        0.176834
trainer/policy/normal/log_std Max       -0.123329
trainer/policy/normal/log_std Min       -0.648764
trainer/Alpha                            0.0515567
trainer/Alpha Loss                      -5.3467
exploration/num steps total         204000
exploration/num paths total           1020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.30579
exploration/Rewards Std                  1.03464
exploration/Rewards Max                 -2.38601
exploration/Rewards Min                 -6.14183
exploration/Returns Mean             -1061.16
exploration/Returns Std                181.099
exploration/Returns Max               -691.51
exploration/Returns Min              -1179.19
exploration/Actions Mean                 0.324211
exploration/Actions Std                  0.679
exploration/Actions Max                  0.998556
exploration/Actions Min                 -0.994477
exploration/Num Paths                   10
exploration/Average Returns          -1061.16
evaluation/num steps total          487224
evaluation/num paths total            2424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.72826
evaluation/Rewards Std                   0.693759
evaluation/Rewards Max                  -3.37422
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1151.38
evaluation/Returns Std                 132.803
evaluation/Returns Max                -718.691
evaluation/Returns Min               -1213.06
evaluation/Actions Mean                  0.312714
evaluation/Actions Std                   0.604552
evaluation/Actions Max                   0.960729
evaluation/Actions Min                  -0.536838
evaluation/Num Paths                    24
evaluation/Average Returns           -1151.38
time/data storing (s)                    0.0200341
time/evaluation sampling (s)            11.3969
time/exploration sampling (s)            4.67834
time/logging (s)                         0.0162242
time/sac training (s)                   12.1038
time/saving (s)                          0.020251
time/training (s)                        0.000116371
time/epoch (s)                          28.2356
time/total (s)                        3173.11
Epoch                                  100
----------------------------------  ----------------
2020-11-09 14:15:15.765581 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 101 finished
----------------------------------  ----------------
replay_buffer/size                  206000
trainer/num train calls             102000
trainer/QF1 Loss                       873.913
trainer/QF2 Loss                       870.716
trainer/Policy Loss                    564.785
trainer/Q1 Predictions Mean           -564.912
trainer/Q1 Predictions Std              25.173
trainer/Q1 Predictions Max            -431.169
trainer/Q1 Predictions Min            -640.764
trainer/Q2 Predictions Mean           -564.908
trainer/Q2 Predictions Std              25.2188
trainer/Q2 Predictions Max            -430.81
trainer/Q2 Predictions Min            -641.309
trainer/Q Targets Mean                -566.138
trainer/Q Targets Std                   43.1401
trainer/Q Targets Max                   -2.99046
trainer/Q Targets Min                 -642.877
trainer/Log Pis Mean                     1.40285
trainer/Log Pis Std                      1.85004
trainer/Log Pis Max                      5.70933
trainer/Log Pis Min                     -5.42058
trainer/policy/mean Mean                 0.0439592
trainer/policy/mean Std                  0.870272
trainer/policy/mean Max                  0.980886
trainer/policy/mean Min                 -0.957539
trainer/policy/normal/std Mean           0.600001
trainer/policy/normal/std Std            0.0369458
trainer/policy/normal/std Max            0.679014
trainer/policy/normal/std Min            0.47515
trainer/policy/normal/log_std Mean      -0.512769
trainer/policy/normal/log_std Std        0.0627947
trainer/policy/normal/log_std Max       -0.387113
trainer/policy/normal/log_std Min       -0.744125
trainer/Alpha                            0.050368
trainer/Alpha Loss                      -1.78451
exploration/num steps total         206000
exploration/num paths total           1030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.67108
exploration/Rewards Std                  0.336819
exploration/Rewards Max                 -4.39881
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1134.22
exploration/Returns Std                 38.1388
exploration/Returns Max              -1028.96
exploration/Returns Min              -1162.98
exploration/Actions Mean                 0.0736964
exploration/Actions Std                  0.797773
exploration/Actions Max                  0.99753
exploration/Actions Min                 -0.998037
exploration/Num Paths                   10
exploration/Average Returns          -1134.22
evaluation/num steps total          492048
evaluation/num paths total            2448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.51241
evaluation/Rewards Std                   1.01778
evaluation/Rewards Max                  -3.36763
evaluation/Rewards Min                  -6.14197
evaluation/Returns Mean              -1108
evaluation/Returns Std                 193.877
evaluation/Returns Max                -701.209
evaluation/Returns Min               -1211.8
evaluation/Actions Mean                  0.0389207
evaluation/Actions Std                   0.88483
evaluation/Actions Max                   0.963063
evaluation/Actions Min                  -0.931327
evaluation/Num Paths                    24
evaluation/Average Returns           -1108
time/data storing (s)                    0.0201856
time/evaluation sampling (s)            11.1886
time/exploration sampling (s)            4.49608
time/logging (s)                         0.0179637
time/sac training (s)                   11.4024
time/saving (s)                          0.0197247
time/training (s)                        0.000107315
time/epoch (s)                          27.145
time/total (s)                        3201.34
Epoch                                  101
----------------------------------  ----------------
2020-11-09 14:15:43.583401 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 102 finished
----------------------------------  ----------------
replay_buffer/size                  208000
trainer/num train calls             103000
trainer/QF1 Loss                        21.9776
trainer/QF2 Loss                        22.1191
trainer/Policy Loss                    565.39
trainer/Q1 Predictions Mean           -565.396
trainer/Q1 Predictions Std              23.8206
trainer/Q1 Predictions Max            -457.288
trainer/Q1 Predictions Min            -609.341
trainer/Q2 Predictions Mean           -565.387
trainer/Q2 Predictions Std              23.8118
trainer/Q2 Predictions Max            -457.665
trainer/Q2 Predictions Min            -609.936
trainer/Q Targets Mean                -567.851
trainer/Q Targets Std                   24.5329
trainer/Q Targets Max                 -457.001
trainer/Q Targets Min                 -613.636
trainer/Log Pis Mean                    -0.764767
trainer/Log Pis Std                      0.922674
trainer/Log Pis Max                      2.45728
trainer/Log Pis Min                     -3.26699
trainer/policy/mean Mean                 0.165145
trainer/policy/mean Std                  0.48028
trainer/policy/mean Max                  0.905346
trainer/policy/mean Min                 -0.754707
trainer/policy/normal/std Mean           0.791573
trainer/policy/normal/std Std            0.0683813
trainer/policy/normal/std Max            0.869198
trainer/policy/normal/std Min            0.60684
trainer/policy/normal/log_std Mean      -0.237632
trainer/policy/normal/log_std Std        0.0892896
trainer/policy/normal/log_std Max       -0.140184
trainer/policy/normal/log_std Min       -0.499489
trainer/Alpha                            0.0484952
trainer/Alpha Loss                      -8.36699
exploration/num steps total         208000
exploration/num paths total           1040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.42887
exploration/Rewards Std                  0.741849
exploration/Rewards Max                 -3.00645
exploration/Rewards Min                 -6.14169
exploration/Returns Mean             -1085.77
exploration/Returns Std                110.815
exploration/Returns Max               -809.099
exploration/Returns Min              -1164.89
exploration/Actions Mean                 0.149099
exploration/Actions Std                  0.619098
exploration/Actions Max                  0.995318
exploration/Actions Min                 -0.994032
exploration/Num Paths                   10
exploration/Average Returns          -1085.77
evaluation/num steps total          496872
evaluation/num paths total            2472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.66351
evaluation/Rewards Std                   0.595255
evaluation/Rewards Max                  -3.99014
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1138.36
evaluation/Returns Std                  94.6671
evaluation/Returns Max                -906.759
evaluation/Returns Min               -1212.13
evaluation/Actions Mean                  0.162358
evaluation/Actions Std                   0.492076
evaluation/Actions Max                   0.8777
evaluation/Actions Min                  -0.707137
evaluation/Num Paths                    24
evaluation/Average Returns           -1138.36
time/data storing (s)                    0.0201101
time/evaluation sampling (s)            10.4744
time/exploration sampling (s)            4.43432
time/logging (s)                         0.0202318
time/sac training (s)                   11.7137
time/saving (s)                          0.0214038
time/training (s)                        0.000102607
time/epoch (s)                          26.6844
time/total (s)                        3229.13
Epoch                                  102
----------------------------------  ----------------
2020-11-09 14:16:12.004340 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 103 finished
----------------------------------  --------------
replay_buffer/size                  210000
trainer/num train calls             104000
trainer/QF1 Loss                        14.4003
trainer/QF2 Loss                        14.915
trainer/Policy Loss                    566.599
trainer/Q1 Predictions Mean           -566.533
trainer/Q1 Predictions Std              26.4758
trainer/Q1 Predictions Max            -448.793
trainer/Q1 Predictions Min            -638.44
trainer/Q2 Predictions Mean           -566.525
trainer/Q2 Predictions Std              26.4545
trainer/Q2 Predictions Max            -448.62
trainer/Q2 Predictions Min            -639.956
trainer/Q Targets Mean                -568.969
trainer/Q Targets Std                   26.4259
trainer/Q Targets Max                 -450.228
trainer/Q Targets Min                 -636.212
trainer/Log Pis Mean                    -0.54482
trainer/Log Pis Std                      1.08147
trainer/Log Pis Max                      2.9577
trainer/Log Pis Min                     -3.5283
trainer/policy/mean Mean                 0.260295
trainer/policy/mean Std                  0.476093
trainer/policy/mean Max                  0.951333
trainer/policy/mean Min                 -0.664603
trainer/policy/normal/std Mean           0.787728
trainer/policy/normal/std Std            0.152052
trainer/policy/normal/std Max            0.969996
trainer/policy/normal/std Min            0.477326
trainer/policy/normal/log_std Mean      -0.258632
trainer/policy/normal/log_std Std        0.203899
trainer/policy/normal/log_std Max       -0.0304637
trainer/policy/normal/log_std Min       -0.739556
trainer/Alpha                            0.0469728
trainer/Alpha Loss                      -7.78253
exploration/num steps total         210000
exploration/num paths total           1050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.41149
exploration/Rewards Std                  0.836446
exploration/Rewards Max                 -3.21326
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1082.3
exploration/Returns Std                142.359
exploration/Returns Max               -700.006
exploration/Returns Min              -1185.82
exploration/Actions Mean                 0.232916
exploration/Actions Std                  0.634691
exploration/Actions Max                  0.998235
exploration/Actions Min                 -0.996988
exploration/Num Paths                   10
exploration/Average Returns          -1082.3
evaluation/num steps total          501696
evaluation/num paths total            2496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.4432
evaluation/Rewards Std                   0.926949
evaluation/Rewards Max                  -3.28374
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1094.08
evaluation/Returns Std                 149.23
evaluation/Returns Max                -703.769
evaluation/Returns Min               -1210.63
evaluation/Actions Mean                  0.241948
evaluation/Actions Std                   0.557255
evaluation/Actions Max                   0.947551
evaluation/Actions Min                  -0.667933
evaluation/Num Paths                    24
evaluation/Average Returns           -1094.08
time/data storing (s)                    0.0213999
time/evaluation sampling (s)            10.71
time/exploration sampling (s)            4.59877
time/logging (s)                         0.0168093
time/sac training (s)                   11.8971
time/saving (s)                          0.0212988
time/training (s)                        9.807e-05
time/epoch (s)                          27.2655
time/total (s)                        3257.53
Epoch                                  103
----------------------------------  --------------
2020-11-09 14:16:41.041096 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 104 finished
----------------------------------  ----------------
replay_buffer/size                  212000
trainer/num train calls             105000
trainer/QF1 Loss                        10.358
trainer/QF2 Loss                        10.3211
trainer/Policy Loss                    564.733
trainer/Q1 Predictions Mean           -564.83
trainer/Q1 Predictions Std              27.1965
trainer/Q1 Predictions Max            -456.24
trainer/Q1 Predictions Min            -611.331
trainer/Q2 Predictions Mean           -564.867
trainer/Q2 Predictions Std              27.1818
trainer/Q2 Predictions Max            -456.334
trainer/Q2 Predictions Min            -611.81
trainer/Q Targets Mean                -567.481
trainer/Q Targets Std                   27.6757
trainer/Q Targets Max                 -455.982
trainer/Q Targets Min                 -612.988
trainer/Log Pis Mean                     0.581273
trainer/Log Pis Std                      1.60864
trainer/Log Pis Max                      4.46907
trainer/Log Pis Min                     -3.98869
trainer/policy/mean Mean                 0.210128
trainer/policy/mean Std                  0.703659
trainer/policy/mean Max                  0.987732
trainer/policy/mean Min                 -0.846133
trainer/policy/normal/std Mean           0.725528
trainer/policy/normal/std Std            0.0882913
trainer/policy/normal/std Max            0.839525
trainer/policy/normal/std Min            0.531535
trainer/policy/normal/log_std Mean      -0.328534
trainer/policy/normal/log_std Std        0.125068
trainer/policy/normal/log_std Max       -0.174919
trainer/policy/normal/log_std Min       -0.631986
trainer/Alpha                            0.0462465
trainer/Alpha Loss                      -4.36084
exploration/num steps total         212000
exploration/num paths total           1060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.66939
exploration/Rewards Std                  0.471814
exploration/Rewards Max                 -3.50939
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1133.88
exploration/Returns Std                 80.9726
exploration/Returns Max               -903.721
exploration/Returns Min              -1192.36
exploration/Actions Mean                 0.246881
exploration/Actions Std                  0.69084
exploration/Actions Max                  0.998831
exploration/Actions Min                 -0.994741
exploration/Num Paths                   10
exploration/Average Returns          -1133.88
evaluation/num steps total          506520
evaluation/num paths total            2520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.87849
evaluation/Rewards Std                   0.504126
evaluation/Rewards Max                  -3.39986
evaluation/Rewards Min                  -6.14192
evaluation/Returns Mean              -1181.58
evaluation/Returns Std                  97.5142
evaluation/Returns Max                -719.755
evaluation/Returns Min               -1213.94
evaluation/Actions Mean                  0.219057
evaluation/Actions Std                   0.688772
evaluation/Actions Max                   0.97379
evaluation/Actions Min                  -0.787997
evaluation/Num Paths                    24
evaluation/Average Returns           -1181.58
time/data storing (s)                    0.0220646
time/evaluation sampling (s)            11.0884
time/exploration sampling (s)            4.44149
time/logging (s)                         0.0273156
time/sac training (s)                   12.2608
time/saving (s)                          0.0225781
time/training (s)                        0.000101098
time/epoch (s)                          27.8628
time/total (s)                        3286.55
Epoch                                  104
----------------------------------  ----------------
2020-11-09 14:17:09.604895 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 105 finished
----------------------------------  ----------------
replay_buffer/size                  214000
trainer/num train calls             106000
trainer/QF1 Loss                        13.6591
trainer/QF2 Loss                        13.7359
trainer/Policy Loss                    566.419
trainer/Q1 Predictions Mean           -566.445
trainer/Q1 Predictions Std              26.2026
trainer/Q1 Predictions Max            -455.052
trainer/Q1 Predictions Min            -644.167
trainer/Q2 Predictions Mean           -566.433
trainer/Q2 Predictions Std              26.2168
trainer/Q2 Predictions Max            -455.064
trainer/Q2 Predictions Min            -644.73
trainer/Q Targets Mean                -569.196
trainer/Q Targets Std                   26.4578
trainer/Q Targets Max                 -457.569
trainer/Q Targets Min                 -647.45
trainer/Log Pis Mean                    -0.0345591
trainer/Log Pis Std                      1.26713
trainer/Log Pis Max                      2.70849
trainer/Log Pis Min                     -4.72983
trainer/policy/mean Mean                 0.565741
trainer/policy/mean Std                  0.302018
trainer/policy/mean Max                  0.975081
trainer/policy/mean Min                 -0.160712
trainer/policy/normal/std Mean           0.756623
trainer/policy/normal/std Std            0.132159
trainer/policy/normal/std Max            0.919193
trainer/policy/normal/std Min            0.511112
trainer/policy/normal/log_std Mean      -0.294782
trainer/policy/normal/log_std Std        0.18004
trainer/policy/normal/log_std Max       -0.0842594
trainer/policy/normal/log_std Min       -0.671167
trainer/Alpha                            0.0447334
trainer/Alpha Loss                      -6.32145
exploration/num steps total         214000
exploration/num paths total           1070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.8505
exploration/Rewards Std                  0.16287
exploration/Rewards Max                 -5.21218
exploration/Rewards Min                 -6.14193
exploration/Returns Mean             -1170.1
exploration/Returns Std                 24.5538
exploration/Returns Max              -1109.69
exploration/Returns Min              -1192.34
exploration/Actions Mean                 0.473854
exploration/Actions Std                  0.513938
exploration/Actions Max                  0.997894
exploration/Actions Min                 -0.991041
exploration/Num Paths                   10
exploration/Average Returns          -1170.1
evaluation/num steps total          511344
evaluation/num paths total            2544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81733
evaluation/Rewards Std                   0.37
evaluation/Rewards Max                  -3.97936
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1169.28
evaluation/Returns Std                  68.68
evaluation/Returns Max                -968.808
evaluation/Returns Min               -1209.5
evaluation/Actions Mean                  0.574653
evaluation/Actions Std                   0.291011
evaluation/Actions Max                   0.959399
evaluation/Actions Min                  -0.10951
evaluation/Num Paths                    24
evaluation/Average Returns           -1169.28
time/data storing (s)                    0.0200164
time/evaluation sampling (s)            11.0329
time/exploration sampling (s)            4.4181
time/logging (s)                         0.0234259
time/sac training (s)                   11.8812
time/saving (s)                          0.0281998
time/training (s)                        0.000129135
time/epoch (s)                          27.4039
time/total (s)                        3315.09
Epoch                                  105
----------------------------------  ----------------
2020-11-09 14:17:40.291403 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 106 finished
----------------------------------  --------------
replay_buffer/size                  216000
trainer/num train calls             107000
trainer/QF1 Loss                      2332.35
trainer/QF2 Loss                      2333.12
trainer/Policy Loss                    564.957
trainer/Q1 Predictions Mean           -564.885
trainer/Q1 Predictions Std              30.8421
trainer/Q1 Predictions Max            -449.761
trainer/Q1 Predictions Min            -611.182
trainer/Q2 Predictions Mean           -564.915
trainer/Q2 Predictions Std              30.783
trainer/Q2 Predictions Max            -449.69
trainer/Q2 Predictions Min            -611.614
trainer/Q Targets Mean                -562.929
trainer/Q Targets Std                   58.4033
trainer/Q Targets Max                   -5.05923
trainer/Q Targets Min                 -612.756
trainer/Log Pis Mean                    -0.909221
trainer/Log Pis Std                      0.802802
trainer/Log Pis Max                      0.738646
trainer/Log Pis Min                     -2.9854
trainer/policy/mean Mean                 0.440674
trainer/policy/mean Std                  0.189609
trainer/policy/mean Max                  0.822603
trainer/policy/mean Min                  0.0224056
trainer/policy/normal/std Mean           0.81371
trainer/policy/normal/std Std            0.0381317
trainer/policy/normal/std Max            0.887153
trainer/policy/normal/std Min            0.757431
trainer/policy/normal/log_std Mean      -0.207233
trainer/policy/normal/log_std Std        0.0463148
trainer/policy/normal/log_std Max       -0.119738
trainer/policy/normal/log_std Min       -0.277823
trainer/Alpha                            0.0432084
trainer/Alpha Loss                      -9.13996
exploration/num steps total         216000
exploration/num paths total           1080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.44113
exploration/Rewards Std                  0.937583
exploration/Rewards Max                 -3.03677
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1088.23
exploration/Returns Std                150.502
exploration/Returns Max               -738.636
exploration/Returns Min              -1194.06
exploration/Actions Mean                 0.336207
exploration/Actions Std                  0.538822
exploration/Actions Max                  0.997355
exploration/Actions Min                 -0.988638
exploration/Num Paths                   10
exploration/Average Returns          -1088.23
evaluation/num steps total          516168
evaluation/num paths total            2568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96098
evaluation/Rewards Std                   0.228821
evaluation/Rewards Max                  -4.4054
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1198.16
evaluation/Returns Std                  30.8898
evaluation/Returns Max               -1081.46
evaluation/Returns Min               -1224.18
evaluation/Actions Mean                  0.446712
evaluation/Actions Std                   0.164251
evaluation/Actions Max                   0.815187
evaluation/Actions Min                   0.0253052
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.16
time/data storing (s)                    0.0217012
time/evaluation sampling (s)            12.4694
time/exploration sampling (s)            4.84143
time/logging (s)                         0.0188189
time/sac training (s)                   12.1275
time/saving (s)                          0.0246102
time/training (s)                        9.453e-05
time/epoch (s)                          29.5035
time/total (s)                        3345.75
Epoch                                  106
----------------------------------  --------------
2020-11-09 14:18:11.023179 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 107 finished
----------------------------------  ----------------
replay_buffer/size                  218000
trainer/num train calls             108000
trainer/QF1 Loss                      1153.76
trainer/QF2 Loss                      1158.43
trainer/Policy Loss                    568.988
trainer/Q1 Predictions Mean           -569.032
trainer/Q1 Predictions Std              25.4547
trainer/Q1 Predictions Max            -404.647
trainer/Q1 Predictions Min            -643.874
trainer/Q2 Predictions Mean           -569.032
trainer/Q2 Predictions Std              25.4761
trainer/Q2 Predictions Max            -404.847
trainer/Q2 Predictions Min            -644.53
trainer/Q Targets Mean                -569.026
trainer/Q Targets Std                   43.7792
trainer/Q Targets Max                   -5.38516
trainer/Q Targets Min                 -645.213
trainer/Log Pis Mean                    -0.569387
trainer/Log Pis Std                      1.21626
trainer/Log Pis Max                      3.20308
trainer/Log Pis Min                     -6.47029
trainer/policy/mean Mean                 0.348832
trainer/policy/mean Std                  0.392658
trainer/policy/mean Max                  0.974168
trainer/policy/mean Min                 -0.583307
trainer/policy/normal/std Mean           0.76802
trainer/policy/normal/std Std            0.14018
trainer/policy/normal/std Max            0.958079
trainer/policy/normal/std Min            0.433181
trainer/policy/normal/log_std Mean      -0.282396
trainer/policy/normal/log_std Std        0.197383
trainer/policy/normal/log_std Max       -0.0428255
trainer/policy/normal/log_std Min       -0.8366
trainer/Alpha                            0.0417844
trainer/Alpha Loss                      -8.1584
exploration/num steps total         218000
exploration/num paths total           1090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.40709
exploration/Rewards Std                  0.94506
exploration/Rewards Max                 -3.32204
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1081.42
exploration/Returns Std                169.667
exploration/Returns Max               -707.266
exploration/Returns Min              -1187.44
exploration/Actions Mean                 0.2966
exploration/Actions Std                  0.622286
exploration/Actions Max                  0.998637
exploration/Actions Min                 -0.998427
exploration/Num Paths                   10
exploration/Average Returns          -1081.42
evaluation/num steps total          520992
evaluation/num paths total            2592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.75022
evaluation/Rewards Std                   0.41246
evaluation/Rewards Max                  -3.32758
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1155.79
evaluation/Returns Std                  54.6777
evaluation/Returns Max                -978.486
evaluation/Returns Min               -1194.81
evaluation/Actions Mean                  0.356093
evaluation/Actions Std                   0.380456
evaluation/Actions Max                   0.964764
evaluation/Actions Min                  -0.564543
evaluation/Num Paths                    24
evaluation/Average Returns           -1155.79
time/data storing (s)                    0.0261182
time/evaluation sampling (s)            12.4272
time/exploration sampling (s)            4.83011
time/logging (s)                         0.0209857
time/sac training (s)                   12.2024
time/saving (s)                          0.026209
time/training (s)                        0.000117364
time/epoch (s)                          29.5331
time/total (s)                        3376.46
Epoch                                  107
----------------------------------  ----------------
2020-11-09 14:18:44.143626 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 108 finished
----------------------------------  ----------------
replay_buffer/size                  220000
trainer/num train calls             109000
trainer/QF1 Loss                        11.5881
trainer/QF2 Loss                        11.5005
trainer/Policy Loss                    570.85
trainer/Q1 Predictions Mean           -570.982
trainer/Q1 Predictions Std              24.63
trainer/Q1 Predictions Max            -411.508
trainer/Q1 Predictions Min            -647.182
trainer/Q2 Predictions Mean           -570.995
trainer/Q2 Predictions Std              24.5885
trainer/Q2 Predictions Max            -411.768
trainer/Q2 Predictions Min            -647.934
trainer/Q Targets Mean                -573.849
trainer/Q Targets Std                   24.7559
trainer/Q Targets Max                 -411.314
trainer/Q Targets Min                 -647.431
trainer/Log Pis Mean                     0.232459
trainer/Log Pis Std                      1.63711
trainer/Log Pis Max                      4.69203
trainer/Log Pis Min                     -3.86224
trainer/policy/mean Mean                 0.155168
trainer/policy/mean Std                  0.685775
trainer/policy/mean Max                  0.983087
trainer/policy/mean Min                 -0.900836
trainer/policy/normal/std Mean           0.679091
trainer/policy/normal/std Std            0.049517
trainer/policy/normal/std Max            0.813893
trainer/policy/normal/std Min            0.530576
trainer/policy/normal/log_std Mean      -0.389726
trainer/policy/normal/log_std Std        0.0743513
trainer/policy/normal/log_std Max       -0.205926
trainer/policy/normal/log_std Min       -0.633791
trainer/Alpha                            0.0407412
trainer/Alpha Loss                      -5.65704
exploration/num steps total         220000
exploration/num paths total           1100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.69537
exploration/Rewards Std                  0.320414
exploration/Rewards Max                 -4.60725
exploration/Rewards Min                 -6.14155
exploration/Returns Mean             -1139.07
exploration/Returns Std                 30.6372
exploration/Returns Max              -1075.75
exploration/Returns Min              -1181.85
exploration/Actions Mean                 0.167394
exploration/Actions Std                  0.669835
exploration/Actions Max                  0.997495
exploration/Actions Min                 -0.994735
exploration/Num Paths                   10
exploration/Average Returns          -1139.07
evaluation/num steps total          525816
evaluation/num paths total            2616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79029
evaluation/Rewards Std                   0.492255
evaluation/Rewards Max                  -3.40099
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1163.85
evaluation/Returns Std                  93.1018
evaluation/Returns Max                -729.505
evaluation/Returns Min               -1205.3
evaluation/Actions Mean                  0.168612
evaluation/Actions Std                   0.653538
evaluation/Actions Max                   0.974189
evaluation/Actions Min                  -0.881383
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.85
time/data storing (s)                    0.0259077
time/evaluation sampling (s)            13.6301
time/exploration sampling (s)            4.64117
time/logging (s)                         0.0271874
time/sac training (s)                   13.5204
time/saving (s)                          0.0253936
time/training (s)                        0.000126965
time/epoch (s)                          31.8704
time/total (s)                        3409.56
Epoch                                  108
----------------------------------  ----------------
2020-11-09 14:19:20.218597 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 109 finished
----------------------------------  ----------------
replay_buffer/size                  222000
trainer/num train calls             110000
trainer/QF1 Loss                      1290.81
trainer/QF2 Loss                      1291.31
trainer/Policy Loss                    570.851
trainer/Q1 Predictions Mean           -570.819
trainer/Q1 Predictions Std              29.1373
trainer/Q1 Predictions Max            -436.202
trainer/Q1 Predictions Min            -654.802
trainer/Q2 Predictions Mean           -570.804
trainer/Q2 Predictions Std              29.1683
trainer/Q2 Predictions Max            -436.41
trainer/Q2 Predictions Min            -655.59
trainer/Q Targets Mean                -570.762
trainer/Q Targets Std                   46.0573
trainer/Q Targets Max                   -5.62232
trainer/Q Targets Min                 -655.812
trainer/Log Pis Mean                     0.235938
trainer/Log Pis Std                      1.53199
trainer/Log Pis Max                      4.07997
trainer/Log Pis Min                     -4.08739
trainer/policy/mean Mean                -0.0626045
trainer/policy/mean Std                  0.740124
trainer/policy/mean Max                  0.907814
trainer/policy/mean Min                 -0.970603
trainer/policy/normal/std Mean           0.768358
trainer/policy/normal/std Std            0.0640807
trainer/policy/normal/std Max            0.894212
trainer/policy/normal/std Min            0.632933
trainer/policy/normal/log_std Mean      -0.267004
trainer/policy/normal/log_std Std        0.0839015
trainer/policy/normal/log_std Max       -0.111812
trainer/policy/normal/log_std Min       -0.457391
trainer/Alpha                            0.0402624
trainer/Alpha Loss                      -5.66676
exploration/num steps total         222000
exploration/num paths total           1110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.73396
exploration/Rewards Std                  1.00077
exploration/Rewards Max                 -2.47531
exploration/Rewards Min                 -6.14172
exploration/Returns Mean              -946.791
exploration/Returns Std                126.749
exploration/Returns Max               -754.5
exploration/Returns Min              -1131.91
exploration/Actions Mean                -0.0805567
exploration/Actions Std                  0.767191
exploration/Actions Max                  0.998307
exploration/Actions Min                 -0.99918
exploration/Num Paths                   10
exploration/Average Returns           -946.791
evaluation/num steps total          530640
evaluation/num paths total            2640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.85481
evaluation/Rewards Std                   0.23191
evaluation/Rewards Max                  -5.0771
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1176.82
evaluation/Returns Std                  43.5731
evaluation/Returns Max               -1038.53
evaluation/Returns Min               -1208.81
evaluation/Actions Mean                 -0.0646728
evaluation/Actions Std                   0.778128
evaluation/Actions Max                   0.869769
evaluation/Actions Min                  -0.953492
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.82
time/data storing (s)                    0.0204109
time/evaluation sampling (s)            15.0901
time/exploration sampling (s)            6.28949
time/logging (s)                         0.0171681
time/sac training (s)                   13.3923
time/saving (s)                          0.0202252
time/training (s)                        0.000114007
time/epoch (s)                          34.8298
time/total (s)                        3445.6
Epoch                                  109
----------------------------------  ----------------
2020-11-09 14:19:48.457248 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 110 finished
----------------------------------  ----------------
replay_buffer/size                  224000
trainer/num train calls             111000
trainer/QF1 Loss                      2498.47
trainer/QF2 Loss                      2497.75
trainer/Policy Loss                    568.404
trainer/Q1 Predictions Mean           -568.506
trainer/Q1 Predictions Std              28.6325
trainer/Q1 Predictions Max            -441.442
trainer/Q1 Predictions Min            -619.96
trainer/Q2 Predictions Mean           -568.526
trainer/Q2 Predictions Std              28.6181
trainer/Q2 Predictions Max            -441.665
trainer/Q2 Predictions Min            -619.849
trainer/Q Targets Mean                -566.908
trainer/Q Targets Std                   57.6535
trainer/Q Targets Max                   -5.19711
trainer/Q Targets Min                 -621.625
trainer/Log Pis Mean                     0.0926037
trainer/Log Pis Std                      1.47013
trainer/Log Pis Max                      4.49098
trainer/Log Pis Min                     -5.69179
trainer/policy/mean Mean                 0.270346
trainer/policy/mean Std                  0.585124
trainer/policy/mean Max                  0.980346
trainer/policy/mean Min                 -0.761807
trainer/policy/normal/std Mean           0.749523
trainer/policy/normal/std Std            0.142215
trainer/policy/normal/std Max            0.922278
trainer/policy/normal/std Min            0.470214
trainer/policy/normal/log_std Mean      -0.307509
trainer/policy/normal/log_std Std        0.199065
trainer/policy/normal/log_std Max       -0.0809081
trainer/policy/normal/log_std Min       -0.754568
trainer/Alpha                            0.0389194
trainer/Alpha Loss                      -6.19191
exploration/num steps total         224000
exploration/num paths total           1120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.13755
exploration/Rewards Std                  1.03757
exploration/Rewards Max                 -3.01861
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1027.51
exploration/Returns Std                162.292
exploration/Returns Max               -749.96
exploration/Returns Min              -1179.17
exploration/Actions Mean                 0.258568
exploration/Actions Std                  0.696178
exploration/Actions Max                  0.998407
exploration/Actions Min                 -0.999528
exploration/Num Paths                   10
exploration/Average Returns          -1027.51
evaluation/num steps total          535464
evaluation/num paths total            2664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79477
evaluation/Rewards Std                   0.500277
evaluation/Rewards Max                  -3.37603
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1164.75
evaluation/Returns Std                  92.6258
evaluation/Returns Max                -745.798
evaluation/Returns Min               -1208.14
evaluation/Actions Mean                  0.269131
evaluation/Actions Std                   0.600468
evaluation/Actions Max                   0.966535
evaluation/Actions Min                  -0.719069
evaluation/Num Paths                    24
evaluation/Average Returns           -1164.75
time/data storing (s)                    0.0203506
time/evaluation sampling (s)            10.7435
time/exploration sampling (s)            4.47781
time/logging (s)                         0.0207475
time/sac training (s)                   11.8119
time/saving (s)                          0.0223826
time/training (s)                        0.000185048
time/epoch (s)                          27.0969
time/total (s)                        3473.82
Epoch                                  110
----------------------------------  ----------------
2020-11-09 14:20:18.729734 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 111 finished
----------------------------------  ----------------
replay_buffer/size                  226000
trainer/num train calls             112000
trainer/QF1 Loss                        12.1152
trainer/QF2 Loss                        12.2742
trainer/Policy Loss                    573.178
trainer/Q1 Predictions Mean           -573.207
trainer/Q1 Predictions Std              24.2465
trainer/Q1 Predictions Max            -441.194
trainer/Q1 Predictions Min            -609.257
trainer/Q2 Predictions Mean           -573.191
trainer/Q2 Predictions Std              24.2282
trainer/Q2 Predictions Max            -441.401
trainer/Q2 Predictions Min            -608.933
trainer/Q Targets Mean                -575.365
trainer/Q Targets Std                   24.441
trainer/Q Targets Max                 -441.212
trainer/Q Targets Min                 -611.298
trainer/Log Pis Mean                    -0.623132
trainer/Log Pis Std                      1.08144
trainer/Log Pis Max                      2.75322
trainer/Log Pis Min                     -3.56931
trainer/policy/mean Mean                 0.333136
trainer/policy/mean Std                  0.401169
trainer/policy/mean Max                  0.972318
trainer/policy/mean Min                 -0.634256
trainer/policy/normal/std Mean           0.788016
trainer/policy/normal/std Std            0.0820712
trainer/policy/normal/std Max            0.889393
trainer/policy/normal/std Min            0.534256
trainer/policy/normal/log_std Mean      -0.244063
trainer/policy/normal/log_std Std        0.109954
trainer/policy/normal/log_std Max       -0.117216
trainer/policy/normal/log_std Min       -0.626881
trainer/Alpha                            0.0376843
trainer/Alpha Loss                      -8.59997
exploration/num steps total         226000
exploration/num paths total           1130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.30557
exploration/Rewards Std                  1.0485
exploration/Rewards Max                 -1.48954
exploration/Rewards Min                 -6.14188
exploration/Returns Mean             -1061.11
exploration/Returns Std                169.968
exploration/Returns Max               -642.178
exploration/Returns Min              -1191.65
exploration/Actions Mean                 0.277778
exploration/Actions Std                  0.612505
exploration/Actions Max                  0.997699
exploration/Actions Min                 -0.998628
exploration/Num Paths                   10
exploration/Average Returns          -1061.11
evaluation/num steps total          540288
evaluation/num paths total            2688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7401
evaluation/Rewards Std                   0.421096
evaluation/Rewards Max                  -4.10016
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1153.76
evaluation/Returns Std                  72.9551
evaluation/Returns Max                -869.131
evaluation/Returns Min               -1200.24
evaluation/Actions Mean                  0.336588
evaluation/Actions Std                   0.401237
evaluation/Actions Max                   0.941326
evaluation/Actions Min                  -0.55136
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.76
time/data storing (s)                    0.0316096
time/evaluation sampling (s)            11.0689
time/exploration sampling (s)            4.5703
time/logging (s)                         0.0226955
time/sac training (s)                   13.3319
time/saving (s)                          0.0214
time/training (s)                        0.000100369
time/epoch (s)                          29.0469
time/total (s)                        3504.07
Epoch                                  111
----------------------------------  ----------------
2020-11-09 14:20:47.626059 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 112 finished
----------------------------------  ----------------
replay_buffer/size                  228000
trainer/num train calls             113000
trainer/QF1 Loss                         8.62439
trainer/QF2 Loss                         8.61409
trainer/Policy Loss                    569.823
trainer/Q1 Predictions Mean           -569.803
trainer/Q1 Predictions Std              27.4662
trainer/Q1 Predictions Max            -455.444
trainer/Q1 Predictions Min            -615.276
trainer/Q2 Predictions Mean           -569.811
trainer/Q2 Predictions Std              27.4411
trainer/Q2 Predictions Max            -455.499
trainer/Q2 Predictions Min            -615.515
trainer/Q Targets Mean                -572.285
trainer/Q Targets Std                   27.7163
trainer/Q Targets Max                 -455.454
trainer/Q Targets Min                 -616.929
trainer/Log Pis Mean                     1.12216
trainer/Log Pis Std                      1.65705
trainer/Log Pis Max                      4.56091
trainer/Log Pis Min                     -6.72178
trainer/policy/mean Mean                 0.816695
trainer/policy/mean Std                  0.10784
trainer/policy/mean Max                  0.993495
trainer/policy/mean Min                  0.491794
trainer/policy/normal/std Mean           0.640078
trainer/policy/normal/std Std            0.0422326
trainer/policy/normal/std Max            0.733215
trainer/policy/normal/std Min            0.477714
trainer/policy/normal/log_std Mean      -0.448488
trainer/policy/normal/log_std Std        0.0693164
trainer/policy/normal/log_std Max       -0.310317
trainer/policy/normal/log_std Min       -0.738742
trainer/Alpha                            0.0371434
trainer/Alpha Loss                      -2.89071
exploration/num steps total         228000
exploration/num paths total           1140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.69195
exploration/Rewards Std                  0.780176
exploration/Rewards Max                 -3.26943
exploration/Rewards Min                 -6.14196
exploration/Returns Mean             -1138.39
exploration/Returns Std                151.052
exploration/Returns Max               -688.271
exploration/Returns Min              -1210.73
exploration/Actions Mean                 0.733097
exploration/Actions Std                  0.319949
exploration/Actions Max                  0.998547
exploration/Actions Min                 -0.918594
exploration/Num Paths                   10
exploration/Average Returns          -1138.39
evaluation/num steps total          545112
evaluation/num paths total            2712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.88142
evaluation/Rewards Std                   0.51662
evaluation/Rewards Max                  -3.36299
evaluation/Rewards Min                  -6.14194
evaluation/Returns Mean              -1182.16
evaluation/Returns Std                 101.134
evaluation/Returns Max                -700.052
evaluation/Returns Min               -1210.85
evaluation/Actions Mean                  0.828907
evaluation/Actions Std                   0.0995654
evaluation/Actions Max                   0.975109
evaluation/Actions Min                   0.490924
evaluation/Num Paths                    24
evaluation/Average Returns           -1182.16
time/data storing (s)                    0.0234066
time/evaluation sampling (s)            10.9839
time/exploration sampling (s)            4.47226
time/logging (s)                         0.0184146
time/sac training (s)                   12.177
time/saving (s)                          0.0209177
time/training (s)                        0.000121375
time/epoch (s)                          27.696
time/total (s)                        3532.94
Epoch                                  112
----------------------------------  ----------------
2020-11-09 14:21:18.360738 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 113 finished
----------------------------------  ----------------
replay_buffer/size                  230000
trainer/num train calls             114000
trainer/QF1 Loss                        16.6376
trainer/QF2 Loss                        16.6293
trainer/Policy Loss                    567.601
trainer/Q1 Predictions Mean           -567.644
trainer/Q1 Predictions Std              32.5439
trainer/Q1 Predictions Max            -428.438
trainer/Q1 Predictions Min            -642.743
trainer/Q2 Predictions Mean           -567.637
trainer/Q2 Predictions Std              32.5339
trainer/Q2 Predictions Max            -428.179
trainer/Q2 Predictions Min            -641.854
trainer/Q Targets Mean                -570.187
trainer/Q Targets Std                   33.423
trainer/Q Targets Max                 -428.148
trainer/Q Targets Min                 -643.175
trainer/Log Pis Mean                     0.99679
trainer/Log Pis Std                      1.65205
trainer/Log Pis Max                      4.87017
trainer/Log Pis Min                     -5.54068
trainer/policy/mean Mean                 0.219247
trainer/policy/mean Std                  0.720849
trainer/policy/mean Max                  0.989503
trainer/policy/mean Min                 -0.849561
trainer/policy/normal/std Mean           0.679109
trainer/policy/normal/std Std            0.11091
trainer/policy/normal/std Max            0.8113
trainer/policy/normal/std Min            0.461997
trainer/policy/normal/log_std Mean      -0.400982
trainer/policy/normal/log_std Std        0.16941
trainer/policy/normal/log_std Max       -0.209117
trainer/policy/normal/log_std Min       -0.772196
trainer/Alpha                            0.0360857
trainer/Alpha Loss                      -3.33252
exploration/num steps total         230000
exploration/num paths total           1150
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.7747
exploration/Rewards Std                  1.20145
exploration/Rewards Max                 -3.06647
exploration/Rewards Min                 -6.14202
exploration/Returns Mean              -954.939
exploration/Returns Std                223.43
exploration/Returns Max               -690.263
exploration/Returns Min              -1201.07
exploration/Actions Mean                 0.211827
exploration/Actions Std                  0.787537
exploration/Actions Max                  0.999611
exploration/Actions Min                 -0.999143
exploration/Num Paths                   10
exploration/Average Returns           -954.939
evaluation/num steps total          549936
evaluation/num paths total            2736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73492
evaluation/Rewards Std                   0.857062
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1152.72
evaluation/Returns Std                 169.092
evaluation/Returns Max                -692.451
evaluation/Returns Min               -1221.27
evaluation/Actions Mean                  0.205582
evaluation/Actions Std                   0.737148
evaluation/Actions Max                   0.976959
evaluation/Actions Min                  -0.805492
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.72
time/data storing (s)                    0.0208767
time/evaluation sampling (s)            10.8245
time/exploration sampling (s)            4.81444
time/logging (s)                         0.0195021
time/sac training (s)                   13.7966
time/saving (s)                          0.028437
time/training (s)                        0.000100629
time/epoch (s)                          29.5044
time/total (s)                        3563.65
Epoch                                  113
----------------------------------  ----------------
2020-11-09 14:21:53.904155 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 114 finished
----------------------------------  ---------------
replay_buffer/size                  232000
trainer/num train calls             115000
trainer/QF1 Loss                        12.1072
trainer/QF2 Loss                        12.27
trainer/Policy Loss                    570.637
trainer/Q1 Predictions Mean           -570.893
trainer/Q1 Predictions Std              27.7895
trainer/Q1 Predictions Max            -435.515
trainer/Q1 Predictions Min            -615.704
trainer/Q2 Predictions Mean           -570.886
trainer/Q2 Predictions Std              27.7717
trainer/Q2 Predictions Max            -435.442
trainer/Q2 Predictions Min            -615.087
trainer/Q Targets Mean                -573.382
trainer/Q Targets Std                   28.2726
trainer/Q Targets Max                 -438.778
trainer/Q Targets Min                 -617.509
trainer/Log Pis Mean                     1.75169
trainer/Log Pis Std                      1.85385
trainer/Log Pis Max                      6.99401
trainer/Log Pis Min                     -3.76925
trainer/policy/mean Mean                 0.0123362
trainer/policy/mean Std                  0.874673
trainer/policy/mean Max                  0.978861
trainer/policy/mean Min                 -0.9828
trainer/policy/normal/std Mean           0.609766
trainer/policy/normal/std Std            0.0748907
trainer/policy/normal/std Max            0.754508
trainer/policy/normal/std Min            0.440775
trainer/policy/normal/log_std Mean      -0.502346
trainer/policy/normal/log_std Std        0.124362
trainer/policy/normal/log_std Max       -0.28169
trainer/policy/normal/log_std Min       -0.81922
trainer/Alpha                            0.0353034
trainer/Alpha Loss                      -0.830303
exploration/num steps total         232000
exploration/num paths total           1160
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.45829
exploration/Rewards Std                  0.694716
exploration/Rewards Max                 -3.17716
exploration/Rewards Min                 -6.14179
exploration/Returns Mean             -1091.66
exploration/Returns Std                123.706
exploration/Returns Max               -732.214
exploration/Returns Min              -1159.42
exploration/Actions Mean                 0.00485638
exploration/Actions Std                  0.790596
exploration/Actions Max                  0.998512
exploration/Actions Min                 -0.998173
exploration/Num Paths                   10
exploration/Average Returns          -1091.66
evaluation/num steps total          554760
evaluation/num paths total            2760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.945
evaluation/Rewards Std                   0.310855
evaluation/Rewards Max                  -4.90747
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1194.95
evaluation/Returns Std                  61.9172
evaluation/Returns Max                -991.559
evaluation/Returns Min               -1221.82
evaluation/Actions Mean                  0.00639533
evaluation/Actions Std                   0.894108
evaluation/Actions Max                   0.949253
evaluation/Actions Min                  -0.954933
evaluation/Num Paths                    24
evaluation/Average Returns           -1194.95
time/data storing (s)                    0.0255028
time/evaluation sampling (s)            14.657
time/exploration sampling (s)            5.80847
time/logging (s)                         0.0201931
time/sac training (s)                   13.7931
time/saving (s)                          0.0231593
time/training (s)                        0.00014418
time/epoch (s)                          34.3275
time/total (s)                        3599.17
Epoch                                  114
----------------------------------  ---------------
2020-11-09 14:22:26.812093 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 115 finished
----------------------------------  ---------------
replay_buffer/size                  234000
trainer/num train calls             116000
trainer/QF1 Loss                        12.9093
trainer/QF2 Loss                        13.3065
trainer/Policy Loss                    574.539
trainer/Q1 Predictions Mean           -574.485
trainer/Q1 Predictions Std              23.8596
trainer/Q1 Predictions Max            -429.885
trainer/Q1 Predictions Min            -641.974
trainer/Q2 Predictions Mean           -574.487
trainer/Q2 Predictions Std              23.8577
trainer/Q2 Predictions Max            -429.59
trainer/Q2 Predictions Min            -642.671
trainer/Q Targets Mean                -577.036
trainer/Q Targets Std                   23.9903
trainer/Q Targets Max                 -431.67
trainer/Q Targets Min                 -643.219
trainer/Log Pis Mean                    -0.819756
trainer/Log Pis Std                      0.98805
trainer/Log Pis Max                      2.68288
trainer/Log Pis Min                     -3.36332
trainer/policy/mean Mean                 0.00870056
trainer/policy/mean Std                  0.51685
trainer/policy/mean Max                  0.822884
trainer/policy/mean Min                 -0.878928
trainer/policy/normal/std Mean           0.807156
trainer/policy/normal/std Std            0.0541994
trainer/policy/normal/std Max            0.91375
trainer/policy/normal/std Min            0.710342
trainer/policy/normal/log_std Mean      -0.216478
trainer/policy/normal/log_std Std        0.0668167
trainer/policy/normal/log_std Max       -0.0901987
trainer/policy/normal/log_std Min       -0.342009
trainer/Alpha                            0.0341182
trainer/Alpha Loss                      -9.52492
exploration/num steps total         234000
exploration/num paths total           1170
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.34856
exploration/Rewards Std                  0.717151
exploration/Rewards Max                 -2.88083
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1069.71
exploration/Returns Std                 89.7281
exploration/Returns Max               -815.109
exploration/Returns Min              -1136.26
exploration/Actions Mean                -0.00743693
exploration/Actions Std                  0.630146
exploration/Actions Max                  0.998141
exploration/Actions Min                 -0.998212
exploration/Num Paths                   10
exploration/Average Returns          -1069.71
evaluation/num steps total          559584
evaluation/num paths total            2784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.69756
evaluation/Rewards Std                   0.652878
evaluation/Rewards Max                  -3.31974
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1145.21
evaluation/Returns Std                 109.259
evaluation/Returns Max                -737.639
evaluation/Returns Min               -1208.62
evaluation/Actions Mean                  0.0125305
evaluation/Actions Std                   0.513345
evaluation/Actions Max                   0.836563
evaluation/Actions Min                  -0.897645
evaluation/Num Paths                    24
evaluation/Average Returns           -1145.21
time/data storing (s)                    0.02729
time/evaluation sampling (s)            14.0621
time/exploration sampling (s)            5.83696
time/logging (s)                         0.0173179
time/sac training (s)                   11.7915
time/saving (s)                          0.0188177
time/training (s)                        9.8132e-05
time/epoch (s)                          31.7541
time/total (s)                        3632.05
Epoch                                  115
----------------------------------  ---------------
2020-11-09 14:22:55.291659 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 116 finished
----------------------------------  ----------------
replay_buffer/size                  236000
trainer/num train calls             117000
trainer/QF1 Loss                      1310.44
trainer/QF2 Loss                      1310.3
trainer/Policy Loss                    565.549
trainer/Q1 Predictions Mean           -565.504
trainer/Q1 Predictions Std              38.0804
trainer/Q1 Predictions Max            -434.517
trainer/Q1 Predictions Min            -619.509
trainer/Q2 Predictions Mean           -565.507
trainer/Q2 Predictions Std              38.0751
trainer/Q2 Predictions Max            -434.646
trainer/Q2 Predictions Min            -619.581
trainer/Q Targets Mean                -566.285
trainer/Q Targets Std                   52.1206
trainer/Q Targets Max                   -5.63421
trainer/Q Targets Min                 -621.872
trainer/Log Pis Mean                    -0.715857
trainer/Log Pis Std                      1.2932
trainer/Log Pis Max                      3.44526
trainer/Log Pis Min                     -5.37572
trainer/policy/mean Mean                -0.0501087
trainer/policy/mean Std                  0.523298
trainer/policy/mean Max                  0.877752
trainer/policy/mean Min                 -0.946336
trainer/policy/normal/std Mean           0.748524
trainer/policy/normal/std Std            0.0703327
trainer/policy/normal/std Max            0.924942
trainer/policy/normal/std Min            0.61301
trainer/policy/normal/log_std Mean      -0.294009
trainer/policy/normal/log_std Std        0.0931119
trainer/policy/normal/log_std Max       -0.0780241
trainer/policy/normal/log_std Min       -0.489373
trainer/Alpha                            0.0328222
trainer/Alpha Loss                      -9.27913
exploration/num steps total         236000
exploration/num paths total           1180
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.40239
exploration/Rewards Std                  0.544491
exploration/Rewards Max                 -3.42127
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1080.48
exploration/Returns Std                 72.3351
exploration/Returns Max               -919.913
exploration/Returns Min              -1156.57
exploration/Actions Mean                -0.038959
exploration/Actions Std                  0.603027
exploration/Actions Max                  0.995366
exploration/Actions Min                 -0.997872
exploration/Num Paths                   10
exploration/Average Returns          -1080.48
evaluation/num steps total          564408
evaluation/num paths total            2808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.81169
evaluation/Rewards Std                   0.377677
evaluation/Rewards Max                  -3.3494
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1168.15
evaluation/Returns Std                  47.8441
evaluation/Returns Max               -1061.22
evaluation/Returns Min               -1213.3
evaluation/Actions Mean                 -0.0596694
evaluation/Actions Std                   0.471391
evaluation/Actions Max                   0.808408
evaluation/Actions Min                  -0.906942
evaluation/Num Paths                    24
evaluation/Average Returns           -1168.15
time/data storing (s)                    0.021064
time/evaluation sampling (s)            10.7827
time/exploration sampling (s)            4.66306
time/logging (s)                         0.0245046
time/sac training (s)                   11.832
time/saving (s)                          0.0188626
time/training (s)                        0.000131951
time/epoch (s)                          27.3424
time/total (s)                        3660.51
Epoch                                  116
----------------------------------  ----------------
2020-11-09 14:23:25.434689 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 117 finished
----------------------------------  ----------------
replay_buffer/size                  238000
trainer/num train calls             118000
trainer/QF1 Loss                      1465.13
trainer/QF2 Loss                      1464.64
trainer/Policy Loss                    574.144
trainer/Q1 Predictions Mean           -574.169
trainer/Q1 Predictions Std              28.0586
trainer/Q1 Predictions Max            -443.813
trainer/Q1 Predictions Min            -650.753
trainer/Q2 Predictions Mean           -574.189
trainer/Q2 Predictions Std              28.0697
trainer/Q2 Predictions Max            -444.059
trainer/Q2 Predictions Min            -651.53
trainer/Q Targets Mean                -574.622
trainer/Q Targets Std                   45.4909
trainer/Q Targets Max                   -4.85837
trainer/Q Targets Min                 -657.202
trainer/Log Pis Mean                    -1.05444
trainer/Log Pis Std                      0.762227
trainer/Log Pis Max                      1.79991
trainer/Log Pis Min                     -5.53699
trainer/policy/mean Mean                 0.055559
trainer/policy/mean Std                  0.383516
trainer/policy/mean Max                  0.871436
trainer/policy/mean Min                 -0.816812
trainer/policy/normal/std Mean           0.777327
trainer/policy/normal/std Std            0.0667614
trainer/policy/normal/std Max            0.865282
trainer/policy/normal/std Min            0.500149
trainer/policy/normal/log_std Mean      -0.256033
trainer/policy/normal/log_std Std        0.0938355
trainer/policy/normal/log_std Max       -0.144699
trainer/policy/normal/log_std Min       -0.692849
trainer/Alpha                            0.0317246
trainer/Alpha Loss                     -10.5399
exploration/num steps total         238000
exploration/num paths total           1190
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.76914
exploration/Rewards Std                  0.529213
exploration/Rewards Max                 -3.18849
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1153.83
exploration/Returns Std                 60.7405
exploration/Returns Max               -985.703
exploration/Returns Min              -1199.73
exploration/Actions Mean                 0.0407056
exploration/Actions Std                  0.599273
exploration/Actions Max                  0.993756
exploration/Actions Min                 -0.995347
exploration/Num Paths                   10
exploration/Average Returns          -1153.83
evaluation/num steps total          569232
evaluation/num paths total            2832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03887
evaluation/Rewards Std                   0.274825
evaluation/Rewards Max                  -3.7586
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1213.81
evaluation/Returns Std                  41.1455
evaluation/Returns Max               -1020.74
evaluation/Returns Min               -1230.37
evaluation/Actions Mean                  0.0501802
evaluation/Actions Std                   0.298497
evaluation/Actions Max                   0.880517
evaluation/Actions Min                  -0.842857
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.81
time/data storing (s)                    0.0252973
time/evaluation sampling (s)            11.7928
time/exploration sampling (s)            4.77397
time/logging (s)                         0.017272
time/sac training (s)                   12.31
time/saving (s)                          0.0215117
time/training (s)                        0.000136213
time/epoch (s)                          28.941
time/total (s)                        3690.62
Epoch                                  117
----------------------------------  ----------------
2020-11-09 14:23:54.829732 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 118 finished
----------------------------------  ----------------
replay_buffer/size                  240000
trainer/num train calls             119000
trainer/QF1 Loss                      2632.91
trainer/QF2 Loss                      2632.04
trainer/Policy Loss                    573.639
trainer/Q1 Predictions Mean           -573.915
trainer/Q1 Predictions Std              30.606
trainer/Q1 Predictions Max            -442.335
trainer/Q1 Predictions Min            -638.057
trainer/Q2 Predictions Mean           -573.897
trainer/Q2 Predictions Std              30.5854
trainer/Q2 Predictions Max            -442.383
trainer/Q2 Predictions Min            -638.713
trainer/Q Targets Mean                -571.61
trainer/Q Targets Std                   58.895
trainer/Q Targets Max                   -5.23112
trainer/Q Targets Min                 -640.293
trainer/Log Pis Mean                     2.01076
trainer/Log Pis Std                      2.70978
trainer/Log Pis Max                     10.0186
trainer/Log Pis Min                     -3.86547
trainer/policy/mean Mean                 0.154995
trainer/policy/mean Std                  0.772803
trainer/policy/mean Max                  0.999361
trainer/policy/mean Min                 -0.969241
trainer/policy/normal/std Mean           0.649566
trainer/policy/normal/std Std            0.263951
trainer/policy/normal/std Max            0.96072
trainer/policy/normal/std Min            0.214953
trainer/policy/normal/log_std Mean      -0.529515
trainer/policy/normal/log_std Std        0.461935
trainer/policy/normal/log_std Max       -0.0400718
trainer/policy/normal/log_std Min       -1.53733
trainer/Alpha                            0.0310014
trainer/Alpha Loss                       0.037369
exploration/num steps total         240000
exploration/num paths total           1200
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.65447
exploration/Rewards Std                  0.751702
exploration/Rewards Max                 -3.4012
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1130.89
exploration/Returns Std                146.302
exploration/Returns Max               -695.948
exploration/Returns Min              -1207.14
exploration/Actions Mean                 0.216771
exploration/Actions Std                  0.807496
exploration/Actions Max                  0.999631
exploration/Actions Min                 -0.999674
exploration/Num Paths                   10
exploration/Average Returns          -1130.89
evaluation/num steps total          574056
evaluation/num paths total            2856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.968
evaluation/Rewards Std                   0.520271
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1199.57
evaluation/Returns Std                 101.078
evaluation/Returns Max                -715.096
evaluation/Returns Min               -1221.75
evaluation/Actions Mean                  0.145218
evaluation/Actions Std                   0.812899
evaluation/Actions Max                   0.998733
evaluation/Actions Min                  -0.958441
evaluation/Num Paths                    24
evaluation/Average Returns           -1199.57
time/data storing (s)                    0.0285989
time/evaluation sampling (s)            11.4786
time/exploration sampling (s)            4.71258
time/logging (s)                         0.0225226
time/sac training (s)                   11.9943
time/saving (s)                          0.0261462
time/training (s)                        0.000119916
time/epoch (s)                          28.2628
time/total (s)                        3720
Epoch                                  118
----------------------------------  ----------------
2020-11-09 14:24:24.588277 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 119 finished
----------------------------------  ---------------
replay_buffer/size                  242000
trainer/num train calls             120000
trainer/QF1 Loss                      2495.13
trainer/QF2 Loss                      2494.68
trainer/Policy Loss                    570.701
trainer/Q1 Predictions Mean           -570.688
trainer/Q1 Predictions Std              33.4552
trainer/Q1 Predictions Max            -431.297
trainer/Q1 Predictions Min            -661.599
trainer/Q2 Predictions Mean           -570.676
trainer/Q2 Predictions Std              33.4681
trainer/Q2 Predictions Max            -431.121
trainer/Q2 Predictions Min            -662.245
trainer/Q Targets Mean                -568.096
trainer/Q Targets Std                   60.245
trainer/Q Targets Max                   -5.22655
trainer/Q Targets Min                 -661.872
trainer/Log Pis Mean                    -0.426853
trainer/Log Pis Std                      1.4576
trainer/Log Pis Max                      4.13927
trainer/Log Pis Min                     -4.81286
trainer/policy/mean Mean                 0.353485
trainer/policy/mean Std                  0.424217
trainer/policy/mean Max                  0.992473
trainer/policy/mean Min                 -0.662925
trainer/policy/normal/std Mean           0.798402
trainer/policy/normal/std Std            0.0892173
trainer/policy/normal/std Max            0.948488
trainer/policy/normal/std Min            0.60372
trainer/policy/normal/log_std Mean      -0.231562
trainer/policy/normal/log_std Std        0.114116
trainer/policy/normal/log_std Max       -0.0528861
trainer/policy/normal/log_std Min       -0.504645
trainer/Alpha                            0.0303157
trainer/Alpha Loss                      -8.48449
exploration/num steps total         242000
exploration/num paths total           1210
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.61835
exploration/Rewards Std                  0.666419
exploration/Rewards Max                 -3.29754
exploration/Rewards Min                 -6.14172
exploration/Returns Mean             -1123.67
exploration/Returns Std                104.944
exploration/Returns Max               -815.567
exploration/Returns Min              -1186.15
exploration/Actions Mean                 0.285608
exploration/Actions Std                  0.588319
exploration/Actions Max                  0.999576
exploration/Actions Min                 -0.993324
exploration/Num Paths                   10
exploration/Average Returns          -1123.67
evaluation/num steps total          578880
evaluation/num paths total            2880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61938
evaluation/Rewards Std                   0.750341
evaluation/Rewards Max                  -3.3242
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1129.5
evaluation/Returns Std                 131.609
evaluation/Returns Max                -710.884
evaluation/Returns Min               -1196.34
evaluation/Actions Mean                  0.34896
evaluation/Actions Std                   0.442975
evaluation/Actions Max                   0.982597
evaluation/Actions Min                  -0.60347
evaluation/Num Paths                    24
evaluation/Average Returns           -1129.5
time/data storing (s)                    0.0273517
time/evaluation sampling (s)            10.8549
time/exploration sampling (s)            4.71115
time/logging (s)                         0.0233675
time/sac training (s)                   12.9352
time/saving (s)                          0.0193845
time/training (s)                        9.9903e-05
time/epoch (s)                          28.5715
time/total (s)                        3749.74
Epoch                                  119
----------------------------------  ---------------
2020-11-09 14:24:55.332059 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 120 finished
----------------------------------  ----------------
replay_buffer/size                  244000
trainer/num train calls             121000
trainer/QF1 Loss                      2626.7
trainer/QF2 Loss                      2638.9
trainer/Policy Loss                    574.233
trainer/Q1 Predictions Mean           -574.31
trainer/Q1 Predictions Std              26.9565
trainer/Q1 Predictions Max            -458.907
trainer/Q1 Predictions Min            -620.62
trainer/Q2 Predictions Mean           -574.29
trainer/Q2 Predictions Std              26.972
trainer/Q2 Predictions Max            -458.856
trainer/Q2 Predictions Min            -620.924
trainer/Q Targets Mean                -572.004
trainer/Q Targets Std                   57.5578
trainer/Q Targets Max                   -3.98132
trainer/Q Targets Min                 -622.682
trainer/Log Pis Mean                     0.643209
trainer/Log Pis Std                      2.0394
trainer/Log Pis Max                      7.46826
trainer/Log Pis Min                     -7.56356
trainer/policy/mean Mean                 0.217176
trainer/policy/mean Std                  0.638123
trainer/policy/mean Max                  0.998202
trainer/policy/mean Min                 -0.927311
trainer/policy/normal/std Mean           0.638235
trainer/policy/normal/std Std            0.120415
trainer/policy/normal/std Max            0.81085
trainer/policy/normal/std Min            0.33757
trainer/policy/normal/log_std Mean      -0.469041
trainer/policy/normal/log_std Std        0.206197
trainer/policy/normal/log_std Max       -0.209672
trainer/policy/normal/log_std Min       -1.08598
trainer/Alpha                            0.0293578
trainer/Alpha Loss                      -4.78703
exploration/num steps total         244000
exploration/num paths total           1220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.79493
exploration/Rewards Std                  0.245252
exploration/Rewards Max                 -4.44898
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1158.99
exploration/Returns Std                 36.8838
exploration/Returns Max              -1088.32
exploration/Returns Min              -1192.79
exploration/Actions Mean                 0.236633
exploration/Actions Std                  0.682533
exploration/Actions Max                  0.998699
exploration/Actions Min                 -0.995122
exploration/Num Paths                   10
exploration/Average Returns          -1158.99
evaluation/num steps total          583704
evaluation/num paths total            2904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73916
evaluation/Rewards Std                   0.693818
evaluation/Rewards Max                  -3.40107
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1153.57
evaluation/Returns Std                 135.659
evaluation/Returns Max                -700.654
evaluation/Returns Min               -1208.2
evaluation/Actions Mean                  0.23903
evaluation/Actions Std                   0.609054
evaluation/Actions Max                   0.995183
evaluation/Actions Min                  -0.893687
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.57
time/data storing (s)                    0.0210128
time/evaluation sampling (s)            11.0506
time/exploration sampling (s)            5.89245
time/logging (s)                         0.0225007
time/sac training (s)                   12.5254
time/saving (s)                          0.0179059
time/training (s)                        0.000101808
time/epoch (s)                          29.5299
time/total (s)                        3780.46
Epoch                                  120
----------------------------------  ----------------
2020-11-09 14:25:31.922849 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 121 finished
----------------------------------  ---------------
replay_buffer/size                  246000
trainer/num train calls             122000
trainer/QF1 Loss                      2314.59
trainer/QF2 Loss                      2319.84
trainer/Policy Loss                    572.89
trainer/Q1 Predictions Mean           -572.888
trainer/Q1 Predictions Std              28.9278
trainer/Q1 Predictions Max            -453.931
trainer/Q1 Predictions Min            -629.531
trainer/Q2 Predictions Mean           -572.887
trainer/Q2 Predictions Std              28.909
trainer/Q2 Predictions Max            -453.756
trainer/Q2 Predictions Min            -629.294
trainer/Q Targets Mean                -570.781
trainer/Q Targets Std                   58.1329
trainer/Q Targets Max                   -2.82399
trainer/Q Targets Min                 -631.002
trainer/Log Pis Mean                     0.545155
trainer/Log Pis Std                      2.26154
trainer/Log Pis Max                      7.64525
trainer/Log Pis Min                     -3.77885
trainer/policy/mean Mean                 0.142919
trainer/policy/mean Std                  0.666224
trainer/policy/mean Max                  0.998228
trainer/policy/mean Min                 -0.964374
trainer/policy/normal/std Mean           0.647863
trainer/policy/normal/std Std            0.099444
trainer/policy/normal/std Max            0.815107
trainer/policy/normal/std Min            0.365188
trainer/policy/normal/log_std Mean      -0.447291
trainer/policy/normal/log_std Std        0.167692
trainer/policy/normal/log_std Max       -0.204436
trainer/policy/normal/log_std Min       -1.00734
trainer/Alpha                            0.0285938
trainer/Alpha Loss                      -5.17134
exploration/num steps total         246000
exploration/num paths total           1230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.75869
exploration/Rewards Std                  0.197252
exploration/Rewards Max                 -5.26878
exploration/Rewards Min                 -6.14145
exploration/Returns Mean             -1151.74
exploration/Returns Std                 20.1543
exploration/Returns Max              -1100.67
exploration/Returns Min              -1171.7
exploration/Actions Mean                 0.164068
exploration/Actions Std                  0.63522
exploration/Actions Max                  0.999532
exploration/Actions Min                 -0.993852
exploration/Num Paths                   10
exploration/Average Returns          -1151.74
evaluation/num steps total          588528
evaluation/num paths total            2928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.93848
evaluation/Rewards Std                   0.0978137
evaluation/Rewards Max                  -4.19222
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1193.63
evaluation/Returns Std                  11.6946
evaluation/Returns Max               -1169.2
evaluation/Returns Min               -1207.7
evaluation/Actions Mean                  0.164566
evaluation/Actions Std                   0.681445
evaluation/Actions Max                   0.991383
evaluation/Actions Min                  -0.917455
evaluation/Num Paths                    24
evaluation/Average Returns           -1193.63
time/data storing (s)                    0.0258529
time/evaluation sampling (s)            13.9884
time/exploration sampling (s)            6.11691
time/logging (s)                         0.0271823
time/sac training (s)                   15.1232
time/saving (s)                          0.0276837
time/training (s)                        0.00010936
time/epoch (s)                          35.3093
time/total (s)                        3817.03
Epoch                                  121
----------------------------------  ---------------
2020-11-09 14:26:13.491659 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 122 finished
----------------------------------  ----------------
replay_buffer/size                  248000
trainer/num train calls             123000
trainer/QF1 Loss                        25.8792
trainer/QF2 Loss                        25.5474
trainer/Policy Loss                    573.535
trainer/Q1 Predictions Mean           -573.533
trainer/Q1 Predictions Std              31.2764
trainer/Q1 Predictions Max            -446.377
trainer/Q1 Predictions Min            -663.784
trainer/Q2 Predictions Mean           -573.58
trainer/Q2 Predictions Std              31.3181
trainer/Q2 Predictions Max            -446.907
trainer/Q2 Predictions Min            -664.572
trainer/Q Targets Mean                -576.49
trainer/Q Targets Std                   31.4397
trainer/Q Targets Max                 -447.812
trainer/Q Targets Min                 -664.499
trainer/Log Pis Mean                     0.796314
trainer/Log Pis Std                      2.48276
trainer/Log Pis Max                      8.67023
trainer/Log Pis Min                     -4.45215
trainer/policy/mean Mean                 0.0823512
trainer/policy/mean Std                  0.71321
trainer/policy/mean Max                  0.997369
trainer/policy/mean Min                 -0.98027
trainer/policy/normal/std Mean           0.660232
trainer/policy/normal/std Std            0.0699622
trainer/policy/normal/std Max            0.827185
trainer/policy/normal/std Min            0.483308
trainer/policy/normal/log_std Mean      -0.420859
trainer/policy/normal/log_std Std        0.107189
trainer/policy/normal/log_std Max       -0.189727
trainer/policy/normal/log_std Min       -0.727101
trainer/Alpha                            0.0279537
trainer/Alpha Loss                      -4.30583
exploration/num steps total         248000
exploration/num paths total           1240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.09153
exploration/Rewards Std                  1.03695
exploration/Rewards Max                 -3.25602
exploration/Rewards Min                 -6.14169
exploration/Returns Mean             -1018.31
exploration/Returns Std                172.772
exploration/Returns Max               -701.749
exploration/Returns Min              -1186.42
exploration/Actions Mean                 0.0730776
exploration/Actions Std                  0.781564
exploration/Actions Max                  0.999687
exploration/Actions Min                 -0.998544
exploration/Num Paths                   10
exploration/Average Returns          -1018.31
evaluation/num steps total          593352
evaluation/num paths total            2952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61248
evaluation/Rewards Std                   0.855117
evaluation/Rewards Max                  -3.28854
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1128.11
evaluation/Returns Std                 154
evaluation/Returns Max                -722.621
evaluation/Returns Min               -1210.46
evaluation/Actions Mean                  0.0822185
evaluation/Actions Std                   0.771227
evaluation/Actions Max                   0.991146
evaluation/Actions Min                  -0.957639
evaluation/Num Paths                    24
evaluation/Average Returns           -1128.11
time/data storing (s)                    0.0273246
time/evaluation sampling (s)            18.5823
time/exploration sampling (s)            7.76588
time/logging (s)                         0.0290264
time/sac training (s)                   13.9303
time/saving (s)                          0.0226311
time/training (s)                        0.000116764
time/epoch (s)                          40.3575
time/total (s)                        3858.57
Epoch                                  122
----------------------------------  ----------------
2020-11-09 14:26:46.535913 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 123 finished
----------------------------------  ---------------
replay_buffer/size                  250000
trainer/num train calls             124000
trainer/QF1 Loss                      1204.2
trainer/QF2 Loss                      1204.5
trainer/Policy Loss                    573.067
trainer/Q1 Predictions Mean           -572.947
trainer/Q1 Predictions Std              30.2436
trainer/Q1 Predictions Max            -404.151
trainer/Q1 Predictions Min            -627.663
trainer/Q2 Predictions Mean           -572.964
trainer/Q2 Predictions Std              30.2377
trainer/Q2 Predictions Max            -404.38
trainer/Q2 Predictions Min            -627.434
trainer/Q Targets Mean                -573.321
trainer/Q Targets Std                   47.0713
trainer/Q Targets Max                   -5.09114
trainer/Q Targets Min                 -629.332
trainer/Log Pis Mean                     0.0239288
trainer/Log Pis Std                      2.01577
trainer/Log Pis Max                      7.83061
trainer/Log Pis Min                     -3.74588
trainer/policy/mean Mean                -0.142315
trainer/policy/mean Std                  0.626607
trainer/policy/mean Max                  0.985779
trainer/policy/mean Min                 -0.994341
trainer/policy/normal/std Mean           0.67918
trainer/policy/normal/std Std            0.0764375
trainer/policy/normal/std Max            0.86188
trainer/policy/normal/std Min            0.479989
trainer/policy/normal/log_std Mean      -0.393351
trainer/policy/normal/log_std Std        0.114686
trainer/policy/normal/log_std Max       -0.148639
trainer/policy/normal/log_std Min       -0.733991
trainer/Alpha                            0.02724
trainer/Alpha Loss                      -7.11992
exploration/num steps total         250000
exploration/num paths total           1250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.03015
exploration/Rewards Std                  0.831071
exploration/Rewards Max                 -3.21281
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1006.03
exploration/Returns Std                115.187
exploration/Returns Max               -742.217
exploration/Returns Min              -1117.97
exploration/Actions Mean                -0.110116
exploration/Actions Std                  0.715576
exploration/Actions Max                  0.999123
exploration/Actions Min                 -0.99966
exploration/Num Paths                   10
exploration/Average Returns          -1006.03
evaluation/num steps total          598176
evaluation/num paths total            2976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.86809
evaluation/Rewards Std                   0.130373
evaluation/Rewards Max                  -5.28954
evaluation/Rewards Min                  -6.14195
evaluation/Returns Mean              -1179.49
evaluation/Returns Std                  15.579
evaluation/Returns Max               -1145
evaluation/Returns Min               -1202.3
evaluation/Actions Mean                 -0.126632
evaluation/Actions Std                   0.659816
evaluation/Actions Max                   0.855185
evaluation/Actions Min                  -0.935724
evaluation/Num Paths                    24
evaluation/Average Returns           -1179.49
time/data storing (s)                    0.0237207
time/evaluation sampling (s)            13.3674
time/exploration sampling (s)            5.72172
time/logging (s)                         0.01638
time/sac training (s)                   12.7188
time/saving (s)                          0.0176532
time/training (s)                        0.00011585
time/epoch (s)                          31.8658
time/total (s)                        3891.58
Epoch                                  123
----------------------------------  ---------------
2020-11-09 14:27:17.077809 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 124 finished
----------------------------------  ---------------
replay_buffer/size                  252000
trainer/num train calls             125000
trainer/QF1 Loss                        15.5987
trainer/QF2 Loss                        15.6453
trainer/Policy Loss                    571.223
trainer/Q1 Predictions Mean           -571.338
trainer/Q1 Predictions Std              30.0648
trainer/Q1 Predictions Max            -428.947
trainer/Q1 Predictions Min            -655.575
trainer/Q2 Predictions Mean           -571.328
trainer/Q2 Predictions Std              30.0741
trainer/Q2 Predictions Max            -429.149
trainer/Q2 Predictions Min            -656.562
trainer/Q Targets Mean                -574.126
trainer/Q Targets Std                   30.3429
trainer/Q Targets Max                 -429.828
trainer/Q Targets Min                 -657.354
trainer/Log Pis Mean                     0.149598
trainer/Log Pis Std                      1.58378
trainer/Log Pis Max                      4.431
trainer/Log Pis Min                     -4.36349
trainer/policy/mean Mean                 0.585529
trainer/policy/mean Std                  0.312758
trainer/policy/mean Max                  0.998036
trainer/policy/mean Min                 -0.412637
trainer/policy/normal/std Mean           0.750203
trainer/policy/normal/std Std            0.153075
trainer/policy/normal/std Max            1.00731
trainer/policy/normal/std Min            0.390039
trainer/policy/normal/log_std Mean      -0.310257
trainer/policy/normal/log_std Std        0.219112
trainer/policy/normal/log_std Max        0.00728546
trainer/policy/normal/log_std Min       -0.941509
trainer/Alpha                            0.0266452
trainer/Alpha Loss                      -6.70798
exploration/num steps total         252000
exploration/num paths total           1260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.85368
exploration/Rewards Std                  0.179832
exploration/Rewards Max                 -5.34438
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1170.74
exploration/Returns Std                 29.2503
exploration/Returns Max              -1108.08
exploration/Returns Min              -1198.18
exploration/Actions Mean                 0.492218
exploration/Actions Std                  0.507433
exploration/Actions Max                  0.998797
exploration/Actions Min                 -0.991261
exploration/Num Paths                   10
exploration/Average Returns          -1170.74
evaluation/num steps total          603000
evaluation/num paths total            3000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.69322
evaluation/Rewards Std                   0.689762
evaluation/Rewards Max                  -3.33192
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1144.34
evaluation/Returns Std                 128.627
evaluation/Returns Max                -704.444
evaluation/Returns Min               -1208.27
evaluation/Actions Mean                  0.58936
evaluation/Actions Std                   0.312527
evaluation/Actions Max                   0.981685
evaluation/Actions Min                  -0.353174
evaluation/Num Paths                    24
evaluation/Average Returns           -1144.34
time/data storing (s)                    0.0225633
time/evaluation sampling (s)            12.2922
time/exploration sampling (s)            5.01836
time/logging (s)                         0.017503
time/sac training (s)                   12.041
time/saving (s)                          0.0200538
time/training (s)                        9.3139e-05
time/epoch (s)                          29.4118
time/total (s)                        3922.1
Epoch                                  124
----------------------------------  ---------------
2020-11-09 14:27:44.940618 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 125 finished
----------------------------------  ----------------
replay_buffer/size                  254000
trainer/num train calls             126000
trainer/QF1 Loss                      2759.08
trainer/QF2 Loss                      2759.87
trainer/Policy Loss                    570.771
trainer/Q1 Predictions Mean           -571.269
trainer/Q1 Predictions Std              32.4924
trainer/Q1 Predictions Max            -445.388
trainer/Q1 Predictions Min            -665.261
trainer/Q2 Predictions Mean           -571.275
trainer/Q2 Predictions Std              32.493
trainer/Q2 Predictions Max            -445.186
trainer/Q2 Predictions Min            -666.238
trainer/Q Targets Mean                -569.821
trainer/Q Targets Std                   59.8097
trainer/Q Targets Max                   -5.67963
trainer/Q Targets Min                 -667.532
trainer/Log Pis Mean                     1.22106
trainer/Log Pis Std                      2.77656
trainer/Log Pis Max                      8.61374
trainer/Log Pis Min                     -7.04269
trainer/policy/mean Mean                -0.0139531
trainer/policy/mean Std                  0.770811
trainer/policy/mean Max                  0.99771
trainer/policy/mean Min                 -0.991778
trainer/policy/normal/std Mean           0.633792
trainer/policy/normal/std Std            0.0798561
trainer/policy/normal/std Max            0.868728
trainer/policy/normal/std Min            0.452045
trainer/policy/normal/log_std Mean      -0.463913
trainer/policy/normal/log_std Std        0.125492
trainer/policy/normal/log_std Max       -0.140725
trainer/policy/normal/log_std Min       -0.793973
trainer/Alpha                            0.0257141
trainer/Alpha Loss                      -2.85147
exploration/num steps total         254000
exploration/num paths total           1270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.15273
exploration/Rewards Std                  0.778597
exploration/Rewards Max                 -3.2962
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1030.55
exploration/Returns Std                122.286
exploration/Returns Max               -709.351
exploration/Returns Min              -1135.32
exploration/Actions Mean                -0.00473833
exploration/Actions Std                  0.787723
exploration/Actions Max                  0.99964
exploration/Actions Min                 -0.99899
exploration/Num Paths                   10
exploration/Average Returns          -1030.55
evaluation/num steps total          607824
evaluation/num paths total            3024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.88894
evaluation/Rewards Std                   0.114342
evaluation/Rewards Max                  -5.2662
evaluation/Rewards Min                  -6.14195
evaluation/Returns Mean              -1183.68
evaluation/Returns Std                  15.1188
evaluation/Returns Max               -1145.88
evaluation/Returns Min               -1203.5
evaluation/Actions Mean                  0.00152257
evaluation/Actions Std                   0.79901
evaluation/Actions Max                   0.964852
evaluation/Actions Min                  -0.934849
evaluation/Num Paths                    24
evaluation/Average Returns           -1183.68
time/data storing (s)                    0.0202444
time/evaluation sampling (s)            10.8921
time/exploration sampling (s)            4.38894
time/logging (s)                         0.0169369
time/sac training (s)                   11.4377
time/saving (s)                          0.0229055
time/training (s)                        0.000113223
time/epoch (s)                          26.7789
time/total (s)                        3949.94
Epoch                                  125
----------------------------------  ----------------
2020-11-09 14:28:14.871461 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 126 finished
----------------------------------  ----------------
replay_buffer/size                  256000
trainer/num train calls             127000
trainer/QF1 Loss                       970.469
trainer/QF2 Loss                       969.76
trainer/Policy Loss                    572.751
trainer/Q1 Predictions Mean           -572.888
trainer/Q1 Predictions Std              32.3698
trainer/Q1 Predictions Max            -444.432
trainer/Q1 Predictions Min            -619.624
trainer/Q2 Predictions Mean           -572.871
trainer/Q2 Predictions Std              32.3578
trainer/Q2 Predictions Max            -444.409
trainer/Q2 Predictions Min            -619.591
trainer/Q Targets Mean                -573.641
trainer/Q Targets Std                   48.3743
trainer/Q Targets Max                   -4.50558
trainer/Q Targets Min                 -621.474
trainer/Log Pis Mean                     1.3002
trainer/Log Pis Std                      2.18762
trainer/Log Pis Max                      8.31589
trainer/Log Pis Min                     -5.91841
trainer/policy/mean Mean                -0.194395
trainer/policy/mean Std                  0.73582
trainer/policy/mean Max                  0.980989
trainer/policy/mean Min                 -0.997062
trainer/policy/normal/std Mean           0.645257
trainer/policy/normal/std Std            0.100203
trainer/policy/normal/std Max            0.902059
trainer/policy/normal/std Min            0.428662
trainer/policy/normal/log_std Mean      -0.450106
trainer/policy/normal/log_std Std        0.154928
trainer/policy/normal/log_std Max       -0.103076
trainer/policy/normal/log_std Min       -0.847087
trainer/Alpha                            0.0255403
trainer/Alpha Loss                      -2.56651
exploration/num steps total         256000
exploration/num paths total           1280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.64846
exploration/Rewards Std                  0.948396
exploration/Rewards Max                 -2.76497
exploration/Rewards Min                 -6.14199
exploration/Returns Mean              -929.692
exploration/Returns Std                119.696
exploration/Returns Max               -680.675
exploration/Returns Min              -1081.88
exploration/Actions Mean                -0.209606
exploration/Actions Std                  0.741064
exploration/Actions Max                  0.99864
exploration/Actions Min                 -0.999776
exploration/Num Paths                   10
exploration/Average Returns           -929.692
evaluation/num steps total          612648
evaluation/num paths total            3048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9713
evaluation/Rewards Std                   0.0849184
evaluation/Rewards Max                  -5.71913
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1200.23
evaluation/Returns Std                  16.172
evaluation/Returns Max               -1152.79
evaluation/Returns Min               -1220.18
evaluation/Actions Mean                 -0.165246
evaluation/Actions Std                   0.753685
evaluation/Actions Max                   0.834146
evaluation/Actions Min                  -0.969106
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.23
time/data storing (s)                    0.0201742
time/evaluation sampling (s)            11.5789
time/exploration sampling (s)            4.74378
time/logging (s)                         0.0194745
time/sac training (s)                   12.3661
time/saving (s)                          0.0206742
time/training (s)                        0.000119037
time/epoch (s)                          28.7492
time/total (s)                        3979.85
Epoch                                  126
----------------------------------  ----------------
2020-11-09 14:28:42.790816 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 127 finished
----------------------------------  ---------------
replay_buffer/size                  258000
trainer/num train calls             128000
trainer/QF1 Loss                         8.31456
trainer/QF2 Loss                         8.40726
trainer/Policy Loss                    572.667
trainer/Q1 Predictions Mean           -572.937
trainer/Q1 Predictions Std              29.1665
trainer/Q1 Predictions Max            -449.066
trainer/Q1 Predictions Min            -620.573
trainer/Q2 Predictions Mean           -572.934
trainer/Q2 Predictions Std              29.1759
trainer/Q2 Predictions Max            -449.043
trainer/Q2 Predictions Min            -620.559
trainer/Q Targets Mean                -575.338
trainer/Q Targets Std                   29.3995
trainer/Q Targets Max                 -450.027
trainer/Q Targets Min                 -625.629
trainer/Log Pis Mean                     0.786424
trainer/Log Pis Std                      1.98917
trainer/Log Pis Max                      7.10698
trainer/Log Pis Min                     -5.14567
trainer/policy/mean Mean                -0.411712
trainer/policy/mean Std                  0.567482
trainer/policy/mean Max                  0.952314
trainer/policy/mean Min                 -0.996459
trainer/policy/normal/std Mean           0.537915
trainer/policy/normal/std Std            0.0726441
trainer/policy/normal/std Max            0.69139
trainer/policy/normal/std Min            0.31203
trainer/policy/normal/log_std Mean      -0.630007
trainer/policy/normal/log_std Std        0.14457
trainer/policy/normal/log_std Max       -0.369051
trainer/policy/normal/log_std Min       -1.16466
trainer/Alpha                            0.0246171
trainer/Alpha Loss                      -4.49547
exploration/num steps total         258000
exploration/num paths total           1290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.64441
exploration/Rewards Std                  0.98127
exploration/Rewards Max                 -0.253589
exploration/Rewards Min                 -6.14178
exploration/Returns Mean              -928.882
exploration/Returns Std                 97.1941
exploration/Returns Max               -713.423
exploration/Returns Min              -1020.75
exploration/Actions Mean                -0.425947
exploration/Actions Std                  0.514741
exploration/Actions Max                  0.956883
exploration/Actions Min                 -0.997773
exploration/Num Paths                   10
exploration/Average Returns           -928.882
evaluation/num steps total          617472
evaluation/num paths total            3072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.92392
evaluation/Rewards Std                   0.230493
evaluation/Rewards Max                  -4.54931
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1190.71
evaluation/Returns Std                  43.6776
evaluation/Returns Max               -1029.25
evaluation/Returns Min               -1220.46
evaluation/Actions Mean                 -0.390356
evaluation/Actions Std                   0.526089
evaluation/Actions Max                   0.377567
evaluation/Actions Min                  -0.951695
evaluation/Num Paths                    24
evaluation/Average Returns           -1190.71
time/data storing (s)                    0.0234299
time/evaluation sampling (s)            10.2792
time/exploration sampling (s)            4.95599
time/logging (s)                         0.0173579
time/sac training (s)                   11.5122
time/saving (s)                          0.0200976
time/training (s)                        9.2396e-05
time/epoch (s)                          26.8085
time/total (s)                        4007.74
Epoch                                  127
----------------------------------  ---------------
2020-11-09 14:29:15.668026 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 128 finished
----------------------------------  ---------------
replay_buffer/size                  260000
trainer/num train calls             129000
trainer/QF1 Loss                      2385.18
trainer/QF2 Loss                      2387.34
trainer/Policy Loss                    573.64
trainer/Q1 Predictions Mean           -573.617
trainer/Q1 Predictions Std              27.4494
trainer/Q1 Predictions Max            -430.669
trainer/Q1 Predictions Min            -632.908
trainer/Q2 Predictions Mean           -573.612
trainer/Q2 Predictions Std              27.4898
trainer/Q2 Predictions Max            -430.517
trainer/Q2 Predictions Min            -633.08
trainer/Q Targets Mean                -571.653
trainer/Q Targets Std                   57.5211
trainer/Q Targets Max                   -4.43341
trainer/Q Targets Min                 -633.345
trainer/Log Pis Mean                     0.680868
trainer/Log Pis Std                      2.60043
trainer/Log Pis Max                      9.3439
trainer/Log Pis Min                     -4.55741
trainer/policy/mean Mean                -0.108129
trainer/policy/mean Std                  0.681419
trainer/policy/mean Max                  0.998389
trainer/policy/mean Min                 -0.984599
trainer/policy/normal/std Mean           0.634741
trainer/policy/normal/std Std            0.117303
trainer/policy/normal/std Max            0.764646
trainer/policy/normal/std Min            0.334151
trainer/policy/normal/log_std Mean      -0.474174
trainer/policy/normal/log_std Std        0.205496
trainer/policy/normal/log_std Max       -0.268342
trainer/policy/normal/log_std Min       -1.09616
trainer/Alpha                            0.0239453
trainer/Alpha Loss                      -4.92298
exploration/num steps total         260000
exploration/num paths total           1300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.03948
exploration/Rewards Std                  0.935702
exploration/Rewards Max                 -3.32441
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1007.9
exploration/Returns Std                159.499
exploration/Returns Max               -699.951
exploration/Returns Min              -1161.44
exploration/Actions Mean                -0.0877979
exploration/Actions Std                  0.723671
exploration/Actions Max                  0.999514
exploration/Actions Min                 -0.999467
exploration/Num Paths                   10
exploration/Average Returns          -1007.9
evaluation/num steps total          622296
evaluation/num paths total            3096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8716
evaluation/Rewards Std                   0.146269
evaluation/Rewards Max                  -3.93761
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1180.19
evaluation/Returns Std                  14.0815
evaluation/Returns Max               -1143.2
evaluation/Returns Min               -1202.46
evaluation/Actions Mean                 -0.0807301
evaluation/Actions Std                   0.66863
evaluation/Actions Max                   0.993682
evaluation/Actions Min                  -0.961446
evaluation/Num Paths                    24
evaluation/Average Returns           -1180.19
time/data storing (s)                    0.0241321
time/evaluation sampling (s)            13.7439
time/exploration sampling (s)            6.25192
time/logging (s)                         0.0161591
time/sac training (s)                   11.6791
time/saving (s)                          0.0207425
time/training (s)                        9.3944e-05
time/epoch (s)                          31.736
time/total (s)                        4040.6
Epoch                                  128
----------------------------------  ---------------
2020-11-09 14:29:48.698531 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 129 finished
----------------------------------  ----------------
replay_buffer/size                  262000
trainer/num train calls             130000
trainer/QF1 Loss                      1189.29
trainer/QF2 Loss                      1189.23
trainer/Policy Loss                    573.988
trainer/Q1 Predictions Mean           -573.9
trainer/Q1 Predictions Std              28.5906
trainer/Q1 Predictions Max            -438.526
trainer/Q1 Predictions Min            -667.177
trainer/Q2 Predictions Mean           -573.909
trainer/Q2 Predictions Std              28.622
trainer/Q2 Predictions Max            -438.348
trainer/Q2 Predictions Min            -668.127
trainer/Q Targets Mean                -574.638
trainer/Q Targets Std                   46.0614
trainer/Q Targets Max                   -4.82811
trainer/Q Targets Min                 -668.546
trainer/Log Pis Mean                     0.698424
trainer/Log Pis Std                      2.79593
trainer/Log Pis Max                      9.66738
trainer/Log Pis Min                     -5.97505
trainer/policy/mean Mean                -0.102109
trainer/policy/mean Std                  0.667654
trainer/policy/mean Max                  0.999421
trainer/policy/mean Min                 -0.989076
trainer/policy/normal/std Mean           0.60194
trainer/policy/normal/std Std            0.0924628
trainer/policy/normal/std Max            0.735349
trainer/policy/normal/std Min            0.357761
trainer/policy/normal/log_std Mean      -0.520433
trainer/policy/normal/log_std Std        0.163875
trainer/policy/normal/log_std Max       -0.30741
trainer/policy/normal/log_std Min       -1.02789
trainer/Alpha                            0.0232142
trainer/Alpha Loss                      -4.89782
exploration/num steps total         262000
exploration/num paths total           1310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5466
exploration/Rewards Std                  0.385315
exploration/Rewards Max                 -4.72061
exploration/Rewards Min                 -6.14138
exploration/Returns Mean             -1109.32
exploration/Returns Std                 50.928
exploration/Returns Max              -1015.73
exploration/Returns Min              -1161.12
exploration/Actions Mean                -0.110754
exploration/Actions Std                  0.675501
exploration/Actions Max                  0.998187
exploration/Actions Min                 -0.998482
exploration/Num Paths                   10
exploration/Average Returns          -1109.32
evaluation/num steps total          627120
evaluation/num paths total            3120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78386
evaluation/Rewards Std                   0.5169
evaluation/Rewards Max                  -3.3589
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1162.56
evaluation/Returns Std                  98.0322
evaluation/Returns Max                -707.205
evaluation/Returns Min               -1205.86
evaluation/Actions Mean                 -0.0860329
evaluation/Actions Std                   0.639091
evaluation/Actions Max                   0.995541
evaluation/Actions Min                  -0.959419
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.56
time/data storing (s)                    0.0218213
time/evaluation sampling (s)            13.2896
time/exploration sampling (s)            5.5555
time/logging (s)                         0.0187437
time/sac training (s)                   12.966
time/saving (s)                          0.0196349
time/training (s)                        0.000114238
time/epoch (s)                          31.8714
time/total (s)                        4073.61
Epoch                                  129
----------------------------------  ----------------
2020-11-09 14:30:20.753358 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 130 finished
----------------------------------  ---------------
replay_buffer/size                  264000
trainer/num train calls             131000
trainer/QF1 Loss                      2586.35
trainer/QF2 Loss                      2585.74
trainer/Policy Loss                    571.689
trainer/Q1 Predictions Mean           -571.795
trainer/Q1 Predictions Std              30.8558
trainer/Q1 Predictions Max            -432.48
trainer/Q1 Predictions Min            -621.337
trainer/Q2 Predictions Mean           -571.772
trainer/Q2 Predictions Std              30.853
trainer/Q2 Predictions Max            -432.596
trainer/Q2 Predictions Min            -621.385
trainer/Q Targets Mean                -569.727
trainer/Q Targets Std                   58.917
trainer/Q Targets Max                   -5.22655
trainer/Q Targets Min                 -623.156
trainer/Log Pis Mean                     2.34911
trainer/Log Pis Std                      3.14677
trainer/Log Pis Max                     11.8676
trainer/Log Pis Min                     -3.57937
trainer/policy/mean Mean                -0.159309
trainer/policy/mean Std                  0.812148
trainer/policy/mean Max                  0.999216
trainer/policy/mean Min                 -0.999026
trainer/policy/normal/std Mean           0.61113
trainer/policy/normal/std Std            0.0830767
trainer/policy/normal/std Max            0.763282
trainer/policy/normal/std Min            0.40651
trainer/policy/normal/log_std Mean      -0.502219
trainer/policy/normal/log_std Std        0.141858
trainer/policy/normal/log_std Max       -0.270128
trainer/policy/normal/log_std Min       -0.900147
trainer/Alpha                            0.0232955
trainer/Alpha Loss                       1.31247
exploration/num steps total         264000
exploration/num paths total           1320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.84759
exploration/Rewards Std                  0.862466
exploration/Rewards Max                 -3.14586
exploration/Rewards Min                 -6.14069
exploration/Returns Mean              -969.519
exploration/Returns Std                137.402
exploration/Returns Max               -679.96
exploration/Returns Min              -1081.43
exploration/Actions Mean                -0.166509
exploration/Actions Std                  0.820853
exploration/Actions Max                  0.999851
exploration/Actions Min                 -0.999738
exploration/Num Paths                   10
exploration/Average Returns           -969.519
evaluation/num steps total          631944
evaluation/num paths total            3144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79446
evaluation/Rewards Std                   0.535777
evaluation/Rewards Max                  -3.32404
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1164.69
evaluation/Returns Std                 104.605
evaluation/Returns Max                -693.779
evaluation/Returns Min               -1216.63
evaluation/Actions Mean                 -0.0705026
evaluation/Actions Std                   0.889356
evaluation/Actions Max                   0.992003
evaluation/Actions Min                  -0.992457
evaluation/Num Paths                    24
evaluation/Average Returns           -1164.69
time/data storing (s)                    0.0220866
time/evaluation sampling (s)            13.53
time/exploration sampling (s)            5.14317
time/logging (s)                         0.0177243
time/sac training (s)                   12.1677
time/saving (s)                          0.0216021
time/training (s)                        0.00015653
time/epoch (s)                          30.9025
time/total (s)                        4105.64
Epoch                                  130
----------------------------------  ---------------
2020-11-09 14:30:48.958295 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 131 finished
----------------------------------  ----------------
replay_buffer/size                  266000
trainer/num train calls             132000
trainer/QF1 Loss                      3549.82
trainer/QF2 Loss                      3550.05
trainer/Policy Loss                    569.761
trainer/Q1 Predictions Mean           -569.938
trainer/Q1 Predictions Std              34.4825
trainer/Q1 Predictions Max            -429.774
trainer/Q1 Predictions Min            -621.038
trainer/Q2 Predictions Mean           -569.93
trainer/Q2 Predictions Std              34.4868
trainer/Q2 Predictions Max            -429.971
trainer/Q2 Predictions Min            -621.293
trainer/Q Targets Mean                -565.446
trainer/Q Targets Std                   70.2243
trainer/Q Targets Max                   -4.50558
trainer/Q Targets Min                 -622.839
trainer/Log Pis Mean                     1.02085
trainer/Log Pis Std                      2.38927
trainer/Log Pis Max                      9.7942
trainer/Log Pis Min                     -3.58358
trainer/policy/mean Mean                -0.243687
trainer/policy/mean Std                  0.661298
trainer/policy/mean Max                  0.998385
trainer/policy/mean Min                 -0.993399
trainer/policy/normal/std Mean           0.564548
trainer/policy/normal/std Std            0.0874182
trainer/policy/normal/std Max            0.689755
trainer/policy/normal/std Min            0.375929
trainer/policy/normal/log_std Mean      -0.584065
trainer/policy/normal/log_std Std        0.158216
trainer/policy/normal/log_std Max       -0.371419
trainer/policy/normal/log_std Min       -0.978356
trainer/Alpha                            0.0226037
trainer/Alpha Loss                      -3.71063
exploration/num steps total         266000
exploration/num paths total           1330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.11405
exploration/Rewards Std                  0.690077
exploration/Rewards Max                 -2.74992
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1022.81
exploration/Returns Std                 59.9272
exploration/Returns Max               -925.383
exploration/Returns Min              -1101.46
exploration/Actions Mean                -0.145194
exploration/Actions Std                  0.758159
exploration/Actions Max                  0.999092
exploration/Actions Min                 -0.999741
exploration/Num Paths                   10
exploration/Average Returns          -1022.81
evaluation/num steps total          636768
evaluation/num paths total            3168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7714
evaluation/Rewards Std                   0.297986
evaluation/Rewards Max                  -4.26671
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1160.05
evaluation/Returns Std                  37.9152
evaluation/Returns Max               -1015.75
evaluation/Returns Min               -1199.84
evaluation/Actions Mean                 -0.235062
evaluation/Actions Std                   0.559162
evaluation/Actions Max                   0.948244
evaluation/Actions Min                  -0.943114
evaluation/Num Paths                    24
evaluation/Average Returns           -1160.05
time/data storing (s)                    0.0213676
time/evaluation sampling (s)            10.4919
time/exploration sampling (s)            4.53037
time/logging (s)                         0.0195906
time/sac training (s)                   11.9792
time/saving (s)                          0.022098
time/training (s)                        0.000119559
time/epoch (s)                          27.0646
time/total (s)                        4133.82
Epoch                                  131
----------------------------------  ----------------
2020-11-09 14:31:18.376678 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 132 finished
----------------------------------  ----------------
replay_buffer/size                  268000
trainer/num train calls             133000
trainer/QF1 Loss                      1379.01
trainer/QF2 Loss                      1379.18
trainer/Policy Loss                    570.659
trainer/Q1 Predictions Mean           -570.868
trainer/Q1 Predictions Std              33.6264
trainer/Q1 Predictions Max            -410.272
trainer/Q1 Predictions Min            -635.314
trainer/Q2 Predictions Mean           -570.901
trainer/Q2 Predictions Std              33.6092
trainer/Q2 Predictions Max            -410.411
trainer/Q2 Predictions Min            -635.756
trainer/Q Targets Mean                -571.199
trainer/Q Targets Std                   49.1717
trainer/Q Targets Max                   -5.8288
trainer/Q Targets Min                 -637.552
trainer/Log Pis Mean                     2.57924
trainer/Log Pis Std                      3.45515
trainer/Log Pis Max                     14.0805
trainer/Log Pis Min                     -3.99432
trainer/policy/mean Mean                -0.251317
trainer/policy/mean Std                  0.786303
trainer/policy/mean Max                  0.99972
trainer/policy/mean Min                 -0.999366
trainer/policy/normal/std Mean           0.578624
trainer/policy/normal/std Std            0.0361085
trainer/policy/normal/std Max            0.722325
trainer/policy/normal/std Min            0.436921
trainer/policy/normal/log_std Mean      -0.54907
trainer/policy/normal/log_std Std        0.062955
trainer/policy/normal/log_std Max       -0.32528
trainer/policy/normal/log_std Min       -0.828003
trainer/Alpha                            0.0226391
trainer/Alpha Loss                       2.19421
exploration/num steps total         268000
exploration/num paths total           1340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.00049
exploration/Rewards Std                  0.655238
exploration/Rewards Max                 -3.18465
exploration/Rewards Min                 -6.14093
exploration/Returns Mean             -1000.1
exploration/Returns Std                 86.2616
exploration/Returns Max               -793.989
exploration/Returns Min              -1103.37
exploration/Actions Mean                -0.240321
exploration/Actions Std                  0.802202
exploration/Actions Max                  0.999838
exploration/Actions Min                 -0.999858
exploration/Num Paths                   10
exploration/Average Returns          -1000.1
evaluation/num steps total          641592
evaluation/num paths total            3192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84255
evaluation/Rewards Std                   0.247266
evaluation/Rewards Max                  -5.04927
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1174.35
evaluation/Returns Std                  47.2216
evaluation/Returns Max               -1032.62
evaluation/Returns Min               -1215.53
evaluation/Actions Mean                 -0.152998
evaluation/Actions Std                   0.808275
evaluation/Actions Max                   0.989294
evaluation/Actions Min                  -0.990156
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.35
time/data storing (s)                    0.0225847
time/evaluation sampling (s)            10.9334
time/exploration sampling (s)            4.59026
time/logging (s)                         0.0229143
time/sac training (s)                   12.6151
time/saving (s)                          0.0186061
time/training (s)                        0.000124078
time/epoch (s)                          28.2029
time/total (s)                        4163.22
Epoch                                  132
----------------------------------  ----------------
2020-11-09 14:31:49.960516 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 133 finished
----------------------------------  ----------------
replay_buffer/size                  270000
trainer/num train calls             134000
trainer/QF1 Loss                        21.9738
trainer/QF2 Loss                        21.9666
trainer/Policy Loss                    570.742
trainer/Q1 Predictions Mean           -570.966
trainer/Q1 Predictions Std              30.2997
trainer/Q1 Predictions Max            -438.534
trainer/Q1 Predictions Min            -619.283
trainer/Q2 Predictions Mean           -570.967
trainer/Q2 Predictions Std              30.331
trainer/Q2 Predictions Max            -438.587
trainer/Q2 Predictions Min            -619.627
trainer/Q Targets Mean                -573.134
trainer/Q Targets Std                   31.5737
trainer/Q Targets Max                 -438.218
trainer/Q Targets Min                 -621.798
trainer/Log Pis Mean                     2.55687
trainer/Log Pis Std                      3.10998
trainer/Log Pis Max                     12.4935
trainer/Log Pis Min                     -4.63237
trainer/policy/mean Mean                -0.230868
trainer/policy/mean Std                  0.807195
trainer/policy/mean Max                  0.999502
trainer/policy/mean Min                 -0.998261
trainer/policy/normal/std Mean           0.562274
trainer/policy/normal/std Std            0.0237643
trainer/policy/normal/std Max            0.648074
trainer/policy/normal/std Min            0.506362
trainer/policy/normal/log_std Mean      -0.576643
trainer/policy/normal/log_std Std        0.0417164
trainer/policy/normal/log_std Max       -0.433751
trainer/policy/normal/log_std Min       -0.680502
trainer/Alpha                            0.0226986
trainer/Alpha Loss                       2.10802
exploration/num steps total         270000
exploration/num paths total           1350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.89481
exploration/Rewards Std                  0.84584
exploration/Rewards Max                 -2.37859
exploration/Rewards Min                 -6.13758
exploration/Returns Mean              -978.962
exploration/Returns Std                 87.1091
exploration/Returns Max               -824.142
exploration/Returns Min              -1128.28
exploration/Actions Mean                -0.180598
exploration/Actions Std                  0.85011
exploration/Actions Max                  0.999947
exploration/Actions Min                 -0.999866
exploration/Num Paths                   10
exploration/Average Returns           -978.962
evaluation/num steps total          646416
evaluation/num paths total            3216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.75452
evaluation/Rewards Std                   0.471669
evaluation/Rewards Max                  -3.54444
evaluation/Rewards Min                  -6.14176
evaluation/Returns Mean              -1156.66
evaluation/Returns Std                  89.4885
evaluation/Returns Max                -758.254
evaluation/Returns Min               -1219.16
evaluation/Actions Mean                 -0.12765
evaluation/Actions Std                   0.838784
evaluation/Actions Max                   0.979282
evaluation/Actions Min                  -0.984918
evaluation/Num Paths                    24
evaluation/Average Returns           -1156.66
time/data storing (s)                    0.0232337
time/evaluation sampling (s)            13.2448
time/exploration sampling (s)            5.49752
time/logging (s)                         0.0553649
time/sac training (s)                   11.6327
time/saving (s)                          0.0291412
time/training (s)                        0.000157258
time/epoch (s)                          30.4829
time/total (s)                        4194.81
Epoch                                  133
----------------------------------  ----------------
2020-11-09 14:32:21.651894 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 134 finished
----------------------------------  ----------------
replay_buffer/size                  272000
trainer/num train calls             135000
trainer/QF1 Loss                      2670.15
trainer/QF2 Loss                      2673.41
trainer/Policy Loss                    572.057
trainer/Q1 Predictions Mean           -572.159
trainer/Q1 Predictions Std              29.4063
trainer/Q1 Predictions Max            -446.017
trainer/Q1 Predictions Min            -640.795
trainer/Q2 Predictions Mean           -572.167
trainer/Q2 Predictions Std              29.4349
trainer/Q2 Predictions Max            -445.834
trainer/Q2 Predictions Min            -641.55
trainer/Q Targets Mean                -570.467
trainer/Q Targets Std                   58.3709
trainer/Q Targets Max                   -5.54683
trainer/Q Targets Min                 -643.345
trainer/Log Pis Mean                     0.311427
trainer/Log Pis Std                      1.41763
trainer/Log Pis Max                      4.1258
trainer/Log Pis Min                     -3.93489
trainer/policy/mean Mean                 0.0575007
trainer/policy/mean Std                  0.643235
trainer/policy/mean Max                  0.996189
trainer/policy/mean Min                 -0.95212
trainer/policy/normal/std Mean           0.645219
trainer/policy/normal/std Std            0.18471
trainer/policy/normal/std Max            1.22917
trainer/policy/normal/std Min            0.426045
trainer/policy/normal/log_std Mean      -0.474948
trainer/policy/normal/log_std Std        0.264629
trainer/policy/normal/log_std Max        0.206339
trainer/policy/normal/log_std Min       -0.853209
trainer/Alpha                            0.0222686
trainer/Alpha Loss                      -6.42431
exploration/num steps total         272000
exploration/num paths total           1360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.74289
exploration/Rewards Std                  0.661936
exploration/Rewards Max                 -3.30233
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1148.58
exploration/Returns Std                105.268
exploration/Returns Max               -843.435
exploration/Returns Min              -1218.6
exploration/Actions Mean                 0.086559
exploration/Actions Std                  0.659507
exploration/Actions Max                  0.998474
exploration/Actions Min                 -0.997165
exploration/Num Paths                   10
exploration/Average Returns          -1148.58
evaluation/num steps total          651240
evaluation/num paths total            3240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.08289
evaluation/Rewards Std                   0.0965428
evaluation/Rewards Max                  -5.41314
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1222.66
evaluation/Returns Std                  13.9096
evaluation/Returns Max               -1163.14
evaluation/Returns Min               -1232.75
evaluation/Actions Mean                 -0.00313874
evaluation/Actions Std                   0.438319
evaluation/Actions Max                   0.921649
evaluation/Actions Min                  -0.658317
evaluation/Num Paths                    24
evaluation/Average Returns           -1222.66
time/data storing (s)                    0.0231002
time/evaluation sampling (s)            13.3761
time/exploration sampling (s)            5.52104
time/logging (s)                         0.0194309
time/sac training (s)                   11.56
time/saving (s)                          0.0197964
time/training (s)                        0.000168404
time/epoch (s)                          30.5196
time/total (s)                        4226.44
Epoch                                  134
----------------------------------  ----------------
2020-11-09 14:32:59.599689 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 135 finished
----------------------------------  ---------------
replay_buffer/size                  274000
trainer/num train calls             136000
trainer/QF1 Loss                      1363.97
trainer/QF2 Loss                      1364.92
trainer/Policy Loss                    570.459
trainer/Q1 Predictions Mean           -570.504
trainer/Q1 Predictions Std              32.0137
trainer/Q1 Predictions Max            -434.672
trainer/Q1 Predictions Min            -618.741
trainer/Q2 Predictions Mean           -570.485
trainer/Q2 Predictions Std              31.9988
trainer/Q2 Predictions Max            -434.493
trainer/Q2 Predictions Min            -619.042
trainer/Q Targets Mean                -571.205
trainer/Q Targets Std                   48.0263
trainer/Q Targets Max                   -5.70811
trainer/Q Targets Min                 -621.121
trainer/Log Pis Mean                     2.91575
trainer/Log Pis Std                      3.48452
trainer/Log Pis Max                     11.3233
trainer/Log Pis Min                     -6.63849
trainer/policy/mean Mean                -0.0370353
trainer/policy/mean Std                  0.866059
trainer/policy/mean Max                  0.99999
trainer/policy/mean Min                 -0.995531
trainer/policy/normal/std Mean           0.632516
trainer/policy/normal/std Std            0.0387082
trainer/policy/normal/std Max            0.768181
trainer/policy/normal/std Min            0.566114
trainer/policy/normal/log_std Mean      -0.45984
trainer/policy/normal/log_std Std        0.0592016
trainer/policy/normal/log_std Max       -0.26373
trainer/policy/normal/log_std Min       -0.568959
trainer/Alpha                            0.0221796
trainer/Alpha Loss                       3.48773
exploration/num steps total         274000
exploration/num paths total           1370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.36285
exploration/Rewards Std                  0.737497
exploration/Rewards Max                 -3.39447
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1072.57
exploration/Returns Std                136.518
exploration/Returns Max               -706.75
exploration/Returns Min              -1197.61
exploration/Actions Mean                -0.0134581
exploration/Actions Std                  0.862027
exploration/Actions Max                  0.999992
exploration/Actions Min                 -0.998953
exploration/Num Paths                   10
exploration/Average Returns          -1072.57
evaluation/num steps total          656064
evaluation/num paths total            3264
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97254
evaluation/Rewards Std                   0.515071
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1200.48
evaluation/Returns Std                 100.266
evaluation/Returns Max                -719.62
evaluation/Returns Min               -1222.16
evaluation/Actions Mean                  0.0322089
evaluation/Actions Std                   0.933753
evaluation/Actions Max                   0.999084
evaluation/Actions Min                  -0.966336
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.48
time/data storing (s)                    0.0398382
time/evaluation sampling (s)            15.5809
time/exploration sampling (s)            7.50723
time/logging (s)                         0.0269942
time/sac training (s)                   13.0116
time/saving (s)                          0.025
time/training (s)                        9.7451e-05
time/epoch (s)                          36.1917
time/total (s)                        4264.37
Epoch                                  135
----------------------------------  ---------------
2020-11-09 14:33:33.988242 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 136 finished
----------------------------------  ----------------
replay_buffer/size                  276000
trainer/num train calls             137000
trainer/QF1 Loss                        16.7454
trainer/QF2 Loss                        16.6414
trainer/Policy Loss                    569.683
trainer/Q1 Predictions Mean           -569.743
trainer/Q1 Predictions Std              35.1007
trainer/Q1 Predictions Max            -415.691
trainer/Q1 Predictions Min            -666.195
trainer/Q2 Predictions Mean           -569.782
trainer/Q2 Predictions Std              35.1106
trainer/Q2 Predictions Max            -415.545
trainer/Q2 Predictions Min            -667.035
trainer/Q Targets Mean                -572.509
trainer/Q Targets Std                   35.2545
trainer/Q Targets Max                 -413.168
trainer/Q Targets Min                 -667.619
trainer/Log Pis Mean                     0.27148
trainer/Log Pis Std                      1.86372
trainer/Log Pis Max                      7.22253
trainer/Log Pis Min                     -5.40272
trainer/policy/mean Mean                -0.0418986
trainer/policy/mean Std                  0.602357
trainer/policy/mean Max                  0.998499
trainer/policy/mean Min                 -0.933291
trainer/policy/normal/std Mean           0.632813
trainer/policy/normal/std Std            0.0980859
trainer/policy/normal/std Max            0.852062
trainer/policy/normal/std Min            0.498632
trainer/policy/normal/log_std Mean      -0.469348
trainer/policy/normal/log_std Std        0.152644
trainer/policy/normal/log_std Max       -0.160097
trainer/policy/normal/log_std Min       -0.695887
trainer/Alpha                            0.021705
trainer/Alpha Loss                      -6.6206
exploration/num steps total         276000
exploration/num paths total           1380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.71647
exploration/Rewards Std                  0.451216
exploration/Rewards Max                 -3.92123
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1143.29
exploration/Returns Std                 65.2722
exploration/Returns Max               -962.111
exploration/Returns Min              -1205.44
exploration/Actions Mean                -0.0556508
exploration/Actions Std                  0.583405
exploration/Actions Max                  0.999923
exploration/Actions Min                 -0.995368
exploration/Num Paths                   10
exploration/Average Returns          -1143.29
evaluation/num steps total          660888
evaluation/num paths total            3288
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97171
evaluation/Rewards Std                   0.136821
evaluation/Rewards Max                  -5.3674
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1200.31
evaluation/Returns Std                  16.5251
evaluation/Returns Max               -1168.59
evaluation/Returns Min               -1222.63
evaluation/Actions Mean                 -0.0892103
evaluation/Actions Std                   0.360948
evaluation/Actions Max                   0.963342
evaluation/Actions Min                  -0.899091
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.31
time/data storing (s)                    0.0213349
time/evaluation sampling (s)            14.3216
time/exploration sampling (s)            5.71465
time/logging (s)                         0.0233904
time/sac training (s)                   12.9641
time/saving (s)                          0.0256184
time/training (s)                        0.000165177
time/epoch (s)                          33.0708
time/total (s)                        4298.73
Epoch                                  136
----------------------------------  ----------------
2020-11-09 14:34:05.907977 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 137 finished
----------------------------------  ----------------
replay_buffer/size                  278000
trainer/num train calls             138000
trainer/QF1 Loss                      1290.17
trainer/QF2 Loss                      1290.18
trainer/Policy Loss                    568.231
trainer/Q1 Predictions Mean           -568.382
trainer/Q1 Predictions Std              34.8778
trainer/Q1 Predictions Max            -404.124
trainer/Q1 Predictions Min            -628.341
trainer/Q2 Predictions Mean           -568.354
trainer/Q2 Predictions Std              34.9053
trainer/Q2 Predictions Max            -404.321
trainer/Q2 Predictions Min            -628.212
trainer/Q Targets Mean                -568.317
trainer/Q Targets Std                   49.9877
trainer/Q Targets Max                   -5.35388
trainer/Q Targets Min                 -629.66
trainer/Log Pis Mean                     0.731588
trainer/Log Pis Std                      1.94079
trainer/Log Pis Max                      6.96022
trainer/Log Pis Min                     -5.19798
trainer/policy/mean Mean                 0.25706
trainer/policy/mean Std                  0.63698
trainer/policy/mean Max                  0.999646
trainer/policy/mean Min                 -0.961555
trainer/policy/normal/std Mean           0.567488
trainer/policy/normal/std Std            0.0987402
trainer/policy/normal/std Max            0.856318
trainer/policy/normal/std Min            0.430027
trainer/policy/normal/log_std Mean      -0.580615
trainer/policy/normal/log_std Std        0.165007
trainer/policy/normal/log_std Max       -0.155114
trainer/policy/normal/log_std Min       -0.843907
trainer/Alpha                            0.0210417
trainer/Alpha Loss                      -4.89765
exploration/num steps total         278000
exploration/num paths total           1390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.99112
exploration/Rewards Std                  0.117593
exploration/Rewards Max                 -4.40568
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1198.22
exploration/Returns Std                 23.9852
exploration/Returns Max              -1138.88
exploration/Returns Min              -1221.86
exploration/Actions Mean                 0.225833
exploration/Actions Std                  0.60349
exploration/Actions Max                  0.998024
exploration/Actions Min                 -0.993791
exploration/Num Paths                   10
exploration/Average Returns          -1198.22
evaluation/num steps total          665712
evaluation/num paths total            3312
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83443
evaluation/Rewards Std                   0.636447
evaluation/Rewards Max                  -3.37623
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1172.72
evaluation/Returns Std                 107.156
evaluation/Returns Max                -791.243
evaluation/Returns Min               -1229.29
evaluation/Actions Mean                  0.306819
evaluation/Actions Std                   0.556202
evaluation/Actions Max                   0.990449
evaluation/Actions Min                  -0.765467
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.72
time/data storing (s)                    0.0244053
time/evaluation sampling (s)            12.8707
time/exploration sampling (s)            5.50851
time/logging (s)                         0.0202189
time/sac training (s)                   12.2561
time/saving (s)                          0.0243601
time/training (s)                        0.000212521
time/epoch (s)                          30.7045
time/total (s)                        4330.63
Epoch                                  137
----------------------------------  ----------------
2020-11-09 14:34:39.301561 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 138 finished
----------------------------------  ----------------
replay_buffer/size                  280000
trainer/num train calls             139000
trainer/QF1 Loss                      1291.79
trainer/QF2 Loss                      1293.66
trainer/Policy Loss                    570.71
trainer/Q1 Predictions Mean           -570.765
trainer/Q1 Predictions Std              31.7409
trainer/Q1 Predictions Max            -406.92
trainer/Q1 Predictions Min            -624.031
trainer/Q2 Predictions Mean           -570.743
trainer/Q2 Predictions Std              31.7199
trainer/Q2 Predictions Max            -407.172
trainer/Q2 Predictions Min            -623.984
trainer/Q Targets Mean                -570.834
trainer/Q Targets Std                   48.1259
trainer/Q Targets Max                   -5.11005
trainer/Q Targets Min                 -626.634
trainer/Log Pis Mean                     1.06072
trainer/Log Pis Std                      2.47848
trainer/Log Pis Max                     11.0387
trainer/Log Pis Min                     -3.63825
trainer/policy/mean Mean                -0.115515
trainer/policy/mean Std                  0.676895
trainer/policy/mean Max                  0.999839
trainer/policy/mean Min                 -0.980429
trainer/policy/normal/std Mean           0.551317
trainer/policy/normal/std Std            0.0586192
trainer/policy/normal/std Max            0.707048
trainer/policy/normal/std Min            0.457847
trainer/policy/normal/log_std Mean      -0.601157
trainer/policy/normal/log_std Std        0.107157
trainer/policy/normal/log_std Max       -0.346657
trainer/policy/normal/log_std Min       -0.781221
trainer/Alpha                            0.0204607
trainer/Alpha Loss                      -3.65308
exploration/num steps total         280000
exploration/num paths total           1400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.37797
exploration/Rewards Std                  0.776447
exploration/Rewards Max                 -3.35563
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1075.59
exploration/Returns Std                131.256
exploration/Returns Max               -736.056
exploration/Returns Min              -1191.6
exploration/Actions Mean                -0.0680036
exploration/Actions Std                  0.747085
exploration/Actions Max                  0.999837
exploration/Actions Min                 -0.999705
exploration/Num Paths                   10
exploration/Average Returns          -1075.59
evaluation/num steps total          670536
evaluation/num paths total            3336
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.72855
evaluation/Rewards Std                   0.689105
evaluation/Rewards Max                  -3.37062
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1151.44
evaluation/Returns Std                 129.76
evaluation/Returns Max                -718.229
evaluation/Returns Min               -1216.54
evaluation/Actions Mean                 -0.0880502
evaluation/Actions Std                   0.552382
evaluation/Actions Max                   0.99631
evaluation/Actions Min                  -0.933515
evaluation/Num Paths                    24
evaluation/Average Returns           -1151.44
time/data storing (s)                    0.0245487
time/evaluation sampling (s)            14.2583
time/exploration sampling (s)            5.53479
time/logging (s)                         0.0194765
time/sac training (s)                   12.372
time/saving (s)                          0.0224023
time/training (s)                        0.000110184
time/epoch (s)                          32.2316
time/total (s)                        4364
Epoch                                  138
----------------------------------  ----------------
2020-11-09 14:35:13.263399 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 139 finished
----------------------------------  ----------------
replay_buffer/size                  282000
trainer/num train calls             140000
trainer/QF1 Loss                      1142.79
trainer/QF2 Loss                      1141.99
trainer/Policy Loss                    568.228
trainer/Q1 Predictions Mean           -568.159
trainer/Q1 Predictions Std              34.4446
trainer/Q1 Predictions Max            -425.872
trainer/Q1 Predictions Min            -652.578
trainer/Q2 Predictions Mean           -568.173
trainer/Q2 Predictions Std              34.4547
trainer/Q2 Predictions Max            -425.78
trainer/Q2 Predictions Min            -654.326
trainer/Q Targets Mean                -569.149
trainer/Q Targets Std                   49.5093
trainer/Q Targets Max                   -5.64315
trainer/Q Targets Min                 -655.969
trainer/Log Pis Mean                     1.53262
trainer/Log Pis Std                      2.15646
trainer/Log Pis Max                      9.49687
trainer/Log Pis Min                     -3.72205
trainer/policy/mean Mean                -0.337546
trainer/policy/mean Std                  0.669508
trainer/policy/mean Max                  0.999058
trainer/policy/mean Min                 -0.993129
trainer/policy/normal/std Mean           0.547405
trainer/policy/normal/std Std            0.0731118
trainer/policy/normal/std Max            0.666548
trainer/policy/normal/std Min            0.433196
trainer/policy/normal/log_std Mean      -0.611769
trainer/policy/normal/log_std Std        0.13669
trainer/policy/normal/log_std Max       -0.405644
trainer/policy/normal/log_std Min       -0.836564
trainer/Alpha                            0.0201026
trainer/Alpha Loss                      -1.82601
exploration/num steps total         282000
exploration/num paths total           1410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.08813
exploration/Rewards Std                  0.87869
exploration/Rewards Max                 -2.61667
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1017.63
exploration/Returns Std                155.615
exploration/Returns Max               -607.256
exploration/Returns Min              -1156.33
exploration/Actions Mean                -0.316539
exploration/Actions Std                  0.671397
exploration/Actions Max                  0.999933
exploration/Actions Min                 -0.999554
exploration/Num Paths                   10
exploration/Average Returns          -1017.63
evaluation/num steps total          675360
evaluation/num paths total            3360
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79282
evaluation/Rewards Std                   0.333893
evaluation/Rewards Max                  -3.81365
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1164.36
evaluation/Returns Std                  51.345
evaluation/Returns Max                -959.301
evaluation/Returns Min               -1203.89
evaluation/Actions Mean                 -0.412485
evaluation/Actions Std                   0.480161
evaluation/Actions Max                   0.841712
evaluation/Actions Min                  -0.971142
evaluation/Num Paths                    24
evaluation/Average Returns           -1164.36
time/data storing (s)                    0.0298541
time/evaluation sampling (s)            15.6243
time/exploration sampling (s)            5.50968
time/logging (s)                         0.0205395
time/sac training (s)                   11.6307
time/saving (s)                          0.023811
time/training (s)                        0.000114702
time/epoch (s)                          32.8391
time/total (s)                        4397.93
Epoch                                  139
----------------------------------  ----------------
2020-11-09 14:35:47.954032 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 140 finished
----------------------------------  ----------------
replay_buffer/size                  284000
trainer/num train calls             141000
trainer/QF1 Loss                      7012.46
trainer/QF2 Loss                      7016.52
trainer/Policy Loss                    568.483
trainer/Q1 Predictions Mean           -568.526
trainer/Q1 Predictions Std              39.7444
trainer/Q1 Predictions Max            -390.011
trainer/Q1 Predictions Min            -668.627
trainer/Q2 Predictions Mean           -568.539
trainer/Q2 Predictions Std              39.749
trainer/Q2 Predictions Max            -389.89
trainer/Q2 Predictions Min            -669.467
trainer/Q Targets Mean                -558.382
trainer/Q Targets Std                   94.2784
trainer/Q Targets Max                   -3.28203
trainer/Q Targets Min                 -669.437
trainer/Log Pis Mean                     2.33542
trainer/Log Pis Std                      2.93111
trainer/Log Pis Max                     11.376
trainer/Log Pis Min                     -4.11343
trainer/policy/mean Mean                -0.391713
trainer/policy/mean Std                  0.726939
trainer/policy/mean Max                  0.999414
trainer/policy/mean Min                 -0.998111
trainer/policy/normal/std Mean           0.558933
trainer/policy/normal/std Std            0.0524158
trainer/policy/normal/std Max            0.705405
trainer/policy/normal/std Min            0.462677
trainer/policy/normal/log_std Mean      -0.586131
trainer/policy/normal/log_std Std        0.0939821
trainer/policy/normal/log_std Max       -0.348983
trainer/policy/normal/log_std Min       -0.770727
trainer/Alpha                            0.0203918
trainer/Alpha Loss                       1.30567
exploration/num steps total         284000
exploration/num paths total           1420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.77963
exploration/Rewards Std                  0.777162
exploration/Rewards Max                 -1.83816
exploration/Rewards Min                 -6.142
exploration/Returns Mean              -955.926
exploration/Returns Std                 68.2113
exploration/Returns Max               -857.567
exploration/Returns Min              -1072.38
exploration/Actions Mean                -0.357069
exploration/Actions Std                  0.727755
exploration/Actions Max                  0.999974
exploration/Actions Min                 -0.99972
exploration/Num Paths                   10
exploration/Average Returns           -955.926
evaluation/num steps total          680184
evaluation/num paths total            3384
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82365
evaluation/Rewards Std                   0.282179
evaluation/Rewards Max                  -4.58624
evaluation/Rewards Min                  -6.14193
evaluation/Returns Mean              -1170.55
evaluation/Returns Std                  53.2371
evaluation/Returns Max               -1022.44
evaluation/Returns Min               -1221.28
evaluation/Actions Mean                 -0.371971
evaluation/Actions Std                   0.598678
evaluation/Actions Max                   0.911171
evaluation/Actions Min                  -0.977236
evaluation/Num Paths                    24
evaluation/Average Returns           -1170.55
time/data storing (s)                    0.023141
time/evaluation sampling (s)            15.3815
time/exploration sampling (s)            5.73774
time/logging (s)                         0.0273789
time/sac training (s)                   12.3494
time/saving (s)                          0.0244817
time/training (s)                        0.000100677
time/epoch (s)                          33.5437
time/total (s)                        4432.61
Epoch                                  140
----------------------------------  ----------------
2020-11-09 14:36:20.442909 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 141 finished
----------------------------------  ----------------
replay_buffer/size                  286000
trainer/num train calls             142000
trainer/QF1 Loss                      1246.23
trainer/QF2 Loss                      1241.05
trainer/Policy Loss                    568.891
trainer/Q1 Predictions Mean           -569.046
trainer/Q1 Predictions Std              34.5043
trainer/Q1 Predictions Max            -433.754
trainer/Q1 Predictions Min            -667.183
trainer/Q2 Predictions Mean           -569.067
trainer/Q2 Predictions Std              34.5583
trainer/Q2 Predictions Max            -433.868
trainer/Q2 Predictions Min            -668.096
trainer/Q Targets Mean                -569.292
trainer/Q Targets Std                   49.7302
trainer/Q Targets Max                   -3.25019
trainer/Q Targets Min                 -668.863
trainer/Log Pis Mean                     1.88896
trainer/Log Pis Std                      2.86459
trainer/Log Pis Max                     13.0891
trainer/Log Pis Min                     -3.46212
trainer/policy/mean Mean                -0.31746
trainer/policy/mean Std                  0.701782
trainer/policy/mean Max                  0.999887
trainer/policy/mean Min                 -0.996182
trainer/policy/normal/std Mean           0.551229
trainer/policy/normal/std Std            0.0712856
trainer/policy/normal/std Max            0.654671
trainer/policy/normal/std Min            0.431645
trainer/policy/normal/log_std Mean      -0.60422
trainer/policy/normal/log_std Std        0.132237
trainer/policy/normal/log_std Max       -0.423623
trainer/policy/normal/log_std Min       -0.840151
trainer/Alpha                            0.019853
trainer/Alpha Loss                      -0.435219
exploration/num steps total         286000
exploration/num paths total           1430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.1045
exploration/Rewards Std                  0.615355
exploration/Rewards Max                 -3.21434
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1020.9
exploration/Returns Std                 68.7963
exploration/Returns Max               -914.186
exploration/Returns Min              -1118.96
exploration/Actions Mean                -0.370344
exploration/Actions Std                  0.651866
exploration/Actions Max                  0.999934
exploration/Actions Min                 -0.999527
exploration/Num Paths                   10
exploration/Average Returns          -1020.9
evaluation/num steps total          685008
evaluation/num paths total            3408
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.71584
evaluation/Rewards Std                   0.299473
evaluation/Rewards Max                  -4.72779
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1148.88
evaluation/Returns Std                  45.9331
evaluation/Returns Max               -1027.46
evaluation/Returns Min               -1205.49
evaluation/Actions Mean                 -0.340407
evaluation/Actions Std                   0.595152
evaluation/Actions Max                   0.985395
evaluation/Actions Min                  -0.963986
evaluation/Num Paths                    24
evaluation/Average Returns           -1148.88
time/data storing (s)                    0.0323554
time/evaluation sampling (s)            14.0524
time/exploration sampling (s)            5.55211
time/logging (s)                         0.0200087
time/sac training (s)                   11.6538
time/saving (s)                          0.0279516
time/training (s)                        0.000117401
time/epoch (s)                          31.3387
time/total (s)                        4465.07
Epoch                                  141
----------------------------------  ----------------
2020-11-09 14:36:52.949753 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 142 finished
----------------------------------  ----------------
replay_buffer/size                  288000
trainer/num train calls             143000
trainer/QF1 Loss                        14.2144
trainer/QF2 Loss                        14.212
trainer/Policy Loss                    572.26
trainer/Q1 Predictions Mean           -572.289
trainer/Q1 Predictions Std              29.6716
trainer/Q1 Predictions Max            -420.368
trainer/Q1 Predictions Min            -666.674
trainer/Q2 Predictions Mean           -572.311
trainer/Q2 Predictions Std              29.6789
trainer/Q2 Predictions Max            -420.507
trainer/Q2 Predictions Min            -667.6
trainer/Q Targets Mean                -575.193
trainer/Q Targets Std                   29.9075
trainer/Q Targets Max                 -421.769
trainer/Q Targets Min                 -668.729
trainer/Log Pis Mean                     1.24659
trainer/Log Pis Std                      2.82883
trainer/Log Pis Max                     13.2454
trainer/Log Pis Min                     -5.67401
trainer/policy/mean Mean                -0.227896
trainer/policy/mean Std                  0.686072
trainer/policy/mean Max                  0.999964
trainer/policy/mean Min                 -0.989832
trainer/policy/normal/std Mean           0.609752
trainer/policy/normal/std Std            0.0968886
trainer/policy/normal/std Max            0.76559
trainer/policy/normal/std Min            0.466582
trainer/policy/normal/log_std Mean      -0.507806
trainer/policy/normal/log_std Std        0.163313
trainer/policy/normal/log_std Max       -0.267108
trainer/policy/normal/log_std Min       -0.762321
trainer/Alpha                            0.0195817
trainer/Alpha Loss                      -2.96327
exploration/num steps total         288000
exploration/num paths total           1440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.6474
exploration/Rewards Std                  0.283268
exploration/Rewards Max                 -4.26719
exploration/Rewards Min                 -6.14165
exploration/Returns Mean             -1129.48
exploration/Returns Std                 35.4366
exploration/Returns Max              -1065.32
exploration/Returns Min              -1175.97
exploration/Actions Mean                -0.301394
exploration/Actions Std                  0.641791
exploration/Actions Max                  0.999116
exploration/Actions Min                 -0.9967
exploration/Num Paths                   10
exploration/Average Returns          -1129.48
evaluation/num steps total          689832
evaluation/num paths total            3432
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.88087
evaluation/Rewards Std                   0.230504
evaluation/Rewards Max                  -4.74544
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1182.05
evaluation/Returns Std                  30.6454
evaluation/Returns Max               -1093.19
evaluation/Returns Min               -1224.67
evaluation/Actions Mean                 -0.269143
evaluation/Actions Std                   0.442405
evaluation/Actions Max                   0.991567
evaluation/Actions Min                  -0.96742
evaluation/Num Paths                    24
evaluation/Average Returns           -1182.05
time/data storing (s)                    0.02373
time/evaluation sampling (s)            14.2062
time/exploration sampling (s)            5.45543
time/logging (s)                         0.0199574
time/sac training (s)                   11.6451
time/saving (s)                          0.0230482
time/training (s)                        0.000115003
time/epoch (s)                          31.3736
time/total (s)                        4497.55
Epoch                                  142
----------------------------------  ----------------
2020-11-09 14:37:24.550770 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 143 finished
----------------------------------  ----------------
replay_buffer/size                  290000
trainer/num train calls             144000
trainer/QF1 Loss                      2562
trainer/QF2 Loss                      2560.1
trainer/Policy Loss                    570.699
trainer/Q1 Predictions Mean           -570.851
trainer/Q1 Predictions Std              32.24
trainer/Q1 Predictions Max            -425.614
trainer/Q1 Predictions Min            -666.346
trainer/Q2 Predictions Mean           -570.862
trainer/Q2 Predictions Std              32.2592
trainer/Q2 Predictions Max            -425.461
trainer/Q2 Predictions Min            -667.265
trainer/Q Targets Mean                -569.147
trainer/Q Targets Std                   59.7552
trainer/Q Targets Max                   -5.18456
trainer/Q Targets Min                 -667.865
trainer/Log Pis Mean                     3.04377
trainer/Log Pis Std                      3.66872
trainer/Log Pis Max                     15.3918
trainer/Log Pis Min                     -5.1869
trainer/policy/mean Mean                -0.374336
trainer/policy/mean Std                  0.748792
trainer/policy/mean Max                  0.999988
trainer/policy/mean Min                 -0.99946
trainer/policy/normal/std Mean           0.541901
trainer/policy/normal/std Std            0.0751631
trainer/policy/normal/std Max            0.79247
trainer/policy/normal/std Min            0.357861
trainer/policy/normal/log_std Mean      -0.622018
trainer/policy/normal/log_std Std        0.136099
trainer/policy/normal/log_std Max       -0.2326
trainer/policy/normal/log_std Min       -1.02761
trainer/Alpha                            0.0195874
trainer/Alpha Loss                       4.10502
exploration/num steps total         290000
exploration/num paths total           1450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.83486
exploration/Rewards Std                  0.763062
exploration/Rewards Max                 -2.68975
exploration/Rewards Min                 -6.14141
exploration/Returns Mean              -966.971
exploration/Returns Std                 75.0667
exploration/Returns Max               -863.388
exploration/Returns Min              -1072.44
exploration/Actions Mean                -0.479599
exploration/Actions Std                  0.636843
exploration/Actions Max                  0.999373
exploration/Actions Min                 -0.998892
exploration/Num Paths                   10
exploration/Average Returns           -966.971
evaluation/num steps total          694656
evaluation/num paths total            3456
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56943
evaluation/Rewards Std                   0.853164
evaluation/Rewards Max                  -2.2893
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1119.45
evaluation/Returns Std                 160.854
evaluation/Returns Max                -597.319
evaluation/Returns Min               -1213
evaluation/Actions Mean                 -0.318573
evaluation/Actions Std                   0.689951
evaluation/Actions Max                   0.999434
evaluation/Actions Min                  -0.995106
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.45
time/data storing (s)                    0.0222682
time/evaluation sampling (s)            13.3479
time/exploration sampling (s)            5.50961
time/logging (s)                         0.025593
time/sac training (s)                   11.5689
time/saving (s)                          0.0196807
time/training (s)                        0.000119425
time/epoch (s)                          30.4941
time/total (s)                        4529.13
Epoch                                  143
----------------------------------  ----------------
2020-11-09 14:37:56.888907 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 144 finished
----------------------------------  ---------------
replay_buffer/size                  292000
trainer/num train calls             145000
trainer/QF1 Loss                      2131.14
trainer/QF2 Loss                      2133.81
trainer/Policy Loss                    566.976
trainer/Q1 Predictions Mean           -566.924
trainer/Q1 Predictions Std              37.0541
trainer/Q1 Predictions Max            -403.024
trainer/Q1 Predictions Min            -640.078
trainer/Q2 Predictions Mean           -566.928
trainer/Q2 Predictions Std              36.9829
trainer/Q2 Predictions Max            -402.758
trainer/Q2 Predictions Min            -638.256
trainer/Q Targets Mean                -565.48
trainer/Q Targets Std                   61.8787
trainer/Q Targets Max                   -2.50439
trainer/Q Targets Min                 -640.588
trainer/Log Pis Mean                     2.19366
trainer/Log Pis Std                      2.94004
trainer/Log Pis Max                     13.7558
trainer/Log Pis Min                     -4.56415
trainer/policy/mean Mean                -0.39691
trainer/policy/mean Std                  0.732748
trainer/policy/mean Max                  0.999952
trainer/policy/mean Min                 -0.996178
trainer/policy/normal/std Mean           0.632445
trainer/policy/normal/std Std            0.118885
trainer/policy/normal/std Max            0.898479
trainer/policy/normal/std Min            0.448021
trainer/policy/normal/log_std Mean      -0.475948
trainer/policy/normal/log_std Std        0.189165
trainer/policy/normal/log_std Max       -0.107052
trainer/policy/normal/log_std Min       -0.802915
trainer/Alpha                            0.0204257
trainer/Alpha Loss                       0.753519
exploration/num steps total         292000
exploration/num paths total           1460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.60436
exploration/Rewards Std                  0.991275
exploration/Rewards Max                 -2.43303
exploration/Rewards Min                 -6.14202
exploration/Returns Mean              -920.872
exploration/Returns Std                 99.7905
exploration/Returns Max               -740.741
exploration/Returns Min              -1076.51
exploration/Actions Mean                -0.392457
exploration/Actions Std                  0.713072
exploration/Actions Max                  0.998989
exploration/Actions Min                 -0.999488
exploration/Num Paths                   10
exploration/Average Returns           -920.872
evaluation/num steps total          699480
evaluation/num paths total            3480
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.77731
evaluation/Rewards Std                   0.249308
evaluation/Rewards Max                  -5.02384
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1161.24
evaluation/Returns Std                  46.7062
evaluation/Returns Max               -1022.74
evaluation/Returns Min               -1214.19
evaluation/Actions Mean                 -0.339049
evaluation/Actions Std                   0.652915
evaluation/Actions Max                   0.997961
evaluation/Actions Min                  -0.988487
evaluation/Num Paths                    24
evaluation/Average Returns           -1161.24
time/data storing (s)                    0.0360247
time/evaluation sampling (s)            13.182
time/exploration sampling (s)            5.53033
time/logging (s)                         0.0197034
time/sac training (s)                   12.3794
time/saving (s)                          0.0190449
time/training (s)                        9.3354e-05
time/epoch (s)                          31.1666
time/total (s)                        4561.44
Epoch                                  144
----------------------------------  ---------------
2020-11-09 14:38:39.293790 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 145 finished
----------------------------------  ----------------
replay_buffer/size                  294000
trainer/num train calls             146000
trainer/QF1 Loss                        16.9416
trainer/QF2 Loss                        16.9669
trainer/Policy Loss                    562.727
trainer/Q1 Predictions Mean           -562.853
trainer/Q1 Predictions Std              39.1226
trainer/Q1 Predictions Max            -400.061
trainer/Q1 Predictions Min            -664.66
trainer/Q2 Predictions Mean           -562.86
trainer/Q2 Predictions Std              39.1118
trainer/Q2 Predictions Max            -400.201
trainer/Q2 Predictions Min            -665.62
trainer/Q Targets Mean                -566.013
trainer/Q Targets Std                   39.5119
trainer/Q Targets Max                 -401.086
trainer/Q Targets Min                 -667.134
trainer/Log Pis Mean                     1.17258
trainer/Log Pis Std                      2.92845
trainer/Log Pis Max                     13.9607
trainer/Log Pis Min                     -5.93768
trainer/policy/mean Mean                -0.17241
trainer/policy/mean Std                  0.692523
trainer/policy/mean Max                  0.999997
trainer/policy/mean Min                 -0.97484
trainer/policy/normal/std Mean           0.687604
trainer/policy/normal/std Std            0.133044
trainer/policy/normal/std Max            0.934058
trainer/policy/normal/std Min            0.490871
trainer/policy/normal/log_std Mean      -0.393719
trainer/policy/normal/log_std Std        0.19704
trainer/policy/normal/log_std Max       -0.0682172
trainer/policy/normal/log_std Min       -0.711573
trainer/Alpha                            0.0204534
trainer/Alpha Loss                      -3.21835
exploration/num steps total         294000
exploration/num paths total           1470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.3379
exploration/Rewards Std                  0.762145
exploration/Rewards Max                 -3.30706
exploration/Rewards Min                 -6.14187
exploration/Returns Mean             -1067.58
exploration/Returns Std                124.934
exploration/Returns Max               -714.976
exploration/Returns Min              -1163.76
exploration/Actions Mean                -0.0852564
exploration/Actions Std                  0.755361
exploration/Actions Max                  0.999942
exploration/Actions Min                 -0.997931
exploration/Num Paths                   10
exploration/Average Returns          -1067.58
evaluation/num steps total          704304
evaluation/num paths total            3504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.76714
evaluation/Rewards Std                   0.623089
evaluation/Rewards Max                  -3.28672
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1159.2
evaluation/Returns Std                 107.99
evaluation/Returns Max                -700.04
evaluation/Returns Min               -1212.84
evaluation/Actions Mean                 -0.089183
evaluation/Actions Std                   0.685309
evaluation/Actions Max                   0.996745
evaluation/Actions Min                  -0.975295
evaluation/Num Paths                    24
evaluation/Average Returns           -1159.2
time/data storing (s)                    0.0487484
time/evaluation sampling (s)            13.8191
time/exploration sampling (s)            9.37035
time/logging (s)                         0.0310062
time/sac training (s)                   14.6105
time/saving (s)                          0.0249067
time/training (s)                        0.000127503
time/epoch (s)                          37.9048
time/total (s)                        4603.83
Epoch                                  145
----------------------------------  ----------------
2020-11-09 14:39:13.213491 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 146 finished
----------------------------------  ----------------
replay_buffer/size                  296000
trainer/num train calls             147000
trainer/QF1 Loss                      2831.76
trainer/QF2 Loss                      2827.05
trainer/Policy Loss                    567.442
trainer/Q1 Predictions Mean           -567.47
trainer/Q1 Predictions Std              35.1926
trainer/Q1 Predictions Max            -416.843
trainer/Q1 Predictions Min            -627.397
trainer/Q2 Predictions Mean           -567.441
trainer/Q2 Predictions Std              35.1299
trainer/Q2 Predictions Max            -416.936
trainer/Q2 Predictions Min            -626.575
trainer/Q Targets Mean                -565.472
trainer/Q Targets Std                   60.9598
trainer/Q Targets Max                   -5.0218
trainer/Q Targets Min                 -622.862
trainer/Log Pis Mean                     0.856673
trainer/Log Pis Std                      2.40764
trainer/Log Pis Max                     10.5466
trainer/Log Pis Min                     -4.67188
trainer/policy/mean Mean                -0.00904416
trainer/policy/mean Std                  0.6477
trainer/policy/mean Max                  0.999986
trainer/policy/mean Min                 -0.974977
trainer/policy/normal/std Mean           0.708979
trainer/policy/normal/std Std            0.124637
trainer/policy/normal/std Max            0.92546
trainer/policy/normal/std Min            0.543783
trainer/policy/normal/log_std Mean      -0.359535
trainer/policy/normal/log_std Std        0.177032
trainer/policy/normal/log_std Max       -0.0774646
trainer/policy/normal/log_std Min       -0.609206
trainer/Alpha                            0.0204764
trainer/Alpha Loss                      -4.44581
exploration/num steps total         296000
exploration/num paths total           1480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.8172
exploration/Rewards Std                  0.189374
exploration/Rewards Max                 -5.32504
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1163.44
exploration/Returns Std                 27.624
exploration/Returns Max              -1102.09
exploration/Returns Min              -1193.97
exploration/Actions Mean                 0.0897604
exploration/Actions Std                  0.734271
exploration/Actions Max                  0.999786
exploration/Actions Min                 -0.999542
exploration/Num Paths                   10
exploration/Average Returns          -1163.44
evaluation/num steps total          709128
evaluation/num paths total            3528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.90761
evaluation/Rewards Std                   0.515484
evaluation/Rewards Max                  -3.39424
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1187.43
evaluation/Returns Std                  99.9263
evaluation/Returns Max                -711.045
evaluation/Returns Min               -1224.57
evaluation/Actions Mean                 -0.0160709
evaluation/Actions Std                   0.457668
evaluation/Actions Max                   0.991629
evaluation/Actions Min                  -0.906271
evaluation/Num Paths                    24
evaluation/Average Returns           -1187.43
time/data storing (s)                    0.0254844
time/evaluation sampling (s)            14.8689
time/exploration sampling (s)            5.7408
time/logging (s)                         0.0192379
time/sac training (s)                   11.8769
time/saving (s)                          0.0256234
time/training (s)                        0.000123036
time/epoch (s)                          32.557
time/total (s)                        4637.72
Epoch                                  146
----------------------------------  ----------------
2020-11-09 14:39:46.566385 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 147 finished
----------------------------------  ----------------
replay_buffer/size                  298000
trainer/num train calls             148000
trainer/QF1 Loss                       831.605
trainer/QF2 Loss                       833.402
trainer/Policy Loss                    567.122
trainer/Q1 Predictions Mean           -567.204
trainer/Q1 Predictions Std              33.2978
trainer/Q1 Predictions Max            -411.347
trainer/Q1 Predictions Min            -620.838
trainer/Q2 Predictions Mean           -567.21
trainer/Q2 Predictions Std              33.2699
trainer/Q2 Predictions Max            -411.166
trainer/Q2 Predictions Min            -620.971
trainer/Q Targets Mean                -567.637
trainer/Q Targets Std                   48.3037
trainer/Q Targets Max                   -2.50439
trainer/Q Targets Min                 -620.95
trainer/Log Pis Mean                     1.01809
trainer/Log Pis Std                      2.57643
trainer/Log Pis Max                     11.4445
trainer/Log Pis Min                     -6.20737
trainer/policy/mean Mean                -0.184995
trainer/policy/mean Std                  0.695168
trainer/policy/mean Max                  0.999904
trainer/policy/mean Min                 -0.980205
trainer/policy/normal/std Mean           0.60321
trainer/policy/normal/std Std            0.0449016
trainer/policy/normal/std Max            0.70334
trainer/policy/normal/std Min            0.506565
trainer/policy/normal/log_std Mean      -0.508277
trainer/policy/normal/log_std Std        0.0747986
trainer/policy/normal/log_std Max       -0.351914
trainer/policy/normal/log_std Min       -0.680103
trainer/Alpha                            0.0199154
trainer/Alpha Loss                      -3.84541
exploration/num steps total         298000
exploration/num paths total           1490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.63466
exploration/Rewards Std                  0.391818
exploration/Rewards Max                 -4.42067
exploration/Rewards Min                 -6.14185
exploration/Returns Mean             -1126.93
exploration/Returns Std                 59.0873
exploration/Returns Max               -966.233
exploration/Returns Min              -1189.85
exploration/Actions Mean                -0.178082
exploration/Actions Std                  0.701025
exploration/Actions Max                  0.999685
exploration/Actions Min                 -0.998642
exploration/Num Paths                   10
exploration/Average Returns          -1126.93
evaluation/num steps total          713952
evaluation/num paths total            3552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.88191
evaluation/Rewards Std                   0.234162
evaluation/Rewards Max                  -4.60209
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1182.26
evaluation/Returns Std                  29.3861
evaluation/Returns Max               -1089.34
evaluation/Returns Min               -1211.27
evaluation/Actions Mean                 -0.158055
evaluation/Actions Std                   0.579464
evaluation/Actions Max                   0.981721
evaluation/Actions Min                  -0.973234
evaluation/Num Paths                    24
evaluation/Average Returns           -1182.26
time/data storing (s)                    0.0256065
time/evaluation sampling (s)            14.5515
time/exploration sampling (s)            5.63066
time/logging (s)                         0.0190717
time/sac training (s)                   11.9388
time/saving (s)                          0.0213479
time/training (s)                        0.000116007
time/epoch (s)                          32.1871
time/total (s)                        4671.05
Epoch                                  147
----------------------------------  ----------------
2020-11-09 14:40:19.856316 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 148 finished
----------------------------------  ---------------
replay_buffer/size                  300000
trainer/num train calls             149000
trainer/QF1 Loss                         7.47525
trainer/QF2 Loss                         7.4826
trainer/Policy Loss                    569.163
trainer/Q1 Predictions Mean           -569.306
trainer/Q1 Predictions Std              33.1386
trainer/Q1 Predictions Max            -411.434
trainer/Q1 Predictions Min            -636.467
trainer/Q2 Predictions Mean           -569.301
trainer/Q2 Predictions Std              33.1542
trainer/Q2 Predictions Max            -411.32
trainer/Q2 Predictions Min            -637.226
trainer/Q Targets Mean                -571.395
trainer/Q Targets Std                   33.5287
trainer/Q Targets Max                 -412.447
trainer/Q Targets Min                 -638.504
trainer/Log Pis Mean                     0.982679
trainer/Log Pis Std                      2.32857
trainer/Log Pis Max                     11.0379
trainer/Log Pis Min                     -4.06508
trainer/policy/mean Mean                -0.074106
trainer/policy/mean Std                  0.699727
trainer/policy/mean Max                  0.999919
trainer/policy/mean Min                 -0.979668
trainer/policy/normal/std Mean           0.615693
trainer/policy/normal/std Std            0.0741928
trainer/policy/normal/std Max            0.738562
trainer/policy/normal/std Min            0.502725
trainer/policy/normal/log_std Mean      -0.492345
trainer/policy/normal/log_std Std        0.121432
trainer/policy/normal/log_std Max       -0.30305
trainer/policy/normal/log_std Min       -0.687711
trainer/Alpha                            0.0195897
trainer/Alpha Loss                      -4.00087
exploration/num steps total         300000
exploration/num paths total           1500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.34761
exploration/Rewards Std                  0.972884
exploration/Rewards Max                 -3.17061
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1069.52
exploration/Returns Std                160.07
exploration/Returns Max               -725.097
exploration/Returns Min              -1201.45
exploration/Actions Mean                -0.056405
exploration/Actions Std                  0.743653
exploration/Actions Max                  0.999929
exploration/Actions Min                 -0.99788
exploration/Num Paths                   10
exploration/Average Returns          -1069.52
evaluation/num steps total          718776
evaluation/num paths total            3576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.90012
evaluation/Rewards Std                   0.519039
evaluation/Rewards Max                  -3.38407
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1185.92
evaluation/Returns Std                  99.0462
evaluation/Returns Max                -714.132
evaluation/Returns Min               -1226.1
evaluation/Actions Mean                 -0.104848
evaluation/Actions Std                   0.440511
evaluation/Actions Max                   0.991345
evaluation/Actions Min                  -0.960257
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.92
time/data storing (s)                    0.022985
time/evaluation sampling (s)            14.717
time/exploration sampling (s)            5.67025
time/logging (s)                         0.0215834
time/sac training (s)                   11.7147
time/saving (s)                          0.0203338
time/training (s)                        9.6207e-05
time/epoch (s)                          32.167
time/total (s)                        4704.32
Epoch                                  148
----------------------------------  ---------------
2020-11-09 14:40:53.154063 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 149 finished
----------------------------------  ----------------
replay_buffer/size                  302000
trainer/num train calls             150000
trainer/QF1 Loss                        50.3042
trainer/QF2 Loss                        50.4646
trainer/Policy Loss                    564.343
trainer/Q1 Predictions Mean           -564.495
trainer/Q1 Predictions Std              37.9069
trainer/Q1 Predictions Max            -430.287
trainer/Q1 Predictions Min            -645.934
trainer/Q2 Predictions Mean           -564.494
trainer/Q2 Predictions Std              37.8892
trainer/Q2 Predictions Max            -430.302
trainer/Q2 Predictions Min            -647.05
trainer/Q Targets Mean                -567.492
trainer/Q Targets Std                   37.982
trainer/Q Targets Max                 -431.083
trainer/Q Targets Min                 -647.87
trainer/Log Pis Mean                     1.58091
trainer/Log Pis Std                      2.66803
trainer/Log Pis Max                     13.1357
trainer/Log Pis Min                     -4.25384
trainer/policy/mean Mean                -0.256943
trainer/policy/mean Std                  0.696766
trainer/policy/mean Max                  0.999983
trainer/policy/mean Min                 -0.991877
trainer/policy/normal/std Mean           0.593362
trainer/policy/normal/std Std            0.0810747
trainer/policy/normal/std Max            0.728344
trainer/policy/normal/std Min            0.437981
trainer/policy/normal/log_std Mean      -0.531307
trainer/policy/normal/log_std Std        0.136879
trainer/policy/normal/log_std Max       -0.316981
trainer/policy/normal/log_std Min       -0.825579
trainer/Alpha                            0.0193518
trainer/Alpha Loss                      -1.65328
exploration/num steps total         302000
exploration/num paths total           1510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.48656
exploration/Rewards Std                  0.557159
exploration/Rewards Max                 -3.11144
exploration/Rewards Min                 -6.14179
exploration/Returns Mean             -1097.31
exploration/Returns Std                 44.0495
exploration/Returns Max               -990.265
exploration/Returns Min              -1159.25
exploration/Actions Mean                -0.288439
exploration/Actions Std                  0.65334
exploration/Actions Max                  0.999789
exploration/Actions Min                 -0.997992
exploration/Num Paths                   10
exploration/Average Returns          -1097.31
evaluation/num steps total          723600
evaluation/num paths total            3600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73217
evaluation/Rewards Std                   0.53144
evaluation/Rewards Max                  -3.36193
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1152.17
evaluation/Returns Std                  92.9443
evaluation/Returns Max                -733.662
evaluation/Returns Min               -1208.96
evaluation/Actions Mean                 -0.27775
evaluation/Actions Std                   0.58017
evaluation/Actions Max                   0.986484
evaluation/Actions Min                  -0.973212
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.17
time/data storing (s)                    0.0229621
time/evaluation sampling (s)            14.5885
time/exploration sampling (s)            5.64435
time/logging (s)                         0.0192273
time/sac training (s)                   11.8653
time/saving (s)                          0.0221971
time/training (s)                        0.000138896
time/epoch (s)                          32.1627
time/total (s)                        4737.59
Epoch                                  149
----------------------------------  ----------------
2020-11-09 14:41:25.495803 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 150 finished
----------------------------------  ----------------
replay_buffer/size                  304000
trainer/num train calls             151000
trainer/QF1 Loss                      2424.51
trainer/QF2 Loss                      2431.01
trainer/Policy Loss                    564.681
trainer/Q1 Predictions Mean           -564.77
trainer/Q1 Predictions Std              35.0641
trainer/Q1 Predictions Max            -413.105
trainer/Q1 Predictions Min            -632.748
trainer/Q2 Predictions Mean           -564.805
trainer/Q2 Predictions Std              35.0722
trainer/Q2 Predictions Max            -413.319
trainer/Q2 Predictions Min            -633.58
trainer/Q Targets Mean                -563.459
trainer/Q Targets Std                   60.9419
trainer/Q Targets Max                   -4.69185
trainer/Q Targets Min                 -634.383
trainer/Log Pis Mean                     3.01698
trainer/Log Pis Std                      4.27082
trainer/Log Pis Max                     18.6709
trainer/Log Pis Min                     -5.76896
trainer/policy/mean Mean                 0.0900331
trainer/policy/mean Std                  0.753351
trainer/policy/mean Max                  1
trainer/policy/mean Min                 -0.978306
trainer/policy/normal/std Mean           0.594882
trainer/policy/normal/std Std            0.0509354
trainer/policy/normal/std Max            0.775829
trainer/policy/normal/std Min            0.458406
trainer/policy/normal/log_std Mean      -0.522916
trainer/policy/normal/log_std Std        0.0832304
trainer/policy/normal/log_std Max       -0.253823
trainer/policy/normal/log_std Min       -0.78
trainer/Alpha                            0.0191235
trainer/Alpha Loss                       4.02402
exploration/num steps total         304000
exploration/num paths total           1520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.95731
exploration/Rewards Std                  0.0924477
exploration/Rewards Max                 -5.62817
exploration/Rewards Min                 -6.14159
exploration/Returns Mean             -1191.46
exploration/Returns Std                 18.4963
exploration/Returns Max              -1144.6
exploration/Returns Min              -1211.04
exploration/Actions Mean                 0.0708942
exploration/Actions Std                  0.756172
exploration/Actions Max                  0.999956
exploration/Actions Min                 -0.996905
exploration/Num Paths                   10
exploration/Average Returns          -1191.46
evaluation/num steps total          728424
evaluation/num paths total            3624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04455
evaluation/Rewards Std                   0.0426364
evaluation/Rewards Max                  -5.36872
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1214.95
evaluation/Returns Std                   7.2352
evaluation/Returns Max               -1197.75
evaluation/Returns Min               -1222.38
evaluation/Actions Mean                  0.261799
evaluation/Actions Std                   0.659101
evaluation/Actions Max                   0.998844
evaluation/Actions Min                  -0.829303
evaluation/Num Paths                    24
evaluation/Average Returns           -1214.95
time/data storing (s)                    0.0220512
time/evaluation sampling (s)            13.6053
time/exploration sampling (s)            5.64101
time/logging (s)                         0.0192265
time/sac training (s)                   11.8917
time/saving (s)                          0.0244972
time/training (s)                        0.000113696
time/epoch (s)                          31.2039
time/total (s)                        4769.91
Epoch                                  150
----------------------------------  ----------------
2020-11-09 14:42:07.305670 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 151 finished
----------------------------------  ----------------
replay_buffer/size                  306000
trainer/num train calls             152000
trainer/QF1 Loss                      2626.74
trainer/QF2 Loss                      2620.93
trainer/Policy Loss                    565.559
trainer/Q1 Predictions Mean           -565.814
trainer/Q1 Predictions Std              32.9254
trainer/Q1 Predictions Max            -406.97
trainer/Q1 Predictions Min            -622.594
trainer/Q2 Predictions Mean           -565.793
trainer/Q2 Predictions Std              32.8983
trainer/Q2 Predictions Max            -406.984
trainer/Q2 Predictions Min            -622.256
trainer/Q Targets Mean                -564.254
trainer/Q Targets Std                   59.7845
trainer/Q Targets Max                   -5.02064
trainer/Q Targets Min                 -624.305
trainer/Log Pis Mean                     1.54879
trainer/Log Pis Std                      2.43374
trainer/Log Pis Max                      8.57365
trainer/Log Pis Min                     -4.16325
trainer/policy/mean Mean                 0.0783231
trainer/policy/mean Std                  0.746739
trainer/policy/mean Max                  0.999938
trainer/policy/mean Min                 -0.985093
trainer/policy/normal/std Mean           0.576813
trainer/policy/normal/std Std            0.0500893
trainer/policy/normal/std Max            0.734655
trainer/policy/normal/std Min            0.488556
trainer/policy/normal/log_std Mean      -0.553935
trainer/policy/normal/log_std Std        0.085639
trainer/policy/normal/log_std Max       -0.308354
trainer/policy/normal/log_std Min       -0.7163
trainer/Alpha                            0.0192854
trainer/Alpha Loss                      -1.78156
exploration/num steps total         306000
exploration/num paths total           1530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.78221
exploration/Rewards Std                  0.760162
exploration/Rewards Max                 -3.35593
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1156.44
exploration/Returns Std                142.792
exploration/Returns Max               -732.731
exploration/Returns Min              -1227.68
exploration/Actions Mean                 0.0451352
exploration/Actions Std                  0.736291
exploration/Actions Max                  0.99932
exploration/Actions Min                 -0.998811
exploration/Num Paths                   10
exploration/Average Returns          -1156.44
evaluation/num steps total          733248
evaluation/num paths total            3648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.965
evaluation/Rewards Std                   0.517237
evaluation/Rewards Max                  -3.38453
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1198.96
evaluation/Returns Std                  99.1754
evaluation/Returns Max                -727.975
evaluation/Returns Min               -1232.29
evaluation/Actions Mean                  0.0915988
evaluation/Actions Std                   0.582654
evaluation/Actions Max                   0.990596
evaluation/Actions Min                  -0.726795
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.96
time/data storing (s)                    0.0213395
time/evaluation sampling (s)            14.0919
time/exploration sampling (s)            5.82899
time/logging (s)                         0.0353483
time/sac training (s)                   19.8515
time/saving (s)                          0.0319544
time/training (s)                        0.000166153
time/epoch (s)                          39.8612
time/total (s)                        4811.71
Epoch                                  151
----------------------------------  ----------------
2020-11-09 14:42:48.671518 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 152 finished
----------------------------------  ----------------
replay_buffer/size                  308000
trainer/num train calls             153000
trainer/QF1 Loss                        13.0529
trainer/QF2 Loss                        13.1477
trainer/Policy Loss                    558.643
trainer/Q1 Predictions Mean           -558.754
trainer/Q1 Predictions Std              44.6649
trainer/Q1 Predictions Max            -393.453
trainer/Q1 Predictions Min            -626.325
trainer/Q2 Predictions Mean           -558.752
trainer/Q2 Predictions Std              44.6587
trainer/Q2 Predictions Max            -393.191
trainer/Q2 Predictions Min            -624.939
trainer/Q Targets Mean                -561.287
trainer/Q Targets Std                   44.9862
trainer/Q Targets Max                 -392.862
trainer/Q Targets Min                 -626.578
trainer/Log Pis Mean                     2.85489
trainer/Log Pis Std                      4.16031
trainer/Log Pis Max                     20.2977
trainer/Log Pis Min                     -5.19937
trainer/policy/mean Mean                -0.0557809
trainer/policy/mean Std                  0.776566
trainer/policy/mean Max                  1
trainer/policy/mean Min                 -0.998044
trainer/policy/normal/std Mean           0.556387
trainer/policy/normal/std Std            0.059929
trainer/policy/normal/std Max            0.747947
trainer/policy/normal/std Min            0.385141
trainer/policy/normal/log_std Mean      -0.591879
trainer/policy/normal/log_std Std        0.104914
trainer/policy/normal/log_std Max       -0.290424
trainer/policy/normal/log_std Min       -0.954146
trainer/Alpha                            0.0192778
trainer/Alpha Loss                       3.37578
exploration/num steps total         308000
exploration/num paths total           1540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.20792
exploration/Rewards Std                  1.11416
exploration/Rewards Max                 -3.34231
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1041.58
exploration/Returns Std                198.914
exploration/Returns Max               -712.248
exploration/Returns Min              -1204.25
exploration/Actions Mean                -0.0538793
exploration/Actions Std                  0.834
exploration/Actions Max                  0.999985
exploration/Actions Min                 -0.999147
exploration/Num Paths                   10
exploration/Average Returns          -1041.58
evaluation/num steps total          738072
evaluation/num paths total            3672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78708
evaluation/Rewards Std                   0.700094
evaluation/Rewards Max                  -3.39797
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1163.2
evaluation/Returns Std                 134.442
evaluation/Returns Max                -709.236
evaluation/Returns Min               -1220.29
evaluation/Actions Mean                 -0.059866
evaluation/Actions Std                   0.636765
evaluation/Actions Max                   0.999177
evaluation/Actions Min                  -0.969127
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.2
time/data storing (s)                    0.0250715
time/evaluation sampling (s)            14.9408
time/exploration sampling (s)            5.66878
time/logging (s)                         0.029298
time/sac training (s)                   14.8914
time/saving (s)                          0.0214469
time/training (s)                        0.000114802
time/epoch (s)                          35.5769
time/total (s)                        4853.04
Epoch                                  152
----------------------------------  ----------------
2020-11-09 14:43:22.879259 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 153 finished
----------------------------------  ----------------
replay_buffer/size                  310000
trainer/num train calls             154000
trainer/QF1 Loss                      4979.66
trainer/QF2 Loss                      4980
trainer/Policy Loss                    568.784
trainer/Q1 Predictions Mean           -568.889
trainer/Q1 Predictions Std              30.7675
trainer/Q1 Predictions Max            -425.948
trainer/Q1 Predictions Min            -640.462
trainer/Q2 Predictions Mean           -568.881
trainer/Q2 Predictions Std              30.7689
trainer/Q2 Predictions Max            -425.964
trainer/Q2 Predictions Min            -641.371
trainer/Q Targets Mean                -561.991
trainer/Q Targets Std                   76.5496
trainer/Q Targets Max                   -3.58316
trainer/Q Targets Min                 -646.067
trainer/Log Pis Mean                     1.39166
trainer/Log Pis Std                      2.96517
trainer/Log Pis Max                     13.0691
trainer/Log Pis Min                     -5.17887
trainer/policy/mean Mean                -0.131135
trainer/policy/mean Std                  0.737716
trainer/policy/mean Max                  0.999994
trainer/policy/mean Min                 -0.995062
trainer/policy/normal/std Mean           0.707034
trainer/policy/normal/std Std            0.132159
trainer/policy/normal/std Max            0.958456
trainer/policy/normal/std Min            0.517426
trainer/policy/normal/log_std Mean      -0.364381
trainer/policy/normal/log_std Std        0.18884
trainer/policy/normal/log_std Max       -0.042432
trainer/policy/normal/log_std Min       -0.658888
trainer/Alpha                            0.0199193
trainer/Alpha Loss                      -2.38228
exploration/num steps total         310000
exploration/num paths total           1550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.60191
exploration/Rewards Std                  0.313356
exploration/Rewards Max                 -4.51572
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1120.38
exploration/Returns Std                 45.4376
exploration/Returns Max              -1010.69
exploration/Returns Min              -1176.41
exploration/Actions Mean                -0.0901363
exploration/Actions Std                  0.773211
exploration/Actions Max                  0.999972
exploration/Actions Min                 -0.999821
exploration/Num Paths                   10
exploration/Average Returns          -1120.38
evaluation/num steps total          742896
evaluation/num paths total            3696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.98486
evaluation/Rewards Std                   0.10949
evaluation/Rewards Max                  -5.38479
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1202.96
evaluation/Returns Std                  11.5234
evaluation/Returns Max               -1172.78
evaluation/Returns Min               -1217.88
evaluation/Actions Mean                 -0.107828
evaluation/Actions Std                   0.63465
evaluation/Actions Max                   0.982703
evaluation/Actions Min                  -0.958439
evaluation/Num Paths                    24
evaluation/Average Returns           -1202.96
time/data storing (s)                    0.0232472
time/evaluation sampling (s)            13.166
time/exploration sampling (s)            6.76185
time/logging (s)                         0.0212478
time/sac training (s)                   11.9332
time/saving (s)                          0.0234232
time/training (s)                        0.000115871
time/epoch (s)                          31.9291
time/total (s)                        4887.21
Epoch                                  153
----------------------------------  ----------------
2020-11-09 14:43:54.802726 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 154 finished
----------------------------------  ---------------
replay_buffer/size                  312000
trainer/num train calls             155000
trainer/QF1 Loss                      1325.97
trainer/QF2 Loss                      1326.44
trainer/Policy Loss                    558.988
trainer/Q1 Predictions Mean           -559.168
trainer/Q1 Predictions Std              40.3907
trainer/Q1 Predictions Max            -404.577
trainer/Q1 Predictions Min            -647.772
trainer/Q2 Predictions Mean           -559.145
trainer/Q2 Predictions Std              40.3842
trainer/Q2 Predictions Max            -404.773
trainer/Q2 Predictions Min            -648.339
trainer/Q Targets Mean                -560.256
trainer/Q Targets Std                   53.7432
trainer/Q Targets Max                   -5.5504
trainer/Q Targets Min                 -650.229
trainer/Log Pis Mean                     1.99281
trainer/Log Pis Std                      2.72304
trainer/Log Pis Max                     17.8669
trainer/Log Pis Min                     -5.92514
trainer/policy/mean Mean                -0.132684
trainer/policy/mean Std                  0.771712
trainer/policy/mean Max                  0.999998
trainer/policy/mean Min                 -0.996087
trainer/policy/normal/std Mean           0.567122
trainer/policy/normal/std Std            0.0999374
trainer/policy/normal/std Max            0.789704
trainer/policy/normal/std Min            0.395892
trainer/policy/normal/log_std Mean      -0.583161
trainer/policy/normal/log_std Std        0.180163
trainer/policy/normal/log_std Max       -0.236097
trainer/policy/normal/log_std Min       -0.926613
trainer/Alpha                            0.0196372
trainer/Alpha Loss                      -0.0282709
exploration/num steps total         312000
exploration/num paths total           1560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.82184
exploration/Rewards Std                  0.319777
exploration/Rewards Max                 -4.01655
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1164.37
exploration/Returns Std                 39.7701
exploration/Returns Max              -1090.19
exploration/Returns Min              -1217.16
exploration/Actions Mean                -0.236222
exploration/Actions Std                  0.677982
exploration/Actions Max                  0.998425
exploration/Actions Min                 -0.998363
exploration/Num Paths                   10
exploration/Average Returns          -1164.37
evaluation/num steps total          747720
evaluation/num paths total            3720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.99565
evaluation/Rewards Std                   0.142477
evaluation/Rewards Max                  -5.18742
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1205.13
evaluation/Returns Std                  17.5919
evaluation/Returns Max               -1157.06
evaluation/Returns Min               -1225.22
evaluation/Actions Mean                 -0.176974
evaluation/Actions Std                   0.607623
evaluation/Actions Max                   0.969919
evaluation/Actions Min                  -0.976931
evaluation/Num Paths                    24
evaluation/Average Returns           -1205.13
time/data storing (s)                    0.0246503
time/evaluation sampling (s)            13.3039
time/exploration sampling (s)            5.51647
time/logging (s)                         0.0188997
time/sac training (s)                   11.8287
time/saving (s)                          0.0205373
time/training (s)                        9.8178e-05
time/epoch (s)                          30.7132
time/total (s)                        4919.11
Epoch                                  154
----------------------------------  ---------------
2020-11-09 14:44:28.721194 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 155 finished
----------------------------------  ----------------
replay_buffer/size                  314000
trainer/num train calls             156000
trainer/QF1 Loss                        13.484
trainer/QF2 Loss                        13.9462
trainer/Policy Loss                    564.7
trainer/Q1 Predictions Mean           -564.903
trainer/Q1 Predictions Std              40.0895
trainer/Q1 Predictions Max            -372.841
trainer/Q1 Predictions Min            -643.345
trainer/Q2 Predictions Mean           -564.88
trainer/Q2 Predictions Std              40.1142
trainer/Q2 Predictions Max            -372.742
trainer/Q2 Predictions Min            -644.322
trainer/Q Targets Mean                -568.1
trainer/Q Targets Std                   40.3431
trainer/Q Targets Max                 -373.9
trainer/Q Targets Min                 -646.445
trainer/Log Pis Mean                     2.42397
trainer/Log Pis Std                      3.16343
trainer/Log Pis Max                     14.9081
trainer/Log Pis Min                     -6.97872
trainer/policy/mean Mean                -0.257998
trainer/policy/mean Std                  0.751803
trainer/policy/mean Max                  0.999967
trainer/policy/mean Min                 -0.99787
trainer/policy/normal/std Mean           0.567357
trainer/policy/normal/std Std            0.0783491
trainer/policy/normal/std Max            0.766772
trainer/policy/normal/std Min            0.429318
trainer/policy/normal/log_std Mean      -0.576635
trainer/policy/normal/log_std Std        0.14173
trainer/policy/normal/log_std Max       -0.265566
trainer/policy/normal/log_std Min       -0.845558
trainer/Alpha                            0.0198805
trainer/Alpha Loss                       1.66114
exploration/num steps total         314000
exploration/num paths total           1570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.50999
exploration/Rewards Std                  0.341819
exploration/Rewards Max                 -4.70289
exploration/Rewards Min                 -6.14193
exploration/Returns Mean             -1102
exploration/Returns Std                 32.9444
exploration/Returns Max              -1038.75
exploration/Returns Min              -1141.2
exploration/Actions Mean                -0.337882
exploration/Actions Std                  0.671374
exploration/Actions Max                  0.999887
exploration/Actions Min                 -0.998506
exploration/Num Paths                   10
exploration/Average Returns          -1102
evaluation/num steps total          752544
evaluation/num paths total            3744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67547
evaluation/Rewards Std                   0.551339
evaluation/Rewards Max                  -3.03211
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1140.77
evaluation/Returns Std                  96.6352
evaluation/Returns Max                -702.377
evaluation/Returns Min               -1207.09
evaluation/Actions Mean                 -0.228603
evaluation/Actions Std                   0.719292
evaluation/Actions Max                   0.996522
evaluation/Actions Min                  -0.981684
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.77
time/data storing (s)                    0.0228834
time/evaluation sampling (s)            14.4517
time/exploration sampling (s)            5.65048
time/logging (s)                         0.0240731
time/sac training (s)                   12.4529
time/saving (s)                          0.0237646
time/training (s)                        0.000111402
time/epoch (s)                          32.6259
time/total (s)                        4953.01
Epoch                                  155
----------------------------------  ----------------
2020-11-09 14:45:01.707789 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 156 finished
----------------------------------  ---------------
replay_buffer/size                  316000
trainer/num train calls             157000
trainer/QF1 Loss                        31.0497
trainer/QF2 Loss                        30.9402
trainer/Policy Loss                    564.992
trainer/Q1 Predictions Mean           -565.087
trainer/Q1 Predictions Std              30.5336
trainer/Q1 Predictions Max            -426.238
trainer/Q1 Predictions Min            -631.096
trainer/Q2 Predictions Mean           -565.088
trainer/Q2 Predictions Std              30.5713
trainer/Q2 Predictions Max            -426.256
trainer/Q2 Predictions Min            -631.587
trainer/Q Targets Mean                -567.719
trainer/Q Targets Std                   31.0313
trainer/Q Targets Max                 -428.249
trainer/Q Targets Min                 -639.51
trainer/Log Pis Mean                     2.75301
trainer/Log Pis Std                      2.70274
trainer/Log Pis Max                     11.8735
trainer/Log Pis Min                     -6.69382
trainer/policy/mean Mean                 0.386103
trainer/policy/mean Std                  0.721189
trainer/policy/mean Max                  1
trainer/policy/mean Min                 -0.98282
trainer/policy/normal/std Mean           0.600596
trainer/policy/normal/std Std            0.0892375
trainer/policy/normal/std Max            0.87175
trainer/policy/normal/std Min            0.453616
trainer/policy/normal/log_std Mean      -0.520762
trainer/policy/normal/log_std Std        0.147737
trainer/policy/normal/log_std Max       -0.137252
trainer/policy/normal/log_std Min       -0.790504
trainer/Alpha                            0.0202977
trainer/Alpha Loss                       2.93466
exploration/num steps total         316000
exploration/num paths total           1580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.7696
exploration/Rewards Std                  0.771557
exploration/Rewards Max                 -3.397
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1153.92
exploration/Returns Std                149.932
exploration/Returns Max               -706.989
exploration/Returns Min              -1217.19
exploration/Actions Mean                 0.328389
exploration/Actions Std                  0.756192
exploration/Actions Max                  0.999992
exploration/Actions Min                 -0.996862
exploration/Num Paths                   10
exploration/Average Returns          -1153.92
evaluation/num steps total          757368
evaluation/num paths total            3768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.02484
evaluation/Rewards Std                   0.0777248
evaluation/Rewards Max                  -4.5446
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1210.99
evaluation/Returns Std                  10.2037
evaluation/Returns Max               -1188.82
evaluation/Returns Min               -1225.31
evaluation/Actions Mean                  0.594454
evaluation/Actions Std                   0.536572
evaluation/Actions Max                   0.998427
evaluation/Actions Min                  -0.856566
evaluation/Num Paths                    24
evaluation/Average Returns           -1210.99
time/data storing (s)                    0.0231577
time/evaluation sampling (s)            13.3087
time/exploration sampling (s)            5.96057
time/logging (s)                         0.0180199
time/sac training (s)                   12.4364
time/saving (s)                          0.0264995
time/training (s)                        9.4385e-05
time/epoch (s)                          31.7734
time/total (s)                        4985.97
Epoch                                  156
----------------------------------  ---------------
2020-11-09 14:45:33.950296 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 157 finished
----------------------------------  ----------------
replay_buffer/size                  318000
trainer/num train calls             158000
trainer/QF1 Loss                      2124.14
trainer/QF2 Loss                      2124.47
trainer/Policy Loss                    570.017
trainer/Q1 Predictions Mean           -570.267
trainer/Q1 Predictions Std              22.192
trainer/Q1 Predictions Max            -444.331
trainer/Q1 Predictions Min            -620.146
trainer/Q2 Predictions Mean           -570.237
trainer/Q2 Predictions Std              22.207
trainer/Q2 Predictions Max            -444.372
trainer/Q2 Predictions Min            -620.729
trainer/Q Targets Mean                -568.413
trainer/Q Targets Std                   54.4976
trainer/Q Targets Max                   -4.14053
trainer/Q Targets Min                 -621.207
trainer/Log Pis Mean                     2.08091
trainer/Log Pis Std                      3.28888
trainer/Log Pis Max                     15.196
trainer/Log Pis Min                     -6.9491
trainer/policy/mean Mean                -0.20147
trainer/policy/mean Std                  0.761826
trainer/policy/mean Max                  0.999976
trainer/policy/mean Min                 -0.997935
trainer/policy/normal/std Mean           0.571121
trainer/policy/normal/std Std            0.0528252
trainer/policy/normal/std Max            0.794341
trainer/policy/normal/std Min            0.451926
trainer/policy/normal/log_std Mean      -0.564336
trainer/policy/normal/log_std Std        0.0910522
trainer/policy/normal/log_std Max       -0.230243
trainer/policy/normal/log_std Min       -0.794237
trainer/Alpha                            0.0206891
trainer/Alpha Loss                       0.313793
exploration/num steps total         318000
exploration/num paths total           1590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.3795
exploration/Rewards Std                  0.483878
exploration/Rewards Max                 -4.24751
exploration/Rewards Min                 -6.14161
exploration/Returns Mean             -1075.9
exploration/Returns Std                 50.8387
exploration/Returns Max               -967.966
exploration/Returns Min              -1132.54
exploration/Actions Mean                -0.12477
exploration/Actions Std                  0.847888
exploration/Actions Max                  0.999984
exploration/Actions Min                 -0.999684
exploration/Num Paths                   10
exploration/Average Returns          -1075.9
evaluation/num steps total          762192
evaluation/num paths total            3792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83167
evaluation/Rewards Std                   0.268051
evaluation/Rewards Max                  -4.11768
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1172.17
evaluation/Returns Std                  33.9872
evaluation/Returns Max               -1091.82
evaluation/Returns Min               -1216.16
evaluation/Actions Mean                 -0.219205
evaluation/Actions Std                   0.694939
evaluation/Actions Max                   0.995156
evaluation/Actions Min                  -0.975907
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.17
time/data storing (s)                    0.0235862
time/evaluation sampling (s)            13.1239
time/exploration sampling (s)            5.43409
time/logging (s)                         0.0253775
time/sac training (s)                   12.4312
time/saving (s)                          0.0193009
time/training (s)                        0.000116079
time/epoch (s)                          31.0576
time/total (s)                        5018.19
Epoch                                  157
----------------------------------  ----------------
2020-11-09 14:46:09.456854 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 158 finished
----------------------------------  ----------------
replay_buffer/size                  320000
trainer/num train calls             159000
trainer/QF1 Loss                      1328.65
trainer/QF2 Loss                      1329.75
trainer/Policy Loss                    563.138
trainer/Q1 Predictions Mean           -563.253
trainer/Q1 Predictions Std              36.5725
trainer/Q1 Predictions Max            -418.005
trainer/Q1 Predictions Min            -616.612
trainer/Q2 Predictions Mean           -563.253
trainer/Q2 Predictions Std              36.5297
trainer/Q2 Predictions Max            -417.933
trainer/Q2 Predictions Min            -616.95
trainer/Q Targets Mean                -563.497
trainer/Q Targets Std                   50.626
trainer/Q Targets Max                   -5.4241
trainer/Q Targets Min                 -619.123
trainer/Log Pis Mean                     2.08597
trainer/Log Pis Std                      3.33611
trainer/Log Pis Max                     14.5921
trainer/Log Pis Min                     -4.4885
trainer/policy/mean Mean                -0.0980437
trainer/policy/mean Std                  0.764564
trainer/policy/mean Max                  0.999992
trainer/policy/mean Min                 -0.994084
trainer/policy/normal/std Mean           0.611681
trainer/policy/normal/std Std            0.0721692
trainer/policy/normal/std Max            0.76279
trainer/policy/normal/std Min            0.460909
trainer/policy/normal/log_std Mean      -0.498799
trainer/policy/normal/log_std Std        0.121737
trainer/policy/normal/log_std Max       -0.270772
trainer/policy/normal/log_std Min       -0.774555
trainer/Alpha                            0.0209136
trainer/Alpha Loss                       0.332488
exploration/num steps total         320000
exploration/num paths total           1600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.65136
exploration/Rewards Std                  0.710846
exploration/Rewards Max                 -3.3758
exploration/Rewards Min                 -6.14186
exploration/Returns Mean             -1130.27
exploration/Returns Std                127.329
exploration/Returns Max               -755.84
exploration/Returns Min              -1200.31
exploration/Actions Mean                -0.11235
exploration/Actions Std                  0.772947
exploration/Actions Max                  0.999943
exploration/Actions Min                 -0.999482
exploration/Num Paths                   10
exploration/Average Returns          -1130.27
evaluation/num steps total          767016
evaluation/num paths total            3816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95874
evaluation/Rewards Std                   0.138571
evaluation/Rewards Max                  -5.41696
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1197.71
evaluation/Returns Std                  16.7009
evaluation/Returns Max               -1159.41
evaluation/Returns Min               -1216.7
evaluation/Actions Mean                 -0.139668
evaluation/Actions Std                   0.617895
evaluation/Actions Max                   0.983598
evaluation/Actions Min                  -0.967785
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.71
time/data storing (s)                    0.0351751
time/evaluation sampling (s)            14.1206
time/exploration sampling (s)            6.12181
time/logging (s)                         0.0169057
time/sac training (s)                   13.8333
time/saving (s)                          0.0194969
time/training (s)                        0.000114644
time/epoch (s)                          34.1474
time/total (s)                        5053.66
Epoch                                  158
----------------------------------  ----------------
2020-11-09 14:46:43.034095 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 159 finished
----------------------------------  ----------------
replay_buffer/size                  322000
trainer/num train calls             160000
trainer/QF1 Loss                         8.49178
trainer/QF2 Loss                         8.53489
trainer/Policy Loss                    564.202
trainer/Q1 Predictions Mean           -564.533
trainer/Q1 Predictions Std              37.5317
trainer/Q1 Predictions Max            -406.288
trainer/Q1 Predictions Min            -615.482
trainer/Q2 Predictions Mean           -564.542
trainer/Q2 Predictions Std              37.5386
trainer/Q2 Predictions Max            -406.015
trainer/Q2 Predictions Min            -615.693
trainer/Q Targets Mean                -566.251
trainer/Q Targets Std                   37.9733
trainer/Q Targets Max                 -403.46
trainer/Q Targets Min                 -618.378
trainer/Log Pis Mean                     2.18118
trainer/Log Pis Std                      3.058
trainer/Log Pis Max                     13.8995
trainer/Log Pis Min                     -7.5079
trainer/policy/mean Mean                -0.356823
trainer/policy/mean Std                  0.728698
trainer/policy/mean Max                  0.999854
trainer/policy/mean Min                 -0.999343
trainer/policy/normal/std Mean           0.597627
trainer/policy/normal/std Std            0.0578911
trainer/policy/normal/std Max            0.79077
trainer/policy/normal/std Min            0.430437
trainer/policy/normal/log_std Mean      -0.519431
trainer/policy/normal/log_std Std        0.0962622
trainer/policy/normal/log_std Max       -0.234749
trainer/policy/normal/log_std Min       -0.842954
trainer/Alpha                            0.021675
trainer/Alpha Loss                       0.694194
exploration/num steps total         322000
exploration/num paths total           1610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.33091
exploration/Rewards Std                  0.413913
exploration/Rewards Max                 -3.72099
exploration/Rewards Min                 -6.14164
exploration/Returns Mean             -1066.18
exploration/Returns Std                 45.5596
exploration/Returns Max               -967.765
exploration/Returns Min              -1116.49
exploration/Actions Mean                -0.418356
exploration/Actions Std                  0.630034
exploration/Actions Max                  0.999615
exploration/Actions Min                 -0.999536
exploration/Num Paths                   10
exploration/Average Returns          -1066.18
evaluation/num steps total          771840
evaluation/num paths total            3840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73107
evaluation/Rewards Std                   0.329355
evaluation/Rewards Max                  -4.64784
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1151.95
evaluation/Returns Std                  58.61
evaluation/Returns Max               -1009.74
evaluation/Returns Min               -1217.34
evaluation/Actions Mean                 -0.326522
evaluation/Actions Std                   0.661952
evaluation/Actions Max                   0.985911
evaluation/Actions Min                  -0.991415
evaluation/Num Paths                    24
evaluation/Average Returns           -1151.95
time/data storing (s)                    0.0269382
time/evaluation sampling (s)            13.6429
time/exploration sampling (s)            5.51604
time/logging (s)                         0.0215268
time/sac training (s)                   13.0785
time/saving (s)                          0.0210404
time/training (s)                        0.000110387
time/epoch (s)                          32.3071
time/total (s)                        5087.22
Epoch                                  159
----------------------------------  ----------------
2020-11-09 14:47:22.630534 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 160 finished
----------------------------------  ----------------
replay_buffer/size                  324000
trainer/num train calls             161000
trainer/QF1 Loss                      3710.31
trainer/QF2 Loss                      3710.63
trainer/Policy Loss                    566.717
trainer/Q1 Predictions Mean           -566.808
trainer/Q1 Predictions Std              33.7601
trainer/Q1 Predictions Max            -413.114
trainer/Q1 Predictions Min            -609.232
trainer/Q2 Predictions Mean           -566.828
trainer/Q2 Predictions Std              33.7555
trainer/Q2 Predictions Max            -413.241
trainer/Q2 Predictions Min            -608.663
trainer/Q Targets Mean                -563.035
trainer/Q Targets Std                   69.674
trainer/Q Targets Max                   -4.8138
trainer/Q Targets Min                 -611.617
trainer/Log Pis Mean                     1.67184
trainer/Log Pis Std                      2.62215
trainer/Log Pis Max                     15.1536
trainer/Log Pis Min                     -3.74272
trainer/policy/mean Mean                -0.12632
trainer/policy/mean Std                  0.762053
trainer/policy/mean Max                  0.999995
trainer/policy/mean Min                 -0.994733
trainer/policy/normal/std Mean           0.57725
trainer/policy/normal/std Std            0.0812361
trainer/policy/normal/std Max            0.734054
trainer/policy/normal/std Min            0.419893
trainer/policy/normal/log_std Mean      -0.559785
trainer/policy/normal/log_std Std        0.145029
trainer/policy/normal/log_std Max       -0.309172
trainer/policy/normal/log_std Min       -0.867754
trainer/Alpha                            0.021429
trainer/Alpha Loss                      -1.26114
exploration/num steps total         324000
exploration/num paths total           1620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.67057
exploration/Rewards Std                  0.483671
exploration/Rewards Max                 -3.84835
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1134.11
exploration/Returns Std                 77.0934
exploration/Returns Max              -1007.81
exploration/Returns Min              -1212.62
exploration/Actions Mean                -0.196254
exploration/Actions Std                  0.744062
exploration/Actions Max                  0.999985
exploration/Actions Min                 -0.998571
exploration/Num Paths                   10
exploration/Average Returns          -1134.11
evaluation/num steps total          776664
evaluation/num paths total            3864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97317
evaluation/Rewards Std                   0.15075
evaluation/Rewards Max                  -5.23881
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1200.61
evaluation/Returns Std                  21.6406
evaluation/Returns Max               -1139.37
evaluation/Returns Min               -1221.35
evaluation/Actions Mean                 -0.177529
evaluation/Actions Std                   0.569519
evaluation/Actions Max                   0.982984
evaluation/Actions Min                  -0.969973
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.61
time/data storing (s)                    0.0270632
time/evaluation sampling (s)            15.1404
time/exploration sampling (s)            6.81265
time/logging (s)                         0.0357613
time/sac training (s)                   14.5092
time/saving (s)                          0.0373118
time/training (s)                        0.000146552
time/epoch (s)                          36.5625
time/total (s)                        5126.8
Epoch                                  160
----------------------------------  ----------------
2020-11-09 14:47:59.414474 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 161 finished
----------------------------------  ----------------
replay_buffer/size                  326000
trainer/num train calls             162000
trainer/QF1 Loss                        17.4296
trainer/QF2 Loss                        17.665
trainer/Policy Loss                    564.761
trainer/Q1 Predictions Mean           -564.817
trainer/Q1 Predictions Std              37.1679
trainer/Q1 Predictions Max            -405.7
trainer/Q1 Predictions Min            -623.354
trainer/Q2 Predictions Mean           -564.797
trainer/Q2 Predictions Std              37.1353
trainer/Q2 Predictions Max            -405.848
trainer/Q2 Predictions Min            -622.699
trainer/Q Targets Mean                -567.568
trainer/Q Targets Std                   37.9358
trainer/Q Targets Max                 -407.17
trainer/Q Targets Min                 -624.024
trainer/Log Pis Mean                     2.18648
trainer/Log Pis Std                      3.36146
trainer/Log Pis Max                     13.1928
trainer/Log Pis Min                     -5.50823
trainer/policy/mean Mean                 0.100534
trainer/policy/mean Std                  0.755576
trainer/policy/mean Max                  0.999999
trainer/policy/mean Min                 -0.974319
trainer/policy/normal/std Mean           0.633453
trainer/policy/normal/std Std            0.0415686
trainer/policy/normal/std Max            0.753661
trainer/policy/normal/std Min            0.543959
trainer/policy/normal/log_std Mean      -0.458705
trainer/policy/normal/log_std Std        0.0652739
trainer/policy/normal/log_std Max       -0.282813
trainer/policy/normal/log_std Min       -0.608882
trainer/Alpha                            0.0215286
trainer/Alpha Loss                       0.715761
exploration/num steps total         326000
exploration/num paths total           1630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.25751
exploration/Rewards Std                  1.12618
exploration/Rewards Max                 -3.33952
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1051.5
exploration/Returns Std                213.19
exploration/Returns Max               -687.518
exploration/Returns Min              -1213.54
exploration/Actions Mean                 0.0567478
exploration/Actions Std                  0.795527
exploration/Actions Max                  0.999978
exploration/Actions Min                 -0.999441
exploration/Num Paths                   10
exploration/Average Returns          -1051.5
evaluation/num steps total          781488
evaluation/num paths total            3888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83052
evaluation/Rewards Std                   0.71826
evaluation/Rewards Max                  -3.40111
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1171.93
evaluation/Returns Std                 142.041
evaluation/Returns Max                -699.486
evaluation/Returns Min               -1225.08
evaluation/Actions Mean                  0.165025
evaluation/Actions Std                   0.661928
evaluation/Actions Max                   0.998542
evaluation/Actions Min                  -0.899111
evaluation/Num Paths                    24
evaluation/Average Returns           -1171.93
time/data storing (s)                    0.0240533
time/evaluation sampling (s)            14.584
time/exploration sampling (s)            5.8586
time/logging (s)                         0.0225363
time/sac training (s)                   14.7736
time/saving (s)                          0.0226357
time/training (s)                        0.000139958
time/epoch (s)                          35.2855
time/total (s)                        5163.54
Epoch                                  161
----------------------------------  ----------------
2020-11-09 14:48:34.287828 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 162 finished
----------------------------------  ----------------
replay_buffer/size                  328000
trainer/num train calls             163000
trainer/QF1 Loss                      2253.38
trainer/QF2 Loss                      2260.68
trainer/Policy Loss                    565.975
trainer/Q1 Predictions Mean           -566.067
trainer/Q1 Predictions Std              34.2834
trainer/Q1 Predictions Max            -398.153
trainer/Q1 Predictions Min            -646.695
trainer/Q2 Predictions Mean           -566.045
trainer/Q2 Predictions Std              34.2755
trainer/Q2 Predictions Max            -398.122
trainer/Q2 Predictions Min            -647.696
trainer/Q Targets Mean                -563.885
trainer/Q Targets Std                   60.4249
trainer/Q Targets Max                   -3.33724
trainer/Q Targets Min                 -648.064
trainer/Log Pis Mean                     1.84959
trainer/Log Pis Std                      2.7704
trainer/Log Pis Max                     12.9613
trainer/Log Pis Min                    -10.3324
trainer/policy/mean Mean                 0.0313394
trainer/policy/mean Std                  0.7739
trainer/policy/mean Max                  0.999994
trainer/policy/mean Min                 -0.985698
trainer/policy/normal/std Mean           0.556887
trainer/policy/normal/std Std            0.0438645
trainer/policy/normal/std Max            0.704789
trainer/policy/normal/std Min            0.448087
trainer/policy/normal/log_std Mean      -0.588556
trainer/policy/normal/log_std Std        0.0799729
trainer/policy/normal/log_std Max       -0.349857
trainer/policy/normal/log_std Min       -0.802769
trainer/Alpha                            0.0213563
trainer/Alpha Loss                      -0.578528
exploration/num steps total         328000
exploration/num paths total           1640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.49417
exploration/Rewards Std                  0.990911
exploration/Rewards Max                 -3.37746
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1098.83
exploration/Returns Std                197.683
exploration/Returns Max               -699.421
exploration/Returns Min              -1219.64
exploration/Actions Mean                -0.0305517
exploration/Actions Std                  0.783397
exploration/Actions Max                  0.999952
exploration/Actions Min                 -0.998798
exploration/Num Paths                   10
exploration/Average Returns          -1098.83
evaluation/num steps total          786312
evaluation/num paths total            3912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.88198
evaluation/Rewards Std                   0.666678
evaluation/Rewards Max                  -3.36868
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1182.28
evaluation/Returns Std                 119.596
evaluation/Returns Max                -726.469
evaluation/Returns Min               -1227.57
evaluation/Actions Mean                 -0.0351184
evaluation/Actions Std                   0.600324
evaluation/Actions Max                   0.996608
evaluation/Actions Min                  -0.953639
evaluation/Num Paths                    24
evaluation/Average Returns           -1182.28
time/data storing (s)                    0.0275902
time/evaluation sampling (s)            14.0792
time/exploration sampling (s)            5.80166
time/logging (s)                         0.020323
time/sac training (s)                   13.6404
time/saving (s)                          0.0244314
time/training (s)                        0.000125717
time/epoch (s)                          33.5937
time/total (s)                        5198.39
Epoch                                  162
----------------------------------  ----------------
2020-11-09 14:49:10.442425 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 163 finished
----------------------------------  ----------------
replay_buffer/size                  330000
trainer/num train calls             164000
trainer/QF1 Loss                        15.2319
trainer/QF2 Loss                        15.1976
trainer/Policy Loss                    564.347
trainer/Q1 Predictions Mean           -564.422
trainer/Q1 Predictions Std              37.2033
trainer/Q1 Predictions Max            -409.668
trainer/Q1 Predictions Min            -665.213
trainer/Q2 Predictions Mean           -564.444
trainer/Q2 Predictions Std              37.2176
trainer/Q2 Predictions Max            -409.669
trainer/Q2 Predictions Min            -666.138
trainer/Q Targets Mean                -566.9
trainer/Q Targets Std                   37.6327
trainer/Q Targets Max                 -411.185
trainer/Q Targets Min                 -666.733
trainer/Log Pis Mean                     2.76278
trainer/Log Pis Std                      3.4786
trainer/Log Pis Max                     13.6046
trainer/Log Pis Min                     -4.14547
trainer/policy/mean Mean                 0.115478
trainer/policy/mean Std                  0.802452
trainer/policy/mean Max                  0.999999
trainer/policy/mean Min                 -0.986395
trainer/policy/normal/std Mean           0.603304
trainer/policy/normal/std Std            0.0503257
trainer/policy/normal/std Max            0.749343
trainer/policy/normal/std Min            0.505132
trainer/policy/normal/log_std Mean      -0.508707
trainer/policy/normal/log_std Std        0.0815356
trainer/policy/normal/log_std Max       -0.288559
trainer/policy/normal/log_std Min       -0.682936
trainer/Alpha                            0.0217099
trainer/Alpha Loss                       2.92145
exploration/num steps total         330000
exploration/num paths total           1650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.99592
exploration/Rewards Std                  0.0539746
exploration/Rewards Max                 -5.86402
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1199.18
exploration/Returns Std                 19.4803
exploration/Returns Max              -1142.5
exploration/Returns Min              -1213.54
exploration/Actions Mean                 0.126556
exploration/Actions Std                  0.742864
exploration/Actions Max                  0.999699
exploration/Actions Min                 -0.998464
exploration/Num Paths                   10
exploration/Average Returns          -1199.18
evaluation/num steps total          791136
evaluation/num paths total            3936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.93747
evaluation/Rewards Std                   0.530589
evaluation/Rewards Max                  -3.35448
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1193.43
evaluation/Returns Std                 105.457
evaluation/Returns Max                -688.555
evaluation/Returns Min               -1226.29
evaluation/Actions Mean                  0.167452
evaluation/Actions Std                   0.689414
evaluation/Actions Max                   0.998942
evaluation/Actions Min                  -0.936649
evaluation/Num Paths                    24
evaluation/Average Returns           -1193.43
time/data storing (s)                    0.0234243
time/evaluation sampling (s)            14.8733
time/exploration sampling (s)            6.02197
time/logging (s)                         0.0222049
time/sac training (s)                   13.7934
time/saving (s)                          0.0288767
time/training (s)                        0.000152035
time/epoch (s)                          34.7633
time/total (s)                        5234.51
Epoch                                  163
----------------------------------  ----------------
2020-11-09 14:49:42.967992 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 164 finished
----------------------------------  ----------------
replay_buffer/size                  332000
trainer/num train calls             165000
trainer/QF1 Loss                      1302.18
trainer/QF2 Loss                      1304.16
trainer/Policy Loss                    560.897
trainer/Q1 Predictions Mean           -561.11
trainer/Q1 Predictions Std              40.4541
trainer/Q1 Predictions Max            -412.838
trainer/Q1 Predictions Min            -613.358
trainer/Q2 Predictions Mean           -561.073
trainer/Q2 Predictions Std              40.4371
trainer/Q2 Predictions Max            -412.776
trainer/Q2 Predictions Min            -613.477
trainer/Q Targets Mean                -561.892
trainer/Q Targets Std                   53.5724
trainer/Q Targets Max                   -5.76544
trainer/Q Targets Min                 -616.057
trainer/Log Pis Mean                     2.82221
trainer/Log Pis Std                      3.58147
trainer/Log Pis Max                     14.128
trainer/Log Pis Min                     -3.61398
trainer/policy/mean Mean                 0.0649799
trainer/policy/mean Std                  0.814919
trainer/policy/mean Max                  0.999993
trainer/policy/mean Min                 -0.99372
trainer/policy/normal/std Mean           0.630294
trainer/policy/normal/std Std            0.100006
trainer/policy/normal/std Max            0.945696
trainer/policy/normal/std Min            0.481107
trainer/policy/normal/log_std Mean      -0.473158
trainer/policy/normal/log_std Std        0.149263
trainer/policy/normal/log_std Max       -0.0558338
trainer/policy/normal/log_std Min       -0.731665
trainer/Alpha                            0.0223281
trainer/Alpha Loss                       3.12596
exploration/num steps total         332000
exploration/num paths total           1660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.86946
exploration/Rewards Std                  0.246995
exploration/Rewards Max                 -4.14091
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1173.89
exploration/Returns Std                 36.4263
exploration/Returns Max              -1084.23
exploration/Returns Min              -1207.6
exploration/Actions Mean                 0.0994333
exploration/Actions Std                  0.783949
exploration/Actions Max                  0.999937
exploration/Actions Min                 -0.997709
exploration/Num Paths                   10
exploration/Average Returns          -1173.89
evaluation/num steps total          795960
evaluation/num paths total            3960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.93297
evaluation/Rewards Std                   0.50953
evaluation/Rewards Max                  -3.39854
evaluation/Rewards Min                  -6.14197
evaluation/Returns Mean              -1192.53
evaluation/Returns Std                  99.4608
evaluation/Returns Max                -716.3
evaluation/Returns Min               -1224.54
evaluation/Actions Mean                  0.0962808
evaluation/Actions Std                   0.71163
evaluation/Actions Max                   0.99768
evaluation/Actions Min                  -0.962995
evaluation/Num Paths                    24
evaluation/Average Returns           -1192.53
time/data storing (s)                    0.0206079
time/evaluation sampling (s)            14.2403
time/exploration sampling (s)            5.2911
time/logging (s)                         0.017924
time/sac training (s)                   11.7938
time/saving (s)                          0.0208188
time/training (s)                        0.000122502
time/epoch (s)                          31.3848
time/total (s)                        5267.01
Epoch                                  164
----------------------------------  ----------------
2020-11-09 14:50:16.917024 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 165 finished
----------------------------------  ----------------
replay_buffer/size                  334000
trainer/num train calls             166000
trainer/QF1 Loss                        21.4723
trainer/QF2 Loss                        21.4819
trainer/Policy Loss                    567.383
trainer/Q1 Predictions Mean           -567.524
trainer/Q1 Predictions Std              32.1677
trainer/Q1 Predictions Max            -413.992
trainer/Q1 Predictions Min            -620.887
trainer/Q2 Predictions Mean           -567.545
trainer/Q2 Predictions Std              32.1838
trainer/Q2 Predictions Max            -413.784
trainer/Q2 Predictions Min            -621.788
trainer/Q Targets Mean                -570.435
trainer/Q Targets Std                   32.3352
trainer/Q Targets Max                 -419.313
trainer/Q Targets Min                 -623.445
trainer/Log Pis Mean                     2.12974
trainer/Log Pis Std                      2.74446
trainer/Log Pis Max                     12.88
trainer/Log Pis Min                     -2.56685
trainer/policy/mean Mean                -0.0198778
trainer/policy/mean Std                  0.793683
trainer/policy/mean Max                  0.999952
trainer/policy/mean Min                 -0.993728
trainer/policy/normal/std Mean           0.552505
trainer/policy/normal/std Std            0.0586996
trainer/policy/normal/std Max            0.692924
trainer/policy/normal/std Min            0.413424
trainer/policy/normal/log_std Mean      -0.599217
trainer/policy/normal/log_std Std        0.110225
trainer/policy/normal/log_std Max       -0.366834
trainer/policy/normal/log_std Min       -0.883282
trainer/Alpha                            0.0224784
trainer/Alpha Loss                       0.492385
exploration/num steps total         334000
exploration/num paths total           1670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.00991
exploration/Rewards Std                  0.125906
exploration/Rewards Max                 -5.57475
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1201.98
exploration/Returns Std                 27.9428
exploration/Returns Max              -1135.25
exploration/Returns Min              -1220.66
exploration/Actions Mean                -0.102341
exploration/Actions Std                  0.753717
exploration/Actions Max                  0.999767
exploration/Actions Min                 -0.998238
exploration/Num Paths                   10
exploration/Average Returns          -1201.98
evaluation/num steps total          800784
evaluation/num paths total            3984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.02881
evaluation/Rewards Std                   0.105388
evaluation/Rewards Max                  -5.2337
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1211.79
evaluation/Returns Std                  13.2158
evaluation/Returns Max               -1182.22
evaluation/Returns Min               -1229.76
evaluation/Actions Mean                 -0.0782239
evaluation/Actions Std                   0.530112
evaluation/Actions Max                   0.977891
evaluation/Actions Min                  -0.952636
evaluation/Num Paths                    24
evaluation/Average Returns           -1211.79
time/data storing (s)                    0.0224989
time/evaluation sampling (s)            12.7689
time/exploration sampling (s)            5.79121
time/logging (s)                         0.0191814
time/sac training (s)                   14.0013
time/saving (s)                          0.0241056
time/training (s)                        0.000122025
time/epoch (s)                          32.6273
time/total (s)                        5300.93
Epoch                                  165
----------------------------------  ----------------
2020-11-09 14:50:53.794838 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 166 finished
----------------------------------  ----------------
replay_buffer/size                  336000
trainer/num train calls             167000
trainer/QF1 Loss                        13.5963
trainer/QF2 Loss                        13.6381
trainer/Policy Loss                    560.289
trainer/Q1 Predictions Mean           -560.474
trainer/Q1 Predictions Std              43.6479
trainer/Q1 Predictions Max            -395.253
trainer/Q1 Predictions Min            -641.433
trainer/Q2 Predictions Mean           -560.476
trainer/Q2 Predictions Std              43.6553
trainer/Q2 Predictions Max            -395.39
trainer/Q2 Predictions Min            -641.801
trainer/Q Targets Mean                -563.314
trainer/Q Targets Std                   43.9314
trainer/Q Targets Max                 -396.36
trainer/Q Targets Min                 -642.244
trainer/Log Pis Mean                     2.50904
trainer/Log Pis Std                      3.11897
trainer/Log Pis Max                     14.9346
trainer/Log Pis Min                     -4.02396
trainer/policy/mean Mean                -0.113332
trainer/policy/mean Std                  0.823764
trainer/policy/mean Max                  0.999998
trainer/policy/mean Min                 -0.999674
trainer/policy/normal/std Mean           0.582224
trainer/policy/normal/std Std            0.0849432
trainer/policy/normal/std Max            0.713836
trainer/policy/normal/std Min            0.393383
trainer/policy/normal/log_std Mean      -0.552238
trainer/policy/normal/log_std Std        0.153062
trainer/policy/normal/log_std Max       -0.337101
trainer/policy/normal/log_std Min       -0.932973
trainer/Alpha                            0.0228826
trainer/Alpha Loss                       1.92285
exploration/num steps total         336000
exploration/num paths total           1680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.52328
exploration/Rewards Std                  0.757325
exploration/Rewards Max                 -3.30549
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1104.66
exploration/Returns Std                131.576
exploration/Returns Max               -727.629
exploration/Returns Min              -1204.97
exploration/Actions Mean                -0.140153
exploration/Actions Std                  0.777646
exploration/Actions Max                  0.999969
exploration/Actions Min                 -0.999638
exploration/Num Paths                   10
exploration/Average Returns          -1104.66
evaluation/num steps total          805608
evaluation/num paths total            4008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.86706
evaluation/Rewards Std                   0.511139
evaluation/Rewards Max                  -3.38111
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1179.28
evaluation/Returns Std                  95.2353
evaluation/Returns Max                -727.872
evaluation/Returns Min               -1220.17
evaluation/Actions Mean                 -0.186317
evaluation/Actions Std                   0.655083
evaluation/Actions Max                   0.990936
evaluation/Actions Min                  -0.981162
evaluation/Num Paths                    24
evaluation/Average Returns           -1179.28
time/data storing (s)                    0.0349941
time/evaluation sampling (s)            14.7734
time/exploration sampling (s)            5.21575
time/logging (s)                         0.0278161
time/sac training (s)                   13.1895
time/saving (s)                          0.0345376
time/training (s)                        0.000149523
time/epoch (s)                          33.2762
time/total (s)                        5337.8
Epoch                                  166
----------------------------------  ----------------
2020-11-09 14:51:46.002045 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 167 finished
----------------------------------  ---------------
replay_buffer/size                  338000
trainer/num train calls             168000
trainer/QF1 Loss                      1316.03
trainer/QF2 Loss                      1315.71
trainer/Policy Loss                    562.246
trainer/Q1 Predictions Mean           -562.492
trainer/Q1 Predictions Std              39.0611
trainer/Q1 Predictions Max            -402.147
trainer/Q1 Predictions Min            -621.712
trainer/Q2 Predictions Mean           -562.469
trainer/Q2 Predictions Std              39.0412
trainer/Q2 Predictions Max            -402.288
trainer/Q2 Predictions Min            -622.152
trainer/Q Targets Mean                -563.316
trainer/Q Targets Std                   52.8814
trainer/Q Targets Max                   -5.22461
trainer/Q Targets Min                 -624.862
trainer/Log Pis Mean                     3.66759
trainer/Log Pis Std                      3.95374
trainer/Log Pis Max                     18.8072
trainer/Log Pis Min                     -4.13727
trainer/policy/mean Mean                -0.314645
trainer/policy/mean Std                  0.790385
trainer/policy/mean Max                  0.999993
trainer/policy/mean Min                 -0.999894
trainer/policy/normal/std Mean           0.600943
trainer/policy/normal/std Std            0.115661
trainer/policy/normal/std Max            0.819997
trainer/policy/normal/std Min            0.376135
trainer/policy/normal/log_std Mean      -0.528787
trainer/policy/normal/log_std Std        0.200522
trainer/policy/normal/log_std Max       -0.198455
trainer/policy/normal/log_std Min       -0.977807
trainer/Alpha                            0.0237729
trainer/Alpha Loss                       6.23549
exploration/num steps total         338000
exploration/num paths total           1690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.22908
exploration/Rewards Std                  0.610571
exploration/Rewards Max                 -3.12549
exploration/Rewards Min                 -6.14065
exploration/Returns Mean             -1045.82
exploration/Returns Std                 79.2808
exploration/Returns Max               -897.733
exploration/Returns Min              -1127.62
exploration/Actions Mean                -0.430804
exploration/Actions Std                  0.696784
exploration/Actions Max                  0.999984
exploration/Actions Min                 -0.999948
exploration/Num Paths                   10
exploration/Average Returns          -1045.82
evaluation/num steps total          810432
evaluation/num paths total            4032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.68446
evaluation/Rewards Std                   0.259186
evaluation/Rewards Max                  -4.93756
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1142.58
evaluation/Returns Std                  45.7387
evaluation/Returns Max               -1030.25
evaluation/Returns Min               -1216
evaluation/Actions Mean                 -0.388427
evaluation/Actions Std                   0.718617
evaluation/Actions Max                   0.994592
evaluation/Actions Min                  -0.995556
evaluation/Num Paths                    24
evaluation/Average Returns           -1142.58
time/data storing (s)                    0.0399007
time/evaluation sampling (s)            21.1698
time/exploration sampling (s)            9.41308
time/logging (s)                         0.0274202
time/sac training (s)                   18.6374
time/saving (s)                          0.0325894
time/training (s)                        0.00015213
time/epoch (s)                          49.3204
time/total (s)                        5389.97
Epoch                                  167
----------------------------------  ---------------
2020-11-09 14:52:21.728059 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 168 finished
----------------------------------  ----------------
replay_buffer/size                  340000
trainer/num train calls             169000
trainer/QF1 Loss                      3766.55
trainer/QF2 Loss                      3766.98
trainer/Policy Loss                    565.941
trainer/Q1 Predictions Mean           -566.287
trainer/Q1 Predictions Std              33.0035
trainer/Q1 Predictions Max            -392.186
trainer/Q1 Predictions Min            -666.195
trainer/Q2 Predictions Mean           -566.258
trainer/Q2 Predictions Std              33.005
trainer/Q2 Predictions Max            -392.293
trainer/Q2 Predictions Min            -667.235
trainer/Q Targets Mean                -561.63
trainer/Q Targets Std                   69.337
trainer/Q Targets Max                   -5.31957
trainer/Q Targets Min                 -666.695
trainer/Log Pis Mean                     1.82034
trainer/Log Pis Std                      2.66274
trainer/Log Pis Max                     12.2458
trainer/Log Pis Min                     -3.68742
trainer/policy/mean Mean                -0.257751
trainer/policy/mean Std                  0.742958
trainer/policy/mean Max                  0.999927
trainer/policy/mean Min                 -0.997236
trainer/policy/normal/std Mean           0.636404
trainer/policy/normal/std Std            0.104937
trainer/policy/normal/std Max            0.783111
trainer/policy/normal/std Min            0.419709
trainer/policy/normal/log_std Mean      -0.466479
trainer/policy/normal/log_std Std        0.17365
trainer/policy/normal/log_std Max       -0.244481
trainer/policy/normal/log_std Min       -0.868195
trainer/Alpha                            0.0241812
trainer/Alpha Loss                      -0.66872
exploration/num steps total         340000
exploration/num paths total           1700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.53016
exploration/Rewards Std                  0.486267
exploration/Rewards Max                 -4.22026
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1106.03
exploration/Returns Std                 61.6266
exploration/Returns Max               -992.132
exploration/Returns Min              -1202.05
exploration/Actions Mean                -0.278941
exploration/Actions Std                  0.713426
exploration/Actions Max                  0.999917
exploration/Actions Min                 -0.999283
exploration/Num Paths                   10
exploration/Average Returns          -1106.03
evaluation/num steps total          815256
evaluation/num paths total            4056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83522
evaluation/Rewards Std                   0.226201
evaluation/Rewards Max                  -4.85192
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1172.88
evaluation/Returns Std                  32.6351
evaluation/Returns Max               -1090.42
evaluation/Returns Min               -1214.52
evaluation/Actions Mean                 -0.27915
evaluation/Actions Std                   0.664937
evaluation/Actions Max                   0.98797
evaluation/Actions Min                  -0.984593
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.88
time/data storing (s)                    0.0241524
time/evaluation sampling (s)            16.7467
time/exploration sampling (s)            5.06182
time/logging (s)                         0.0177211
time/sac training (s)                   12.558
time/saving (s)                          0.0232678
time/training (s)                        0.000102194
time/epoch (s)                          34.4318
time/total (s)                        5425.66
Epoch                                  168
----------------------------------  ----------------
2020-11-09 14:52:53.624716 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 169 finished
----------------------------------  ----------------
replay_buffer/size                  342000
trainer/num train calls             170000
trainer/QF1 Loss                        54.5883
trainer/QF2 Loss                        54.845
trainer/Policy Loss                    565.432
trainer/Q1 Predictions Mean           -565.576
trainer/Q1 Predictions Std              36.7379
trainer/Q1 Predictions Max            -400.16
trainer/Q1 Predictions Min            -652.317
trainer/Q2 Predictions Mean           -565.551
trainer/Q2 Predictions Std              36.7499
trainer/Q2 Predictions Max            -399.975
trainer/Q2 Predictions Min            -653.41
trainer/Q Targets Mean                -567.513
trainer/Q Targets Std                   37.8042
trainer/Q Targets Max                 -399.78
trainer/Q Targets Min                 -654.202
trainer/Log Pis Mean                     1.79674
trainer/Log Pis Std                      2.93858
trainer/Log Pis Max                     16.5884
trainer/Log Pis Min                     -4.37779
trainer/policy/mean Mean                 0.0459001
trainer/policy/mean Std                  0.782094
trainer/policy/mean Max                  0.999999
trainer/policy/mean Min                 -0.986914
trainer/policy/normal/std Mean           0.626906
trainer/policy/normal/std Std            0.0647334
trainer/policy/normal/std Max            0.911856
trainer/policy/normal/std Min            0.451443
trainer/policy/normal/log_std Mean      -0.471991
trainer/policy/normal/log_std Std        0.0990826
trainer/policy/normal/log_std Max       -0.092273
trainer/policy/normal/log_std Min       -0.795306
trainer/Alpha                            0.0242742
trainer/Alpha Loss                      -0.755776
exploration/num steps total         342000
exploration/num paths total           1710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.97052
exploration/Rewards Std                  0.137033
exploration/Rewards Max                 -5.47739
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1194.1
exploration/Returns Std                 36.6481
exploration/Returns Max              -1089.15
exploration/Returns Min              -1227.93
exploration/Actions Mean                 0.0428632
exploration/Actions Std                  0.777366
exploration/Actions Max                  0.999901
exploration/Actions Min                 -0.998862
exploration/Num Paths                   10
exploration/Average Returns          -1194.1
evaluation/num steps total          820080
evaluation/num paths total            4080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74846
evaluation/Rewards Std                   0.854466
evaluation/Rewards Max                  -3.37625
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1155.44
evaluation/Returns Std                 165.092
evaluation/Returns Max                -700.005
evaluation/Returns Min               -1231.83
evaluation/Actions Mean                  0.0371963
evaluation/Actions Std                   0.663547
evaluation/Actions Max                   0.991667
evaluation/Actions Min                  -0.946084
evaluation/Num Paths                    24
evaluation/Average Returns           -1155.44
time/data storing (s)                    0.0252276
time/evaluation sampling (s)            12.2272
time/exploration sampling (s)            5.04938
time/logging (s)                         0.0192038
time/sac training (s)                   13.1969
time/saving (s)                          0.0224791
time/training (s)                        0.000117478
time/epoch (s)                          30.5405
time/total (s)                        5457.53
Epoch                                  169
----------------------------------  ----------------
2020-11-09 14:53:26.054087 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 170 finished
----------------------------------  ---------------
replay_buffer/size                  344000
trainer/num train calls             171000
trainer/QF1 Loss                      1338.83
trainer/QF2 Loss                      1340.23
trainer/Policy Loss                    565.595
trainer/Q1 Predictions Mean           -565.802
trainer/Q1 Predictions Std              37.1552
trainer/Q1 Predictions Max            -415.946
trainer/Q1 Predictions Min            -625.073
trainer/Q2 Predictions Mean           -565.806
trainer/Q2 Predictions Std              37.1339
trainer/Q2 Predictions Max            -416.653
trainer/Q2 Predictions Min            -624.163
trainer/Q Targets Mean                -565.479
trainer/Q Targets Std                   51.2258
trainer/Q Targets Max                   -5.66168
trainer/Q Targets Min                 -626.352
trainer/Log Pis Mean                     2.41858
trainer/Log Pis Std                      3.43592
trainer/Log Pis Max                     13.988
trainer/Log Pis Min                     -4.31865
trainer/policy/mean Mean                -0.31378
trainer/policy/mean Std                  0.751045
trainer/policy/mean Max                  0.999929
trainer/policy/mean Min                 -0.998907
trainer/policy/normal/std Mean           0.619115
trainer/policy/normal/std Std            0.095284
trainer/policy/normal/std Max            0.787197
trainer/policy/normal/std Min            0.428083
trainer/policy/normal/log_std Mean      -0.491925
trainer/policy/normal/log_std Std        0.16
trainer/policy/normal/log_std Max       -0.239277
trainer/policy/normal/log_std Min       -0.848438
trainer/Alpha                            0.0249331
trainer/Alpha Loss                       1.5452
exploration/num steps total         344000
exploration/num paths total           1720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.29443
exploration/Rewards Std                  0.525148
exploration/Rewards Max                 -3.35534
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1058.89
exploration/Returns Std                 61.1325
exploration/Returns Max               -953.495
exploration/Returns Min              -1147.24
exploration/Actions Mean                -0.380576
exploration/Actions Std                  0.686251
exploration/Actions Max                  0.999988
exploration/Actions Min                 -0.999822
exploration/Num Paths                   10
exploration/Average Returns          -1058.89
evaluation/num steps total          824904
evaluation/num paths total            4104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.55134
evaluation/Rewards Std                   0.571847
evaluation/Rewards Max                  -3.3795
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1115.82
evaluation/Returns Std                 108.392
evaluation/Returns Max                -704.22
evaluation/Returns Min               -1208.03
evaluation/Actions Mean                 -0.227178
evaluation/Actions Std                   0.793031
evaluation/Actions Max                   0.996133
evaluation/Actions Min                  -0.990452
evaluation/Num Paths                    24
evaluation/Average Returns           -1115.82
time/data storing (s)                    0.0224427
time/evaluation sampling (s)            12.855
time/exploration sampling (s)            5.59847
time/logging (s)                         0.0166988
time/sac training (s)                   12.7427
time/saving (s)                          0.0178559
time/training (s)                        9.5185e-05
time/epoch (s)                          31.2533
time/total (s)                        5489.94
Epoch                                  170
----------------------------------  ---------------
2020-11-09 14:53:58.660133 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 171 finished
----------------------------------  ---------------
replay_buffer/size                  346000
trainer/num train calls             172000
trainer/QF1 Loss                      3582.65
trainer/QF2 Loss                      3573.18
trainer/Policy Loss                    566.179
trainer/Q1 Predictions Mean           -566.271
trainer/Q1 Predictions Std              39.1324
trainer/Q1 Predictions Max            -398.533
trainer/Q1 Predictions Min            -649.294
trainer/Q2 Predictions Mean           -566.301
trainer/Q2 Predictions Std              39.1136
trainer/Q2 Predictions Max            -398.673
trainer/Q2 Predictions Min            -650.243
trainer/Q Targets Mean                -561.921
trainer/Q Targets Std                   72.4464
trainer/Q Targets Max                   -2.38459
trainer/Q Targets Min                 -650.716
trainer/Log Pis Mean                     1.85012
trainer/Log Pis Std                      3.29885
trainer/Log Pis Max                     18.9324
trainer/Log Pis Min                     -4.32049
trainer/policy/mean Mean                -0.276202
trainer/policy/mean Std                  0.749642
trainer/policy/mean Max                  0.999991
trainer/policy/mean Min                 -0.99913
trainer/policy/normal/std Mean           0.707699
trainer/policy/normal/std Std            0.0879049
trainer/policy/normal/std Max            1.11358
trainer/policy/normal/std Min            0.513232
trainer/policy/normal/log_std Mean      -0.353307
trainer/policy/normal/log_std Std        0.122708
trainer/policy/normal/log_std Max        0.107581
trainer/policy/normal/log_std Min       -0.667028
trainer/Alpha                            0.0255884
trainer/Alpha Loss                      -0.549405
exploration/num steps total         346000
exploration/num paths total           1730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.50988
exploration/Rewards Std                  0.349465
exploration/Rewards Max                 -3.95449
exploration/Rewards Min                 -6.14164
exploration/Returns Mean             -1101.98
exploration/Returns Std                 26.0193
exploration/Returns Max              -1048.95
exploration/Returns Min              -1140.88
exploration/Actions Mean                -0.250378
exploration/Actions Std                  0.758781
exploration/Actions Max                  0.999954
exploration/Actions Min                 -0.999726
exploration/Num Paths                   10
exploration/Average Returns          -1101.98
evaluation/num steps total          829728
evaluation/num paths total            4128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.68182
evaluation/Rewards Std                   0.509878
evaluation/Rewards Max                  -3.32657
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1142.05
evaluation/Returns Std                  98.0519
evaluation/Returns Max                -682.794
evaluation/Returns Min               -1200.61
evaluation/Actions Mean                 -0.249853
evaluation/Actions Std                   0.730644
evaluation/Actions Max                   0.996104
evaluation/Actions Min                  -0.983078
evaluation/Num Paths                    24
evaluation/Average Returns           -1142.05
time/data storing (s)                    0.0210124
time/evaluation sampling (s)            12.8626
time/exploration sampling (s)            5.25892
time/logging (s)                         0.0276142
time/sac training (s)                   13.1667
time/saving (s)                          0.0241694
time/training (s)                        9.4709e-05
time/epoch (s)                          31.3611
time/total (s)                        5522.53
Epoch                                  171
----------------------------------  ---------------
2020-11-09 14:54:52.534377 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 172 finished
----------------------------------  ---------------
replay_buffer/size                  348000
trainer/num train calls             173000
trainer/QF1 Loss                      2621.51
trainer/QF2 Loss                      2621.56
trainer/Policy Loss                    568.258
trainer/Q1 Predictions Mean           -568.468
trainer/Q1 Predictions Std              36.0878
trainer/Q1 Predictions Max            -392.725
trainer/Q1 Predictions Min            -664.972
trainer/Q2 Predictions Mean           -568.52
trainer/Q2 Predictions Std              36.088
trainer/Q2 Predictions Max            -392.853
trainer/Q2 Predictions Min            -665.861
trainer/Q Targets Mean                -566.062
trainer/Q Targets Std                   61.5574
trainer/Q Targets Max                   -5.15527
trainer/Q Targets Min                 -665.759
trainer/Log Pis Mean                     1.42787
trainer/Log Pis Std                      2.2682
trainer/Log Pis Max                      7.94772
trainer/Log Pis Min                     -5.68444
trainer/policy/mean Mean                 0.0331418
trainer/policy/mean Std                  0.789955
trainer/policy/mean Max                  0.999577
trainer/policy/mean Min                 -0.98784
trainer/policy/normal/std Mean           0.551133
trainer/policy/normal/std Std            0.0749291
trainer/policy/normal/std Max            0.746464
trainer/policy/normal/std Min            0.367948
trainer/policy/normal/log_std Mean      -0.605438
trainer/policy/normal/log_std Std        0.140676
trainer/policy/normal/log_std Max       -0.292408
trainer/policy/normal/log_std Min       -0.999813
trainer/Alpha                            0.025049
trainer/Alpha Loss                      -2.1094
exploration/num steps total         348000
exploration/num paths total           1740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.05593
exploration/Rewards Std                  0.0980261
exploration/Rewards Max                 -5.58805
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1211.19
exploration/Returns Std                 22.9262
exploration/Returns Max              -1155.01
exploration/Returns Min              -1228.18
exploration/Actions Mean                -0.0657933
exploration/Actions Std                  0.765398
exploration/Actions Max                  0.996501
exploration/Actions Min                 -0.996071
exploration/Num Paths                   10
exploration/Average Returns          -1211.19
evaluation/num steps total          834552
evaluation/num paths total            4152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.10406
evaluation/Rewards Std                   0.045686
evaluation/Rewards Max                  -5.76662
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1226.92
evaluation/Returns Std                   5.19024
evaluation/Returns Max               -1212.85
evaluation/Returns Min               -1232.86
evaluation/Actions Mean                 -0.0742867
evaluation/Actions Std                   0.647365
evaluation/Actions Max                   0.902816
evaluation/Actions Min                  -0.960737
evaluation/Num Paths                    24
evaluation/Average Returns           -1226.92
time/data storing (s)                    0.0443478
time/evaluation sampling (s)            20.0803
time/exploration sampling (s)            9.43695
time/logging (s)                         0.0292784
time/sac training (s)                   21.209
time/saving (s)                          0.0540921
time/training (s)                        0.00017677
time/epoch (s)                          50.8541
time/total (s)                        5576.37
Epoch                                  172
----------------------------------  ---------------
2020-11-09 14:55:29.819941 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 173 finished
----------------------------------  ----------------
replay_buffer/size                  350000
trainer/num train calls             174000
trainer/QF1 Loss                      2231.82
trainer/QF2 Loss                      2235.71
trainer/Policy Loss                    563.465
trainer/Q1 Predictions Mean           -563.627
trainer/Q1 Predictions Std              41.7312
trainer/Q1 Predictions Max            -402.197
trainer/Q1 Predictions Min            -622.03
trainer/Q2 Predictions Mean           -563.583
trainer/Q2 Predictions Std              41.6969
trainer/Q2 Predictions Max            -402.438
trainer/Q2 Predictions Min            -622.299
trainer/Q Targets Mean                -561.702
trainer/Q Targets Std                   64.3993
trainer/Q Targets Max                   -3.7816
trainer/Q Targets Min                 -620.442
trainer/Log Pis Mean                     1.71062
trainer/Log Pis Std                      2.43842
trainer/Log Pis Max                     11.1462
trainer/Log Pis Min                     -3.8457
trainer/policy/mean Mean                 0.00752725
trainer/policy/mean Std                  0.787318
trainer/policy/mean Max                  0.999945
trainer/policy/mean Min                 -0.986242
trainer/policy/normal/std Mean           0.566414
trainer/policy/normal/std Std            0.0513114
trainer/policy/normal/std Max            0.701138
trainer/policy/normal/std Min            0.411136
trainer/policy/normal/log_std Mean      -0.572683
trainer/policy/normal/log_std Std        0.0931723
trainer/policy/normal/log_std Max       -0.355051
trainer/policy/normal/log_std Min       -0.888832
trainer/Alpha                            0.0250687
trainer/Alpha Loss                      -1.0667
exploration/num steps total         350000
exploration/num paths total           1750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.67434
exploration/Rewards Std                  0.750665
exploration/Rewards Max                 -3.34666
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1134.87
exploration/Returns Std                145.165
exploration/Returns Max               -710.099
exploration/Returns Min              -1221.61
exploration/Actions Mean                -0.00209793
exploration/Actions Std                  0.779272
exploration/Actions Max                  0.999741
exploration/Actions Min                 -0.996964
exploration/Num Paths                   10
exploration/Average Returns          -1134.87
evaluation/num steps total          839376
evaluation/num paths total            4176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07115
evaluation/Rewards Std                   0.0785933
evaluation/Rewards Max                  -5.72282
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1220.3
evaluation/Returns Std                  10.4478
evaluation/Returns Max               -1181.77
evaluation/Returns Min               -1232
evaluation/Actions Mean                 -0.0900616
evaluation/Actions Std                   0.496287
evaluation/Actions Max                   0.955712
evaluation/Actions Min                  -0.954621
evaluation/Num Paths                    24
evaluation/Average Returns           -1220.3
time/data storing (s)                    0.0210881
time/evaluation sampling (s)            17.7325
time/exploration sampling (s)            5.56124
time/logging (s)                         0.021214
time/sac training (s)                   12.5578
time/saving (s)                          0.022563
time/training (s)                        0.000125774
time/epoch (s)                          35.9165
time/total (s)                        5613.62
Epoch                                  173
----------------------------------  ----------------
2020-11-09 14:56:02.654181 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 174 finished
----------------------------------  ---------------
replay_buffer/size                  352000
trainer/num train calls             175000
trainer/QF1 Loss                      1445.42
trainer/QF2 Loss                      1444.43
trainer/Policy Loss                    564.519
trainer/Q1 Predictions Mean           -564.821
trainer/Q1 Predictions Std              38.917
trainer/Q1 Predictions Max            -388.666
trainer/Q1 Predictions Min            -631.391
trainer/Q2 Predictions Mean           -564.852
trainer/Q2 Predictions Std              38.9233
trainer/Q2 Predictions Max            -388.554
trainer/Q2 Predictions Min            -631.839
trainer/Q Targets Mean                -565.078
trainer/Q Targets Std                   52.3306
trainer/Q Targets Max                   -4.839
trainer/Q Targets Min                 -633.861
trainer/Log Pis Mean                     2.6292
trainer/Log Pis Std                      2.81139
trainer/Log Pis Max                     14.5622
trainer/Log Pis Min                     -2.3342
trainer/policy/mean Mean                -0.326415
trainer/policy/mean Std                  0.749789
trainer/policy/mean Max                  0.999888
trainer/policy/mean Min                 -0.998972
trainer/policy/normal/std Mean           0.570575
trainer/policy/normal/std Std            0.096649
trainer/policy/normal/std Max            0.721313
trainer/policy/normal/std Min            0.354329
trainer/policy/normal/log_std Mean      -0.576726
trainer/policy/normal/log_std Std        0.180664
trainer/policy/normal/log_std Max       -0.326682
trainer/policy/normal/log_std Min       -1.03753
trainer/Alpha                            0.0254824
trainer/Alpha Loss                       2.30903
exploration/num steps total         352000
exploration/num paths total           1760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.29206
exploration/Rewards Std                  0.45095
exploration/Rewards Max                 -3.28823
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1058.41
exploration/Returns Std                 51.1538
exploration/Returns Max               -975.202
exploration/Returns Min              -1143.31
exploration/Actions Mean                -0.323898
exploration/Actions Std                  0.754655
exploration/Actions Max                  0.999627
exploration/Actions Min                 -0.999478
exploration/Num Paths                   10
exploration/Average Returns          -1058.41
evaluation/num steps total          844200
evaluation/num paths total            4200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60345
evaluation/Rewards Std                   0.319521
evaluation/Rewards Max                  -4.77504
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1126.29
evaluation/Returns Std                  51.0881
evaluation/Returns Max                -979.434
evaluation/Returns Min               -1203.49
evaluation/Actions Mean                 -0.367797
evaluation/Actions Std                   0.696061
evaluation/Actions Max                   0.995564
evaluation/Actions Min                  -0.992769
evaluation/Num Paths                    24
evaluation/Average Returns           -1126.29
time/data storing (s)                    0.021416
time/evaluation sampling (s)            13.2602
time/exploration sampling (s)            5.36853
time/logging (s)                         0.0196945
time/sac training (s)                   12.8833
time/saving (s)                          0.0234115
time/training (s)                        9.7885e-05
time/epoch (s)                          31.5766
time/total (s)                        5646.43
Epoch                                  174
----------------------------------  ---------------
2020-11-09 14:56:35.639908 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 175 finished
----------------------------------  ----------------
replay_buffer/size                  354000
trainer/num train calls             176000
trainer/QF1 Loss                        11.7003
trainer/QF2 Loss                        11.8801
trainer/Policy Loss                    565.236
trainer/Q1 Predictions Mean           -565.505
trainer/Q1 Predictions Std              36.1892
trainer/Q1 Predictions Max            -397.073
trainer/Q1 Predictions Min            -616.24
trainer/Q2 Predictions Mean           -565.519
trainer/Q2 Predictions Std              36.165
trainer/Q2 Predictions Max            -397.242
trainer/Q2 Predictions Min            -616.279
trainer/Q Targets Mean                -567.49
trainer/Q Targets Std                   36.5876
trainer/Q Targets Max                 -397.635
trainer/Q Targets Min                 -617.838
trainer/Log Pis Mean                     1.92135
trainer/Log Pis Std                      2.34437
trainer/Log Pis Max                     10.4375
trainer/Log Pis Min                     -3.9327
trainer/policy/mean Mean                -0.0118204
trainer/policy/mean Std                  0.817147
trainer/policy/mean Max                  0.999906
trainer/policy/mean Min                 -0.990588
trainer/policy/normal/std Mean           0.571741
trainer/policy/normal/std Std            0.0553546
trainer/policy/normal/std Max            0.713757
trainer/policy/normal/std Min            0.413036
trainer/policy/normal/log_std Mean      -0.564023
trainer/policy/normal/log_std Std        0.100998
trainer/policy/normal/log_std Max       -0.337212
trainer/policy/normal/log_std Min       -0.884221
trainer/Alpha                            0.0256333
trainer/Alpha Loss                      -0.288173
exploration/num steps total         354000
exploration/num paths total           1770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.56081
exploration/Rewards Std                  0.958981
exploration/Rewards Max                 -3.18936
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1112.16
exploration/Returns Std                154.523
exploration/Returns Max               -767.596
exploration/Returns Min              -1224.18
exploration/Actions Mean                -0.0209958
exploration/Actions Std                  0.751687
exploration/Actions Max                  0.999312
exploration/Actions Min                 -0.998267
exploration/Num Paths                   10
exploration/Average Returns          -1112.16
evaluation/num steps total          849024
evaluation/num paths total            4224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.08306
evaluation/Rewards Std                   0.0702501
evaluation/Rewards Max                  -5.85087
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1222.69
evaluation/Returns Std                   9.79707
evaluation/Returns Max               -1193.04
evaluation/Returns Min               -1231.51
evaluation/Actions Mean                 -0.0831816
evaluation/Actions Std                   0.496977
evaluation/Actions Max                   0.963365
evaluation/Actions Min                  -0.959888
evaluation/Num Paths                    24
evaluation/Average Returns           -1222.69
time/data storing (s)                    0.0211643
time/evaluation sampling (s)            12.4353
time/exploration sampling (s)            5.1965
time/logging (s)                         0.029064
time/sac training (s)                   13.9986
time/saving (s)                          0.0351776
time/training (s)                        0.000152906
time/epoch (s)                          31.7159
time/total (s)                        5679.4
Epoch                                  175
----------------------------------  ----------------
2020-11-09 14:57:09.837714 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 176 finished
----------------------------------  ----------------
replay_buffer/size                  356000
trainer/num train calls             177000
trainer/QF1 Loss                      3478.19
trainer/QF2 Loss                      3480.6
trainer/Policy Loss                    562.01
trainer/Q1 Predictions Mean           -562.109
trainer/Q1 Predictions Std              40.5182
trainer/Q1 Predictions Max            -362.581
trainer/Q1 Predictions Min            -612.186
trainer/Q2 Predictions Mean           -562.137
trainer/Q2 Predictions Std              40.5123
trainer/Q2 Predictions Max            -362.54
trainer/Q2 Predictions Min            -611.818
trainer/Q Targets Mean                -558.449
trainer/Q Targets Std                   72.6347
trainer/Q Targets Max                   -4.07439
trainer/Q Targets Min                 -614.278
trainer/Log Pis Mean                     2.02342
trainer/Log Pis Std                      2.50691
trainer/Log Pis Max                     13.0142
trainer/Log Pis Min                     -5.75403
trainer/policy/mean Mean                 0.193506
trainer/policy/mean Std                  0.78983
trainer/policy/mean Max                  0.999995
trainer/policy/mean Min                 -0.986846
trainer/policy/normal/std Mean           0.626606
trainer/policy/normal/std Std            0.0956885
trainer/policy/normal/std Max            0.895739
trainer/policy/normal/std Min            0.442305
trainer/policy/normal/log_std Mean      -0.47869
trainer/policy/normal/log_std Std        0.149032
trainer/policy/normal/log_std Max       -0.110106
trainer/policy/normal/log_std Min       -0.815756
trainer/Alpha                            0.0262351
trainer/Alpha Loss                       0.0852793
exploration/num steps total         356000
exploration/num paths total           1780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.71158
exploration/Rewards Std                  1.11813
exploration/Rewards Max                 -0.843777
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1142.32
exploration/Returns Std                192.982
exploration/Returns Max               -566.893
exploration/Returns Min              -1228.48
exploration/Actions Mean                 0.148821
exploration/Actions Std                  0.784862
exploration/Actions Max                  0.999853
exploration/Actions Min                 -0.997843
exploration/Num Paths                   10
exploration/Average Returns          -1142.32
evaluation/num steps total          853848
evaluation/num paths total            4248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.98397
evaluation/Rewards Std                   0.515638
evaluation/Rewards Max                  -3.39177
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1202.78
evaluation/Returns Std                 100.023
evaluation/Returns Max                -725.691
evaluation/Returns Min               -1232.45
evaluation/Actions Mean                  0.140665
evaluation/Actions Std                   0.733756
evaluation/Actions Max                   0.987598
evaluation/Actions Min                  -0.890464
evaluation/Num Paths                    24
evaluation/Average Returns           -1202.78
time/data storing (s)                    0.0218548
time/evaluation sampling (s)            13.6722
time/exploration sampling (s)            5.12828
time/logging (s)                         0.0217018
time/sac training (s)                   13.7478
time/saving (s)                          0.0273196
time/training (s)                        0.000138514
time/epoch (s)                          32.6193
time/total (s)                        5713.56
Epoch                                  176
----------------------------------  ----------------
2020-11-09 14:57:41.851069 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 177 finished
----------------------------------  ---------------
replay_buffer/size                  358000
trainer/num train calls             178000
trainer/QF1 Loss                      2667.78
trainer/QF2 Loss                      2667.35
trainer/Policy Loss                    559.07
trainer/Q1 Predictions Mean           -559.168
trainer/Q1 Predictions Std              46.1414
trainer/Q1 Predictions Max            -350.026
trainer/Q1 Predictions Min            -666.605
trainer/Q2 Predictions Mean           -559.194
trainer/Q2 Predictions Std              46.1272
trainer/Q2 Predictions Max            -349.815
trainer/Q2 Predictions Min            -667.715
trainer/Q Targets Mean                -557.738
trainer/Q Targets Std                   67.5678
trainer/Q Targets Max                   -5.2885
trainer/Q Targets Min                 -668.346
trainer/Log Pis Mean                     2.40972
trainer/Log Pis Std                      3.46806
trainer/Log Pis Max                     14.3394
trainer/Log Pis Min                     -5.01799
trainer/policy/mean Mean                -0.177579
trainer/policy/mean Std                  0.798347
trainer/policy/mean Max                  0.999991
trainer/policy/mean Min                 -0.998567
trainer/policy/normal/std Mean           0.64198
trainer/policy/normal/std Std            0.0836253
trainer/policy/normal/std Max            0.817873
trainer/policy/normal/std Min            0.444359
trainer/policy/normal/log_std Mean      -0.452418
trainer/policy/normal/log_std Std        0.138725
trainer/policy/normal/log_std Max       -0.201048
trainer/policy/normal/log_std Min       -0.811122
trainer/Alpha                            0.0270037
trainer/Alpha Loss                       1.47981
exploration/num steps total         358000
exploration/num paths total           1790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.17715
exploration/Rewards Std                  0.896139
exploration/Rewards Max                 -3.19768
exploration/Rewards Min                 -6.14178
exploration/Returns Mean             -1035.43
exploration/Returns Std                171.095
exploration/Returns Max               -662.064
exploration/Returns Min              -1160.09
exploration/Actions Mean                -0.245453
exploration/Actions Std                  0.745777
exploration/Actions Max                  0.999997
exploration/Actions Min                 -0.999575
exploration/Num Paths                   10
exploration/Average Returns          -1035.43
evaluation/num steps total          858672
evaluation/num paths total            4272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83168
evaluation/Rewards Std                   0.22807
evaluation/Rewards Max                  -5.04609
evaluation/Rewards Min                  -6.14197
evaluation/Returns Mean              -1172.17
evaluation/Returns Std                  37.4786
evaluation/Returns Max               -1043.32
evaluation/Returns Min               -1214.36
evaluation/Actions Mean                 -0.107968
evaluation/Actions Std                   0.818079
evaluation/Actions Max                   0.999852
evaluation/Actions Min                  -0.995271
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.17
time/data storing (s)                    0.0209556
time/evaluation sampling (s)            12.6175
time/exploration sampling (s)            4.7934
time/logging (s)                         0.0205429
time/sac training (s)                   13.1041
time/saving (s)                          0.0186717
time/training (s)                        9.8653e-05
time/epoch (s)                          30.5753
time/total (s)                        5745.54
Epoch                                  177
----------------------------------  ---------------
2020-11-09 14:58:12.604715 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 178 finished
----------------------------------  ----------------
replay_buffer/size                  360000
trainer/num train calls             179000
trainer/QF1 Loss                        32.9445
trainer/QF2 Loss                        33.0514
trainer/Policy Loss                    565.012
trainer/Q1 Predictions Mean           -565.305
trainer/Q1 Predictions Std              32.3688
trainer/Q1 Predictions Max            -405.843
trainer/Q1 Predictions Min            -615.554
trainer/Q2 Predictions Mean           -565.275
trainer/Q2 Predictions Std              32.3668
trainer/Q2 Predictions Max            -405.749
trainer/Q2 Predictions Min            -615.328
trainer/Q Targets Mean                -568.082
trainer/Q Targets Std                   32.255
trainer/Q Targets Max                 -407.079
trainer/Q Targets Min                 -619.055
trainer/Log Pis Mean                     2.49271
trainer/Log Pis Std                      2.86357
trainer/Log Pis Max                     11.7237
trainer/Log Pis Min                     -5.42743
trainer/policy/mean Mean                -0.220279
trainer/policy/mean Std                  0.784689
trainer/policy/mean Max                  0.999961
trainer/policy/mean Min                 -0.997643
trainer/policy/normal/std Mean           0.58035
trainer/policy/normal/std Std            0.0892711
trainer/policy/normal/std Max            0.747891
trainer/policy/normal/std Min            0.376791
trainer/policy/normal/log_std Mean      -0.556439
trainer/policy/normal/log_std Std        0.158703
trainer/policy/normal/log_std Max       -0.290498
trainer/policy/normal/log_std Min       -0.976064
trainer/Alpha                            0.0271976
trainer/Alpha Loss                       1.77603
exploration/num steps total         360000
exploration/num paths total           1800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.49627
exploration/Rewards Std                  0.437219
exploration/Rewards Max                 -4.15599
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1099.25
exploration/Returns Std                 61.7653
exploration/Returns Max               -942.119
exploration/Returns Min              -1166.68
exploration/Actions Mean                -0.201629
exploration/Actions Std                  0.818227
exploration/Actions Max                  0.999963
exploration/Actions Min                 -0.999571
exploration/Num Paths                   10
exploration/Average Returns          -1099.25
evaluation/num steps total          863496
evaluation/num paths total            4296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.85629
evaluation/Rewards Std                   0.17221
evaluation/Rewards Max                  -4.06244
evaluation/Rewards Min                  -6.14004
evaluation/Returns Mean              -1177.11
evaluation/Returns Std                  19.5743
evaluation/Returns Max               -1127.84
evaluation/Returns Min               -1207.53
evaluation/Actions Mean                 -0.191627
evaluation/Actions Std                   0.780446
evaluation/Actions Max                   0.997667
evaluation/Actions Min                  -0.988686
evaluation/Num Paths                    24
evaluation/Average Returns           -1177.11
time/data storing (s)                    0.0205214
time/evaluation sampling (s)            12.6238
time/exploration sampling (s)            4.74741
time/logging (s)                         0.0231018
time/sac training (s)                   12.0949
time/saving (s)                          0.0324709
time/training (s)                        0.000113301
time/epoch (s)                          29.5423
time/total (s)                        5776.28
Epoch                                  178
----------------------------------  ----------------
2020-11-09 14:58:40.486936 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 179 finished
----------------------------------  ----------------
replay_buffer/size                  362000
trainer/num train calls             180000
trainer/QF1 Loss                      2496.48
trainer/QF2 Loss                      2502.33
trainer/Policy Loss                    567.215
trainer/Q1 Predictions Mean           -567.448
trainer/Q1 Predictions Std              32.0999
trainer/Q1 Predictions Max            -404.462
trainer/Q1 Predictions Min            -620.273
trainer/Q2 Predictions Mean           -567.486
trainer/Q2 Predictions Std              32.0684
trainer/Q2 Predictions Max            -404.493
trainer/Q2 Predictions Min            -620.959
trainer/Q Targets Mean                -565.003
trainer/Q Targets Std                   59.0868
trainer/Q Targets Max                   -3.12462
trainer/Q Targets Min                 -621.505
trainer/Log Pis Mean                     1.39714
trainer/Log Pis Std                      2.35502
trainer/Log Pis Max                     10.6139
trainer/Log Pis Min                     -4.91119
trainer/policy/mean Mean                -0.0796575
trainer/policy/mean Std                  0.79886
trainer/policy/mean Max                  0.999769
trainer/policy/mean Min                 -0.988143
trainer/policy/normal/std Mean           0.636816
trainer/policy/normal/std Std            0.0830974
trainer/policy/normal/std Max            0.7964
trainer/policy/normal/std Min            0.415454
trainer/policy/normal/log_std Mean      -0.460412
trainer/policy/normal/log_std Std        0.137707
trainer/policy/normal/log_std Max       -0.227653
trainer/policy/normal/log_std Min       -0.878384
trainer/Alpha                            0.0277188
trainer/Alpha Loss                      -2.16166
exploration/num steps total         362000
exploration/num paths total           1810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.9456
exploration/Rewards Std                  0.145651
exploration/Rewards Max                 -5.33963
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1189.12
exploration/Returns Std                 22.0708
exploration/Returns Max              -1142.43
exploration/Returns Min              -1216.95
exploration/Actions Mean                -0.203341
exploration/Actions Std                  0.69745
exploration/Actions Max                  0.999547
exploration/Actions Min                 -0.998609
exploration/Num Paths                   10
exploration/Average Returns          -1189.12
evaluation/num steps total          868320
evaluation/num paths total            4320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97181
evaluation/Rewards Std                   0.188566
evaluation/Rewards Max                  -4.8929
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1200.33
evaluation/Returns Std                  27.4842
evaluation/Returns Max               -1108.73
evaluation/Returns Min               -1228.06
evaluation/Actions Mean                 -0.13413
evaluation/Actions Std                   0.527979
evaluation/Actions Max                   0.974515
evaluation/Actions Min                  -0.965819
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.33
time/data storing (s)                    0.0204417
time/evaluation sampling (s)            10.4959
time/exploration sampling (s)            4.29744
time/logging (s)                         0.0226968
time/sac training (s)                   11.8552
time/saving (s)                          0.0228132
time/training (s)                        0.000122379
time/epoch (s)                          26.7146
time/total (s)                        5804.14
Epoch                                  179
----------------------------------  ----------------
2020-11-09 14:59:15.440471 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 180 finished
----------------------------------  ----------------
replay_buffer/size                  364000
trainer/num train calls             181000
trainer/QF1 Loss                        19.3473
trainer/QF2 Loss                        19.7087
trainer/Policy Loss                    562.047
trainer/Q1 Predictions Mean           -562.501
trainer/Q1 Predictions Std              41.6379
trainer/Q1 Predictions Max            -385.775
trainer/Q1 Predictions Min            -616.02
trainer/Q2 Predictions Mean           -562.473
trainer/Q2 Predictions Std              41.6551
trainer/Q2 Predictions Max            -385.623
trainer/Q2 Predictions Min            -616.561
trainer/Q Targets Mean                -565.513
trainer/Q Targets Std                   41.8316
trainer/Q Targets Max                 -390.696
trainer/Q Targets Min                 -618.674
trainer/Log Pis Mean                     2.91214
trainer/Log Pis Std                      3.91585
trainer/Log Pis Max                     17.4346
trainer/Log Pis Min                     -3.32459
trainer/policy/mean Mean                -0.254959
trainer/policy/mean Std                  0.79941
trainer/policy/mean Max                  0.999996
trainer/policy/mean Min                 -0.998983
trainer/policy/normal/std Mean           0.636849
trainer/policy/normal/std Std            0.0845531
trainer/policy/normal/std Max            0.816279
trainer/policy/normal/std Min            0.454891
trainer/policy/normal/log_std Mean      -0.460316
trainer/policy/normal/log_std Std        0.136002
trainer/policy/normal/log_std Max       -0.203
trainer/policy/normal/log_std Min       -0.787697
trainer/Alpha                            0.0284319
trainer/Alpha Loss                       3.24745
exploration/num steps total         364000
exploration/num paths total           1820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.55009
exploration/Rewards Std                  0.329546
exploration/Rewards Max                 -4.53612
exploration/Rewards Min                 -6.14172
exploration/Returns Mean             -1110.02
exploration/Returns Std                 46.1585
exploration/Returns Max              -1032.26
exploration/Returns Min              -1179.51
exploration/Actions Mean                -0.125843
exploration/Actions Std                  0.895996
exploration/Actions Max                  0.999996
exploration/Actions Min                 -0.999863
exploration/Num Paths                   10
exploration/Average Returns          -1110.02
evaluation/num steps total          873144
evaluation/num paths total            4344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.57842
evaluation/Rewards Std                   0.702175
evaluation/Rewards Max                  -3.18997
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1121.26
evaluation/Returns Std                 132.783
evaluation/Returns Max                -698.758
evaluation/Returns Min               -1216.2
evaluation/Actions Mean                 -0.179526
evaluation/Actions Std                   0.85673
evaluation/Actions Max                   0.999217
evaluation/Actions Min                  -0.991163
evaluation/Num Paths                    24
evaluation/Average Returns           -1121.26
time/data storing (s)                    0.021626
time/evaluation sampling (s)            14.2194
time/exploration sampling (s)            5.23325
time/logging (s)                         0.0199683
time/sac training (s)                   12.7218
time/saving (s)                          0.0217948
time/training (s)                        0.000137193
time/epoch (s)                          32.2379
time/total (s)                        5839.06
Epoch                                  180
----------------------------------  ----------------
2020-11-09 14:59:49.390837 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 181 finished
----------------------------------  ----------------
replay_buffer/size                  366000
trainer/num train calls             182000
trainer/QF1 Loss                      1276.78
trainer/QF2 Loss                      1275.62
trainer/Policy Loss                    566.892
trainer/Q1 Predictions Mean           -567.01
trainer/Q1 Predictions Std              35.7213
trainer/Q1 Predictions Max            -403.573
trainer/Q1 Predictions Min            -653.221
trainer/Q2 Predictions Mean           -566.973
trainer/Q2 Predictions Std              35.7168
trainer/Q2 Predictions Max            -403.571
trainer/Q2 Predictions Min            -654.276
trainer/Q Targets Mean                -566.377
trainer/Q Targets Std                   50.3473
trainer/Q Targets Max                   -5.97249
trainer/Q Targets Min                 -653.622
trainer/Log Pis Mean                     1.79474
trainer/Log Pis Std                      3.07785
trainer/Log Pis Max                     15.6529
trainer/Log Pis Min                     -5.11383
trainer/policy/mean Mean                -0.186272
trainer/policy/mean Std                  0.776766
trainer/policy/mean Max                  0.999992
trainer/policy/mean Min                 -0.996821
trainer/policy/normal/std Mean           0.669614
trainer/policy/normal/std Std            0.0834851
trainer/policy/normal/std Max            0.951069
trainer/policy/normal/std Min            0.499076
trainer/policy/normal/log_std Mean      -0.408712
trainer/policy/normal/log_std Std        0.123406
trainer/policy/normal/log_std Max       -0.050169
trainer/policy/normal/log_std Min       -0.694996
trainer/Alpha                            0.028938
trainer/Alpha Loss                      -0.727166
exploration/num steps total         366000
exploration/num paths total           1830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.51755
exploration/Rewards Std                  0.471523
exploration/Rewards Max                 -3.64212
exploration/Rewards Min                 -6.14184
exploration/Returns Mean             -1103.51
exploration/Returns Std                 47.8295
exploration/Returns Max               -977.727
exploration/Returns Min              -1173.64
exploration/Actions Mean                -0.204463
exploration/Actions Std                  0.753018
exploration/Actions Max                  0.999802
exploration/Actions Min                 -0.999271
exploration/Num Paths                   10
exploration/Average Returns          -1103.51
evaluation/num steps total          877968
evaluation/num paths total            4368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.69804
evaluation/Rewards Std                   0.689619
evaluation/Rewards Max                  -3.39504
evaluation/Rewards Min                  -6.14192
evaluation/Returns Mean              -1145.31
evaluation/Returns Std                 135.415
evaluation/Returns Max                -691.424
evaluation/Returns Min               -1214.9
evaluation/Actions Mean                 -0.156379
evaluation/Actions Std                   0.801862
evaluation/Actions Max                   0.989577
evaluation/Actions Min                  -0.959799
evaluation/Num Paths                    24
evaluation/Average Returns           -1145.31
time/data storing (s)                    0.0227563
time/evaluation sampling (s)            13.9909
time/exploration sampling (s)            5.41651
time/logging (s)                         0.0180502
time/sac training (s)                   12.7792
time/saving (s)                          0.0238905
time/training (s)                        0.000125903
time/epoch (s)                          32.2514
time/total (s)                        5872.99
Epoch                                  181
----------------------------------  ----------------
2020-11-09 15:00:25.166984 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 182 finished
----------------------------------  ----------------
replay_buffer/size                  368000
trainer/num train calls             183000
trainer/QF1 Loss                      3701.6
trainer/QF2 Loss                      3703.43
trainer/Policy Loss                    564.794
trainer/Q1 Predictions Mean           -564.988
trainer/Q1 Predictions Std              35.0436
trainer/Q1 Predictions Max            -385.176
trainer/Q1 Predictions Min            -650.212
trainer/Q2 Predictions Mean           -564.985
trainer/Q2 Predictions Std              35.0674
trainer/Q2 Predictions Max            -385.09
trainer/Q2 Predictions Min            -651.322
trainer/Q Targets Mean                -561.39
trainer/Q Targets Std                   70.0717
trainer/Q Targets Max                   -4.96178
trainer/Q Targets Min                 -653.047
trainer/Log Pis Mean                     1.70552
trainer/Log Pis Std                      2.43737
trainer/Log Pis Max                     10.9457
trainer/Log Pis Min                     -8.10015
trainer/policy/mean Mean                -0.432316
trainer/policy/mean Std                  0.68719
trainer/policy/mean Max                  0.999753
trainer/policy/mean Min                 -0.997351
trainer/policy/normal/std Mean           0.580069
trainer/policy/normal/std Std            0.116877
trainer/policy/normal/std Max            0.785267
trainer/policy/normal/std Min            0.370441
trainer/policy/normal/log_std Mean      -0.565229
trainer/policy/normal/log_std Std        0.203945
trainer/policy/normal/log_std Max       -0.241732
trainer/policy/normal/log_std Min       -0.99306
trainer/Alpha                            0.0293189
trainer/Alpha Loss                      -1.03937
exploration/num steps total         368000
exploration/num paths total           1840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.00373
exploration/Rewards Std                  0.70906
exploration/Rewards Max                 -3.0239
exploration/Rewards Min                 -6.14181
exploration/Returns Mean             -1000.75
exploration/Returns Std                 73.0508
exploration/Returns Max               -892.216
exploration/Returns Min              -1115.44
exploration/Actions Mean                -0.456094
exploration/Actions Std                  0.637637
exploration/Actions Max                  0.999602
exploration/Actions Min                 -0.999367
exploration/Num Paths                   10
exploration/Average Returns          -1000.75
evaluation/num steps total          882792
evaluation/num paths total            4392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67125
evaluation/Rewards Std                   0.336775
evaluation/Rewards Max                  -4.61565
evaluation/Rewards Min                  -6.14195
evaluation/Returns Mean              -1139.92
evaluation/Returns Std                  59.7301
evaluation/Returns Max                -976.93
evaluation/Returns Min               -1206.59
evaluation/Actions Mean                 -0.325411
evaluation/Actions Std                   0.699257
evaluation/Actions Max                   0.998532
evaluation/Actions Min                  -0.994696
evaluation/Num Paths                    24
evaluation/Average Returns           -1139.92
time/data storing (s)                    0.0236051
time/evaluation sampling (s)            12.1001
time/exploration sampling (s)            5.08653
time/logging (s)                         0.0244496
time/sac training (s)                   15.9
time/saving (s)                          0.025015
time/training (s)                        0.000136614
time/epoch (s)                          33.1599
time/total (s)                        5908.74
Epoch                                  182
----------------------------------  ----------------
2020-11-09 15:00:55.924837 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 183 finished
----------------------------------  ----------------
replay_buffer/size                  370000
trainer/num train calls             184000
trainer/QF1 Loss                        11.1256
trainer/QF2 Loss                        11.1364
trainer/Policy Loss                    558.151
trainer/Q1 Predictions Mean           -558.315
trainer/Q1 Predictions Std              40.4756
trainer/Q1 Predictions Max            -380.088
trainer/Q1 Predictions Min            -643.167
trainer/Q2 Predictions Mean           -558.31
trainer/Q2 Predictions Std              40.481
trainer/Q2 Predictions Max            -380.055
trainer/Q2 Predictions Min            -644.069
trainer/Q Targets Mean                -560.768
trainer/Q Targets Std                   40.8597
trainer/Q Targets Max                 -381.368
trainer/Q Targets Min                 -645.303
trainer/Log Pis Mean                     1.5003
trainer/Log Pis Std                      2.66439
trainer/Log Pis Max                      9.8584
trainer/Log Pis Min                     -3.26519
trainer/policy/mean Mean                 0.14943
trainer/policy/mean Std                  0.715128
trainer/policy/mean Max                  0.999989
trainer/policy/mean Min                 -0.972974
trainer/policy/normal/std Mean           0.732831
trainer/policy/normal/std Std            0.0679575
trainer/policy/normal/std Max            0.977646
trainer/policy/normal/std Min            0.573232
trainer/policy/normal/log_std Mean      -0.31517
trainer/policy/normal/log_std Std        0.0932888
trainer/policy/normal/log_std Max       -0.0226079
trainer/policy/normal/log_std Min       -0.556465
trainer/Alpha                            0.0292708
trainer/Alpha Loss                      -1.76454
exploration/num steps total         370000
exploration/num paths total           1850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.3076
exploration/Rewards Std                  1.12423
exploration/Rewards Max                 -3.2705
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1061.52
exploration/Returns Std                208.629
exploration/Returns Max               -698.838
exploration/Returns Min              -1206.22
exploration/Actions Mean                 0.0979829
exploration/Actions Std                  0.767851
exploration/Actions Max                  0.999947
exploration/Actions Min                 -0.9994
exploration/Num Paths                   10
exploration/Average Returns          -1061.52
evaluation/num steps total          887616
evaluation/num paths total            4416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.94287
evaluation/Rewards Std                   0.512478
evaluation/Rewards Max                  -3.38824
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1194.52
evaluation/Returns Std                  99.5518
evaluation/Returns Max                -718.299
evaluation/Returns Min               -1224.67
evaluation/Actions Mean                  0.155893
evaluation/Actions Std                   0.606782
evaluation/Actions Max                   0.994643
evaluation/Actions Min                  -0.850166
evaluation/Num Paths                    24
evaluation/Average Returns           -1194.52
time/data storing (s)                    0.0212848
time/evaluation sampling (s)            11.7621
time/exploration sampling (s)            4.43096
time/logging (s)                         0.0185149
time/sac training (s)                   13.1208
time/saving (s)                          0.0189143
time/training (s)                        0.000120029
time/epoch (s)                          29.3727
time/total (s)                        5939.47
Epoch                                  183
----------------------------------  ----------------
2020-11-09 15:01:25.446737 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 184 finished
----------------------------------  ----------------
replay_buffer/size                  372000
trainer/num train calls             185000
trainer/QF1 Loss                      1329.68
trainer/QF2 Loss                      1328.67
trainer/Policy Loss                    556.883
trainer/Q1 Predictions Mean           -557.273
trainer/Q1 Predictions Std              42.8182
trainer/Q1 Predictions Max            -405.354
trainer/Q1 Predictions Min            -620.746
trainer/Q2 Predictions Mean           -557.296
trainer/Q2 Predictions Std              42.8042
trainer/Q2 Predictions Max            -405.31
trainer/Q2 Predictions Min            -620.102
trainer/Q Targets Mean                -558.002
trainer/Q Targets Std                   55.1604
trainer/Q Targets Max                   -5.94364
trainer/Q Targets Min                 -623.147
trainer/Log Pis Mean                     2.54012
trainer/Log Pis Std                      2.9688
trainer/Log Pis Max                     12.6079
trainer/Log Pis Min                     -4.46347
trainer/policy/mean Mean                -0.296756
trainer/policy/mean Std                  0.8082
trainer/policy/mean Max                  0.999891
trainer/policy/mean Min                 -0.997267
trainer/policy/normal/std Mean           0.588138
trainer/policy/normal/std Std            0.0606587
trainer/policy/normal/std Max            0.777316
trainer/policy/normal/std Min            0.432048
trainer/policy/normal/log_std Mean      -0.536114
trainer/policy/normal/log_std Std        0.103256
trainer/policy/normal/log_std Max       -0.251908
trainer/policy/normal/log_std Min       -0.839218
trainer/Alpha                            0.029686
trainer/Alpha Loss                       1.89964
exploration/num steps total         372000
exploration/num paths total           1860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.8834
exploration/Rewards Std                  0.967775
exploration/Rewards Max                 -2.667
exploration/Rewards Min                 -6.14011
exploration/Returns Mean              -976.679
exploration/Returns Std                134.507
exploration/Returns Max               -659.949
exploration/Returns Min              -1105.65
exploration/Actions Mean                -0.281843
exploration/Actions Std                  0.796934
exploration/Actions Max                  0.999998
exploration/Actions Min                 -0.999717
exploration/Num Paths                   10
exploration/Average Returns           -976.679
evaluation/num steps total          892440
evaluation/num paths total            4440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.70454
evaluation/Rewards Std                   0.313821
evaluation/Rewards Max                  -3.44324
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1146.61
evaluation/Returns Std                  54.6359
evaluation/Returns Max                -972.356
evaluation/Returns Min               -1213.58
evaluation/Actions Mean                 -0.177365
evaluation/Actions Std                   0.857645
evaluation/Actions Max                   0.977023
evaluation/Actions Min                  -0.980811
evaluation/Num Paths                    24
evaluation/Average Returns           -1146.61
time/data storing (s)                    0.020473
time/evaluation sampling (s)            11.1034
time/exploration sampling (s)            4.43382
time/logging (s)                         0.0186576
time/sac training (s)                   12.5443
time/saving (s)                          0.022783
time/training (s)                        0.000119073
time/epoch (s)                          28.1436
time/total (s)                        5968.97
Epoch                                  184
----------------------------------  ----------------
2020-11-09 15:01:54.215980 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 185 finished
----------------------------------  ----------------
replay_buffer/size                  374000
trainer/num train calls             186000
trainer/QF1 Loss                      2837.66
trainer/QF2 Loss                      2835.72
trainer/Policy Loss                    564.003
trainer/Q1 Predictions Mean           -564.157
trainer/Q1 Predictions Std              36.9223
trainer/Q1 Predictions Max            -407.588
trainer/Q1 Predictions Min            -661.962
trainer/Q2 Predictions Mean           -564.15
trainer/Q2 Predictions Std              36.8949
trainer/Q2 Predictions Max            -408.131
trainer/Q2 Predictions Min            -663.06
trainer/Q Targets Mean                -561.571
trainer/Q Targets Std                   61.9039
trainer/Q Targets Max                   -3.44591
trainer/Q Targets Min                 -662.911
trainer/Log Pis Mean                     1.51196
trainer/Log Pis Std                      2.43941
trainer/Log Pis Max                      9.76539
trainer/Log Pis Min                     -4.00351
trainer/policy/mean Mean                -0.113086
trainer/policy/mean Std                  0.751239
trainer/policy/mean Max                  0.999705
trainer/policy/mean Min                 -0.984092
trainer/policy/normal/std Mean           0.621487
trainer/policy/normal/std Std            0.0867386
trainer/policy/normal/std Max            0.875026
trainer/policy/normal/std Min            0.457556
trainer/policy/normal/log_std Mean      -0.485311
trainer/policy/normal/log_std Std        0.138905
trainer/policy/normal/log_std Max       -0.133502
trainer/policy/normal/log_std Min       -0.781856
trainer/Alpha                            0.0294907
trainer/Alpha Loss                      -1.7197
exploration/num steps total         374000
exploration/num paths total           1870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.80474
exploration/Rewards Std                  0.242822
exploration/Rewards Max                 -5.07609
exploration/Rewards Min                 -6.14174
exploration/Returns Mean             -1160.95
exploration/Returns Std                 26.9067
exploration/Returns Max              -1114.89
exploration/Returns Min              -1193.67
exploration/Actions Mean                -0.104522
exploration/Actions Std                  0.753831
exploration/Actions Max                  0.999742
exploration/Actions Min                 -0.99937
exploration/Num Paths                   10
exploration/Average Returns          -1160.95
evaluation/num steps total          897264
evaluation/num paths total            4464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74599
evaluation/Rewards Std                   0.757118
evaluation/Rewards Max                  -3.38288
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1154.94
evaluation/Returns Std                 139.038
evaluation/Returns Max                -705.078
evaluation/Returns Min               -1215.79
evaluation/Actions Mean                 -0.0874476
evaluation/Actions Std                   0.675231
evaluation/Actions Max                   0.991263
evaluation/Actions Min                  -0.968651
evaluation/Num Paths                    24
evaluation/Average Returns           -1154.94
time/data storing (s)                    0.0203272
time/evaluation sampling (s)            10.8948
time/exploration sampling (s)            4.39608
time/logging (s)                         0.0181963
time/sac training (s)                   12.2542
time/saving (s)                          0.0205743
time/training (s)                        0.000100907
time/epoch (s)                          27.6043
time/total (s)                        5997.71
Epoch                                  185
----------------------------------  ----------------
2020-11-09 15:02:38.041865 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 186 finished
----------------------------------  ----------------
replay_buffer/size                  376000
trainer/num train calls             187000
trainer/QF1 Loss                      1340.46
trainer/QF2 Loss                      1338.68
trainer/Policy Loss                    560.844
trainer/Q1 Predictions Mean           -560.993
trainer/Q1 Predictions Std              42.07
trainer/Q1 Predictions Max            -386.882
trainer/Q1 Predictions Min            -661.418
trainer/Q2 Predictions Mean           -561.02
trainer/Q2 Predictions Std              42.0675
trainer/Q2 Predictions Max            -386.902
trainer/Q2 Predictions Min            -662.404
trainer/Q Targets Mean                -560.696
trainer/Q Targets Std                   54.683
trainer/Q Targets Max                   -5.55474
trainer/Q Targets Min                 -661.622
trainer/Log Pis Mean                     2.09676
trainer/Log Pis Std                      2.24065
trainer/Log Pis Max                      9.85477
trainer/Log Pis Min                     -3.02075
trainer/policy/mean Mean                 0.144911
trainer/policy/mean Std                  0.784601
trainer/policy/mean Max                  0.999886
trainer/policy/mean Min                 -0.984311
trainer/policy/normal/std Mean           0.558552
trainer/policy/normal/std Std            0.0724335
trainer/policy/normal/std Max            0.845466
trainer/policy/normal/std Min            0.391188
trainer/policy/normal/log_std Mean      -0.590501
trainer/policy/normal/log_std Std        0.12635
trainer/policy/normal/log_std Max       -0.167867
trainer/policy/normal/log_std Min       -0.938567
trainer/Alpha                            0.0291311
trainer/Alpha Loss                       0.342128
exploration/num steps total         376000
exploration/num paths total           1880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.74706
exploration/Rewards Std                  0.783556
exploration/Rewards Max                 -3.27879
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1149.41
exploration/Returns Std                152.596
exploration/Returns Max               -695.585
exploration/Returns Min              -1222.3
exploration/Actions Mean                 0.145375
exploration/Actions Std                  0.756633
exploration/Actions Max                  0.999574
exploration/Actions Min                 -0.999289
exploration/Num Paths                   10
exploration/Average Returns          -1149.41
evaluation/num steps total          902088
evaluation/num paths total            4488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.94362
evaluation/Rewards Std                   0.551746
evaluation/Rewards Max                  -3.39457
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1194.67
evaluation/Returns Std                 103.921
evaluation/Returns Max                -704.631
evaluation/Returns Min               -1231.62
evaluation/Actions Mean                  0.169061
evaluation/Actions Std                   0.688601
evaluation/Actions Max                   0.98782
evaluation/Actions Min                  -0.919128
evaluation/Num Paths                    24
evaluation/Average Returns           -1194.67
time/data storing (s)                    0.0242263
time/evaluation sampling (s)            16.5402
time/exploration sampling (s)            6.34233
time/logging (s)                         0.0302107
time/sac training (s)                   14.2729
time/saving (s)                          0.0279064
time/training (s)                        0.000120075
time/epoch (s)                          37.2379
time/total (s)                        6041.52
Epoch                                  186
----------------------------------  ----------------
2020-11-09 15:03:11.647146 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 187 finished
----------------------------------  ----------------
replay_buffer/size                  378000
trainer/num train calls             188000
trainer/QF1 Loss                      2075.43
trainer/QF2 Loss                      2075.44
trainer/Policy Loss                    560.392
trainer/Q1 Predictions Mean           -560.555
trainer/Q1 Predictions Std              41.2877
trainer/Q1 Predictions Max            -369.018
trainer/Q1 Predictions Min            -623.04
trainer/Q2 Predictions Mean           -560.524
trainer/Q2 Predictions Std              41.2819
trainer/Q2 Predictions Max            -368.803
trainer/Q2 Predictions Min            -622.065
trainer/Q Targets Mean                -558.988
trainer/Q Targets Std                   63.9672
trainer/Q Targets Max                   -3.33331
trainer/Q Targets Min                 -624.853
trainer/Log Pis Mean                     2.45239
trainer/Log Pis Std                      3.19571
trainer/Log Pis Max                     13.2917
trainer/Log Pis Min                     -5.0773
trainer/policy/mean Mean                -0.0587903
trainer/policy/mean Std                  0.821602
trainer/policy/mean Max                  0.99996
trainer/policy/mean Min                 -0.992762
trainer/policy/normal/std Mean           0.592648
trainer/policy/normal/std Std            0.0688509
trainer/policy/normal/std Max            0.83465
trainer/policy/normal/std Min            0.429065
trainer/policy/normal/log_std Mean      -0.529932
trainer/policy/normal/log_std Std        0.116713
trainer/policy/normal/log_std Max       -0.180743
trainer/policy/normal/log_std Min       -0.846147
trainer/Alpha                            0.0292621
trainer/Alpha Loss                       1.59761
exploration/num steps total         378000
exploration/num paths total           1890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.63679
exploration/Rewards Std                  0.763893
exploration/Rewards Max                 -3.2699
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1127.36
exploration/Returns Std                144.253
exploration/Returns Max               -705.473
exploration/Returns Min              -1206.86
exploration/Actions Mean                -0.112294
exploration/Actions Std                  0.78762
exploration/Actions Max                  0.999977
exploration/Actions Min                 -0.999179
exploration/Num Paths                   10
exploration/Average Returns          -1127.36
evaluation/num steps total          906912
evaluation/num paths total            4512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.68772
evaluation/Rewards Std                   0.851903
evaluation/Rewards Max                  -3.39979
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1143.23
evaluation/Returns Std                 168.535
evaluation/Returns Max                -695.304
evaluation/Returns Min               -1218.78
evaluation/Actions Mean                 -0.0241956
evaluation/Actions Std                   0.769328
evaluation/Actions Max                   0.993836
evaluation/Actions Min                  -0.970132
evaluation/Num Paths                    24
evaluation/Average Returns           -1143.23
time/data storing (s)                    0.0328533
time/evaluation sampling (s)            10.8835
time/exploration sampling (s)            5.09367
time/logging (s)                         0.0315516
time/sac training (s)                   13.889
time/saving (s)                          0.0236389
time/training (s)                        0.000119724
time/epoch (s)                          29.9543
time/total (s)                        6075.1
Epoch                                  187
----------------------------------  ----------------
2020-11-09 15:03:45.042076 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 188 finished
----------------------------------  ---------------
replay_buffer/size                  380000
trainer/num train calls             189000
trainer/QF1 Loss                      1241.64
trainer/QF2 Loss                      1241.58
trainer/Policy Loss                    558.335
trainer/Q1 Predictions Mean           -558.382
trainer/Q1 Predictions Std              46.2779
trainer/Q1 Predictions Max            -390.208
trainer/Q1 Predictions Min            -633.334
trainer/Q2 Predictions Mean           -558.377
trainer/Q2 Predictions Std              46.2974
trainer/Q2 Predictions Max            -390.449
trainer/Q2 Predictions Min            -634.07
trainer/Q Targets Mean                -558.852
trainer/Q Targets Std                   58.325
trainer/Q Targets Max                   -3.20329
trainer/Q Targets Min                 -635.82
trainer/Log Pis Mean                     2.33884
trainer/Log Pis Std                      3.16471
trainer/Log Pis Max                     15.4448
trainer/Log Pis Min                     -4.06108
trainer/policy/mean Mean                -0.252115
trainer/policy/mean Std                  0.773437
trainer/policy/mean Max                  0.99998
trainer/policy/mean Min                 -0.998231
trainer/policy/normal/std Mean           0.664101
trainer/policy/normal/std Std            0.0808657
trainer/policy/normal/std Max            0.926539
trainer/policy/normal/std Min            0.480795
trainer/policy/normal/log_std Mean      -0.416933
trainer/policy/normal/log_std Std        0.124319
trainer/policy/normal/log_std Max       -0.0762989
trainer/policy/normal/log_std Min       -0.732315
trainer/Alpha                            0.0302274
trainer/Alpha Loss                       1.18562
exploration/num steps total         380000
exploration/num paths total           1900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.25062
exploration/Rewards Std                  0.746933
exploration/Rewards Max                 -3.17503
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1050.12
exploration/Returns Std                129.218
exploration/Returns Max               -700.859
exploration/Returns Min              -1171.51
exploration/Actions Mean                -0.181558
exploration/Actions Std                  0.819592
exploration/Actions Max                  0.999901
exploration/Actions Min                 -0.99965
exploration/Num Paths                   10
exploration/Average Returns          -1050.12
evaluation/num steps total          911736
evaluation/num paths total            4536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.71574
evaluation/Rewards Std                   0.410903
evaluation/Rewards Max                  -4.03409
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1148.86
evaluation/Returns Std                  68.07
evaluation/Returns Max                -944.657
evaluation/Returns Min               -1214.49
evaluation/Actions Mean                 -0.181731
evaluation/Actions Std                   0.787201
evaluation/Actions Max                   0.980264
evaluation/Actions Min                  -0.975912
evaluation/Num Paths                    24
evaluation/Average Returns           -1148.86
time/data storing (s)                    0.0284887
time/evaluation sampling (s)            12.6497
time/exploration sampling (s)            5.70459
time/logging (s)                         0.0295139
time/sac training (s)                   13.0354
time/saving (s)                          0.0256139
time/training (s)                        9.5653e-05
time/epoch (s)                          31.4734
time/total (s)                        6108.47
Epoch                                  188
----------------------------------  ---------------
2020-11-09 15:04:29.428982 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 189 finished
----------------------------------  ----------------
replay_buffer/size                  382000
trainer/num train calls             190000
trainer/QF1 Loss                      2403.12
trainer/QF2 Loss                      2408.36
trainer/Policy Loss                    561.584
trainer/Q1 Predictions Mean           -561.87
trainer/Q1 Predictions Std              38.9231
trainer/Q1 Predictions Max            -404.602
trainer/Q1 Predictions Min            -638.385
trainer/Q2 Predictions Mean           -561.901
trainer/Q2 Predictions Std              38.9092
trainer/Q2 Predictions Max            -404.65
trainer/Q2 Predictions Min            -639.344
trainer/Q Targets Mean                -560.134
trainer/Q Targets Std                   63.2226
trainer/Q Targets Max                   -4.69185
trainer/Q Targets Min                 -640.818
trainer/Log Pis Mean                     1.87152
trainer/Log Pis Std                      2.08427
trainer/Log Pis Max                      6.9906
trainer/Log Pis Min                     -6.53425
trainer/policy/mean Mean                 0.0156059
trainer/policy/mean Std                  0.814591
trainer/policy/mean Max                  0.998621
trainer/policy/mean Min                 -0.987063
trainer/policy/normal/std Mean           0.532552
trainer/policy/normal/std Std            0.0584814
trainer/policy/normal/std Max            0.690319
trainer/policy/normal/std Min            0.379709
trainer/policy/normal/log_std Mean      -0.636287
trainer/policy/normal/log_std Std        0.112401
trainer/policy/normal/log_std Max       -0.370601
trainer/policy/normal/log_std Min       -0.968351
trainer/Alpha                            0.0296087
trainer/Alpha Loss                      -0.452203
exploration/num steps total         382000
exploration/num paths total           1910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.03992
exploration/Rewards Std                  0.0767776
exploration/Rewards Max                 -5.73475
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1207.98
exploration/Returns Std                 17.8595
exploration/Returns Max              -1163.13
exploration/Returns Min              -1227.68
exploration/Actions Mean                -0.106874
exploration/Actions Std                  0.742128
exploration/Actions Max                  0.997603
exploration/Actions Min                 -0.996686
exploration/Num Paths                   10
exploration/Average Returns          -1207.98
evaluation/num steps total          916560
evaluation/num paths total            4560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04941
evaluation/Rewards Std                   0.140896
evaluation/Rewards Max                  -5.5749
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1215.93
evaluation/Returns Std                  24.2226
evaluation/Returns Max               -1138.41
evaluation/Returns Min               -1232.1
evaluation/Actions Mean                 -0.0558894
evaluation/Actions Std                   0.455357
evaluation/Actions Max                   0.953943
evaluation/Actions Min                  -0.935949
evaluation/Num Paths                    24
evaluation/Average Returns           -1215.93
time/data storing (s)                    0.0243846
time/evaluation sampling (s)            11.7743
time/exploration sampling (s)            6.19864
time/logging (s)                         0.0422116
time/sac training (s)                   21.8763
time/saving (s)                          0.0348956
time/training (s)                        0.000262093
time/epoch (s)                          39.951
time/total (s)                        6152.83
Epoch                                  189
----------------------------------  ----------------
2020-11-09 15:05:25.730097 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 190 finished
----------------------------------  ---------------
replay_buffer/size                  384000
trainer/num train calls             191000
trainer/QF1 Loss                      3591.04
trainer/QF2 Loss                      3592.26
trainer/Policy Loss                    555.204
trainer/Q1 Predictions Mean           -555.38
trainer/Q1 Predictions Std              45.4566
trainer/Q1 Predictions Max            -396.75
trainer/Q1 Predictions Min            -646.875
trainer/Q2 Predictions Mean           -555.365
trainer/Q2 Predictions Std              45.461
trainer/Q2 Predictions Max            -396.974
trainer/Q2 Predictions Min            -647.449
trainer/Q Targets Mean                -551.193
trainer/Q Targets Std                   75.1854
trainer/Q Targets Max                   -5.07902
trainer/Q Targets Min                 -647.048
trainer/Log Pis Mean                     3.51028
trainer/Log Pis Std                      3.03039
trainer/Log Pis Max                     14.1603
trainer/Log Pis Min                     -3.81264
trainer/policy/mean Mean                -0.345059
trainer/policy/mean Std                  0.798881
trainer/policy/mean Max                  0.999653
trainer/policy/mean Min                 -0.999304
trainer/policy/normal/std Mean           0.612566
trainer/policy/normal/std Std            0.104805
trainer/policy/normal/std Max            0.816941
trainer/policy/normal/std Min            0.383938
trainer/policy/normal/log_std Mean      -0.50606
trainer/policy/normal/log_std Std        0.182746
trainer/policy/normal/log_std Max       -0.202188
trainer/policy/normal/log_std Min       -0.957275
trainer/Alpha                            0.0304002
trainer/Alpha Loss                       5.27586
exploration/num steps total         384000
exploration/num paths total           1920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.66134
exploration/Rewards Std                  1.03929
exploration/Rewards Max                 -1.47482
exploration/Rewards Min                 -6.14186
exploration/Returns Mean              -932.268
exploration/Returns Std                135.441
exploration/Returns Max               -701.243
exploration/Returns Min              -1114.09
exploration/Actions Mean                -0.426394
exploration/Actions Std                  0.723233
exploration/Actions Max                  0.999699
exploration/Actions Min                 -0.999947
exploration/Num Paths                   10
exploration/Average Returns           -932.268
evaluation/num steps total          921384
evaluation/num paths total            4584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.40169
evaluation/Rewards Std                   0.599562
evaluation/Rewards Max                  -3.35144
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1085.74
evaluation/Returns Std                 109.317
evaluation/Returns Max                -699.528
evaluation/Returns Min               -1213.97
evaluation/Actions Mean                 -0.420377
evaluation/Actions Std                   0.712646
evaluation/Actions Max                   0.998885
evaluation/Actions Min                  -0.998591
evaluation/Num Paths                    24
evaluation/Average Returns           -1085.74
time/data storing (s)                    0.0286354
time/evaluation sampling (s)            25.1792
time/exploration sampling (s)            8.64842
time/logging (s)                         0.0297167
time/sac training (s)                   17.1218
time/saving (s)                          0.0348451
time/training (s)                        0.00013912
time/epoch (s)                          51.0427
time/total (s)                        6209.09
Epoch                                  190
----------------------------------  ---------------
2020-11-09 15:06:19.105978 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 191 finished
----------------------------------  ---------------
replay_buffer/size                  386000
trainer/num train calls             192000
trainer/QF1 Loss                      3833.83
trainer/QF2 Loss                      3832.29
trainer/Policy Loss                    559.914
trainer/Q1 Predictions Mean           -560.059
trainer/Q1 Predictions Std              41.5923
trainer/Q1 Predictions Max            -400.264
trainer/Q1 Predictions Min            -625.781
trainer/Q2 Predictions Mean           -560.058
trainer/Q2 Predictions Std              41.5894
trainer/Q2 Predictions Max            -399.802
trainer/Q2 Predictions Min            -625.535
trainer/Q Targets Mean                -556.059
trainer/Q Targets Std                   73.2709
trainer/Q Targets Max                   -4.58144
trainer/Q Targets Min                 -626.665
trainer/Log Pis Mean                     1.50325
trainer/Log Pis Std                      2.33406
trainer/Log Pis Max                     12.6576
trainer/Log Pis Min                     -3.97416
trainer/policy/mean Mean                -0.149209
trainer/policy/mean Std                  0.766802
trainer/policy/mean Max                  0.999984
trainer/policy/mean Min                 -0.99015
trainer/policy/normal/std Mean           0.65014
trainer/policy/normal/std Std            0.109017
trainer/policy/normal/std Max            0.866426
trainer/policy/normal/std Min            0.434186
trainer/policy/normal/log_std Mean      -0.445501
trainer/policy/normal/log_std Std        0.175473
trainer/policy/normal/log_std Max       -0.143378
trainer/policy/normal/log_std Min       -0.834283
trainer/Alpha                            0.0307349
trainer/Alpha Loss                      -1.72984
exploration/num steps total         386000
exploration/num paths total           1930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.69811
exploration/Rewards Std                  0.503426
exploration/Rewards Max                 -3.63105
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1139.62
exploration/Returns Std                 71.048
exploration/Returns Max               -934.31
exploration/Returns Min              -1186.84
exploration/Actions Mean                -0.177292
exploration/Actions Std                  0.734409
exploration/Actions Max                  0.99948
exploration/Actions Min                 -0.999761
exploration/Num Paths                   10
exploration/Average Returns          -1139.62
evaluation/num steps total          926208
evaluation/num paths total            4608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.01364
evaluation/Rewards Std                   0.0657152
evaluation/Rewards Max                  -5.32262
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1208.74
evaluation/Returns Std                   6.32661
evaluation/Returns Max               -1194.46
evaluation/Returns Min               -1219.03
evaluation/Actions Mean                 -0.109643
evaluation/Actions Std                   0.73229
evaluation/Actions Max                   0.982378
evaluation/Actions Min                  -0.971162
evaluation/Num Paths                    24
evaluation/Average Returns           -1208.74
time/data storing (s)                    0.0325838
time/evaluation sampling (s)            20.1707
time/exploration sampling (s)            8.73319
time/logging (s)                         0.0317314
time/sac training (s)                   20.6574
time/saving (s)                          0.0449139
time/training (s)                        0.00012352
time/epoch (s)                          49.6706
time/total (s)                        6262.43
Epoch                                  191
----------------------------------  ---------------
2020-11-09 15:07:03.363470 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 192 finished
----------------------------------  ----------------
replay_buffer/size                  388000
trainer/num train calls             193000
trainer/QF1 Loss                      2572.69
trainer/QF2 Loss                      2572.02
trainer/Policy Loss                    565.56
trainer/Q1 Predictions Mean           -565.752
trainer/Q1 Predictions Std              31.7591
trainer/Q1 Predictions Max            -406.45
trainer/Q1 Predictions Min            -630.287
trainer/Q2 Predictions Mean           -565.766
trainer/Q2 Predictions Std              31.6644
trainer/Q2 Predictions Max            -408.174
trainer/Q2 Predictions Min            -630.731
trainer/Q Targets Mean                -563.945
trainer/Q Targets Std                   59.008
trainer/Q Targets Max                   -5.01197
trainer/Q Targets Min                 -632.512
trainer/Log Pis Mean                     1.87293
trainer/Log Pis Std                      2.26617
trainer/Log Pis Max                     12.1709
trainer/Log Pis Min                     -4.1041
trainer/policy/mean Mean                 0.182101
trainer/policy/mean Std                  0.791947
trainer/policy/mean Max                  0.999996
trainer/policy/mean Min                 -0.982172
trainer/policy/normal/std Mean           0.627998
trainer/policy/normal/std Std            0.0711932
trainer/policy/normal/std Max            0.832085
trainer/policy/normal/std Min            0.46015
trainer/policy/normal/log_std Mean      -0.471595
trainer/policy/normal/log_std Std        0.112861
trainer/policy/normal/log_std Max       -0.18382
trainer/policy/normal/log_std Min       -0.776202
trainer/Alpha                            0.0306442
trainer/Alpha Loss                      -0.442887
exploration/num steps total         388000
exploration/num paths total           1940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.05483
exploration/Rewards Std                  0.0513155
exploration/Rewards Max                 -5.84295
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1210.97
exploration/Returns Std                 22.1711
exploration/Returns Max              -1146.47
exploration/Returns Min              -1228.53
exploration/Actions Mean                 0.0579249
exploration/Actions Std                  0.793456
exploration/Actions Max                  0.999413
exploration/Actions Min                 -0.998271
exploration/Num Paths                   10
exploration/Average Returns          -1210.97
evaluation/num steps total          931032
evaluation/num paths total            4632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97862
evaluation/Rewards Std                   0.527119
evaluation/Rewards Max                  -3.39305
evaluation/Rewards Min                  -6.14193
evaluation/Returns Mean              -1201.7
evaluation/Returns Std                 102.655
evaluation/Returns Max                -711.507
evaluation/Returns Min               -1232.65
evaluation/Actions Mean                  0.208021
evaluation/Actions Std                   0.725557
evaluation/Actions Max                   0.981574
evaluation/Actions Min                  -0.876511
evaluation/Num Paths                    24
evaluation/Average Returns           -1201.7
time/data storing (s)                    0.0223096
time/evaluation sampling (s)            22.7001
time/exploration sampling (s)            6.16371
time/logging (s)                         0.0262151
time/sac training (s)                   13.2969
time/saving (s)                          0.01882
time/training (s)                        0.000100272
time/epoch (s)                          42.2281
time/total (s)                        6306.65
Epoch                                  192
----------------------------------  ----------------
2020-11-09 15:08:08.071725 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 193 finished
----------------------------------  ----------------
replay_buffer/size                  390000
trainer/num train calls             194000
trainer/QF1 Loss                        17.7154
trainer/QF2 Loss                        17.5349
trainer/Policy Loss                    561.492
trainer/Q1 Predictions Mean           -561.354
trainer/Q1 Predictions Std              39.5242
trainer/Q1 Predictions Max            -388.552
trainer/Q1 Predictions Min            -648.776
trainer/Q2 Predictions Mean           -561.397
trainer/Q2 Predictions Std              39.5239
trainer/Q2 Predictions Max            -388.596
trainer/Q2 Predictions Min            -648.248
trainer/Q Targets Mean                -564.214
trainer/Q Targets Std                   39.8691
trainer/Q Targets Max                 -390.503
trainer/Q Targets Min                 -649.205
trainer/Log Pis Mean                     2.07129
trainer/Log Pis Std                      2.66176
trainer/Log Pis Max                     11.9944
trainer/Log Pis Min                     -5.20395
trainer/policy/mean Mean                -0.261793
trainer/policy/mean Std                  0.783156
trainer/policy/mean Max                  0.999968
trainer/policy/mean Min                 -0.996132
trainer/policy/normal/std Mean           0.704287
trainer/policy/normal/std Std            0.136701
trainer/policy/normal/std Max            0.899072
trainer/policy/normal/std Min            0.447522
trainer/policy/normal/log_std Mean      -0.371097
trainer/policy/normal/log_std Std        0.207049
trainer/policy/normal/log_std Max       -0.106392
trainer/policy/normal/log_std Min       -0.804029
trainer/Alpha                            0.0310973
trainer/Alpha Loss                       0.24742
exploration/num steps total         390000
exploration/num paths total           1950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.51326
exploration/Rewards Std                  0.340562
exploration/Rewards Max                 -3.75265
exploration/Rewards Min                 -6.13944
exploration/Returns Mean             -1102.65
exploration/Returns Std                 32.1991
exploration/Returns Max              -1038.53
exploration/Returns Min              -1158.49
exploration/Actions Mean                -0.196592
exploration/Actions Std                  0.830114
exploration/Actions Max                  0.99988
exploration/Actions Min                 -0.99983
exploration/Num Paths                   10
exploration/Average Returns          -1102.65
evaluation/num steps total          935856
evaluation/num paths total            4656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.47414
evaluation/Rewards Std                   0.822626
evaluation/Rewards Max                  -3.24217
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1100.3
evaluation/Returns Std                 149.512
evaluation/Returns Max                -690.517
evaluation/Returns Min               -1206.35
evaluation/Actions Mean                 -0.257323
evaluation/Actions Std                   0.76093
evaluation/Actions Max                   0.988312
evaluation/Actions Min                  -0.97844
evaluation/Num Paths                    24
evaluation/Average Returns           -1100.3
time/data storing (s)                    0.0432758
time/evaluation sampling (s)            25.7454
time/exploration sampling (s)            9.12697
time/logging (s)                         0.0305403
time/sac training (s)                   21.351
time/saving (s)                          0.0384406
time/training (s)                        0.000129597
time/epoch (s)                          56.3358
time/total (s)                        6371.33
Epoch                                  193
----------------------------------  ----------------
2020-11-09 15:09:02.795792 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 194 finished
----------------------------------  ----------------
replay_buffer/size                  392000
trainer/num train calls             195000
trainer/QF1 Loss                        12.0384
trainer/QF2 Loss                        12.1036
trainer/Policy Loss                    562.176
trainer/Q1 Predictions Mean           -562.305
trainer/Q1 Predictions Std              38.5158
trainer/Q1 Predictions Max            -400.751
trainer/Q1 Predictions Min            -621.988
trainer/Q2 Predictions Mean           -562.306
trainer/Q2 Predictions Std              38.5261
trainer/Q2 Predictions Max            -400.662
trainer/Q2 Predictions Min            -622.031
trainer/Q Targets Mean                -564.208
trainer/Q Targets Std                   38.9549
trainer/Q Targets Max                 -398.832
trainer/Q Targets Min                 -627.365
trainer/Log Pis Mean                     1.40562
trainer/Log Pis Std                      2.28396
trainer/Log Pis Max                      7.60722
trainer/Log Pis Min                     -3.64148
trainer/policy/mean Mean                -0.145393
trainer/policy/mean Std                  0.768767
trainer/policy/mean Max                  0.999701
trainer/policy/mean Min                 -0.981084
trainer/policy/normal/std Mean           0.651712
trainer/policy/normal/std Std            0.0939908
trainer/policy/normal/std Max            0.873139
trainer/policy/normal/std Min            0.457356
trainer/policy/normal/log_std Mean      -0.439053
trainer/policy/normal/log_std Std        0.149478
trainer/policy/normal/log_std Max       -0.13566
trainer/policy/normal/log_std Min       -0.782293
trainer/Alpha                            0.0307751
trainer/Alpha Loss                      -2.06908
exploration/num steps total         392000
exploration/num paths total           1960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.51649
exploration/Rewards Std                  0.749877
exploration/Rewards Max                 -3.27131
exploration/Rewards Min                 -6.1417
exploration/Returns Mean             -1103.3
exploration/Returns Std                133.529
exploration/Returns Max               -722.476
exploration/Returns Min              -1189.14
exploration/Actions Mean                -0.133117
exploration/Actions Std                  0.773889
exploration/Actions Max                  0.999388
exploration/Actions Min                 -0.998963
exploration/Num Paths                   10
exploration/Average Returns          -1103.3
evaluation/num steps total          940680
evaluation/num paths total            4680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89367
evaluation/Rewards Std                   0.522461
evaluation/Rewards Max                  -3.39682
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1184.63
evaluation/Returns Std                 102.393
evaluation/Returns Max                -698.095
evaluation/Returns Min               -1217.39
evaluation/Actions Mean                 -0.0344918
evaluation/Actions Std                   0.778379
evaluation/Actions Max                   0.990981
evaluation/Actions Min                  -0.956957
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.63
time/data storing (s)                    0.0349597
time/evaluation sampling (s)            21.1088
time/exploration sampling (s)            8.39437
time/logging (s)                         0.034159
time/sac training (s)                   20.5673
time/saving (s)                          0.0427712
time/training (s)                        0.000142541
time/epoch (s)                          50.1825
time/total (s)                        6426.02
Epoch                                  194
----------------------------------  ----------------
2020-11-09 15:10:15.744114 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 195 finished
----------------------------------  ----------------
replay_buffer/size                  394000
trainer/num train calls             196000
trainer/QF1 Loss                        19.1638
trainer/QF2 Loss                        19.1331
trainer/Policy Loss                    559.279
trainer/Q1 Predictions Mean           -559.331
trainer/Q1 Predictions Std              42.0938
trainer/Q1 Predictions Max            -375
trainer/Q1 Predictions Min            -649.055
trainer/Q2 Predictions Mean           -559.332
trainer/Q2 Predictions Std              42.1266
trainer/Q2 Predictions Max            -374.988
trainer/Q2 Predictions Min            -650.344
trainer/Q Targets Mean                -562.04
trainer/Q Targets Std                   42.3811
trainer/Q Targets Max                 -376.387
trainer/Q Targets Min                 -652.317
trainer/Log Pis Mean                     1.73009
trainer/Log Pis Std                      2.19583
trainer/Log Pis Max                     11.1144
trainer/Log Pis Min                     -5.69931
trainer/policy/mean Mean                 0.16337
trainer/policy/mean Std                  0.767272
trainer/policy/mean Max                  0.999993
trainer/policy/mean Min                 -0.979348
trainer/policy/normal/std Mean           0.620973
trainer/policy/normal/std Std            0.103044
trainer/policy/normal/std Max            0.837417
trainer/policy/normal/std Min            0.417172
trainer/policy/normal/log_std Mean      -0.490826
trainer/policy/normal/log_std Std        0.171305
trainer/policy/normal/log_std Max       -0.177433
trainer/policy/normal/log_std Min       -0.874256
trainer/Alpha                            0.0302448
trainer/Alpha Loss                      -0.944247
exploration/num steps total         394000
exploration/num paths total           1970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.99871
exploration/Rewards Std                  0.164413
exploration/Rewards Max                 -4.79967
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1199.74
exploration/Returns Std                 27.5585
exploration/Returns Max              -1141.74
exploration/Returns Min              -1226.46
exploration/Actions Mean                 0.0965616
exploration/Actions Std                  0.771066
exploration/Actions Max                  0.99886
exploration/Actions Min                 -0.998371
exploration/Num Paths                   10
exploration/Average Returns          -1199.74
evaluation/num steps total          945504
evaluation/num paths total            4704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84132
evaluation/Rewards Std                   0.733366
evaluation/Rewards Max                  -3.39291
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1174.1
evaluation/Returns Std                 144.796
evaluation/Returns Max                -691.472
evaluation/Returns Min               -1230.42
evaluation/Actions Mean                  0.144313
evaluation/Actions Std                   0.709955
evaluation/Actions Max                   0.989818
evaluation/Actions Min                  -0.901762
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.1
time/data storing (s)                    0.0390762
time/evaluation sampling (s)            24.4588
time/exploration sampling (s)           10.5478
time/logging (s)                         0.0523518
time/sac training (s)                   26.6734
time/saving (s)                          0.0666163
time/training (s)                        0.000167877
time/epoch (s)                          61.8382
time/total (s)                        6498.95
Epoch                                  195
----------------------------------  ----------------
2020-11-09 15:11:32.724490 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 196 finished
----------------------------------  ----------------
replay_buffer/size                  396000
trainer/num train calls             197000
trainer/QF1 Loss                      1450.27
trainer/QF2 Loss                      1449.69
trainer/Policy Loss                    559.29
trainer/Q1 Predictions Mean           -559.81
trainer/Q1 Predictions Std              42.2649
trainer/Q1 Predictions Max            -390.202
trainer/Q1 Predictions Min            -620.825
trainer/Q2 Predictions Mean           -559.846
trainer/Q2 Predictions Std              42.283
trainer/Q2 Predictions Max            -390.27
trainer/Q2 Predictions Min            -620.688
trainer/Q Targets Mean                -558.066
trainer/Q Targets Std                   64.3104
trainer/Q Targets Max                   -3.18165
trainer/Q Targets Min                 -621.261
trainer/Log Pis Mean                     2.66727
trainer/Log Pis Std                      2.29923
trainer/Log Pis Max                      7.91471
trainer/Log Pis Min                     -3.66907
trainer/policy/mean Mean                 0.19246
trainer/policy/mean Std                  0.830695
trainer/policy/mean Max                  0.999514
trainer/policy/mean Min                 -0.992886
trainer/policy/normal/std Mean           0.541419
trainer/policy/normal/std Std            0.0504134
trainer/policy/normal/std Max            0.704297
trainer/policy/normal/std Min            0.395284
trainer/policy/normal/log_std Mean      -0.617799
trainer/policy/normal/log_std Std        0.0916924
trainer/policy/normal/log_std Max       -0.350555
trainer/policy/normal/log_std Min       -0.92815
trainer/Alpha                            0.0296982
trainer/Alpha Loss                       2.34657
exploration/num steps total         396000
exploration/num paths total           1980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.06206
exploration/Rewards Std                  0.162711
exploration/Rewards Max                 -5.05296
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1212.41
exploration/Returns Std                 29.5517
exploration/Returns Max              -1144.53
exploration/Returns Min              -1232.93
exploration/Actions Mean                 0.038774
exploration/Actions Std                  0.854916
exploration/Actions Max                  0.997153
exploration/Actions Min                 -0.99805
exploration/Num Paths                   10
exploration/Average Returns          -1212.41
evaluation/num steps total          950328
evaluation/num paths total            4728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.1329
evaluation/Rewards Std                   0.0140672
evaluation/Rewards Max                  -5.97974
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1232.71
evaluation/Returns Std                   1.53761
evaluation/Returns Max               -1228.8
evaluation/Returns Min               -1234.34
evaluation/Actions Mean                 -0.00790069
evaluation/Actions Std                   0.875906
evaluation/Actions Max                   0.887442
evaluation/Actions Min                  -0.930359
evaluation/Num Paths                    24
evaluation/Average Returns           -1232.71
time/data storing (s)                    0.0386998
time/evaluation sampling (s)            27.7538
time/exploration sampling (s)            9.16285
time/logging (s)                         0.0385791
time/sac training (s)                   20.9229
time/saving (s)                          0.0353678
time/training (s)                        0.000143903
time/epoch (s)                          57.9523
time/total (s)                        6575.88
Epoch                                  196
----------------------------------  ----------------
2020-11-09 15:13:08.533007 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 197 finished
----------------------------------  ----------------
replay_buffer/size                  398000
trainer/num train calls             198000
trainer/QF1 Loss                      1343.46
trainer/QF2 Loss                      1341.14
trainer/Policy Loss                    563.191
trainer/Q1 Predictions Mean           -563.351
trainer/Q1 Predictions Std              33.7542
trainer/Q1 Predictions Max            -405.345
trainer/Q1 Predictions Min            -606.41
trainer/Q2 Predictions Mean           -563.361
trainer/Q2 Predictions Std              33.7772
trainer/Q2 Predictions Max            -405.444
trainer/Q2 Predictions Min            -606.343
trainer/Q Targets Mean                -563.721
trainer/Q Targets Std                   48.9621
trainer/Q Targets Max                   -4.97452
trainer/Q Targets Min                 -608.106
trainer/Log Pis Mean                     2.93905
trainer/Log Pis Std                      2.63954
trainer/Log Pis Max                     17.9951
trainer/Log Pis Min                     -2.30716
trainer/policy/mean Mean                -0.502713
trainer/policy/mean Std                  0.69182
trainer/policy/mean Max                  0.999997
trainer/policy/mean Min                 -0.99983
trainer/policy/normal/std Mean           0.58181
trainer/policy/normal/std Std            0.102573
trainer/policy/normal/std Max            0.800845
trainer/policy/normal/std Min            0.386454
trainer/policy/normal/log_std Mean      -0.558188
trainer/policy/normal/log_std Std        0.18513
trainer/policy/normal/log_std Max       -0.222088
trainer/policy/normal/log_std Min       -0.950744
trainer/Alpha                            0.0305594
trainer/Alpha Loss                       3.27549
exploration/num steps total         398000
exploration/num paths total           1990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.13348
exploration/Rewards Std                  0.656229
exploration/Rewards Max                 -2.853
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1026.7
exploration/Returns Std                 64.9982
exploration/Returns Max               -871.747
exploration/Returns Min              -1115.35
exploration/Actions Mean                -0.584713
exploration/Actions Std                  0.595543
exploration/Actions Max                  0.999973
exploration/Actions Min                 -0.999904
exploration/Num Paths                   10
exploration/Average Returns          -1026.7
evaluation/num steps total          955152
evaluation/num paths total            4752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.5657
evaluation/Rewards Std                   0.486528
evaluation/Rewards Max                  -3.20802
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1118.71
evaluation/Returns Std                  83.7479
evaluation/Returns Max                -836.551
evaluation/Returns Min               -1201.65
evaluation/Actions Mean                 -0.466831
evaluation/Actions Std                   0.726425
evaluation/Actions Max                   0.982212
evaluation/Actions Min                  -0.992349
evaluation/Num Paths                    24
evaluation/Average Returns           -1118.71
time/data storing (s)                    0.0497278
time/evaluation sampling (s)            20.6856
time/exploration sampling (s)            8.40177
time/logging (s)                         0.0809553
time/sac training (s)                   41.6479
time/saving (s)                          0.0589892
time/training (s)                        0.000141837
time/epoch (s)                          70.9251
time/total (s)                        6671.69
Epoch                                  197
----------------------------------  ----------------
2020-11-09 15:14:23.125880 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 198 finished
----------------------------------  ----------------
replay_buffer/size                  400000
trainer/num train calls             199000
trainer/QF1 Loss                      1250.34
trainer/QF2 Loss                      1250.69
trainer/Policy Loss                    562.087
trainer/Q1 Predictions Mean           -562.384
trainer/Q1 Predictions Std              34.2587
trainer/Q1 Predictions Max            -398.665
trainer/Q1 Predictions Min            -620.425
trainer/Q2 Predictions Mean           -562.414
trainer/Q2 Predictions Std              34.256
trainer/Q2 Predictions Max            -398.866
trainer/Q2 Predictions Min            -621.397
trainer/Q Targets Mean                -562.435
trainer/Q Targets Std                   49.4366
trainer/Q Targets Max                   -5.37632
trainer/Q Targets Min                 -622.833
trainer/Log Pis Mean                     3.43632
trainer/Log Pis Std                      2.77414
trainer/Log Pis Max                     13.637
trainer/Log Pis Min                     -2.57458
trainer/policy/mean Mean                -0.475723
trainer/policy/mean Std                  0.744017
trainer/policy/mean Max                  0.999813
trainer/policy/mean Min                 -0.998975
trainer/policy/normal/std Mean           0.567315
trainer/policy/normal/std Std            0.0726941
trainer/policy/normal/std Max            0.788431
trainer/policy/normal/std Min            0.400276
trainer/policy/normal/log_std Mean      -0.575222
trainer/policy/normal/log_std Std        0.130257
trainer/policy/normal/log_std Max       -0.23771
trainer/policy/normal/log_std Min       -0.915601
trainer/Alpha                            0.0311518
trainer/Alpha Loss                       4.98243
exploration/num steps total         400000
exploration/num paths total           2000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.61686
exploration/Rewards Std                  0.995334
exploration/Rewards Max                 -2.68769
exploration/Rewards Min                 -6.14181
exploration/Returns Mean              -923.373
exploration/Returns Std                121.498
exploration/Returns Max               -787.863
exploration/Returns Min              -1135.47
exploration/Actions Mean                -0.467992
exploration/Actions Std                  0.745001
exploration/Actions Max                  0.999941
exploration/Actions Min                 -0.999689
exploration/Num Paths                   10
exploration/Average Returns           -923.373
evaluation/num steps total          959976
evaluation/num paths total            4776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59898
evaluation/Rewards Std                   0.357792
evaluation/Rewards Max                  -3.27956
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1125.4
evaluation/Returns Std                  59.0806
evaluation/Returns Max                -928.664
evaluation/Returns Min               -1204.37
evaluation/Actions Mean                 -0.476288
evaluation/Actions Std                   0.737147
evaluation/Actions Max                   0.994379
evaluation/Actions Min                  -0.994928
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.4
time/data storing (s)                    0.0466904
time/evaluation sampling (s)            22.7962
time/exploration sampling (s)            8.86289
time/logging (s)                         0.0305442
time/sac training (s)                   25.9156
time/saving (s)                          0.0397197
time/training (s)                        0.000217061
time/epoch (s)                          57.6919
time/total (s)                        6746.19
Epoch                                  198
----------------------------------  ----------------
2020-11-09 15:15:44.209264 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 199 finished
----------------------------------  ----------------
replay_buffer/size                  402000
trainer/num train calls             200000
trainer/QF1 Loss                         9.41114
trainer/QF2 Loss                         9.28547
trainer/Policy Loss                    559.04
trainer/Q1 Predictions Mean           -559.276
trainer/Q1 Predictions Std              40.7529
trainer/Q1 Predictions Max            -402.15
trainer/Q1 Predictions Min            -615.038
trainer/Q2 Predictions Mean           -559.279
trainer/Q2 Predictions Std              40.733
trainer/Q2 Predictions Max            -402.26
trainer/Q2 Predictions Min            -615.194
trainer/Q Targets Mean                -561.314
trainer/Q Targets Std                   41.1425
trainer/Q Targets Max                 -403.265
trainer/Q Targets Min                 -616.665
trainer/Log Pis Mean                     1.82755
trainer/Log Pis Std                      2.17375
trainer/Log Pis Max                     10.8467
trainer/Log Pis Min                     -4.40015
trainer/policy/mean Mean                -0.366347
trainer/policy/mean Std                  0.713635
trainer/policy/mean Max                  0.999825
trainer/policy/mean Min                 -0.991869
trainer/policy/normal/std Mean           0.636665
trainer/policy/normal/std Std            0.114351
trainer/policy/normal/std Max            0.858843
trainer/policy/normal/std Min            0.428399
trainer/policy/normal/log_std Mean      -0.468086
trainer/policy/normal/log_std Std        0.183466
trainer/policy/normal/log_std Max       -0.152169
trainer/policy/normal/log_std Min       -0.847701
trainer/Alpha                            0.0312341
trainer/Alpha Loss                      -0.597764
exploration/num steps total         402000
exploration/num paths total           2010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.51014
exploration/Rewards Std                  0.389502
exploration/Rewards Max                 -4.40902
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1102.03
exploration/Returns Std                 52.398
exploration/Returns Max               -971.374
exploration/Returns Min              -1167.25
exploration/Actions Mean                -0.381562
exploration/Actions Std                  0.705427
exploration/Actions Max                  0.998697
exploration/Actions Min                 -0.999537
exploration/Num Paths                   10
exploration/Average Returns          -1102.03
evaluation/num steps total          964800
evaluation/num paths total            4800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73372
evaluation/Rewards Std                   0.301548
evaluation/Rewards Max                  -4.94163
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1152.48
evaluation/Returns Std                  43.808
evaluation/Returns Max               -1009.91
evaluation/Returns Min               -1199.36
evaluation/Actions Mean                 -0.536907
evaluation/Actions Std                   0.559839
evaluation/Actions Max                   0.996325
evaluation/Actions Min                  -0.985221
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.48
time/data storing (s)                    0.0381226
time/evaluation sampling (s)            21.4574
time/exploration sampling (s)            8.98926
time/logging (s)                         0.0589266
time/sac training (s)                   27.9455
time/saving (s)                          0.062588
time/training (s)                        0.000127405
time/epoch (s)                          58.5519
time/total (s)                        6827.27
Epoch                                  199
----------------------------------  ----------------
2020-11-09 15:17:12.564412 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 200 finished
----------------------------------  ----------------
replay_buffer/size                  404000
trainer/num train calls             201000
trainer/QF1 Loss                      3666.96
trainer/QF2 Loss                      3662.84
trainer/Policy Loss                    555.307
trainer/Q1 Predictions Mean           -555.483
trainer/Q1 Predictions Std              44.1311
trainer/Q1 Predictions Max            -377.22
trainer/Q1 Predictions Min            -616.055
trainer/Q2 Predictions Mean           -555.491
trainer/Q2 Predictions Std              44.1523
trainer/Q2 Predictions Max            -377.068
trainer/Q2 Predictions Min            -616.909
trainer/Q Targets Mean                -551.626
trainer/Q Targets Std                   74.3124
trainer/Q Targets Max                   -5.09017
trainer/Q Targets Min                 -617.589
trainer/Log Pis Mean                     1.88072
trainer/Log Pis Std                      2.43099
trainer/Log Pis Max                      8.93461
trainer/Log Pis Min                     -3.50811
trainer/policy/mean Mean                -0.228782
trainer/policy/mean Std                  0.77633
trainer/policy/mean Max                  0.999801
trainer/policy/mean Min                 -0.986264
trainer/policy/normal/std Mean           0.654215
trainer/policy/normal/std Std            0.0812419
trainer/policy/normal/std Max            0.885266
trainer/policy/normal/std Min            0.483816
trainer/policy/normal/log_std Mean      -0.432104
trainer/policy/normal/log_std Std        0.125177
trainer/policy/normal/log_std Max       -0.121868
trainer/policy/normal/log_std Min       -0.726051
trainer/Alpha                            0.0309892
trainer/Alpha Loss                      -0.41439
exploration/num steps total         404000
exploration/num paths total           2020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.64158
exploration/Rewards Std                  0.331329
exploration/Rewards Max                 -4.60527
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1128.32
exploration/Returns Std                 45.4689
exploration/Returns Max              -1046.83
exploration/Returns Min              -1195.3
exploration/Actions Mean                -0.278848
exploration/Actions Std                  0.750921
exploration/Actions Max                  0.99993
exploration/Actions Min                 -0.998966
exploration/Num Paths                   10
exploration/Average Returns          -1128.32
evaluation/num steps total          969624
evaluation/num paths total            4824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.72345
evaluation/Rewards Std                   0.644037
evaluation/Rewards Max                  -3.29888
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1150.41
evaluation/Returns Std                 112.587
evaluation/Returns Max                -714.911
evaluation/Returns Min               -1214.85
evaluation/Actions Mean                 -0.187164
evaluation/Actions Std                   0.802664
evaluation/Actions Max                   0.9921
evaluation/Actions Min                  -0.977413
evaluation/Num Paths                    24
evaluation/Average Returns           -1150.41
time/data storing (s)                    0.0465635
time/evaluation sampling (s)            18.7976
time/exploration sampling (s)            7.56155
time/logging (s)                         0.0522462
time/sac training (s)                   27.9798
time/saving (s)                          0.0890169
time/training (s)                        0.000145303
time/epoch (s)                          54.527
time/total (s)                        6915.56
Epoch                                  200
----------------------------------  ----------------
2020-11-09 15:18:43.796462 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 201 finished
----------------------------------  ----------------
replay_buffer/size                  406000
trainer/num train calls             202000
trainer/QF1 Loss                      1222.47
trainer/QF2 Loss                      1218.9
trainer/Policy Loss                    556.326
trainer/Q1 Predictions Mean           -556.665
trainer/Q1 Predictions Std              45.7202
trainer/Q1 Predictions Max            -351.535
trainer/Q1 Predictions Min            -651.394
trainer/Q2 Predictions Mean           -556.657
trainer/Q2 Predictions Std              45.6809
trainer/Q2 Predictions Max            -351.549
trainer/Q2 Predictions Min            -651.137
trainer/Q Targets Mean                -557.23
trainer/Q Targets Std                   57.6739
trainer/Q Targets Max                   -4.92684
trainer/Q Targets Min                 -651.878
trainer/Log Pis Mean                     1.46916
trainer/Log Pis Std                      1.74369
trainer/Log Pis Max                      5.36199
trainer/Log Pis Min                     -3.3653
trainer/policy/mean Mean                 0.0756963
trainer/policy/mean Std                  0.79382
trainer/policy/mean Max                  0.996843
trainer/policy/mean Min                 -0.982165
trainer/policy/normal/std Mean           0.593881
trainer/policy/normal/std Std            0.0739441
trainer/policy/normal/std Max            0.771845
trainer/policy/normal/std Min            0.385148
trainer/policy/normal/log_std Mean      -0.529163
trainer/policy/normal/log_std Std        0.128614
trainer/policy/normal/log_std Max       -0.258972
trainer/policy/normal/log_std Min       -0.954127
trainer/Alpha                            0.0306607
trainer/Alpha Loss                      -1.84987
exploration/num steps total         406000
exploration/num paths total           2030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.03018
exploration/Rewards Std                  0.115575
exploration/Rewards Max                 -5.10568
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1206.04
exploration/Returns Std                 18.3617
exploration/Returns Max              -1166.55
exploration/Returns Min              -1226.11
exploration/Actions Mean                 0.0267505
exploration/Actions Std                  0.760549
exploration/Actions Max                  0.997898
exploration/Actions Min                 -0.998793
exploration/Num Paths                   10
exploration/Average Returns          -1206.04
evaluation/num steps total          974448
evaluation/num paths total            4848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.11776
evaluation/Rewards Std                   0.0263711
evaluation/Rewards Max                  -5.97728
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1229.67
evaluation/Returns Std                   2.97597
evaluation/Returns Max               -1222.19
evaluation/Returns Min               -1233.07
evaluation/Actions Mean                 -0.0454796
evaluation/Actions Std                   0.573006
evaluation/Actions Max                   0.787346
evaluation/Actions Min                  -0.941314
evaluation/Num Paths                    24
evaluation/Average Returns           -1229.67
time/data storing (s)                    0.0298472
time/evaluation sampling (s)            22.7421
time/exploration sampling (s)            7.94256
time/logging (s)                         0.0678155
time/sac training (s)                   28.4543
time/saving (s)                          0.0731607
time/training (s)                        0.000145361
time/epoch (s)                          59.3099
time/total (s)                        7006.75
Epoch                                  201
----------------------------------  ----------------
2020-11-09 15:20:02.199647 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 202 finished
----------------------------------  ----------------
replay_buffer/size                  408000
trainer/num train calls             203000
trainer/QF1 Loss                        22.6729
trainer/QF2 Loss                        22.5751
trainer/Policy Loss                    563.707
trainer/Q1 Predictions Mean           -563.724
trainer/Q1 Predictions Std              36.5779
trainer/Q1 Predictions Max            -396.661
trainer/Q1 Predictions Min            -654.905
trainer/Q2 Predictions Mean           -563.761
trainer/Q2 Predictions Std              36.6195
trainer/Q2 Predictions Max            -396.744
trainer/Q2 Predictions Min            -655.845
trainer/Q Targets Mean                -566.31
trainer/Q Targets Std                   36.6085
trainer/Q Targets Max                 -398.297
trainer/Q Targets Min                 -656.323
trainer/Log Pis Mean                     1.65029
trainer/Log Pis Std                      2.23512
trainer/Log Pis Max                      9.44417
trainer/Log Pis Min                     -5.39165
trainer/policy/mean Mean                -0.155039
trainer/policy/mean Std                  0.775486
trainer/policy/mean Max                  0.999598
trainer/policy/mean Min                 -0.98704
trainer/policy/normal/std Mean           0.623566
trainer/policy/normal/std Std            0.0808069
trainer/policy/normal/std Max            0.864569
trainer/policy/normal/std Min            0.464931
trainer/policy/normal/log_std Mean      -0.480776
trainer/policy/normal/log_std Std        0.130597
trainer/policy/normal/log_std Max       -0.145524
trainer/policy/normal/log_std Min       -0.765866
trainer/Alpha                            0.0303223
trainer/Alpha Loss                      -1.22255
exploration/num steps total         408000
exploration/num paths total           2040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.36875
exploration/Rewards Std                  1.03071
exploration/Rewards Max                 -2.96132
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1073.75
exploration/Returns Std                204.515
exploration/Returns Max               -617.559
exploration/Returns Min              -1195.31
exploration/Actions Mean                -0.129979
exploration/Actions Std                  0.799442
exploration/Actions Max                  0.999774
exploration/Actions Min                 -0.998433
exploration/Num Paths                   10
exploration/Average Returns          -1073.75
evaluation/num steps total          979272
evaluation/num paths total            4872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.90381
evaluation/Rewards Std                   0.51787
evaluation/Rewards Max                  -3.39328
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1186.67
evaluation/Returns Std                 101.736
evaluation/Returns Max                -701.114
evaluation/Returns Min               -1215.61
evaluation/Actions Mean                 -0.0779069
evaluation/Actions Std                   0.810538
evaluation/Actions Max                   0.997049
evaluation/Actions Min                  -0.972388
evaluation/Num Paths                    24
evaluation/Average Returns           -1186.67
time/data storing (s)                    0.0288874
time/evaluation sampling (s)            22.5895
time/exploration sampling (s)            7.03742
time/logging (s)                         0.0411633
time/sac training (s)                   23.6879
time/saving (s)                          0.045361
time/training (s)                        0.000527637
time/epoch (s)                          53.4307
time/total (s)                        7085.1
Epoch                                  202
----------------------------------  ----------------
2020-11-09 15:21:35.069694 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 203 finished
----------------------------------  ----------------
replay_buffer/size                  410000
trainer/num train calls             204000
trainer/QF1 Loss                      2599.85
trainer/QF2 Loss                      2601.18
trainer/Policy Loss                    562.79
trainer/Q1 Predictions Mean           -563.102
trainer/Q1 Predictions Std              31.3796
trainer/Q1 Predictions Max            -403.477
trainer/Q1 Predictions Min            -641.09
trainer/Q2 Predictions Mean           -563.104
trainer/Q2 Predictions Std              31.3798
trainer/Q2 Predictions Max            -403.514
trainer/Q2 Predictions Min            -642.016
trainer/Q Targets Mean                -560.089
trainer/Q Targets Std                   59.2016
trainer/Q Targets Max                   -5.2885
trainer/Q Targets Min                 -642.19
trainer/Log Pis Mean                     2.63863
trainer/Log Pis Std                      2.11325
trainer/Log Pis Max                      7.16418
trainer/Log Pis Min                     -4.13189
trainer/policy/mean Mean                 0.176017
trainer/policy/mean Std                  0.848085
trainer/policy/mean Max                  0.999738
trainer/policy/mean Min                 -0.990688
trainer/policy/normal/std Mean           0.581038
trainer/policy/normal/std Std            0.0583938
trainer/policy/normal/std Max            0.696376
trainer/policy/normal/std Min            0.400953
trainer/policy/normal/log_std Mean      -0.548329
trainer/policy/normal/log_std Std        0.105602
trainer/policy/normal/log_std Max       -0.361866
trainer/policy/normal/log_std Min       -0.913911
trainer/Alpha                            0.0308357
trainer/Alpha Loss                       2.22184
exploration/num steps total         410000
exploration/num paths total           2050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.11558
exploration/Rewards Std                  0.0273537
exploration/Rewards Max                 -5.96678
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1223.12
exploration/Returns Std                 17.9592
exploration/Returns Max              -1169.81
exploration/Returns Min              -1232.25
exploration/Actions Mean                -0.0173755
exploration/Actions Std                  0.863354
exploration/Actions Max                  0.998526
exploration/Actions Min                 -0.999164
exploration/Num Paths                   10
exploration/Average Returns          -1223.12
evaluation/num steps total          984096
evaluation/num paths total            4896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.13028
evaluation/Rewards Std                   0.0174275
evaluation/Rewards Max                  -6.01321
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1232.19
evaluation/Returns Std                   2.58178
evaluation/Returns Max               -1222.82
evaluation/Returns Min               -1234.21
evaluation/Actions Mean                 -0.00058283
evaluation/Actions Std                   0.856946
evaluation/Actions Max                   0.890725
evaluation/Actions Min                  -0.946485
evaluation/Num Paths                    24
evaluation/Average Returns           -1232.19
time/data storing (s)                    0.0641652
time/evaluation sampling (s)            21.5229
time/exploration sampling (s)            8.46601
time/logging (s)                         0.0551289
time/sac training (s)                   33.1706
time/saving (s)                          0.122655
time/training (s)                        0.000134393
time/epoch (s)                          63.4016
time/total (s)                        7177.92
Epoch                                  203
----------------------------------  ----------------
2020-11-09 15:22:52.166886 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 204 finished
----------------------------------  ----------------
replay_buffer/size                  412000
trainer/num train calls             205000
trainer/QF1 Loss                      1251.66
trainer/QF2 Loss                      1251.81
trainer/Policy Loss                    557.193
trainer/Q1 Predictions Mean           -557.378
trainer/Q1 Predictions Std              42.5119
trainer/Q1 Predictions Max            -372.117
trainer/Q1 Predictions Min            -635.638
trainer/Q2 Predictions Mean           -557.348
trainer/Q2 Predictions Std              42.4573
trainer/Q2 Predictions Max            -372.19
trainer/Q2 Predictions Min            -635.222
trainer/Q Targets Mean                -557.528
trainer/Q Targets Std                   55.1572
trainer/Q Targets Max                   -4.83274
trainer/Q Targets Min                 -634.514
trainer/Log Pis Mean                     2.20456
trainer/Log Pis Std                      2.20003
trainer/Log Pis Max                      8.7677
trainer/Log Pis Min                     -6.48981
trainer/policy/mean Mean                 0.298756
trainer/policy/mean Std                  0.78614
trainer/policy/mean Max                  0.999967
trainer/policy/mean Min                 -0.973867
trainer/policy/normal/std Mean           0.622545
trainer/policy/normal/std Std            0.076184
trainer/policy/normal/std Max            0.858433
trainer/policy/normal/std Min            0.507051
trainer/policy/normal/log_std Mean      -0.4811
trainer/policy/normal/log_std Std        0.118396
trainer/policy/normal/log_std Max       -0.152646
trainer/policy/normal/log_std Min       -0.679144
trainer/Alpha                            0.0312138
trainer/Alpha Loss                       0.709182
exploration/num steps total         412000
exploration/num paths total           2060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.05838
exploration/Rewards Std                  0.0556618
exploration/Rewards Max                 -5.80691
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1211.68
exploration/Returns Std                 23.2692
exploration/Returns Max              -1146.32
exploration/Returns Min              -1230.34
exploration/Actions Mean                 0.189963
exploration/Actions Std                  0.819978
exploration/Actions Max                  0.9997
exploration/Actions Min                 -0.998565
exploration/Num Paths                   10
exploration/Average Returns          -1211.68
evaluation/num steps total          988920
evaluation/num paths total            4920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.10298
evaluation/Rewards Std                   0.0425283
evaluation/Rewards Max                  -5.58855
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1226.7
evaluation/Returns Std                   7.67125
evaluation/Returns Max               -1205.41
evaluation/Returns Min               -1232.6
evaluation/Actions Mean                  0.228021
evaluation/Actions Std                   0.812353
evaluation/Actions Max                   0.98205
evaluation/Actions Min                  -0.89595
evaluation/Num Paths                    24
evaluation/Average Returns           -1226.7
time/data storing (s)                    0.0373733
time/evaluation sampling (s)            20.6559
time/exploration sampling (s)            7.90924
time/logging (s)                         0.143793
time/sac training (s)                   23.9532
time/saving (s)                          0.0717905
time/training (s)                        0.000170612
time/epoch (s)                          52.7714
time/total (s)                        7255.08
Epoch                                  204
----------------------------------  ----------------
2020-11-09 15:24:24.028497 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 205 finished
----------------------------------  ----------------
replay_buffer/size                  414000
trainer/num train calls             206000
trainer/QF1 Loss                      1230.14
trainer/QF2 Loss                      1228.73
trainer/Policy Loss                    562.37
trainer/Q1 Predictions Mean           -562.53
trainer/Q1 Predictions Std              33.6862
trainer/Q1 Predictions Max            -400.904
trainer/Q1 Predictions Min            -614.433
trainer/Q2 Predictions Mean           -562.483
trainer/Q2 Predictions Std              33.6859
trainer/Q2 Predictions Max            -401.013
trainer/Q2 Predictions Min            -613.973
trainer/Q Targets Mean                -562.467
trainer/Q Targets Std                   49.0734
trainer/Q Targets Max                   -5.43308
trainer/Q Targets Min                 -612.622
trainer/Log Pis Mean                     1.47794
trainer/Log Pis Std                      2.07286
trainer/Log Pis Max                      8.03558
trainer/Log Pis Min                     -3.31428
trainer/policy/mean Mean                 0.0486426
trainer/policy/mean Std                  0.793894
trainer/policy/mean Max                  0.999946
trainer/policy/mean Min                 -0.972631
trainer/policy/normal/std Mean           0.621127
trainer/policy/normal/std Std            0.0563889
trainer/policy/normal/std Max            0.822861
trainer/policy/normal/std Min            0.469313
trainer/policy/normal/log_std Mean      -0.480483
trainer/policy/normal/log_std Std        0.093225
trainer/policy/normal/log_std Max       -0.194968
trainer/policy/normal/log_std Min       -0.756485
trainer/Alpha                            0.0309701
trainer/Alpha Loss                      -1.81401
exploration/num steps total         414000
exploration/num paths total           2070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.79511
exploration/Rewards Std                  0.745105
exploration/Rewards Max                 -3.29628
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1159.02
exploration/Returns Std                136.17
exploration/Returns Max               -760.368
exploration/Returns Min              -1225.22
exploration/Actions Mean                 0.0375783
exploration/Actions Std                  0.788012
exploration/Actions Max                  0.999656
exploration/Actions Min                 -0.997736
exploration/Num Paths                   10
exploration/Average Returns          -1159.02
evaluation/num steps total          993744
evaluation/num paths total            4944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.08672
evaluation/Rewards Std                   0.05994
evaluation/Rewards Max                  -5.73442
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1223.43
evaluation/Returns Std                   9.37594
evaluation/Returns Max               -1185.03
evaluation/Returns Min               -1232.37
evaluation/Actions Mean                 -0.0183543
evaluation/Actions Std                   0.650721
evaluation/Actions Max                   0.979645
evaluation/Actions Min                  -0.92053
evaluation/Num Paths                    24
evaluation/Average Returns           -1223.43
time/data storing (s)                    0.0500949
time/evaluation sampling (s)            20.3992
time/exploration sampling (s)            9.67643
time/logging (s)                         0.0708843
time/sac training (s)                   30.4218
time/saving (s)                          0.0571361
time/training (s)                        0.000154354
time/epoch (s)                          60.6756
time/total (s)                        7346.82
Epoch                                  205
----------------------------------  ----------------
2020-11-09 15:25:47.087505 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 206 finished
----------------------------------  ---------------
replay_buffer/size                  416000
trainer/num train calls             207000
trainer/QF1 Loss                       788.812
trainer/QF2 Loss                       788.565
trainer/Policy Loss                    549.984
trainer/Q1 Predictions Mean           -550.057
trainer/Q1 Predictions Std              47.3815
trainer/Q1 Predictions Max            -395.4
trainer/Q1 Predictions Min            -604.857
trainer/Q2 Predictions Mean           -550.054
trainer/Q2 Predictions Std              47.3654
trainer/Q2 Predictions Max            -395.491
trainer/Q2 Predictions Min            -605.185
trainer/Q Targets Mean                -551.27
trainer/Q Targets Std                   58.4115
trainer/Q Targets Max                   -3.83866
trainer/Q Targets Min                 -608.067
trainer/Log Pis Mean                     2.48091
trainer/Log Pis Std                      2.98726
trainer/Log Pis Max                     14.5025
trainer/Log Pis Min                     -4.58701
trainer/policy/mean Mean                -0.135655
trainer/policy/mean Std                  0.813239
trainer/policy/mean Max                  0.999999
trainer/policy/mean Min                 -0.997032
trainer/policy/normal/std Mean           0.599275
trainer/policy/normal/std Std            0.0662635
trainer/policy/normal/std Max            0.876129
trainer/policy/normal/std Min            0.430439
trainer/policy/normal/log_std Mean      -0.518261
trainer/policy/normal/log_std Std        0.112244
trainer/policy/normal/log_std Max       -0.132242
trainer/policy/normal/log_std Min       -0.842951
trainer/Alpha                            0.030348
trainer/Alpha Loss                       1.68081
exploration/num steps total         416000
exploration/num paths total           2080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.63419
exploration/Rewards Std                  0.781071
exploration/Rewards Max                 -3.17506
exploration/Rewards Min                 -6.14149
exploration/Returns Mean             -1126.84
exploration/Returns Std                134.981
exploration/Returns Max               -738.856
exploration/Returns Min              -1212.61
exploration/Actions Mean                -0.237342
exploration/Actions Std                  0.701289
exploration/Actions Max                  0.999708
exploration/Actions Min                 -0.998075
exploration/Num Paths                   10
exploration/Average Returns          -1126.84
evaluation/num steps total          998568
evaluation/num paths total            4968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.00283
evaluation/Rewards Std                   0.132956
evaluation/Rewards Max                  -3.79321
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1206.57
evaluation/Returns Std                  16.7366
evaluation/Returns Max               -1144.15
evaluation/Returns Min               -1219.42
evaluation/Actions Mean                 -0.069761
evaluation/Actions Std                   0.827415
evaluation/Actions Max                   0.999519
evaluation/Actions Min                  -0.97127
evaluation/Num Paths                    24
evaluation/Average Returns           -1206.57
time/data storing (s)                    0.0340938
time/evaluation sampling (s)            22.6069
time/exploration sampling (s)            8.4325
time/logging (s)                         0.0671027
time/sac training (s)                   22.6702
time/saving (s)                          0.054805
time/training (s)                        0.00016402
time/epoch (s)                          53.8658
time/total (s)                        7429.85
Epoch                                  206
----------------------------------  ---------------
2020-11-09 15:27:47.602688 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 207 finished
----------------------------------  ----------------
replay_buffer/size                  418000
trainer/num train calls             208000
trainer/QF1 Loss                      2598.33
trainer/QF2 Loss                      2600.04
trainer/Policy Loss                    560.426
trainer/Q1 Predictions Mean           -560.509
trainer/Q1 Predictions Std              35.8544
trainer/Q1 Predictions Max            -402.82
trainer/Q1 Predictions Min            -637.208
trainer/Q2 Predictions Mean           -560.487
trainer/Q2 Predictions Std              35.8167
trainer/Q2 Predictions Max            -402.926
trainer/Q2 Predictions Min            -635.166
trainer/Q Targets Mean                -558.28
trainer/Q Targets Std                   60.9315
trainer/Q Targets Max                   -4.8443
trainer/Q Targets Min                 -637.615
trainer/Log Pis Mean                     1.59842
trainer/Log Pis Std                      2.16494
trainer/Log Pis Max                      8.25541
trainer/Log Pis Min                     -3.33222
trainer/policy/mean Mean                -0.0857003
trainer/policy/mean Std                  0.799219
trainer/policy/mean Max                  0.99985
trainer/policy/mean Min                 -0.976956
trainer/policy/normal/std Mean           0.589249
trainer/policy/normal/std Std            0.0691683
trainer/policy/normal/std Max            0.853
trainer/policy/normal/std Min            0.429686
trainer/policy/normal/log_std Mean      -0.535735
trainer/policy/normal/log_std Std        0.116793
trainer/policy/normal/log_std Max       -0.158996
trainer/policy/normal/log_std Min       -0.8447
trainer/Alpha                            0.0297842
trainer/Alpha Loss                      -1.41108
exploration/num steps total         418000
exploration/num paths total           2090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.83703
exploration/Rewards Std                  0.556747
exploration/Rewards Max                 -3.26536
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1167.41
exploration/Returns Std                 68.7348
exploration/Returns Max               -972.196
exploration/Returns Min              -1220.02
exploration/Actions Mean                -0.120676
exploration/Actions Std                  0.734173
exploration/Actions Max                  0.999488
exploration/Actions Min                 -0.996064
exploration/Num Paths                   10
exploration/Average Returns          -1167.41
evaluation/num steps total               1.00339e+06
evaluation/num paths total            4992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.03976
evaluation/Rewards Std                   0.0783535
evaluation/Rewards Max                  -4.76003
evaluation/Rewards Min                  -6.14197
evaluation/Returns Mean              -1213.99
evaluation/Returns Std                   8.95548
evaluation/Returns Max               -1190.8
evaluation/Returns Min               -1226.86
evaluation/Actions Mean                 -0.0796698
evaluation/Actions Std                   0.658248
evaluation/Actions Max                   0.992781
evaluation/Actions Min                  -0.943224
evaluation/Num Paths                    24
evaluation/Average Returns           -1213.99
time/data storing (s)                    0.0362211
time/evaluation sampling (s)            19.1586
time/exploration sampling (s)            9.62797
time/logging (s)                         0.0685318
time/sac training (s)                   43.2886
time/saving (s)                          0.0549732
time/training (s)                        0.00016623
time/epoch (s)                          72.2351
time/total (s)                        7550.32
Epoch                                  207
----------------------------------  ----------------
2020-11-09 15:29:44.087202 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 208 finished
----------------------------------  ----------------
replay_buffer/size                  420000
trainer/num train calls             209000
trainer/QF1 Loss                      1135.79
trainer/QF2 Loss                      1137.21
trainer/Policy Loss                    559.809
trainer/Q1 Predictions Mean           -560.126
trainer/Q1 Predictions Std              35.6131
trainer/Q1 Predictions Max            -390.246
trainer/Q1 Predictions Min            -619.222
trainer/Q2 Predictions Mean           -560.106
trainer/Q2 Predictions Std              35.6113
trainer/Q2 Predictions Max            -390
trainer/Q2 Predictions Min            -619.876
trainer/Q Targets Mean                -560.381
trainer/Q Targets Std                   49.6506
trainer/Q Targets Max                   -5.5896
trainer/Q Targets Min                 -620.885
trainer/Log Pis Mean                     1.84579
trainer/Log Pis Std                      2.23733
trainer/Log Pis Max                      8.6683
trainer/Log Pis Min                     -5.45399
trainer/policy/mean Mean                -0.257991
trainer/policy/mean Std                  0.761766
trainer/policy/mean Max                  0.996708
trainer/policy/mean Min                 -0.992315
trainer/policy/normal/std Mean           0.596196
trainer/policy/normal/std Std            0.113471
trainer/policy/normal/std Max            0.840163
trainer/policy/normal/std Min            0.405184
trainer/policy/normal/log_std Mean      -0.535454
trainer/policy/normal/log_std Std        0.191734
trainer/policy/normal/log_std Max       -0.17416
trainer/policy/normal/log_std Min       -0.903414
trainer/Alpha                            0.0297532
trainer/Alpha Loss                      -0.542024
exploration/num steps total         420000
exploration/num paths total           2100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.68091
exploration/Rewards Std                  0.283974
exploration/Rewards Max                 -5.0318
exploration/Rewards Min                 -6.14194
exploration/Returns Mean             -1136.18
exploration/Returns Std                 38.924
exploration/Returns Max              -1093.64
exploration/Returns Min              -1215.21
exploration/Actions Mean                -0.289831
exploration/Actions Std                  0.751792
exploration/Actions Max                  0.998233
exploration/Actions Min                 -0.999211
exploration/Num Paths                   10
exploration/Average Returns          -1136.18
evaluation/num steps total               1.00822e+06
evaluation/num paths total            5016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79806
evaluation/Rewards Std                   0.254646
evaluation/Rewards Max                  -5.07427
evaluation/Rewards Min                  -6.14191
evaluation/Returns Mean              -1165.41
evaluation/Returns Std                  39.5963
evaluation/Returns Max               -1066.17
evaluation/Returns Min               -1203.15
evaluation/Actions Mean                 -0.227786
evaluation/Actions Std                   0.790959
evaluation/Actions Max                   0.976315
evaluation/Actions Min                  -0.976645
evaluation/Num Paths                    24
evaluation/Average Returns           -1165.41
time/data storing (s)                    0.0377114
time/evaluation sampling (s)            25.9923
time/exploration sampling (s)            9.32914
time/logging (s)                         0.0681092
time/sac training (s)                   34.7552
time/saving (s)                          0.347258
time/training (s)                        0.000218959
time/epoch (s)                          70.53
time/total (s)                        7666.77
Epoch                                  208
----------------------------------  ----------------
2020-11-09 15:31:15.514786 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 209 finished
----------------------------------  ----------------
replay_buffer/size                  422000
trainer/num train calls             210000
trainer/QF1 Loss                      1296.57
trainer/QF2 Loss                      1296.35
trainer/Policy Loss                    560.251
trainer/Q1 Predictions Mean           -560.306
trainer/Q1 Predictions Std              40.0799
trainer/Q1 Predictions Max            -357.315
trainer/Q1 Predictions Min            -617.969
trainer/Q2 Predictions Mean           -560.311
trainer/Q2 Predictions Std              40.0947
trainer/Q2 Predictions Max            -357.163
trainer/Q2 Predictions Min            -618.246
trainer/Q Targets Mean                -560.521
trainer/Q Targets Std                   53.4532
trainer/Q Targets Max                   -5.82972
trainer/Q Targets Min                 -619.473
trainer/Log Pis Mean                     1.51205
trainer/Log Pis Std                      2.60671
trainer/Log Pis Max                     10.4611
trainer/Log Pis Min                     -5.87394
trainer/policy/mean Mean                -0.239073
trainer/policy/mean Std                  0.751239
trainer/policy/mean Max                  0.999734
trainer/policy/mean Min                 -0.985896
trainer/policy/normal/std Mean           0.70984
trainer/policy/normal/std Std            0.133361
trainer/policy/normal/std Max            0.952
trainer/policy/normal/std Min            0.464033
trainer/policy/normal/log_std Mean      -0.360726
trainer/policy/normal/log_std Std        0.190833
trainer/policy/normal/log_std Max       -0.04919
trainer/policy/normal/log_std Min       -0.767799
trainer/Alpha                            0.0303042
trainer/Alpha Loss                      -1.7061
exploration/num steps total         422000
exploration/num paths total           2110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.45036
exploration/Rewards Std                  0.59323
exploration/Rewards Max                 -3.62965
exploration/Rewards Min                 -6.14165
exploration/Returns Mean             -1090.07
exploration/Returns Std                 79.2128
exploration/Returns Max               -943.6
exploration/Returns Min              -1180.45
exploration/Actions Mean                -0.282961
exploration/Actions Std                  0.724225
exploration/Actions Max                  0.999589
exploration/Actions Min                 -0.999168
exploration/Num Paths                   10
exploration/Average Returns          -1090.07
evaluation/num steps total               1.01304e+06
evaluation/num paths total            5040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.86217
evaluation/Rewards Std                   0.495646
evaluation/Rewards Max                  -3.38963
evaluation/Rewards Min                  -6.14184
evaluation/Returns Mean              -1178.3
evaluation/Returns Std                  92.2443
evaluation/Returns Max                -740.569
evaluation/Returns Min               -1214.14
evaluation/Actions Mean                 -0.118335
evaluation/Actions Std                   0.834842
evaluation/Actions Max                   0.988392
evaluation/Actions Min                  -0.968178
evaluation/Num Paths                    24
evaluation/Average Returns           -1178.3
time/data storing (s)                    0.0410772
time/evaluation sampling (s)            18.9153
time/exploration sampling (s)           10.0935
time/logging (s)                         0.0594712
time/sac training (s)                   24.1636
time/saving (s)                          0.340465
time/training (s)                        0.000145578
time/epoch (s)                          53.6136
time/total (s)                        7758.14
Epoch                                  209
----------------------------------  ----------------
2020-11-09 15:32:35.470389 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 210 finished
----------------------------------  ----------------
replay_buffer/size                  424000
trainer/num train calls             211000
trainer/QF1 Loss                      1061.53
trainer/QF2 Loss                      1060.57
trainer/Policy Loss                    558.89
trainer/Q1 Predictions Mean           -559.01
trainer/Q1 Predictions Std              40.7575
trainer/Q1 Predictions Max            -397.623
trainer/Q1 Predictions Min            -657.111
trainer/Q2 Predictions Mean           -559.004
trainer/Q2 Predictions Std              40.7573
trainer/Q2 Predictions Max            -397.68
trainer/Q2 Predictions Min            -658.199
trainer/Q Targets Mean                -559.28
trainer/Q Targets Std                   53.9704
trainer/Q Targets Max                   -5.13468
trainer/Q Targets Min                 -658.74
trainer/Log Pis Mean                     1.69236
trainer/Log Pis Std                      2.60675
trainer/Log Pis Max                      9.93093
trainer/Log Pis Min                     -5.74211
trainer/policy/mean Mean                -0.145334
trainer/policy/mean Std                  0.783624
trainer/policy/mean Max                  0.999585
trainer/policy/mean Min                 -0.985855
trainer/policy/normal/std Mean           0.650117
trainer/policy/normal/std Std            0.0740714
trainer/policy/normal/std Max            0.922244
trainer/policy/normal/std Min            0.488892
trainer/policy/normal/log_std Mean      -0.436916
trainer/policy/normal/log_std Std        0.111722
trainer/policy/normal/log_std Max       -0.0809459
trainer/policy/normal/log_std Min       -0.715614
trainer/Alpha                            0.0296424
trainer/Alpha Loss                      -1.08246
exploration/num steps total         424000
exploration/num paths total           2120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.52304
exploration/Rewards Std                  0.731127
exploration/Rewards Max                 -3.22945
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1104.61
exploration/Returns Std                117.829
exploration/Returns Max               -767.872
exploration/Returns Min              -1188.57
exploration/Actions Mean                -0.19783
exploration/Actions Std                  0.719924
exploration/Actions Max                  0.999559
exploration/Actions Min                 -0.998595
exploration/Num Paths                   10
exploration/Average Returns          -1104.61
evaluation/num steps total               1.01786e+06
evaluation/num paths total            5064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.90962
evaluation/Rewards Std                   0.508593
evaluation/Rewards Max                  -3.37083
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1187.83
evaluation/Returns Std                  97.204
evaluation/Returns Max                -723.481
evaluation/Returns Min               -1218.37
evaluation/Actions Mean                 -0.113786
evaluation/Actions Std                   0.78803
evaluation/Actions Max                   0.988368
evaluation/Actions Min                  -0.949523
evaluation/Num Paths                    24
evaluation/Average Returns           -1187.83
time/data storing (s)                    0.035723
time/evaluation sampling (s)            18.4588
time/exploration sampling (s)            7.54634
time/logging (s)                         0.0648086
time/sac training (s)                   23.5885
time/saving (s)                          0.0966537
time/training (s)                        0.000154752
time/epoch (s)                          49.791
time/total (s)                        7838.07
Epoch                                  210
----------------------------------  ----------------
2020-11-09 15:34:33.908031 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 211 finished
----------------------------------  ----------------
replay_buffer/size                  426000
trainer/num train calls             212000
trainer/QF1 Loss                      1050.35
trainer/QF2 Loss                      1053.89
trainer/Policy Loss                    560.585
trainer/Q1 Predictions Mean           -560.721
trainer/Q1 Predictions Std              39.4534
trainer/Q1 Predictions Max            -398.709
trainer/Q1 Predictions Min            -638.678
trainer/Q2 Predictions Mean           -560.731
trainer/Q2 Predictions Std              39.4439
trainer/Q2 Predictions Max            -398.776
trainer/Q2 Predictions Min            -639.609
trainer/Q Targets Mean                -560.291
trainer/Q Targets Std                   53.0596
trainer/Q Targets Max                   -5.1727
trainer/Q Targets Min                 -639.655
trainer/Log Pis Mean                     1.98048
trainer/Log Pis Std                      2.52471
trainer/Log Pis Max                     10.3318
trainer/Log Pis Min                     -3.5957
trainer/policy/mean Mean                -0.199327
trainer/policy/mean Std                  0.778348
trainer/policy/mean Max                  0.999478
trainer/policy/mean Min                 -0.986269
trainer/policy/normal/std Mean           0.597749
trainer/policy/normal/std Std            0.102968
trainer/policy/normal/std Max            0.803885
trainer/policy/normal/std Min            0.426395
trainer/policy/normal/log_std Mean      -0.529137
trainer/policy/normal/log_std Std        0.169868
trainer/policy/normal/log_std Max       -0.2183
trainer/policy/normal/log_std Min       -0.85239
trainer/Alpha                            0.0289405
trainer/Alpha Loss                      -0.0691382
exploration/num steps total         426000
exploration/num paths total           2130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.6928
exploration/Rewards Std                  0.394495
exploration/Rewards Max                 -4.29491
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1138.56
exploration/Returns Std                 59.8921
exploration/Returns Max               -970.895
exploration/Returns Min              -1188.6
exploration/Actions Mean                -0.209942
exploration/Actions Std                  0.771721
exploration/Actions Max                  0.999997
exploration/Actions Min                 -0.999314
exploration/Num Paths                   10
exploration/Average Returns          -1138.56
evaluation/num steps total               1.02269e+06
evaluation/num paths total            5088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8878
evaluation/Rewards Std                   0.453539
evaluation/Rewards Max                  -3.30839
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1183.45
evaluation/Returns Std                  73.6325
evaluation/Returns Max                -836.986
evaluation/Returns Min               -1215.55
evaluation/Actions Mean                 -0.147413
evaluation/Actions Std                   0.805107
evaluation/Actions Max                   0.990386
evaluation/Actions Min                  -0.969633
evaluation/Num Paths                    24
evaluation/Average Returns           -1183.45
time/data storing (s)                    0.0381729
time/evaluation sampling (s)            20.3496
time/exploration sampling (s)            8.47992
time/logging (s)                         0.0666112
time/sac training (s)                   33.9736
time/saving (s)                          0.167892
time/training (s)                        0.000131101
time/epoch (s)                          63.0759
time/total (s)                        7956.46
Epoch                                  211
----------------------------------  ----------------
2020-11-09 15:36:29.587180 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 212 finished
----------------------------------  ----------------
replay_buffer/size                  428000
trainer/num train calls             213000
trainer/QF1 Loss                        13.906
trainer/QF2 Loss                        13.9277
trainer/Policy Loss                    563.363
trainer/Q1 Predictions Mean           -563.608
trainer/Q1 Predictions Std              37.3638
trainer/Q1 Predictions Max            -357.91
trainer/Q1 Predictions Min            -653.892
trainer/Q2 Predictions Mean           -563.595
trainer/Q2 Predictions Std              37.3933
trainer/Q2 Predictions Max            -357.919
trainer/Q2 Predictions Min            -654.944
trainer/Q Targets Mean                -566.062
trainer/Q Targets Std                   37.5159
trainer/Q Targets Max                 -358.497
trainer/Q Targets Min                 -655.19
trainer/Log Pis Mean                     1.60922
trainer/Log Pis Std                      1.71975
trainer/Log Pis Max                      7.24885
trainer/Log Pis Min                     -3.41603
trainer/policy/mean Mean                -0.233497
trainer/policy/mean Std                  0.763152
trainer/policy/mean Max                  0.990516
trainer/policy/mean Min                 -0.984832
trainer/policy/normal/std Mean           0.642366
trainer/policy/normal/std Std            0.152786
trainer/policy/normal/std Max            0.928506
trainer/policy/normal/std Min            0.412571
trainer/policy/normal/log_std Mean      -0.47121
trainer/policy/normal/log_std Std        0.239949
trainer/policy/normal/log_std Max       -0.074178
trainer/policy/normal/log_std Min       -0.885346
trainer/Alpha                            0.0287251
trainer/Alpha Loss                      -1.38728
exploration/num steps total         428000
exploration/num paths total           2140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.28075
exploration/Rewards Std                  0.783643
exploration/Rewards Max                 -3.20406
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1056.15
exploration/Returns Std                114.057
exploration/Returns Max               -788.822
exploration/Returns Min              -1166.75
exploration/Actions Mean                -0.232387
exploration/Actions Std                  0.790911
exploration/Actions Max                  0.998968
exploration/Actions Min                 -0.999537
exploration/Num Paths                   10
exploration/Average Returns          -1056.15
evaluation/num steps total               1.02751e+06
evaluation/num paths total            5112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6734
evaluation/Rewards Std                   0.698915
evaluation/Rewards Max                  -3.23221
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1140.35
evaluation/Returns Std                 121.869
evaluation/Returns Max                -817.616
evaluation/Returns Min               -1219.12
evaluation/Actions Mean                 -0.235368
evaluation/Actions Std                   0.749817
evaluation/Actions Max                   0.993349
evaluation/Actions Min                  -0.976117
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.35
time/data storing (s)                    0.0447284
time/evaluation sampling (s)            20.8053
time/exploration sampling (s)           10.1672
time/logging (s)                         0.0763367
time/sac training (s)                   34.5473
time/saving (s)                          0.0833319
time/training (s)                        0.000167091
time/epoch (s)                          65.7243
time/total (s)                        8072.1
Epoch                                  212
----------------------------------  ----------------
2020-11-09 15:38:23.473097 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 213 finished
----------------------------------  ----------------
replay_buffer/size                  430000
trainer/num train calls             214000
trainer/QF1 Loss                        24.3836
trainer/QF2 Loss                        24.5545
trainer/Policy Loss                    558.2
trainer/Q1 Predictions Mean           -558.561
trainer/Q1 Predictions Std              36.4641
trainer/Q1 Predictions Max            -395.651
trainer/Q1 Predictions Min            -650.762
trainer/Q2 Predictions Mean           -558.558
trainer/Q2 Predictions Std              36.4537
trainer/Q2 Predictions Max            -395.782
trainer/Q2 Predictions Min            -651.778
trainer/Q Targets Mean                -561.544
trainer/Q Targets Std                   36.9213
trainer/Q Targets Max                 -397.359
trainer/Q Targets Min                 -652.939
trainer/Log Pis Mean                     2.28896
trainer/Log Pis Std                      2.21725
trainer/Log Pis Max                     11.1634
trainer/Log Pis Min                     -3.40613
trainer/policy/mean Mean                -0.26315
trainer/policy/mean Std                  0.781221
trainer/policy/mean Max                  0.999512
trainer/policy/mean Min                 -0.99497
trainer/policy/normal/std Mean           0.579479
trainer/policy/normal/std Std            0.102283
trainer/policy/normal/std Max            0.814578
trainer/policy/normal/std Min            0.375566
trainer/policy/normal/log_std Mean      -0.56117
trainer/policy/normal/log_std Std        0.176465
trainer/policy/normal/log_std Max       -0.205085
trainer/policy/normal/log_std Min       -0.979322
trainer/Alpha                            0.0284378
trainer/Alpha Loss                       1.02869
exploration/num steps total         430000
exploration/num paths total           2150
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.28007
exploration/Rewards Std                  1.04231
exploration/Rewards Max                 -1.24138
exploration/Rewards Min                 -6.14167
exploration/Returns Mean             -1056.01
exploration/Returns Std                142.238
exploration/Returns Max               -671.966
exploration/Returns Min              -1195.29
exploration/Actions Mean                -0.25248
exploration/Actions Std                  0.80915
exploration/Actions Max                  0.999939
exploration/Actions Min                 -0.999687
exploration/Num Paths                   10
exploration/Average Returns          -1056.01
evaluation/num steps total               1.03234e+06
evaluation/num paths total            5136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79854
evaluation/Rewards Std                   0.330492
evaluation/Rewards Max                  -4.47041
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1165.51
evaluation/Returns Std                  57.7222
evaluation/Returns Max                -928.64
evaluation/Returns Min               -1212.02
evaluation/Actions Mean                 -0.30372
evaluation/Actions Std                   0.741039
evaluation/Actions Max                   0.984869
evaluation/Actions Min                  -0.983478
evaluation/Num Paths                    24
evaluation/Average Returns           -1165.51
time/data storing (s)                    0.0376351
time/evaluation sampling (s)            20.0164
time/exploration sampling (s)            8.44576
time/logging (s)                         0.0644719
time/sac training (s)                   32.3716
time/saving (s)                          0.0510076
time/training (s)                        0.000117221
time/epoch (s)                          60.987
time/total (s)                        8185.93
Epoch                                  213
----------------------------------  ----------------
2020-11-09 15:41:06.144360 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 214 finished
----------------------------------  ----------------
replay_buffer/size                  432000
trainer/num train calls             215000
trainer/QF1 Loss                        13.2632
trainer/QF2 Loss                        13.1181
trainer/Policy Loss                    562.329
trainer/Q1 Predictions Mean           -562.317
trainer/Q1 Predictions Std              35.3068
trainer/Q1 Predictions Max            -383.037
trainer/Q1 Predictions Min            -612.025
trainer/Q2 Predictions Mean           -562.355
trainer/Q2 Predictions Std              35.3436
trainer/Q2 Predictions Max            -383.072
trainer/Q2 Predictions Min            -612.423
trainer/Q Targets Mean                -565.007
trainer/Q Targets Std                   35.6128
trainer/Q Targets Max                 -384.601
trainer/Q Targets Min                 -614.019
trainer/Log Pis Mean                     1.91932
trainer/Log Pis Std                      2.41735
trainer/Log Pis Max                     10.6852
trainer/Log Pis Min                     -4.31795
trainer/policy/mean Mean                -0.342973
trainer/policy/mean Std                  0.728643
trainer/policy/mean Max                  0.999273
trainer/policy/mean Min                 -0.994572
trainer/policy/normal/std Mean           0.723987
trainer/policy/normal/std Std            0.147218
trainer/policy/normal/std Max            0.981044
trainer/policy/normal/std Min            0.498403
trainer/policy/normal/log_std Mean      -0.344118
trainer/policy/normal/log_std Std        0.206739
trainer/policy/normal/log_std Max       -0.0191376
trainer/policy/normal/log_std Min       -0.696346
trainer/Alpha                            0.0295372
trainer/Alpha Loss                      -0.284158
exploration/num steps total         432000
exploration/num paths total           2160
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.24736
exploration/Rewards Std                  0.783467
exploration/Rewards Max                 -2.25041
exploration/Rewards Min                 -6.14193
exploration/Returns Mean             -1049.47
exploration/Returns Std                 97.0079
exploration/Returns Max               -860.226
exploration/Returns Min              -1171.78
exploration/Actions Mean                -0.284048
exploration/Actions Std                  0.778652
exploration/Actions Max                  0.999873
exploration/Actions Min                 -0.999775
exploration/Num Paths                   10
exploration/Average Returns          -1049.47
evaluation/num steps total               1.03716e+06
evaluation/num paths total            5160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60242
evaluation/Rewards Std                   0.571675
evaluation/Rewards Max                  -3.15309
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1126.09
evaluation/Returns Std                  82.2788
evaluation/Returns Max                -816.586
evaluation/Returns Min               -1201.54
evaluation/Actions Mean                 -0.227185
evaluation/Actions Std                   0.8242
evaluation/Actions Max                   0.992204
evaluation/Actions Min                  -0.979145
evaluation/Num Paths                    24
evaluation/Average Returns           -1126.09
time/data storing (s)                    0.0534989
time/evaluation sampling (s)            21.8842
time/exploration sampling (s)           12.772
time/logging (s)                         0.079779
time/sac training (s)                   43.7934
time/saving (s)                          0.0828971
time/training (s)                        0.000174335
time/epoch (s)                          78.6661
time/total (s)                        8348.57
Epoch                                  214
----------------------------------  ----------------
2020-11-09 15:43:33.686137 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 215 finished
----------------------------------  ----------------
replay_buffer/size                  434000
trainer/num train calls             216000
trainer/QF1 Loss                      2476.54
trainer/QF2 Loss                      2475.96
trainer/Policy Loss                    555.326
trainer/Q1 Predictions Mean           -555.555
trainer/Q1 Predictions Std              44.6814
trainer/Q1 Predictions Max            -365.887
trainer/Q1 Predictions Min            -634.486
trainer/Q2 Predictions Mean           -555.588
trainer/Q2 Predictions Std              44.6622
trainer/Q2 Predictions Max            -365.875
trainer/Q2 Predictions Min            -635.43
trainer/Q Targets Mean                -553.794
trainer/Q Targets Std                   66.3165
trainer/Q Targets Max                   -5.79062
trainer/Q Targets Min                 -637.01
trainer/Log Pis Mean                     2.62038
trainer/Log Pis Std                      2.03302
trainer/Log Pis Max                      9.57612
trainer/Log Pis Min                     -3.42855
trainer/policy/mean Mean                -0.530078
trainer/policy/mean Std                  0.666505
trainer/policy/mean Max                  0.997003
trainer/policy/mean Min                 -0.998857
trainer/policy/normal/std Mean           0.549696
trainer/policy/normal/std Std            0.113047
trainer/policy/normal/std Max            0.777881
trainer/policy/normal/std Min            0.358284
trainer/policy/normal/log_std Mean      -0.619347
trainer/policy/normal/log_std Std        0.204413
trainer/policy/normal/log_std Max       -0.251182
trainer/policy/normal/log_std Min       -1.02643
trainer/Alpha                            0.0291112
trainer/Alpha Loss                       2.19404
exploration/num steps total         434000
exploration/num paths total           2170
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.77898
exploration/Rewards Std                  1.01893
exploration/Rewards Max                 -2.27216
exploration/Rewards Min                 -6.14176
exploration/Returns Mean              -955.796
exploration/Returns Std                155.43
exploration/Returns Max               -586.762
exploration/Returns Min              -1145.01
exploration/Actions Mean                -0.639992
exploration/Actions Std                  0.534988
exploration/Actions Max                  0.998367
exploration/Actions Min                 -0.999313
exploration/Num Paths                   10
exploration/Average Returns           -955.796
evaluation/num steps total               1.04198e+06
evaluation/num paths total            5184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59552
evaluation/Rewards Std                   0.359485
evaluation/Rewards Max                  -4.24616
evaluation/Rewards Min                  -6.13858
evaluation/Returns Mean              -1124.7
evaluation/Returns Std                  62.7276
evaluation/Returns Max                -953.099
evaluation/Returns Min               -1210.99
evaluation/Actions Mean                 -0.670338
evaluation/Actions Std                   0.563977
evaluation/Actions Max                   0.949864
evaluation/Actions Min                  -0.993839
evaluation/Num Paths                    24
evaluation/Average Returns           -1124.7
time/data storing (s)                    0.0365971
time/evaluation sampling (s)            21.8725
time/exploration sampling (s)            7.71063
time/logging (s)                         0.0809007
time/sac training (s)                   34.1004
time/saving (s)                          0.0710159
time/training (s)                        0.000175233
time/epoch (s)                          63.8722
time/total (s)                        8496.08
Epoch                                  215
----------------------------------  ----------------
2020-11-09 15:45:56.126335 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 216 finished
----------------------------------  ----------------
replay_buffer/size                  436000
trainer/num train calls             217000
trainer/QF1 Loss                      1218.91
trainer/QF2 Loss                      1215.51
trainer/Policy Loss                    563.452
trainer/Q1 Predictions Mean           -563.581
trainer/Q1 Predictions Std              36.7248
trainer/Q1 Predictions Max            -402.38
trainer/Q1 Predictions Min            -638.293
trainer/Q2 Predictions Mean           -563.576
trainer/Q2 Predictions Std              36.6619
trainer/Q2 Predictions Max            -402.465
trainer/Q2 Predictions Min            -636.481
trainer/Q Targets Mean                -564.907
trainer/Q Targets Std                   50.639
trainer/Q Targets Max                   -4.51091
trainer/Q Targets Min                 -641.464
trainer/Log Pis Mean                     1.78234
trainer/Log Pis Std                      2.14211
trainer/Log Pis Max                     11.7233
trainer/Log Pis Min                     -5.63223
trainer/policy/mean Mean                -0.168139
trainer/policy/mean Std                  0.773193
trainer/policy/mean Max                  0.999867
trainer/policy/mean Min                 -0.976407
trainer/policy/normal/std Mean           0.617249
trainer/policy/normal/std Std            0.0978574
trainer/policy/normal/std Max            0.820949
trainer/policy/normal/std Min            0.444813
trainer/policy/normal/log_std Mean      -0.494689
trainer/policy/normal/log_std Std        0.155146
trainer/policy/normal/log_std Max       -0.197294
trainer/policy/normal/log_std Min       -0.810101
trainer/Alpha                            0.0288977
trainer/Alpha Loss                      -0.771377
exploration/num steps total         436000
exploration/num paths total           2180
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.80768
exploration/Rewards Std                  0.250828
exploration/Rewards Max                 -4.96715
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1161.54
exploration/Returns Std                 24.4426
exploration/Returns Max              -1106.52
exploration/Returns Min              -1199.71
exploration/Actions Mean                -0.286022
exploration/Actions Std                  0.700565
exploration/Actions Max                  0.99957
exploration/Actions Min                 -0.998066
exploration/Num Paths                   10
exploration/Average Returns          -1161.54
evaluation/num steps total               1.04681e+06
evaluation/num paths total            5208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.83746
evaluation/Rewards Std                   0.639499
evaluation/Rewards Max                  -3.29412
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1173.33
evaluation/Returns Std                 110.322
evaluation/Returns Max                -739.687
evaluation/Returns Min               -1218.19
evaluation/Actions Mean                 -0.0985679
evaluation/Actions Std                   0.811926
evaluation/Actions Max                   0.988792
evaluation/Actions Min                  -0.966696
evaluation/Num Paths                    24
evaluation/Average Returns           -1173.33
time/data storing (s)                    0.0294221
time/evaluation sampling (s)            21.0288
time/exploration sampling (s)           10.7937
time/logging (s)                         0.0626298
time/sac training (s)                   34.1117
time/saving (s)                          0.0509864
time/training (s)                        0.00015539
time/epoch (s)                          66.0774
time/total (s)                        8638.45
Epoch                                  216
----------------------------------  ----------------
2020-11-09 15:48:31.733775 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 217 finished
----------------------------------  ----------------
replay_buffer/size                  438000
trainer/num train calls             218000
trainer/QF1 Loss                      1281.18
trainer/QF2 Loss                      1278.69
trainer/Policy Loss                    556.574
trainer/Q1 Predictions Mean           -556.715
trainer/Q1 Predictions Std              45.5385
trainer/Q1 Predictions Max            -340.534
trainer/Q1 Predictions Min            -632.392
trainer/Q2 Predictions Mean           -556.757
trainer/Q2 Predictions Std              45.5372
trainer/Q2 Predictions Max            -340.43
trainer/Q2 Predictions Min            -632.849
trainer/Q Targets Mean                -557.209
trainer/Q Targets Std                   57.4062
trainer/Q Targets Max                   -5.82215
trainer/Q Targets Min                 -635.28
trainer/Log Pis Mean                     3.25185
trainer/Log Pis Std                      2.45726
trainer/Log Pis Max                     11.344
trainer/Log Pis Min                     -4.46394
trainer/policy/mean Mean                -0.4894
trainer/policy/mean Std                  0.7487
trainer/policy/mean Max                  0.997981
trainer/policy/mean Min                 -0.998754
trainer/policy/normal/std Mean           0.571613
trainer/policy/normal/std Std            0.0738045
trainer/policy/normal/std Max            0.745153
trainer/policy/normal/std Min            0.431796
trainer/policy/normal/log_std Mean      -0.567741
trainer/policy/normal/log_std Std        0.130525
trainer/policy/normal/log_std Max       -0.294166
trainer/policy/normal/log_std Min       -0.839802
trainer/Alpha                            0.0291875
trainer/Alpha Loss                       4.42405
exploration/num steps total         438000
exploration/num paths total           2190
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.0489
exploration/Rewards Std                  0.912928
exploration/Rewards Max                 -1.61357
exploration/Rewards Min                 -6.14179
exploration/Returns Mean             -1009.78
exploration/Returns Std                152.804
exploration/Returns Max               -562.543
exploration/Returns Min              -1114.66
exploration/Actions Mean                -0.540748
exploration/Actions Std                  0.69975
exploration/Actions Max                  0.999205
exploration/Actions Min                 -0.999798
exploration/Num Paths                   10
exploration/Average Returns          -1009.78
evaluation/num steps total               1.05163e+06
evaluation/num paths total            5232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73994
evaluation/Rewards Std                   0.2236
evaluation/Rewards Max                  -4.7657
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1153.73
evaluation/Returns Std                  40.5597
evaluation/Returns Max               -1028.42
evaluation/Returns Min               -1200.56
evaluation/Actions Mean                 -0.465275
evaluation/Actions Std                   0.7504
evaluation/Actions Max                   0.993802
evaluation/Actions Min                  -0.996597
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.73
time/data storing (s)                    0.0388105
time/evaluation sampling (s)            17.3941
time/exploration sampling (s)            8.74261
time/logging (s)                         0.0712734
time/sac training (s)                   42.0887
time/saving (s)                          0.122301
time/training (s)                        0.00020311
time/epoch (s)                          68.4579
time/total (s)                        8794.02
Epoch                                  217
----------------------------------  ----------------
2020-11-09 15:50:41.614975 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 218 finished
----------------------------------  ----------------
replay_buffer/size                  440000
trainer/num train calls             219000
trainer/QF1 Loss                      1311.48
trainer/QF2 Loss                      1312.52
trainer/Policy Loss                    559.417
trainer/Q1 Predictions Mean           -559.702
trainer/Q1 Predictions Std              44.6751
trainer/Q1 Predictions Max            -383.237
trainer/Q1 Predictions Min            -656.065
trainer/Q2 Predictions Mean           -559.72
trainer/Q2 Predictions Std              44.7044
trainer/Q2 Predictions Max            -383.272
trainer/Q2 Predictions Min            -657.042
trainer/Q Targets Mean                -559.8
trainer/Q Targets Std                   56.6562
trainer/Q Targets Max                   -5.79475
trainer/Q Targets Min                 -657.25
trainer/Log Pis Mean                     2.46843
trainer/Log Pis Std                      2.11119
trainer/Log Pis Max                      8.63023
trainer/Log Pis Min                     -9.76798
trainer/policy/mean Mean                -0.313114
trainer/policy/mean Std                  0.750612
trainer/policy/mean Max                  0.998695
trainer/policy/mean Min                 -0.989411
trainer/policy/normal/std Mean           0.601046
trainer/policy/normal/std Std            0.111011
trainer/policy/normal/std Max            0.813636
trainer/policy/normal/std Min            0.387835
trainer/policy/normal/log_std Mean      -0.526117
trainer/policy/normal/log_std Std        0.184699
trainer/policy/normal/log_std Max       -0.206242
trainer/policy/normal/log_std Min       -0.947175
trainer/Alpha                            0.028726
trainer/Alpha Loss                       1.6629
exploration/num steps total         440000
exploration/num paths total           2200
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.31063
exploration/Rewards Std                  0.754158
exploration/Rewards Max                 -2.86068
exploration/Rewards Min                 -6.14198
exploration/Returns Mean             -1062.13
exploration/Returns Std                 99.7268
exploration/Returns Max               -795.815
exploration/Returns Min              -1144.75
exploration/Actions Mean                -0.329305
exploration/Actions Std                  0.764064
exploration/Actions Max                  0.999495
exploration/Actions Min                 -0.999276
exploration/Num Paths                   10
exploration/Average Returns          -1062.13
evaluation/num steps total               1.05646e+06
evaluation/num paths total            5256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.80151
evaluation/Rewards Std                   0.179432
evaluation/Rewards Max                  -5.23738
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1166.1
evaluation/Returns Std                  22.4607
evaluation/Returns Max               -1103.39
evaluation/Returns Min               -1190.34
evaluation/Actions Mean                 -0.290861
evaluation/Actions Std                   0.786174
evaluation/Actions Max                   0.98864
evaluation/Actions Min                  -0.982574
evaluation/Num Paths                    24
evaluation/Average Returns           -1166.1
time/data storing (s)                    0.0340101
time/evaluation sampling (s)            23.4035
time/exploration sampling (s)            7.8126
time/logging (s)                         0.0728023
time/sac training (s)                   32.2754
time/saving (s)                          0.0863829
time/training (s)                        0.000170673
time/epoch (s)                          63.6849
time/total (s)                        8923.86
Epoch                                  218
----------------------------------  ----------------
2020-11-09 15:52:50.176246 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 219 finished
----------------------------------  ----------------
replay_buffer/size                  442000
trainer/num train calls             220000
trainer/QF1 Loss                        13.3149
trainer/QF2 Loss                        13.2701
trainer/Policy Loss                    562.359
trainer/Q1 Predictions Mean           -562.548
trainer/Q1 Predictions Std              39.4232
trainer/Q1 Predictions Max            -394.114
trainer/Q1 Predictions Min            -622.908
trainer/Q2 Predictions Mean           -562.531
trainer/Q2 Predictions Std              39.4033
trainer/Q2 Predictions Max            -394.087
trainer/Q2 Predictions Min            -623.692
trainer/Q Targets Mean                -564.662
trainer/Q Targets Std                   39.7626
trainer/Q Targets Max                 -394.711
trainer/Q Targets Min                 -625.09
trainer/Log Pis Mean                     1.55742
trainer/Log Pis Std                      1.67248
trainer/Log Pis Max                      6.96422
trainer/Log Pis Min                     -3.99128
trainer/policy/mean Mean                -0.124166
trainer/policy/mean Std                  0.782806
trainer/policy/mean Max                  0.997071
trainer/policy/mean Min                 -0.98205
trainer/policy/normal/std Mean           0.585652
trainer/policy/normal/std Std            0.0848745
trainer/policy/normal/std Max            0.737933
trainer/policy/normal/std Min            0.411996
trainer/policy/normal/log_std Mean      -0.545723
trainer/policy/normal/log_std Std        0.146921
trainer/policy/normal/log_std Max       -0.303902
trainer/policy/normal/log_std Min       -0.886741
trainer/Alpha                            0.0283645
trainer/Alpha Loss                      -1.57675
exploration/num steps total         442000
exploration/num paths total           2210
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.76403
exploration/Rewards Std                  0.571182
exploration/Rewards Max                 -3.36715
exploration/Rewards Min                 -6.14197
exploration/Returns Mean             -1152.81
exploration/Returns Std                 93.8408
exploration/Returns Max               -897.319
exploration/Returns Min              -1220.31
exploration/Actions Mean                -0.12768
exploration/Actions Std                  0.771451
exploration/Actions Max                  0.999074
exploration/Actions Min                 -0.997824
exploration/Num Paths                   10
exploration/Average Returns          -1152.81
evaluation/num steps total               1.06128e+06
evaluation/num paths total            5280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84659
evaluation/Rewards Std                   0.70192
evaluation/Rewards Max                  -3.36956
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1175.17
evaluation/Returns Std                 132.122
evaluation/Returns Max                -732.995
evaluation/Returns Min               -1224.95
evaluation/Actions Mean                 -0.056855
evaluation/Actions Std                   0.746873
evaluation/Actions Max                   0.9767
evaluation/Actions Min                  -0.966274
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.17
time/data storing (s)                    0.036283
time/evaluation sampling (s)            21.7651
time/exploration sampling (s)            9.65722
time/logging (s)                         0.0769097
time/sac training (s)                   32.3496
time/saving (s)                          0.111195
time/training (s)                        0.000315069
time/epoch (s)                          63.9966
time/total (s)                        9052.39
Epoch                                  219
----------------------------------  ----------------
2020-11-09 15:55:04.649828 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 220 finished
----------------------------------  ---------------
replay_buffer/size                  444000
trainer/num train calls             221000
trainer/QF1 Loss                      2693.27
trainer/QF2 Loss                      2695.59
trainer/Policy Loss                    562.628
trainer/Q1 Predictions Mean           -562.706
trainer/Q1 Predictions Std              41.5921
trainer/Q1 Predictions Max            -375.473
trainer/Q1 Predictions Min            -651.469
trainer/Q2 Predictions Mean           -562.754
trainer/Q2 Predictions Std              41.6058
trainer/Q2 Predictions Max            -375.48
trainer/Q2 Predictions Min            -652.854
trainer/Q Targets Mean                -560.587
trainer/Q Targets Std                   64.6587
trainer/Q Targets Max                   -3.20406
trainer/Q Targets Min                 -653.232
trainer/Log Pis Mean                     2.23406
trainer/Log Pis Std                      2.85691
trainer/Log Pis Max                      9.53654
trainer/Log Pis Min                     -3.47772
trainer/policy/mean Mean                -0.331484
trainer/policy/mean Std                  0.776605
trainer/policy/mean Max                  0.999903
trainer/policy/mean Min                 -0.995161
trainer/policy/normal/std Mean           0.657546
trainer/policy/normal/std Std            0.0835818
trainer/policy/normal/std Max            0.859891
trainer/policy/normal/std Min            0.517494
trainer/policy/normal/log_std Mean      -0.427149
trainer/policy/normal/log_std Std        0.125173
trainer/policy/normal/log_std Max       -0.15095
trainer/policy/normal/log_std Min       -0.658757
trainer/Alpha                            0.0286181
trainer/Alpha Loss                       0.831784
exploration/num steps total         444000
exploration/num paths total           2220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.12385
exploration/Rewards Std                  0.923601
exploration/Rewards Max                 -3.12168
exploration/Rewards Min                 -6.14191
exploration/Returns Mean             -1024.77
exploration/Returns Std                132.009
exploration/Returns Max               -760.861
exploration/Returns Min              -1171.07
exploration/Actions Mean                -0.239174
exploration/Actions Std                  0.828926
exploration/Actions Max                  0.999878
exploration/Actions Min                 -0.999387
exploration/Num Paths                   10
exploration/Average Returns          -1024.77
evaluation/num steps total               1.0661e+06
evaluation/num paths total            5304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.57877
evaluation/Rewards Std                   0.547663
evaluation/Rewards Max                  -3.28381
evaluation/Rewards Min                  -6.14107
evaluation/Returns Mean              -1121.33
evaluation/Returns Std                  91.2198
evaluation/Returns Max                -738.892
evaluation/Returns Min               -1202.38
evaluation/Actions Mean                 -0.378426
evaluation/Actions Std                   0.752538
evaluation/Actions Max                   0.997937
evaluation/Actions Min                  -0.987032
evaluation/Num Paths                    24
evaluation/Average Returns           -1121.33
time/data storing (s)                    0.0340435
time/evaluation sampling (s)            21.6106
time/exploration sampling (s)            8.41389
time/logging (s)                         0.0590087
time/sac training (s)                   33.7835
time/saving (s)                          0.239842
time/training (s)                        0.00016391
time/epoch (s)                          64.1411
time/total (s)                        9186.8
Epoch                                  220
----------------------------------  ---------------
2020-11-09 15:57:15.017370 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 221 finished
----------------------------------  ----------------
replay_buffer/size                  446000
trainer/num train calls             222000
trainer/QF1 Loss                      1192.26
trainer/QF2 Loss                      1194.7
trainer/Policy Loss                    557.278
trainer/Q1 Predictions Mean           -557.35
trainer/Q1 Predictions Std              46.2603
trainer/Q1 Predictions Max            -387.881
trainer/Q1 Predictions Min            -657.474
trainer/Q2 Predictions Mean           -557.335
trainer/Q2 Predictions Std              46.2625
trainer/Q2 Predictions Max            -387.989
trainer/Q2 Predictions Min            -658.448
trainer/Q Targets Mean                -557.614
trainer/Q Targets Std                   58.3612
trainer/Q Targets Max                   -5.32782
trainer/Q Targets Min                 -659.093
trainer/Log Pis Mean                     1.04281
trainer/Log Pis Std                      2.05541
trainer/Log Pis Max                      8.13329
trainer/Log Pis Min                     -4.81228
trainer/policy/mean Mean                -0.124243
trainer/policy/mean Std                  0.73566
trainer/policy/mean Max                  0.999646
trainer/policy/mean Min                 -0.951639
trainer/policy/normal/std Mean           0.688249
trainer/policy/normal/std Std            0.11185
trainer/policy/normal/std Max            0.869478
trainer/policy/normal/std Min            0.507643
trainer/policy/normal/log_std Mean      -0.38719
trainer/policy/normal/log_std Std        0.16595
trainer/policy/normal/log_std Max       -0.139862
trainer/policy/normal/log_std Min       -0.677976
trainer/Alpha                            0.0289699
trainer/Alpha Loss                      -3.38988
exploration/num steps total         446000
exploration/num paths total           2230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.69691
exploration/Rewards Std                  0.575971
exploration/Rewards Max                 -3.14729
exploration/Rewards Min                 -6.14176
exploration/Returns Mean             -1139.38
exploration/Returns Std                 61.3145
exploration/Returns Max              -1022.98
exploration/Returns Min              -1203.97
exploration/Actions Mean                -0.231913
exploration/Actions Std                  0.697737
exploration/Actions Max                  0.99927
exploration/Actions Min                 -0.999103
exploration/Num Paths                   10
exploration/Average Returns          -1139.38
evaluation/num steps total               1.07093e+06
evaluation/num paths total            5328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.92215
evaluation/Rewards Std                   0.502772
evaluation/Rewards Max                  -3.39391
evaluation/Rewards Min                  -6.14199
evaluation/Returns Mean              -1190.35
evaluation/Returns Std                  95.6245
evaluation/Returns Max                -733.227
evaluation/Returns Min               -1219.15
evaluation/Actions Mean                 -0.0944405
evaluation/Actions Std                   0.741645
evaluation/Actions Max                   0.984366
evaluation/Actions Min                  -0.947457
evaluation/Num Paths                    24
evaluation/Average Returns           -1190.35
time/data storing (s)                    0.0495362
time/evaluation sampling (s)            19.4975
time/exploration sampling (s)            8.40468
time/logging (s)                         0.0690344
time/sac training (s)                   32.6882
time/saving (s)                          0.301889
time/training (s)                        0.000176083
time/epoch (s)                          61.0111
time/total (s)                        9317.14
Epoch                                  221
----------------------------------  ----------------
2020-11-09 15:59:30.270611 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 222 finished
----------------------------------  ----------------
replay_buffer/size                  448000
trainer/num train calls             223000
trainer/QF1 Loss                        51.6157
trainer/QF2 Loss                        51.3608
trainer/Policy Loss                    561.208
trainer/Q1 Predictions Mean           -561.349
trainer/Q1 Predictions Std              44.4148
trainer/Q1 Predictions Max            -347.696
trainer/Q1 Predictions Min            -651.208
trainer/Q2 Predictions Mean           -561.34
trainer/Q2 Predictions Std              44.4125
trainer/Q2 Predictions Max            -347.734
trainer/Q2 Predictions Min            -652.627
trainer/Q Targets Mean                -563.516
trainer/Q Targets Std                   45.862
trainer/Q Targets Max                 -344.878
trainer/Q Targets Min                 -654.979
trainer/Log Pis Mean                     1.37806
trainer/Log Pis Std                      1.57055
trainer/Log Pis Max                      5.65202
trainer/Log Pis Min                     -3.20484
trainer/policy/mean Mean                 0.069765
trainer/policy/mean Std                  0.777606
trainer/policy/mean Max                  0.994419
trainer/policy/mean Min                 -0.976933
trainer/policy/normal/std Mean           0.546444
trainer/policy/normal/std Std            0.0621846
trainer/policy/normal/std Max            0.725859
trainer/policy/normal/std Min            0.417298
trainer/policy/normal/log_std Mean      -0.610835
trainer/policy/normal/log_std Std        0.114331
trainer/policy/normal/log_std Max       -0.320399
trainer/policy/normal/log_std Min       -0.873955
trainer/Alpha                            0.0280765
trainer/Alpha Loss                      -2.22207
exploration/num steps total         448000
exploration/num paths total           2240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.7911
exploration/Rewards Std                  0.765354
exploration/Rewards Max                 -3.09544
exploration/Rewards Min                 -6.142
exploration/Returns Mean             -1158.22
exploration/Returns Std                112.92
exploration/Returns Max               -856.49
exploration/Returns Min              -1227.95
exploration/Actions Mean                -0.0472821
exploration/Actions Std                  0.759514
exploration/Actions Max                  0.99901
exploration/Actions Min                 -0.997451
exploration/Num Paths                   10
exploration/Average Returns          -1158.22
evaluation/num steps total               1.07575e+06
evaluation/num paths total            5352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.05029
evaluation/Rewards Std                   0.231044
evaluation/Rewards Max                  -4.81344
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1216.11
evaluation/Returns Std                  35.5676
evaluation/Returns Max               -1054.24
evaluation/Returns Min               -1232.45
evaluation/Actions Mean                 -0.0695631
evaluation/Actions Std                   0.673137
evaluation/Actions Max                   0.942863
evaluation/Actions Min                  -0.947332
evaluation/Num Paths                    24
evaluation/Average Returns           -1216.11
time/data storing (s)                    0.0473255
time/evaluation sampling (s)            26.0999
time/exploration sampling (s)            9.23199
time/logging (s)                         0.0807705
time/sac training (s)                   31.72
time/saving (s)                          0.13473
time/training (s)                        0.000213071
time/epoch (s)                          67.3149
time/total (s)                        9452.36
Epoch                                  222
----------------------------------  ----------------
2020-11-09 16:01:49.994388 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 223 finished
----------------------------------  ----------------
replay_buffer/size                  450000
trainer/num train calls             224000
trainer/QF1 Loss                      2529.07
trainer/QF2 Loss                      2531.07
trainer/Policy Loss                    562.211
trainer/Q1 Predictions Mean           -562.654
trainer/Q1 Predictions Std              37.478
trainer/Q1 Predictions Max            -394.517
trainer/Q1 Predictions Min            -635.561
trainer/Q2 Predictions Mean           -562.656
trainer/Q2 Predictions Std              37.5018
trainer/Q2 Predictions Max            -394.456
trainer/Q2 Predictions Min            -636.403
trainer/Q Targets Mean                -560.605
trainer/Q Targets Std                   62.0105
trainer/Q Targets Max                   -5.4714
trainer/Q Targets Min                 -637.728
trainer/Log Pis Mean                     2.20202
trainer/Log Pis Std                      1.97814
trainer/Log Pis Max                      6.8484
trainer/Log Pis Min                     -3.40015
trainer/policy/mean Mean                 0.177173
trainer/policy/mean Std                  0.844799
trainer/policy/mean Max                  0.993274
trainer/policy/mean Min                 -0.989458
trainer/policy/normal/std Mean           0.554198
trainer/policy/normal/std Std            0.0440995
trainer/policy/normal/std Max            0.719949
trainer/policy/normal/std Min            0.446015
trainer/policy/normal/log_std Mean      -0.593428
trainer/policy/normal/log_std Std        0.080155
trainer/policy/normal/log_std Max       -0.328575
trainer/policy/normal/log_std Min       -0.807403
trainer/Alpha                            0.0281047
trainer/Alpha Loss                       0.721561
exploration/num steps total         450000
exploration/num paths total           2250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.10884
exploration/Rewards Std                  0.0459315
exploration/Rewards Max                 -5.90429
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1221.77
exploration/Returns Std                 22.7181
exploration/Returns Max              -1154.86
exploration/Returns Min              -1232.97
exploration/Actions Mean                -0.00187616
exploration/Actions Std                  0.856801
exploration/Actions Max                  0.997804
exploration/Actions Min                 -0.997788
exploration/Num Paths                   10
exploration/Average Returns          -1221.77
evaluation/num steps total               1.08058e+06
evaluation/num paths total            5376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.12971
evaluation/Rewards Std                   0.0178898
evaluation/Rewards Max                  -6.01628
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1232.07
evaluation/Returns Std                   2.67062
evaluation/Returns Max               -1222.89
evaluation/Returns Min               -1234.05
evaluation/Actions Mean                 -0.0139254
evaluation/Actions Std                   0.881168
evaluation/Actions Max                   0.880047
evaluation/Actions Min                  -0.933984
evaluation/Num Paths                    24
evaluation/Average Returns           -1232.07
time/data storing (s)                    0.0325715
time/evaluation sampling (s)            22.154
time/exploration sampling (s)            7.7203
time/logging (s)                         0.0482446
time/sac training (s)                   35.7759
time/saving (s)                          0.131398
time/training (s)                        0.000169679
time/epoch (s)                          65.8626
time/total (s)                        9592.01
Epoch                                  223
----------------------------------  ----------------
2020-11-09 16:04:15.107208 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 224 finished
----------------------------------  ----------------
replay_buffer/size                  452000
trainer/num train calls             225000
trainer/QF1 Loss                      3990.11
trainer/QF2 Loss                      3991.44
trainer/Policy Loss                    560.244
trainer/Q1 Predictions Mean           -560.328
trainer/Q1 Predictions Std              44.286
trainer/Q1 Predictions Max            -395.55
trainer/Q1 Predictions Min            -634.46
trainer/Q2 Predictions Mean           -560.339
trainer/Q2 Predictions Std              44.2764
trainer/Q2 Predictions Max            -396.415
trainer/Q2 Predictions Min            -635.722
trainer/Q Targets Mean                -555.94
trainer/Q Targets Std                   74.7015
trainer/Q Targets Max                   -5.334
trainer/Q Targets Min                 -637.111
trainer/Log Pis Mean                     1.77675
trainer/Log Pis Std                      2.02586
trainer/Log Pis Max                      7.87601
trainer/Log Pis Min                     -5.24135
trainer/policy/mean Mean                -0.180864
trainer/policy/mean Std                  0.77258
trainer/policy/mean Max                  0.999589
trainer/policy/mean Min                 -0.989658
trainer/policy/normal/std Mean           0.635605
trainer/policy/normal/std Std            0.082688
trainer/policy/normal/std Max            0.799613
trainer/policy/normal/std Min            0.481789
trainer/policy/normal/log_std Mean      -0.461889
trainer/policy/normal/log_std Std        0.133016
trainer/policy/normal/log_std Max       -0.223627
trainer/policy/normal/log_std Min       -0.730249
trainer/Alpha                            0.028505
trainer/Alpha Loss                      -0.794239
exploration/num steps total         452000
exploration/num paths total           2260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.88057
exploration/Rewards Std                  0.196102
exploration/Rewards Max                 -5.25659
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1176.11
exploration/Returns Std                 33.0235
exploration/Returns Max              -1108.93
exploration/Returns Min              -1212.76
exploration/Actions Mean                -0.261274
exploration/Actions Std                  0.743097
exploration/Actions Max                  0.999278
exploration/Actions Min                 -0.998384
exploration/Num Paths                   10
exploration/Average Returns          -1176.11
evaluation/num steps total               1.0854e+06
evaluation/num paths total            5400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.79885
evaluation/Rewards Std                   0.70593
evaluation/Rewards Max                  -3.38976
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1165.57
evaluation/Returns Std                 136.999
evaluation/Returns Max                -711.834
evaluation/Returns Min               -1223.86
evaluation/Actions Mean                 -0.112292
evaluation/Actions Std                   0.79985
evaluation/Actions Max                   0.983879
evaluation/Actions Min                  -0.983544
evaluation/Num Paths                    24
evaluation/Average Returns           -1165.57
time/data storing (s)                    0.034144
time/evaluation sampling (s)            20.8023
time/exploration sampling (s)            8.50187
time/logging (s)                         0.0857668
time/sac training (s)                   37.8866
time/saving (s)                          0.0812817
time/training (s)                        0.000162146
time/epoch (s)                          67.3921
time/total (s)                        9737.11
Epoch                                  224
----------------------------------  ----------------
2020-11-09 16:06:29.523522 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 225 finished
----------------------------------  ----------------
replay_buffer/size                  454000
trainer/num train calls             226000
trainer/QF1 Loss                      2513.74
trainer/QF2 Loss                      2517.4
trainer/Policy Loss                    564.559
trainer/Q1 Predictions Mean           -564.622
trainer/Q1 Predictions Std              39.9937
trainer/Q1 Predictions Max            -397.769
trainer/Q1 Predictions Min            -662.031
trainer/Q2 Predictions Mean           -564.622
trainer/Q2 Predictions Std              40.0375
trainer/Q2 Predictions Max            -397.788
trainer/Q2 Predictions Min            -663.089
trainer/Q Targets Mean                -562.889
trainer/Q Targets Std                   64.0676
trainer/Q Targets Max                   -5.16413
trainer/Q Targets Min                 -663.786
trainer/Log Pis Mean                     1.26797
trainer/Log Pis Std                      1.69653
trainer/Log Pis Max                      6.2121
trainer/Log Pis Min                     -4.5425
trainer/policy/mean Mean                -0.14954
trainer/policy/mean Std                  0.769165
trainer/policy/mean Max                  0.998753
trainer/policy/mean Min                 -0.977988
trainer/policy/normal/std Mean           0.670481
trainer/policy/normal/std Std            0.072797
trainer/policy/normal/std Max            0.818971
trainer/policy/normal/std Min            0.526512
trainer/policy/normal/log_std Mean      -0.405673
trainer/policy/normal/log_std Std        0.108873
trainer/policy/normal/log_std Max       -0.199707
trainer/policy/normal/log_std Min       -0.641481
trainer/Alpha                            0.0283417
trainer/Alpha Loss                      -2.60853
exploration/num steps total         454000
exploration/num paths total           2270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.73904
exploration/Rewards Std                  0.427432
exploration/Rewards Max                 -3.83653
exploration/Rewards Min                 -6.14203
exploration/Returns Mean             -1147.81
exploration/Returns Std                 61.1761
exploration/Returns Max               -995.896
exploration/Returns Min              -1207.64
exploration/Actions Mean                -0.203266
exploration/Actions Std                  0.731461
exploration/Actions Max                  0.998594
exploration/Actions Min                 -0.99833
exploration/Num Paths                   10
exploration/Average Returns          -1147.81
evaluation/num steps total               1.09022e+06
evaluation/num paths total            5424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9846
evaluation/Rewards Std                   0.156904
evaluation/Rewards Max                  -5.06982
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1202.9
evaluation/Returns Std                  26.4842
evaluation/Returns Max               -1085.29
evaluation/Returns Min               -1222.33
evaluation/Actions Mean                 -0.135114
evaluation/Actions Std                   0.754531
evaluation/Actions Max                   0.962621
evaluation/Actions Min                  -0.965253
evaluation/Num Paths                    24
evaluation/Average Returns           -1202.9
time/data storing (s)                    0.033613
time/evaluation sampling (s)            17.9331
time/exploration sampling (s)            8.79914
time/logging (s)                         0.0646475
time/sac training (s)                   35.6561
time/saving (s)                          0.0587686
time/training (s)                        0.000164226
time/epoch (s)                          62.5456
time/total (s)                        9871.47
Epoch                                  225
----------------------------------  ----------------
2020-11-09 16:10:15.629269 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 226 finished
----------------------------------  ----------------
replay_buffer/size                  456000
trainer/num train calls             227000
trainer/QF1 Loss                        20.1301
trainer/QF2 Loss                        20.1678
trainer/Policy Loss                    558.127
trainer/Q1 Predictions Mean           -558.161
trainer/Q1 Predictions Std              45.9337
trainer/Q1 Predictions Max            -389.686
trainer/Q1 Predictions Min            -642.12
trainer/Q2 Predictions Mean           -558.142
trainer/Q2 Predictions Std              45.9559
trainer/Q2 Predictions Max            -389.475
trainer/Q2 Predictions Min            -642.943
trainer/Q Targets Mean                -561.138
trainer/Q Targets Std                   46.4189
trainer/Q Targets Max                 -391.014
trainer/Q Targets Min                 -644.315
trainer/Log Pis Mean                     2.3599
trainer/Log Pis Std                      2.86957
trainer/Log Pis Max                     10.0446
trainer/Log Pis Min                     -6.69782
trainer/policy/mean Mean                -0.267342
trainer/policy/mean Std                  0.775415
trainer/policy/mean Max                  0.999877
trainer/policy/mean Min                 -0.993836
trainer/policy/normal/std Mean           0.619143
trainer/policy/normal/std Std            0.0799579
trainer/policy/normal/std Max            0.797265
trainer/policy/normal/std Min            0.457474
trainer/policy/normal/log_std Mean      -0.487542
trainer/policy/normal/log_std Std        0.126678
trainer/policy/normal/log_std Max       -0.226568
trainer/policy/normal/log_std Min       -0.782036
trainer/Alpha                            0.0278914
trainer/Alpha Loss                       1.28824
exploration/num steps total         456000
exploration/num paths total           2280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.20574
exploration/Rewards Std                  0.970393
exploration/Rewards Max                 -3.26705
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1041.15
exploration/Returns Std                165.139
exploration/Returns Max               -690.47
exploration/Returns Min              -1167.97
exploration/Actions Mean                -0.227727
exploration/Actions Std                  0.817402
exploration/Actions Max                  0.999846
exploration/Actions Min                 -0.999597
exploration/Num Paths                   10
exploration/Average Returns          -1041.15
evaluation/num steps total               1.09505e+06
evaluation/num paths total            5448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.87035
evaluation/Rewards Std                   0.139028
evaluation/Rewards Max                  -5.41253
evaluation/Rewards Min                  -6.14192
evaluation/Returns Mean              -1179.94
evaluation/Returns Std                  21.3209
evaluation/Returns Max               -1139.73
evaluation/Returns Min               -1215.64
evaluation/Actions Mean                 -0.180599
evaluation/Actions Std                   0.829012
evaluation/Actions Max                   0.993918
evaluation/Actions Min                  -0.972555
evaluation/Num Paths                    24
evaluation/Average Returns           -1179.94
time/data storing (s)                    0.0304989
time/evaluation sampling (s)            25.0922
time/exploration sampling (s)            8.35859
time/logging (s)                         0.0858755
time/sac training (s)                   42.2861
time/saving (s)                          0.16136
time/training (s)                        0.000133151
time/epoch (s)                          76.0148
time/total (s)                       10097.5
Epoch                                  226
----------------------------------  ----------------
2020-11-09 16:13:10.761000 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 227 finished
----------------------------------  ----------------
replay_buffer/size                  458000
trainer/num train calls             228000
trainer/QF1 Loss                        18.2522
trainer/QF2 Loss                        18.3428
trainer/Policy Loss                    564.765
trainer/Q1 Predictions Mean           -564.917
trainer/Q1 Predictions Std              40.1627
trainer/Q1 Predictions Max            -388.607
trainer/Q1 Predictions Min            -660.848
trainer/Q2 Predictions Mean           -564.952
trainer/Q2 Predictions Std              40.1974
trainer/Q2 Predictions Max            -388.567
trainer/Q2 Predictions Min            -661.923
trainer/Q Targets Mean                -567.022
trainer/Q Targets Std                   40.5173
trainer/Q Targets Max                 -389.329
trainer/Q Targets Min                 -661.668
trainer/Log Pis Mean                     1.70184
trainer/Log Pis Std                      1.70094
trainer/Log Pis Max                      6.16233
trainer/Log Pis Min                     -4.10758
trainer/policy/mean Mean                 0.00191059
trainer/policy/mean Std                  0.809145
trainer/policy/mean Max                  0.996502
trainer/policy/mean Min                 -0.981303
trainer/policy/normal/std Mean           0.544389
trainer/policy/normal/std Std            0.0595795
trainer/policy/normal/std Max            0.678642
trainer/policy/normal/std Min            0.431676
trainer/policy/normal/log_std Mean      -0.614044
trainer/policy/normal/log_std Std        0.108953
trainer/policy/normal/log_std Max       -0.387662
trainer/policy/normal/log_std Min       -0.840081
trainer/Alpha                            0.0276066
trainer/Alpha Loss                      -1.0703
exploration/num steps total         458000
exploration/num paths total           2290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.85993
exploration/Rewards Std                  0.679754
exploration/Rewards Max                 -3.26413
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1171.99
exploration/Returns Std                107.316
exploration/Returns Max               -864.602
exploration/Returns Min              -1228.77
exploration/Actions Mean                -0.0750927
exploration/Actions Std                  0.789866
exploration/Actions Max                  0.997704
exploration/Actions Min                 -0.998786
exploration/Num Paths                   10
exploration/Average Returns          -1171.99
evaluation/num steps total               1.09987e+06
evaluation/num paths total            5472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9428
evaluation/Rewards Std                   0.562003
evaluation/Rewards Max                  -3.31679
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1194.5
evaluation/Returns Std                  87.8623
evaluation/Returns Max                -809.544
evaluation/Returns Min               -1231.7
evaluation/Actions Mean                 -0.0764925
evaluation/Actions Std                   0.708165
evaluation/Actions Max                   0.961882
evaluation/Actions Min                  -0.960638
evaluation/Num Paths                    24
evaluation/Average Returns           -1194.5
time/data storing (s)                    0.0315136
time/evaluation sampling (s)            18.6734
time/exploration sampling (s)            7.55679
time/logging (s)                         0.068795
time/sac training (s)                   28.9505
time/saving (s)                          0.0846755
time/training (s)                        0.000215776
time/epoch (s)                          55.3658
time/total (s)                       10272.6
Epoch                                  227
----------------------------------  ----------------
2020-11-09 16:16:31.041085 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 228 finished
----------------------------------  ---------------
replay_buffer/size                  460000
trainer/num train calls             229000
trainer/QF1 Loss                      1485.06
trainer/QF2 Loss                      1488.85
trainer/Policy Loss                    564.622
trainer/Q1 Predictions Mean           -564.64
trainer/Q1 Predictions Std              40.144
trainer/Q1 Predictions Max            -395.49
trainer/Q1 Predictions Min            -641.286
trainer/Q2 Predictions Mean           -564.645
trainer/Q2 Predictions Std              40.1282
trainer/Q2 Predictions Max            -396.315
trainer/Q2 Predictions Min            -640.92
trainer/Q Targets Mean                -564.44
trainer/Q Targets Std                   53.6029
trainer/Q Targets Max                   -4.40267
trainer/Q Targets Min                 -641.663
trainer/Log Pis Mean                     2.7041
trainer/Log Pis Std                      2.54005
trainer/Log Pis Max                     10.2938
trainer/Log Pis Min                     -3.24277
trainer/policy/mean Mean                -0.473675
trainer/policy/mean Std                  0.719991
trainer/policy/mean Max                  0.99762
trainer/policy/mean Min                 -0.995283
trainer/policy/normal/std Mean           0.645007
trainer/policy/normal/std Std            0.100716
trainer/policy/normal/std Max            0.833672
trainer/policy/normal/std Min            0.487626
trainer/policy/normal/log_std Mean      -0.450685
trainer/policy/normal/log_std Std        0.156195
trainer/policy/normal/log_std Max       -0.181915
trainer/policy/normal/log_std Min       -0.718207
trainer/Alpha                            0.0283161
trainer/Alpha Loss                       2.50965
exploration/num steps total         460000
exploration/num paths total           2300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.69946
exploration/Rewards Std                  0.970007
exploration/Rewards Max                 -2.87424
exploration/Rewards Min                 -6.14202
exploration/Returns Mean              -939.891
exploration/Returns Std                147.094
exploration/Returns Max               -715.499
exploration/Returns Min              -1104.24
exploration/Actions Mean                -0.274965
exploration/Actions Std                  0.859554
exploration/Actions Max                  0.999813
exploration/Actions Min                 -0.999823
exploration/Num Paths                   10
exploration/Average Returns           -939.891
evaluation/num steps total               1.1047e+06
evaluation/num paths total            5496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.63982
evaluation/Rewards Std                   0.496375
evaluation/Rewards Max                  -3.23085
evaluation/Rewards Min                  -6.14161
evaluation/Returns Mean              -1133.6
evaluation/Returns Std                  83.868
evaluation/Returns Max                -778.142
evaluation/Returns Min               -1212.12
evaluation/Actions Mean                 -0.597791
evaluation/Actions Std                   0.592963
evaluation/Actions Max                   0.99062
evaluation/Actions Min                  -0.990906
evaluation/Num Paths                    24
evaluation/Average Returns           -1133.6
time/data storing (s)                    0.0337995
time/evaluation sampling (s)            19.8108
time/exploration sampling (s)            8.38465
time/logging (s)                         0.135075
time/sac training (s)                   31.7809
time/saving (s)                          0.0917234
time/training (s)                        0.00016418
time/epoch (s)                          60.2372
time/total (s)                       10472.9
Epoch                                  228
----------------------------------  ---------------
2020-11-09 16:20:04.055357 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 229 finished
----------------------------------  ----------------
replay_buffer/size                  462000
trainer/num train calls             230000
trainer/QF1 Loss                      1264.9
trainer/QF2 Loss                      1264.76
trainer/Policy Loss                    559.005
trainer/Q1 Predictions Mean           -559.095
trainer/Q1 Predictions Std              45.0256
trainer/Q1 Predictions Max            -378.18
trainer/Q1 Predictions Min            -616.747
trainer/Q2 Predictions Mean           -559.107
trainer/Q2 Predictions Std              44.9966
trainer/Q2 Predictions Max            -378.181
trainer/Q2 Predictions Min            -616.686
trainer/Q Targets Mean                -559.291
trainer/Q Targets Std                   57.1644
trainer/Q Targets Max                   -6.0571
trainer/Q Targets Min                 -617.506
trainer/Log Pis Mean                     1.79389
trainer/Log Pis Std                      2.42034
trainer/Log Pis Max                      7.71323
trainer/Log Pis Min                     -5.65263
trainer/policy/mean Mean                -0.016029
trainer/policy/mean Std                  0.794286
trainer/policy/mean Max                  0.99973
trainer/policy/mean Min                 -0.959143
trainer/policy/normal/std Mean           0.626831
trainer/policy/normal/std Std            0.0466354
trainer/policy/normal/std Max            0.84744
trainer/policy/normal/std Min            0.519487
trainer/policy/normal/log_std Mean      -0.469756
trainer/policy/normal/log_std Std        0.0726582
trainer/policy/normal/log_std Max       -0.165536
trainer/policy/normal/log_std Min       -0.654913
trainer/Alpha                            0.0280631
trainer/Alpha Loss                      -0.736503
exploration/num steps total         462000
exploration/num paths total           2310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.5173
exploration/Rewards Std                  1.03206
exploration/Rewards Max                 -3.36512
exploration/Rewards Min                 -6.14188
exploration/Returns Mean             -1103.46
exploration/Returns Std                212.16
exploration/Returns Max               -663.378
exploration/Returns Min              -1222.35
exploration/Actions Mean                 0.0424327
exploration/Actions Std                  0.798467
exploration/Actions Max                  0.999964
exploration/Actions Min                 -0.997949
exploration/Num Paths                   10
exploration/Average Returns          -1103.46
evaluation/num steps total               1.10952e+06
evaluation/num paths total            5520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73597
evaluation/Rewards Std                   0.871793
evaluation/Rewards Max                  -3.4006
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1152.93
evaluation/Returns Std                 173.659
evaluation/Returns Max                -692.085
evaluation/Returns Min               -1228.08
evaluation/Actions Mean                  0.0229528
evaluation/Actions Std                   0.735837
evaluation/Actions Max                   0.99278
evaluation/Actions Min                  -0.912832
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.93
time/data storing (s)                    0.0380332
time/evaluation sampling (s)            18.812
time/exploration sampling (s)            7.72603
time/logging (s)                         0.0843878
time/sac training (s)                   35.7793
time/saving (s)                          0.117095
time/training (s)                        0.000171257
time/epoch (s)                          62.557
time/total (s)                       10685.8
Epoch                                  229
----------------------------------  ----------------
2020-11-09 16:23:59.037500 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 230 finished
----------------------------------  ----------------
replay_buffer/size                  464000
trainer/num train calls             231000
trainer/QF1 Loss                        14.5567
trainer/QF2 Loss                        15.0553
trainer/Policy Loss                    566.483
trainer/Q1 Predictions Mean           -566.547
trainer/Q1 Predictions Std              38.4883
trainer/Q1 Predictions Max            -381.454
trainer/Q1 Predictions Min            -654.973
trainer/Q2 Predictions Mean           -566.56
trainer/Q2 Predictions Std              38.4777
trainer/Q2 Predictions Max            -381.461
trainer/Q2 Predictions Min            -655.316
trainer/Q Targets Mean                -569.485
trainer/Q Targets Std                   38.8157
trainer/Q Targets Max                 -383.005
trainer/Q Targets Min                 -655.712
trainer/Log Pis Mean                     1.94387
trainer/Log Pis Std                      3.30518
trainer/Log Pis Max                     10.5959
trainer/Log Pis Min                     -5.23885
trainer/policy/mean Mean                -0.0885486
trainer/policy/mean Std                  0.781918
trainer/policy/mean Max                  0.999957
trainer/policy/mean Min                 -0.975746
trainer/policy/normal/std Mean           0.708516
trainer/policy/normal/std Std            0.0873704
trainer/policy/normal/std Max            0.959868
trainer/policy/normal/std Min            0.475308
trainer/policy/normal/log_std Mean      -0.35259
trainer/policy/normal/log_std Std        0.128441
trainer/policy/normal/log_std Max       -0.0409596
trainer/policy/normal/log_std Min       -0.743792
trainer/Alpha                            0.0278155
trainer/Alpha Loss                      -0.201055
exploration/num steps total         464000
exploration/num paths total           2320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.67611
exploration/Rewards Std                  0.748261
exploration/Rewards Max                 -3.38511
exploration/Rewards Min                 -6.14176
exploration/Returns Mean             -1135.22
exploration/Returns Std                145.286
exploration/Returns Max               -704.658
exploration/Returns Min              -1204.2
exploration/Actions Mean                -0.00224191
exploration/Actions Std                  0.832003
exploration/Actions Max                  0.999965
exploration/Actions Min                 -0.999402
exploration/Num Paths                   10
exploration/Average Returns          -1135.22
evaluation/num steps total               1.11434e+06
evaluation/num paths total            5544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82962
evaluation/Rewards Std                   0.720597
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1171.75
evaluation/Returns Std                 143.156
evaluation/Returns Max                -695.352
evaluation/Returns Min               -1220.8
evaluation/Actions Mean                 -0.00662345
evaluation/Actions Std                   0.837539
evaluation/Actions Max                   0.997223
evaluation/Actions Min                  -0.935101
evaluation/Num Paths                    24
evaluation/Average Returns           -1171.75
time/data storing (s)                    0.0303606
time/evaluation sampling (s)            23.8977
time/exploration sampling (s)            9.64082
time/logging (s)                         0.078298
time/sac training (s)                   31.5112
time/saving (s)                          0.0668329
time/training (s)                        0.000133914
time/epoch (s)                          65.2254
time/total (s)                       10920.8
Epoch                                  230
----------------------------------  ----------------
2020-11-09 16:29:26.163451 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 231 finished
----------------------------------  ----------------
replay_buffer/size                  466000
trainer/num train calls             232000
trainer/QF1 Loss                        12.8542
trainer/QF2 Loss                        12.7593
trainer/Policy Loss                    559.581
trainer/Q1 Predictions Mean           -559.709
trainer/Q1 Predictions Std              46.1202
trainer/Q1 Predictions Max            -394.324
trainer/Q1 Predictions Min            -624.471
trainer/Q2 Predictions Mean           -559.722
trainer/Q2 Predictions Std              46.1264
trainer/Q2 Predictions Max            -394.132
trainer/Q2 Predictions Min            -624.414
trainer/Q Targets Mean                -562.393
trainer/Q Targets Std                   46.4999
trainer/Q Targets Max                 -392.77
trainer/Q Targets Min                 -624.69
trainer/Log Pis Mean                     1.26011
trainer/Log Pis Std                      2.25845
trainer/Log Pis Max                      8.86851
trainer/Log Pis Min                     -5.49777
trainer/policy/mean Mean                 0.0623394
trainer/policy/mean Std                  0.780046
trainer/policy/mean Max                  0.999391
trainer/policy/mean Min                 -0.920352
trainer/policy/normal/std Mean           0.610364
trainer/policy/normal/std Std            0.115661
trainer/policy/normal/std Max            1.05199
trainer/policy/normal/std Min            0.385553
trainer/policy/normal/log_std Mean      -0.510287
trainer/policy/normal/log_std Std        0.179161
trainer/policy/normal/log_std Max        0.0506836
trainer/policy/normal/log_std Min       -0.953077
trainer/Alpha                            0.0273811
trainer/Alpha Loss                      -2.66207
exploration/num steps total         466000
exploration/num paths total           2330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.98669
exploration/Rewards Std                  0.107226
exploration/Rewards Max                 -5.16144
exploration/Rewards Min                 -6.14193
exploration/Returns Mean             -1197.34
exploration/Returns Std                 18.5386
exploration/Returns Max              -1145.73
exploration/Returns Min              -1212.39
exploration/Actions Mean                 0.0790316
exploration/Actions Std                  0.70196
exploration/Actions Max                  0.999252
exploration/Actions Min                 -0.996368
exploration/Num Paths                   10
exploration/Average Returns          -1197.34
evaluation/num steps total               1.11917e+06
evaluation/num paths total            5568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96432
evaluation/Rewards Std                   0.529879
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1198.83
evaluation/Returns Std                 104.149
evaluation/Returns Max                -702.221
evaluation/Returns Min               -1231.12
evaluation/Actions Mean                  0.0281337
evaluation/Actions Std                   0.634089
evaluation/Actions Max                   0.984955
evaluation/Actions Min                  -0.891107
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.83
time/data storing (s)                    0.0320585
time/evaluation sampling (s)            25.0852
time/exploration sampling (s)           13.0414
time/logging (s)                         0.104903
time/sac training (s)                   51.7322
time/saving (s)                          0.126901
time/training (s)                        0.000229943
time/epoch (s)                          90.1229
time/total (s)                       11247.9
Epoch                                  231
----------------------------------  ----------------
2020-11-09 16:34:56.634478 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 232 finished
----------------------------------  ----------------
replay_buffer/size                  468000
trainer/num train calls             233000
trainer/QF1 Loss                      2544.92
trainer/QF2 Loss                      2544.49
trainer/Policy Loss                    563.426
trainer/Q1 Predictions Mean           -563.777
trainer/Q1 Predictions Std              41.7995
trainer/Q1 Predictions Max            -375.543
trainer/Q1 Predictions Min            -637.319
trainer/Q2 Predictions Mean           -563.769
trainer/Q2 Predictions Std              41.7883
trainer/Q2 Predictions Max            -375.579
trainer/Q2 Predictions Min            -637.733
trainer/Q Targets Mean                -561.162
trainer/Q Targets Std                   65.1883
trainer/Q Targets Max                   -5.23724
trainer/Q Targets Min                 -639.276
trainer/Log Pis Mean                     1.72449
trainer/Log Pis Std                      1.8878
trainer/Log Pis Max                      6.17111
trainer/Log Pis Min                     -5.64044
trainer/policy/mean Mean                 0.0872652
trainer/policy/mean Std                  0.833
trainer/policy/mean Max                  0.996195
trainer/policy/mean Min                 -0.968657
trainer/policy/normal/std Mean           0.517328
trainer/policy/normal/std Std            0.0590419
trainer/policy/normal/std Max            0.714056
trainer/policy/normal/std Min            0.380203
trainer/policy/normal/log_std Mean      -0.665739
trainer/policy/normal/log_std Std        0.11624
trainer/policy/normal/log_std Max       -0.336794
trainer/policy/normal/log_std Min       -0.967051
trainer/Alpha                            0.0269391
trainer/Alpha Loss                      -0.995744
exploration/num steps total         468000
exploration/num paths total           2340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.90999
exploration/Rewards Std                  0.618724
exploration/Rewards Max                 -3.32689
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1182
exploration/Returns Std                 81.3436
exploration/Returns Max               -990.68
exploration/Returns Min              -1231.01
exploration/Actions Mean                -0.00468701
exploration/Actions Std                  0.808229
exploration/Actions Max                  0.996574
exploration/Actions Min                 -0.996809
exploration/Num Paths                   10
exploration/Average Returns          -1182
evaluation/num steps total               1.12399e+06
evaluation/num paths total            5592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.11015
evaluation/Rewards Std                   0.043067
evaluation/Rewards Max                  -5.95284
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1228.14
evaluation/Returns Std                   7.21122
evaluation/Returns Max               -1199.44
evaluation/Returns Min               -1233.9
evaluation/Actions Mean                 -0.0046878
evaluation/Actions Std                   0.703368
evaluation/Actions Max                   0.933282
evaluation/Actions Min                  -0.908011
evaluation/Num Paths                    24
evaluation/Average Returns           -1228.14
time/data storing (s)                    0.0405606
time/evaluation sampling (s)            29.7578
time/exploration sampling (s)           11.6122
time/logging (s)                         0.0955281
time/sac training (s)                   37.0512
time/saving (s)                          0.151
time/training (s)                        0.000251588
time/epoch (s)                          78.7086
time/total (s)                       11578.3
Epoch                                  232
----------------------------------  ----------------
2020-11-09 16:39:38.747390 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 233 finished
----------------------------------  ----------------
replay_buffer/size                  470000
trainer/num train calls             234000
trainer/QF1 Loss                        15.244
trainer/QF2 Loss                        14.8803
trainer/Policy Loss                    563.634
trainer/Q1 Predictions Mean           -563.73
trainer/Q1 Predictions Std              42.5339
trainer/Q1 Predictions Max            -392.267
trainer/Q1 Predictions Min            -639.038
trainer/Q2 Predictions Mean           -563.787
trainer/Q2 Predictions Std              42.5598
trainer/Q2 Predictions Max            -393.083
trainer/Q2 Predictions Min            -637.98
trainer/Q Targets Mean                -566.152
trainer/Q Targets Std                   43.2913
trainer/Q Targets Max                 -393.798
trainer/Q Targets Min                 -640.26
trainer/Log Pis Mean                     1.89597
trainer/Log Pis Std                      2.14481
trainer/Log Pis Max                      7.82548
trainer/Log Pis Min                     -4.5852
trainer/policy/mean Mean                 0.030485
trainer/policy/mean Std                  0.838274
trainer/policy/mean Max                  0.999412
trainer/policy/mean Min                 -0.964705
trainer/policy/normal/std Mean           0.599623
trainer/policy/normal/std Std            0.0693135
trainer/policy/normal/std Max            0.892796
trainer/policy/normal/std Min            0.421035
trainer/policy/normal/log_std Mean      -0.518123
trainer/policy/normal/log_std Std        0.115699
trainer/policy/normal/log_std Max       -0.113397
trainer/policy/normal/log_std Min       -0.865038
trainer/Alpha                            0.0272687
trainer/Alpha Loss                      -0.374728
exploration/num steps total         470000
exploration/num paths total           2350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.85277
exploration/Rewards Std                  0.648824
exploration/Rewards Max                 -3.33769
exploration/Rewards Min                 -6.14157
exploration/Returns Mean             -1170.55
exploration/Returns Std                100.445
exploration/Returns Max               -880.982
exploration/Returns Min              -1221.87
exploration/Actions Mean                 0.036193
exploration/Actions Std                  0.794953
exploration/Actions Max                  0.999563
exploration/Actions Min                 -0.997751
exploration/Num Paths                   10
exploration/Average Returns          -1170.55
evaluation/num steps total               1.12882e+06
evaluation/num paths total            5616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9733
evaluation/Rewards Std                   0.51191
evaluation/Rewards Max                  -3.39682
evaluation/Rewards Min                  -6.14193
evaluation/Returns Mean              -1200.63
evaluation/Returns Std                  97.4595
evaluation/Returns Max                -734.073
evaluation/Returns Min               -1231.69
evaluation/Actions Mean                  0.0188528
evaluation/Actions Std                   0.708992
evaluation/Actions Max                   0.986582
evaluation/Actions Min                  -0.90385
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.63
time/data storing (s)                    0.0453278
time/evaluation sampling (s)            21.7491
time/exploration sampling (s)            8.00677
time/logging (s)                         0.0745025
time/sac training (s)                   34.4354
time/saving (s)                          0.100523
time/training (s)                        0.000259964
time/epoch (s)                          64.4119
time/total (s)                       11860.3
Epoch                                  233
----------------------------------  ----------------
2020-11-09 16:44:27.399291 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 234 finished
----------------------------------  ----------------
replay_buffer/size                  472000
trainer/num train calls             235000
trainer/QF1 Loss                      1439.76
trainer/QF2 Loss                      1439.31
trainer/Policy Loss                    564.41
trainer/Q1 Predictions Mean           -564.56
trainer/Q1 Predictions Std              42.5053
trainer/Q1 Predictions Max            -367.995
trainer/Q1 Predictions Min            -658.716
trainer/Q2 Predictions Mean           -564.557
trainer/Q2 Predictions Std              42.5311
trainer/Q2 Predictions Max            -367.869
trainer/Q2 Predictions Min            -659.833
trainer/Q Targets Mean                -564.925
trainer/Q Targets Std                   55.3048
trainer/Q Targets Max                   -5.0117
trainer/Q Targets Min                 -660.166
trainer/Log Pis Mean                     2.37579
trainer/Log Pis Std                      2.3114
trainer/Log Pis Max                      7.60792
trainer/Log Pis Min                     -3.39685
trainer/policy/mean Mean                 0.0231052
trainer/policy/mean Std                  0.859687
trainer/policy/mean Max                  0.999797
trainer/policy/mean Min                 -0.976814
trainer/policy/normal/std Mean           0.532979
trainer/policy/normal/std Std            0.0600989
trainer/policy/normal/std Max            0.854863
trainer/policy/normal/std Min            0.380322
trainer/policy/normal/log_std Mean      -0.635322
trainer/policy/normal/log_std Std        0.108996
trainer/policy/normal/log_std Max       -0.156814
trainer/policy/normal/log_std Min       -0.966738
trainer/Alpha                            0.0272679
trainer/Alpha Loss                       1.3536
exploration/num steps total         472000
exploration/num paths total           2360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.01779
exploration/Rewards Std                  0.0843247
exploration/Rewards Max                 -5.6376
exploration/Rewards Min                 -6.14199
exploration/Returns Mean             -1203.56
exploration/Returns Std                 18.6958
exploration/Returns Max              -1163.16
exploration/Returns Min              -1225.57
exploration/Actions Mean                 0.0104886
exploration/Actions Std                  0.790864
exploration/Actions Max                  0.999547
exploration/Actions Min                 -0.997968
exploration/Num Paths                   10
exploration/Average Returns          -1203.56
evaluation/num steps total               1.13364e+06
evaluation/num paths total            5640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.06309
evaluation/Rewards Std                   0.0820315
evaluation/Rewards Max                  -3.6332
evaluation/Rewards Min                  -6.14201
evaluation/Returns Mean              -1218.68
evaluation/Returns Std                   7.61465
evaluation/Returns Max               -1195.45
evaluation/Returns Min               -1230.16
evaluation/Actions Mean                  0.0302775
evaluation/Actions Std                   0.761371
evaluation/Actions Max                   0.985848
evaluation/Actions Min                  -0.941324
evaluation/Num Paths                    24
evaluation/Average Returns           -1218.68
time/data storing (s)                    0.0331577
time/evaluation sampling (s)            20.1465
time/exploration sampling (s)            7.86915
time/logging (s)                         0.113116
time/sac training (s)                   34.3596
time/saving (s)                          0.0855427
time/training (s)                        0.00016304
time/epoch (s)                          62.6072
time/total (s)                       12149
Epoch                                  234
----------------------------------  ----------------
2020-11-09 16:48:50.934231 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 235 finished
----------------------------------  ----------------
replay_buffer/size                  474000
trainer/num train calls             236000
trainer/QF1 Loss                      1292.54
trainer/QF2 Loss                      1293.53
trainer/Policy Loss                    564.323
trainer/Q1 Predictions Mean           -564.479
trainer/Q1 Predictions Std              40.6417
trainer/Q1 Predictions Max            -372.767
trainer/Q1 Predictions Min            -628.122
trainer/Q2 Predictions Mean           -564.501
trainer/Q2 Predictions Std              40.6279
trainer/Q2 Predictions Max            -372.794
trainer/Q2 Predictions Min            -628.577
trainer/Q Targets Mean                -564.635
trainer/Q Targets Std                   53.9019
trainer/Q Targets Max                   -5.68097
trainer/Q Targets Min                 -629.337
trainer/Log Pis Mean                     2.70351
trainer/Log Pis Std                      2.69609
trainer/Log Pis Max                     12.7806
trainer/Log Pis Min                     -3.28682
trainer/policy/mean Mean                -0.45786
trainer/policy/mean Std                  0.71555
trainer/policy/mean Max                  0.999108
trainer/policy/mean Min                 -0.999406
trainer/policy/normal/std Mean           0.639404
trainer/policy/normal/std Std            0.155819
trainer/policy/normal/std Max            0.830149
trainer/policy/normal/std Min            0.448829
trainer/policy/normal/log_std Mean      -0.478101
trainer/policy/normal/log_std Std        0.250508
trainer/policy/normal/log_std Max       -0.18615
trainer/policy/normal/log_std Min       -0.801112
trainer/Alpha                            0.0284165
trainer/Alpha Loss                       2.50506
exploration/num steps total         474000
exploration/num paths total           2370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.13281
exploration/Rewards Std                  0.609259
exploration/Rewards Max                 -3.32296
exploration/Rewards Min                 -6.14163
exploration/Returns Mean             -1026.56
exploration/Returns Std                 69.1348
exploration/Returns Max               -924.553
exploration/Returns Min              -1133.38
exploration/Actions Mean                -0.355909
exploration/Actions Std                  0.796418
exploration/Actions Max                  0.999343
exploration/Actions Min                 -0.999959
exploration/Num Paths                   10
exploration/Average Returns          -1026.56
evaluation/num steps total               1.13846e+06
evaluation/num paths total            5664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60824
evaluation/Rewards Std                   0.579556
evaluation/Rewards Max                  -3.26913
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1127.26
evaluation/Returns Std                  99.4621
evaluation/Returns Max                -738.036
evaluation/Returns Min               -1200.63
evaluation/Actions Mean                 -0.373862
evaluation/Actions Std                   0.80741
evaluation/Actions Max                   0.987049
evaluation/Actions Min                  -0.995051
evaluation/Num Paths                    24
evaluation/Average Returns           -1127.26
time/data storing (s)                    0.0343927
time/evaluation sampling (s)            21.2639
time/exploration sampling (s)            8.22494
time/logging (s)                         0.0674285
time/sac training (s)                   36.033
time/saving (s)                          0.0934904
time/training (s)                        0.000174618
time/epoch (s)                          65.7173
time/total (s)                       12412.4
Epoch                                  235
----------------------------------  ----------------
2020-11-09 16:53:14.876979 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 236 finished
----------------------------------  ----------------
replay_buffer/size                  476000
trainer/num train calls             237000
trainer/QF1 Loss                      2575.93
trainer/QF2 Loss                      2572.66
trainer/Policy Loss                    564.927
trainer/Q1 Predictions Mean           -564.995
trainer/Q1 Predictions Std              39.4193
trainer/Q1 Predictions Max            -398.026
trainer/Q1 Predictions Min            -644.108
trainer/Q2 Predictions Mean           -565.008
trainer/Q2 Predictions Std              39.4103
trainer/Q2 Predictions Max            -398.092
trainer/Q2 Predictions Min            -642.669
trainer/Q Targets Mean                -563.114
trainer/Q Targets Std                   63.7719
trainer/Q Targets Max                   -4.94511
trainer/Q Targets Min                 -644.597
trainer/Log Pis Mean                     1.60158
trainer/Log Pis Std                      3.14506
trainer/Log Pis Max                     12.739
trainer/Log Pis Min                     -3.76329
trainer/policy/mean Mean                -0.134473
trainer/policy/mean Std                  0.761847
trainer/policy/mean Max                  0.999919
trainer/policy/mean Min                 -0.991404
trainer/policy/normal/std Mean           0.728233
trainer/policy/normal/std Std            0.0653324
trainer/policy/normal/std Max            1.05044
trainer/policy/normal/std Min            0.547908
trainer/policy/normal/log_std Mean      -0.321034
trainer/policy/normal/log_std Std        0.0878039
trainer/policy/normal/log_std Max        0.0492061
trainer/policy/normal/log_std Min       -0.601648
trainer/Alpha                            0.0289227
trainer/Alpha Loss                      -1.41165
exploration/num steps total         476000
exploration/num paths total           2380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.33302
exploration/Rewards Std                  0.947926
exploration/Rewards Max                 -3.35377
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1066.6
exploration/Returns Std                176.163
exploration/Returns Max               -715.626
exploration/Returns Min              -1185.88
exploration/Actions Mean                -0.100775
exploration/Actions Std                  0.782127
exploration/Actions Max                  0.999792
exploration/Actions Min                 -0.999791
exploration/Num Paths                   10
exploration/Average Returns          -1066.6
evaluation/num steps total               1.14329e+06
evaluation/num paths total            5688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9201
evaluation/Rewards Std                   0.520787
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1189.94
evaluation/Returns Std                 102.786
evaluation/Returns Max                -701.981
evaluation/Returns Min               -1220.92
evaluation/Actions Mean                 -0.023223
evaluation/Actions Std                   0.863711
evaluation/Actions Max                   0.991136
evaluation/Actions Min                  -0.942782
evaluation/Num Paths                    24
evaluation/Average Returns           -1189.94
time/data storing (s)                    0.038043
time/evaluation sampling (s)            18.2326
time/exploration sampling (s)            7.29299
time/logging (s)                         0.0741247
time/sac training (s)                   35.1435
time/saving (s)                          0.116516
time/training (s)                        0.000168725
time/epoch (s)                          60.8979
time/total (s)                       12676.3
Epoch                                  236
----------------------------------  ----------------
2020-11-09 16:57:35.978218 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 237 finished
----------------------------------  ----------------
replay_buffer/size                  478000
trainer/num train calls             238000
trainer/QF1 Loss                      1200.46
trainer/QF2 Loss                      1201.36
trainer/Policy Loss                    565.34
trainer/Q1 Predictions Mean           -565.597
trainer/Q1 Predictions Std              37.5514
trainer/Q1 Predictions Max            -388.16
trainer/Q1 Predictions Min            -662.3
trainer/Q2 Predictions Mean           -565.627
trainer/Q2 Predictions Std              37.5626
trainer/Q2 Predictions Max            -388.134
trainer/Q2 Predictions Min            -662.982
trainer/Q Targets Mean                -565.987
trainer/Q Targets Std                   51.6485
trainer/Q Targets Max                   -5.66728
trainer/Q Targets Min                 -662.791
trainer/Log Pis Mean                     1.88874
trainer/Log Pis Std                      2.19107
trainer/Log Pis Max                      9.01991
trainer/Log Pis Min                     -4.22422
trainer/policy/mean Mean                -0.0833197
trainer/policy/mean Std                  0.831428
trainer/policy/mean Max                  0.998441
trainer/policy/mean Min                 -0.979787
trainer/policy/normal/std Mean           0.544091
trainer/policy/normal/std Std            0.0569898
trainer/policy/normal/std Max            0.723528
trainer/policy/normal/std Min            0.430036
trainer/policy/normal/log_std Mean      -0.614119
trainer/policy/normal/log_std Std        0.104684
trainer/policy/normal/log_std Max       -0.323616
trainer/policy/normal/log_std Min       -0.843886
trainer/Alpha                            0.0284796
trainer/Alpha Loss                      -0.395933
exploration/num steps total         478000
exploration/num paths total           2390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.914
exploration/Rewards Std                  0.131992
exploration/Rewards Max                 -5.62443
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1182.8
exploration/Returns Std                 24.7878
exploration/Returns Max              -1124
exploration/Returns Min              -1216.76
exploration/Actions Mean                -0.107807
exploration/Actions Std                  0.798663
exploration/Actions Max                  0.997911
exploration/Actions Min                 -0.997847
exploration/Num Paths                   10
exploration/Average Returns          -1182.8
evaluation/num steps total               1.14811e+06
evaluation/num paths total            5712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04548
evaluation/Rewards Std                   0.0524009
evaluation/Rewards Max                  -5.77185
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1215.14
evaluation/Returns Std                   8.06574
evaluation/Returns Max               -1186.4
evaluation/Returns Min               -1225.4
evaluation/Actions Mean                 -0.0765018
evaluation/Actions Std                   0.822028
evaluation/Actions Max                   0.973426
evaluation/Actions Min                  -0.954065
evaluation/Num Paths                    24
evaluation/Average Returns           -1215.14
time/data storing (s)                    0.0327605
time/evaluation sampling (s)            19.6422
time/exploration sampling (s)            7.52632
time/logging (s)                         0.0926433
time/sac training (s)                   34.6325
time/saving (s)                          0.116485
time/training (s)                        0.000150843
time/epoch (s)                          62.043
time/total (s)                       12937.4
Epoch                                  237
----------------------------------  ----------------
2020-11-09 17:02:02.798727 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 238 finished
----------------------------------  ----------------
replay_buffer/size                  480000
trainer/num train calls             239000
trainer/QF1 Loss                      1077.66
trainer/QF2 Loss                      1078.86
trainer/Policy Loss                    566.632
trainer/Q1 Predictions Mean           -566.78
trainer/Q1 Predictions Std              36.0934
trainer/Q1 Predictions Max            -384.735
trainer/Q1 Predictions Min            -646.575
trainer/Q2 Predictions Mean           -566.812
trainer/Q2 Predictions Std              36.1039
trainer/Q2 Predictions Max            -384.741
trainer/Q2 Predictions Min            -647.453
trainer/Q Targets Mean                -567.551
trainer/Q Targets Std                   50.6323
trainer/Q Targets Max                   -4.78894
trainer/Q Targets Min                 -648.215
trainer/Log Pis Mean                     2.06513
trainer/Log Pis Std                      2.2921
trainer/Log Pis Max                      8.37017
trainer/Log Pis Min                     -8.05159
trainer/policy/mean Mean                -0.208214
trainer/policy/mean Std                  0.79598
trainer/policy/mean Max                  0.995416
trainer/policy/mean Min                 -0.993378
trainer/policy/normal/std Mean           0.633385
trainer/policy/normal/std Std            0.112732
trainer/policy/normal/std Max            0.807239
trainer/policy/normal/std Min            0.468542
trainer/policy/normal/log_std Mean      -0.472641
trainer/policy/normal/log_std Std        0.178962
trainer/policy/normal/log_std Max       -0.214135
trainer/policy/normal/log_std Min       -0.75813
trainer/Alpha                            0.0289112
trainer/Alpha Loss                       0.230799
exploration/num steps total         480000
exploration/num paths total           2400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.11001
exploration/Rewards Std                  0.939948
exploration/Rewards Max                 -2.76438
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1022
exploration/Returns Std                111.243
exploration/Returns Max               -832.925
exploration/Returns Min              -1158.7
exploration/Actions Mean                -0.165409
exploration/Actions Std                  0.84308
exploration/Actions Max                  0.999322
exploration/Actions Min                 -0.999707
exploration/Num Paths                   10
exploration/Average Returns          -1022
evaluation/num steps total               1.15294e+06
evaluation/num paths total            5736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78954
evaluation/Rewards Std                   0.531878
evaluation/Rewards Max                  -3.29961
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1163.7
evaluation/Returns Std                 102.487
evaluation/Returns Max                -686.554
evaluation/Returns Min               -1213.24
evaluation/Actions Mean                 -0.152454
evaluation/Actions Std                   0.835504
evaluation/Actions Max                   0.973242
evaluation/Actions Min                  -0.978874
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.7
time/data storing (s)                    0.0332731
time/evaluation sampling (s)            22.0691
time/exploration sampling (s)            8.49974
time/logging (s)                         0.0821629
time/sac training (s)                   30.5027
time/saving (s)                          0.0990795
time/training (s)                        0.000135277
time/epoch (s)                          61.2862
time/total (s)                       13204.1
Epoch                                  238
----------------------------------  ----------------
2020-11-09 17:08:26.031925 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 239 finished
----------------------------------  ----------------
replay_buffer/size                  482000
trainer/num train calls             240000
trainer/QF1 Loss                      1374.72
trainer/QF2 Loss                      1373.47
trainer/Policy Loss                    563.122
trainer/Q1 Predictions Mean           -563.284
trainer/Q1 Predictions Std              40.3729
trainer/Q1 Predictions Max            -373.292
trainer/Q1 Predictions Min            -608.633
trainer/Q2 Predictions Mean           -563.258
trainer/Q2 Predictions Std              40.3767
trainer/Q2 Predictions Max            -373.366
trainer/Q2 Predictions Min            -608.69
trainer/Q Targets Mean                -563.464
trainer/Q Targets Std                   53.4815
trainer/Q Targets Max                   -5.20287
trainer/Q Targets Min                 -611.017
trainer/Log Pis Mean                     1.59866
trainer/Log Pis Std                      2.22036
trainer/Log Pis Max                      9.6511
trainer/Log Pis Min                     -6.23005
trainer/policy/mean Mean                 0.0467242
trainer/policy/mean Std                  0.834871
trainer/policy/mean Max                  0.99966
trainer/policy/mean Min                 -0.953586
trainer/policy/normal/std Mean           0.626137
trainer/policy/normal/std Std            0.0556476
trainer/policy/normal/std Max            0.85995
trainer/policy/normal/std Min            0.487998
trainer/policy/normal/log_std Mean      -0.472017
trainer/policy/normal/log_std Std        0.0869786
trainer/policy/normal/log_std Max       -0.150881
trainer/policy/normal/log_std Min       -0.717443
trainer/Alpha                            0.0293938
trainer/Alpha Loss                      -1.41552
exploration/num steps total         482000
exploration/num paths total           2410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.92948
exploration/Rewards Std                  0.222233
exploration/Rewards Max                 -4.64709
exploration/Rewards Min                 -6.14105
exploration/Returns Mean             -1185.9
exploration/Returns Std                 32.0953
exploration/Returns Max              -1110.38
exploration/Returns Min              -1223.48
exploration/Actions Mean                 0.0179346
exploration/Actions Std                  0.775796
exploration/Actions Max                  0.999447
exploration/Actions Min                 -0.997851
exploration/Num Paths                   10
exploration/Average Returns          -1185.9
evaluation/num steps total               1.15776e+06
evaluation/num paths total            5760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07295
evaluation/Rewards Std                   0.0450353
evaluation/Rewards Max                  -5.27085
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1220.66
evaluation/Returns Std                   6.97502
evaluation/Returns Max               -1196.61
evaluation/Returns Min               -1229.94
evaluation/Actions Mean                  0.023754
evaluation/Actions Std                   0.716384
evaluation/Actions Max                   0.983508
evaluation/Actions Min                  -0.862152
evaluation/Num Paths                    24
evaluation/Average Returns           -1220.66
time/data storing (s)                    0.0278992
time/evaluation sampling (s)            16.0362
time/exploration sampling (s)            6.50026
time/logging (s)                         0.0812065
time/sac training (s)                   27.3578
time/saving (s)                          0.388368
time/training (s)                        0.000150774
time/epoch (s)                          50.3919
time/total (s)                       13587.3
Epoch                                  239
----------------------------------  ----------------
2020-11-09 17:14:21.292423 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 240 finished
----------------------------------  ----------------
replay_buffer/size                  484000
trainer/num train calls             241000
trainer/QF1 Loss                        13.7877
trainer/QF2 Loss                        13.8513
trainer/Policy Loss                    557.566
trainer/Q1 Predictions Mean           -557.833
trainer/Q1 Predictions Std              48.5126
trainer/Q1 Predictions Max            -326.885
trainer/Q1 Predictions Min            -661.492
trainer/Q2 Predictions Mean           -557.849
trainer/Q2 Predictions Std              48.5011
trainer/Q2 Predictions Max            -326.788
trainer/Q2 Predictions Min            -662.595
trainer/Q Targets Mean                -560.272
trainer/Q Targets Std                   49.0408
trainer/Q Targets Max                 -327.667
trainer/Q Targets Min                 -662.589
trainer/Log Pis Mean                     1.7177
trainer/Log Pis Std                      1.52646
trainer/Log Pis Max                      5.4159
trainer/Log Pis Min                     -3.67584
trainer/policy/mean Mean                 0.318803
trainer/policy/mean Std                  0.750098
trainer/policy/mean Max                  0.989264
trainer/policy/mean Min                 -0.920375
trainer/policy/normal/std Mean           0.578096
trainer/policy/normal/std Std            0.0906444
trainer/policy/normal/std Max            0.929031
trainer/policy/normal/std Min            0.432218
trainer/policy/normal/log_std Mean      -0.559144
trainer/policy/normal/log_std Std        0.145676
trainer/policy/normal/log_std Max       -0.0736133
trainer/policy/normal/log_std Min       -0.838824
trainer/Alpha                            0.0290085
trainer/Alpha Loss                      -0.999386
exploration/num steps total         484000
exploration/num paths total           2420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.07344
exploration/Rewards Std                  0.0563014
exploration/Rewards Max                 -5.57276
exploration/Rewards Min                 -6.14202
exploration/Returns Mean             -1214.69
exploration/Returns Std                 19.6256
exploration/Returns Max              -1161.51
exploration/Returns Min              -1230.14
exploration/Actions Mean                 0.189541
exploration/Actions Std                  0.804769
exploration/Actions Max                  0.999016
exploration/Actions Min                 -0.996311
exploration/Num Paths                   10
exploration/Average Returns          -1214.69
evaluation/num steps total               1.16258e+06
evaluation/num paths total            5784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.93313
evaluation/Rewards Std                   0.597551
evaluation/Rewards Max                  -2.61606
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1192.56
evaluation/Returns Std                 109.496
evaluation/Returns Max                -746.911
evaluation/Returns Min               -1233.42
evaluation/Actions Mean                  0.210722
evaluation/Actions Std                   0.780485
evaluation/Actions Max                   0.964099
evaluation/Actions Min                  -0.782999
evaluation/Num Paths                    24
evaluation/Average Returns           -1192.56
time/data storing (s)                    0.0306906
time/evaluation sampling (s)            20.2536
time/exploration sampling (s)            9.71269
time/logging (s)                         0.100304
time/sac training (s)                   21.7764
time/saving (s)                          0.129498
time/training (s)                        0.000194609
time/epoch (s)                          52.0034
time/total (s)                       13942.6
Epoch                                  240
----------------------------------  ----------------
2020-11-09 17:20:58.688236 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 241 finished
----------------------------------  ----------------
replay_buffer/size                  486000
trainer/num train calls             242000
trainer/QF1 Loss                      3766.51
trainer/QF2 Loss                      3768.97
trainer/Policy Loss                    564.229
trainer/Q1 Predictions Mean           -564.508
trainer/Q1 Predictions Std              39.1823
trainer/Q1 Predictions Max            -386.831
trainer/Q1 Predictions Min            -630.983
trainer/Q2 Predictions Mean           -564.517
trainer/Q2 Predictions Std              39.1793
trainer/Q2 Predictions Max            -386.948
trainer/Q2 Predictions Min            -631.815
trainer/Q Targets Mean                -560.367
trainer/Q Targets Std                   72.2167
trainer/Q Targets Max                   -4.58555
trainer/Q Targets Min                 -631.887
trainer/Log Pis Mean                     2.10634
trainer/Log Pis Std                      1.9731
trainer/Log Pis Max                      6.18417
trainer/Log Pis Min                     -3.90836
trainer/policy/mean Mean                 0.0411871
trainer/policy/mean Std                  0.859815
trainer/policy/mean Max                  0.993791
trainer/policy/mean Min                 -0.978919
trainer/policy/normal/std Mean           0.520519
trainer/policy/normal/std Std            0.0425671
trainer/policy/normal/std Max            0.761126
trainer/policy/normal/std Min            0.434983
trainer/policy/normal/log_std Mean      -0.656115
trainer/policy/normal/log_std Std        0.0789751
trainer/policy/normal/log_std Max       -0.272957
trainer/policy/normal/log_std Min       -0.832448
trainer/Alpha                            0.0291004
trainer/Alpha Loss                       0.376129
exploration/num steps total         486000
exploration/num paths total           2430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.73185
exploration/Rewards Std                  0.783123
exploration/Rewards Max                 -3.33522
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1146.37
exploration/Returns Std                131.375
exploration/Returns Max               -839.61
exploration/Returns Min              -1230.87
exploration/Actions Mean                 0.0101104
exploration/Actions Std                  0.828612
exploration/Actions Max                  0.998431
exploration/Actions Min                 -0.998031
exploration/Num Paths                   10
exploration/Average Returns          -1146.37
evaluation/num steps total               1.16741e+06
evaluation/num paths total            5808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07996
evaluation/Rewards Std                   0.104237
evaluation/Rewards Max                  -3.63529
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1222.07
evaluation/Returns Std                  12.4953
evaluation/Returns Max               -1180.56
evaluation/Returns Min               -1232.77
evaluation/Actions Mean                 -0.014635
evaluation/Actions Std                   0.744667
evaluation/Actions Max                   0.971799
evaluation/Actions Min                  -0.93226
evaluation/Num Paths                    24
evaluation/Average Returns           -1222.07
time/data storing (s)                    0.0282767
time/evaluation sampling (s)            17.0706
time/exploration sampling (s)            8.19077
time/logging (s)                         0.364141
time/sac training (s)                   25.3241
time/saving (s)                          0.152212
time/training (s)                        0.00015633
time/epoch (s)                          51.1303
time/total (s)                       14340.2
Epoch                                  241
----------------------------------  ----------------
2020-11-09 17:27:53.686815 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 242 finished
----------------------------------  ----------------
replay_buffer/size                  488000
trainer/num train calls             243000
trainer/QF1 Loss                      1293.63
trainer/QF2 Loss                      1296.2
trainer/Policy Loss                    561.147
trainer/Q1 Predictions Mean           -561.219
trainer/Q1 Predictions Std              40.277
trainer/Q1 Predictions Max            -381.849
trainer/Q1 Predictions Min            -646.692
trainer/Q2 Predictions Mean           -561.229
trainer/Q2 Predictions Std              40.3445
trainer/Q2 Predictions Max            -381.892
trainer/Q2 Predictions Min            -648.218
trainer/Q Targets Mean                -561.948
trainer/Q Targets Std                   53.5652
trainer/Q Targets Max                   -5.78861
trainer/Q Targets Min                 -648.748
trainer/Log Pis Mean                     1.93127
trainer/Log Pis Std                      2.17805
trainer/Log Pis Max                      8.30297
trainer/Log Pis Min                     -3.80505
trainer/policy/mean Mean                 0.0166343
trainer/policy/mean Std                  0.865497
trainer/policy/mean Max                  0.999584
trainer/policy/mean Min                 -0.978521
trainer/policy/normal/std Mean           0.621816
trainer/policy/normal/std Std            0.0442119
trainer/policy/normal/std Max            0.804902
trainer/policy/normal/std Min            0.500784
trainer/policy/normal/log_std Mean      -0.477605
trainer/policy/normal/log_std Std        0.070479
trainer/policy/normal/log_std Max       -0.217035
trainer/policy/normal/log_std Min       -0.69158
trainer/Alpha                            0.0297004
trainer/Alpha Loss                      -0.241685
exploration/num steps total         488000
exploration/num paths total           2440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.99974
exploration/Rewards Std                  0.12789
exploration/Rewards Max                 -5.58842
exploration/Rewards Min                 -6.14186
exploration/Returns Mean             -1199.95
exploration/Returns Std                 24.7488
exploration/Returns Max              -1151.27
exploration/Returns Min              -1223.67
exploration/Actions Mean                -0.00366822
exploration/Actions Std                  0.815947
exploration/Actions Max                  0.999857
exploration/Actions Min                 -0.998895
exploration/Num Paths                   10
exploration/Average Returns          -1199.95
evaluation/num steps total               1.17223e+06
evaluation/num paths total            5832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.87047
evaluation/Rewards Std                   0.723426
evaluation/Rewards Max                  -3.38725
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1179.96
evaluation/Returns Std                 142.082
evaluation/Returns Max                -705.33
evaluation/Returns Min               -1230.93
evaluation/Actions Mean                 -0.0246071
evaluation/Actions Std                   0.793843
evaluation/Actions Max                   0.981323
evaluation/Actions Min                  -0.910088
evaluation/Num Paths                    24
evaluation/Average Returns           -1179.96
time/data storing (s)                    0.0385245
time/evaluation sampling (s)            19.4055
time/exploration sampling (s)            8.71154
time/logging (s)                         0.115899
time/sac training (s)                   25.1863
time/saving (s)                          0.232122
time/training (s)                        0.000626651
time/epoch (s)                          53.6906
time/total (s)                       14754.9
Epoch                                  242
----------------------------------  ----------------
2020-11-09 17:36:03.672475 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 243 finished
----------------------------------  ----------------
replay_buffer/size                  490000
trainer/num train calls             244000
trainer/QF1 Loss                      2632.8
trainer/QF2 Loss                      2630.16
trainer/Policy Loss                    560.927
trainer/Q1 Predictions Mean           -560.971
trainer/Q1 Predictions Std              46.1398
trainer/Q1 Predictions Max            -392.128
trainer/Q1 Predictions Min            -643.34
trainer/Q2 Predictions Mean           -561.001
trainer/Q2 Predictions Std              46.1437
trainer/Q2 Predictions Max            -392.142
trainer/Q2 Predictions Min            -644.07
trainer/Q Targets Mean                -559.037
trainer/Q Targets Std                   67.8891
trainer/Q Targets Max                   -5.86671
trainer/Q Targets Min                 -645.057
trainer/Log Pis Mean                     2.26617
trainer/Log Pis Std                      2.53889
trainer/Log Pis Max                      8.79203
trainer/Log Pis Min                     -4.44783
trainer/policy/mean Mean                -0.0641191
trainer/policy/mean Std                  0.843876
trainer/policy/mean Max                  0.99763
trainer/policy/mean Min                 -0.980899
trainer/policy/normal/std Mean           0.62384
trainer/policy/normal/std Std            0.0661984
trainer/policy/normal/std Max            0.784973
trainer/policy/normal/std Min            0.534601
trainer/policy/normal/log_std Mean      -0.47735
trainer/policy/normal/log_std Std        0.104122
trainer/policy/normal/log_std Max       -0.242106
trainer/policy/normal/log_std Min       -0.626235
trainer/Alpha                            0.0297584
trainer/Alpha Loss                       0.935487
exploration/num steps total         490000
exploration/num paths total           2450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.83321
exploration/Rewards Std                  0.357897
exploration/Rewards Max                 -4.06216
exploration/Rewards Min                 -6.14195
exploration/Returns Mean             -1166.64
exploration/Returns Std                 58.5337
exploration/Returns Max              -1017.58
exploration/Returns Min              -1219.06
exploration/Actions Mean                -0.0696557
exploration/Actions Std                  0.829405
exploration/Actions Max                  0.999528
exploration/Actions Min                 -0.99927
exploration/Num Paths                   10
exploration/Average Returns          -1166.64
evaluation/num steps total               1.17706e+06
evaluation/num paths total            5856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.04458
evaluation/Rewards Std                   0.0539115
evaluation/Rewards Max                  -5.03261
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1214.96
evaluation/Returns Std                   7.26367
evaluation/Returns Max               -1197.79
evaluation/Returns Min               -1225.81
evaluation/Actions Mean                 -0.0445203
evaluation/Actions Std                   0.850558
evaluation/Actions Max                   0.989466
evaluation/Actions Min                  -0.945592
evaluation/Num Paths                    24
evaluation/Average Returns           -1214.96
time/data storing (s)                    0.0348258
time/evaluation sampling (s)            27.467
time/exploration sampling (s)            8.44
time/logging (s)                         0.187628
time/sac training (s)                   23.3464
time/saving (s)                          0.203326
time/training (s)                        0.000136953
time/epoch (s)                          59.6793
time/total (s)                       15244.9
Epoch                                  243
----------------------------------  ----------------
2020-11-09 17:44:18.608162 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 244 finished
----------------------------------  ----------------
replay_buffer/size                  492000
trainer/num train calls             245000
trainer/QF1 Loss                        20.6871
trainer/QF2 Loss                        20.5862
trainer/Policy Loss                    563.548
trainer/Q1 Predictions Mean           -563.601
trainer/Q1 Predictions Std              42.1998
trainer/Q1 Predictions Max            -374.487
trainer/Q1 Predictions Min            -644.787
trainer/Q2 Predictions Mean           -563.611
trainer/Q2 Predictions Std              42.1605
trainer/Q2 Predictions Max            -374.603
trainer/Q2 Predictions Min            -643.479
trainer/Q Targets Mean                -565.97
trainer/Q Targets Std                   41.967
trainer/Q Targets Max                 -374.944
trainer/Q Targets Min                 -644.795
trainer/Log Pis Mean                     1.78711
trainer/Log Pis Std                      3.13122
trainer/Log Pis Max                     11.1949
trainer/Log Pis Min                     -4.80323
trainer/policy/mean Mean                -0.0463041
trainer/policy/mean Std                  0.800442
trainer/policy/mean Max                  0.999844
trainer/policy/mean Min                 -0.993231
trainer/policy/normal/std Mean           0.710785
trainer/policy/normal/std Std            0.088385
trainer/policy/normal/std Max            0.970189
trainer/policy/normal/std Min            0.485158
trainer/policy/normal/log_std Mean      -0.349177
trainer/policy/normal/log_std Std        0.12522
trainer/policy/normal/log_std Max       -0.0302646
trainer/policy/normal/log_std Min       -0.723282
trainer/Alpha                            0.029589
trainer/Alpha Loss                      -0.749434
exploration/num steps total         492000
exploration/num paths total           2460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.74025
exploration/Rewards Std                  0.665555
exploration/Rewards Max                 -3.33153
exploration/Rewards Min                 -6.14204
exploration/Returns Mean             -1148.05
exploration/Returns Std                112.027
exploration/Returns Max               -816.901
exploration/Returns Min              -1208.04
exploration/Actions Mean                -0.0292698
exploration/Actions Std                  0.806604
exploration/Actions Max                  0.9997
exploration/Actions Min                 -0.999004
exploration/Num Paths                   10
exploration/Average Returns          -1148.05
evaluation/num steps total               1.18188e+06
evaluation/num paths total            5880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.94095
evaluation/Rewards Std                   0.514833
evaluation/Rewards Max                  -3.39795
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1194.13
evaluation/Returns Std                 100.196
evaluation/Returns Max                -714.15
evaluation/Returns Min               -1223.45
evaluation/Actions Mean                 -0.0293491
evaluation/Actions Std                   0.834398
evaluation/Actions Max                   0.990095
evaluation/Actions Min                  -0.955657
evaluation/Num Paths                    24
evaluation/Average Returns           -1194.13
time/data storing (s)                    0.0527582
time/evaluation sampling (s)            17.4489
time/exploration sampling (s)            6.7373
time/logging (s)                         0.19168
time/sac training (s)                   20.4406
time/saving (s)                          0.206258
time/training (s)                        0.000153041
time/epoch (s)                          45.0777
time/total (s)                       15739.8
Epoch                                  244
----------------------------------  ----------------
2020-11-09 17:52:19.458084 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 245 finished
----------------------------------  ---------------
replay_buffer/size                  494000
trainer/num train calls             246000
trainer/QF1 Loss                      1145.83
trainer/QF2 Loss                      1146.99
trainer/Policy Loss                    561.721
trainer/Q1 Predictions Mean           -561.855
trainer/Q1 Predictions Std              47.501
trainer/Q1 Predictions Max            -393.239
trainer/Q1 Predictions Min            -645.496
trainer/Q2 Predictions Mean           -561.891
trainer/Q2 Predictions Std              47.4742
trainer/Q2 Predictions Max            -393.311
trainer/Q2 Predictions Min            -646.008
trainer/Q Targets Mean                -562.639
trainer/Q Targets Std                   59.2949
trainer/Q Targets Max                   -5.5896
trainer/Q Targets Min                 -647.247
trainer/Log Pis Mean                     1.2543
trainer/Log Pis Std                      1.95431
trainer/Log Pis Max                      6.91288
trainer/Log Pis Min                     -5.32803
trainer/policy/mean Mean                 0.231103
trainer/policy/mean Std                  0.721891
trainer/policy/mean Max                  0.99904
trainer/policy/mean Min                 -0.842903
trainer/policy/normal/std Mean           0.663145
trainer/policy/normal/std Std            0.115484
trainer/policy/normal/std Max            1.08036
trainer/policy/normal/std Min            0.481017
trainer/policy/normal/log_std Mean      -0.424909
trainer/policy/normal/log_std Std        0.165572
trainer/policy/normal/log_std Max        0.07729
trainer/policy/normal/log_std Min       -0.731852
trainer/Alpha                            0.0291478
trainer/Alpha Loss                      -2.63633
exploration/num steps total         494000
exploration/num paths total           2470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.50942
exploration/Rewards Std                  1.02267
exploration/Rewards Max                 -3.34821
exploration/Rewards Min                 -6.1414
exploration/Returns Mean             -1101.88
exploration/Returns Std                210.11
exploration/Returns Max               -660.295
exploration/Returns Min              -1215.12
exploration/Actions Mean                 0.268318
exploration/Actions Std                  0.731334
exploration/Actions Max                  0.999855
exploration/Actions Min                 -0.996396
exploration/Num Paths                   10
exploration/Average Returns          -1101.88
evaluation/num steps total               1.1867e+06
evaluation/num paths total            5904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.63006
evaluation/Rewards Std                   0.979112
evaluation/Rewards Max                  -3.39744
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1131.64
evaluation/Returns Std                 194.777
evaluation/Returns Max                -691.101
evaluation/Returns Min               -1229.08
evaluation/Actions Mean                  0.285964
evaluation/Actions Std                   0.668528
evaluation/Actions Max                   0.990125
evaluation/Actions Min                  -0.710316
evaluation/Num Paths                    24
evaluation/Average Returns           -1131.64
time/data storing (s)                    0.0429171
time/evaluation sampling (s)            26.0556
time/exploration sampling (s)            9.56511
time/logging (s)                         0.283202
time/sac training (s)                   29.7764
time/saving (s)                          0.143826
time/training (s)                        0.00021956
time/epoch (s)                          65.8673
time/total (s)                       16220.7
Epoch                                  245
----------------------------------  ---------------
2020-11-09 17:59:42.754267 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 246 finished
----------------------------------  ----------------
replay_buffer/size                  496000
trainer/num train calls             247000
trainer/QF1 Loss                        22.1571
trainer/QF2 Loss                        21.984
trainer/Policy Loss                    561.411
trainer/Q1 Predictions Mean           -561.534
trainer/Q1 Predictions Std              44.7067
trainer/Q1 Predictions Max            -390.969
trainer/Q1 Predictions Min            -646.692
trainer/Q2 Predictions Mean           -561.579
trainer/Q2 Predictions Std              44.7454
trainer/Q2 Predictions Max            -390.954
trainer/Q2 Predictions Min            -647.591
trainer/Q Targets Mean                -564.432
trainer/Q Targets Std                   45.2224
trainer/Q Targets Max                 -392.378
trainer/Q Targets Min                 -648.779
trainer/Log Pis Mean                     2.11785
trainer/Log Pis Std                      2.55451
trainer/Log Pis Max                      9.63414
trainer/Log Pis Min                     -3.6171
trainer/policy/mean Mean                -0.220184
trainer/policy/mean Std                  0.782324
trainer/policy/mean Max                  0.997406
trainer/policy/mean Min                 -0.997873
trainer/policy/normal/std Mean           0.584039
trainer/policy/normal/std Std            0.0930481
trainer/policy/normal/std Max            0.785866
trainer/policy/normal/std Min            0.447938
trainer/policy/normal/log_std Mean      -0.550535
trainer/policy/normal/log_std Std        0.159921
trainer/policy/normal/log_std Max       -0.240968
trainer/policy/normal/log_std Min       -0.8031
trainer/Alpha                            0.0286256
trainer/Alpha Loss                       0.418776
exploration/num steps total         496000
exploration/num paths total           2480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.0478
exploration/Rewards Std                  0.948304
exploration/Rewards Max                 -3.13703
exploration/Rewards Min                 -6.14201
exploration/Returns Mean             -1009.56
exploration/Returns Std                140.46
exploration/Returns Max               -759.377
exploration/Returns Min              -1182.96
exploration/Actions Mean                -0.188058
exploration/Actions Std                  0.804105
exploration/Actions Max                  0.998574
exploration/Actions Min                 -0.999843
exploration/Num Paths                   10
exploration/Average Returns          -1009.56
evaluation/num steps total               1.19153e+06
evaluation/num paths total            5928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.66119
evaluation/Rewards Std                   0.560975
evaluation/Rewards Max                  -3.39288
evaluation/Rewards Min                  -6.14198
evaluation/Returns Mean              -1137.9
evaluation/Returns Std                 105.904
evaluation/Returns Max                -698.865
evaluation/Returns Min               -1209.64
evaluation/Actions Mean                 -0.127077
evaluation/Actions Std                   0.860947
evaluation/Actions Max                   0.990599
evaluation/Actions Min                  -0.994183
evaluation/Num Paths                    24
evaluation/Average Returns           -1137.9
time/data storing (s)                    0.029239
time/evaluation sampling (s)            16.9193
time/exploration sampling (s)            7.21979
time/logging (s)                         0.0915345
time/sac training (s)                   18.7518
time/saving (s)                          0.194501
time/training (s)                        0.000130351
time/epoch (s)                          43.2063
time/total (s)                       16663.7
Epoch                                  246
----------------------------------  ----------------
2020-11-09 18:07:38.230316 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 247 finished
----------------------------------  ----------------
replay_buffer/size                  498000
trainer/num train calls             248000
trainer/QF1 Loss                        20.0366
trainer/QF2 Loss                        20.0673
trainer/Policy Loss                    560.481
trainer/Q1 Predictions Mean           -560.594
trainer/Q1 Predictions Std              45.3341
trainer/Q1 Predictions Max            -394.491
trainer/Q1 Predictions Min            -631.254
trainer/Q2 Predictions Mean           -560.601
trainer/Q2 Predictions Std              45.3194
trainer/Q2 Predictions Max            -394.587
trainer/Q2 Predictions Min            -630.141
trainer/Q Targets Mean                -563.391
trainer/Q Targets Std                   45.6794
trainer/Q Targets Max                 -396.337
trainer/Q Targets Min                 -631.412
trainer/Log Pis Mean                     2.16324
trainer/Log Pis Std                      1.81449
trainer/Log Pis Max                      7.32851
trainer/Log Pis Min                     -2.80309
trainer/policy/mean Mean                 0.154825
trainer/policy/mean Std                  0.821425
trainer/policy/mean Max                  0.999458
trainer/policy/mean Min                 -0.923731
trainer/policy/normal/std Mean           0.532387
trainer/policy/normal/std Std            0.057629
trainer/policy/normal/std Max            0.76228
trainer/policy/normal/std Min            0.413711
trainer/policy/normal/log_std Mean      -0.635878
trainer/policy/normal/log_std Std        0.10327
trainer/policy/normal/log_std Max       -0.271441
trainer/policy/normal/log_std Min       -0.882587
trainer/Alpha                            0.0284855
trainer/Alpha Loss                       0.580863
exploration/num steps total         498000
exploration/num paths total           2490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.04683
exploration/Rewards Std                  0.0402865
exploration/Rewards Max                 -5.71814
exploration/Rewards Min                 -6.14181
exploration/Returns Mean             -1209.37
exploration/Returns Std                 17.5161
exploration/Returns Max              -1159.09
exploration/Returns Min              -1223.67
exploration/Actions Mean                 0.195451
exploration/Actions Std                  0.775949
exploration/Actions Max                  0.99936
exploration/Actions Min                 -0.995429
exploration/Num Paths                   10
exploration/Average Returns          -1209.37
evaluation/num steps total               1.19635e+06
evaluation/num paths total            5952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96788
evaluation/Rewards Std                   0.518687
evaluation/Rewards Max                  -3.38946
evaluation/Rewards Min                  -6.14185
evaluation/Returns Mean              -1199.54
evaluation/Returns Std                 100.386
evaluation/Returns Max                -718.91
evaluation/Returns Min               -1231.26
evaluation/Actions Mean                  0.223124
evaluation/Actions Std                   0.747629
evaluation/Actions Max                   0.989858
evaluation/Actions Min                  -0.816285
evaluation/Num Paths                    24
evaluation/Average Returns           -1199.54
time/data storing (s)                    0.0294278
time/evaluation sampling (s)            16.8906
time/exploration sampling (s)            6.61363
time/logging (s)                         0.311925
time/sac training (s)                   20.9659
time/saving (s)                          0.244693
time/training (s)                        0.000286593
time/epoch (s)                          45.0565
time/total (s)                       17139.4
Epoch                                  247
----------------------------------  ----------------
2020-11-09 18:16:16.883979 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 248 finished
----------------------------------  ----------------
replay_buffer/size                  500000
trainer/num train calls             249000
trainer/QF1 Loss                      3862.78
trainer/QF2 Loss                      3860.65
trainer/Policy Loss                    563.353
trainer/Q1 Predictions Mean           -563.509
trainer/Q1 Predictions Std              43.2179
trainer/Q1 Predictions Max            -383.494
trainer/Q1 Predictions Min            -622.367
trainer/Q2 Predictions Mean           -563.46
trainer/Q2 Predictions Std              43.1902
trainer/Q2 Predictions Max            -383.613
trainer/Q2 Predictions Min            -622.706
trainer/Q Targets Mean                -558.996
trainer/Q Targets Std                   74.2665
trainer/Q Targets Max                   -5.11496
trainer/Q Targets Min                 -624.146
trainer/Log Pis Mean                     2.82573
trainer/Log Pis Std                      3.60274
trainer/Log Pis Max                      9.39523
trainer/Log Pis Min                     -6.65851
trainer/policy/mean Mean                -0.185232
trainer/policy/mean Std                  0.82309
trainer/policy/mean Max                  0.999035
trainer/policy/mean Min                 -0.998788
trainer/policy/normal/std Mean           0.614134
trainer/policy/normal/std Std            0.0834939
trainer/policy/normal/std Max            0.799794
trainer/policy/normal/std Min            0.515877
trainer/policy/normal/log_std Mean      -0.496506
trainer/policy/normal/log_std Std        0.132884
trainer/policy/normal/log_std Max       -0.223402
trainer/policy/normal/log_std Min       -0.661887
trainer/Alpha                            0.0289554
trainer/Alpha Loss                       2.92474
exploration/num steps total         500000
exploration/num paths total           2500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.71922
exploration/Rewards Std                  0.261399
exploration/Rewards Max                 -5.04182
exploration/Rewards Min                 -6.14165
exploration/Returns Mean             -1143.84
exploration/Returns Std                 30.7225
exploration/Returns Max              -1090.95
exploration/Returns Min              -1185.72
exploration/Actions Mean                -0.184218
exploration/Actions Std                  0.836673
exploration/Actions Max                  0.999649
exploration/Actions Min                 -0.999787
exploration/Num Paths                   10
exploration/Average Returns          -1143.84
evaluation/num steps total               1.20118e+06
evaluation/num paths total            5976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73004
evaluation/Rewards Std                   0.698798
evaluation/Rewards Max                  -3.26225
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1151.74
evaluation/Returns Std                 134.595
evaluation/Returns Max                -707.479
evaluation/Returns Min               -1216.97
evaluation/Actions Mean                 -0.122508
evaluation/Actions Std                   0.877606
evaluation/Actions Max                   0.996051
evaluation/Actions Min                  -0.994585
evaluation/Num Paths                    24
evaluation/Average Returns           -1151.74
time/data storing (s)                    0.0698967
time/evaluation sampling (s)            19.7235
time/exploration sampling (s)            8.48494
time/logging (s)                         0.182159
time/sac training (s)                   19.2985
time/saving (s)                          0.133319
time/training (s)                        0.000154448
time/epoch (s)                          47.8924
time/total (s)                       17657.9
Epoch                                  248
----------------------------------  ----------------
2020-11-09 18:25:03.593321 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 249 finished
----------------------------------  ----------------
replay_buffer/size                  502000
trainer/num train calls             250000
trainer/QF1 Loss                      1235.91
trainer/QF2 Loss                      1236.68
trainer/Policy Loss                    560.106
trainer/Q1 Predictions Mean           -560.242
trainer/Q1 Predictions Std              46.7698
trainer/Q1 Predictions Max            -370.304
trainer/Q1 Predictions Min            -630.544
trainer/Q2 Predictions Mean           -560.254
trainer/Q2 Predictions Std              46.743
trainer/Q2 Predictions Max            -370.337
trainer/Q2 Predictions Min            -631.27
trainer/Q Targets Mean                -560.933
trainer/Q Targets Std                   58.4971
trainer/Q Targets Max                   -5.43947
trainer/Q Targets Min                 -633.853
trainer/Log Pis Mean                     2.79352
trainer/Log Pis Std                      3.38728
trainer/Log Pis Max                     10.305
trainer/Log Pis Min                     -4.39912
trainer/policy/mean Mean                 0.0178564
trainer/policy/mean Std                  0.858632
trainer/policy/mean Max                  0.999922
trainer/policy/mean Min                 -0.993353
trainer/policy/normal/std Mean           0.63226
trainer/policy/normal/std Std            0.0659171
trainer/policy/normal/std Max            0.811223
trainer/policy/normal/std Min            0.457436
trainer/policy/normal/log_std Mean      -0.464088
trainer/policy/normal/log_std Std        0.107188
trainer/policy/normal/log_std Max       -0.209213
trainer/policy/normal/log_std Min       -0.782118
trainer/Alpha                            0.0294346
trainer/Alpha Loss                       2.79763
exploration/num steps total         502000
exploration/num paths total           2510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.99735
exploration/Rewards Std                  0.0948687
exploration/Rewards Max                 -4.31099
exploration/Rewards Min                 -6.14052
exploration/Returns Mean             -1199.47
exploration/Returns Std                 19.5611
exploration/Returns Max              -1142.85
exploration/Returns Min              -1215.08
exploration/Actions Mean                 0.0364272
exploration/Actions Std                  0.888781
exploration/Actions Max                  0.999962
exploration/Actions Min                 -0.998537
exploration/Num Paths                   10
exploration/Average Returns          -1199.47
evaluation/num steps total               1.206e+06
evaluation/num paths total            6000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.94801
evaluation/Rewards Std                   0.523313
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1195.55
evaluation/Returns Std                 103.969
evaluation/Returns Max                -697.223
evaluation/Returns Min               -1221.5
evaluation/Actions Mean                  0.00164084
evaluation/Actions Std                   0.829459
evaluation/Actions Max                   0.996563
evaluation/Actions Min                  -0.957658
evaluation/Num Paths                    24
evaluation/Average Returns           -1195.55
time/data storing (s)                    0.0525327
time/evaluation sampling (s)            22.6043
time/exploration sampling (s)            7.98824
time/logging (s)                         0.144829
time/sac training (s)                   23.0977
time/saving (s)                          0.269438
time/training (s)                        0.000208939
time/epoch (s)                          54.1573
time/total (s)                       18184.5
Epoch                                  249
----------------------------------  ----------------
2020-11-09 18:33:40.950363 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 250 finished
----------------------------------  ----------------
replay_buffer/size                  504000
trainer/num train calls             251000
trainer/QF1 Loss                      1114.54
trainer/QF2 Loss                      1119.53
trainer/Policy Loss                    565.421
trainer/Q1 Predictions Mean           -565.532
trainer/Q1 Predictions Std              39.4925
trainer/Q1 Predictions Max            -277.914
trainer/Q1 Predictions Min            -625.445
trainer/Q2 Predictions Mean           -565.534
trainer/Q2 Predictions Std              39.4529
trainer/Q2 Predictions Max            -277.865
trainer/Q2 Predictions Min            -624.846
trainer/Q Targets Mean                -565.908
trainer/Q Targets Std                   53.0324
trainer/Q Targets Max                   -5.52154
trainer/Q Targets Min                 -626.244
trainer/Log Pis Mean                     1.92539
trainer/Log Pis Std                      2.26846
trainer/Log Pis Max                      6.85446
trainer/Log Pis Min                     -3.88003
trainer/policy/mean Mean                -0.0129495
trainer/policy/mean Std                  0.857867
trainer/policy/mean Max                  0.999273
trainer/policy/mean Min                 -0.99279
trainer/policy/normal/std Mean           0.545241
trainer/policy/normal/std Std            0.0538351
trainer/policy/normal/std Max            0.680373
trainer/policy/normal/std Min            0.410069
trainer/policy/normal/log_std Mean      -0.611378
trainer/policy/normal/log_std Std        0.0983974
trainer/policy/normal/log_std Max       -0.385114
trainer/policy/normal/log_std Min       -0.89143
trainer/Alpha                            0.0291726
trainer/Alpha Loss                      -0.263728
exploration/num steps total         504000
exploration/num paths total           2520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.94924
exploration/Rewards Std                  0.135624
exploration/Rewards Max                 -5.57891
exploration/Rewards Min                 -6.14186
exploration/Returns Mean             -1189.85
exploration/Returns Std                 26.073
exploration/Returns Max              -1146.38
exploration/Returns Min              -1221.68
exploration/Actions Mean                -0.0262329
exploration/Actions Std                  0.802584
exploration/Actions Max                  0.998593
exploration/Actions Min                 -0.996534
exploration/Num Paths                   10
exploration/Average Returns          -1189.85
evaluation/num steps total               1.21082e+06
evaluation/num paths total            6024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95122
evaluation/Rewards Std                   0.516825
evaluation/Rewards Max                  -3.40094
evaluation/Rewards Min                  -6.14197
evaluation/Returns Mean              -1196.19
evaluation/Returns Std                 101.503
evaluation/Returns Max                -710.012
evaluation/Returns Min               -1228.83
evaluation/Actions Mean                 -0.0273742
evaluation/Actions Std                   0.812239
evaluation/Actions Max                   0.979469
evaluation/Actions Min                  -0.954997
evaluation/Num Paths                    24
evaluation/Average Returns           -1196.19
time/data storing (s)                    0.028911
time/evaluation sampling (s)            18.5698
time/exploration sampling (s)            8.05449
time/logging (s)                         0.157213
time/sac training (s)                   23.7188
time/saving (s)                          0.198591
time/training (s)                        0.000165242
time/epoch (s)                          50.728
time/total (s)                       18701.8
Epoch                                  250
----------------------------------  ----------------
2020-11-09 18:41:41.158100 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 251 finished
----------------------------------  ----------------
replay_buffer/size                  506000
trainer/num train calls             252000
trainer/QF1 Loss                        44.3815
trainer/QF2 Loss                        44.358
trainer/Policy Loss                    559.098
trainer/Q1 Predictions Mean           -559.291
trainer/Q1 Predictions Std              48.8694
trainer/Q1 Predictions Max            -368.629
trainer/Q1 Predictions Min            -635.001
trainer/Q2 Predictions Mean           -559.307
trainer/Q2 Predictions Std              48.8617
trainer/Q2 Predictions Max            -368.327
trainer/Q2 Predictions Min            -635.684
trainer/Q Targets Mean                -562.555
trainer/Q Targets Std                   49.1532
trainer/Q Targets Max                 -368.801
trainer/Q Targets Min                 -637.816
trainer/Log Pis Mean                     1.90183
trainer/Log Pis Std                      1.55869
trainer/Log Pis Max                      5.16586
trainer/Log Pis Min                     -3.72703
trainer/policy/mean Mean                 0.212431
trainer/policy/mean Std                  0.787874
trainer/policy/mean Max                  0.992036
trainer/policy/mean Min                 -0.916752
trainer/policy/normal/std Mean           0.546433
trainer/policy/normal/std Std            0.0448251
trainer/policy/normal/std Max            0.720516
trainer/policy/normal/std Min            0.480966
trainer/policy/normal/log_std Mean      -0.607537
trainer/policy/normal/log_std Std        0.0789424
trainer/policy/normal/log_std Max       -0.327787
trainer/policy/normal/log_std Min       -0.731958
trainer/Alpha                            0.0293802
trainer/Alpha Loss                      -0.346305
exploration/num steps total         506000
exploration/num paths total           2530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -6.01889
exploration/Rewards Std                  0.0915833
exploration/Rewards Max                 -5.54904
exploration/Rewards Min                 -6.14183
exploration/Returns Mean             -1203.78
exploration/Returns Std                 23.6454
exploration/Returns Max              -1144.07
exploration/Returns Min              -1227.63
exploration/Actions Mean                 0.264042
exploration/Actions Std                  0.742657
exploration/Actions Max                  0.998983
exploration/Actions Min                 -0.995754
exploration/Num Paths                   10
exploration/Average Returns          -1203.78
evaluation/num steps total               1.21565e+06
evaluation/num paths total            6048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97028
evaluation/Rewards Std                   0.537083
evaluation/Rewards Max                  -3.36856
evaluation/Rewards Min                  -6.142
evaluation/Returns Mean              -1200.03
evaluation/Returns Std                 106.941
evaluation/Returns Max                -687.953
evaluation/Returns Min               -1230.27
evaluation/Actions Mean                  0.244185
evaluation/Actions Std                   0.748867
evaluation/Actions Max                   0.978406
evaluation/Actions Min                  -0.824277
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.03
time/data storing (s)                    0.123256
time/evaluation sampling (s)            18.4293
time/exploration sampling (s)            7.79945
time/logging (s)                         0.327641
time/sac training (s)                   20.658
time/saving (s)                          0.214175
time/training (s)                        0.000131397
time/epoch (s)                          47.5519
time/total (s)                       19182.1
Epoch                                  251
----------------------------------  ----------------
2020-11-09 18:49:49.959951 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 252 finished
----------------------------------  ----------------
replay_buffer/size                  508000
trainer/num train calls             253000
trainer/QF1 Loss                      2667.23
trainer/QF2 Loss                      2665.81
trainer/Policy Loss                    564.309
trainer/Q1 Predictions Mean           -564.596
trainer/Q1 Predictions Std              43.4211
trainer/Q1 Predictions Max            -370.448
trainer/Q1 Predictions Min            -636.989
trainer/Q2 Predictions Mean           -564.574
trainer/Q2 Predictions Std              43.4132
trainer/Q2 Predictions Max            -370.355
trainer/Q2 Predictions Min            -637.843
trainer/Q Targets Mean                -562.222
trainer/Q Targets Std                   65.9697
trainer/Q Targets Max                   -5.45729
trainer/Q Targets Min                 -637.82
trainer/Log Pis Mean                     2.0352
trainer/Log Pis Std                      1.97678
trainer/Log Pis Max                      8.45878
trainer/Log Pis Min                     -5.40448
trainer/policy/mean Mean                 0.047484
trainer/policy/mean Std                  0.86865
trainer/policy/mean Max                  0.9974
trainer/policy/mean Min                 -0.965046
trainer/policy/normal/std Mean           0.568456
trainer/policy/normal/std Std            0.0380039
trainer/policy/normal/std Max            0.716094
trainer/policy/normal/std Min            0.466901
trainer/policy/normal/log_std Mean      -0.567023
trainer/policy/normal/log_std Std        0.065972
trainer/policy/normal/log_std Max       -0.333944
trainer/policy/normal/log_std Min       -0.761639
trainer/Alpha                            0.0299755
trainer/Alpha Loss                       0.123469
exploration/num steps total         508000
exploration/num paths total           2540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.58789
exploration/Rewards Std                  1.10995
exploration/Rewards Max                 -0.965138
exploration/Rewards Min                 -6.14192
exploration/Returns Mean             -1117.58
exploration/Returns Std                194.698
exploration/Returns Max               -575.61
exploration/Returns Min              -1229.47
exploration/Actions Mean                 0.039179
exploration/Actions Std                  0.827644
exploration/Actions Max                  0.999348
exploration/Actions Min                 -0.997358
exploration/Num Paths                   10
exploration/Average Returns          -1117.58
evaluation/num steps total               1.22047e+06
evaluation/num paths total            6072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.09893
evaluation/Rewards Std                   0.0395963
evaluation/Rewards Max                  -5.71629
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1225.88
evaluation/Returns Std                   7.32637
evaluation/Returns Max               -1204.97
evaluation/Returns Min               -1233.07
evaluation/Actions Mean                  0.0168348
evaluation/Actions Std                   0.830244
evaluation/Actions Max                   0.967296
evaluation/Actions Min                  -0.899564
evaluation/Num Paths                    24
evaluation/Average Returns           -1225.88
time/data storing (s)                    0.0348377
time/evaluation sampling (s)            19.301
time/exploration sampling (s)            9.83464
time/logging (s)                         0.0959459
time/sac training (s)                   17.7362
time/saving (s)                          0.287288
time/training (s)                        0.000138084
time/epoch (s)                          47.2901
time/total (s)                       19670.7
Epoch                                  252
----------------------------------  ----------------
2020-11-09 18:57:48.526836 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 253 finished
----------------------------------  ----------------
replay_buffer/size                  510000
trainer/num train calls             254000
trainer/QF1 Loss                      1260.4
trainer/QF2 Loss                      1258.93
trainer/Policy Loss                    562.866
trainer/Q1 Predictions Mean           -562.989
trainer/Q1 Predictions Std              49.4335
trainer/Q1 Predictions Max            -395.256
trainer/Q1 Predictions Min            -620.037
trainer/Q2 Predictions Mean           -562.98
trainer/Q2 Predictions Std              49.4084
trainer/Q2 Predictions Max            -395.363
trainer/Q2 Predictions Min            -619.594
trainer/Q Targets Mean                -563.322
trainer/Q Targets Std                   60.8567
trainer/Q Targets Max                   -5.32481
trainer/Q Targets Min                 -622.148
trainer/Log Pis Mean                     2.7769
trainer/Log Pis Std                      2.74749
trainer/Log Pis Max                     10.2296
trainer/Log Pis Min                     -3.74433
trainer/policy/mean Mean                -0.0930704
trainer/policy/mean Std                  0.876246
trainer/policy/mean Max                  0.998349
trainer/policy/mean Min                 -0.996867
trainer/policy/normal/std Mean           0.674829
trainer/policy/normal/std Std            0.0611261
trainer/policy/normal/std Max            0.855215
trainer/policy/normal/std Min            0.585655
trainer/policy/normal/log_std Mean      -0.397281
trainer/policy/normal/log_std Std        0.088652
trainer/policy/normal/log_std Max       -0.156402
trainer/policy/normal/log_std Min       -0.535024
trainer/Alpha                            0.030848
trainer/Alpha Loss                       2.7026
exploration/num steps total         510000
exploration/num paths total           2550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.62634
exploration/Rewards Std                  0.752486
exploration/Rewards Max                 -3.27199
exploration/Rewards Min                 -6.14169
exploration/Returns Mean             -1125.27
exploration/Returns Std                144.902
exploration/Returns Max               -695.501
exploration/Returns Min              -1198.91
exploration/Actions Mean                -0.15098
exploration/Actions Std                  0.826923
exploration/Actions Max                  0.999695
exploration/Actions Min                 -0.999927
exploration/Num Paths                   10
exploration/Average Returns          -1125.27
evaluation/num steps total               1.2253e+06
evaluation/num paths total            6096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7037
evaluation/Rewards Std                   0.816893
evaluation/Rewards Max                  -3.34208
evaluation/Rewards Min                  -6.14204
evaluation/Returns Mean              -1146.44
evaluation/Returns Std                 154.224
evaluation/Returns Max                -699.278
evaluation/Returns Min               -1220.09
evaluation/Actions Mean                 -0.0537823
evaluation/Actions Std                   0.924091
evaluation/Actions Max                   0.994104
evaluation/Actions Min                  -0.986977
evaluation/Num Paths                    24
evaluation/Average Returns           -1146.44
time/data storing (s)                    0.0552694
time/evaluation sampling (s)            17.9571
time/exploration sampling (s)            8.42123
time/logging (s)                         0.320345
time/sac training (s)                   17.5814
time/saving (s)                          0.242868
time/training (s)                        0.000158813
time/epoch (s)                          44.5783
time/total (s)                       20149.4
Epoch                                  253
----------------------------------  ----------------
2020-11-09 19:05:36.486531 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 254 finished
----------------------------------  ----------------
replay_buffer/size                  512000
trainer/num train calls             255000
trainer/QF1 Loss                        20.7588
trainer/QF2 Loss                        20.5368
trainer/Policy Loss                    569.104
trainer/Q1 Predictions Mean           -569.123
trainer/Q1 Predictions Std              37.775
trainer/Q1 Predictions Max            -392.185
trainer/Q1 Predictions Min            -625.492
trainer/Q2 Predictions Mean           -569.159
trainer/Q2 Predictions Std              37.7863
trainer/Q2 Predictions Max            -392.445
trainer/Q2 Predictions Min            -627.056
trainer/Q Targets Mean                -571.438
trainer/Q Targets Std                   38.554
trainer/Q Targets Max                 -392.93
trainer/Q Targets Min                 -627.411
trainer/Log Pis Mean                     1.9275
trainer/Log Pis Std                      2.50935
trainer/Log Pis Max                      8.35673
trainer/Log Pis Min                     -4.36778
trainer/policy/mean Mean                -0.213925
trainer/policy/mean Std                  0.794875
trainer/policy/mean Max                  0.989695
trainer/policy/mean Min                 -0.993991
trainer/policy/normal/std Mean           0.669128
trainer/policy/normal/std Std            0.158142
trainer/policy/normal/std Max            0.94488
trainer/policy/normal/std Min            0.485408
trainer/policy/normal/log_std Mean      -0.430158
trainer/policy/normal/log_std Std        0.238906
trainer/policy/normal/log_std Max       -0.056697
trainer/policy/normal/log_std Min       -0.722766
trainer/Alpha                            0.0313777
trainer/Alpha Loss                      -0.25096
exploration/num steps total         512000
exploration/num paths total           2560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.54926
exploration/Rewards Std                  0.553523
exploration/Rewards Max                 -3.2787
exploration/Rewards Min                 -6.14172
exploration/Returns Mean             -1109.85
exploration/Returns Std                 66.1259
exploration/Returns Max               -931.515
exploration/Returns Min              -1165.05
exploration/Actions Mean                -0.160119
exploration/Actions Std                  0.853801
exploration/Actions Max                  0.998251
exploration/Actions Min                 -0.999944
exploration/Num Paths                   10
exploration/Average Returns          -1109.85
evaluation/num steps total               1.23012e+06
evaluation/num paths total            6120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.70537
evaluation/Rewards Std                   0.562906
evaluation/Rewards Max                  -3.13679
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1146.78
evaluation/Returns Std                  77.1757
evaluation/Returns Max                -915.969
evaluation/Returns Min               -1211.9
evaluation/Actions Mean                 -0.16797
evaluation/Actions Std                   0.831923
evaluation/Actions Max                   0.980482
evaluation/Actions Min                  -0.989859
evaluation/Num Paths                    24
evaluation/Average Returns           -1146.78
time/data storing (s)                    0.0388465
time/evaluation sampling (s)            18.5441
time/exploration sampling (s)            7.79722
time/logging (s)                         0.112567
time/sac training (s)                   16.7906
time/saving (s)                          0.165289
time/training (s)                        0.000147005
time/epoch (s)                          43.4488
time/total (s)                       20617.1
Epoch                                  254
----------------------------------  ----------------
2020-11-09 19:14:00.078135 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 255 finished
----------------------------------  ----------------
replay_buffer/size                  514000
trainer/num train calls             256000
trainer/QF1 Loss                        48.6016
trainer/QF2 Loss                        48.2339
trainer/Policy Loss                    567.847
trainer/Q1 Predictions Mean           -568.168
trainer/Q1 Predictions Std              41.0874
trainer/Q1 Predictions Max            -378.938
trainer/Q1 Predictions Min            -633.048
trainer/Q2 Predictions Mean           -568.239
trainer/Q2 Predictions Std              41.0991
trainer/Q2 Predictions Max            -379.012
trainer/Q2 Predictions Min            -633.855
trainer/Q Targets Mean                -570.998
trainer/Q Targets Std                   40.991
trainer/Q Targets Max                 -380.783
trainer/Q Targets Min                 -633.694
trainer/Log Pis Mean                     3.72482
trainer/Log Pis Std                      3.91606
trainer/Log Pis Max                     13.6307
trainer/Log Pis Min                     -3.57196
trainer/policy/mean Mean                -0.228446
trainer/policy/mean Std                  0.843435
trainer/policy/mean Max                  0.99932
trainer/policy/mean Min                 -0.999416
trainer/policy/normal/std Mean           0.736867
trainer/policy/normal/std Std            0.0885685
trainer/policy/normal/std Max            0.987189
trainer/policy/normal/std Min            0.58415
trainer/policy/normal/log_std Mean      -0.31237
trainer/policy/normal/log_std Std        0.11778
trainer/policy/normal/log_std Max       -0.0128934
trainer/policy/normal/log_std Min       -0.537598
trainer/Alpha                            0.0325158
trainer/Alpha Loss                       5.90929
exploration/num steps total         514000
exploration/num paths total           2570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.99071
exploration/Rewards Std                  0.991906
exploration/Rewards Max                 -3.26925
exploration/Rewards Min                 -6.14166
exploration/Returns Mean              -998.142
exploration/Returns Std                148.105
exploration/Returns Max               -696.006
exploration/Returns Min              -1179.16
exploration/Actions Mean                -0.0967462
exploration/Actions Std                  0.924323
exploration/Actions Max                  0.99995
exploration/Actions Min                 -0.999879
exploration/Num Paths                   10
exploration/Average Returns           -998.142
evaluation/num steps total               1.23494e+06
evaluation/num paths total            6144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.65452
evaluation/Rewards Std                   0.971464
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.14203
evaluation/Returns Mean              -1136.56
evaluation/Returns Std                 189.936
evaluation/Returns Max                -688.674
evaluation/Returns Min               -1221.82
evaluation/Actions Mean                 -0.00245241
evaluation/Actions Std                   0.990177
evaluation/Actions Max                   0.992043
evaluation/Actions Min                  -0.994768
evaluation/Num Paths                    24
evaluation/Average Returns           -1136.56
time/data storing (s)                    0.0511077
time/evaluation sampling (s)            17.6314
time/exploration sampling (s)            7.06251
time/logging (s)                         0.226835
time/sac training (s)                   18.7021
time/saving (s)                          0.253485
time/training (s)                        0.000139627
time/epoch (s)                          43.9275
time/total (s)                       21120.8
Epoch                                  255
----------------------------------  ----------------
2020-11-09 19:22:52.374427 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 256 finished
----------------------------------  ----------------
replay_buffer/size                  516000
trainer/num train calls             257000
trainer/QF1 Loss                      2931.09
trainer/QF2 Loss                      2930.69
trainer/Policy Loss                    565.747
trainer/Q1 Predictions Mean           -565.947
trainer/Q1 Predictions Std              44.15
trainer/Q1 Predictions Max            -365.743
trainer/Q1 Predictions Min            -643.392
trainer/Q2 Predictions Mean           -565.924
trainer/Q2 Predictions Std              44.0862
trainer/Q2 Predictions Max            -365.79
trainer/Q2 Predictions Min            -641.761
trainer/Q Targets Mean                -563.561
trainer/Q Targets Std                   66.2448
trainer/Q Targets Max                   -5.32612
trainer/Q Targets Min                 -647.536
trainer/Log Pis Mean                     1.6363
trainer/Log Pis Std                      2.90833
trainer/Log Pis Max                      7.50159
trainer/Log Pis Min                     -4.6868
trainer/policy/mean Mean                -0.152958
trainer/policy/mean Std                  0.748711
trainer/policy/mean Max                  0.998472
trainer/policy/mean Min                 -0.991997
trainer/policy/normal/std Mean           0.598632
trainer/policy/normal/std Std            0.0721684
trainer/policy/normal/std Max            0.79134
trainer/policy/normal/std Min            0.484483
trainer/policy/normal/log_std Mean      -0.520244
trainer/policy/normal/log_std Std        0.119
trainer/policy/normal/log_std Max       -0.234027
trainer/policy/normal/log_std Min       -0.724672
trainer/Alpha                            0.0324254
trainer/Alpha Loss                      -1.24706
exploration/num steps total         516000
exploration/num paths total           2580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.48261
exploration/Rewards Std                  0.633103
exploration/Rewards Max                 -3.42474
exploration/Rewards Min                 -6.14161
exploration/Returns Mean             -1096.52
exploration/Returns Std                102.529
exploration/Returns Max               -798.397
exploration/Returns Min              -1162.53
exploration/Actions Mean                -0.178345
exploration/Actions Std                  0.693691
exploration/Actions Max                  0.998622
exploration/Actions Min                 -0.99882
exploration/Num Paths                   10
exploration/Average Returns          -1096.52
evaluation/num steps total               1.23977e+06
evaluation/num paths total            6168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.97422
evaluation/Rewards Std                   0.11835
evaluation/Rewards Max                  -4.5438
evaluation/Rewards Min                  -6.14196
evaluation/Returns Mean              -1200.82
evaluation/Returns Std                  20.808
evaluation/Returns Max               -1123.89
evaluation/Returns Min               -1218.06
evaluation/Actions Mean                 -0.0277203
evaluation/Actions Std                   0.915864
evaluation/Actions Max                   0.983279
evaluation/Actions Min                  -0.968069
evaluation/Num Paths                    24
evaluation/Average Returns           -1200.82
time/data storing (s)                    0.0345241
time/evaluation sampling (s)            21.3772
time/exploration sampling (s)            9.06604
time/logging (s)                         0.0796293
time/sac training (s)                   20.6322
time/saving (s)                          0.19356
time/training (s)                        0.000151049
time/epoch (s)                          51.3833
time/total (s)                       21652.9
Epoch                                  256
----------------------------------  ----------------
2020-11-09 19:31:02.425506 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 257 finished
----------------------------------  ----------------
replay_buffer/size                  518000
trainer/num train calls             258000
trainer/QF1 Loss                      1370.05
trainer/QF2 Loss                      1371.23
trainer/Policy Loss                    567.928
trainer/Q1 Predictions Mean           -568.043
trainer/Q1 Predictions Std              41.3782
trainer/Q1 Predictions Max            -367.963
trainer/Q1 Predictions Min            -647.781
trainer/Q2 Predictions Mean           -568.07
trainer/Q2 Predictions Std              41.3312
trainer/Q2 Predictions Max            -367.988
trainer/Q2 Predictions Min            -646.567
trainer/Q Targets Mean                -568.21
trainer/Q Targets Std                   54.5889
trainer/Q Targets Max                   -5.96562
trainer/Q Targets Min                 -648.196
trainer/Log Pis Mean                     2.13648
trainer/Log Pis Std                      2.5772
trainer/Log Pis Max                      8.06505
trainer/Log Pis Min                     -3.99537
trainer/policy/mean Mean                -0.141186
trainer/policy/mean Std                  0.802767
trainer/policy/mean Max                  0.99706
trainer/policy/mean Min                 -0.987064
trainer/policy/normal/std Mean           0.539305
trainer/policy/normal/std Std            0.100536
trainer/policy/normal/std Max            0.799703
trainer/policy/normal/std Min            0.384238
trainer/policy/normal/log_std Mean      -0.634831
trainer/policy/normal/log_std Std        0.18653
trainer/policy/normal/log_std Max       -0.223515
trainer/policy/normal/log_std Min       -0.956493
trainer/Alpha                            0.0317887
trainer/Alpha Loss                       0.470684
exploration/num steps total         518000
exploration/num paths total           2590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.95372
exploration/Rewards Std                  0.101763
exploration/Rewards Max                 -5.31965
exploration/Rewards Min                 -6.14168
exploration/Returns Mean             -1190.74
exploration/Returns Std                 24.3784
exploration/Returns Max              -1121.83
exploration/Returns Min              -1209.75
exploration/Actions Mean                -0.195479
exploration/Actions Std                  0.761469
exploration/Actions Max                  0.999048
exploration/Actions Min                 -0.996996
exploration/Num Paths                   10
exploration/Average Returns          -1190.74
evaluation/num steps total               1.24459e+06
evaluation/num paths total            6192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0024
evaluation/Rewards Std                   0.100676
evaluation/Rewards Max                  -4.25578
evaluation/Rewards Min                  -6.14193
evaluation/Returns Mean              -1206.48
evaluation/Returns Std                  14.1838
evaluation/Returns Max               -1157.08
evaluation/Returns Min               -1220.53
evaluation/Actions Mean                 -0.0782975
evaluation/Actions Std                   0.873358
evaluation/Actions Max                   0.985055
evaluation/Actions Min                  -0.962792
evaluation/Num Paths                    24
evaluation/Average Returns           -1206.48
time/data storing (s)                    0.0896573
time/evaluation sampling (s)            15.7984
time/exploration sampling (s)            8.26708
time/logging (s)                         0.136032
time/sac training (s)                   18.5226
time/saving (s)                          0.208025
time/training (s)                        0.000163615
time/epoch (s)                          43.022
time/total (s)                       22142.9
Epoch                                  257
----------------------------------  ----------------
2020-11-09 19:40:03.983922 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 258 finished
----------------------------------  ----------------
replay_buffer/size                  520000
trainer/num train calls             259000
trainer/QF1 Loss                        13.5853
trainer/QF2 Loss                        13.3447
trainer/Policy Loss                    566.68
trainer/Q1 Predictions Mean           -566.843
trainer/Q1 Predictions Std              37.8425
trainer/Q1 Predictions Max            -393.649
trainer/Q1 Predictions Min            -632.75
trainer/Q2 Predictions Mean           -566.903
trainer/Q2 Predictions Std              37.8699
trainer/Q2 Predictions Max            -393.749
trainer/Q2 Predictions Min            -634.164
trainer/Q Targets Mean                -569.456
trainer/Q Targets Std                   38.2701
trainer/Q Targets Max                 -395.781
trainer/Q Targets Min                 -634.219
trainer/Log Pis Mean                     2.37558
trainer/Log Pis Std                      2.41896
trainer/Log Pis Max                      7.74163
trainer/Log Pis Min                     -3.67
trainer/policy/mean Mean                -0.340711
trainer/policy/mean Std                  0.758928
trainer/policy/mean Max                  0.990591
trainer/policy/mean Min                 -0.992523
trainer/policy/normal/std Mean           0.594415
trainer/policy/normal/std Std            0.118605
trainer/policy/normal/std Max            0.850728
trainer/policy/normal/std Min            0.439599
trainer/policy/normal/log_std Mean      -0.539901
trainer/policy/normal/log_std Std        0.198273
trainer/policy/normal/log_std Max       -0.161663
trainer/policy/normal/log_std Min       -0.821892
trainer/Alpha                            0.0321648
trainer/Alpha Loss                       1.29081
exploration/num steps total         520000
exploration/num paths total           2600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -4.94479
exploration/Rewards Std                  1.02433
exploration/Rewards Max                 -3.13011
exploration/Rewards Min                 -6.142
exploration/Returns Mean              -988.957
exploration/Returns Std                180.405
exploration/Returns Max               -667.749
exploration/Returns Min              -1165.46
exploration/Actions Mean                -0.24759
exploration/Actions Std                  0.832113
exploration/Actions Max                  0.998458
exploration/Actions Min                 -0.999782
exploration/Num Paths                   10
exploration/Average Returns           -988.957
evaluation/num steps total               1.24942e+06
evaluation/num paths total            6216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74833
evaluation/Rewards Std                   0.273414
evaluation/Rewards Max                  -4.95151
evaluation/Rewards Min                  -6.14161
evaluation/Returns Mean              -1155.42
evaluation/Returns Std                  46.5462
evaluation/Returns Max               -1041.09
evaluation/Returns Min               -1214.06
evaluation/Actions Mean                 -0.231843
evaluation/Actions Std                   0.850767
evaluation/Actions Max                   0.976932
evaluation/Actions Min                  -0.984773
evaluation/Num Paths                    24
evaluation/Average Returns           -1155.42
time/data storing (s)                    0.0289292
time/evaluation sampling (s)            15.4258
time/exploration sampling (s)            6.5987
time/logging (s)                         0.275253
time/sac training (s)                   23.8997
time/saving (s)                          0.230393
time/training (s)                        0.00014775
time/epoch (s)                          46.4589
time/total (s)                       22684.6
Epoch                                  258
----------------------------------  ----------------
2020-11-09 19:49:37.982349 EST | [tabular_active_search_neg_entropy_2020_11_09_13_18_43_0000--s-0] Epoch 259 finished
----------------------------------  ----------------
replay_buffer/size                  522000
trainer/num train calls             260000
trainer/QF1 Loss                        43.1627
trainer/QF2 Loss                        42.2915
trainer/Policy Loss                    564.774
trainer/Q1 Predictions Mean           -564.825
trainer/Q1 Predictions Std              44.4251
trainer/Q1 Predictions Max            -375.897
trainer/Q1 Predictions Min            -640.649
trainer/Q2 Predictions Mean           -564.801
trainer/Q2 Predictions Std              44.4054
trainer/Q2 Predictions Max            -375.923
trainer/Q2 Predictions Min            -641.597
trainer/Q Targets Mean                -566.828
trainer/Q Targets Std                   44.8418
trainer/Q Targets Max                 -377.749
trainer/Q Targets Min                 -635.708
trainer/Log Pis Mean                     2.02677
trainer/Log Pis Std                      1.96649
trainer/Log Pis Max                      5.60451
trainer/Log Pis Min                     -4.23756
trainer/policy/mean Mean                 0.0257158
trainer/policy/mean Std                  0.853132
trainer/policy/mean Max                  0.995595
trainer/policy/mean Min                 -0.977319
trainer/policy/normal/std Mean           0.562726
trainer/policy/normal/std Std            0.0385541
trainer/policy/normal/std Max            0.719093
trainer/policy/normal/std Min            0.475508
trainer/policy/normal/log_std Mean      -0.577323
trainer/policy/normal/log_std Std        0.0688761
trainer/policy/normal/log_std Max       -0.329765
trainer/policy/normal/log_std Min       -0.743372
trainer/Alpha                            0.0317507
trainer/Alpha Loss                       0.0923526
exploration/num steps total         522000
exploration/num paths total           2610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -5.7175
exploration/Rewards Std                  0.856152
exploration/Rewards Max                 -3.27571
exploration/Rewards Min                 -6.14179
exploration/Returns Mean             -1143.5
exploration/Returns Std                155.435
exploration/Returns Max               -708.867
exploration/Returns Min              -1224.51
exploration/Actions Mean                -0.00298062
exploration/Actions Std                  0.828669
exploration/Actions Max                  0.999441
exploration/Actions Min                 -0.998392
exploration/Num Paths                   10
exploration/Average Returns          -1143.5
evaluation/num steps total               1.25424e+06
evaluation/num paths total            6240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89074
evaluation/Rewards Std                   0.673419
evaluation/Rewards Max                  -3.39129
evaluation/Rewards Min                  -6.14202
evaluation/Returns Mean              -1184.04
evaluation/Returns Std                 123.7
evaluation/Returns Max                -706.1
evaluation/Returns Min               -1232.41
evaluation/Actions Mean                  0.0189619
evaluation/Actions Std                   0.785742
evaluation/Actions Max                   0.98388
evaluation/Actions Min                  -0.950083
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.04
time/data storing (s)                    0.0355001
time/evaluation sampling (s)            18.2617
time/exploration sampling (s)            7.79236
time/logging (s)                         0.115524
time/sac training (s)                   19.7066
time/saving (s)                          0.110348
time/training (s)                        0.000146186
time/epoch (s)                          46.0222
time/total (s)                       23258.4
Epoch                                  259
----------------------------------  ----------------
