2020-11-08 12:02:53.386655 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 0 finished
----------------------------------  --------------
replay_buffer/size                  2000
trainer/num train calls             1000
trainer/QF1 Loss                       2.31206
trainer/QF2 Loss                       2.31038
trainer/Policy Loss                   -1.33104
trainer/Q1 Predictions Mean           -0.000263711
trainer/Q1 Predictions Std             0.000206117
trainer/Q1 Predictions Max             8.97527e-05
trainer/Q1 Predictions Min            -0.000794205
trainer/Q2 Predictions Mean            0.000296199
trainer/Q2 Predictions Std             0.000110614
trainer/Q2 Predictions Max             0.000529427
trainer/Q2 Predictions Min             6.38518e-05
trainer/Q Targets Mean                 1.48628
trainer/Q Targets Std                  0.319766
trainer/Q Targets Max                  2.02162
trainer/Q Targets Min                  0.695617
trainer/Log Pis Mean                  -1.33135
trainer/Log Pis Std                    0.304073
trainer/Log Pis Max                   -0.5816
trainer/Log Pis Min                   -1.83744
trainer/policy/mean Mean              -9.67397e-07
trainer/policy/mean Std                6.58038e-06
trainer/policy/mean Max                1.80259e-05
trainer/policy/mean Min               -2.65461e-05
trainer/policy/normal/std Mean         1.00003
trainer/policy/normal/std Std          0.000800796
trainer/policy/normal/std Max          1.00084
trainer/policy/normal/std Min          0.999216
trainer/policy/normal/log_std Mean     2.99437e-05
trainer/policy/normal/log_std Std      0.000800772
trainer/policy/normal/log_std Max      0.000838405
trainer/policy/normal/log_std Min     -0.000784765
trainer/Alpha                          1
trainer/Alpha Loss                    -0
exploration/num steps total         2000
exploration/num paths total           10
exploration/path length Mean         200
exploration/path length Std            2
exploration/path length Max          201
exploration/path length Min          196
exploration/Rewards Mean               0.118956
exploration/Rewards Std                0.00631784
exploration/Rewards Max                0.127159
exploration/Rewards Min                0.0951312
exploration/Returns Mean              23.7913
exploration/Returns Std                0.826597
exploration/Returns Max               24.8549
exploration/Returns Min               22.7806
exploration/Actions Mean               0.019181
exploration/Actions Std                0.617501
exploration/Actions Max                0.997586
exploration/Actions Min               -0.998658
exploration/Num Paths                  5
exploration/Average Returns           23.7913
evaluation/num steps total          4824
evaluation/num paths total            24
evaluation/path length Mean          201
evaluation/path length Std             0
evaluation/path length Max           201
evaluation/path length Min           201
evaluation/Rewards Mean                0.115549
evaluation/Rewards Std                 0.0116113
evaluation/Rewards Max                 0.127662
evaluation/Rewards Min                 0.0905987
evaluation/Returns Mean               23.2254
evaluation/Returns Std                 2.32094
evaluation/Returns Max                25.079
evaluation/Returns Min                18.5385
evaluation/Actions Mean               -1.22286e-06
evaluation/Actions Std                 4.55851e-06
evaluation/Actions Max                 6.54525e-06
evaluation/Actions Min                -1.9064e-05
evaluation/Num Paths                  24
evaluation/Average Returns            23.2254
time/data storing (s)                  0.0216809
time/evaluation sampling (s)          60.5443
time/exploration sampling (s)         11.7512
time/logging (s)                       0.0225213
time/sac training (s)                 18.3243
time/saving (s)                        0.0446878
time/training (s)                      0.000136949
time/epoch (s)                        90.7088
time/total (s)                       104.979
Epoch                                  0
----------------------------------  --------------
2020-11-08 12:04:24.123388 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 1 finished
----------------------------------  --------------
replay_buffer/size                  3000
trainer/num train calls             2000
trainer/QF1 Loss                       0.106489
trainer/QF2 Loss                       0.105696
trainer/Policy Loss                   -6.1058
trainer/Q1 Predictions Mean            5.09434
trainer/Q1 Predictions Std             0.0851148
trainer/Q1 Predictions Max             5.29488
trainer/Q1 Predictions Min             4.66559
trainer/Q2 Predictions Mean            5.08869
trainer/Q2 Predictions Std             0.0807508
trainer/Q2 Predictions Max             5.25562
trainer/Q2 Predictions Min             4.6883
trainer/Q Targets Mean                 5.06303
trainer/Q Targets Std                  0.335959
trainer/Q Targets Max                  5.7688
trainer/Q Targets Min                  0.118339
trainer/Log Pis Mean                  -1.37847
trainer/Log Pis Std                    0.210262
trainer/Log Pis Max                   -1.04312
trainer/Log Pis Min                   -2.84412
trainer/policy/mean Mean               0.00295155
trainer/policy/mean Std                0.00481544
trainer/policy/mean Max                0.00808851
trainer/policy/mean Min               -0.00204319
trainer/policy/normal/std Mean         0.886426
trainer/policy/normal/std Std          0.00376304
trainer/policy/normal/std Max          0.896486
trainer/policy/normal/std Min          0.878818
trainer/policy/normal/log_std Mean    -0.120566
trainer/policy/normal/log_std Std      0.00424391
trainer/policy/normal/log_std Max     -0.109272
trainer/policy/normal/log_std Min     -0.129177
trainer/Alpha                          0.740625
trainer/Alpha Loss                    -1.01442
exploration/num steps total         3000
exploration/num paths total           15
exploration/path length Mean         200
exploration/path length Std            2
exploration/path length Max          201
exploration/path length Min          196
exploration/Rewards Mean               0.108623
exploration/Rewards Std                0.016175
exploration/Rewards Max                0.12867
exploration/Rewards Min                0.0727763
exploration/Returns Mean              21.7245
exploration/Returns Std                2.73179
exploration/Returns Max               25.2755
exploration/Returns Min               17.52
exploration/Actions Mean               0.000359084
exploration/Actions Std                0.595457
exploration/Actions Max                0.998094
exploration/Actions Min               -0.992226
exploration/Num Paths                  5
exploration/Average Returns           21.7245
evaluation/num steps total          9648
evaluation/num paths total            48
evaluation/path length Mean          201
evaluation/path length Std             0
evaluation/path length Max           201
evaluation/path length Min           201
evaluation/Rewards Mean                0.120785
evaluation/Rewards Std                 0.0059624
evaluation/Rewards Max                 0.124813
evaluation/Rewards Min                 0.092302
evaluation/Returns Mean               24.2778
evaluation/Returns Std                 1.18629
evaluation/Returns Max                24.739
evaluation/Returns Min                18.7202
evaluation/Actions Mean                0.00295374
evaluation/Actions Std                 0.00481867
evaluation/Actions Max                 0.00779327
evaluation/Actions Min                -0.0018674
evaluation/Num Paths                  24
evaluation/Average Returns            24.2778
time/data storing (s)                  0.0161714
time/evaluation sampling (s)          59.4788
time/exploration sampling (s)         12.2217
time/logging (s)                       0.0226315
time/sac training (s)                 17.6725
time/saving (s)                        0.0322977
time/training (s)                      0.000139917
time/epoch (s)                        89.4442
time/total (s)                       195.687
Epoch                                  1
----------------------------------  --------------
2020-11-08 12:05:54.077447 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 2 finished
----------------------------------  ---------------
replay_buffer/size                   4000
trainer/num train calls              3000
trainer/QF1 Loss                        0.0105562
trainer/QF2 Loss                        0.00968919
trainer/Policy Loss                    -9.98136
trainer/Q1 Predictions Mean             9.24252
trainer/Q1 Predictions Std              0.348144
trainer/Q1 Predictions Max             10.5828
trainer/Q1 Predictions Min              7.62425
trainer/Q2 Predictions Mean             9.23822
trainer/Q2 Predictions Std              0.338144
trainer/Q2 Predictions Max             10.4739
trainer/Q2 Predictions Min              7.6638
trainer/Q Targets Mean                  9.24092
trainer/Q Targets Std                   0.29524
trainer/Q Targets Max                  10.3788
trainer/Q Targets Min                   7.90792
trainer/Log Pis Mean                   -1.36706
trainer/Log Pis Std                     0.164529
trainer/Log Pis Max                    -1.0237
trainer/Log Pis Min                    -2.40662
trainer/policy/mean Mean                0.00382211
trainer/policy/mean Std                 0.0021867
trainer/policy/mean Max                 0.00635976
trainer/policy/mean Min                 0.00150193
trainer/policy/normal/std Mean          0.887416
trainer/policy/normal/std Std           0.00192003
trainer/policy/normal/std Max           0.893141
trainer/policy/normal/std Min           0.880243
trainer/policy/normal/log_std Mean     -0.119444
trainer/policy/normal/log_std Std       0.00216343
trainer/policy/normal/log_std Max      -0.113011
trainer/policy/normal/log_std Min      -0.127557
trainer/Alpha                           0.548639
trainer/Alpha Loss                     -2.0213
exploration/num steps total          4000
exploration/num paths total            20
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.121999
exploration/Rewards Std                 0.00316063
exploration/Rewards Max                 0.128002
exploration/Rewards Min                 0.115149
exploration/Returns Mean               24.3998
exploration/Returns Std                 0.360308
exploration/Returns Max                24.9342
exploration/Returns Min                23.9152
exploration/Actions Mean               -0.00939023
exploration/Actions Std                 0.595155
exploration/Actions Max                 0.991124
exploration/Actions Min                -0.992615
exploration/Num Paths                   5
exploration/Average Returns            24.3998
evaluation/num steps total          14472
evaluation/num paths total             72
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.119208
evaluation/Rewards Std                  0.00803355
evaluation/Rewards Max                  0.125127
evaluation/Rewards Min                  0.0897706
evaluation/Returns Mean                23.9608
evaluation/Returns Std                  1.60132
evaluation/Returns Max                 24.8149
evaluation/Returns Min                 18.5768
evaluation/Actions Mean                 0.00379916
evaluation/Actions Std                  0.00218249
evaluation/Actions Max                  0.00610826
evaluation/Actions Min                  0.00156085
evaluation/Num Paths                   24
evaluation/Average Returns             23.9608
time/data storing (s)                   0.0180406
time/evaluation sampling (s)           59.1762
time/exploration sampling (s)          12.2541
time/logging (s)                        0.0219161
time/sac training (s)                  17.1543
time/saving (s)                         0.0285622
time/training (s)                       0.000147058
time/epoch (s)                         88.6534
time/total (s)                        285.611
Epoch                                   2
----------------------------------  ---------------
2020-11-08 12:07:23.967553 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 3 finished
----------------------------------  ---------------
replay_buffer/size                   5000
trainer/num train calls              4000
trainer/QF1 Loss                        1.0967
trainer/QF2 Loss                        1.09536
trainer/Policy Loss                   -12.971
trainer/Q1 Predictions Mean            12.4242
trainer/Q1 Predictions Std              0.515587
trainer/Q1 Predictions Max             13.6154
trainer/Q1 Predictions Min             10.4133
trainer/Q2 Predictions Mean            12.4228
trainer/Q2 Predictions Std              0.514631
trainer/Q2 Predictions Max             13.6163
trainer/Q2 Predictions Min             10.4276
trainer/Q Targets Mean                 12.316
trainer/Q Targets Std                   1.1844
trainer/Q Targets Max                  13.5842
trainer/Q Targets Min                   0.116704
trainer/Log Pis Mean                   -1.36133
trainer/Log Pis Std                     0.173499
trainer/Log Pis Max                    -0.974964
trainer/Log Pis Min                    -2.05555
trainer/policy/mean Mean               -0.00342369
trainer/policy/mean Std                 0.00297568
trainer/policy/mean Max                -0.000371754
trainer/policy/mean Min                -0.00710994
trainer/policy/normal/std Mean          0.896926
trainer/policy/normal/std Std           0.00595835
trainer/policy/normal/std Max           0.908379
trainer/policy/normal/std Min           0.87936
trainer/policy/normal/log_std Mean     -0.108804
trainer/policy/normal/log_std Std       0.00664799
trainer/policy/normal/log_std Max      -0.0960934
trainer/policy/normal/log_std Min      -0.128561
trainer/Alpha                           0.406447
trainer/Alpha Loss                     -3.02621
exploration/num steps total          5000
exploration/num paths total            25
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.120349
exploration/Rewards Std                 0.00407489
exploration/Rewards Max                 0.12564
exploration/Rewards Min                 0.10307
exploration/Returns Mean               24.0698
exploration/Returns Std                 0.409175
exploration/Returns Max                24.6705
exploration/Returns Min                23.4371
exploration/Actions Mean               -0.0169391
exploration/Actions Std                 0.601732
exploration/Actions Max                 0.992042
exploration/Actions Min                -0.996315
exploration/Num Paths                   5
exploration/Average Returns            24.0698
evaluation/num steps total          19296
evaluation/num paths total             96
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.118745
evaluation/Rewards Std                  0.00818614
evaluation/Rewards Max                  0.124878
evaluation/Rewards Min                  0.0885623
evaluation/Returns Mean                23.8677
evaluation/Returns Std                  1.63221
evaluation/Returns Max                 24.7264
evaluation/Returns Min                 18.2063
evaluation/Actions Mean                -0.00339922
evaluation/Actions Std                  0.00295383
evaluation/Actions Max                 -0.000424908
evaluation/Actions Min                 -0.00659836
evaluation/Num Paths                   24
evaluation/Average Returns             23.8677
time/data storing (s)                   0.0182357
time/evaluation sampling (s)           59.9561
time/exploration sampling (s)          12.081
time/logging (s)                        0.0335169
time/sac training (s)                  16.504
time/saving (s)                         0.035824
time/training (s)                       0.000154845
time/epoch (s)                         88.6288
time/total (s)                        375.485
Epoch                                   3
----------------------------------  ---------------
2020-11-08 12:08:52.316340 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 4 finished
----------------------------------  ---------------
replay_buffer/size                   6000
trainer/num train calls              5000
trainer/QF1 Loss                        0.0207598
trainer/QF2 Loss                        0.0209634
trainer/Policy Loss                   -15.0429
trainer/Q1 Predictions Mean            14.638
trainer/Q1 Predictions Std              0.801431
trainer/Q1 Predictions Max             16.2687
trainer/Q1 Predictions Min             12.3583
trainer/Q2 Predictions Mean            14.6391
trainer/Q2 Predictions Std              0.801406
trainer/Q2 Predictions Max             16.2623
trainer/Q2 Predictions Min             12.3438
trainer/Q Targets Mean                 14.6637
trainer/Q Targets Std                   0.772186
trainer/Q Targets Max                  16.3085
trainer/Q Targets Min                  12.42
trainer/Log Pis Mean                   -1.36202
trainer/Log Pis Std                     0.190751
trainer/Log Pis Max                    -0.906075
trainer/Log Pis Min                    -1.87046
trainer/policy/mean Mean               -0.000304976
trainer/policy/mean Std                 0.00689045
trainer/policy/mean Max                 0.00752286
trainer/policy/mean Min                -0.00792606
trainer/policy/normal/std Mean          0.918727
trainer/policy/normal/std Std           0.00310771
trainer/policy/normal/std Max           0.929033
trainer/policy/normal/std Min           0.90668
trainer/policy/normal/log_std Mean     -0.084772
trainer/policy/normal/log_std Std       0.00338556
trainer/policy/normal/log_std Max      -0.0736107
trainer/policy/normal/log_std Min      -0.0979653
trainer/Alpha                           0.301125
trainer/Alpha Loss                     -4.0352
exploration/num steps total          6000
exploration/num paths total            30
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.0982207
exploration/Rewards Std                 0.0187257
exploration/Rewards Max                 0.123357
exploration/Rewards Min                 0.0578801
exploration/Returns Mean               19.6441
exploration/Returns Std                 3.2464
exploration/Returns Max                23.865
exploration/Returns Min                14.9221
exploration/Actions Mean               -0.0026603
exploration/Actions Std                 0.60182
exploration/Actions Max                 0.996814
exploration/Actions Min                -0.99559
exploration/Num Paths                   5
exploration/Average Returns            19.6441
evaluation/num steps total          24120
evaluation/num paths total            120
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.11884
evaluation/Rewards Std                  0.00821147
evaluation/Rewards Max                  0.126276
evaluation/Rewards Min                  0.0898084
evaluation/Returns Mean                23.8869
evaluation/Returns Std                  1.6271
evaluation/Returns Max                 24.7855
evaluation/Returns Min                 18.4629
evaluation/Actions Mean                -0.000302792
evaluation/Actions Std                  0.00690634
evaluation/Actions Max                  0.00701201
evaluation/Actions Min                 -0.00755964
evaluation/Num Paths                   24
evaluation/Average Returns             23.8869
time/data storing (s)                   0.0184761
time/evaluation sampling (s)           58.4624
time/exploration sampling (s)          11.8629
time/logging (s)                        0.0279592
time/sac training (s)                  16.6439
time/saving (s)                         0.0290444
time/training (s)                       0.000142906
time/epoch (s)                         87.0448
time/total (s)                        463.799
Epoch                                   4
----------------------------------  ---------------
2020-11-08 12:10:19.934785 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 5 finished
----------------------------------  ---------------
replay_buffer/size                   7000
trainer/num train calls              6000
trainer/QF1 Loss                        0.0192497
trainer/QF2 Loss                        0.0192593
trainer/Policy Loss                   -16.3256
trainer/Q1 Predictions Mean            16.0274
trainer/Q1 Predictions Std              1.00916
trainer/Q1 Predictions Max             19.4043
trainer/Q1 Predictions Min             10.8381
trainer/Q2 Predictions Mean            16.0312
trainer/Q2 Predictions Std              1.00866
trainer/Q2 Predictions Max             19.5295
trainer/Q2 Predictions Min             10.9196
trainer/Q Targets Mean                 16.0751
trainer/Q Targets Std                   0.954946
trainer/Q Targets Max                  19.3052
trainer/Q Targets Min                  11.0658
trainer/Log Pis Mean                   -1.31808
trainer/Log Pis Std                     0.21771
trainer/Log Pis Max                    -0.807583
trainer/Log Pis Min                    -1.71998
trainer/policy/mean Mean               -0.0165462
trainer/policy/mean Std                 0.00246074
trainer/policy/mean Max                -0.0121384
trainer/policy/mean Min                -0.023501
trainer/policy/normal/std Mean          0.941819
trainer/policy/normal/std Std           0.00511357
trainer/policy/normal/std Max           0.954816
trainer/policy/normal/std Min           0.918752
trainer/policy/normal/log_std Mean     -0.0599569
trainer/policy/normal/log_std Std       0.00543775
trainer/policy/normal/log_std Max      -0.0462369
trainer/policy/normal/log_std Min      -0.0847386
trainer/Alpha                           0.223134
trainer/Alpha Loss                     -4.97706
exploration/num steps total          7000
exploration/num paths total            35
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.11262
exploration/Rewards Std                 0.0123775
exploration/Rewards Max                 0.125081
exploration/Rewards Min                 0.0648743
exploration/Returns Mean               22.524
exploration/Returns Std                 0.957451
exploration/Returns Max                23.5269
exploration/Returns Min                21.2116
exploration/Actions Mean                0.000945565
exploration/Actions Std                 0.611796
exploration/Actions Max                 0.998882
exploration/Actions Min                -0.995252
exploration/Num Paths                   5
exploration/Average Returns            22.524
evaluation/num steps total          28944
evaluation/num paths total            144
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.121573
evaluation/Rewards Std                  0.00229472
evaluation/Rewards Max                  0.128142
evaluation/Rewards Min                  0.114822
evaluation/Returns Mean                24.4362
evaluation/Returns Std                  0.394608
evaluation/Returns Max                 25.1926
evaluation/Returns Min                 23.5993
evaluation/Actions Mean                -0.0166723
evaluation/Actions Std                  0.00234361
evaluation/Actions Max                 -0.0138679
evaluation/Actions Min                 -0.0198523
evaluation/Num Paths                   24
evaluation/Average Returns             24.4362
time/data storing (s)                   0.0239865
time/evaluation sampling (s)           57.5146
time/exploration sampling (s)          11.9665
time/logging (s)                        0.021009
time/sac training (s)                  16.7508
time/saving (s)                         0.0283935
time/training (s)                       0.000151091
time/epoch (s)                         86.3054
time/total (s)                        551.382
Epoch                                   5
----------------------------------  ---------------
2020-11-08 12:11:48.373185 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 6 finished
----------------------------------  --------------
replay_buffer/size                   8000
trainer/num train calls              7000
trainer/QF1 Loss                        0.0255487
trainer/QF2 Loss                        0.0252386
trainer/Policy Loss                   -17.2612
trainer/Q1 Predictions Mean            17.0417
trainer/Q1 Predictions Std              1.11628
trainer/Q1 Predictions Max             19.7722
trainer/Q1 Predictions Min             11.7747
trainer/Q2 Predictions Mean            17.0402
trainer/Q2 Predictions Std              1.11417
trainer/Q2 Predictions Max             19.8228
trainer/Q2 Predictions Min             11.8546
trainer/Q Targets Mean                 17.0975
trainer/Q Targets Std                   1.08475
trainer/Q Targets Max                  19.7407
trainer/Q Targets Min                  12.128
trainer/Log Pis Mean                   -1.3589
trainer/Log Pis Std                     0.269282
trainer/Log Pis Max                    -0.700192
trainer/Log Pis Min                    -1.90021
trainer/policy/mean Mean               -0.0232239
trainer/policy/mean Std                 0.0171421
trainer/policy/mean Max                -0.00341418
trainer/policy/mean Min                -0.0507782
trainer/policy/normal/std Mean          0.967857
trainer/policy/normal/std Std           0.00694576
trainer/policy/normal/std Max           0.982754
trainer/policy/normal/std Min           0.931484
trainer/policy/normal/log_std Mean     -0.0326968
trainer/policy/normal/log_std Std       0.00719881
trainer/policy/normal/log_std Max      -0.0173969
trainer/policy/normal/log_std Min      -0.0709758
trainer/Alpha                           0.165396
trainer/Alpha Loss                     -6.04406
exploration/num steps total          8000
exploration/num paths total            40
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.115775
exploration/Rewards Std                 0.00693833
exploration/Rewards Max                 0.124894
exploration/Rewards Min                 0.0967801
exploration/Returns Mean               23.155
exploration/Returns Std                 1.04253
exploration/Returns Max                23.889
exploration/Returns Min                21.0989
exploration/Actions Mean               -0.00696182
exploration/Actions Std                 0.625629
exploration/Actions Max                 0.997376
exploration/Actions Min                -0.998193
exploration/Num Paths                   5
exploration/Average Returns            23.155
evaluation/num steps total          33768
evaluation/num paths total            168
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.120235
evaluation/Rewards Std                  0.00574058
evaluation/Rewards Max                  0.125979
evaluation/Rewards Min                  0.0933221
evaluation/Returns Mean                24.1672
evaluation/Returns Std                  1.12716
evaluation/Returns Max                 24.9398
evaluation/Returns Min                 18.9883
evaluation/Actions Mean                -0.0237558
evaluation/Actions Std                  0.0171786
evaluation/Actions Max                 -0.00647124
evaluation/Actions Min                 -0.0414925
evaluation/Num Paths                   24
evaluation/Average Returns             24.1672
time/data storing (s)                   0.0191724
time/evaluation sampling (s)           57.6109
time/exploration sampling (s)          11.7082
time/logging (s)                        0.0289089
time/sac training (s)                  17.6936
time/saving (s)                         0.0292436
time/training (s)                       0.00014444
time/epoch (s)                         87.0902
time/total (s)                        639.799
Epoch                                   6
----------------------------------  --------------
2020-11-08 12:13:19.668796 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 7 finished
----------------------------------  ---------------
replay_buffer/size                   9000
trainer/num train calls              8000
trainer/QF1 Loss                        1.23153
trainer/QF2 Loss                        1.23733
trainer/Policy Loss                   -18.0492
trainer/Q1 Predictions Mean            17.8856
trainer/Q1 Predictions Std              1.42443
trainer/Q1 Predictions Max             22.0379
trainer/Q1 Predictions Min             10.8347
trainer/Q2 Predictions Mean            17.8905
trainer/Q2 Predictions Std              1.42291
trainer/Q2 Predictions Max             22.1008
trainer/Q2 Predictions Min             10.8959
trainer/Q Targets Mean                 17.8676
trainer/Q Targets Std                   2.02628
trainer/Q Targets Max                  21.9437
trainer/Q Targets Min                   0.0730971
trainer/Log Pis Mean                   -1.30091
trainer/Log Pis Std                     0.372191
trainer/Log Pis Max                    -0.239648
trainer/Log Pis Min                    -1.89503
trainer/policy/mean Mean               -0.00806521
trainer/policy/mean Std                 0.0486169
trainer/policy/mean Max                 0.0459856
trainer/policy/mean Min                -0.0607781
trainer/policy/normal/std Mean          1.02094
trainer/policy/normal/std Std           0.0118481
trainer/policy/normal/std Max           1.03887
trainer/policy/normal/std Min           0.974808
trainer/policy/normal/log_std Mean      0.0206524
trainer/policy/normal/log_std Std       0.0116683
trainer/policy/normal/log_std Max       0.0381361
trainer/policy/normal/log_std Min      -0.0255147
trainer/Alpha                           0.12265
trainer/Alpha Loss                     -6.9267
exploration/num steps total          9000
exploration/num paths total            45
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.121363
exploration/Rewards Std                 0.0033742
exploration/Rewards Max                 0.127396
exploration/Rewards Min                 0.108787
exploration/Returns Mean               24.2727
exploration/Returns Std                 0.535454
exploration/Returns Max                25.2227
exploration/Returns Min                23.7409
exploration/Actions Mean                0.0128697
exploration/Actions Std                 0.637105
exploration/Actions Max                 0.997767
exploration/Actions Min                -0.996163
exploration/Num Paths                   5
exploration/Average Returns            24.2727
evaluation/num steps total          38592
evaluation/num paths total            192
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.120639
evaluation/Rewards Std                  0.00587779
evaluation/Rewards Max                  0.127347
evaluation/Rewards Min                  0.0918719
evaluation/Returns Mean                24.2485
evaluation/Returns Std                  1.16245
evaluation/Returns Max                 24.9376
evaluation/Returns Min                 18.7687
evaluation/Actions Mean                -0.00800685
evaluation/Actions Std                  0.0485237
evaluation/Actions Max                  0.0443785
evaluation/Actions Min                 -0.0595489
evaluation/Num Paths                   24
evaluation/Average Returns             24.2485
time/data storing (s)                   0.0193418
time/evaluation sampling (s)           59.7336
time/exploration sampling (s)          12.2749
time/logging (s)                        0.0221017
time/sac training (s)                  17.8402
time/saving (s)                         0.0296921
time/training (s)                       0.000141063
time/epoch (s)                         89.9201
time/total (s)                        731.058
Epoch                                   7
----------------------------------  ---------------
2020-11-08 12:14:49.524392 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 8 finished
----------------------------------  ---------------
replay_buffer/size                  10000
trainer/num train calls              9000
trainer/QF1 Loss                        1.19148
trainer/QF2 Loss                        1.18784
trainer/Policy Loss                   -18.4039
trainer/Q1 Predictions Mean            18.2886
trainer/Q1 Predictions Std              1.39879
trainer/Q1 Predictions Max             22.584
trainer/Q1 Predictions Min             12.5857
trainer/Q2 Predictions Mean            18.288
trainer/Q2 Predictions Std              1.39277
trainer/Q2 Predictions Max             22.5851
trainer/Q2 Predictions Min             12.636
trainer/Q Targets Mean                 18.318
trainer/Q Targets Std                   1.77774
trainer/Q Targets Max                  22.6338
trainer/Q Targets Min                   0.1176
trainer/Log Pis Mean                   -1.23123
trainer/Log Pis Std                     0.526348
trainer/Log Pis Max                     0.677468
trainer/Log Pis Min                    -2.14962
trainer/policy/mean Mean                0.0388467
trainer/policy/mean Std                 0.187983
trainer/policy/mean Max                 0.345486
trainer/policy/mean Min                -0.278845
trainer/policy/normal/std Mean          1.08094
trainer/policy/normal/std Std           0.0538914
trainer/policy/normal/std Max           1.19219
trainer/policy/normal/std Min           0.877274
trainer/policy/normal/log_std Mean      0.0765381
trainer/policy/normal/log_std Std       0.0513375
trainer/policy/normal/log_std Max       0.175794
trainer/policy/normal/log_std Min      -0.130936
trainer/Alpha                           0.0911414
trainer/Alpha Loss                     -7.7399
exploration/num steps total         10000
exploration/num paths total            50
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.1158
exploration/Rewards Std                 0.0048555
exploration/Rewards Max                 0.12626
exploration/Rewards Min                 0.102639
exploration/Returns Mean               23.1599
exploration/Returns Std                 0.593413
exploration/Returns Max                24.2805
exploration/Returns Min                22.6464
exploration/Actions Mean                0.0147518
exploration/Actions Std                 0.654914
exploration/Actions Max                 0.999627
exploration/Actions Min                -0.999593
exploration/Num Paths                   5
exploration/Average Returns            23.1599
evaluation/num steps total          43416
evaluation/num paths total            216
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.121794
evaluation/Rewards Std                  0.00195903
evaluation/Rewards Max                  0.125289
evaluation/Rewards Min                  0.113062
evaluation/Returns Mean                24.4806
evaluation/Returns Std                  0.342597
evaluation/Returns Max                 24.8432
evaluation/Returns Min                 23.3162
evaluation/Actions Mean                 0.0387383
evaluation/Actions Std                  0.143269
evaluation/Actions Max                  0.238903
evaluation/Actions Min                 -0.179528
evaluation/Num Paths                   24
evaluation/Average Returns             24.4806
time/data storing (s)                   0.0220931
time/evaluation sampling (s)           59.456
time/exploration sampling (s)          11.6674
time/logging (s)                        0.022629
time/sac training (s)                  17.2974
time/saving (s)                         0.0298433
time/training (s)                       0.000146581
time/epoch (s)                         88.4955
time/total (s)                        820.885
Epoch                                   8
----------------------------------  ---------------
2020-11-08 12:16:19.779456 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 9 finished
----------------------------------  ---------------
replay_buffer/size                  11000
trainer/num train calls             10000
trainer/QF1 Loss                        3.8151
trainer/QF2 Loss                        3.82831
trainer/Policy Loss                   -18.7715
trainer/Q1 Predictions Mean            18.6812
trainer/Q1 Predictions Std              1.44716
trainer/Q1 Predictions Max             22.0758
trainer/Q1 Predictions Min             13.9568
trainer/Q2 Predictions Mean            18.675
trainer/Q2 Predictions Std              1.44326
trainer/Q2 Predictions Max             22.0184
trainer/Q2 Predictions Min             13.9457
trainer/Q Targets Mean                 18.5024
trainer/Q Targets Std                   2.45039
trainer/Q Targets Max                  22.3338
trainer/Q Targets Min                   0.119204
trainer/Log Pis Mean                   -1.09199
trainer/Log Pis Std                     0.824703
trainer/Log Pis Max                     2.69671
trainer/Log Pis Min                    -2.35924
trainer/policy/mean Mean               -0.000695306
trainer/policy/mean Std                 0.255627
trainer/policy/mean Max                 0.495749
trainer/policy/mean Min                -0.54968
trainer/policy/normal/std Mean          1.13545
trainer/policy/normal/std Std           0.0843023
trainer/policy/normal/std Max           1.33008
trainer/policy/normal/std Min           0.85075
trainer/policy/normal/log_std Mean      0.124205
trainer/policy/normal/log_std Std       0.0756596
trainer/policy/normal/log_std Max       0.285241
trainer/policy/normal/log_std Min      -0.161637
trainer/Alpha                           0.0678868
trainer/Alpha Loss                     -8.31717
exploration/num steps total         11000
exploration/num paths total            55
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.112931
exploration/Rewards Std                 0.0165232
exploration/Rewards Max                 0.123921
exploration/Rewards Min                 0.04684
exploration/Returns Mean               22.5863
exploration/Returns Std                 2.51975
exploration/Returns Max                24.6119
exploration/Returns Min                17.7049
exploration/Actions Mean               -0.0198967
exploration/Actions Std                 0.663901
exploration/Actions Max                 0.999214
exploration/Actions Min                -0.998699
exploration/Num Paths                   5
exploration/Average Returns            22.5863
evaluation/num steps total          48240
evaluation/num paths total            240
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.118225
evaluation/Rewards Std                  0.00978296
evaluation/Rewards Max                  0.126069
evaluation/Rewards Min                  0.0874991
evaluation/Returns Mean                23.7632
evaluation/Returns Std                  1.95623
evaluation/Returns Max                 24.9182
evaluation/Returns Min                 18.1808
evaluation/Actions Mean                 0.00406232
evaluation/Actions Std                  0.125485
evaluation/Actions Max                  0.157254
evaluation/Actions Min                 -0.1564
evaluation/Num Paths                   24
evaluation/Average Returns             23.7632
time/data storing (s)                   0.0200701
time/evaluation sampling (s)           59.8191
time/exploration sampling (s)          11.6381
time/logging (s)                        0.028555
time/sac training (s)                  17.3603
time/saving (s)                         0.0294533
time/training (s)                       0.000122151
time/epoch (s)                         88.8958
time/total (s)                        911.117
Epoch                                   9
----------------------------------  ---------------
2020-11-08 12:17:47.605574 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 10 finished
----------------------------------  ---------------
replay_buffer/size                  12000
trainer/num train calls             11000
trainer/QF1 Loss                        1.38652
trainer/QF2 Loss                        1.39878
trainer/Policy Loss                   -18.7155
trainer/Q1 Predictions Mean            18.6458
trainer/Q1 Predictions Std              1.70861
trainer/Q1 Predictions Max             24.1243
trainer/Q1 Predictions Min             13.6484
trainer/Q2 Predictions Mean            18.6459
trainer/Q2 Predictions Std              1.71105
trainer/Q2 Predictions Max             24.2253
trainer/Q2 Predictions Min             13.58
trainer/Q Targets Mean                 18.6859
trainer/Q Targets Std                   2.03831
trainer/Q Targets Max                  24.1287
trainer/Q Targets Min                   0.112715
trainer/Log Pis Mean                   -0.907682
trainer/Log Pis Std                     1.04522
trainer/Log Pis Max                     2.11804
trainer/Log Pis Min                    -2.83941
trainer/policy/mean Mean                0.136162
trainer/policy/mean Std                 0.372988
trainer/policy/mean Max                 0.785986
trainer/policy/mean Min                -0.742464
trainer/policy/normal/std Mean          1.23445
trainer/policy/normal/std Std           0.158865
trainer/policy/normal/std Max           1.69384
trainer/policy/normal/std Min           0.764302
trainer/policy/normal/log_std Mean      0.202129
trainer/policy/normal/log_std Std       0.131636
trainer/policy/normal/log_std Max       0.526999
trainer/policy/normal/log_std Min      -0.268792
trainer/Alpha                           0.0507506
trainer/Alpha Loss                     -8.66731
exploration/num steps total         12000
exploration/num paths total            60
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.115305
exploration/Rewards Std                 0.0157366
exploration/Rewards Max                 0.127068
exploration/Rewards Min                 0.0660175
exploration/Returns Mean               23.0611
exploration/Returns Std                 2.58176
exploration/Returns Max                25.2396
exploration/Returns Min                17.9926
exploration/Actions Mean                0.113981
exploration/Actions Std                 0.689525
exploration/Actions Max                 0.999846
exploration/Actions Min                -0.999918
exploration/Num Paths                   5
exploration/Average Returns            23.0611
evaluation/num steps total          53064
evaluation/num paths total            264
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.119694
evaluation/Rewards Std                  0.00847191
evaluation/Rewards Max                  0.127219
evaluation/Rewards Min                  0.0890116
evaluation/Returns Mean                24.0586
evaluation/Returns Std                  1.69224
evaluation/Returns Max                 24.9282
evaluation/Returns Min                 18.2209
evaluation/Actions Mean                 0.145726
evaluation/Actions Std                  0.215586
evaluation/Actions Max                  0.379834
evaluation/Actions Min                 -0.1145
evaluation/Num Paths                   24
evaluation/Average Returns             24.0586
time/data storing (s)                   0.0176656
time/evaluation sampling (s)           57.2691
time/exploration sampling (s)          11.6042
time/logging (s)                        0.0234618
time/sac training (s)                  17.5116
time/saving (s)                         0.0322309
time/training (s)                       0.000159281
time/epoch (s)                         86.4583
time/total (s)                        998.909
Epoch                                  10
----------------------------------  ---------------
2020-11-08 12:19:17.475873 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 11 finished
----------------------------------  ---------------
replay_buffer/size                  13000
trainer/num train calls             12000
trainer/QF1 Loss                        1.95952
trainer/QF2 Loss                        1.97668
trainer/Policy Loss                   -18.6998
trainer/Q1 Predictions Mean            18.6443
trainer/Q1 Predictions Std              1.77778
trainer/Q1 Predictions Max             23.1188
trainer/Q1 Predictions Min             11.2655
trainer/Q2 Predictions Mean            18.6362
trainer/Q2 Predictions Std              1.77896
trainer/Q2 Predictions Max             23.1326
trainer/Q2 Predictions Min             11.3795
trainer/Q Targets Mean                 18.5849
trainer/Q Targets Std                   2.40092
trainer/Q Targets Max                  23.436
trainer/Q Targets Min                   0.118339
trainer/Log Pis Mean                   -0.858018
trainer/Log Pis Std                     1.29556
trainer/Log Pis Max                     8.48956
trainer/Log Pis Min                    -3.40316
trainer/policy/mean Mean                0.183352
trainer/policy/mean Std                 0.386877
trainer/policy/mean Max                 0.961274
trainer/policy/mean Min                -0.913747
trainer/policy/normal/std Mean          1.23089
trainer/policy/normal/std Std           0.188827
trainer/policy/normal/std Max           2.30318
trainer/policy/normal/std Min           0.731387
trainer/policy/normal/log_std Mean      0.195934
trainer/policy/normal/log_std Std       0.154584
trainer/policy/normal/log_std Max       0.83429
trainer/policy/normal/log_std Min      -0.312812
trainer/Alpha                           0.0382467
trainer/Alpha Loss                     -9.32771
exploration/num steps total         13000
exploration/num paths total            65
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.10999
exploration/Rewards Std                 0.017435
exploration/Rewards Max                 0.1238
exploration/Rewards Min                 0.0615845
exploration/Returns Mean               21.9981
exploration/Returns Std                 2.33983
exploration/Returns Max                24.386
exploration/Returns Min                17.6618
exploration/Actions Mean                0.147982
exploration/Actions Std                 0.679287
exploration/Actions Max                 0.999843
exploration/Actions Min                -0.999767
exploration/Num Paths                   5
exploration/Average Returns            21.9981
evaluation/num steps total          57888
evaluation/num paths total            288
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.118855
evaluation/Rewards Std                  0.0087244
evaluation/Rewards Max                  0.129118
evaluation/Rewards Min                  0.0915536
evaluation/Returns Mean                23.8898
evaluation/Returns Std                  1.68321
evaluation/Returns Max                 25.1904
evaluation/Returns Min                 18.6531
evaluation/Actions Mean                 0.212113
evaluation/Actions Std                  0.156784
evaluation/Actions Max                  0.853886
evaluation/Actions Min                 -0.248419
evaluation/Num Paths                   24
evaluation/Average Returns             23.8898
time/data storing (s)                   0.0172368
time/evaluation sampling (s)           59.3779
time/exploration sampling (s)          11.567
time/logging (s)                        0.0220611
time/sac training (s)                  17.4745
time/saving (s)                         0.030042
time/training (s)                       0.000180971
time/epoch (s)                         88.4889
time/total (s)                       1088.75
Epoch                                  11
----------------------------------  ---------------
2020-11-08 12:20:45.145490 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 12 finished
----------------------------------  ---------------
replay_buffer/size                  14000
trainer/num train calls             13000
trainer/QF1 Loss                        0.158877
trainer/QF2 Loss                        0.143323
trainer/Policy Loss                   -19.288
trainer/Q1 Predictions Mean            19.2535
trainer/Q1 Predictions Std              3.68646
trainer/Q1 Predictions Max             49.7613
trainer/Q1 Predictions Min             11.3159
trainer/Q2 Predictions Mean            19.2519
trainer/Q2 Predictions Std              3.66532
trainer/Q2 Predictions Max             49.6761
trainer/Q2 Predictions Min             11.4353
trainer/Q Targets Mean                 19.1503
trainer/Q Targets Std                   3.49853
trainer/Q Targets Max                  47.9945
trainer/Q Targets Min                  12.3419
trainer/Log Pis Mean                   -0.552409
trainer/Log Pis Std                     1.66884
trainer/Log Pis Max                    11.256
trainer/Log Pis Min                    -2.81418
trainer/policy/mean Mean                0.237088
trainer/policy/mean Std                 0.391657
trainer/policy/mean Max                 0.992204
trainer/policy/mean Min                -0.977357
trainer/policy/normal/std Mean          1.29677
trainer/policy/normal/std Std           0.309536
trainer/policy/normal/std Max           3.59215
trainer/policy/normal/std Min           0.811457
trainer/policy/normal/log_std Mean      0.237501
trainer/policy/normal/log_std Std       0.201822
trainer/policy/normal/log_std Max       1.27875
trainer/policy/normal/log_std Min      -0.208924
trainer/Alpha                           0.029043
trainer/Alpha Loss                     -9.03292
exploration/num steps total         14000
exploration/num paths total            70
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.104317
exploration/Rewards Std                 0.02295
exploration/Rewards Max                 0.127675
exploration/Rewards Min                 0.04972
exploration/Returns Mean               20.8634
exploration/Returns Std                 3.52538
exploration/Returns Max                24.7824
exploration/Returns Min                16.149
exploration/Actions Mean                0.140812
exploration/Actions Std                 0.702842
exploration/Actions Max                 0.99993
exploration/Actions Min                -0.999862
exploration/Num Paths                   5
exploration/Average Returns            20.8634
evaluation/num steps total          62712
evaluation/num paths total            312
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.121099
evaluation/Rewards Std                  0.00597441
evaluation/Rewards Max                  0.127822
evaluation/Rewards Min                  0.0934963
evaluation/Returns Mean                24.3408
evaluation/Returns Std                  1.17918
evaluation/Returns Max                 25.2097
evaluation/Returns Min                 18.9033
evaluation/Actions Mean                 0.241002
evaluation/Actions Std                  0.0554311
evaluation/Actions Max                  0.521819
evaluation/Actions Min                  0.0956342
evaluation/Num Paths                   24
evaluation/Average Returns             24.3408
time/data storing (s)                   0.0183785
time/evaluation sampling (s)           57.3225
time/exploration sampling (s)          11.631
time/logging (s)                        0.0241277
time/sac training (s)                  17.2817
time/saving (s)                         0.0327813
time/training (s)                       0.000136914
time/epoch (s)                         86.3106
time/total (s)                       1176.39
Epoch                                  12
----------------------------------  ---------------
2020-11-08 12:22:12.782894 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 13 finished
----------------------------------  ---------------
replay_buffer/size                  15000
trainer/num train calls             14000
trainer/QF1 Loss                        0.97496
trainer/QF2 Loss                        0.97834
trainer/Policy Loss                   -19.1514
trainer/Q1 Predictions Mean            19.1108
trainer/Q1 Predictions Std              2.90924
trainer/Q1 Predictions Max             42.8618
trainer/Q1 Predictions Min              8.01957
trainer/Q2 Predictions Mean            19.1037
trainer/Q2 Predictions Std              2.90665
trainer/Q2 Predictions Max             42.855
trainer/Q2 Predictions Min              8.04088
trainer/Q Targets Mean                 18.9751
trainer/Q Targets Std                   3.27259
trainer/Q Targets Max                  42.9938
trainer/Q Targets Min                   0.0720128
trainer/Log Pis Mean                   -0.0374413
trainer/Log Pis Std                     2.35162
trainer/Log Pis Max                    10.5615
trainer/Log Pis Min                    -3.44059
trainer/policy/mean Mean                0.10515
trainer/policy/mean Std                 0.446204
trainer/policy/mean Max                 0.994036
trainer/policy/mean Min                -0.993789
trainer/policy/normal/std Mean          1.41658
trainer/policy/normal/std Std           0.524798
trainer/policy/normal/std Max           4.36374
trainer/policy/normal/std Min           0.588506
trainer/policy/normal/log_std Mean      0.293081
trainer/policy/normal/log_std Std       0.321209
trainer/policy/normal/log_std Max       1.47333
trainer/policy/normal/log_std Min      -0.530168
trainer/Alpha                           0.022068
trainer/Alpha Loss                     -7.77004
exploration/num steps total         15000
exploration/num paths total            75
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.111227
exploration/Rewards Std                 0.0118428
exploration/Rewards Max                 0.124164
exploration/Rewards Min                 0.0746513
exploration/Returns Mean               22.2453
exploration/Returns Std                 1.97571
exploration/Returns Max                24.3087
exploration/Returns Min                18.6904
exploration/Actions Mean                0.122217
exploration/Actions Std                 0.708198
exploration/Actions Max                 0.999977
exploration/Actions Min                -0.999873
exploration/Num Paths                   5
exploration/Average Returns            22.2453
evaluation/num steps total          67536
evaluation/num paths total            336
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.118636
evaluation/Rewards Std                  0.010265
evaluation/Rewards Max                  0.129972
evaluation/Rewards Min                  0.0887457
evaluation/Returns Mean                23.8459
evaluation/Returns Std                  2.05653
evaluation/Returns Max                 25.4558
evaluation/Returns Min                 18.2245
evaluation/Actions Mean                 0.0201038
evaluation/Actions Std                  0.299019
evaluation/Actions Max                  0.337063
evaluation/Actions Min                 -0.605842
evaluation/Num Paths                   24
evaluation/Average Returns             23.8459
time/data storing (s)                   0.0199365
time/evaluation sampling (s)           57.2708
time/exploration sampling (s)          11.5202
time/logging (s)                        0.0247908
time/sac training (s)                  17.4128
time/saving (s)                         0.0296063
time/training (s)                       0.000146604
time/epoch (s)                         86.2783
time/total (s)                       1263.99
Epoch                                  13
----------------------------------  ---------------
2020-11-08 12:23:40.759630 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 14 finished
----------------------------------  ---------------
replay_buffer/size                  16000
trainer/num train calls             15000
trainer/QF1 Loss                        2.71559
trainer/QF2 Loss                        2.75637
trainer/Policy Loss                   -18.7619
trainer/Q1 Predictions Mean            18.7446
trainer/Q1 Predictions Std              3.13142
trainer/Q1 Predictions Max             44.212
trainer/Q1 Predictions Min             12.9258
trainer/Q2 Predictions Mean            18.7419
trainer/Q2 Predictions Std              3.13406
trainer/Q2 Predictions Max             44.2335
trainer/Q2 Predictions Min             13.123
trainer/Q Targets Mean                 18.8172
trainer/Q Targets Std                   3.55755
trainer/Q Targets Max                  44.2835
trainer/Q Targets Min                   0.112799
trainer/Log Pis Mean                    0.545071
trainer/Log Pis Std                     2.34205
trainer/Log Pis Max                     9.92057
trainer/Log Pis Min                    -5.31732
trainer/policy/mean Mean               -0.410578
trainer/policy/mean Std                 0.443566
trainer/policy/mean Max                 0.993617
trainer/policy/mean Min                -0.995591
trainer/policy/normal/std Mean          1.20084
trainer/policy/normal/std Std           0.635943
trainer/policy/normal/std Max           3.52747
trainer/policy/normal/std Min           0.415209
trainer/policy/normal/log_std Mean      0.0494888
trainer/policy/normal/log_std Std       0.513858
trainer/policy/normal/log_std Max       1.26058
trainer/policy/normal/log_std Min      -0.878973
trainer/Alpha                           0.0170814
trainer/Alpha Loss                     -5.92122
exploration/num steps total         16000
exploration/num paths total            80
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.118908
exploration/Rewards Std                 0.00456497
exploration/Rewards Max                 0.124184
exploration/Rewards Min                 0.107688
exploration/Returns Mean               23.7816
exploration/Returns Std                 0.919789
exploration/Returns Max                24.6918
exploration/Returns Min                22.06
exploration/Actions Mean               -0.444758
exploration/Actions Std                 0.683709
exploration/Actions Max                 0.999959
exploration/Actions Min                -0.999998
exploration/Num Paths                   5
exploration/Average Returns            23.7816
evaluation/num steps total          72360
evaluation/num paths total            360
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.120245
evaluation/Rewards Std                  0.00576932
evaluation/Rewards Max                  0.127519
evaluation/Rewards Min                  0.0934485
evaluation/Returns Mean                24.1692
evaluation/Returns Std                  1.12408
evaluation/Returns Max                 25.0557
evaluation/Returns Min                 19.1354
evaluation/Actions Mean                -0.550775
evaluation/Actions Std                  0.285802
evaluation/Actions Max                 -0.193479
evaluation/Actions Min                 -0.973735
evaluation/Num Paths                   24
evaluation/Average Returns             24.1692
time/data storing (s)                   0.0185453
time/evaluation sampling (s)           57.9042
time/exploration sampling (s)          11.5324
time/logging (s)                        0.0287715
time/sac training (s)                  17.1037
time/saving (s)                         0.0363203
time/training (s)                       0.000139642
time/epoch (s)                         86.6241
time/total (s)                       1351.95
Epoch                                  14
----------------------------------  ---------------
2020-11-08 12:25:07.216167 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 15 finished
----------------------------------  ---------------
replay_buffer/size                  17000
trainer/num train calls             16000
trainer/QF1 Loss                        2.14751
trainer/QF2 Loss                        2.17977
trainer/Policy Loss                   -18.7635
trainer/Q1 Predictions Mean            18.7405
trainer/Q1 Predictions Std              3.30453
trainer/Q1 Predictions Max             44.4002
trainer/Q1 Predictions Min             10.8846
trainer/Q2 Predictions Mean            18.7399
trainer/Q2 Predictions Std              3.30495
trainer/Q2 Predictions Max             44.4548
trainer/Q2 Predictions Min             10.9468
trainer/Q Targets Mean                 18.7274
trainer/Q Targets Std                   3.69591
trainer/Q Targets Max                  44.7664
trainer/Q Targets Min                   0.0469027
trainer/Log Pis Mean                    1.27247
trainer/Log Pis Std                     3.2006
trainer/Log Pis Max                    14.9375
trainer/Log Pis Min                    -4.71076
trainer/policy/mean Mean                0.437769
trainer/policy/mean Std                 0.639387
trainer/policy/mean Max                 0.999624
trainer/policy/mean Min                -0.994725
trainer/policy/normal/std Mean          1.08358
trainer/policy/normal/std Std           0.510192
trainer/policy/normal/std Max           4.47815
trainer/policy/normal/std Min           0.585158
trainer/policy/normal/log_std Mean      0.012129
trainer/policy/normal/log_std Std       0.333293
trainer/policy/normal/log_std Max       1.49921
trainer/policy/normal/log_std Min      -0.535873
trainer/Alpha                           0.0144369
trainer/Alpha Loss                     -3.08323
exploration/num steps total         17000
exploration/num paths total            85
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.118798
exploration/Rewards Std                 0.0060044
exploration/Rewards Max                 0.126498
exploration/Rewards Min                 0.0882106
exploration/Returns Mean               23.7596
exploration/Returns Std                 1.0113
exploration/Returns Max                24.4592
exploration/Returns Min                21.7652
exploration/Actions Mean                0.453763
exploration/Actions Std                 0.654091
exploration/Actions Max                 0.999844
exploration/Actions Min                -0.998926
exploration/Num Paths                   5
exploration/Average Returns            23.7596
evaluation/num steps total          77184
evaluation/num paths total            384
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.120117
evaluation/Rewards Std                  0.00605274
evaluation/Rewards Max                  0.127691
evaluation/Rewards Min                  0.092373
evaluation/Returns Mean                24.1436
evaluation/Returns Std                  1.20036
evaluation/Returns Max                 25.2875
evaluation/Returns Min                 18.597
evaluation/Actions Mean                 0.497151
evaluation/Actions Std                  0.5148
evaluation/Actions Max                  0.962468
evaluation/Actions Min                 -0.672125
evaluation/Num Paths                   24
evaluation/Average Returns             24.1436
time/data storing (s)                   0.0175739
time/evaluation sampling (s)           56.5206
time/exploration sampling (s)          11.4204
time/logging (s)                        0.0231147
time/sac training (s)                  17.0823
time/saving (s)                         0.029347
time/training (s)                       0.000125242
time/epoch (s)                         85.0934
time/total (s)                       1438.37
Epoch                                  15
----------------------------------  ---------------
2020-11-08 12:26:33.900127 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 16 finished
----------------------------------  ---------------
replay_buffer/size                  18000
trainer/num train calls             17000
trainer/QF1 Loss                        3.21184
trainer/QF2 Loss                        3.19773
trainer/Policy Loss                   -18.6453
trainer/Q1 Predictions Mean            18.6476
trainer/Q1 Predictions Std              2.02774
trainer/Q1 Predictions Max             35.4446
trainer/Q1 Predictions Min             13.2572
trainer/Q2 Predictions Mean            18.6459
trainer/Q2 Predictions Std              2.02399
trainer/Q2 Predictions Max             35.4057
trainer/Q2 Predictions Min             13.2597
trainer/Q Targets Mean                 18.4999
trainer/Q Targets Std                   2.84818
trainer/Q Targets Max                  36.9949
trainer/Q Targets Min                   0.0857969
trainer/Log Pis Mean                    2.65393
trainer/Log Pis Std                     2.34332
trainer/Log Pis Max                     9.75248
trainer/Log Pis Min                    -2.8894
trainer/policy/mean Mean                0.857162
trainer/policy/mean Std                 0.336182
trainer/policy/mean Max                 0.998444
trainer/policy/mean Min                -0.990722
trainer/policy/normal/std Mean          0.780831
trainer/policy/normal/std Std           0.276825
trainer/policy/normal/std Max           3.05064
trainer/policy/normal/std Min           0.452832
trainer/policy/normal/log_std Mean     -0.283878
trainer/policy/normal/log_std Std       0.24083
trainer/policy/normal/log_std Max       1.11535
trainer/policy/normal/log_std Min      -0.792234
trainer/Alpha                           0.015945
trainer/Alpha Loss                      2.70637
exploration/num steps total         18000
exploration/num paths total            90
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.117836
exploration/Rewards Std                 0.00889276
exploration/Rewards Max                 0.124292
exploration/Rewards Min                 0.0914628
exploration/Returns Mean               23.5672
exploration/Returns Std                 1.36881
exploration/Returns Max                24.4369
exploration/Returns Min                20.8724
exploration/Actions Mean                0.757373
exploration/Actions Std                 0.511937
exploration/Actions Max                 0.999981
exploration/Actions Min                -0.999996
exploration/Num Paths                   5
exploration/Average Returns            23.5672
evaluation/num steps total          82008
evaluation/num paths total            408
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.114241
evaluation/Rewards Std                  0.0169492
evaluation/Rewards Max                  0.125933
evaluation/Rewards Min                  0.0631687
evaluation/Returns Mean                22.9624
evaluation/Returns Std                  3.24512
evaluation/Returns Max                 25.2896
evaluation/Returns Min                 13.9441
evaluation/Actions Mean                 0.848882
evaluation/Actions Std                  0.356674
evaluation/Actions Max                  0.9926
evaluation/Actions Min                 -0.868989
evaluation/Num Paths                   24
evaluation/Average Returns             22.9624
time/data storing (s)                   0.0181545
time/evaluation sampling (s)           56.1837
time/exploration sampling (s)          11.3667
time/logging (s)                        0.0275298
time/sac training (s)                  17.6942
time/saving (s)                         0.0376932
time/training (s)                       0.000162241
time/epoch (s)                         85.3281
time/total (s)                       1525.02
Epoch                                  16
----------------------------------  ---------------
2020-11-08 12:28:01.342710 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 17 finished
----------------------------------  ---------------
replay_buffer/size                  19000
trainer/num train calls             18000
trainer/QF1 Loss                        0.0494745
trainer/QF2 Loss                        0.0492917
trainer/Policy Loss                   -18.633
trainer/Q1 Predictions Mean            18.5511
trainer/Q1 Predictions Std              2.01077
trainer/Q1 Predictions Max             27.0626
trainer/Q1 Predictions Min             13.106
trainer/Q2 Predictions Mean            18.5536
trainer/Q2 Predictions Std              2.00809
trainer/Q2 Predictions Max             27.1019
trainer/Q2 Predictions Min             13.0044
trainer/Q Targets Mean                 18.6639
trainer/Q Targets Std                   1.97563
trainer/Q Targets Max                  27.127
trainer/Q Targets Min                  13.3572
trainer/Log Pis Mean                    1.40394
trainer/Log Pis Std                     2.64277
trainer/Log Pis Max                    10.0834
trainer/Log Pis Min                    -4.97828
trainer/policy/mean Mean                0.528687
trainer/policy/mean Std                 0.612302
trainer/policy/mean Max                 0.99767
trainer/policy/mean Min                -0.991935
trainer/policy/normal/std Mean          0.891966
trainer/policy/normal/std Std           0.322363
trainer/policy/normal/std Max           3.00467
trainer/policy/normal/std Min           0.452618
trainer/policy/normal/log_std Mean     -0.162112
trainer/policy/normal/log_std Std       0.289589
trainer/policy/normal/log_std Max       1.10017
trainer/policy/normal/log_std Min      -0.792707
trainer/Alpha                           0.0135591
trainer/Alpha Loss                     -2.56349
exploration/num steps total         19000
exploration/num paths total            95
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.112645
exploration/Rewards Std                 0.0116173
exploration/Rewards Max                 0.12331
exploration/Rewards Min                 0.0879083
exploration/Returns Mean               22.529
exploration/Returns Std                 2.19034
exploration/Returns Max                24.3424
exploration/Returns Min                18.3651
exploration/Actions Mean                0.173892
exploration/Actions Std                 0.799059
exploration/Actions Max                 0.999906
exploration/Actions Min                -0.999007
exploration/Num Paths                   5
exploration/Average Returns            22.529
evaluation/num steps total          86832
evaluation/num paths total            432
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.122265
evaluation/Rewards Std                  0.00148644
evaluation/Rewards Max                  0.125594
evaluation/Rewards Min                  0.113858
evaluation/Returns Mean                24.5752
evaluation/Returns Std                  0.254048
evaluation/Returns Max                 24.9478
evaluation/Returns Min                 23.6829
evaluation/Actions Mean                 0.138596
evaluation/Actions Std                  0.677241
evaluation/Actions Max                  0.957675
evaluation/Actions Min                 -0.85071
evaluation/Num Paths                   24
evaluation/Average Returns             24.5752
time/data storing (s)                   0.0179183
time/evaluation sampling (s)           56.3529
time/exploration sampling (s)          11.4023
time/logging (s)                        0.0277592
time/sac training (s)                  18.246
time/saving (s)                         0.0285349
time/training (s)                       0.000150868
time/epoch (s)                         86.0755
time/total (s)                       1612.44
Epoch                                  17
----------------------------------  ---------------
2020-11-08 12:29:27.841550 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 18 finished
----------------------------------  ---------------
replay_buffer/size                  20000
trainer/num train calls             19000
trainer/QF1 Loss                        0.0586396
trainer/QF2 Loss                        0.0576686
trainer/Policy Loss                   -18.496
trainer/Q1 Predictions Mean            18.4587
trainer/Q1 Predictions Std              2.15111
trainer/Q1 Predictions Max             33.4191
trainer/Q1 Predictions Min             12.8773
trainer/Q2 Predictions Mean            18.4461
trainer/Q2 Predictions Std              2.14464
trainer/Q2 Predictions Max             33.3624
trainer/Q2 Predictions Min             12.8861
trainer/Q Targets Mean                 18.5466
trainer/Q Targets Std                   2.16836
trainer/Q Targets Max                  34.9781
trainer/Q Targets Min                  13.4668
trainer/Log Pis Mean                    1.56894
trainer/Log Pis Std                     2.76225
trainer/Log Pis Max                    10.6312
trainer/Log Pis Min                    -5.82671
trainer/policy/mean Mean                0.417707
trainer/policy/mean Std                 0.703982
trainer/policy/mean Max                 0.998283
trainer/policy/mean Min                -0.994983
trainer/policy/normal/std Mean          0.961539
trainer/policy/normal/std Std           0.418092
trainer/policy/normal/std Max           3.99876
trainer/policy/normal/std Min           0.455696
trainer/policy/normal/log_std Mean     -0.107756
trainer/policy/normal/log_std Std       0.346729
trainer/policy/normal/log_std Max       1.38598
trainer/policy/normal/log_std Min      -0.78593
trainer/Alpha                           0.0111017
trainer/Alpha Loss                     -1.94004
exploration/num steps total         20000
exploration/num paths total           100
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.120641
exploration/Rewards Std                 0.00462087
exploration/Rewards Max                 0.125571
exploration/Rewards Min                 0.105699
exploration/Returns Mean               24.1282
exploration/Returns Std                 0.658475
exploration/Returns Max                24.9177
exploration/Returns Min                23.221
exploration/Actions Mean                0.180566
exploration/Actions Std                 0.750124
exploration/Actions Max                 0.999956
exploration/Actions Min                -0.997217
exploration/Num Paths                   5
exploration/Average Returns            24.1282
evaluation/num steps total          91656
evaluation/num paths total            456
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.119856
evaluation/Rewards Std                  0.00802718
evaluation/Rewards Max                  0.12505
evaluation/Rewards Min                  0.0930132
evaluation/Returns Mean                24.0911
evaluation/Returns Std                  1.60484
evaluation/Returns Max                 24.8721
evaluation/Returns Min                 18.77
evaluation/Actions Mean                 0.0335227
evaluation/Actions Std                  0.711208
evaluation/Actions Max                  0.89978
evaluation/Actions Min                 -0.829844
evaluation/Num Paths                   24
evaluation/Average Returns             24.0911
time/data storing (s)                   0.016308
time/evaluation sampling (s)           56.4039
time/exploration sampling (s)          11.3502
time/logging (s)                        0.0234638
time/sac training (s)                  17.2886
time/saving (s)                         0.0314794
time/training (s)                       0.000143971
time/epoch (s)                         85.1141
time/total (s)                       1698.9
Epoch                                  18
----------------------------------  ---------------
2020-11-08 12:30:54.516118 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 19 finished
----------------------------------  ---------------
replay_buffer/size                  21000
trainer/num train calls             20000
trainer/QF1 Loss                        3.5456
trainer/QF2 Loss                        3.54377
trainer/Policy Loss                   -18.65
trainer/Q1 Predictions Mean            18.6274
trainer/Q1 Predictions Std              2.70373
trainer/Q1 Predictions Max             35.0331
trainer/Q1 Predictions Min             12.6401
trainer/Q2 Predictions Mean            18.6209
trainer/Q2 Predictions Std              2.71076
trainer/Q2 Predictions Max             35.0211
trainer/Q2 Predictions Min             12.6101
trainer/Q Targets Mean                 18.4716
trainer/Q Targets Std                   3.32159
trainer/Q Targets Max                  34.5926
trainer/Q Targets Min                   0.0746513
trainer/Log Pis Mean                    2.16409
trainer/Log Pis Std                     2.53923
trainer/Log Pis Max                    13.6769
trainer/Log Pis Min                    -4.52824
trainer/policy/mean Mean                0.519749
trainer/policy/mean Std                 0.697209
trainer/policy/mean Max                 0.999711
trainer/policy/mean Min                -0.993141
trainer/policy/normal/std Mean          0.665664
trainer/policy/normal/std Std           0.113096
trainer/policy/normal/std Max           0.949151
trainer/policy/normal/std Min           0.335797
trainer/policy/normal/log_std Mean     -0.42203
trainer/policy/normal/log_std Std       0.176258
trainer/policy/normal/log_std Max      -0.0521873
trainer/policy/normal/log_std Min      -1.09125
trainer/Alpha                           0.0113329
trainer/Alpha Loss                      0.735154
exploration/num steps total         21000
exploration/num paths total           105
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean                0.115904
exploration/Rewards Std                 0.0118845
exploration/Rewards Max                 0.123933
exploration/Rewards Min                 0.0920226
exploration/Returns Mean               23.1809
exploration/Returns Std                 2.35399
exploration/Returns Max                24.7649
exploration/Returns Min                18.5941
exploration/Actions Mean                0.329008
exploration/Actions Std                 0.776525
exploration/Actions Max                 0.999925
exploration/Actions Min                -0.997666
exploration/Num Paths                   5
exploration/Average Returns            23.1809
evaluation/num steps total          96480
evaluation/num paths total            480
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                 0.122291
evaluation/Rewards Std                  0.000904004
evaluation/Rewards Max                  0.124035
evaluation/Rewards Min                  0.117085
evaluation/Returns Mean                24.5804
evaluation/Returns Std                  0.140259
evaluation/Returns Max                 24.7479
evaluation/Returns Min                 24.2114
evaluation/Actions Mean                 0.142618
evaluation/Actions Std                  0.823881
evaluation/Actions Max                  0.951554
evaluation/Actions Min                 -0.894671
evaluation/Num Paths                   24
evaluation/Average Returns             24.5804
time/data storing (s)                   0.019068
time/evaluation sampling (s)           56.5491
time/exploration sampling (s)          11.5338
time/logging (s)                        0.022611
time/sac training (s)                  17.1613
time/saving (s)                         0.0397902
time/training (s)                       0.00012983
time/epoch (s)                         85.3258
time/total (s)                       1785.55
Epoch                                  19
----------------------------------  ---------------
2020-11-08 12:32:20.738092 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 20 finished
----------------------------------  ----------------
replay_buffer/size                   22000
trainer/num train calls              21000
trainer/QF1 Loss                         3.87967
trainer/QF2 Loss                         3.88006
trainer/Policy Loss                    -18.3535
trainer/Q1 Predictions Mean             18.3162
trainer/Q1 Predictions Std               2.2158
trainer/Q1 Predictions Max              39.1219
trainer/Q1 Predictions Min               9.81574
trainer/Q2 Predictions Mean             18.3183
trainer/Q2 Predictions Std               2.21591
trainer/Q2 Predictions Max              39.1707
trainer/Q2 Predictions Min               9.83918
trainer/Q Targets Mean                  18.1436
trainer/Q Targets Std                    2.92096
trainer/Q Targets Max                   39.0515
trainer/Q Targets Min                    0.103388
trainer/Log Pis Mean                     1.15129
trainer/Log Pis Std                      2.6367
trainer/Log Pis Max                     11.04
trainer/Log Pis Min                     -4.40133
trainer/policy/mean Mean                 0.319199
trainer/policy/mean Std                  0.729468
trainer/policy/mean Max                  0.998401
trainer/policy/mean Min                 -0.999811
trainer/policy/normal/std Mean           0.907972
trainer/policy/normal/std Std            0.340974
trainer/policy/normal/std Max            2.45776
trainer/policy/normal/std Min            0.315116
trainer/policy/normal/log_std Mean      -0.155774
trainer/policy/normal/log_std Std        0.334545
trainer/policy/normal/log_std Max        0.899251
trainer/policy/normal/log_std Min       -1.15481
trainer/Alpha                            0.00991436
trainer/Alpha Loss                      -3.91577
exploration/num steps total          22000
exploration/num paths total            110
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.122466
exploration/Rewards Std                  0.00232842
exploration/Rewards Max                  0.127257
exploration/Rewards Min                  0.116043
exploration/Returns Mean                24.4932
exploration/Returns Std                  0.445773
exploration/Returns Max                 25.2166
exploration/Returns Min                 24.0287
exploration/Actions Mean                -0.12521
exploration/Actions Std                  0.79326
exploration/Actions Max                  0.99976
exploration/Actions Min                 -0.999261
exploration/Num Paths                    5
exploration/Average Returns             24.4932
evaluation/num steps total          101304
evaluation/num paths total             504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.120185
evaluation/Rewards Std                   0.00801651
evaluation/Rewards Max                   0.125401
evaluation/Rewards Min                   0.0934302
evaluation/Returns Mean                 24.1572
evaluation/Returns Std                   1.60686
evaluation/Returns Max                  24.9923
evaluation/Returns Min                  18.8331
evaluation/Actions Mean                 -0.0571655
evaluation/Actions Std                   0.810276
evaluation/Actions Max                   0.810251
evaluation/Actions Min                  -0.879833
evaluation/Num Paths                    24
evaluation/Average Returns              24.1572
time/data storing (s)                    0.0180712
time/evaluation sampling (s)            56.1541
time/exploration sampling (s)           11.4974
time/logging (s)                         0.0230762
time/sac training (s)                   17.1402
time/saving (s)                          0.030338
time/training (s)                        0.000135596
time/epoch (s)                          84.8634
time/total (s)                        1871.74
Epoch                                   20
----------------------------------  ----------------
2020-11-08 12:33:47.965502 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 21 finished
----------------------------------  ---------------
replay_buffer/size                   23000
trainer/num train calls              22000
trainer/QF1 Loss                         2.58943
trainer/QF2 Loss                         2.5838
trainer/Policy Loss                    -18.4676
trainer/Q1 Predictions Mean             18.4319
trainer/Q1 Predictions Std               2.26948
trainer/Q1 Predictions Max              38.2532
trainer/Q1 Predictions Min              12.4193
trainer/Q2 Predictions Mean             18.4356
trainer/Q2 Predictions Std               2.26961
trainer/Q2 Predictions Max              38.2974
trainer/Q2 Predictions Min              12.4012
trainer/Q Targets Mean                  18.3389
trainer/Q Targets Std                    2.76528
trainer/Q Targets Max                   38.4084
trainer/Q Targets Min                    0.120344
trainer/Log Pis Mean                     1.8173
trainer/Log Pis Std                      3.43844
trainer/Log Pis Max                     13.926
trainer/Log Pis Min                     -4.47484
trainer/policy/mean Mean                 0.336319
trainer/policy/mean Std                  0.76014
trainer/policy/mean Max                  0.999435
trainer/policy/mean Min                 -0.997517
trainer/policy/normal/std Mean           0.929003
trainer/policy/normal/std Std            0.558192
trainer/policy/normal/std Max            4.05036
trainer/policy/normal/std Min            0.302735
trainer/policy/normal/log_std Mean      -0.194636
trainer/policy/normal/log_std Std        0.453281
trainer/policy/normal/log_std Max        1.39881
trainer/policy/normal/log_std Min       -1.1949
trainer/Alpha                            0.00852493
trainer/Alpha Loss                      -0.870517
exploration/num steps total          23000
exploration/num paths total            115
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.122074
exploration/Rewards Std                  0.00205795
exploration/Rewards Max                  0.125897
exploration/Rewards Min                  0.117019
exploration/Returns Mean                24.4149
exploration/Returns Std                  0.416151
exploration/Returns Max                 24.9054
exploration/Returns Min                 23.8866
exploration/Actions Mean                 0.0217948
exploration/Actions Std                  0.808302
exploration/Actions Max                  0.999546
exploration/Actions Min                 -0.999626
exploration/Num Paths                    5
exploration/Average Returns             24.4149
evaluation/num steps total          106128
evaluation/num paths total             528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.122563
evaluation/Rewards Std                   0.00091692
evaluation/Rewards Max                   0.12577
evaluation/Rewards Min                   0.11723
evaluation/Returns Mean                 24.6352
evaluation/Returns Std                   0.147151
evaluation/Returns Max                  25.0103
evaluation/Returns Min                  24.1538
evaluation/Actions Mean                  0.0326157
evaluation/Actions Std                   0.810578
evaluation/Actions Max                   0.906485
evaluation/Actions Min                  -0.907252
evaluation/Num Paths                    24
evaluation/Average Returns              24.6352
time/data storing (s)                    0.0182159
time/evaluation sampling (s)            56.9021
time/exploration sampling (s)           11.4288
time/logging (s)                         0.0286518
time/sac training (s)                   17.4442
time/saving (s)                          0.0299482
time/training (s)                        0.00014585
time/epoch (s)                          85.8521
time/total (s)                        1958.94
Epoch                                   21
----------------------------------  ---------------
2020-11-08 12:35:14.537399 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 22 finished
----------------------------------  ----------------
replay_buffer/size                   24000
trainer/num train calls              23000
trainer/QF1 Loss                         0.0410669
trainer/QF2 Loss                         0.041877
trainer/Policy Loss                    -18.4205
trainer/Q1 Predictions Mean             18.3999
trainer/Q1 Predictions Std               1.85651
trainer/Q1 Predictions Max              32.1304
trainer/Q1 Predictions Min              13.9442
trainer/Q2 Predictions Mean             18.4011
trainer/Q2 Predictions Std               1.8626
trainer/Q2 Predictions Max              32.1728
trainer/Q2 Predictions Min              13.8902
trainer/Q Targets Mean                  18.4118
trainer/Q Targets Std                    1.84108
trainer/Q Targets Max                   32.0359
trainer/Q Targets Min                   14.0447
trainer/Log Pis Mean                     4.69771
trainer/Log Pis Std                      3.09392
trainer/Log Pis Max                     12.6437
trainer/Log Pis Min                     -3.28297
trainer/policy/mean Mean                 0.0233376
trainer/policy/mean Std                  0.953396
trainer/policy/mean Max                  0.999482
trainer/policy/mean Min                 -0.999328
trainer/policy/normal/std Mean           0.707351
trainer/policy/normal/std Std            0.114239
trainer/policy/normal/std Max            1.08434
trainer/policy/normal/std Min            0.3151
trainer/policy/normal/log_std Mean      -0.359723
trainer/policy/normal/log_std Std        0.166546
trainer/policy/normal/log_std Max        0.0809684
trainer/policy/normal/log_std Min       -1.15486
trainer/Alpha                            0.0112989
trainer/Alpha Loss                      12.094
exploration/num steps total          24000
exploration/num paths total            120
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.121563
exploration/Rewards Std                  0.002018
exploration/Rewards Max                  0.125334
exploration/Rewards Min                  0.116143
exploration/Returns Mean                24.3125
exploration/Returns Std                  0.420415
exploration/Returns Max                 25.0001
exploration/Returns Min                 23.8627
exploration/Actions Mean                -0.0212257
exploration/Actions Std                  0.927718
exploration/Actions Max                  0.999635
exploration/Actions Min                 -0.999963
exploration/Num Paths                    5
exploration/Average Returns             24.3125
evaluation/num steps total          110952
evaluation/num paths total             552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117506
evaluation/Rewards Std                   0.0159326
evaluation/Rewards Max                   0.125725
evaluation/Rewards Min                   0.0633333
evaluation/Returns Mean                 23.6187
evaluation/Returns Std                   3.15152
evaluation/Returns Max                  24.5841
evaluation/Returns Min                  13.1472
evaluation/Actions Mean                  0.0792823
evaluation/Actions Std                   0.971882
evaluation/Actions Max                   0.991837
evaluation/Actions Min                  -0.974854
evaluation/Num Paths                    24
evaluation/Average Returns              23.6187
time/data storing (s)                    0.0160521
time/evaluation sampling (s)            56.4025
time/exploration sampling (s)           11.4832
time/logging (s)                         0.0222835
time/sac training (s)                   17.2515
time/saving (s)                          0.031796
time/training (s)                        0.000135044
time/epoch (s)                          85.2074
time/total (s)                        2045.48
Epoch                                   22
----------------------------------  ----------------
2020-11-08 12:36:41.020080 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 23 finished
----------------------------------  ----------------
replay_buffer/size                   25000
trainer/num train calls              24000
trainer/QF1 Loss                         1.37106
trainer/QF2 Loss                         1.36841
trainer/Policy Loss                    -18.2524
trainer/Q1 Predictions Mean             18.2375
trainer/Q1 Predictions Std               1.79634
trainer/Q1 Predictions Max              34.7826
trainer/Q1 Predictions Min              13.9899
trainer/Q2 Predictions Mean             18.2393
trainer/Q2 Predictions Std               1.78686
trainer/Q2 Predictions Max              34.7828
trainer/Q2 Predictions Min              14.0098
trainer/Q Targets Mean                  18.2245
trainer/Q Targets Std                    2.10484
trainer/Q Targets Max                   34.8646
trainer/Q Targets Min                    0.122555
trainer/Log Pis Mean                     1.00579
trainer/Log Pis Std                      3.08128
trainer/Log Pis Max                     13.848
trainer/Log Pis Min                     -4.17296
trainer/policy/mean Mean                 0.0936722
trainer/policy/mean Std                  0.756796
trainer/policy/mean Max                  0.998684
trainer/policy/mean Min                 -0.999236
trainer/policy/normal/std Mean           1.24444
trainer/policy/normal/std Std            0.383252
trainer/policy/normal/std Max            2.88495
trainer/policy/normal/std Min            0.453647
trainer/policy/normal/log_std Mean       0.175658
trainer/policy/normal/log_std Std        0.290197
trainer/policy/normal/log_std Max        1.05951
trainer/policy/normal/log_std Min       -0.790437
trainer/Alpha                            0.0111743
trainer/Alpha Loss                      -4.46809
exploration/num steps total          25000
exploration/num paths total            125
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.11979
exploration/Rewards Std                  0.00364212
exploration/Rewards Max                  0.125683
exploration/Rewards Min                  0.105735
exploration/Returns Mean                23.9581
exploration/Returns Std                  0.410982
exploration/Returns Max                 24.5706
exploration/Returns Min                 23.2864
exploration/Actions Mean                 0.0653854
exploration/Actions Std                  0.764791
exploration/Actions Max                  0.999919
exploration/Actions Min                 -0.999999
exploration/Num Paths                    5
exploration/Average Returns             23.9581
evaluation/num steps total          115776
evaluation/num paths total             576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121564
evaluation/Rewards Std                   0.00583
evaluation/Rewards Max                   0.126081
evaluation/Rewards Min                   0.0933939
evaluation/Returns Mean                 24.4344
evaluation/Returns Std                   1.16811
evaluation/Returns Max                  25.0063
evaluation/Returns Min                  18.8568
evaluation/Actions Mean                  0.0278238
evaluation/Actions Std                   0.646083
evaluation/Actions Max                   0.758041
evaluation/Actions Min                  -0.768738
evaluation/Num Paths                    24
evaluation/Average Returns              24.4344
time/data storing (s)                    0.0170221
time/evaluation sampling (s)            56.3593
time/exploration sampling (s)           11.4473
time/logging (s)                         0.0219698
time/sac training (s)                   17.2533
time/saving (s)                          0.0328006
time/training (s)                        0.000155226
time/epoch (s)                          85.1319
time/total (s)                        2131.93
Epoch                                   23
----------------------------------  ----------------
2020-11-08 12:38:09.296333 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 24 finished
----------------------------------  ----------------
replay_buffer/size                   26000
trainer/num train calls              25000
trainer/QF1 Loss                         0.0480069
trainer/QF2 Loss                         0.0451589
trainer/Policy Loss                    -18.2263
trainer/Q1 Predictions Mean             18.2132
trainer/Q1 Predictions Std               2.03637
trainer/Q1 Predictions Max              31.9637
trainer/Q1 Predictions Min               9.46656
trainer/Q2 Predictions Mean             18.2236
trainer/Q2 Predictions Std               2.02855
trainer/Q2 Predictions Max              31.9802
trainer/Q2 Predictions Min               9.52166
trainer/Q Targets Mean                  18.2179
trainer/Q Targets Std                    2.01118
trainer/Q Targets Max                   31.1758
trainer/Q Targets Min                   10.717
trainer/Log Pis Mean                     0.601819
trainer/Log Pis Std                      2.8841
trainer/Log Pis Max                     12.9784
trainer/Log Pis Min                     -3.26011
trainer/policy/mean Mean                 0.0472758
trainer/policy/mean Std                  0.677445
trainer/policy/mean Max                  0.999871
trainer/policy/mean Min                 -0.999483
trainer/policy/normal/std Mean           1.35055
trainer/policy/normal/std Std            0.462452
trainer/policy/normal/std Max            4.83123
trainer/policy/normal/std Min            0.556201
trainer/policy/normal/log_std Mean       0.250377
trainer/policy/normal/log_std Std        0.311218
trainer/policy/normal/log_std Max        1.5751
trainer/policy/normal/log_std Min       -0.586626
trainer/Alpha                            0.0088336
trainer/Alpha Loss                      -6.61227
exploration/num steps total          26000
exploration/num paths total            130
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.11746
exploration/Rewards Std                  0.00787811
exploration/Rewards Max                  0.125401
exploration/Rewards Min                  0.0962196
exploration/Returns Mean                23.4919
exploration/Returns Std                  1.1948
exploration/Returns Max                 24.7039
exploration/Returns Min                 21.2909
exploration/Actions Mean                 0.0962245
exploration/Actions Std                  0.761435
exploration/Actions Max                  0.999996
exploration/Actions Min                 -0.999995
exploration/Num Paths                    5
exploration/Average Returns             23.4919
evaluation/num steps total          120600
evaluation/num paths total             600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.115812
evaluation/Rewards Std                   0.0114491
evaluation/Rewards Max                   0.12483
evaluation/Rewards Min                   0.0922674
evaluation/Returns Mean                 23.2782
evaluation/Returns Std                   2.29611
evaluation/Returns Max                  24.7339
evaluation/Returns Min                  18.7207
evaluation/Actions Mean                 -0.0023991
evaluation/Actions Std                   0.507073
evaluation/Actions Max                   0.8933
evaluation/Actions Min                  -0.858697
evaluation/Num Paths                    24
evaluation/Average Returns              23.2782
time/data storing (s)                    0.0200268
time/evaluation sampling (s)            56.1306
time/exploration sampling (s)           11.3818
time/logging (s)                         0.0282892
time/sac training (s)                   19.0911
time/saving (s)                          0.0490537
time/training (s)                        0.000133334
time/epoch (s)                          86.7011
time/total (s)                        2220.18
Epoch                                   24
----------------------------------  ----------------
2020-11-08 12:39:26.897516 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 25 finished
----------------------------------  ----------------
replay_buffer/size                   27000
trainer/num train calls              26000
trainer/QF1 Loss                         0.0330024
trainer/QF2 Loss                         0.0335506
trainer/Policy Loss                    -17.9063
trainer/Q1 Predictions Mean             17.901
trainer/Q1 Predictions Std               1.82524
trainer/Q1 Predictions Max              34.1489
trainer/Q1 Predictions Min              14.3903
trainer/Q2 Predictions Mean             17.9012
trainer/Q2 Predictions Std               1.82576
trainer/Q2 Predictions Max              34.1496
trainer/Q2 Predictions Min              14.4918
trainer/Q Targets Mean                  17.9527
trainer/Q Targets Std                    1.79579
trainer/Q Targets Max                   34.2071
trainer/Q Targets Min                   14.6849
trainer/Log Pis Mean                     1.0213
trainer/Log Pis Std                      3.38487
trainer/Log Pis Max                     14.2726
trainer/Log Pis Min                     -3.32888
trainer/policy/mean Mean                -0.138263
trainer/policy/mean Std                  0.655841
trainer/policy/mean Max                  0.999727
trainer/policy/mean Min                 -0.999941
trainer/policy/normal/std Mean           1.55716
trainer/policy/normal/std Std            0.511051
trainer/policy/normal/std Max            4.92096
trainer/policy/normal/std Min            0.3752
trainer/policy/normal/log_std Mean       0.391653
trainer/policy/normal/log_std Std        0.32733
trainer/policy/normal/log_std Max        1.5935
trainer/policy/normal/log_std Min       -0.980295
trainer/Alpha                            0.00678832
trainer/Alpha Loss                      -4.8862
exploration/num steps total          27000
exploration/num paths total            135
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.11131
exploration/Rewards Std                  0.0223819
exploration/Rewards Max                  0.127315
exploration/Rewards Min                  0.0546683
exploration/Returns Mean                22.2619
exploration/Returns Std                  4.27376
exploration/Returns Max                 24.7104
exploration/Returns Min                 13.7247
exploration/Actions Mean                -0.131379
exploration/Actions Std                  0.743928
exploration/Actions Max                  0.999933
exploration/Actions Min                 -0.999998
exploration/Num Paths                    5
exploration/Average Returns             22.2619
evaluation/num steps total          125424
evaluation/num paths total             624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117825
evaluation/Rewards Std                   0.00972821
evaluation/Rewards Max                   0.127089
evaluation/Rewards Min                   0.090611
evaluation/Returns Mean                 23.6828
evaluation/Returns Std                   1.93978
evaluation/Returns Max                  25.0997
evaluation/Returns Min                  18.5102
evaluation/Actions Mean                 -0.251092
evaluation/Actions Std                   0.384622
evaluation/Actions Max                   0.912664
evaluation/Actions Min                  -0.915649
evaluation/Num Paths                    24
evaluation/Average Returns              23.6828
time/data storing (s)                    0.0151133
time/evaluation sampling (s)            50.1751
time/exploration sampling (s)            9.92355
time/logging (s)                         0.0208241
time/sac training (s)                   16.1511
time/saving (s)                          0.0287453
time/training (s)                        0.000142539
time/epoch (s)                          76.3146
time/total (s)                        2297.75
Epoch                                   25
----------------------------------  ----------------
2020-11-08 12:40:45.552206 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 26 finished
----------------------------------  ---------------
replay_buffer/size                   28000
trainer/num train calls              27000
trainer/QF1 Loss                         0.0631832
trainer/QF2 Loss                         0.0603156
trainer/Policy Loss                    -18.0026
trainer/Q1 Predictions Mean             17.9429
trainer/Q1 Predictions Std               1.75046
trainer/Q1 Predictions Max              31.8643
trainer/Q1 Predictions Min              12.1592
trainer/Q2 Predictions Mean             17.9504
trainer/Q2 Predictions Std               1.74715
trainer/Q2 Predictions Max              31.8779
trainer/Q2 Predictions Min              12.158
trainer/Q Targets Mean                  17.9878
trainer/Q Targets Std                    1.76252
trainer/Q Targets Max                   32.0366
trainer/Q Targets Min                   12.85
trainer/Log Pis Mean                     2.29605
trainer/Log Pis Std                      3.97176
trainer/Log Pis Max                     21.6595
trainer/Log Pis Min                     -5.03823
trainer/policy/mean Mean                -0.527493
trainer/policy/mean Std                  0.624363
trainer/policy/mean Max                  0.99971
trainer/policy/mean Min                 -0.999944
trainer/policy/normal/std Mean           1.33441
trainer/policy/normal/std Std            0.947049
trainer/policy/normal/std Max            7.38906
trainer/policy/normal/std Min            0.241535
trainer/policy/normal/log_std Mean       0.11969
trainer/policy/normal/log_std Std        0.55055
trainer/policy/normal/log_std Max        2
trainer/policy/normal/log_std Min       -1.42074
trainer/Alpha                            0.00595937
trainer/Alpha Loss                       1.51663
exploration/num steps total          28000
exploration/num paths total            140
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.107618
exploration/Rewards Std                  0.0142217
exploration/Rewards Max                  0.125985
exploration/Rewards Min                  0.0908488
exploration/Returns Mean                21.5236
exploration/Returns Std                  2.70875
exploration/Returns Max                 24.9295
exploration/Returns Min                 18.5478
exploration/Actions Mean                -0.463501
exploration/Actions Std                  0.756428
exploration/Actions Max                  0.999986
exploration/Actions Min                 -1
exploration/Num Paths                    5
exploration/Average Returns             21.5236
evaluation/num steps total          130248
evaluation/num paths total             648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119112
evaluation/Rewards Std                   0.0052586
evaluation/Rewards Max                   0.12534
evaluation/Rewards Min                   0.103939
evaluation/Returns Mean                 23.9415
evaluation/Returns Std                   0.983354
evaluation/Returns Max                  24.8816
evaluation/Returns Min                  21.3703
evaluation/Actions Mean                 -0.787691
evaluation/Actions Std                   0.185305
evaluation/Actions Max                   0.198761
evaluation/Actions Min                  -0.989727
evaluation/Num Paths                    24
evaluation/Average Returns              23.9415
time/data storing (s)                    0.0153591
time/evaluation sampling (s)            50.7124
time/exploration sampling (s)           10.4469
time/logging (s)                         0.0224738
time/sac training (s)                   16.141
time/saving (s)                          0.0286983
time/training (s)                        0.00013052
time/epoch (s)                          77.367
time/total (s)                        2376.38
Epoch                                   26
----------------------------------  ---------------
2020-11-08 12:42:02.495906 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 27 finished
----------------------------------  ----------------
replay_buffer/size                   29000
trainer/num train calls              28000
trainer/QF1 Loss                         1.27823
trainer/QF2 Loss                         1.27168
trainer/Policy Loss                    -17.8892
trainer/Q1 Predictions Mean             17.8304
trainer/Q1 Predictions Std               1.53984
trainer/Q1 Predictions Max              31.1029
trainer/Q1 Predictions Min              12.2594
trainer/Q2 Predictions Mean             17.8282
trainer/Q2 Predictions Std               1.53471
trainer/Q2 Predictions Max              31.101
trainer/Q2 Predictions Min              12.3806
trainer/Q Targets Mean                  17.7815
trainer/Q Targets Std                    1.8844
trainer/Q Targets Max                   31.2469
trainer/Q Targets Min                    0.118386
trainer/Log Pis Mean                     3.91047
trainer/Log Pis Std                      2.78584
trainer/Log Pis Max                     11.3324
trainer/Log Pis Min                     -3.71751
trainer/policy/mean Mean                -0.795116
trainer/policy/mean Std                  0.480294
trainer/policy/mean Max                  0.997567
trainer/policy/mean Min                 -0.999566
trainer/policy/normal/std Mean           0.617647
trainer/policy/normal/std Std            0.108963
trainer/policy/normal/std Max            1.193
trainer/policy/normal/std Min            0.305047
trainer/policy/normal/log_std Mean      -0.496741
trainer/policy/normal/log_std Std        0.172204
trainer/policy/normal/log_std Max        0.176475
trainer/policy/normal/log_std Min       -1.18729
trainer/Alpha                            0.00904954
trainer/Alpha Loss                       8.98884
exploration/num steps total          29000
exploration/num paths total            145
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.106665
exploration/Rewards Std                  0.0213767
exploration/Rewards Max                  0.12471
exploration/Rewards Min                  0.0535086
exploration/Returns Mean                21.333
exploration/Returns Std                  4.16693
exploration/Returns Max                 24.8369
exploration/Returns Min                 14.5839
exploration/Actions Mean                -0.63009
exploration/Actions Std                  0.68756
exploration/Actions Max                  0.998506
exploration/Actions Min                 -0.999809
exploration/Num Paths                    5
exploration/Average Returns             21.333
evaluation/num steps total          135072
evaluation/num paths total             672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119671
evaluation/Rewards Std                   0.00805281
evaluation/Rewards Max                   0.124716
evaluation/Rewards Min                   0.0933333
evaluation/Returns Mean                 24.0539
evaluation/Returns Std                   1.61847
evaluation/Returns Max                  24.8931
evaluation/Returns Min                  18.7601
evaluation/Actions Mean                 -0.916439
evaluation/Actions Std                   0.279995
evaluation/Actions Max                   0.989363
evaluation/Actions Min                  -0.996792
evaluation/Num Paths                    24
evaluation/Average Returns              24.0539
time/data storing (s)                    0.0156231
time/evaluation sampling (s)            49.21
time/exploration sampling (s)            9.94653
time/logging (s)                         0.0230927
time/sac training (s)                   16.4278
time/saving (s)                          0.0326121
time/training (s)                        0.000126225
time/epoch (s)                          75.6558
time/total (s)                        2453.29
Epoch                                   27
----------------------------------  ----------------
2020-11-08 12:43:19.944291 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 28 finished
----------------------------------  ----------------
replay_buffer/size                   30000
trainer/num train calls              29000
trainer/QF1 Loss                         0.811315
trainer/QF2 Loss                         0.807407
trainer/Policy Loss                    -17.7058
trainer/Q1 Predictions Mean             17.6789
trainer/Q1 Predictions Std               1.52452
trainer/Q1 Predictions Max              22.8042
trainer/Q1 Predictions Min              12.4216
trainer/Q2 Predictions Mean             17.6883
trainer/Q2 Predictions Std               1.53141
trainer/Q2 Predictions Max              22.8106
trainer/Q2 Predictions Min              12.4385
trainer/Q Targets Mean                  17.7187
trainer/Q Targets Std                    1.86532
trainer/Q Targets Max                   22.8134
trainer/Q Targets Min                    0.119204
trainer/Log Pis Mean                     3.18956
trainer/Log Pis Std                      2.78583
trainer/Log Pis Max                     10.196
trainer/Log Pis Min                     -5.57663
trainer/policy/mean Mean                -0.755238
trainer/policy/mean Std                  0.503193
trainer/policy/mean Max                  0.999602
trainer/policy/mean Min                 -0.999559
trainer/policy/normal/std Mean           0.725753
trainer/policy/normal/std Std            0.170459
trainer/policy/normal/std Max            1.56131
trainer/policy/normal/std Min            0.341596
trainer/policy/normal/log_std Mean      -0.345077
trainer/policy/normal/log_std Std        0.217082
trainer/policy/normal/log_std Max        0.445526
trainer/policy/normal/log_std Min       -1.07413
trainer/Alpha                            0.0114667
trainer/Alpha Loss                       5.31532
exploration/num steps total          30000
exploration/num paths total            150
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.111549
exploration/Rewards Std                  0.0169363
exploration/Rewards Max                  0.125761
exploration/Rewards Min                  0.0739294
exploration/Returns Mean                22.3098
exploration/Returns Std                  2.58203
exploration/Returns Max                 24.8739
exploration/Returns Min                 17.6589
exploration/Actions Mean                -0.45465
exploration/Actions Std                  0.766751
exploration/Actions Max                  0.999653
exploration/Actions Min                 -0.999759
exploration/Num Paths                    5
exploration/Average Returns             22.3098
evaluation/num steps total          139896
evaluation/num paths total             696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.120368
evaluation/Rewards Std                   0.00687585
evaluation/Rewards Max                   0.126433
evaluation/Rewards Min                   0.0932363
evaluation/Returns Mean                 24.1939
evaluation/Returns Std                   1.35994
evaluation/Returns Max                  25.0497
evaluation/Returns Min                  18.7417
evaluation/Actions Mean                 -0.839741
evaluation/Actions Std                   0.336158
evaluation/Actions Max                   0.665464
evaluation/Actions Min                  -0.967445
evaluation/Num Paths                    24
evaluation/Average Returns              24.1939
time/data storing (s)                    0.0152706
time/evaluation sampling (s)            49.5752
time/exploration sampling (s)           10.2176
time/logging (s)                         0.0231658
time/sac training (s)                   16.3079
time/saving (s)                          0.0275545
time/training (s)                        0.000157699
time/epoch (s)                          76.1669
time/total (s)                        2530.71
Epoch                                   28
----------------------------------  ----------------
2020-11-08 12:44:36.624238 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 29 finished
----------------------------------  ----------------
replay_buffer/size                   31000
trainer/num train calls              30000
trainer/QF1 Loss                         1.28764
trainer/QF2 Loss                         1.28791
trainer/Policy Loss                    -17.5451
trainer/Q1 Predictions Mean             17.5248
trainer/Q1 Predictions Std               1.67765
trainer/Q1 Predictions Max              26.037
trainer/Q1 Predictions Min              11.2259
trainer/Q2 Predictions Mean             17.5186
trainer/Q2 Predictions Std               1.68424
trainer/Q2 Predictions Max              26.1483
trainer/Q2 Predictions Min              11.2157
trainer/Q Targets Mean                  17.592
trainer/Q Targets Std                    2.03564
trainer/Q Targets Max                   26.1747
trainer/Q Targets Min                    0.120762
trainer/Log Pis Mean                     1.50133
trainer/Log Pis Std                      2.76986
trainer/Log Pis Max                     15.7513
trainer/Log Pis Min                     -3.96363
trainer/policy/mean Mean                -0.516463
trainer/policy/mean Std                  0.656523
trainer/policy/mean Max                  0.999988
trainer/policy/mean Min                 -0.99849
trainer/policy/normal/std Mean           0.840998
trainer/policy/normal/std Std            0.244906
trainer/policy/normal/std Max            1.56978
trainer/policy/normal/std Min            0.275883
trainer/policy/normal/log_std Mean      -0.215779
trainer/policy/normal/log_std Std        0.295239
trainer/policy/normal/log_std Max        0.450935
trainer/policy/normal/log_std Min       -1.28778
trainer/Alpha                            0.0124301
trainer/Alpha Loss                      -2.188
exploration/num steps total          31000
exploration/num paths total            155
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.105287
exploration/Rewards Std                  0.0208802
exploration/Rewards Max                  0.127016
exploration/Rewards Min                  0.0606767
exploration/Returns Mean                21.0574
exploration/Returns Std                  3.49613
exploration/Returns Max                 25.2615
exploration/Returns Min                 16.2741
exploration/Actions Mean                -0.230003
exploration/Actions Std                  0.800448
exploration/Actions Max                  0.999942
exploration/Actions Min                 -0.999882
exploration/Num Paths                    5
exploration/Average Returns             21.0574
evaluation/num steps total          144720
evaluation/num paths total             720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.115613
evaluation/Rewards Std                   0.0108243
evaluation/Rewards Max                   0.126208
evaluation/Rewards Min                   0.0906736
evaluation/Returns Mean                 23.2382
evaluation/Returns Std                   2.1247
evaluation/Returns Max                  24.8782
evaluation/Returns Min                  18.7189
evaluation/Actions Mean                 -0.521641
evaluation/Actions Std                   0.492191
evaluation/Actions Max                   0.881982
evaluation/Actions Min                  -0.923031
evaluation/Num Paths                    24
evaluation/Average Returns              23.2382
time/data storing (s)                    0.0148693
time/evaluation sampling (s)            49.0585
time/exploration sampling (s)            9.91134
time/logging (s)                         0.0238711
time/sac training (s)                   16.3312
time/saving (s)                          0.0311044
time/training (s)                        0.000146282
time/epoch (s)                          75.3711
time/total (s)                        2607.37
Epoch                                   29
----------------------------------  ----------------
2020-11-08 12:45:53.337443 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 30 finished
----------------------------------  ----------------
replay_buffer/size                   32000
trainer/num train calls              31000
trainer/QF1 Loss                         2.17516
trainer/QF2 Loss                         2.17083
trainer/Policy Loss                    -17.5005
trainer/Q1 Predictions Mean             17.4815
trainer/Q1 Predictions Std               1.75248
trainer/Q1 Predictions Max              25.4091
trainer/Q1 Predictions Min              11.716
trainer/Q2 Predictions Mean             17.4795
trainer/Q2 Predictions Std               1.76036
trainer/Q2 Predictions Max              25.4194
trainer/Q2 Predictions Min              11.6317
trainer/Q Targets Mean                  17.5043
trainer/Q Targets Std                    2.32054
trainer/Q Targets Max                   25.4704
trainer/Q Targets Min                    0.118339
trainer/Log Pis Mean                     2.77087
trainer/Log Pis Std                      2.89291
trainer/Log Pis Max                     16.6514
trainer/Log Pis Min                     -2.72069
trainer/policy/mean Mean                -0.718431
trainer/policy/mean Std                  0.51592
trainer/policy/mean Max                  0.999975
trainer/policy/mean Min                 -0.999755
trainer/policy/normal/std Mean           0.722505
trainer/policy/normal/std Std            0.214784
trainer/policy/normal/std Max            1.39392
trainer/policy/normal/std Min            0.33187
trainer/policy/normal/log_std Mean      -0.366528
trainer/policy/normal/log_std Std        0.285496
trainer/policy/normal/log_std Max        0.33212
trainer/policy/normal/log_std Min       -1.10301
trainer/Alpha                            0.012981
trainer/Alpha Loss                       3.34888
exploration/num steps total          32000
exploration/num paths total            160
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.104676
exploration/Rewards Std                  0.0185785
exploration/Rewards Max                  0.125859
exploration/Rewards Min                  0.0512422
exploration/Returns Mean                20.9351
exploration/Returns Std                  3.59234
exploration/Returns Max                 24.4679
exploration/Returns Min                 15.9564
exploration/Actions Mean                -0.644274
exploration/Actions Std                  0.508709
exploration/Actions Max                  0.993502
exploration/Actions Min                 -0.999721
exploration/Num Paths                    5
exploration/Average Returns             20.9351
evaluation/num steps total          149544
evaluation/num paths total             744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.112896
evaluation/Rewards Std                   0.0132677
evaluation/Rewards Max                   0.126314
evaluation/Rewards Min                   0.0865572
evaluation/Returns Mean                 22.6921
evaluation/Returns Std                   2.64233
evaluation/Returns Max                  24.8132
evaluation/Returns Min                  17.5423
evaluation/Actions Mean                 -0.855004
evaluation/Actions Std                   0.254205
evaluation/Actions Max                   0.696674
evaluation/Actions Min                  -0.962473
evaluation/Num Paths                    24
evaluation/Average Returns              22.6921
time/data storing (s)                    0.0151348
time/evaluation sampling (s)            49.0702
time/exploration sampling (s)           10.0538
time/logging (s)                         0.0217207
time/sac training (s)                   16.2207
time/saving (s)                          0.0283081
time/training (s)                        0.000143124
time/epoch (s)                          75.4101
time/total (s)                        2684.05
Epoch                                   30
----------------------------------  ----------------
2020-11-08 12:47:10.830281 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 31 finished
----------------------------------  ---------------
replay_buffer/size                   33000
trainer/num train calls              32000
trainer/QF1 Loss                         0.0402964
trainer/QF2 Loss                         0.0401799
trainer/Policy Loss                    -17.6609
trainer/Q1 Predictions Mean             17.6455
trainer/Q1 Predictions Std               2.03009
trainer/Q1 Predictions Max              28.6502
trainer/Q1 Predictions Min              12.3466
trainer/Q2 Predictions Mean             17.6528
trainer/Q2 Predictions Std               2.03038
trainer/Q2 Predictions Max              28.5788
trainer/Q2 Predictions Min              12.3058
trainer/Q Targets Mean                  17.7238
trainer/Q Targets Std                    1.98844
trainer/Q Targets Max                   28.4937
trainer/Q Targets Min                   12.7439
trainer/Log Pis Mean                     1.88739
trainer/Log Pis Std                      2.69982
trainer/Log Pis Max                      9.63903
trainer/Log Pis Min                     -3.48012
trainer/policy/mean Mean                -0.615211
trainer/policy/mean Std                  0.604589
trainer/policy/mean Max                  0.997963
trainer/policy/mean Min                 -0.998485
trainer/policy/normal/std Mean           0.824115
trainer/policy/normal/std Std            0.259072
trainer/policy/normal/std Max            2.08797
trainer/policy/normal/std Min            0.205816
trainer/policy/normal/log_std Mean      -0.243083
trainer/policy/normal/log_std Std        0.322054
trainer/policy/normal/log_std Max        0.736194
trainer/policy/normal/log_std Min       -1.58077
trainer/Alpha                            0.01155
trainer/Alpha Loss                      -0.502355
exploration/num steps total          33000
exploration/num paths total            165
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.114843
exploration/Rewards Std                  0.0163864
exploration/Rewards Max                  0.126242
exploration/Rewards Min                  0.0754408
exploration/Returns Mean                22.9686
exploration/Returns Std                  3.09498
exploration/Returns Max                 24.9524
exploration/Returns Min                 16.8089
exploration/Actions Mean                -0.597021
exploration/Actions Std                  0.566733
exploration/Actions Max                  0.995721
exploration/Actions Min                 -0.999944
exploration/Num Paths                    5
exploration/Average Returns             22.9686
evaluation/num steps total          154368
evaluation/num paths total             768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.116026
evaluation/Rewards Std                   0.0120769
evaluation/Rewards Max                   0.127331
evaluation/Rewards Min                   0.0842861
evaluation/Returns Mean                 23.3213
evaluation/Returns Std                   2.33377
evaluation/Returns Max                  25.3264
evaluation/Returns Min                  17.5217
evaluation/Actions Mean                 -0.806103
evaluation/Actions Std                   0.299996
evaluation/Actions Max                   0.970971
evaluation/Actions Min                  -0.954997
evaluation/Num Paths                    24
evaluation/Average Returns              23.3213
time/data storing (s)                    0.0153172
time/evaluation sampling (s)            49.0918
time/exploration sampling (s)            9.97629
time/logging (s)                         0.0213062
time/sac training (s)                   16.9948
time/saving (s)                          0.0298888
time/training (s)                        0.00035661
time/epoch (s)                          76.1297
time/total (s)                        2761.51
Epoch                                   31
----------------------------------  ---------------
2020-11-08 12:48:27.976909 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 32 finished
----------------------------------  ----------------
replay_buffer/size                   34000
trainer/num train calls              33000
trainer/QF1 Loss                         2.78142
trainer/QF2 Loss                         2.78549
trainer/Policy Loss                    -17.216
trainer/Q1 Predictions Mean             17.1964
trainer/Q1 Predictions Std               1.63898
trainer/Q1 Predictions Max              23.9663
trainer/Q1 Predictions Min              11.0828
trainer/Q2 Predictions Mean             17.1995
trainer/Q2 Predictions Std               1.64273
trainer/Q2 Predictions Max              23.9542
trainer/Q2 Predictions Min              11.0357
trainer/Q Targets Mean                  17.1953
trainer/Q Targets Std                    2.25178
trainer/Q Targets Max                   24.1391
trainer/Q Targets Min                    0.0781805
trainer/Log Pis Mean                     1.49192
trainer/Log Pis Std                      3.14586
trainer/Log Pis Max                     13.575
trainer/Log Pis Min                     -5.08297
trainer/policy/mean Mean                -0.159173
trainer/policy/mean Std                  0.756721
trainer/policy/mean Max                  0.999999
trainer/policy/mean Min                 -0.999451
trainer/policy/normal/std Mean           0.930322
trainer/policy/normal/std Std            0.340193
trainer/policy/normal/std Max            3.83576
trainer/policy/normal/std Min            0.254214
trainer/policy/normal/log_std Mean      -0.138935
trainer/policy/normal/log_std Std        0.377768
trainer/policy/normal/log_std Max        1.34437
trainer/policy/normal/log_std Min       -1.36958
trainer/Alpha                            0.0101355
trainer/Alpha Loss                      -2.33298
exploration/num steps total          34000
exploration/num paths total            170
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.117841
exploration/Rewards Std                  0.00694695
exploration/Rewards Max                  0.124128
exploration/Rewards Min                  0.0935907
exploration/Returns Mean                23.5682
exploration/Returns Std                  1.02094
exploration/Returns Max                 24.6217
exploration/Returns Min                 21.7775
exploration/Actions Mean                -0.132259
exploration/Actions Std                  0.760661
exploration/Actions Max                  0.999862
exploration/Actions Min                 -0.999856
exploration/Num Paths                    5
exploration/Average Returns             23.5682
evaluation/num steps total          159192
evaluation/num paths total             792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121033
evaluation/Rewards Std                   0.00586814
evaluation/Rewards Max                   0.125099
evaluation/Rewards Min                   0.0930066
evaluation/Returns Mean                 24.3276
evaluation/Returns Std                   1.16979
evaluation/Returns Max                  24.8204
evaluation/Returns Min                  18.7727
evaluation/Actions Mean                  0.0243524
evaluation/Actions Std                   0.595609
evaluation/Actions Max                   0.852429
evaluation/Actions Min                  -0.915747
evaluation/Num Paths                    24
evaluation/Average Returns              24.3276
time/data storing (s)                    0.0157431
time/evaluation sampling (s)            49.5238
time/exploration sampling (s)           10.0813
time/logging (s)                         0.0222777
time/sac training (s)                   16.1793
time/saving (s)                          0.0302837
time/training (s)                        0.000169012
time/epoch (s)                          75.8529
time/total (s)                        2838.63
Epoch                                   32
----------------------------------  ----------------
2020-11-08 12:49:44.545637 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 33 finished
----------------------------------  ----------------
replay_buffer/size                   35000
trainer/num train calls              34000
trainer/QF1 Loss                         0.0511288
trainer/QF2 Loss                         0.050254
trainer/Policy Loss                    -17.1777
trainer/Q1 Predictions Mean             17.1624
trainer/Q1 Predictions Std               1.74288
trainer/Q1 Predictions Max              23.9707
trainer/Q1 Predictions Min              10.8706
trainer/Q2 Predictions Mean             17.1627
trainer/Q2 Predictions Std               1.74862
trainer/Q2 Predictions Max              23.9851
trainer/Q2 Predictions Min              11.0542
trainer/Q Targets Mean                  17.2973
trainer/Q Targets Std                    1.72288
trainer/Q Targets Max                   24.0578
trainer/Q Targets Min                   12.0388
trainer/Log Pis Mean                     1.84731
trainer/Log Pis Std                      3.32632
trainer/Log Pis Max                     13.7349
trainer/Log Pis Min                     -4.32479
trainer/policy/mean Mean                -0.402106
trainer/policy/mean Std                  0.71665
trainer/policy/mean Max                  0.999959
trainer/policy/mean Min                 -0.998443
trainer/policy/normal/std Mean           0.915876
trainer/policy/normal/std Std            0.308325
trainer/policy/normal/std Max            1.90575
trainer/policy/normal/std Min            0.259744
trainer/policy/normal/log_std Mean      -0.149444
trainer/policy/normal/log_std Std        0.361941
trainer/policy/normal/log_std Max        0.644878
trainer/policy/normal/log_std Min       -1.34806
trainer/Alpha                            0.0097395
trainer/Alpha Loss                      -0.707185
exploration/num steps total          35000
exploration/num paths total            175
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.110707
exploration/Rewards Std                  0.0181114
exploration/Rewards Max                  0.126026
exploration/Rewards Min                  0.0678447
exploration/Returns Mean                22.1414
exploration/Returns Std                  3.38558
exploration/Returns Max                 24.8523
exploration/Returns Min                 15.5599
exploration/Actions Mean                -0.398275
exploration/Actions Std                  0.669306
exploration/Actions Max                  0.999955
exploration/Actions Min                 -0.999976
exploration/Num Paths                    5
exploration/Average Returns             22.1414
evaluation/num steps total          164016
evaluation/num paths total             816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.112068
evaluation/Rewards Std                   0.0135162
evaluation/Rewards Max                   0.125868
evaluation/Rewards Min                   0.0634571
evaluation/Returns Mean                 22.5256
evaluation/Returns Std                   2.34148
evaluation/Returns Max                  24.9101
evaluation/Returns Min                  18.016
evaluation/Actions Mean                 -0.526237
evaluation/Actions Std                   0.452272
evaluation/Actions Max                   0.993715
evaluation/Actions Min                  -0.983884
evaluation/Num Paths                    24
evaluation/Average Returns              22.5256
time/data storing (s)                    0.0147441
time/evaluation sampling (s)            49.1078
time/exploration sampling (s)            9.96804
time/logging (s)                         0.0274237
time/sac training (s)                   16.1409
time/saving (s)                          0.0349346
time/training (s)                        0.000129248
time/epoch (s)                          75.2939
time/total (s)                        2915.18
Epoch                                   33
----------------------------------  ----------------
2020-11-08 12:51:01.115438 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 34 finished
----------------------------------  ----------------
replay_buffer/size                   36000
trainer/num train calls              35000
trainer/QF1 Loss                         0.982601
trainer/QF2 Loss                         1.03109
trainer/Policy Loss                    -17.121
trainer/Q1 Predictions Mean             17.0858
trainer/Q1 Predictions Std               1.65456
trainer/Q1 Predictions Max              28.3919
trainer/Q1 Predictions Min              12.1448
trainer/Q2 Predictions Mean             17.0838
trainer/Q2 Predictions Std               1.64926
trainer/Q2 Predictions Max              28.403
trainer/Q2 Predictions Min              12.1252
trainer/Q Targets Mean                  17.1494
trainer/Q Targets Std                    1.95436
trainer/Q Targets Max                   28.4594
trainer/Q Targets Min                    0.112182
trainer/Log Pis Mean                     1.94884
trainer/Log Pis Std                      3.14923
trainer/Log Pis Max                     11.4103
trainer/Log Pis Min                     -4.41675
trainer/policy/mean Mean                -0.411168
trainer/policy/mean Std                  0.713282
trainer/policy/mean Max                  0.999892
trainer/policy/mean Min                 -0.998743
trainer/policy/normal/std Mean           0.866176
trainer/policy/normal/std Std            0.296696
trainer/policy/normal/std Max            1.48098
trainer/policy/normal/std Min            0.243925
trainer/policy/normal/log_std Mean      -0.211523
trainer/policy/normal/log_std Std        0.384712
trainer/policy/normal/log_std Max        0.392703
trainer/policy/normal/log_std Min       -1.41089
trainer/Alpha                            0.0106343
trainer/Alpha Loss                      -0.232463
exploration/num steps total          36000
exploration/num paths total            180
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.0935232
exploration/Rewards Std                  0.0178543
exploration/Rewards Max                  0.124693
exploration/Rewards Min                  0.0701173
exploration/Returns Mean                18.7046
exploration/Returns Std                  3.04533
exploration/Returns Max                 24.3089
exploration/Returns Min                 15.2832
exploration/Actions Mean                -0.199639
exploration/Actions Std                  0.816635
exploration/Actions Max                  0.999998
exploration/Actions Min                 -0.999986
exploration/Num Paths                    5
exploration/Average Returns             18.7046
evaluation/num steps total          168840
evaluation/num paths total             840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.11641
evaluation/Rewards Std                   0.00953205
evaluation/Rewards Max                   0.126968
evaluation/Rewards Min                   0.076421
evaluation/Returns Mean                 23.3985
evaluation/Returns Std                   1.54754
evaluation/Returns Max                  25.3727
evaluation/Returns Min                  18.5125
evaluation/Actions Mean                 -0.486189
evaluation/Actions Std                   0.430283
evaluation/Actions Max                   0.982589
evaluation/Actions Min                  -0.994073
evaluation/Num Paths                    24
evaluation/Average Returns              23.3985
time/data storing (s)                    0.0163479
time/evaluation sampling (s)            49.0829
time/exploration sampling (s)            9.94111
time/logging (s)                         0.0245612
time/sac training (s)                   16.1672
time/saving (s)                          0.029099
time/training (s)                        0.000181133
time/epoch (s)                          75.2614
time/total (s)                        2991.72
Epoch                                   34
----------------------------------  ----------------
2020-11-08 12:52:17.903462 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 35 finished
----------------------------------  ----------------
replay_buffer/size                   37000
trainer/num train calls              36000
trainer/QF1 Loss                         0.128008
trainer/QF2 Loss                         0.129455
trainer/Policy Loss                    -17.3589
trainer/Q1 Predictions Mean             17.3578
trainer/Q1 Predictions Std               2.41659
trainer/Q1 Predictions Max              29.752
trainer/Q1 Predictions Min              11.8631
trainer/Q2 Predictions Mean             17.3475
trainer/Q2 Predictions Std               2.41676
trainer/Q2 Predictions Max              29.7335
trainer/Q2 Predictions Min              11.8058
trainer/Q Targets Mean                  17.5125
trainer/Q Targets Std                    2.4012
trainer/Q Targets Max                   29.7255
trainer/Q Targets Min                   12.5974
trainer/Log Pis Mean                     1.49231
trainer/Log Pis Std                      3.12246
trainer/Log Pis Max                     20.2839
trainer/Log Pis Min                     -4.16551
trainer/policy/mean Mean                -0.337468
trainer/policy/mean Std                  0.710725
trainer/policy/mean Max                  0.999997
trainer/policy/mean Min                 -0.99588
trainer/policy/normal/std Mean           0.882729
trainer/policy/normal/std Std            0.26406
trainer/policy/normal/std Max            1.38433
trainer/policy/normal/std Min            0.297601
trainer/policy/normal/log_std Mean      -0.174208
trainer/policy/normal/log_std Std        0.324027
trainer/policy/normal/log_std Max        0.325214
trainer/policy/normal/log_std Min       -1.212
trainer/Alpha                            0.0110647
trainer/Alpha Loss                      -2.28663
exploration/num steps total          37000
exploration/num paths total            185
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.115134
exploration/Rewards Std                  0.0113858
exploration/Rewards Max                  0.124971
exploration/Rewards Min                  0.0888339
exploration/Returns Mean                23.0267
exploration/Returns Std                  2.30858
exploration/Returns Max                 24.808
exploration/Returns Min                 18.5784
exploration/Actions Mean                -0.371132
exploration/Actions Std                  0.681369
exploration/Actions Max                  0.99943
exploration/Actions Min                 -0.999762
exploration/Num Paths                    5
exploration/Average Returns             23.0267
evaluation/num steps total          173664
evaluation/num paths total             864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.116819
evaluation/Rewards Std                   0.0102331
evaluation/Rewards Max                   0.12641
evaluation/Rewards Min                   0.0858981
evaluation/Returns Mean                 23.4807
evaluation/Returns Std                   1.91779
evaluation/Returns Max                  25.0745
evaluation/Returns Min                  18.5579
evaluation/Actions Mean                 -0.535063
evaluation/Actions Std                   0.308192
evaluation/Actions Max                   0.701574
evaluation/Actions Min                  -0.97147
evaluation/Num Paths                    24
evaluation/Average Returns              23.4807
time/data storing (s)                    0.0148179
time/evaluation sampling (s)            49.1978
time/exploration sampling (s)           10.0021
time/logging (s)                         0.0244256
time/sac training (s)                   16.217
time/saving (s)                          0.0298082
time/training (s)                        0.000136793
time/epoch (s)                          75.4862
time/total (s)                        3068.48
Epoch                                   35
----------------------------------  ----------------
2020-11-08 12:53:35.549426 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 36 finished
----------------------------------  ----------------
replay_buffer/size                   38000
trainer/num train calls              37000
trainer/QF1 Loss                         2.50867
trainer/QF2 Loss                         2.45665
trainer/Policy Loss                    -17.1935
trainer/Q1 Predictions Mean             17.1847
trainer/Q1 Predictions Std               1.76254
trainer/Q1 Predictions Max              23.8469
trainer/Q1 Predictions Min              11.3526
trainer/Q2 Predictions Mean             17.1859
trainer/Q2 Predictions Std               1.7578
trainer/Q2 Predictions Max              23.8542
trainer/Q2 Predictions Min              11.3189
trainer/Q Targets Mean                  17.0696
trainer/Q Targets Std                    2.289
trainer/Q Targets Max                   23.8567
trainer/Q Targets Min                    0.1192
trainer/Log Pis Mean                     1.86795
trainer/Log Pis Std                      3.13781
trainer/Log Pis Max                     12.7336
trainer/Log Pis Min                     -3.68884
trainer/policy/mean Mean                -0.314485
trainer/policy/mean Std                  0.740008
trainer/policy/mean Max                  0.999731
trainer/policy/mean Min                 -0.999211
trainer/policy/normal/std Mean           0.854049
trainer/policy/normal/std Std            0.246818
trainer/policy/normal/std Max            1.41265
trainer/policy/normal/std Min            0.226368
trainer/policy/normal/log_std Mean      -0.204086
trainer/policy/normal/log_std Std        0.314444
trainer/policy/normal/log_std Max        0.345468
trainer/policy/normal/log_std Min       -1.48559
trainer/Alpha                            0.00952935
trainer/Alpha Loss                      -0.614473
exploration/num steps total          38000
exploration/num paths total            190
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.100591
exploration/Rewards Std                  0.0205165
exploration/Rewards Max                  0.123757
exploration/Rewards Min                  0.062769
exploration/Returns Mean                20.1181
exploration/Returns Std                  3.91873
exploration/Returns Max                 23.6773
exploration/Returns Min                 13.0153
exploration/Actions Mean                -0.120594
exploration/Actions Std                  0.800436
exploration/Actions Max                  0.999686
exploration/Actions Min                 -0.999863
exploration/Num Paths                    5
exploration/Average Returns             20.1181
evaluation/num steps total          178488
evaluation/num paths total             888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117458
evaluation/Rewards Std                   0.00867215
evaluation/Rewards Max                   0.125543
evaluation/Rewards Min                   0.0922022
evaluation/Returns Mean                 23.6091
evaluation/Returns Std                   1.69255
evaluation/Returns Max                  25.0282
evaluation/Returns Min                  18.8461
evaluation/Actions Mean                 -0.417316
evaluation/Actions Std                   0.422578
evaluation/Actions Max                   0.904705
evaluation/Actions Min                  -0.994624
evaluation/Num Paths                    24
evaluation/Average Returns              23.6091
time/data storing (s)                    0.0163214
time/evaluation sampling (s)            49.7568
time/exploration sampling (s)            9.99486
time/logging (s)                         0.0309659
time/sac training (s)                   16.5107
time/saving (s)                          0.0294728
time/training (s)                        0.000148673
time/epoch (s)                          76.3393
time/total (s)                        3146.1
Epoch                                   36
----------------------------------  ----------------
2020-11-08 12:54:53.130231 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 37 finished
----------------------------------  ----------------
replay_buffer/size                   39000
trainer/num train calls              38000
trainer/QF1 Loss                         1.07807
trainer/QF2 Loss                         1.07937
trainer/Policy Loss                    -17.1276
trainer/Q1 Predictions Mean             17.1282
trainer/Q1 Predictions Std               1.77207
trainer/Q1 Predictions Max              27.9222
trainer/Q1 Predictions Min              12.2941
trainer/Q2 Predictions Mean             17.1305
trainer/Q2 Predictions Std               1.76465
trainer/Q2 Predictions Max              27.9288
trainer/Q2 Predictions Min              12.2908
trainer/Q Targets Mean                  17.0934
trainer/Q Targets Std                    2.03124
trainer/Q Targets Max                   27.6986
trainer/Q Targets Min                    0.10021
trainer/Log Pis Mean                     1.72881
trainer/Log Pis Std                      3.36152
trainer/Log Pis Max                     21.638
trainer/Log Pis Min                     -5.11425
trainer/policy/mean Mean                 0.0486885
trainer/policy/mean Std                  0.802808
trainer/policy/mean Max                  1
trainer/policy/mean Min                 -0.997551
trainer/policy/normal/std Mean           0.927689
trainer/policy/normal/std Std            0.221926
trainer/policy/normal/std Max            1.49378
trainer/policy/normal/std Min            0.187498
trainer/policy/normal/log_std Mean      -0.111249
trainer/policy/normal/log_std Std        0.288741
trainer/policy/normal/log_std Max        0.401308
trainer/policy/normal/log_std Min       -1.67399
trainer/Alpha                            0.00970509
trainer/Alpha Loss                      -1.257
exploration/num steps total          39000
exploration/num paths total            195
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.110948
exploration/Rewards Std                  0.0169333
exploration/Rewards Max                  0.126878
exploration/Rewards Min                  0.0640928
exploration/Returns Mean                22.1896
exploration/Returns Std                  2.27655
exploration/Returns Max                 24.264
exploration/Returns Min                 18.2676
exploration/Actions Mean                 0.123827
exploration/Actions Std                  0.773228
exploration/Actions Max                  0.999979
exploration/Actions Min                 -0.999743
exploration/Num Paths                    5
exploration/Average Returns             22.1896
evaluation/num steps total          183312
evaluation/num paths total             912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.120211
evaluation/Rewards Std                   0.00803178
evaluation/Rewards Max                   0.125944
evaluation/Rewards Min                   0.092021
evaluation/Returns Mean                 24.1625
evaluation/Returns Std                   1.60944
evaluation/Returns Max                  24.9478
evaluation/Returns Min                  18.6629
evaluation/Actions Mean                  0.222548
evaluation/Actions Std                   0.668774
evaluation/Actions Max                   0.996811
evaluation/Actions Min                  -0.940898
evaluation/Num Paths                    24
evaluation/Average Returns              24.1625
time/data storing (s)                    0.0167544
time/evaluation sampling (s)            49.5739
time/exploration sampling (s)           10.073
time/logging (s)                         0.0201867
time/sac training (s)                   16.5434
time/saving (s)                          0.028537
time/training (s)                        0.000122922
time/epoch (s)                          76.2559
time/total (s)                        3223.65
Epoch                                   37
----------------------------------  ----------------
2020-11-08 12:56:10.760974 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 38 finished
----------------------------------  ----------------
replay_buffer/size                   40000
trainer/num train calls              39000
trainer/QF1 Loss                         0.948586
trainer/QF2 Loss                         0.95321
trainer/Policy Loss                    -16.8375
trainer/Q1 Predictions Mean             16.8319
trainer/Q1 Predictions Std               1.69243
trainer/Q1 Predictions Max              26.6957
trainer/Q1 Predictions Min              12.97
trainer/Q2 Predictions Mean             16.834
trainer/Q2 Predictions Std               1.69435
trainer/Q2 Predictions Max              26.6605
trainer/Q2 Predictions Min              13.0394
trainer/Q Targets Mean                  16.8801
trainer/Q Targets Std                    1.98592
trainer/Q Targets Max                   26.9372
trainer/Q Targets Min                    0.0579571
trainer/Log Pis Mean                     1.4552
trainer/Log Pis Std                      2.85606
trainer/Log Pis Max                     13.1471
trainer/Log Pis Min                     -4.86258
trainer/policy/mean Mean                -0.264615
trainer/policy/mean Std                  0.76354
trainer/policy/mean Max                  0.99983
trainer/policy/mean Min                 -0.99897
trainer/policy/normal/std Mean           0.851737
trainer/policy/normal/std Std            0.235828
trainer/policy/normal/std Max            1.37451
trainer/policy/normal/std Min            0.190605
trainer/policy/normal/log_std Mean      -0.208122
trainer/policy/normal/log_std Std        0.329934
trainer/policy/normal/log_std Max        0.318097
trainer/policy/normal/log_std Min       -1.65755
trainer/Alpha                            0.00943302
trainer/Alpha Loss                      -2.5407
exploration/num steps total          40000
exploration/num paths total            200
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.112841
exploration/Rewards Std                  0.0148709
exploration/Rewards Max                  0.12346
exploration/Rewards Min                  0.0765431
exploration/Returns Mean                22.5682
exploration/Returns Std                  2.32276
exploration/Returns Max                 24.4731
exploration/Returns Min                 18.0831
exploration/Actions Mean                -0.348148
exploration/Actions Std                  0.701705
exploration/Actions Max                  0.999801
exploration/Actions Min                 -0.999916
exploration/Num Paths                    5
exploration/Average Returns             22.5682
evaluation/num steps total          188136
evaluation/num paths total             936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.118967
evaluation/Rewards Std                   0.00880757
evaluation/Rewards Max                   0.125399
evaluation/Rewards Min                   0.083958
evaluation/Returns Mean                 23.9124
evaluation/Returns Std                   1.75419
evaluation/Returns Max                  24.776
evaluation/Returns Min                  17.6258
evaluation/Actions Mean                 -0.210816
evaluation/Actions Std                   0.604534
evaluation/Actions Max                   0.912962
evaluation/Actions Min                  -0.991966
evaluation/Num Paths                    24
evaluation/Average Returns              23.9124
time/data storing (s)                    0.0141877
time/evaluation sampling (s)            49.8242
time/exploration sampling (s)            9.98823
time/logging (s)                         0.0219504
time/sac training (s)                   16.4695
time/saving (s)                          0.0282323
time/training (s)                        0.000147034
time/epoch (s)                          76.3464
time/total (s)                        3301.25
Epoch                                   38
----------------------------------  ----------------
2020-11-08 12:57:28.200923 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 39 finished
----------------------------------  ----------------
replay_buffer/size                   41000
trainer/num train calls              40000
trainer/QF1 Loss                         0.508519
trainer/QF2 Loss                         0.512537
trainer/Policy Loss                    -16.7697
trainer/Q1 Predictions Mean             16.7621
trainer/Q1 Predictions Std               1.71761
trainer/Q1 Predictions Max              26.1048
trainer/Q1 Predictions Min               9.53769
trainer/Q2 Predictions Mean             16.756
trainer/Q2 Predictions Std               1.71895
trainer/Q2 Predictions Max              26.0633
trainer/Q2 Predictions Min               9.54473
trainer/Q Targets Mean                  16.7849
trainer/Q Targets Std                    1.9692
trainer/Q Targets Max                   26.1067
trainer/Q Targets Min                    0.0730971
trainer/Log Pis Mean                     1.85092
trainer/Log Pis Std                      3.39918
trainer/Log Pis Max                     17.0763
trainer/Log Pis Min                     -4.0308
trainer/policy/mean Mean                -0.387442
trainer/policy/mean Std                  0.71834
trainer/policy/mean Max                  0.999989
trainer/policy/mean Min                 -0.999963
trainer/policy/normal/std Mean           0.816689
trainer/policy/normal/std Std            0.250552
trainer/policy/normal/std Max            1.34017
trainer/policy/normal/std Min            0.206332
trainer/policy/normal/log_std Mean      -0.257328
trainer/policy/normal/log_std Std        0.347641
trainer/policy/normal/log_std Max        0.292797
trainer/policy/normal/log_std Min       -1.57827
trainer/Alpha                            0.00991251
trainer/Alpha Loss                      -0.687837
exploration/num steps total          41000
exploration/num paths total            205
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.111798
exploration/Rewards Std                  0.0163341
exploration/Rewards Max                  0.125679
exploration/Rewards Min                  0.0763755
exploration/Returns Mean                22.3597
exploration/Returns Std                  2.05228
exploration/Returns Max                 24.6721
exploration/Returns Min                 19.2692
exploration/Actions Mean                -0.296888
exploration/Actions Std                  0.752192
exploration/Actions Max                  1
exploration/Actions Min                 -0.999947
exploration/Num Paths                    5
exploration/Average Returns             22.3597
evaluation/num steps total          192960
evaluation/num paths total             960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.116777
evaluation/Rewards Std                   0.0106176
evaluation/Rewards Max                   0.127199
evaluation/Rewards Min                   0.075361
evaluation/Returns Mean                 23.4722
evaluation/Returns Std                   2.03629
evaluation/Returns Max                  25.132
evaluation/Returns Min                  18.4039
evaluation/Actions Mean                 -0.458198
evaluation/Actions Std                   0.417385
evaluation/Actions Max                   0.891496
evaluation/Actions Min                  -0.957121
evaluation/Num Paths                    24
evaluation/Average Returns              23.4722
time/data storing (s)                    0.0155549
time/evaluation sampling (s)            49.4707
time/exploration sampling (s)           10.0359
time/logging (s)                         0.022832
time/sac training (s)                   16.5465
time/saving (s)                          0.0354321
time/training (s)                        0.000134011
time/epoch (s)                          76.127
time/total (s)                        3378.66
Epoch                                   39
----------------------------------  ----------------
2020-11-08 12:58:46.387226 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 40 finished
----------------------------------  ----------------
replay_buffer/size                   42000
trainer/num train calls              41000
trainer/QF1 Loss                         0.964995
trainer/QF2 Loss                         0.957645
trainer/Policy Loss                    -16.7133
trainer/Q1 Predictions Mean             16.6745
trainer/Q1 Predictions Std               1.9627
trainer/Q1 Predictions Max              27.2495
trainer/Q1 Predictions Min              10.2376
trainer/Q2 Predictions Mean             16.6787
trainer/Q2 Predictions Std               1.9545
trainer/Q2 Predictions Max              27.2646
trainer/Q2 Predictions Min              10.2414
trainer/Q Targets Mean                  16.7561
trainer/Q Targets Std                    2.40201
trainer/Q Targets Max                   27.1848
trainer/Q Targets Min                    0.090867
trainer/Log Pis Mean                     2.37963
trainer/Log Pis Std                      3.24619
trainer/Log Pis Max                     14.8659
trainer/Log Pis Min                     -4.54076
trainer/policy/mean Mean                -0.48694
trainer/policy/mean Std                  0.680645
trainer/policy/mean Max                  0.999736
trainer/policy/mean Min                 -0.999516
trainer/policy/normal/std Mean           0.79436
trainer/policy/normal/std Std            0.237255
trainer/policy/normal/std Max            1.27256
trainer/policy/normal/std Min            0.187003
trainer/policy/normal/log_std Mean      -0.282586
trainer/policy/normal/log_std Std        0.340672
trainer/policy/normal/log_std Max        0.241028
trainer/policy/normal/log_std Min       -1.67663
trainer/Alpha                            0.00923046
trainer/Alpha Loss                       1.77866
exploration/num steps total          42000
exploration/num paths total            210
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.116087
exploration/Rewards Std                  0.0119924
exploration/Rewards Max                  0.124442
exploration/Rewards Min                  0.0778808
exploration/Returns Mean                23.2173
exploration/Returns Std                  1.35748
exploration/Returns Max                 24.6915
exploration/Returns Min                 21.0138
exploration/Actions Mean                -0.217773
exploration/Actions Std                  0.717534
exploration/Actions Max                  0.99988
exploration/Actions Min                 -0.999857
exploration/Num Paths                    5
exploration/Average Returns             23.2173
evaluation/num steps total          197784
evaluation/num paths total             984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117258
evaluation/Rewards Std                   0.0109788
evaluation/Rewards Max                   0.128137
evaluation/Rewards Min                   0.0833957
evaluation/Returns Mean                 23.5688
evaluation/Returns Std                   2.09313
evaluation/Returns Max                  25.1546
evaluation/Returns Min                  17.7991
evaluation/Actions Mean                 -0.582288
evaluation/Actions Std                   0.428648
evaluation/Actions Max                   0.974655
evaluation/Actions Min                  -0.991935
evaluation/Num Paths                    24
evaluation/Average Returns              23.5688
time/data storing (s)                    0.0160485
time/evaluation sampling (s)            50.341
time/exploration sampling (s)            9.96898
time/logging (s)                         0.0285925
time/sac training (s)                   16.479
time/saving (s)                          0.0289351
time/training (s)                        0.000125256
time/epoch (s)                          76.8627
time/total (s)                        3456.83
Epoch                                   40
----------------------------------  ----------------
2020-11-08 13:00:03.271943 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 41 finished
----------------------------------  ----------------
replay_buffer/size                   43000
trainer/num train calls              42000
trainer/QF1 Loss                         1.01446
trainer/QF2 Loss                         0.996458
trainer/Policy Loss                    -16.6614
trainer/Q1 Predictions Mean             16.6472
trainer/Q1 Predictions Std               1.55235
trainer/Q1 Predictions Max              23.7279
trainer/Q1 Predictions Min              11.1096
trainer/Q2 Predictions Mean             16.641
trainer/Q2 Predictions Std               1.55768
trainer/Q2 Predictions Max              23.7278
trainer/Q2 Predictions Min              10.9847
trainer/Q Targets Mean                  16.642
trainer/Q Targets Std                    1.85521
trainer/Q Targets Max                   23.4559
trainer/Q Targets Min                    0.096556
trainer/Log Pis Mean                     1.90739
trainer/Log Pis Std                      3.0656
trainer/Log Pis Max                     14.9735
trainer/Log Pis Min                     -3.1479
trainer/policy/mean Mean                -0.095269
trainer/policy/mean Std                  0.800218
trainer/policy/mean Max                  0.999838
trainer/policy/mean Min                 -0.999551
trainer/policy/normal/std Mean           0.804852
trainer/policy/normal/std Std            0.223151
trainer/policy/normal/std Max            1.32224
trainer/policy/normal/std Min            0.193434
trainer/policy/normal/log_std Mean      -0.26366
trainer/policy/normal/log_std Std        0.323677
trainer/policy/normal/log_std Max        0.279326
trainer/policy/normal/log_std Min       -1.64282
trainer/Alpha                            0.00903245
trainer/Alpha Loss                      -0.435899
exploration/num steps total          43000
exploration/num paths total            215
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.113638
exploration/Rewards Std                  0.0137753
exploration/Rewards Max                  0.125863
exploration/Rewards Min                  0.0866197
exploration/Returns Mean                22.7276
exploration/Returns Std                  2.46233
exploration/Returns Max                 24.7268
exploration/Returns Min                 18.4802
exploration/Actions Mean                -0.119573
exploration/Actions Std                  0.751417
exploration/Actions Max                  0.999888
exploration/Actions Min                 -0.999979
exploration/Num Paths                    5
exploration/Average Returns             22.7276
evaluation/num steps total          202608
evaluation/num paths total            1008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.118834
evaluation/Rewards Std                   0.00966402
evaluation/Rewards Max                   0.126505
evaluation/Rewards Min                   0.0927878
evaluation/Returns Mean                 23.8857
evaluation/Returns Std                   1.93771
evaluation/Returns Max                  25.0103
evaluation/Returns Min                  18.7099
evaluation/Actions Mean                  0.0108196
evaluation/Actions Std                   0.698457
evaluation/Actions Max                   0.922299
evaluation/Actions Min                  -0.886084
evaluation/Num Paths                    24
evaluation/Average Returns              23.8857
time/data storing (s)                    0.0168287
time/evaluation sampling (s)            49.0794
time/exploration sampling (s)           10.0794
time/logging (s)                         0.0212032
time/sac training (s)                   16.3659
time/saving (s)                          0.0328974
time/training (s)                        0.000149184
time/epoch (s)                          75.5957
time/total (s)                        3533.68
Epoch                                   41
----------------------------------  ----------------
2020-11-08 13:01:20.086104 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 42 finished
----------------------------------  ----------------
replay_buffer/size                   44000
trainer/num train calls              43000
trainer/QF1 Loss                         4.32203
trainer/QF2 Loss                         4.41363
trainer/Policy Loss                    -16.6046
trainer/Q1 Predictions Mean             16.5845
trainer/Q1 Predictions Std               1.98537
trainer/Q1 Predictions Max              28.2787
trainer/Q1 Predictions Min               8.42427
trainer/Q2 Predictions Mean             16.5792
trainer/Q2 Predictions Std               1.99068
trainer/Q2 Predictions Max              28.2868
trainer/Q2 Predictions Min               8.4322
trainer/Q Targets Mean                  16.2905
trainer/Q Targets Std                    2.84215
trainer/Q Targets Max                   28.0171
trainer/Q Targets Min                    0.111642
trainer/Log Pis Mean                     2.25962
trainer/Log Pis Std                      3.28607
trainer/Log Pis Max                     14.2839
trainer/Log Pis Min                     -4.02323
trainer/policy/mean Mean                -0.119441
trainer/policy/mean Std                  0.819192
trainer/policy/mean Max                  0.999866
trainer/policy/mean Min                 -0.999643
trainer/policy/normal/std Mean           0.759744
trainer/policy/normal/std Std            0.228258
trainer/policy/normal/std Max            1.3027
trainer/policy/normal/std Min            0.106293
trainer/policy/normal/log_std Mean      -0.33369
trainer/policy/normal/log_std Std        0.37452
trainer/policy/normal/log_std Max        0.264437
trainer/policy/normal/log_std Min       -2.24156
trainer/Alpha                            0.00861055
trainer/Alpha Loss                       1.23441
exploration/num steps total          44000
exploration/num paths total            220
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.122132
exploration/Rewards Std                  0.00248619
exploration/Rewards Max                  0.126338
exploration/Rewards Min                  0.11567
exploration/Returns Mean                24.4265
exploration/Returns Std                  0.335306
exploration/Returns Max                 24.8741
exploration/Returns Min                 23.8975
exploration/Actions Mean                -0.0654329
exploration/Actions Std                  0.765213
exploration/Actions Max                  0.999821
exploration/Actions Min                 -0.999624
exploration/Num Paths                    5
exploration/Average Returns             24.4265
evaluation/num steps total          207432
evaluation/num paths total            1032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.122403
evaluation/Rewards Std                   0.000721827
evaluation/Rewards Max                   0.123921
evaluation/Rewards Min                   0.117677
evaluation/Returns Mean                 24.6031
evaluation/Returns Std                   0.102824
evaluation/Returns Max                  24.6944
evaluation/Returns Min                  24.2664
evaluation/Actions Mean                 -0.00261236
evaluation/Actions Std                   0.83845
evaluation/Actions Max                   0.856656
evaluation/Actions Min                  -0.863748
evaluation/Num Paths                    24
evaluation/Average Returns              24.6031
time/data storing (s)                    0.0150065
time/evaluation sampling (s)            49.175
time/exploration sampling (s)            9.94542
time/logging (s)                         0.0214469
time/sac training (s)                   16.3293
time/saving (s)                          0.032858
time/training (s)                        0.000149175
time/epoch (s)                          75.5191
time/total (s)                        3610.46
Epoch                                   42
----------------------------------  ----------------
2020-11-08 13:02:36.810410 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 43 finished
----------------------------------  ----------------
replay_buffer/size                   45000
trainer/num train calls              44000
trainer/QF1 Loss                         1.99929
trainer/QF2 Loss                         1.99162
trainer/Policy Loss                    -16.5096
trainer/Q1 Predictions Mean             16.504
trainer/Q1 Predictions Std               1.48338
trainer/Q1 Predictions Max              26.0196
trainer/Q1 Predictions Min              12.9364
trainer/Q2 Predictions Mean             16.501
trainer/Q2 Predictions Std               1.48657
trainer/Q2 Predictions Max              25.9722
trainer/Q2 Predictions Min              12.928
trainer/Q Targets Mean                  16.3871
trainer/Q Targets Std                    2.06045
trainer/Q Targets Max                   25.5413
trainer/Q Targets Min                    0.123139
trainer/Log Pis Mean                     2.2811
trainer/Log Pis Std                      3.14744
trainer/Log Pis Max                     14.3675
trainer/Log Pis Min                     -4.04028
trainer/policy/mean Mean                -0.517897
trainer/policy/mean Std                  0.651072
trainer/policy/mean Max                  0.998125
trainer/policy/mean Min                 -0.999882
trainer/policy/normal/std Mean           0.810142
trainer/policy/normal/std Std            0.306757
trainer/policy/normal/std Max            2.54112
trainer/policy/normal/std Min            0.0861909
trainer/policy/normal/log_std Mean      -0.295613
trainer/policy/normal/log_std Std        0.447688
trainer/policy/normal/log_std Max        0.932604
trainer/policy/normal/log_std Min       -2.45119
trainer/Alpha                            0.00828406
trainer/Alpha Loss                       1.34743
exploration/num steps total          45000
exploration/num paths total            225
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.119993
exploration/Rewards Std                  0.00485676
exploration/Rewards Max                  0.125133
exploration/Rewards Min                  0.0922528
exploration/Returns Mean                23.9986
exploration/Returns Std                  0.422273
exploration/Returns Max                 24.5495
exploration/Returns Min                 23.5079
exploration/Actions Mean                -0.386628
exploration/Actions Std                  0.711707
exploration/Actions Max                  0.998521
exploration/Actions Min                 -0.999875
exploration/Num Paths                    5
exploration/Average Returns             23.9986
evaluation/num steps total          212256
evaluation/num paths total            1056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.116439
evaluation/Rewards Std                   0.0105972
evaluation/Rewards Max                   0.127435
evaluation/Rewards Min                   0.0905248
evaluation/Returns Mean                 23.4042
evaluation/Returns Std                   2.02642
evaluation/Returns Max                  25.0215
evaluation/Returns Min                  18.3723
evaluation/Actions Mean                 -0.604803
evaluation/Actions Std                   0.366156
evaluation/Actions Max                   0.690807
evaluation/Actions Min                  -0.985705
evaluation/Num Paths                    24
evaluation/Average Returns              23.4042
time/data storing (s)                    0.0147782
time/evaluation sampling (s)            49.1057
time/exploration sampling (s)            9.95754
time/logging (s)                         0.0209728
time/sac training (s)                   16.3217
time/saving (s)                          0.0296272
time/training (s)                        0.000124228
time/epoch (s)                          75.4505
time/total (s)                        3687.16
Epoch                                   43
----------------------------------  ----------------
2020-11-08 13:03:54.211298 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 44 finished
----------------------------------  ----------------
replay_buffer/size                   46000
trainer/num train calls              45000
trainer/QF1 Loss                         0.70173
trainer/QF2 Loss                         0.699264
trainer/Policy Loss                    -16.4015
trainer/Q1 Predictions Mean             16.3733
trainer/Q1 Predictions Std               1.58413
trainer/Q1 Predictions Max              23.1858
trainer/Q1 Predictions Min               7.18917
trainer/Q2 Predictions Mean             16.3741
trainer/Q2 Predictions Std               1.58145
trainer/Q2 Predictions Max              23.2653
trainer/Q2 Predictions Min               7.20727
trainer/Q Targets Mean                  16.3785
trainer/Q Targets Std                    1.87432
trainer/Q Targets Max                   23.1139
trainer/Q Targets Min                    0.103277
trainer/Log Pis Mean                     2.50666
trainer/Log Pis Std                      2.83864
trainer/Log Pis Max                     11.4014
trainer/Log Pis Min                     -3.03992
trainer/policy/mean Mean                -0.496649
trainer/policy/mean Std                  0.689602
trainer/policy/mean Max                  0.998612
trainer/policy/mean Min                 -0.998844
trainer/policy/normal/std Mean           0.810947
trainer/policy/normal/std Std            0.27819
trainer/policy/normal/std Max            1.73817
trainer/policy/normal/std Min            0.113507
trainer/policy/normal/log_std Mean      -0.28059
trainer/policy/normal/log_std Std        0.405389
trainer/policy/normal/log_std Max        0.552833
trainer/policy/normal/log_std Min       -2.17589
trainer/Alpha                            0.00819253
trainer/Alpha Loss                       2.43425
exploration/num steps total          46000
exploration/num paths total            230
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.110721
exploration/Rewards Std                  0.0184451
exploration/Rewards Max                  0.126345
exploration/Rewards Min                  0.0636573
exploration/Returns Mean                22.1442
exploration/Returns Std                  2.78507
exploration/Returns Max                 24.2059
exploration/Returns Min                 16.9969
exploration/Actions Mean                -0.0800146
exploration/Actions Std                  0.768386
exploration/Actions Max                  0.999748
exploration/Actions Min                 -0.999863
exploration/Num Paths                    5
exploration/Average Returns             22.1442
evaluation/num steps total          217080
evaluation/num paths total            1080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117593
evaluation/Rewards Std                   0.0100505
evaluation/Rewards Max                   0.128209
evaluation/Rewards Min                   0.090545
evaluation/Returns Mean                 23.6362
evaluation/Returns Std                   1.91482
evaluation/Returns Max                  25.2529
evaluation/Returns Min                  18.2786
evaluation/Actions Mean                 -0.564866
evaluation/Actions Std                   0.397194
evaluation/Actions Max                   0.932428
evaluation/Actions Min                  -0.993114
evaluation/Num Paths                    24
evaluation/Average Returns              23.6362
time/data storing (s)                    0.0154042
time/evaluation sampling (s)            49.6947
time/exploration sampling (s)            9.95597
time/logging (s)                         0.021931
time/sac training (s)                   16.3912
time/saving (s)                          0.0287462
time/training (s)                        0.000128043
time/epoch (s)                          76.1081
time/total (s)                        3764.54
Epoch                                   44
----------------------------------  ----------------
2020-11-08 13:05:11.198868 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 45 finished
----------------------------------  ---------------
replay_buffer/size                   47000
trainer/num train calls              46000
trainer/QF1 Loss                         3.16353
trainer/QF2 Loss                         3.20846
trainer/Policy Loss                    -16.3154
trainer/Q1 Predictions Mean             16.3213
trainer/Q1 Predictions Std               1.58187
trainer/Q1 Predictions Max              23.1073
trainer/Q1 Predictions Min               6.65871
trainer/Q2 Predictions Mean             16.3257
trainer/Q2 Predictions Std               1.57648
trainer/Q2 Predictions Max              23.0951
trainer/Q2 Predictions Min               6.65964
trainer/Q Targets Mean                  16.1334
trainer/Q Targets Std                    2.34409
trainer/Q Targets Max                   23.0868
trainer/Q Targets Min                    0.113205
trainer/Log Pis Mean                     2.13528
trainer/Log Pis Std                      2.90148
trainer/Log Pis Max                     11.2517
trainer/Log Pis Min                     -5.10887
trainer/policy/mean Mean                -0.537464
trainer/policy/mean Std                  0.637216
trainer/policy/mean Max                  0.999353
trainer/policy/mean Min                 -0.998844
trainer/policy/normal/std Mean           0.894826
trainer/policy/normal/std Std            0.295743
trainer/policy/normal/std Max            1.7629
trainer/policy/normal/std Min            0.0999245
trainer/policy/normal/log_std Mean      -0.179161
trainer/policy/normal/log_std Std        0.401811
trainer/policy/normal/log_std Max        0.566962
trainer/policy/normal/log_std Min       -2.30334
trainer/Alpha                            0.00829937
trainer/Alpha Loss                       0.648198
exploration/num steps total          47000
exploration/num paths total            235
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.101248
exploration/Rewards Std                  0.0195721
exploration/Rewards Max                  0.12347
exploration/Rewards Min                  0.0531584
exploration/Returns Mean                20.2495
exploration/Returns Std                  2.47112
exploration/Returns Max                 24.1505
exploration/Returns Min                 16.4708
exploration/Actions Mean                -0.210507
exploration/Actions Std                  0.773555
exploration/Actions Max                  0.999625
exploration/Actions Min                 -0.999984
exploration/Num Paths                    5
exploration/Average Returns             20.2495
evaluation/num steps total          221904
evaluation/num paths total            1104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119957
evaluation/Rewards Std                   0.00653095
evaluation/Rewards Max                   0.127518
evaluation/Rewards Min                   0.0920917
evaluation/Returns Mean                 24.1115
evaluation/Returns Std                   1.25899
evaluation/Returns Max                  25.3172
evaluation/Returns Min                  18.681
evaluation/Actions Mean                 -0.633065
evaluation/Actions Std                   0.307186
evaluation/Actions Max                   0.867188
evaluation/Actions Min                  -0.992284
evaluation/Num Paths                    24
evaluation/Average Returns              24.1115
time/data storing (s)                    0.0146957
time/evaluation sampling (s)            49.2523
time/exploration sampling (s)            9.99068
time/logging (s)                         0.022802
time/sac training (s)                   16.3555
time/saving (s)                          0.0313086
time/training (s)                        0.00017454
time/epoch (s)                          75.6675
time/total (s)                        3841.49
Epoch                                   45
----------------------------------  ---------------
2020-11-08 13:06:27.897769 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 46 finished
----------------------------------  ----------------
replay_buffer/size                   48000
trainer/num train calls              47000
trainer/QF1 Loss                         1.98188
trainer/QF2 Loss                         1.99168
trainer/Policy Loss                    -16.1781
trainer/Q1 Predictions Mean             16.1815
trainer/Q1 Predictions Std               1.75442
trainer/Q1 Predictions Max              27.3724
trainer/Q1 Predictions Min              11.1739
trainer/Q2 Predictions Mean             16.1772
trainer/Q2 Predictions Std               1.75451
trainer/Q2 Predictions Max              27.316
trainer/Q2 Predictions Min              11.2063
trainer/Q Targets Mean                  16.076
trainer/Q Targets Std                    2.24794
trainer/Q Targets Max                   27.2784
trainer/Q Targets Min                    0.117706
trainer/Log Pis Mean                     1.98217
trainer/Log Pis Std                      3.08744
trainer/Log Pis Max                     15.2447
trainer/Log Pis Min                     -3.53417
trainer/policy/mean Mean                -0.283376
trainer/policy/mean Std                  0.774578
trainer/policy/mean Max                  0.999941
trainer/policy/mean Min                 -0.999788
trainer/policy/normal/std Mean           0.818883
trainer/policy/normal/std Std            0.276309
trainer/policy/normal/std Max            2.07063
trainer/policy/normal/std Min            0.082305
trainer/policy/normal/log_std Mean      -0.272663
trainer/policy/normal/log_std Std        0.421767
trainer/policy/normal/log_std Max        0.727854
trainer/policy/normal/log_std Min       -2.49732
trainer/Alpha                            0.00746501
trainer/Alpha Loss                      -0.087303
exploration/num steps total          48000
exploration/num paths total            240
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.120687
exploration/Rewards Std                  0.00247681
exploration/Rewards Max                  0.123843
exploration/Rewards Min                  0.111537
exploration/Returns Mean                24.1374
exploration/Returns Std                  0.498452
exploration/Returns Max                 24.7044
exploration/Returns Min                 23.2521
exploration/Actions Mean                -0.295294
exploration/Actions Std                  0.77628
exploration/Actions Max                  0.999554
exploration/Actions Min                 -0.99955
exploration/Num Paths                    5
exploration/Average Returns             24.1374
evaluation/num steps total          226728
evaluation/num paths total            1128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.12101
evaluation/Rewards Std                   0.00588682
evaluation/Rewards Max                   0.125058
evaluation/Rewards Min                   0.0926099
evaluation/Returns Mean                 24.323
evaluation/Returns Std                   1.173
evaluation/Returns Max                  24.7699
evaluation/Returns Min                  18.7501
evaluation/Actions Mean                 -0.119668
evaluation/Actions Std                   0.828693
evaluation/Actions Max                   0.946794
evaluation/Actions Min                  -0.959232
evaluation/Num Paths                    24
evaluation/Average Returns              24.323
time/data storing (s)                    0.0149535
time/evaluation sampling (s)            49.0988
time/exploration sampling (s)            9.91741
time/logging (s)                         0.021533
time/sac training (s)                   16.3333
time/saving (s)                          0.0308756
time/training (s)                        0.000141488
time/epoch (s)                          75.4171
time/total (s)                        3918.16
Epoch                                   46
----------------------------------  ----------------
2020-11-08 13:07:44.743405 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 47 finished
----------------------------------  ----------------
replay_buffer/size                   49000
trainer/num train calls              48000
trainer/QF1 Loss                         0.650156
trainer/QF2 Loss                         0.658275
trainer/Policy Loss                    -16.0058
trainer/Q1 Predictions Mean             16.0103
trainer/Q1 Predictions Std               1.58965
trainer/Q1 Predictions Max              22.4779
trainer/Q1 Predictions Min               7.12355
trainer/Q2 Predictions Mean             16.0088
trainer/Q2 Predictions Std               1.59568
trainer/Q2 Predictions Max              22.4738
trainer/Q2 Predictions Min               6.93966
trainer/Q Targets Mean                  15.9961
trainer/Q Targets Std                    1.80813
trainer/Q Targets Max                   22.4449
trainer/Q Targets Min                    0.112715
trainer/Log Pis Mean                     1.72927
trainer/Log Pis Std                      2.88555
trainer/Log Pis Max                     12.0042
trainer/Log Pis Min                     -3.41068
trainer/policy/mean Mean                -0.424329
trainer/policy/mean Std                  0.698143
trainer/policy/mean Max                  0.999738
trainer/policy/mean Min                 -0.999264
trainer/policy/normal/std Mean           0.914714
trainer/policy/normal/std Std            0.353168
trainer/policy/normal/std Max            2.7473
trainer/policy/normal/std Min            0.0710442
trainer/policy/normal/log_std Mean      -0.179442
trainer/policy/normal/log_std Std        0.469719
trainer/policy/normal/log_std Max        1.01062
trainer/policy/normal/log_std Min       -2.64445
trainer/Alpha                            0.00796246
trainer/Alpha Loss                      -1.30842
exploration/num steps total          49000
exploration/num paths total            245
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.113609
exploration/Rewards Std                  0.0116547
exploration/Rewards Max                  0.123436
exploration/Rewards Min                  0.088545
exploration/Returns Mean                22.7218
exploration/Returns Std                  2.45361
exploration/Returns Max                 24.6104
exploration/Returns Min                 18.0744
exploration/Actions Mean                -0.0345571
exploration/Actions Std                  0.807288
exploration/Actions Max                  0.999765
exploration/Actions Min                 -0.99994
exploration/Num Paths                    5
exploration/Average Returns             22.7218
evaluation/num steps total          231552
evaluation/num paths total            1152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119707
evaluation/Rewards Std                   0.00811299
evaluation/Rewards Max                   0.127669
evaluation/Rewards Min                   0.0929051
evaluation/Returns Mean                 24.0611
evaluation/Returns Std                   1.61152
evaluation/Returns Max                  25.0851
evaluation/Returns Min                  18.7911
evaluation/Actions Mean                 -0.370775
evaluation/Actions Std                   0.598548
evaluation/Actions Max                   0.969166
evaluation/Actions Min                  -0.978807
evaluation/Num Paths                    24
evaluation/Average Returns              24.0611
time/data storing (s)                    0.0154572
time/evaluation sampling (s)            49.1734
time/exploration sampling (s)            9.95079
time/logging (s)                         0.0210751
time/sac training (s)                   16.3585
time/saving (s)                          0.0322762
time/training (s)                        0.000130279
time/epoch (s)                          75.5517
time/total (s)                        3994.98
Epoch                                   47
----------------------------------  ----------------
2020-11-08 13:09:02.236610 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 48 finished
----------------------------------  ----------------
replay_buffer/size                   50000
trainer/num train calls              49000
trainer/QF1 Loss                         0.825304
trainer/QF2 Loss                         0.82354
trainer/Policy Loss                    -16.1119
trainer/Q1 Predictions Mean             16.122
trainer/Q1 Predictions Std               1.47288
trainer/Q1 Predictions Max              21.7587
trainer/Q1 Predictions Min               9.91426
trainer/Q2 Predictions Mean             16.1158
trainer/Q2 Predictions Std               1.47299
trainer/Q2 Predictions Max              21.8371
trainer/Q2 Predictions Min               9.98551
trainer/Q Targets Mean                  16.0881
trainer/Q Targets Std                    1.77301
trainer/Q Targets Max                   21.8094
trainer/Q Targets Min                    0.122462
trainer/Log Pis Mean                     2.09168
trainer/Log Pis Std                      3.02734
trainer/Log Pis Max                     12.4886
trainer/Log Pis Min                     -6.24057
trainer/policy/mean Mean                -0.0951511
trainer/policy/mean Std                  0.837734
trainer/policy/mean Max                  0.999945
trainer/policy/mean Min                 -0.998321
trainer/policy/normal/std Mean           0.770934
trainer/policy/normal/std Std            0.268729
trainer/policy/normal/std Max            1.85754
trainer/policy/normal/std Min            0.0653533
trainer/policy/normal/log_std Mean      -0.345396
trainer/policy/normal/log_std Std        0.474026
trainer/policy/normal/log_std Max        0.619254
trainer/policy/normal/log_std Min       -2.72795
trainer/Alpha                            0.00869382
trainer/Alpha Loss                       0.435015
exploration/num steps total          50000
exploration/num paths total            250
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.1211
exploration/Rewards Std                  0.00361975
exploration/Rewards Max                  0.123399
exploration/Rewards Min                  0.106915
exploration/Returns Mean                24.2201
exploration/Returns Std                  0.529349
exploration/Returns Max                 24.6755
exploration/Returns Min                 23.2521
exploration/Actions Mean                -0.038413
exploration/Actions Std                  0.845752
exploration/Actions Max                  0.999921
exploration/Actions Min                 -0.998637
exploration/Num Paths                    5
exploration/Average Returns             24.2201
evaluation/num steps total          236376
evaluation/num paths total            1176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121291
evaluation/Rewards Std                   0.00580378
evaluation/Rewards Max                   0.123433
evaluation/Rewards Min                   0.09299
evaluation/Returns Mean                 24.3794
evaluation/Returns Std                   1.16428
evaluation/Returns Max                  24.7562
evaluation/Returns Min                  18.8168
evaluation/Actions Mean                  0.0036016
evaluation/Actions Std                   0.927784
evaluation/Actions Max                   0.956476
evaluation/Actions Min                  -0.939265
evaluation/Num Paths                    24
evaluation/Average Returns              24.3794
time/data storing (s)                    0.0149874
time/evaluation sampling (s)            49.6902
time/exploration sampling (s)            9.99904
time/logging (s)                         0.0213598
time/sac training (s)                   16.4188
time/saving (s)                          0.0382811
time/training (s)                        0.000143697
time/epoch (s)                          76.1828
time/total (s)                        4072.44
Epoch                                   48
----------------------------------  ----------------
2020-11-08 13:10:19.108856 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 49 finished
----------------------------------  ----------------
replay_buffer/size                   51000
trainer/num train calls              50000
trainer/QF1 Loss                         2.43482
trainer/QF2 Loss                         2.42826
trainer/Policy Loss                    -16.0871
trainer/Q1 Predictions Mean             16.0592
trainer/Q1 Predictions Std               1.99077
trainer/Q1 Predictions Max              25.7081
trainer/Q1 Predictions Min               5.94699
trainer/Q2 Predictions Mean             16.0623
trainer/Q2 Predictions Std               1.98754
trainer/Q2 Predictions Max              25.7504
trainer/Q2 Predictions Min               5.9469
trainer/Q Targets Mean                  15.8702
trainer/Q Targets Std                    2.6097
trainer/Q Targets Max                   25.5823
trainer/Q Targets Min                    0.0857969
trainer/Log Pis Mean                     2.00563
trainer/Log Pis Std                      3.20326
trainer/Log Pis Max                     13.8155
trainer/Log Pis Min                     -3.47737
trainer/policy/mean Mean                -0.436029
trainer/policy/mean Std                  0.69084
trainer/policy/mean Max                  0.999805
trainer/policy/mean Min                 -0.999808
trainer/policy/normal/std Mean           0.923748
trainer/policy/normal/std Std            0.377659
trainer/policy/normal/std Max            2.57721
trainer/policy/normal/std Min            0.054615
trainer/policy/normal/log_std Mean      -0.188272
trainer/policy/normal/log_std Std        0.525709
trainer/policy/normal/log_std Max        0.946709
trainer/policy/normal/log_std Min       -2.90745
trainer/Alpha                            0.00768291
trainer/Alpha Loss                       0.0274287
exploration/num steps total          51000
exploration/num paths total            255
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.111909
exploration/Rewards Std                  0.0169973
exploration/Rewards Max                  0.124179
exploration/Rewards Min                  0.0683425
exploration/Returns Mean                22.3819
exploration/Returns Std                  3.50318
exploration/Returns Max                 24.6571
exploration/Returns Min                 15.442
exploration/Actions Mean                -0.211559
exploration/Actions Std                  0.791392
exploration/Actions Max                  0.999912
exploration/Actions Min                 -0.999991
exploration/Num Paths                    5
exploration/Average Returns             22.3819
evaluation/num steps total          241200
evaluation/num paths total            1200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119829
evaluation/Rewards Std                   0.00633597
evaluation/Rewards Max                   0.125504
evaluation/Rewards Min                   0.0894774
evaluation/Returns Mean                 24.0857
evaluation/Returns Std                   1.23407
evaluation/Returns Max                  24.9711
evaluation/Returns Min                  18.3988
evaluation/Actions Mean                 -0.454743
evaluation/Actions Std                   0.585197
evaluation/Actions Max                   0.986301
evaluation/Actions Min                  -0.9974
evaluation/Num Paths                    24
evaluation/Average Returns              24.0857
time/data storing (s)                    0.0150575
time/evaluation sampling (s)            49.0998
time/exploration sampling (s)           10.0095
time/logging (s)                         0.0232439
time/sac training (s)                   16.3883
time/saving (s)                          0.0285605
time/training (s)                        0.000125918
time/epoch (s)                          75.5646
time/total (s)                        4149.29
Epoch                                   49
----------------------------------  ----------------
2020-11-08 13:11:35.913825 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 50 finished
----------------------------------  ----------------
replay_buffer/size                   52000
trainer/num train calls              51000
trainer/QF1 Loss                         0.0478592
trainer/QF2 Loss                         0.0474532
trainer/Policy Loss                    -16.1253
trainer/Q1 Predictions Mean             16.1121
trainer/Q1 Predictions Std               1.79251
trainer/Q1 Predictions Max              24.8391
trainer/Q1 Predictions Min               6.65294
trainer/Q2 Predictions Mean             16.1162
trainer/Q2 Predictions Std               1.79263
trainer/Q2 Predictions Max              24.7749
trainer/Q2 Predictions Min               6.65183
trainer/Q Targets Mean                  16.0913
trainer/Q Targets Std                    1.73722
trainer/Q Targets Max                   24.4312
trainer/Q Targets Min                    8.54706
trainer/Log Pis Mean                     1.78882
trainer/Log Pis Std                      3.12341
trainer/Log Pis Max                     13.6332
trainer/Log Pis Min                     -4.41101
trainer/policy/mean Mean                -0.348659
trainer/policy/mean Std                  0.729366
trainer/policy/mean Max                  0.999834
trainer/policy/mean Min                 -0.999428
trainer/policy/normal/std Mean           0.877173
trainer/policy/normal/std Std            0.392033
trainer/policy/normal/std Max            3.28535
trainer/policy/normal/std Min            0.0542899
trainer/policy/normal/log_std Mean      -0.248824
trainer/policy/normal/log_std Std        0.539886
trainer/policy/normal/log_std Max        1.18947
trainer/policy/normal/log_std Min       -2.91342
trainer/Alpha                            0.00764102
trainer/Alpha Loss                      -1.02936
exploration/num steps total          52000
exploration/num paths total            260
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.119881
exploration/Rewards Std                  0.00328162
exploration/Rewards Max                  0.124152
exploration/Rewards Min                  0.109618
exploration/Returns Mean                23.9761
exploration/Returns Std                  0.329982
exploration/Returns Max                 24.4418
exploration/Returns Min                 23.592
exploration/Actions Mean                -0.190428
exploration/Actions Std                  0.762674
exploration/Actions Max                  0.999741
exploration/Actions Min                 -0.999895
exploration/Num Paths                    5
exploration/Average Returns             23.9761
evaluation/num steps total          246024
evaluation/num paths total            1224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.122051
evaluation/Rewards Std                   0.00144055
evaluation/Rewards Max                   0.126153
evaluation/Rewards Min                   0.116497
evaluation/Returns Mean                 24.5322
evaluation/Returns Std                   0.239045
evaluation/Returns Max                  24.891
evaluation/Returns Min                  23.9698
evaluation/Actions Mean                 -0.178183
evaluation/Actions Std                   0.796368
evaluation/Actions Max                   0.96781
evaluation/Actions Min                  -0.98914
evaluation/Num Paths                    24
evaluation/Average Returns              24.5322
time/data storing (s)                    0.0164105
time/evaluation sampling (s)            49.0973
time/exploration sampling (s)           10.0297
time/logging (s)                         0.0204443
time/sac training (s)                   16.3161
time/saving (s)                          0.02948
time/training (s)                        0.000142748
time/epoch (s)                          75.5096
time/total (s)                        4226.06
Epoch                                   50
----------------------------------  ----------------
2020-11-08 13:12:53.153721 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 51 finished
----------------------------------  ----------------
replay_buffer/size                   53000
trainer/num train calls              52000
trainer/QF1 Loss                         0.0428154
trainer/QF2 Loss                         0.0385658
trainer/Policy Loss                    -15.8721
trainer/Q1 Predictions Mean             15.839
trainer/Q1 Predictions Std               1.66039
trainer/Q1 Predictions Max              23.0713
trainer/Q1 Predictions Min               9.56623
trainer/Q2 Predictions Mean             15.8464
trainer/Q2 Predictions Std               1.67857
trainer/Q2 Predictions Max              23.0993
trainer/Q2 Predictions Min               9.63284
trainer/Q Targets Mean                  15.9165
trainer/Q Targets Std                    1.67453
trainer/Q Targets Max                   22.254
trainer/Q Targets Min                   10.3665
trainer/Log Pis Mean                     2.18417
trainer/Log Pis Std                      3.24431
trainer/Log Pis Max                     14.7562
trainer/Log Pis Min                     -4.90315
trainer/policy/mean Mean                -0.300883
trainer/policy/mean Std                  0.781763
trainer/policy/mean Max                  0.999773
trainer/policy/mean Min                 -0.999728
trainer/policy/normal/std Mean           0.884112
trainer/policy/normal/std Std            0.473722
trainer/policy/normal/std Max            5.56231
trainer/policy/normal/std Min            0.0550843
trainer/policy/normal/log_std Mean      -0.252596
trainer/policy/normal/log_std Std        0.542028
trainer/policy/normal/log_std Max        1.71601
trainer/policy/normal/log_std Min       -2.89889
trainer/Alpha                            0.00746731
trainer/Alpha Loss                       0.901917
exploration/num steps total          53000
exploration/num paths total            265
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.111802
exploration/Rewards Std                  0.0176624
exploration/Rewards Max                  0.126353
exploration/Rewards Min                  0.0632843
exploration/Returns Mean                22.3604
exploration/Returns Std                  2.90963
exploration/Returns Max                 25.0461
exploration/Returns Min                 17.9734
exploration/Actions Mean                -0.179655
exploration/Actions Std                  0.823277
exploration/Actions Max                  0.99992
exploration/Actions Min                 -0.999978
exploration/Num Paths                    5
exploration/Average Returns             22.3604
evaluation/num steps total          250848
evaluation/num paths total            1248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.120095
evaluation/Rewards Std                   0.00698609
evaluation/Rewards Max                   0.125664
evaluation/Rewards Min                   0.0877631
evaluation/Returns Mean                 24.139
evaluation/Returns Std                   1.25486
evaluation/Returns Max                  24.9529
evaluation/Returns Min                  18.5468
evaluation/Actions Mean                 -0.2065
evaluation/Actions Std                   0.800982
evaluation/Actions Max                   0.931017
evaluation/Actions Min                  -0.978586
evaluation/Num Paths                    24
evaluation/Average Returns              24.139
time/data storing (s)                    0.0165776
time/evaluation sampling (s)            49.0464
time/exploration sampling (s)            9.98288
time/logging (s)                         0.0237929
time/sac training (s)                   16.8443
time/saving (s)                          0.0370227
time/training (s)                        0.000134086
time/epoch (s)                          75.9512
time/total (s)                        4303.27
Epoch                                   51
----------------------------------  ----------------
2020-11-08 13:14:10.396743 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 52 finished
----------------------------------  ----------------
replay_buffer/size                   54000
trainer/num train calls              53000
trainer/QF1 Loss                         0.106169
trainer/QF2 Loss                         0.108026
trainer/Policy Loss                    -15.8087
trainer/Q1 Predictions Mean             15.8545
trainer/Q1 Predictions Std               2.00237
trainer/Q1 Predictions Max              26.8353
trainer/Q1 Predictions Min               7.26687
trainer/Q2 Predictions Mean             15.8568
trainer/Q2 Predictions Std               2.00301
trainer/Q2 Predictions Max              26.807
trainer/Q2 Predictions Min               7.26892
trainer/Q Targets Mean                  15.9583
trainer/Q Targets Std                    1.96921
trainer/Q Targets Max                   27.0809
trainer/Q Targets Min                    7.54872
trainer/Log Pis Mean                     2.5339
trainer/Log Pis Std                      3.37909
trainer/Log Pis Max                     14.107
trainer/Log Pis Min                     -3.7083
trainer/policy/mean Mean                -0.541241
trainer/policy/mean Std                  0.657912
trainer/policy/mean Max                  0.999889
trainer/policy/mean Min                 -0.999794
trainer/policy/normal/std Mean           0.829348
trainer/policy/normal/std Std            0.38839
trainer/policy/normal/std Max            2.79712
trainer/policy/normal/std Min            0.0528634
trainer/policy/normal/log_std Mean      -0.318137
trainer/policy/normal/log_std Std        0.560023
trainer/policy/normal/log_std Max        1.02859
trainer/policy/normal/log_std Min       -2.94004
trainer/Alpha                            0.00720796
trainer/Alpha Loss                       2.63351
exploration/num steps total          54000
exploration/num paths total            270
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.109629
exploration/Rewards Std                  0.0156394
exploration/Rewards Max                  0.128399
exploration/Rewards Min                  0.072194
exploration/Returns Mean                21.9258
exploration/Returns Std                  2.28173
exploration/Returns Max                 24.928
exploration/Returns Min                 18.5056
exploration/Actions Mean                -0.519513
exploration/Actions Std                  0.742246
exploration/Actions Max                  0.99997
exploration/Actions Min                 -0.999989
exploration/Num Paths                    5
exploration/Average Returns             21.9258
evaluation/num steps total          255672
evaluation/num paths total            1272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.114592
evaluation/Rewards Std                   0.0104867
evaluation/Rewards Max                   0.125619
evaluation/Rewards Min                   0.0855261
evaluation/Returns Mean                 23.033
evaluation/Returns Std                   1.96748
evaluation/Returns Max                  24.7723
evaluation/Returns Min                  17.617
evaluation/Actions Mean                 -0.48817
evaluation/Actions Std                   0.577878
evaluation/Actions Max                   0.999271
evaluation/Actions Min                  -0.999617
evaluation/Num Paths                    24
evaluation/Average Returns              23.033
time/data storing (s)                    0.014435
time/evaluation sampling (s)            49.3082
time/exploration sampling (s)            9.99358
time/logging (s)                         0.0226946
time/sac training (s)                   16.5646
time/saving (s)                          0.0298425
time/training (s)                        0.000152089
time/epoch (s)                          75.9335
time/total (s)                        4380.49
Epoch                                   52
----------------------------------  ----------------
2020-11-08 13:15:27.019771 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 53 finished
----------------------------------  ----------------
replay_buffer/size                   55000
trainer/num train calls              54000
trainer/QF1 Loss                         1.08083
trainer/QF2 Loss                         1.07204
trainer/Policy Loss                    -15.7941
trainer/Q1 Predictions Mean             15.7641
trainer/Q1 Predictions Std               1.9901
trainer/Q1 Predictions Max              25.6197
trainer/Q1 Predictions Min               6.19664
trainer/Q2 Predictions Mean             15.7518
trainer/Q2 Predictions Std               1.9987
trainer/Q2 Predictions Max              25.6158
trainer/Q2 Predictions Min               6.25158
trainer/Q Targets Mean                  15.6506
trainer/Q Targets Std                    2.13957
trainer/Q Targets Max                   24.6538
trainer/Q Targets Min                    0.120344
trainer/Log Pis Mean                     2.1947
trainer/Log Pis Std                      3.26763
trainer/Log Pis Max                     17.2184
trainer/Log Pis Min                     -6.06615
trainer/policy/mean Mean                -0.00918413
trainer/policy/mean Std                  0.828818
trainer/policy/mean Max                  0.999991
trainer/policy/mean Min                 -0.999896
trainer/policy/normal/std Mean           0.95954
trainer/policy/normal/std Std            0.485805
trainer/policy/normal/std Max            7.05707
trainer/policy/normal/std Min            0.0604093
trainer/policy/normal/log_std Mean      -0.144926
trainer/policy/normal/log_std Std        0.496964
trainer/policy/normal/log_std Max        1.95403
trainer/policy/normal/log_std Min       -2.80661
trainer/Alpha                            0.00672254
trainer/Alpha Loss                       0.973968
exploration/num steps total          55000
exploration/num paths total            275
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.110151
exploration/Rewards Std                  0.014103
exploration/Rewards Max                  0.124178
exploration/Rewards Min                  0.0755377
exploration/Returns Mean                22.0302
exploration/Returns Std                  2.09688
exploration/Returns Max                 24.5681
exploration/Returns Min                 18.8386
exploration/Actions Mean                -0.0206778
exploration/Actions Std                  0.75767
exploration/Actions Max                  0.999817
exploration/Actions Min                 -0.999676
exploration/Num Paths                    5
exploration/Average Returns             22.0302
evaluation/num steps total          260496
evaluation/num paths total            1296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.118983
evaluation/Rewards Std                   0.00860724
evaluation/Rewards Max                   0.127337
evaluation/Rewards Min                   0.0876201
evaluation/Returns Mean                 23.9156
evaluation/Returns Std                   1.6025
evaluation/Returns Max                  25.2928
evaluation/Returns Min                  18.9626
evaluation/Actions Mean                 -0.108617
evaluation/Actions Std                   0.713623
evaluation/Actions Max                   0.988043
evaluation/Actions Min                  -0.999008
evaluation/Num Paths                    24
evaluation/Average Returns              23.9156
time/data storing (s)                    0.015017
time/evaluation sampling (s)            49.0144
time/exploration sampling (s)            9.94733
time/logging (s)                         0.0231412
time/sac training (s)                   16.275
time/saving (s)                          0.0283106
time/training (s)                        0.000125531
time/epoch (s)                          75.3034
time/total (s)                        4457.08
Epoch                                   53
----------------------------------  ----------------
2020-11-08 13:16:43.761645 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 54 finished
----------------------------------  ----------------
replay_buffer/size                   56000
trainer/num train calls              55000
trainer/QF1 Loss                         1.07497
trainer/QF2 Loss                         1.07547
trainer/Policy Loss                    -15.9228
trainer/Q1 Predictions Mean             15.9054
trainer/Q1 Predictions Std               1.72912
trainer/Q1 Predictions Max              22.5948
trainer/Q1 Predictions Min              11.0064
trainer/Q2 Predictions Mean             15.8979
trainer/Q2 Predictions Std               1.73469
trainer/Q2 Predictions Max              22.5918
trainer/Q2 Predictions Min              10.9393
trainer/Q Targets Mean                  15.8229
trainer/Q Targets Std                    1.96133
trainer/Q Targets Max                   22.5833
trainer/Q Targets Min                    0.12233
trainer/Log Pis Mean                     1.9901
trainer/Log Pis Std                      3.39787
trainer/Log Pis Max                     16.3365
trainer/Log Pis Min                     -5.19673
trainer/policy/mean Mean                -0.0661
trainer/policy/mean Std                  0.81998
trainer/policy/mean Max                  0.999993
trainer/policy/mean Min                 -0.999546
trainer/policy/normal/std Mean           0.879543
trainer/policy/normal/std Std            0.308815
trainer/policy/normal/std Max            2.04969
trainer/policy/normal/std Min            0.0494654
trainer/policy/normal/log_std Mean      -0.208972
trainer/policy/normal/log_std Std        0.450225
trainer/policy/normal/log_std Max        0.71769
trainer/policy/normal/log_std Min       -3.00648
trainer/Alpha                            0.0077008
trainer/Alpha Loss                      -0.0481904
exploration/num steps total          56000
exploration/num paths total            280
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.114033
exploration/Rewards Std                  0.0115546
exploration/Rewards Max                  0.126628
exploration/Rewards Min                  0.0892163
exploration/Returns Mean                22.8067
exploration/Returns Std                  2.19384
exploration/Returns Max                 24.6786
exploration/Returns Min                 18.5144
exploration/Actions Mean                -0.142375
exploration/Actions Std                  0.758198
exploration/Actions Max                  0.999864
exploration/Actions Min                 -0.999943
exploration/Num Paths                    5
exploration/Average Returns             22.8067
evaluation/num steps total          265320
evaluation/num paths total            1320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121268
evaluation/Rewards Std                   0.00582824
evaluation/Rewards Max                   0.125947
evaluation/Rewards Min                   0.0932842
evaluation/Returns Mean                 24.3749
evaluation/Returns Std                   1.16627
evaluation/Returns Max                  24.9626
evaluation/Returns Min                  18.8122
evaluation/Actions Mean                 -0.00278148
evaluation/Actions Std                   0.838406
evaluation/Actions Max                   0.959913
evaluation/Actions Min                  -0.969418
evaluation/Num Paths                    24
evaluation/Average Returns              24.3749
time/data storing (s)                    0.0150714
time/evaluation sampling (s)            49.0964
time/exploration sampling (s)            9.93601
time/logging (s)                         0.0229405
time/sac training (s)                   16.3557
time/saving (s)                          0.0282635
time/training (s)                        0.000146262
time/epoch (s)                          75.4546
time/total (s)                        4533.8
Epoch                                   54
----------------------------------  ----------------
2020-11-08 13:18:02.297487 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 55 finished
----------------------------------  ----------------
replay_buffer/size                   57000
trainer/num train calls              56000
trainer/QF1 Loss                         0.863766
trainer/QF2 Loss                         0.848943
trainer/Policy Loss                    -15.7378
trainer/Q1 Predictions Mean             15.735
trainer/Q1 Predictions Std               1.7508
trainer/Q1 Predictions Max              24.646
trainer/Q1 Predictions Min               8.98193
trainer/Q2 Predictions Mean             15.7395
trainer/Q2 Predictions Std               1.73855
trainer/Q2 Predictions Max              24.6731
trainer/Q2 Predictions Min               9.11909
trainer/Q Targets Mean                  15.7423
trainer/Q Targets Std                    2.00157
trainer/Q Targets Max                   24.513
trainer/Q Targets Min                    0.118313
trainer/Log Pis Mean                     1.99479
trainer/Log Pis Std                      3.36266
trainer/Log Pis Max                     15.33
trainer/Log Pis Min                     -4.18922
trainer/policy/mean Mean                -0.148426
trainer/policy/mean Std                  0.789095
trainer/policy/mean Max                  0.999952
trainer/policy/mean Min                 -0.99995
trainer/policy/normal/std Mean           0.97611
trainer/policy/normal/std Std            0.514183
trainer/policy/normal/std Max            6.40807
trainer/policy/normal/std Min            0.0514921
trainer/policy/normal/log_std Mean      -0.135173
trainer/policy/normal/log_std Std        0.500112
trainer/policy/normal/log_std Max        1.85756
trainer/policy/normal/log_std Min       -2.96633
trainer/Alpha                            0.00755491
trainer/Alpha Loss                      -0.0254385
exploration/num steps total          57000
exploration/num paths total            285
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.0977469
exploration/Rewards Std                  0.0239842
exploration/Rewards Max                  0.125138
exploration/Rewards Min                  0.0621215
exploration/Returns Mean                19.5494
exploration/Returns Std                  3.15271
exploration/Returns Max                 24.6424
exploration/Returns Min                 15.9466
exploration/Actions Mean                 0.0908488
exploration/Actions Std                  0.837512
exploration/Actions Max                  1
exploration/Actions Min                 -1
exploration/Num Paths                    5
exploration/Average Returns             19.5494
evaluation/num steps total          270144
evaluation/num paths total            1344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.117248
evaluation/Rewards Std                   0.0107336
evaluation/Rewards Max                   0.125029
evaluation/Rewards Min                   0.0901038
evaluation/Returns Mean                 23.5669
evaluation/Returns Std                   2.09274
evaluation/Returns Max                  24.7521
evaluation/Returns Min                  18.7444
evaluation/Actions Mean                 -0.0516186
evaluation/Actions Std                   0.742969
evaluation/Actions Max                   0.999046
evaluation/Actions Min                  -0.999552
evaluation/Num Paths                    24
evaluation/Average Returns              23.5669
time/data storing (s)                    0.0155045
time/evaluation sampling (s)            49.0966
time/exploration sampling (s)            9.90993
time/logging (s)                         0.0276905
time/sac training (s)                   18.1242
time/saving (s)                          0.0460757
time/training (s)                        0.000131332
time/epoch (s)                          77.2201
time/total (s)                        4612.31
Epoch                                   55
----------------------------------  ----------------
2020-11-08 13:19:19.399423 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 56 finished
----------------------------------  ----------------
replay_buffer/size                   58000
trainer/num train calls              57000
trainer/QF1 Loss                         2.97488
trainer/QF2 Loss                         2.97049
trainer/Policy Loss                    -15.8555
trainer/Q1 Predictions Mean             15.8332
trainer/Q1 Predictions Std               1.8387
trainer/Q1 Predictions Max              23.3753
trainer/Q1 Predictions Min               8.85202
trainer/Q2 Predictions Mean             15.8382
trainer/Q2 Predictions Std               1.84792
trainer/Q2 Predictions Max              23.3208
trainer/Q2 Predictions Min               8.91216
trainer/Q Targets Mean                  15.7506
trainer/Q Targets Std                    2.53314
trainer/Q Targets Max                   23.4895
trainer/Q Targets Min                    0.114294
trainer/Log Pis Mean                     1.98181
trainer/Log Pis Std                      3.16007
trainer/Log Pis Max                     12.9785
trainer/Log Pis Min                     -3.95021
trainer/policy/mean Mean                -0.290385
trainer/policy/mean Std                  0.774987
trainer/policy/mean Max                  0.999941
trainer/policy/mean Min                 -0.999912
trainer/policy/normal/std Mean           0.809288
trainer/policy/normal/std Std            0.307887
trainer/policy/normal/std Max            2.05024
trainer/policy/normal/std Min            0.037607
trainer/policy/normal/log_std Mean      -0.314346
trainer/policy/normal/log_std Std        0.530362
trainer/policy/normal/log_std Max        0.717957
trainer/policy/normal/log_std Min       -3.28057
trainer/Alpha                            0.00723548
trainer/Alpha Loss                      -0.0896626
exploration/num steps total          58000
exploration/num paths total            290
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.114932
exploration/Rewards Std                  0.00973782
exploration/Rewards Max                  0.123191
exploration/Rewards Min                  0.0929569
exploration/Returns Mean                22.9863
exploration/Returns Std                  1.45065
exploration/Returns Max                 24.1858
exploration/Returns Min                 20.2788
exploration/Actions Mean                -0.172516
exploration/Actions Std                  0.705314
exploration/Actions Max                  0.99968
exploration/Actions Min                 -0.999944
exploration/Num Paths                    5
exploration/Average Returns             22.9863
evaluation/num steps total          274968
evaluation/num paths total            1368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119624
evaluation/Rewards Std                   0.00828223
evaluation/Rewards Max                   0.125772
evaluation/Rewards Min                   0.0895082
evaluation/Returns Mean                 24.0445
evaluation/Returns Std                   1.65395
evaluation/Returns Max                  24.8273
evaluation/Returns Min                  18.5837
evaluation/Actions Mean                 -0.30132
evaluation/Actions Std                   0.647688
evaluation/Actions Max                   0.773419
evaluation/Actions Min                  -0.982539
evaluation/Num Paths                    24
evaluation/Average Returns              24.0445
time/data storing (s)                    0.0149503
time/evaluation sampling (s)            49.3473
time/exploration sampling (s)            9.99452
time/logging (s)                         0.0270728
time/sac training (s)                   16.3908
time/saving (s)                          0.0276054
time/training (s)                        0.000126594
time/epoch (s)                          75.8024
time/total (s)                        4689.38
Epoch                                   56
----------------------------------  ----------------
2020-11-08 13:20:36.173269 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 57 finished
----------------------------------  ----------------
replay_buffer/size                   59000
trainer/num train calls              58000
trainer/QF1 Loss                         0.0290355
trainer/QF2 Loss                         0.0309025
trainer/Policy Loss                    -15.7433
trainer/Q1 Predictions Mean             15.7528
trainer/Q1 Predictions Std               1.66482
trainer/Q1 Predictions Max              24.1206
trainer/Q1 Predictions Min               6.7145
trainer/Q2 Predictions Mean             15.7415
trainer/Q2 Predictions Std               1.66606
trainer/Q2 Predictions Max              24.0682
trainer/Q2 Predictions Min               6.74881
trainer/Q Targets Mean                  15.7456
trainer/Q Targets Std                    1.64942
trainer/Q Targets Max                   23.9845
trainer/Q Targets Min                    6.83214
trainer/Log Pis Mean                     1.48931
trainer/Log Pis Std                      2.91301
trainer/Log Pis Max                     14.5049
trainer/Log Pis Min                     -4.29802
trainer/policy/mean Mean                 0.0384278
trainer/policy/mean Std                  0.791247
trainer/policy/mean Max                  0.999771
trainer/policy/mean Min                 -0.999008
trainer/policy/normal/std Mean           0.888956
trainer/policy/normal/std Std            0.303545
trainer/policy/normal/std Max            1.70752
trainer/policy/normal/std Min            0.0505403
trainer/policy/normal/log_std Mean      -0.20813
trainer/policy/normal/log_std Std        0.506833
trainer/policy/normal/log_std Max        0.535045
trainer/policy/normal/log_std Min       -2.98498
trainer/Alpha                            0.00740694
trainer/Alpha Loss                      -2.50512
exploration/num steps total          59000
exploration/num paths total            295
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.113184
exploration/Rewards Std                  0.0140801
exploration/Rewards Max                  0.126839
exploration/Rewards Min                  0.0859291
exploration/Returns Mean                22.6368
exploration/Returns Std                  2.77526
exploration/Returns Max                 25.0924
exploration/Returns Min                 18.5214
exploration/Actions Mean                -0.0246236
exploration/Actions Std                  0.785884
exploration/Actions Max                  0.999844
exploration/Actions Min                 -0.999904
exploration/Num Paths                    5
exploration/Average Returns             22.6368
evaluation/num steps total          279792
evaluation/num paths total            1392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119563
evaluation/Rewards Std                   0.00872517
evaluation/Rewards Max                   0.125987
evaluation/Rewards Min                   0.091482
evaluation/Returns Mean                 24.0321
evaluation/Returns Std                   1.67385
evaluation/Returns Max                  25.0439
evaluation/Returns Min                  18.7532
evaluation/Actions Mean                  0.076619
evaluation/Actions Std                   0.725276
evaluation/Actions Max                   0.997987
evaluation/Actions Min                  -0.997822
evaluation/Num Paths                    24
evaluation/Average Returns              24.0321
time/data storing (s)                    0.0146202
time/evaluation sampling (s)            49.1411
time/exploration sampling (s)            9.94897
time/logging (s)                         0.0198913
time/sac training (s)                   16.2924
time/saving (s)                          0.0286327
time/training (s)                        0.000123077
time/epoch (s)                          75.4457
time/total (s)                        4766.12
Epoch                                   57
----------------------------------  ----------------
2020-11-08 13:21:52.804260 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 58 finished
----------------------------------  ----------------
replay_buffer/size                   60000
trainer/num train calls              59000
trainer/QF1 Loss                         0.997043
trainer/QF2 Loss                         0.990164
trainer/Policy Loss                    -15.5312
trainer/Q1 Predictions Mean             15.5282
trainer/Q1 Predictions Std               1.71948
trainer/Q1 Predictions Max              23.7591
trainer/Q1 Predictions Min               8.47211
trainer/Q2 Predictions Mean             15.5186
trainer/Q2 Predictions Std               1.71982
trainer/Q2 Predictions Max              23.7084
trainer/Q2 Predictions Min               8.51854
trainer/Q Targets Mean                  15.4802
trainer/Q Targets Std                    1.94879
trainer/Q Targets Max                   24.0344
trainer/Q Targets Min                    0.092563
trainer/Log Pis Mean                     1.99204
trainer/Log Pis Std                      3.09935
trainer/Log Pis Max                     12.8486
trainer/Log Pis Min                     -4.16907
trainer/policy/mean Mean                -0.162868
trainer/policy/mean Std                  0.810792
trainer/policy/mean Max                  0.999826
trainer/policy/mean Min                 -0.999408
trainer/policy/normal/std Mean           0.867197
trainer/policy/normal/std Std            0.539135
trainer/policy/normal/std Max            6.81819
trainer/policy/normal/std Min            0.0701128
trainer/policy/normal/log_std Mean      -0.249845
trainer/policy/normal/log_std Std        0.465567
trainer/policy/normal/log_std Max        1.91959
trainer/policy/normal/log_std Min       -2.65765
trainer/Alpha                            0.00653314
trainer/Alpha Loss                      -0.0400482
exploration/num steps total          60000
exploration/num paths total            300
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.120886
exploration/Rewards Std                  0.00577094
exploration/Rewards Max                  0.126911
exploration/Rewards Min                  0.0977463
exploration/Returns Mean                24.1773
exploration/Returns Std                  0.638798
exploration/Returns Max                 25.1815
exploration/Returns Min                 23.3768
exploration/Actions Mean                -0.0037051
exploration/Actions Std                  0.789492
exploration/Actions Max                  0.999601
exploration/Actions Min                 -0.999828
exploration/Num Paths                    5
exploration/Average Returns             24.1773
evaluation/num steps total          284616
evaluation/num paths total            1416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119784
evaluation/Rewards Std                   0.00819486
evaluation/Rewards Max                   0.124726
evaluation/Rewards Min                   0.0916206
evaluation/Returns Mean                 24.0766
evaluation/Returns Std                   1.64105
evaluation/Returns Max                  24.7478
evaluation/Returns Min                  18.6303
evaluation/Actions Mean                 -0.0382896
evaluation/Actions Std                   0.847685
evaluation/Actions Max                   0.929489
evaluation/Actions Min                  -0.964584
evaluation/Num Paths                    24
evaluation/Average Returns              24.0766
time/data storing (s)                    0.0146772
time/evaluation sampling (s)            49.0022
time/exploration sampling (s)            9.94318
time/logging (s)                         0.0207458
time/sac training (s)                   16.341
time/saving (s)                          0.026404
time/training (s)                        0.000117239
time/epoch (s)                          75.3484
time/total (s)                        4842.72
Epoch                                   58
----------------------------------  ----------------
2020-11-08 13:23:10.269696 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 59 finished
----------------------------------  ----------------
replay_buffer/size                   61000
trainer/num train calls              60000
trainer/QF1 Loss                         0.729203
trainer/QF2 Loss                         0.734423
trainer/Policy Loss                    -15.4463
trainer/Q1 Predictions Mean             15.4345
trainer/Q1 Predictions Std               1.89144
trainer/Q1 Predictions Max              23.3097
trainer/Q1 Predictions Min               8.25694
trainer/Q2 Predictions Mean             15.4273
trainer/Q2 Predictions Std               1.89602
trainer/Q2 Predictions Max              23.3116
trainer/Q2 Predictions Min               8.18623
trainer/Q Targets Mean                  15.504
trainer/Q Targets Std                    2.09519
trainer/Q Targets Max                   23.3172
trainer/Q Targets Min                    0.117706
trainer/Log Pis Mean                     1.90429
trainer/Log Pis Std                      3.08666
trainer/Log Pis Max                     13.3675
trainer/Log Pis Min                     -4.14692
trainer/policy/mean Mean                -0.0785723
trainer/policy/mean Std                  0.800573
trainer/policy/mean Max                  0.99981
trainer/policy/mean Min                 -0.999315
trainer/policy/normal/std Mean           0.792141
trainer/policy/normal/std Std            0.350189
trainer/policy/normal/std Max            4.81521
trainer/policy/normal/std Min            0.0384332
trainer/policy/normal/log_std Mean      -0.320844
trainer/policy/normal/log_std Std        0.463942
trainer/policy/normal/log_std Max        1.57178
trainer/policy/normal/log_std Min       -3.25883
trainer/Alpha                            0.0065213
trainer/Alpha Loss                      -0.481666
exploration/num steps total          61000
exploration/num paths total            305
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.113806
exploration/Rewards Std                  0.0179658
exploration/Rewards Max                  0.124103
exploration/Rewards Min                  0.0622451
exploration/Returns Mean                22.7613
exploration/Returns Std                  2.73389
exploration/Returns Max                 24.1785
exploration/Returns Min                 17.2954
exploration/Actions Mean                 0.0392881
exploration/Actions Std                  0.761962
exploration/Actions Max                  0.999823
exploration/Actions Min                 -0.9993
exploration/Num Paths                    5
exploration/Average Returns             22.7613
evaluation/num steps total          289440
evaluation/num paths total            1440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121008
evaluation/Rewards Std                   0.00617951
evaluation/Rewards Max                   0.127097
evaluation/Rewards Min                   0.0913129
evaluation/Returns Mean                 24.3227
evaluation/Returns Std                   1.21887
evaluation/Returns Max                  25.1688
evaluation/Returns Min                  18.617
evaluation/Actions Mean                 -0.0676613
evaluation/Actions Std                   0.802965
evaluation/Actions Max                   0.931273
evaluation/Actions Min                  -0.995827
evaluation/Num Paths                    24
evaluation/Average Returns              24.3227
time/data storing (s)                    0.0146238
time/evaluation sampling (s)            49.0742
time/exploration sampling (s)           10.1491
time/logging (s)                         0.0300655
time/sac training (s)                   16.8579
time/saving (s)                          0.0303173
time/training (s)                        0.000141827
time/epoch (s)                          76.1563
time/total (s)                        4920.17
Epoch                                   59
----------------------------------  ----------------
2020-11-08 13:24:27.632818 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 60 finished
----------------------------------  ---------------
replay_buffer/size                   62000
trainer/num train calls              61000
trainer/QF1 Loss                         1.58825
trainer/QF2 Loss                         1.60311
trainer/Policy Loss                    -15.4002
trainer/Q1 Predictions Mean             15.3804
trainer/Q1 Predictions Std               1.68927
trainer/Q1 Predictions Max              23.6959
trainer/Q1 Predictions Min              10.7763
trainer/Q2 Predictions Mean             15.3782
trainer/Q2 Predictions Std               1.6885
trainer/Q2 Predictions Max              23.6633
trainer/Q2 Predictions Min              10.7738
trainer/Q Targets Mean                  15.3802
trainer/Q Targets Std                    1.8967
trainer/Q Targets Max                   23.6936
trainer/Q Targets Min                    0.117425
trainer/Log Pis Mean                     1.82081
trainer/Log Pis Std                      3.1489
trainer/Log Pis Max                     12.3866
trainer/Log Pis Min                     -5.03681
trainer/policy/mean Mean                -0.215873
trainer/policy/mean Std                  0.784204
trainer/policy/mean Max                  0.998306
trainer/policy/mean Min                 -0.999493
trainer/policy/normal/std Mean           0.847651
trainer/policy/normal/std Std            0.398546
trainer/policy/normal/std Max            5.10435
trainer/policy/normal/std Min            0.0373119
trainer/policy/normal/log_std Mean      -0.260459
trainer/policy/normal/log_std Std        0.460847
trainer/policy/normal/log_std Max        1.63009
trainer/policy/normal/log_std Min       -3.28844
trainer/Alpha                            0.0059199
trainer/Alpha Loss                      -0.919164
exploration/num steps total          62000
exploration/num paths total            310
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.0986541
exploration/Rewards Std                  0.0205726
exploration/Rewards Max                  0.124093
exploration/Rewards Min                  0.0625716
exploration/Returns Mean                19.7308
exploration/Returns Std                  2.92351
exploration/Returns Max                 22.9901
exploration/Returns Min                 14.5638
exploration/Actions Mean                -0.1173
exploration/Actions Std                  0.760547
exploration/Actions Max                  0.999977
exploration/Actions Min                 -0.999955
exploration/Num Paths                    5
exploration/Average Returns             19.7308
evaluation/num steps total          294264
evaluation/num paths total            1464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.11908
evaluation/Rewards Std                   0.00763981
evaluation/Rewards Max                   0.126356
evaluation/Rewards Min                   0.093335
evaluation/Returns Mean                 23.9352
evaluation/Returns Std                   1.50955
evaluation/Returns Max                  24.9001
evaluation/Returns Min                  19.0766
evaluation/Actions Mean                 -0.26648
evaluation/Actions Std                   0.674359
evaluation/Actions Max                   0.961152
evaluation/Actions Min                  -0.983647
evaluation/Num Paths                    24
evaluation/Average Returns              23.9352
time/data storing (s)                    0.0162076
time/evaluation sampling (s)            49.0869
time/exploration sampling (s)            9.97146
time/logging (s)                         0.0213274
time/sac training (s)                   16.9327
time/saving (s)                          0.0272434
time/training (s)                        0.00012331
time/epoch (s)                          76.056
time/total (s)                        4997.5
Epoch                                   60
----------------------------------  ---------------
2020-11-08 13:25:59.255939 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 61 finished
----------------------------------  ----------------
replay_buffer/size                   63000
trainer/num train calls              62000
trainer/QF1 Loss                         2.26889
trainer/QF2 Loss                         2.229
trainer/Policy Loss                    -15.3151
trainer/Q1 Predictions Mean             15.2999
trainer/Q1 Predictions Std               1.91992
trainer/Q1 Predictions Max              24.5701
trainer/Q1 Predictions Min               7.1214
trainer/Q2 Predictions Mean             15.2961
trainer/Q2 Predictions Std               1.91671
trainer/Q2 Predictions Max              24.5895
trainer/Q2 Predictions Min               7.15595
trainer/Q Targets Mean                  15.16
trainer/Q Targets Std                    2.43917
trainer/Q Targets Max                   24.5061
trainer/Q Targets Min                    0.118866
trainer/Log Pis Mean                     1.9824
trainer/Log Pis Std                      3.02692
trainer/Log Pis Max                     11.2831
trainer/Log Pis Min                     -4.50616
trainer/policy/mean Mean                -0.10435
trainer/policy/mean Std                  0.796846
trainer/policy/mean Max                  0.998595
trainer/policy/mean Min                 -0.998645
trainer/policy/normal/std Mean           0.816876
trainer/policy/normal/std Std            0.355754
trainer/policy/normal/std Max            4.75681
trainer/policy/normal/std Min            0.0463084
trainer/policy/normal/log_std Mean      -0.289182
trainer/policy/normal/log_std Std        0.458764
trainer/policy/normal/log_std Max        1.55958
trainer/policy/normal/log_std Min       -3.07243
trainer/Alpha                            0.00702085
trainer/Alpha Loss                      -0.0872634
exploration/num steps total          63000
exploration/num paths total            315
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.121544
exploration/Rewards Std                  0.00126542
exploration/Rewards Max                  0.123705
exploration/Rewards Min                  0.11815
exploration/Returns Mean                24.3088
exploration/Returns Std                  0.277603
exploration/Returns Max                 24.5685
exploration/Returns Min                 23.7864
exploration/Actions Mean                -0.0894433
exploration/Actions Std                  0.845899
exploration/Actions Max                  0.999416
exploration/Actions Min                 -0.999897
exploration/Num Paths                    5
exploration/Average Returns             24.3088
evaluation/num steps total          299088
evaluation/num paths total            1488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.119704
evaluation/Rewards Std                   0.0087667
evaluation/Rewards Max                   0.125526
evaluation/Rewards Min                   0.089452
evaluation/Returns Mean                 24.0605
evaluation/Returns Std                   1.69354
evaluation/Returns Max                  24.7838
evaluation/Returns Min                  18.4031
evaluation/Actions Mean                 -0.125387
evaluation/Actions Std                   0.842469
evaluation/Actions Max                   0.92569
evaluation/Actions Min                  -0.969011
evaluation/Num Paths                    24
evaluation/Average Returns              24.0605
time/data storing (s)                    0.0309423
time/evaluation sampling (s)            51.0894
time/exploration sampling (s)           16.4943
time/logging (s)                         0.0261967
time/sac training (s)                   22.3093
time/saving (s)                          0.0351082
time/training (s)                        0.000145931
time/epoch (s)                          89.9854
time/total (s)                        5089.09
Epoch                                   61
----------------------------------  ----------------
2020-11-08 13:27:39.609609 EST | [name-of-experiment_2020_11_08_12_01_08_0000--s-0] Epoch 62 finished
----------------------------------  ----------------
replay_buffer/size                   64000
trainer/num train calls              63000
trainer/QF1 Loss                         0.0950182
trainer/QF2 Loss                         0.0913051
trainer/Policy Loss                    -15.3786
trainer/Q1 Predictions Mean             15.3739
trainer/Q1 Predictions Std               1.88032
trainer/Q1 Predictions Max              25.5215
trainer/Q1 Predictions Min               7.53331
trainer/Q2 Predictions Mean             15.3804
trainer/Q2 Predictions Std               1.88271
trainer/Q2 Predictions Max              25.5519
trainer/Q2 Predictions Min               7.57223
trainer/Q Targets Mean                  15.3302
trainer/Q Targets Std                    1.82969
trainer/Q Targets Max                   25.3815
trainer/Q Targets Min                    8.4964
trainer/Log Pis Mean                     1.90897
trainer/Log Pis Std                      2.80169
trainer/Log Pis Max                     13.4659
trainer/Log Pis Min                     -3.83657
trainer/policy/mean Mean                -0.110984
trainer/policy/mean Std                  0.817351
trainer/policy/mean Max                  0.999697
trainer/policy/mean Min                 -0.998816
trainer/policy/normal/std Mean           0.699331
trainer/policy/normal/std Std            0.258677
trainer/policy/normal/std Max            2.54971
trainer/policy/normal/std Min            0.0300116
trainer/policy/normal/log_std Mean      -0.444841
trainer/policy/normal/log_std Std        0.483886
trainer/policy/normal/log_std Max        0.935979
trainer/policy/normal/log_std Min       -3.50617
trainer/Alpha                            0.00613179
trainer/Alpha Loss                      -0.463723
exploration/num steps total          64000
exploration/num paths total            320
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                 0.118174
exploration/Rewards Std                  0.00869417
exploration/Rewards Max                  0.12476
exploration/Rewards Min                  0.0896903
exploration/Returns Mean                23.6347
exploration/Returns Std                  0.748035
exploration/Returns Max                 24.582
exploration/Returns Min                 22.4433
exploration/Actions Mean                -0.0530293
exploration/Actions Std                  0.796403
exploration/Actions Max                  0.998359
exploration/Actions Min                 -0.999552
exploration/Num Paths                    5
exploration/Average Returns             23.6347
evaluation/num steps total          303912
evaluation/num paths total            1512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                  0.121197
evaluation/Rewards Std                   0.00569593
evaluation/Rewards Max                   0.124147
evaluation/Rewards Min                   0.0934709
evaluation/Returns Mean                 24.3606
evaluation/Returns Std                   1.11686
evaluation/Returns Max                  24.709
evaluation/Returns Min                  19.0519
evaluation/Actions Mean                 -0.0697985
evaluation/Actions Std                   0.855124
evaluation/Actions Max                   0.926963
evaluation/Actions Min                  -0.961487
evaluation/Num Paths                    24
evaluation/Average Returns              24.3606
time/data storing (s)                    0.0168464
time/evaluation sampling (s)            67.4968
time/exploration sampling (s)           12.6285
time/logging (s)                         0.0308058
time/sac training (s)                   18.6326
time/saving (s)                          0.0343026
time/training (s)                        0.000124703
time/epoch (s)                          98.8399
time/total (s)                        5189.42
Epoch                                   62
----------------------------------  ----------------
