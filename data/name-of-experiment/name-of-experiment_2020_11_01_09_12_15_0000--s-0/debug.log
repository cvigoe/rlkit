2020-11-01 09:27:05.935008 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 0 finished
----------------------------------  --------------
replay_buffer/size                  2000
trainer/num train calls             1000
trainer/QF1 Loss                       0.128094
trainer/QF2 Loss                       0.127758
trainer/Policy Loss                   -1.3308
trainer/Q1 Predictions Mean           -0.000846072
trainer/Q1 Predictions Std             0.000351113
trainer/Q1 Predictions Max            -1.14913e-05
trainer/Q1 Predictions Min            -0.00211958
trainer/Q2 Predictions Mean            0.00111134
trainer/Q2 Predictions Std             0.000812751
trainer/Q2 Predictions Max             0.00318994
trainer/Q2 Predictions Min            -0.000479163
trainer/Q Targets Mean                 0.0843373
trainer/Q Targets Std                  0.347611
trainer/Q Targets Max                  0.795826
trainer/Q Targets Min                 -1.02165
trainer/Log Pis Mean                  -1.33166
trainer/Log Pis Std                    0.310869
trainer/Log Pis Max                   -0.550295
trainer/Log Pis Min                   -2.12364
trainer/policy/mean Mean               0.000325837
trainer/policy/mean Std                0.00019094
trainer/policy/mean Max                0.000819027
trainer/policy/mean Min               -0.000152996
trainer/policy/normal/std Mean         1.00062
trainer/policy/normal/std Std          0.00042653
trainer/policy/normal/std Max          1.00156
trainer/policy/normal/std Min          0.99958
trainer/policy/normal/log_std Mean     0.000618023
trainer/policy/normal/log_std Std      0.000426281
trainer/policy/normal/log_std Max      0.00155757
trainer/policy/normal/log_std Min     -0.000420361
trainer/Alpha                          1
trainer/Alpha Loss                    -0
exploration/num steps total         2000
exploration/num paths total           10
exploration/path length Mean         200
exploration/path length Std            2
exploration/path length Max          201
exploration/path length Min          196
exploration/Rewards Mean              -1.22981
exploration/Rewards Std                0.165503
exploration/Rewards Max               -0.970857
exploration/Rewards Min               -1.71872
exploration/Returns Mean            -245.962
exploration/Returns Std               26.1467
exploration/Returns Max             -214.327
exploration/Returns Min             -287.04
exploration/Actions Mean              -0.0140708
exploration/Actions Std                0.63052
exploration/Actions Max                0.994057
exploration/Actions Min               -0.998938
exploration/Num Paths                  5
exploration/Average Returns         -245.962
evaluation/num steps total          4824
evaluation/num paths total            24
evaluation/path length Mean          201
evaluation/path length Std             0
evaluation/path length Max           201
evaluation/path length Min           201
evaluation/Rewards Mean               -1.39868
evaluation/Rewards Std                 0.173982
evaluation/Rewards Max                -1.10768
evaluation/Rewards Min                -1.83635
evaluation/Returns Mean             -281.135
evaluation/Returns Std                34.741
evaluation/Returns Max              -232.01
evaluation/Returns Min              -359.2
evaluation/Actions Mean                0.000284939
evaluation/Actions Std                 0.000125098
evaluation/Actions Max                 0.000918569
evaluation/Actions Min                -0.000201784
evaluation/Num Paths                  24
evaluation/Average Returns          -281.135
time/data storing (s)                  0.0231037
time/evaluation sampling (s)         600.838
time/exploration sampling (s)        143.283
time/logging (s)                       0.0542038
time/sac training (s)                  9.99086
time/saving (s)                        0.081115
time/training (s)                      0.000109513
time/epoch (s)                       754.27
time/total (s)                       890.771
Epoch                                  0
----------------------------------  --------------
2020-11-01 09:38:05.797816 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 1 finished
----------------------------------  --------------
replay_buffer/size                  3000
trainer/num train calls             2000
trainer/QF1 Loss                       0.0315695
trainer/QF2 Loss                       0.0310668
trainer/Policy Loss                   -0.339116
trainer/Q1 Predictions Mean           -0.627188
trainer/Q1 Predictions Std             0.499764
trainer/Q1 Predictions Max             0.391367
trainer/Q1 Predictions Min            -1.58605
trainer/Q2 Predictions Mean           -0.65261
trainer/Q2 Predictions Std             0.499554
trainer/Q2 Predictions Max             0.375661
trainer/Q2 Predictions Min            -1.63355
trainer/Q Targets Mean                -0.617349
trainer/Q Targets Std                  0.517429
trainer/Q Targets Max                  0.749555
trainer/Q Targets Min                 -1.81764
trainer/Log Pis Mean                  -1.35776
trainer/Log Pis Std                    0.154923
trainer/Log Pis Max                   -0.986183
trainer/Log Pis Min                   -1.93545
trainer/policy/mean Mean              -0.00883657
trainer/policy/mean Std                0.0103433
trainer/policy/mean Max                0.00770184
trainer/policy/mean Min               -0.0311657
trainer/policy/normal/std Mean         0.880338
trainer/policy/normal/std Std          0.0141006
trainer/policy/normal/std Max          0.914764
trainer/policy/normal/std Min          0.839387
trainer/policy/normal/log_std Mean    -0.127578
trainer/policy/normal/log_std Std      0.0160412
trainer/policy/normal/log_std Max     -0.0890894
trainer/policy/normal/log_std Min     -0.175083
trainer/Alpha                          0.740748
trainer/Alpha Loss                    -1.00765
exploration/num steps total         3000
exploration/num paths total           15
exploration/path length Mean         200
exploration/path length Std            2
exploration/path length Max          201
exploration/path length Min          196
exploration/Rewards Mean              -1.18793
exploration/Rewards Std                0.168455
exploration/Rewards Max               -0.933543
exploration/Rewards Min               -1.71831
exploration/Returns Mean            -237.586
exploration/Returns Std               24.9541
exploration/Returns Max             -219.967
exploration/Returns Min             -286.129
exploration/Actions Mean               0.0149324
exploration/Actions Std                0.587319
exploration/Actions Max                0.996831
exploration/Actions Min               -0.991713
exploration/Num Paths                  5
exploration/Average Returns         -237.586
evaluation/num steps total          9648
evaluation/num paths total            48
evaluation/path length Mean          201
evaluation/path length Std             0
evaluation/path length Max           201
evaluation/path length Min           201
evaluation/Rewards Mean               -1.36208
evaluation/Rewards Std                 0.147065
evaluation/Rewards Max                -1.08541
evaluation/Rewards Min                -1.88917
evaluation/Returns Mean             -273.778
evaluation/Returns Std                29.2878
evaluation/Returns Max              -228.118
evaluation/Returns Min              -369.169
evaluation/Actions Mean               -0.00971732
evaluation/Actions Std                 0.0108894
evaluation/Actions Max                 0.0042265
evaluation/Actions Min                -0.0315703
evaluation/Num Paths                  24
evaluation/Average Returns          -273.778
time/data storing (s)                  0.0106556
time/evaluation sampling (s)         510.96
time/exploration sampling (s)        136.372
time/logging (s)                       0.062899
time/sac training (s)                 11.6388
time/saving (s)                        0.0583268
time/training (s)                      0.000160404
time/epoch (s)                       659.103
time/total (s)                      1550.61
Epoch                                  1
----------------------------------  --------------
2020-11-01 09:47:53.955249 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 2 finished
----------------------------------  ---------------
replay_buffer/size                   4000
trainer/num train calls              3000
trainer/QF1 Loss                        0.0380372
trainer/QF2 Loss                        0.041883
trainer/Policy Loss                     1.78591
trainer/Q1 Predictions Mean            -2.51942
trainer/Q1 Predictions Std              1.00868
trainer/Q1 Predictions Max             -0.305835
trainer/Q1 Predictions Min             -4.69199
trainer/Q2 Predictions Mean            -2.48846
trainer/Q2 Predictions Std              1.00555
trainer/Q2 Predictions Max             -0.300625
trainer/Q2 Predictions Min             -4.63996
trainer/Q Targets Mean                 -2.49624
trainer/Q Targets Std                   1.0168
trainer/Q Targets Max                  -0.290452
trainer/Q Targets Min                  -4.71165
trainer/Log Pis Mean                   -1.36579
trainer/Log Pis Std                     0.14314
trainer/Log Pis Max                    -0.996381
trainer/Log Pis Min                    -1.76626
trainer/policy/mean Mean               -0.00480546
trainer/policy/mean Std                 0.0130544
trainer/policy/mean Max                 0.0146954
trainer/policy/mean Min                -0.0288033
trainer/policy/normal/std Mean          0.890222
trainer/policy/normal/std Std           0.0085513
trainer/policy/normal/std Max           0.912613
trainer/policy/normal/std Min           0.85918
trainer/policy/normal/log_std Mean     -0.11633
trainer/policy/normal/log_std Std       0.00960681
trainer/policy/normal/log_std Max      -0.0914429
trainer/policy/normal/log_std Min      -0.151776
trainer/Alpha                           0.548752
trainer/Alpha Loss                     -2.01984
exploration/num steps total          4000
exploration/num paths total            20
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.19968
exploration/Rewards Std                 0.11166
exploration/Rewards Max                -0.97945
exploration/Rewards Min                -1.50191
exploration/Returns Mean             -239.936
exploration/Returns Std                12.0332
exploration/Returns Max              -222.065
exploration/Returns Min              -254.768
exploration/Actions Mean               -0.00749331
exploration/Actions Std                 0.595643
exploration/Actions Max                 0.996234
exploration/Actions Min                -0.996177
exploration/Num Paths                   5
exploration/Average Returns          -239.936
evaluation/num steps total          14472
evaluation/num paths total             72
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.429
evaluation/Rewards Std                  0.13284
evaluation/Rewards Max                 -1.11905
evaluation/Rewards Min                 -1.72158
evaluation/Returns Mean              -287.23
evaluation/Returns Std                 26.4211
evaluation/Returns Max               -233.742
evaluation/Returns Min               -335.52
evaluation/Actions Mean                -0.00563724
evaluation/Actions Std                  0.0143271
evaluation/Actions Max                  0.0135667
evaluation/Actions Min                 -0.0316962
evaluation/Num Paths                   24
evaluation/Average Returns           -287.23
time/data storing (s)                   0.0101333
time/evaluation sampling (s)          451.501
time/exploration sampling (s)         125.275
time/logging (s)                        0.0316993
time/sac training (s)                  10.6294
time/saving (s)                         0.0472422
time/training (s)                       0.000156161
time/epoch (s)                        587.495
time/total (s)                       2138.71
Epoch                                   2
----------------------------------  ---------------
2020-11-01 09:58:43.048100 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 3 finished
----------------------------------  ---------------
replay_buffer/size                   5000
trainer/num train calls              4000
trainer/QF1 Loss                        0.10528
trainer/QF2 Loss                        0.123675
trainer/Policy Loss                     4.9215
trainer/Q1 Predictions Mean            -5.43281
trainer/Q1 Predictions Std              1.61792
trainer/Q1 Predictions Max             -2.30867
trainer/Q1 Predictions Min             -8.85731
trainer/Q2 Predictions Mean            -5.4204
trainer/Q2 Predictions Std              1.6328
trainer/Q2 Predictions Max             -2.30964
trainer/Q2 Predictions Min             -8.76502
trainer/Q Targets Mean                 -5.44935
trainer/Q Targets Std                   1.66558
trainer/Q Targets Max                  -1.06944
trainer/Q Targets Min                  -8.83835
trainer/Log Pis Mean                   -1.35983
trainer/Log Pis Std                     0.17141
trainer/Log Pis Max                    -0.906185
trainer/Log Pis Min                    -2.60489
trainer/policy/mean Mean               -0.0186611
trainer/policy/mean Std                 0.0307977
trainer/policy/mean Max                 0.0350798
trainer/policy/mean Min                -0.133106
trainer/policy/normal/std Mean          0.879561
trainer/policy/normal/std Std           0.0102117
trainer/policy/normal/std Max           0.913936
trainer/policy/normal/std Min           0.851188
trainer/policy/normal/log_std Mean     -0.1284
trainer/policy/normal/log_std Std       0.0116161
trainer/policy/normal/log_std Max      -0.0899945
trainer/policy/normal/log_std Min      -0.161123
trainer/Alpha                           0.406544
trainer/Alpha Loss                     -3.02406
exploration/num steps total          5000
exploration/num paths total            25
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.19337
exploration/Rewards Std                 0.180952
exploration/Rewards Max                -0.874379
exploration/Rewards Min                -1.62198
exploration/Returns Mean             -238.674
exploration/Returns Std                28.5876
exploration/Returns Max              -211.506
exploration/Returns Min              -277.631
exploration/Actions Mean               -0.0274852
exploration/Actions Std                 0.590394
exploration/Actions Max                 0.994605
exploration/Actions Min                -0.998984
exploration/Num Paths                   5
exploration/Average Returns          -238.674
evaluation/num steps total          19296
evaluation/num paths total             96
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.40191
evaluation/Rewards Std                  0.205213
evaluation/Rewards Max                 -1.09254
evaluation/Rewards Min                 -2.28356
evaluation/Returns Mean              -281.784
evaluation/Returns Std                 41.0412
evaluation/Returns Max               -231.019
evaluation/Returns Min               -447.122
evaluation/Actions Mean                -0.023967
evaluation/Actions Std                  0.0321948
evaluation/Actions Max                  0.0233853
evaluation/Actions Min                 -0.0998687
evaluation/Num Paths                   24
evaluation/Average Returns           -281.784
time/data storing (s)                   0.0115167
time/evaluation sampling (s)          502.454
time/exploration sampling (s)         135.928
time/logging (s)                        0.0593854
time/sac training (s)                   9.9747
time/saving (s)                         0.0565586
time/training (s)                       0.000145285
time/epoch (s)                        648.484
time/total (s)                       2787.8
Epoch                                   3
----------------------------------  ---------------
2020-11-01 10:09:36.925884 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 4 finished
----------------------------------  ---------------
replay_buffer/size                   6000
trainer/num train calls              5000
trainer/QF1 Loss                        0.172145
trainer/QF2 Loss                        0.217282
trainer/Policy Loss                     8.45507
trainer/Q1 Predictions Mean            -8.79437
trainer/Q1 Predictions Std              2.19833
trainer/Q1 Predictions Max             -3.67991
trainer/Q1 Predictions Min            -13.9026
trainer/Q2 Predictions Mean            -8.77239
trainer/Q2 Predictions Std              2.23233
trainer/Q2 Predictions Max             -2.96107
trainer/Q2 Predictions Min            -13.7712
trainer/Q Targets Mean                 -8.86082
trainer/Q Targets Std                   2.14557
trainer/Q Targets Max                  -4.31117
trainer/Q Targets Min                 -13.827
trainer/Log Pis Mean                   -1.36191
trainer/Log Pis Std                     0.25778
trainer/Log Pis Max                    -0.818957
trainer/Log Pis Min                    -3.20467
trainer/policy/mean Mean               -0.0407938
trainer/policy/mean Std                 0.0733504
trainer/policy/mean Max                 0.124715
trainer/policy/mean Min                -0.369411
trainer/policy/normal/std Mean          0.903739
trainer/policy/normal/std Std           0.0118276
trainer/policy/normal/std Max           0.925763
trainer/policy/normal/std Min           0.866481
trainer/policy/normal/log_std Mean     -0.101301
trainer/policy/normal/log_std Std       0.013151
trainer/policy/normal/log_std Max      -0.0771369
trainer/policy/normal/log_std Min      -0.143315
trainer/Alpha                           0.301232
trainer/Alpha Loss                     -4.03387
exploration/num steps total          6000
exploration/num paths total            30
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.27142
exploration/Rewards Std                 0.101966
exploration/Rewards Max                -1.09643
exploration/Rewards Min                -1.54282
exploration/Returns Mean             -254.284
exploration/Returns Std                 9.65005
exploration/Returns Max              -240.196
exploration/Returns Min              -270.226
exploration/Actions Mean               -0.00693949
exploration/Actions Std                 0.591151
exploration/Actions Max                 0.993008
exploration/Actions Min                -0.991665
exploration/Num Paths                   5
exploration/Average Returns          -254.284
evaluation/num steps total          24120
evaluation/num paths total            120
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.36404
evaluation/Rewards Std                  0.153814
evaluation/Rewards Max                 -1.11075
evaluation/Rewards Min                 -1.76824
evaluation/Returns Mean              -274.172
evaluation/Returns Std                 30.6253
evaluation/Returns Max               -234.618
evaluation/Returns Min               -342.385
evaluation/Actions Mean                -0.0775977
evaluation/Actions Std                  0.0441769
evaluation/Actions Max                  0.0486271
evaluation/Actions Min                 -0.212815
evaluation/Num Paths                   24
evaluation/Average Returns           -274.172
time/data storing (s)                   0.0114261
time/evaluation sampling (s)          506.585
time/exploration sampling (s)         136.055
time/logging (s)                        0.0325313
time/sac training (s)                  10.4782
time/saving (s)                         0.0412055
time/training (s)                       0.000119941
time/epoch (s)                        653.204
time/total (s)                       3441.63
Epoch                                   4
----------------------------------  ---------------
2020-11-01 10:19:40.184362 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 5 finished
----------------------------------  ---------------
replay_buffer/size                   7000
trainer/num train calls              6000
trainer/QF1 Loss                        1.05132
trainer/QF2 Loss                        1.29207
trainer/Policy Loss                    12.4377
trainer/Q1 Predictions Mean           -12.6077
trainer/Q1 Predictions Std              2.8039
trainer/Q1 Predictions Max             -7.02305
trainer/Q1 Predictions Min            -18.1185
trainer/Q2 Predictions Mean           -12.6435
trainer/Q2 Predictions Std              2.82115
trainer/Q2 Predictions Max             -6.83033
trainer/Q2 Predictions Min            -18.426
trainer/Q Targets Mean                -12.5325
trainer/Q Targets Std                   3.07465
trainer/Q Targets Max                  -1.00135
trainer/Q Targets Min                 -18.2423
trainer/Log Pis Mean                   -1.30837
trainer/Log Pis Std                     0.395258
trainer/Log Pis Max                     1.17598
trainer/Log Pis Min                    -2.7572
trainer/policy/mean Mean               -0.0642473
trainer/policy/mean Std                 0.177951
trainer/policy/mean Max                 0.496301
trainer/policy/mean Min                -0.759041
trainer/policy/normal/std Mean          0.899994
trainer/policy/normal/std Std           0.0186504
trainer/policy/normal/std Max           0.939607
trainer/policy/normal/std Min           0.809035
trainer/policy/normal/log_std Mean     -0.105584
trainer/policy/normal/log_std Std       0.0209191
trainer/policy/normal/log_std Max      -0.0622941
trainer/policy/normal/log_std Min      -0.211913
trainer/Alpha                           0.223433
trainer/Alpha Loss                     -4.95807
exploration/num steps total          7000
exploration/num paths total            35
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.18285
exploration/Rewards Std                 0.150841
exploration/Rewards Max                -0.912558
exploration/Rewards Min                -1.65438
exploration/Returns Mean             -236.571
exploration/Returns Std                18.1785
exploration/Returns Max              -210.151
exploration/Returns Min              -261.07
exploration/Actions Mean               -0.0326908
exploration/Actions Std                 0.599295
exploration/Actions Max                 0.993731
exploration/Actions Min                -0.998396
exploration/Num Paths                   5
exploration/Average Returns          -236.571
evaluation/num steps total          28944
evaluation/num paths total            144
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.36583
evaluation/Rewards Std                  0.152836
evaluation/Rewards Max                 -1.07327
evaluation/Rewards Min                 -1.76818
evaluation/Returns Mean              -274.533
evaluation/Returns Std                 30.3737
evaluation/Returns Max               -226.508
evaluation/Returns Min               -340.334
evaluation/Actions Mean                -0.104214
evaluation/Actions Std                  0.218676
evaluation/Actions Max                  0.212167
evaluation/Actions Min                 -0.486739
evaluation/Num Paths                   24
evaluation/Average Returns           -274.533
time/data storing (s)                   0.00896865
time/evaluation sampling (s)          468.247
time/exploration sampling (s)         125.278
time/logging (s)                        0.0287183
time/sac training (s)                   9.04602
time/saving (s)                         0.0330332
time/training (s)                       0.000118936
time/epoch (s)                        602.642
time/total (s)                       4044.86
Epoch                                   5
----------------------------------  ---------------
2020-11-01 10:29:40.245172 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 6 finished
----------------------------------  ---------------
replay_buffer/size                   8000
trainer/num train calls              7000
trainer/QF1 Loss                        1.4906
trainer/QF2 Loss                        1.59568
trainer/Policy Loss                    17.153
trainer/Q1 Predictions Mean           -17.2229
trainer/Q1 Predictions Std              3.46781
trainer/Q1 Predictions Max            -10.3866
trainer/Q1 Predictions Min            -24.5415
trainer/Q2 Predictions Mean           -17.2599
trainer/Q2 Predictions Std              3.42613
trainer/Q2 Predictions Max            -10.3746
trainer/Q2 Predictions Min            -25.013
trainer/Q Targets Mean                -17.2155
trainer/Q Targets Std                   3.61241
trainer/Q Targets Max                  -0.984896
trainer/Q Targets Min                 -24.6345
trainer/Log Pis Mean                   -1.25458
trainer/Log Pis Std                     0.535747
trainer/Log Pis Max                     1.41856
trainer/Log Pis Min                    -2.74973
trainer/policy/mean Mean               -0.0258375
trainer/policy/mean Std                 0.276531
trainer/policy/mean Max                 0.6735
trainer/policy/mean Min                -0.847118
trainer/policy/normal/std Mean          0.915157
trainer/policy/normal/std Std           0.0311426
trainer/policy/normal/std Max           0.985588
trainer/policy/normal/std Min           0.813638
trainer/policy/normal/log_std Mean     -0.0892458
trainer/policy/normal/log_std Std       0.034349
trainer/policy/normal/log_std Max      -0.0145168
trainer/policy/normal/log_std Min      -0.206239
trainer/Alpha                           0.166158
trainer/Alpha Loss                     -5.84139
exploration/num steps total          8000
exploration/num paths total            40
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.24238
exploration/Rewards Std                 0.12543
exploration/Rewards Max                -0.999892
exploration/Rewards Min                -1.61773
exploration/Returns Mean             -248.477
exploration/Returns Std                17.0456
exploration/Returns Max              -226.341
exploration/Returns Min              -274.471
exploration/Actions Mean                0.0402949
exploration/Actions Std                 0.610365
exploration/Actions Max                 0.995282
exploration/Actions Min                -0.995759
exploration/Num Paths                   5
exploration/Average Returns          -248.477
evaluation/num steps total          33768
evaluation/num paths total            168
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.34925
evaluation/Rewards Std                  0.0953882
evaluation/Rewards Max                 -1.07977
evaluation/Rewards Min                 -1.61238
evaluation/Returns Mean              -271.199
evaluation/Returns Std                 18.2309
evaluation/Returns Max               -234.853
evaluation/Returns Min               -310.896
evaluation/Actions Mean                -0.111924
evaluation/Actions Std                  0.355015
evaluation/Actions Max                  0.465133
evaluation/Actions Min                 -0.750655
evaluation/Num Paths                   24
evaluation/Average Returns           -271.199
time/data storing (s)                   0.0151644
time/evaluation sampling (s)          460.18
time/exploration sampling (s)         129.935
time/logging (s)                        0.0379441
time/sac training (s)                   9.21249
time/saving (s)                         0.0414003
time/training (s)                       0.000124927
time/epoch (s)                        599.422
time/total (s)                       4644.9
Epoch                                   6
----------------------------------  ---------------
2020-11-01 10:40:13.779245 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 7 finished
----------------------------------  ---------------
replay_buffer/size                   9000
trainer/num train calls              8000
trainer/QF1 Loss                        0.647581
trainer/QF2 Loss                        0.581795
trainer/Policy Loss                    21.6726
trainer/Q1 Predictions Mean           -21.5603
trainer/Q1 Predictions Std              4.15582
trainer/Q1 Predictions Max            -12.9014
trainer/Q1 Predictions Min            -30.7775
trainer/Q2 Predictions Mean           -21.7652
trainer/Q2 Predictions Std              4.12692
trainer/Q2 Predictions Max            -13.342
trainer/Q2 Predictions Min            -30.2942
trainer/Q Targets Mean                -21.7979
trainer/Q Targets Std                   4.1097
trainer/Q Targets Max                 -12.3718
trainer/Q Targets Min                 -29.9525
trainer/Log Pis Mean                   -1.07428
trainer/Log Pis Std                     0.865025
trainer/Log Pis Max                     4.12815
trainer/Log Pis Min                    -3.26341
trainer/policy/mean Mean               -0.0490898
trainer/policy/mean Std                 0.402873
trainer/policy/mean Max                 0.877811
trainer/policy/mean Min                -0.942039
trainer/policy/normal/std Mean          0.924797
trainer/policy/normal/std Std           0.0567533
trainer/policy/normal/std Max           1.03472
trainer/policy/normal/std Min           0.602985
trainer/policy/normal/log_std Mean     -0.0802023
trainer/policy/normal/log_std Std       0.0648204
trainer/policy/normal/log_std Max       0.0341354
trainer/policy/normal/log_std Min      -0.505863
trainer/Alpha                           0.124411
trainer/Alpha Loss                     -6.40729
exploration/num steps total          9000
exploration/num paths total            45
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.07859
exploration/Rewards Std                 0.137614
exploration/Rewards Max                -0.789644
exploration/Rewards Min                -1.47852
exploration/Returns Mean             -215.717
exploration/Returns Std                17.1252
exploration/Returns Max              -187.924
exploration/Returns Min              -235.333
exploration/Actions Mean               -0.0676804
exploration/Actions Std                 0.623243
exploration/Actions Max                 0.996584
exploration/Actions Min                -0.996737
exploration/Num Paths                   5
exploration/Average Returns          -215.717
evaluation/num steps total          38592
evaluation/num paths total            192
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.34343
evaluation/Rewards Std                  0.119618
evaluation/Rewards Max                 -1.10809
evaluation/Rewards Min                 -1.71771
evaluation/Returns Mean              -270.03
evaluation/Returns Std                 23.2937
evaluation/Returns Max               -234.226
evaluation/Returns Min               -327.934
evaluation/Actions Mean                -0.0478118
evaluation/Actions Std                  0.379423
evaluation/Actions Max                  0.689185
evaluation/Actions Min                 -0.769911
evaluation/Num Paths                   24
evaluation/Average Returns           -270.03
time/data storing (s)                   0.0109452
time/evaluation sampling (s)          496.275
time/exploration sampling (s)         127.118
time/logging (s)                        0.0294813
time/sac training (s)                   9.4269
time/saving (s)                         0.0329999
time/training (s)                       0.000123199
time/epoch (s)                        632.893
time/total (s)                       5278.4
Epoch                                   7
----------------------------------  ---------------
2020-11-01 10:51:20.130100 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 8 finished
----------------------------------  --------------
replay_buffer/size                  10000
trainer/num train calls              9000
trainer/QF1 Loss                        2.32402
trainer/QF2 Loss                        2.14242
trainer/Policy Loss                    26.5716
trainer/Q1 Predictions Mean           -26.4745
trainer/Q1 Predictions Std              5.47072
trainer/Q1 Predictions Max              2.11119
trainer/Q1 Predictions Min            -37.26
trainer/Q2 Predictions Mean           -26.5551
trainer/Q2 Predictions Std              5.29111
trainer/Q2 Predictions Max             -0.762883
trainer/Q2 Predictions Min            -37.192
trainer/Q Targets Mean                -26.347
trainer/Q Targets Std                   5.52943
trainer/Q Targets Max                  -1.12047
trainer/Q Targets Min                 -37.4477
trainer/Log Pis Mean                   -0.738794
trainer/Log Pis Std                     1.22573
trainer/Log Pis Max                     4.39522
trainer/Log Pis Min                    -4.38511
trainer/policy/mean Mean               -0.172127
trainer/policy/mean Std                 0.521807
trainer/policy/mean Max                 0.974475
trainer/policy/mean Min                -0.942002
trainer/policy/normal/std Mean          0.911116
trainer/policy/normal/std Std           0.0859016
trainer/policy/normal/std Max           1.15089
trainer/policy/normal/std Min           0.58008
trainer/policy/normal/log_std Mean     -0.0977794
trainer/policy/normal/log_std Std       0.0984553
trainer/policy/normal/log_std Max       0.140538
trainer/policy/normal/log_std Min      -0.54459
trainer/Alpha                           0.0942621
trainer/Alpha Loss                     -6.46814
exploration/num steps total         10000
exploration/num paths total            50
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.15093
exploration/Rewards Std                 0.194979
exploration/Rewards Max                -0.700813
exploration/Rewards Min                -1.62504
exploration/Returns Mean             -230.187
exploration/Returns Std                24.7903
exploration/Returns Max              -189.375
exploration/Returns Min              -263.316
exploration/Actions Mean               -0.270995
exploration/Actions Std                 0.606169
exploration/Actions Max                 0.995295
exploration/Actions Min                -0.998855
exploration/Num Paths                   5
exploration/Average Returns          -230.187
evaluation/num steps total          43416
evaluation/num paths total            216
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.22054
evaluation/Rewards Std                  0.138336
evaluation/Rewards Max                 -0.901775
evaluation/Rewards Min                 -1.60248
evaluation/Returns Mean              -245.328
evaluation/Returns Std                 24.5689
evaluation/Returns Max               -203.329
evaluation/Returns Min               -287.876
evaluation/Actions Mean                -0.172188
evaluation/Actions Std                  0.477811
evaluation/Actions Max                  0.839236
evaluation/Actions Min                 -0.916686
evaluation/Num Paths                   24
evaluation/Average Returns           -245.328
time/data storing (s)                   0.0074267
time/evaluation sampling (s)          530.795
time/exploration sampling (s)         125.629
time/logging (s)                        0.0203907
time/sac training (s)                   9.25347
time/saving (s)                         0.0270642
time/training (s)                       0.00014884
time/epoch (s)                        665.733
time/total (s)                       5944.71
Epoch                                   8
----------------------------------  --------------
2020-11-01 11:01:47.733025 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 9 finished
----------------------------------  ---------------
replay_buffer/size                  11000
trainer/num train calls             10000
trainer/QF1 Loss                        1.52461
trainer/QF2 Loss                        1.13869
trainer/Policy Loss                    30.4515
trainer/Q1 Predictions Mean           -30.2705
trainer/Q1 Predictions Std              6.09157
trainer/Q1 Predictions Max            -11.3242
trainer/Q1 Predictions Min            -41.5906
trainer/Q2 Predictions Mean           -30.4794
trainer/Q2 Predictions Std              6.05957
trainer/Q2 Predictions Max            -12.0972
trainer/Q2 Predictions Min            -41.7784
trainer/Q Targets Mean                -30.4921
trainer/Q Targets Std                   6.03753
trainer/Q Targets Max                 -10.6424
trainer/Q Targets Min                 -41.7082
trainer/Log Pis Mean                   -0.14936
trainer/Log Pis Std                     1.59382
trainer/Log Pis Max                     5.87214
trainer/Log Pis Min                    -4.30934
trainer/policy/mean Mean               -0.218078
trainer/policy/mean Std                 0.628061
trainer/policy/mean Max                 0.966467
trainer/policy/mean Min                -0.977189
trainer/policy/normal/std Mean          0.868295
trainer/policy/normal/std Std           0.124704
trainer/policy/normal/std Max           1.23438
trainer/policy/normal/std Min           0.431815
trainer/policy/normal/log_std Mean     -0.152117
trainer/policy/normal/log_std Std       0.150214
trainer/policy/normal/log_std Max       0.210572
trainer/policy/normal/log_std Min      -0.839759
trainer/Alpha                           0.073269
trainer/Alpha Loss                     -5.61761
exploration/num steps total         11000
exploration/num paths total            55
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.07406
exploration/Rewards Std                 0.157515
exploration/Rewards Max                -0.66515
exploration/Rewards Min                -1.46747
exploration/Returns Mean             -214.812
exploration/Returns Std                20.3043
exploration/Returns Max              -185.873
exploration/Returns Min              -236.142
exploration/Actions Mean               -0.20312
exploration/Actions Std                 0.671578
exploration/Actions Max                 0.998474
exploration/Actions Min                -0.998964
exploration/Num Paths                   5
exploration/Average Returns          -214.812
evaluation/num steps total          48240
evaluation/num paths total            240
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.11689
evaluation/Rewards Std                  0.177797
evaluation/Rewards Max                 -0.786285
evaluation/Rewards Min                 -1.59705
evaluation/Returns Mean              -224.494
evaluation/Returns Std                 29.0565
evaluation/Returns Max               -181.084
evaluation/Returns Min               -289.003
evaluation/Actions Mean                -0.247964
evaluation/Actions Std                  0.60905
evaluation/Actions Max                  0.965478
evaluation/Actions Min                 -0.984906
evaluation/Num Paths                   24
evaluation/Average Returns           -224.494
time/data storing (s)                   0.00792595
time/evaluation sampling (s)          495.246
time/exploration sampling (s)         122.571
time/logging (s)                        0.0203842
time/sac training (s)                   9.11272
time/saving (s)                         0.0243916
time/training (s)                       0.000119731
time/epoch (s)                        626.982
time/total (s)                       6572.29
Epoch                                   9
----------------------------------  ---------------
2020-11-01 11:11:25.096477 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 10 finished
----------------------------------  ---------------
replay_buffer/size                  12000
trainer/num train calls             11000
trainer/QF1 Loss                        2.00828
trainer/QF2 Loss                        2.36983
trainer/Policy Loss                    33.632
trainer/Q1 Predictions Mean           -33.4239
trainer/Q1 Predictions Std              7.27727
trainer/Q1 Predictions Max             -8.85566
trainer/Q1 Predictions Min            -48.2536
trainer/Q2 Predictions Mean           -33.4997
trainer/Q2 Predictions Std              7.27107
trainer/Q2 Predictions Max             -9.64075
trainer/Q2 Predictions Min            -47.4955
trainer/Q Targets Mean                -33.4848
trainer/Q Targets Std                   7.20257
trainer/Q Targets Max                  -9.07926
trainer/Q Targets Min                 -47.3591
trainer/Log Pis Mean                    0.357163
trainer/Log Pis Std                     1.93383
trainer/Log Pis Max                     5.17171
trainer/Log Pis Min                    -5.96601
trainer/policy/mean Mean               -0.185646
trainer/policy/mean Std                 0.71523
trainer/policy/mean Max                 0.974025
trainer/policy/mean Min                -0.990755
trainer/policy/normal/std Mean          0.839676
trainer/policy/normal/std Std           0.154496
trainer/policy/normal/std Max           1.27773
trainer/policy/normal/std Min           0.447691
trainer/policy/normal/log_std Mean     -0.192537
trainer/policy/normal/log_std Std       0.191967
trainer/policy/normal/log_std Max       0.245085
trainer/policy/normal/log_std Min      -0.803652
trainer/Alpha                           0.0583579
trainer/Alpha Loss                     -4.66756
exploration/num steps total         12000
exploration/num paths total            60
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.0797
exploration/Rewards Std                 0.139223
exploration/Rewards Max                -0.868299
exploration/Rewards Min                -1.55479
exploration/Returns Mean             -215.94
exploration/Returns Std                14.9436
exploration/Returns Max              -190.093
exploration/Returns Min              -230.511
exploration/Actions Mean               -0.104997
exploration/Actions Std                 0.702496
exploration/Actions Max                 0.998307
exploration/Actions Min                -0.999713
exploration/Num Paths                   5
exploration/Average Returns          -215.94
evaluation/num steps total          53064
evaluation/num paths total            264
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.09475
evaluation/Rewards Std                  0.167597
evaluation/Rewards Max                 -0.666203
evaluation/Rewards Min                 -1.642
evaluation/Returns Mean              -220.045
evaluation/Returns Std                 28.0102
evaluation/Returns Max               -159.389
evaluation/Returns Min               -283.297
evaluation/Actions Mean                -0.288916
evaluation/Actions Std                  0.672527
evaluation/Actions Max                  0.970143
evaluation/Actions Min                 -0.999782
evaluation/Num Paths                   24
evaluation/Average Returns           -220.045
time/data storing (s)                   0.00909402
time/evaluation sampling (s)          451.094
time/exploration sampling (s)         114.636
time/logging (s)                        0.022306
time/sac training (s)                  10.9261
time/saving (s)                         0.0366867
time/training (s)                       0.000173494
time/epoch (s)                        576.724
time/total (s)                       7149.62
Epoch                                  10
----------------------------------  ---------------
2020-11-01 11:21:16.974747 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 11 finished
----------------------------------  ---------------
replay_buffer/size                  13000
trainer/num train calls             12000
trainer/QF1 Loss                        2.24858
trainer/QF2 Loss                        2.22583
trainer/Policy Loss                    37.7739
trainer/Q1 Predictions Mean           -37.694
trainer/Q1 Predictions Std              7.74832
trainer/Q1 Predictions Max            -13.8673
trainer/Q1 Predictions Min            -53.4801
trainer/Q2 Predictions Mean           -37.7109
trainer/Q2 Predictions Std              7.61345
trainer/Q2 Predictions Max            -14.043
trainer/Q2 Predictions Min            -52.491
trainer/Q Targets Mean                -38.205
trainer/Q Targets Std                   7.76331
trainer/Q Targets Max                 -11.4551
trainer/Q Targets Min                 -54.6805
trainer/Log Pis Mean                    1.07085
trainer/Log Pis Std                     2.25826
trainer/Log Pis Max                     7.51626
trainer/Log Pis Min                    -5.52135
trainer/policy/mean Mean               -0.348258
trainer/policy/mean Std                 0.708343
trainer/policy/mean Max                 0.993466
trainer/policy/mean Min                -0.992276
trainer/policy/normal/std Mean          0.777153
trainer/policy/normal/std Std           0.155066
trainer/policy/normal/std Max           1.24543
trainer/policy/normal/std Min           0.410023
trainer/policy/normal/log_std Mean     -0.273287
trainer/policy/normal/log_std Std       0.209585
trainer/policy/normal/log_std Max       0.219483
trainer/policy/normal/log_std Min      -0.891541
trainer/Alpha                           0.0478539
trainer/Alpha Loss                     -2.82424
exploration/num steps total         13000
exploration/num paths total            65
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.03294
exploration/Rewards Std                 0.160387
exploration/Rewards Max                -0.730133
exploration/Rewards Min                -1.58696
exploration/Returns Mean             -206.588
exploration/Returns Std                21.3427
exploration/Returns Max              -171.988
exploration/Returns Min              -230.981
exploration/Actions Mean               -0.444242
exploration/Actions Std                 0.636865
exploration/Actions Max                 0.996221
exploration/Actions Min                -0.99946
exploration/Num Paths                   5
exploration/Average Returns          -206.588
evaluation/num steps total          57888
evaluation/num paths total            288
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.08663
evaluation/Rewards Std                  0.14826
evaluation/Rewards Max                 -0.664552
evaluation/Rewards Min                 -1.71572
evaluation/Returns Mean              -218.413
evaluation/Returns Std                 21.648
evaluation/Returns Max               -181.469
evaluation/Returns Min               -257.746
evaluation/Actions Mean                -0.273017
evaluation/Actions Std                  0.659391
evaluation/Actions Max                  0.988645
evaluation/Actions Min                 -0.995862
evaluation/Num Paths                   24
evaluation/Average Returns           -218.413
time/data storing (s)                   0.0104869
time/evaluation sampling (s)          464.562
time/exploration sampling (s)         116.917
time/logging (s)                        0.0534925
time/sac training (s)                   9.65515
time/saving (s)                         0.0504988
time/training (s)                       0.000138661
time/epoch (s)                        591.249
time/total (s)                       7741.51
Epoch                                  11
----------------------------------  ---------------
2020-11-01 11:31:28.580369 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 12 finished
----------------------------------  ---------------
replay_buffer/size                  14000
trainer/num train calls             13000
trainer/QF1 Loss                        2.93885
trainer/QF2 Loss                        2.77253
trainer/Policy Loss                    40.8
trainer/Q1 Predictions Mean           -40.7112
trainer/Q1 Predictions Std              9.41211
trainer/Q1 Predictions Max            -16.9876
trainer/Q1 Predictions Min            -58.687
trainer/Q2 Predictions Mean           -40.593
trainer/Q2 Predictions Std              9.3097
trainer/Q2 Predictions Max            -16.1517
trainer/Q2 Predictions Min            -57.5504
trainer/Q Targets Mean                -40.9491
trainer/Q Targets Std                   9.46992
trainer/Q Targets Max                 -17.1459
trainer/Q Targets Min                 -59.4948
trainer/Log Pis Mean                    1.38702
trainer/Log Pis Std                     2.13225
trainer/Log Pis Max                     8.02896
trainer/Log Pis Min                    -4.42794
trainer/policy/mean Mean               -0.292999
trainer/policy/mean Std                 0.734173
trainer/policy/mean Max                 0.990473
trainer/policy/mean Min                -0.992431
trainer/policy/normal/std Mean          0.764692
trainer/policy/normal/std Std           0.15941
trainer/policy/normal/std Max           1.42055
trainer/policy/normal/std Min           0.42349
trainer/policy/normal/log_std Mean     -0.290466
trainer/policy/normal/log_std Std       0.212573
trainer/policy/normal/log_std Max       0.351045
trainer/policy/normal/log_std Min      -0.859224
trainer/Alpha                           0.0412606
trainer/Alpha Loss                     -1.9541
exploration/num steps total         14000
exploration/num paths total            70
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.08327
exploration/Rewards Std                 0.164546
exploration/Rewards Max                -0.823909
exploration/Rewards Min                -1.66824
exploration/Returns Mean             -216.653
exploration/Returns Std                23.9394
exploration/Returns Max              -193.79
exploration/Returns Min              -259.474
exploration/Actions Mean               -0.230171
exploration/Actions Std                 0.735231
exploration/Actions Max                 0.999337
exploration/Actions Min                -0.999653
exploration/Num Paths                   5
exploration/Average Returns          -216.653
evaluation/num steps total          62712
evaluation/num paths total            312
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.1259
evaluation/Rewards Std                  0.23174
evaluation/Rewards Max                 -0.680344
evaluation/Rewards Min                 -1.87325
evaluation/Returns Mean              -226.306
evaluation/Returns Std                 40.8855
evaluation/Returns Max               -168.578
evaluation/Returns Min               -332.332
evaluation/Actions Mean                -0.127574
evaluation/Actions Std                  0.73577
evaluation/Actions Max                  0.991417
evaluation/Actions Min                 -0.998547
evaluation/Num Paths                   24
evaluation/Average Returns           -226.306
time/data storing (s)                   0.00951644
time/evaluation sampling (s)          486.359
time/exploration sampling (s)         115.267
time/logging (s)                        0.0258649
time/sac training (s)                   9.1869
time/saving (s)                         0.0376876
time/training (s)                       0.000117713
time/epoch (s)                        610.886
time/total (s)                       8353.06
Epoch                                  12
----------------------------------  ---------------
2020-11-01 11:42:35.864673 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 13 finished
----------------------------------  ---------------
replay_buffer/size                  15000
trainer/num train calls             14000
trainer/QF1 Loss                        4.20367
trainer/QF2 Loss                        5.29822
trainer/Policy Loss                    45.7212
trainer/Q1 Predictions Mean           -45.6193
trainer/Q1 Predictions Std             11.7779
trainer/Q1 Predictions Max             -8.92759
trainer/Q1 Predictions Min            -65.0182
trainer/Q2 Predictions Mean           -45.607
trainer/Q2 Predictions Std             11.845
trainer/Q2 Predictions Max             -9.6263
trainer/Q2 Predictions Min            -65.1616
trainer/Q Targets Mean                -45.0205
trainer/Q Targets Std                  11.5803
trainer/Q Targets Max                  -0.724092
trainer/Q Targets Min                 -63.7575
trainer/Log Pis Mean                    1.59657
trainer/Log Pis Std                     2.22167
trainer/Log Pis Max                     8.79351
trainer/Log Pis Min                    -3.62621
trainer/policy/mean Mean               -0.245333
trainer/policy/mean Std                 0.779956
trainer/policy/mean Max                 0.995938
trainer/policy/mean Min                -0.996373
trainer/policy/normal/std Mean          0.757701
trainer/policy/normal/std Std           0.150293
trainer/policy/normal/std Max           1.38151
trainer/policy/normal/std Min           0.467692
trainer/policy/normal/log_std Mean     -0.296506
trainer/policy/normal/log_std Std       0.1943
trainer/policy/normal/log_std Max       0.32318
trainer/policy/normal/log_std Min      -0.759946
trainer/Alpha                           0.0381498
trainer/Alpha Loss                     -1.31769
exploration/num steps total         15000
exploration/num paths total            75
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.07919
exploration/Rewards Std                 0.204972
exploration/Rewards Max                -0.765102
exploration/Rewards Min                -1.75358
exploration/Returns Mean             -215.838
exploration/Returns Std                28.8447
exploration/Returns Max              -186.923
exploration/Returns Min              -270.448
exploration/Actions Mean               -0.183623
exploration/Actions Std                 0.728963
exploration/Actions Max                 0.999059
exploration/Actions Min                -0.998854
exploration/Num Paths                   5
exploration/Average Returns          -215.838
evaluation/num steps total          67536
evaluation/num paths total            336
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.09036
evaluation/Rewards Std                  0.156454
evaluation/Rewards Max                 -0.748632
evaluation/Rewards Min                 -1.67595
evaluation/Returns Mean              -219.163
evaluation/Returns Std                 25.7684
evaluation/Returns Max               -176.733
evaluation/Returns Min               -283.93
evaluation/Actions Mean                -0.0839989
evaluation/Actions Std                  0.708625
evaluation/Actions Max                  0.995232
evaluation/Actions Min                 -0.994754
evaluation/Num Paths                   24
evaluation/Average Returns           -219.163
time/data storing (s)                   0.00810474
time/evaluation sampling (s)          542.938
time/exploration sampling (s)         114.311
time/logging (s)                        0.0231236
time/sac training (s)                   9.28429
time/saving (s)                         0.0393921
time/training (s)                       0.000124614
time/epoch (s)                        666.604
time/total (s)                       9020.31
Epoch                                  13
----------------------------------  ---------------
2020-11-01 11:53:15.141717 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 14 finished
----------------------------------  ---------------
replay_buffer/size                  16000
trainer/num train calls             15000
trainer/QF1 Loss                       10.6088
trainer/QF2 Loss                       12.1947
trainer/Policy Loss                    47.2281
trainer/Q1 Predictions Mean           -47.1111
trainer/Q1 Predictions Std             11.8035
trainer/Q1 Predictions Max             -9.66933
trainer/Q1 Predictions Min            -68.8282
trainer/Q2 Predictions Mean           -46.9341
trainer/Q2 Predictions Std             11.9129
trainer/Q2 Predictions Max            -17.0823
trainer/Q2 Predictions Min            -67.597
trainer/Q Targets Mean                -47.477
trainer/Q Targets Std                  12.0276
trainer/Q Targets Max                  -0.768944
trainer/Q Targets Min                 -68.5556
trainer/Log Pis Mean                    2.25223
trainer/Log Pis Std                     2.34793
trainer/Log Pis Max                    10.3704
trainer/Log Pis Min                    -5.0322
trainer/policy/mean Mean               -0.341498
trainer/policy/mean Std                 0.783004
trainer/policy/mean Max                 0.998906
trainer/policy/mean Min                -0.998033
trainer/policy/normal/std Mean          0.704783
trainer/policy/normal/std Std           0.14166
trainer/policy/normal/std Max           1.12821
trainer/policy/normal/std Min           0.371879
trainer/policy/normal/log_std Mean     -0.370362
trainer/policy/normal/log_std Std       0.20385
trainer/policy/normal/log_std Max       0.120637
trainer/policy/normal/log_std Min      -0.989186
trainer/Alpha                           0.036633
trainer/Alpha Loss                      0.834092
exploration/num steps total         16000
exploration/num paths total            80
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.04792
exploration/Rewards Std                 0.226581
exploration/Rewards Max                -0.603404
exploration/Rewards Min                -1.61922
exploration/Returns Mean             -209.584
exploration/Returns Std                33.9035
exploration/Returns Max              -155.394
exploration/Returns Min              -254.221
exploration/Actions Mean               -0.531231
exploration/Actions Std                 0.640243
exploration/Actions Max                 0.995692
exploration/Actions Min                -0.999665
exploration/Num Paths                   5
exploration/Average Returns          -209.584
evaluation/num steps total          72360
evaluation/num paths total            360
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.06291
evaluation/Rewards Std                  0.19778
evaluation/Rewards Max                 -0.61933
evaluation/Rewards Min                 -1.69569
evaluation/Returns Mean              -213.644
evaluation/Returns Std                 32.7338
evaluation/Returns Max               -161.486
evaluation/Returns Min               -281.095
evaluation/Actions Mean                -0.213851
evaluation/Actions Std                  0.709406
evaluation/Actions Max                  0.994539
evaluation/Actions Min                 -0.997778
evaluation/Num Paths                   24
evaluation/Average Returns           -213.644
time/data storing (s)                   0.0100104
time/evaluation sampling (s)          514.436
time/exploration sampling (s)         114.834
time/logging (s)                        0.0291278
time/sac training (s)                   9.26275
time/saving (s)                         0.0330389
time/training (s)                       0.000122512
time/epoch (s)                        638.605
time/total (s)                       9659.56
Epoch                                  14
----------------------------------  ---------------
2020-11-01 12:04:00.200797 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 15 finished
----------------------------------  ---------------
replay_buffer/size                  17000
trainer/num train calls             16000
trainer/QF1 Loss                        5.73694
trainer/QF2 Loss                        4.25253
trainer/Policy Loss                    49.5246
trainer/Q1 Predictions Mean           -49.1552
trainer/Q1 Predictions Std             12.5482
trainer/Q1 Predictions Max            -16.7037
trainer/Q1 Predictions Min            -72.5039
trainer/Q2 Predictions Mean           -49.4588
trainer/Q2 Predictions Std             12.4087
trainer/Q2 Predictions Max            -19.2826
trainer/Q2 Predictions Min            -74.5659
trainer/Q Targets Mean                -49.8927
trainer/Q Targets Std                  12.5501
trainer/Q Targets Max                 -18.4512
trainer/Q Targets Min                 -75.4499
trainer/Log Pis Mean                    1.77379
trainer/Log Pis Std                     2.28051
trainer/Log Pis Max                     8.14033
trainer/Log Pis Min                    -4.25061
trainer/policy/mean Mean               -0.193664
trainer/policy/mean Std                 0.82057
trainer/policy/mean Max                 0.996355
trainer/policy/mean Min                -0.996817
trainer/policy/normal/std Mean          0.71242
trainer/policy/normal/std Std           0.128927
trainer/policy/normal/std Max           1.13267
trainer/policy/normal/std Min           0.427176
trainer/policy/normal/log_std Mean     -0.355146
trainer/policy/normal/log_std Std       0.17896
trainer/policy/normal/log_std Max       0.124574
trainer/policy/normal/log_std Min      -0.850558
trainer/Alpha                           0.0371232
trainer/Alpha Loss                     -0.745011
exploration/num steps total         17000
exploration/num paths total            85
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -0.989825
exploration/Rewards Std                 0.193585
exploration/Rewards Max                -0.627091
exploration/Rewards Min                -1.58273
exploration/Returns Mean             -197.965
exploration/Returns Std                30.2398
exploration/Returns Max              -170.255
exploration/Returns Min              -252.575
exploration/Actions Mean               -0.122088
exploration/Actions Std                 0.77537
exploration/Actions Max                 0.999271
exploration/Actions Min                -0.999472
exploration/Num Paths                   5
exploration/Average Returns          -197.965
evaluation/num steps total          77184
evaluation/num paths total            384
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.108
evaluation/Rewards Std                  0.195626
evaluation/Rewards Max                 -0.649351
evaluation/Rewards Min                 -1.69934
evaluation/Returns Mean              -222.707
evaluation/Returns Std                 32.9457
evaluation/Returns Max               -161.463
evaluation/Returns Min               -309.055
evaluation/Actions Mean                -0.0866149
evaluation/Actions Std                  0.775271
evaluation/Actions Max                  0.996579
evaluation/Actions Min                 -0.998372
evaluation/Num Paths                   24
evaluation/Average Returns           -222.707
time/data storing (s)                   0.00841772
time/evaluation sampling (s)          523.834
time/exploration sampling (s)         110.455
time/logging (s)                        0.0234323
time/sac training (s)                   9.98499
time/saving (s)                         0.0432694
time/training (s)                       0.000114695
time/epoch (s)                        644.349
time/total (s)                      10304.6
Epoch                                  15
----------------------------------  ---------------
2020-11-01 12:15:41.603338 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 16 finished
----------------------------------  --------------
replay_buffer/size                  18000
trainer/num train calls             17000
trainer/QF1 Loss                        7.72176
trainer/QF2 Loss                        6.78885
trainer/Policy Loss                    53.3792
trainer/Q1 Predictions Mean           -53.258
trainer/Q1 Predictions Std             14.8352
trainer/Q1 Predictions Max             -5.24499
trainer/Q1 Predictions Min            -78.9866
trainer/Q2 Predictions Mean           -53.1385
trainer/Q2 Predictions Std             14.4796
trainer/Q2 Predictions Max            -16.3485
trainer/Q2 Predictions Min            -78.1631
trainer/Q Targets Mean                -53.2973
trainer/Q Targets Std                  14.8256
trainer/Q Targets Max                  -0.768944
trainer/Q Targets Min                 -77.6231
trainer/Log Pis Mean                    2.14986
trainer/Log Pis Std                     2.57825
trainer/Log Pis Max                    11.5104
trainer/Log Pis Min                    -3.88177
trainer/policy/mean Mean               -0.233038
trainer/policy/mean Std                 0.803094
trainer/policy/mean Max                 0.999879
trainer/policy/mean Min                -0.998709
trainer/policy/normal/std Mean          0.693908
trainer/policy/normal/std Std           0.126718
trainer/policy/normal/std Max           1.16179
trainer/policy/normal/std Min           0.422961
trainer/policy/normal/log_std Mean     -0.381926
trainer/policy/normal/log_std Std       0.181956
trainer/policy/normal/log_std Max       0.149959
trainer/policy/normal/log_std Min      -0.860476
trainer/Alpha                           0.0365219
trainer/Alpha Loss                      0.496025
exploration/num steps total         18000
exploration/num paths total            90
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.04671
exploration/Rewards Std                 0.164093
exploration/Rewards Max                -0.740986
exploration/Rewards Min                -1.51471
exploration/Returns Mean             -209.342
exploration/Returns Std                21.0622
exploration/Returns Max              -186.96
exploration/Returns Min              -240.855
exploration/Actions Mean               -0.113213
exploration/Actions Std                 0.711703
exploration/Actions Max                 0.998992
exploration/Actions Min                -0.998812
exploration/Num Paths                   5
exploration/Average Returns          -209.342
evaluation/num steps total          82008
evaluation/num paths total            408
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.10121
evaluation/Rewards Std                  0.193474
evaluation/Rewards Max                 -0.647801
evaluation/Rewards Min                 -1.702
evaluation/Returns Mean              -221.344
evaluation/Returns Std                 33.825
evaluation/Returns Max               -165.956
evaluation/Returns Min               -278.504
evaluation/Actions Mean                -0.085402
evaluation/Actions Std                  0.686183
evaluation/Actions Max                  0.995981
evaluation/Actions Min                 -0.994868
evaluation/Num Paths                   24
evaluation/Average Returns           -221.344
time/data storing (s)                   0.00881214
time/evaluation sampling (s)          566.062
time/exploration sampling (s)         125.284
time/logging (s)                        0.0232192
time/sac training (s)                   9.29218
time/saving (s)                         0.0415181
time/training (s)                       0.00012286
time/epoch (s)                        700.712
time/total (s)                      11006
Epoch                                  16
----------------------------------  --------------
2020-11-01 12:27:21.860177 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 17 finished
----------------------------------  ---------------
replay_buffer/size                  19000
trainer/num train calls             18000
trainer/QF1 Loss                        8.23204
trainer/QF2 Loss                       11.7782
trainer/Policy Loss                    55.1992
trainer/Q1 Predictions Mean           -55.0094
trainer/Q1 Predictions Std             15.2318
trainer/Q1 Predictions Max             -2.59419
trainer/Q1 Predictions Min            -83.5474
trainer/Q2 Predictions Mean           -54.8941
trainer/Q2 Predictions Std             15.1654
trainer/Q2 Predictions Max             -2.85629
trainer/Q2 Predictions Min            -84.4203
trainer/Q Targets Mean                -55.2355
trainer/Q Targets Std                  15.572
trainer/Q Targets Max                  -1.03888
trainer/Q Targets Min                 -82.8392
trainer/Log Pis Mean                    2.04483
trainer/Log Pis Std                     2.28204
trainer/Log Pis Max                     8.01732
trainer/Log Pis Min                    -4.10708
trainer/policy/mean Mean               -0.226604
trainer/policy/mean Std                 0.802825
trainer/policy/mean Max                 0.994359
trainer/policy/mean Min                -0.997633
trainer/policy/normal/std Mean          0.698183
trainer/policy/normal/std Std           0.131242
trainer/policy/normal/std Max           1.1884
trainer/policy/normal/std Min           0.380407
trainer/policy/normal/log_std Mean     -0.376583
trainer/policy/normal/log_std Std       0.185973
trainer/policy/normal/log_std Max       0.172611
trainer/policy/normal/log_std Min      -0.966515
trainer/Alpha                           0.0369302
trainer/Alpha Loss                      0.147879
exploration/num steps total         19000
exploration/num paths total            95
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.03602
exploration/Rewards Std                 0.194786
exploration/Rewards Max                -0.704536
exploration/Rewards Min                -1.57866
exploration/Returns Mean             -207.204
exploration/Returns Std                29.8614
exploration/Returns Max              -174.038
exploration/Returns Min              -259.76
exploration/Actions Mean               -0.307201
exploration/Actions Std                 0.683772
exploration/Actions Max                 0.999368
exploration/Actions Min                -0.999581
exploration/Num Paths                   5
exploration/Average Returns          -207.204
evaluation/num steps total          86832
evaluation/num paths total            432
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.0528
evaluation/Rewards Std                  0.173094
evaluation/Rewards Max                 -0.66843
evaluation/Rewards Min                 -1.99205
evaluation/Returns Mean              -211.612
evaluation/Returns Std                 22.3829
evaluation/Returns Max               -170.908
evaluation/Returns Min               -274.844
evaluation/Actions Mean                -0.37646
evaluation/Actions Std                  0.666857
evaluation/Actions Max                  0.988701
evaluation/Actions Min                 -0.998912
evaluation/Num Paths                   24
evaluation/Average Returns           -211.612
time/data storing (s)                   0.0146562
time/evaluation sampling (s)          564.345
time/exploration sampling (s)         125.819
time/logging (s)                        0.0320222
time/sac training (s)                   9.2829
time/saving (s)                         0.0484174
time/training (s)                       0.000126845
time/epoch (s)                        699.542
time/total (s)                      11706.2
Epoch                                  17
----------------------------------  ---------------
2020-11-01 12:38:45.392268 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 18 finished
----------------------------------  --------------
replay_buffer/size                  20000
trainer/num train calls             19000
trainer/QF1 Loss                        6.53875
trainer/QF2 Loss                       10.0708
trainer/Policy Loss                    60.5665
trainer/Q1 Predictions Mean           -60.3331
trainer/Q1 Predictions Std             15.3256
trainer/Q1 Predictions Max            -17.8338
trainer/Q1 Predictions Min            -88.4488
trainer/Q2 Predictions Mean           -60.2977
trainer/Q2 Predictions Std             15.6155
trainer/Q2 Predictions Max            -14.1091
trainer/Q2 Predictions Min            -88.8118
trainer/Q Targets Mean                -60.3909
trainer/Q Targets Std                  15.569
trainer/Q Targets Max                  -1.13195
trainer/Q Targets Min                 -88.5848
trainer/Log Pis Mean                    1.83765
trainer/Log Pis Std                     2.46668
trainer/Log Pis Max                     9.55584
trainer/Log Pis Min                    -5.42316
trainer/policy/mean Mean               -0.0757072
trainer/policy/mean Std                 0.826811
trainer/policy/mean Max                 0.998864
trainer/policy/mean Min                -0.998928
trainer/policy/normal/std Mean          0.720332
trainer/policy/normal/std Std           0.13778
trainer/policy/normal/std Max           1.46075
trainer/policy/normal/std Min           0.426498
trainer/policy/normal/log_std Mean     -0.345138
trainer/policy/normal/log_std Std       0.182809
trainer/policy/normal/log_std Max       0.378947
trainer/policy/normal/log_std Min      -0.852148
trainer/Alpha                           0.0375235
trainer/Alpha Loss                     -0.532963
exploration/num steps total         20000
exploration/num paths total           100
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.0432
exploration/Rewards Std                 0.154456
exploration/Rewards Max                -0.79655
exploration/Rewards Min                -1.43451
exploration/Returns Mean             -208.64
exploration/Returns Std                20.8161
exploration/Returns Max              -186.718
exploration/Returns Min              -243.247
exploration/Actions Mean               -0.165081
exploration/Actions Std                 0.71922
exploration/Actions Max                 0.999206
exploration/Actions Min                -0.999683
exploration/Num Paths                   5
exploration/Average Returns          -208.64
evaluation/num steps total          91656
evaluation/num paths total            456
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.02896
evaluation/Rewards Std                  0.138166
evaluation/Rewards Max                 -0.622455
evaluation/Rewards Min                 -1.62853
evaluation/Returns Mean              -206.821
evaluation/Returns Std                 18.3076
evaluation/Returns Max               -170.653
evaluation/Returns Min               -239.173
evaluation/Actions Mean                -0.19716
evaluation/Actions Std                  0.674099
evaluation/Actions Max                  0.996403
evaluation/Actions Min                 -0.998523
evaluation/Num Paths                   24
evaluation/Average Returns           -206.821
time/data storing (s)                   0.0131428
time/evaluation sampling (s)          536.142
time/exploration sampling (s)         137.247
time/logging (s)                        0.0244664
time/sac training (s)                   9.35398
time/saving (s)                         0.0469017
time/training (s)                       0.00011366
time/epoch (s)                        682.827
time/total (s)                      12389.7
Epoch                                  18
----------------------------------  --------------
2020-11-01 12:51:35.423983 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 19 finished
----------------------------------  ---------------
replay_buffer/size                  21000
trainer/num train calls             20000
trainer/QF1 Loss                        7.90308
trainer/QF2 Loss                        6.76201
trainer/Policy Loss                    61.6093
trainer/Q1 Predictions Mean           -61.5255
trainer/Q1 Predictions Std             16.2854
trainer/Q1 Predictions Max             -9.81654
trainer/Q1 Predictions Min            -92.7154
trainer/Q2 Predictions Mean           -61.2155
trainer/Q2 Predictions Std             16.2754
trainer/Q2 Predictions Max            -12.9909
trainer/Q2 Predictions Min            -93.999
trainer/Q Targets Mean                -61.5998
trainer/Q Targets Std                  16.2921
trainer/Q Targets Max                 -11.8466
trainer/Q Targets Min                 -94.976
trainer/Log Pis Mean                    2.13562
trainer/Log Pis Std                     2.45263
trainer/Log Pis Max                    10.4146
trainer/Log Pis Min                    -3.56024
trainer/policy/mean Mean               -0.0911069
trainer/policy/mean Std                 0.831265
trainer/policy/mean Max                 0.999374
trainer/policy/mean Min                -0.994732
trainer/policy/normal/std Mean          0.66705
trainer/policy/normal/std Std           0.115508
trainer/policy/normal/std Max           1.14768
trainer/policy/normal/std Min           0.411769
trainer/policy/normal/log_std Mean     -0.419896
trainer/policy/normal/log_std Std       0.173845
trainer/policy/normal/log_std Max       0.137746
trainer/policy/normal/log_std Min      -0.887294
trainer/Alpha                           0.038881
trainer/Alpha Loss                      0.440402
exploration/num steps total         21000
exploration/num paths total           105
exploration/path length Mean          200
exploration/path length Std             2
exploration/path length Max           201
exploration/path length Min           196
exploration/Rewards Mean               -1.06992
exploration/Rewards Std                 0.18037
exploration/Rewards Max                -0.804001
exploration/Rewards Min                -1.57575
exploration/Returns Mean             -213.984
exploration/Returns Std                28.0334
exploration/Returns Max              -185.873
exploration/Returns Min              -267.947
exploration/Actions Mean                0.153969
exploration/Actions Std                 0.717899
exploration/Actions Max                 0.999019
exploration/Actions Min                -0.99781
exploration/Num Paths                   5
exploration/Average Returns          -213.984
evaluation/num steps total          96480
evaluation/num paths total            480
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -1.05418
evaluation/Rewards Std                  0.161636
evaluation/Rewards Max                 -0.626342
evaluation/Rewards Min                 -1.64022
evaluation/Returns Mean              -211.89
evaluation/Returns Std                 23.626
evaluation/Returns Max               -163.468
evaluation/Returns Min               -257.852
evaluation/Actions Mean                -0.158145
evaluation/Actions Std                  0.690412
evaluation/Actions Max                  0.999597
evaluation/Actions Min                 -0.997764
evaluation/Num Paths                   24
evaluation/Average Returns           -211.89
time/data storing (s)                   0.0116347
time/evaluation sampling (s)          607.538
time/exploration sampling (s)         148.954
time/logging (s)                        0.0488828
time/sac training (s)                  12.629
time/saving (s)                         0.0484231
time/training (s)                       0.000123146
time/epoch (s)                        769.231
time/total (s)                      13159.7
Epoch                                  19
----------------------------------  ---------------
2020-11-01 13:05:18.587157 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 20 finished
----------------------------------  ----------------
replay_buffer/size                   22000
trainer/num train calls              21000
trainer/QF1 Loss                         9.48895
trainer/QF2 Loss                         8.98771
trainer/Policy Loss                     65.1565
trainer/Q1 Predictions Mean            -64.9667
trainer/Q1 Predictions Std              17.8102
trainer/Q1 Predictions Max             -11.0248
trainer/Q1 Predictions Min             -97.3495
trainer/Q2 Predictions Mean            -64.6184
trainer/Q2 Predictions Std              17.374
trainer/Q2 Predictions Max             -19.2796
trainer/Q2 Predictions Min             -95.7484
trainer/Q Targets Mean                 -64.7945
trainer/Q Targets Std                   17.8837
trainer/Q Targets Max                   -0.967688
trainer/Q Targets Min                  -96.1248
trainer/Log Pis Mean                     1.97007
trainer/Log Pis Std                      2.27708
trainer/Log Pis Max                      7.69199
trainer/Log Pis Min                     -5.42417
trainer/policy/mean Mean                -0.239408
trainer/policy/mean Std                  0.803995
trainer/policy/mean Max                  0.99847
trainer/policy/mean Min                 -0.995238
trainer/policy/normal/std Mean           0.680505
trainer/policy/normal/std Std            0.102555
trainer/policy/normal/std Max            1.01855
trainer/policy/normal/std Min            0.405678
trainer/policy/normal/log_std Mean      -0.39615
trainer/policy/normal/log_std Std        0.149833
trainer/policy/normal/log_std Max        0.0183779
trainer/policy/normal/log_std Min       -0.902195
trainer/Alpha                            0.0403045
trainer/Alpha Loss                      -0.0961254
exploration/num steps total          22000
exploration/num paths total            110
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.05959
exploration/Rewards Std                  0.173598
exploration/Rewards Max                 -0.774135
exploration/Rewards Min                 -1.79982
exploration/Returns Mean              -211.919
exploration/Returns Std                 16.8418
exploration/Returns Max               -199.391
exploration/Returns Min               -244.294
exploration/Actions Mean                -0.160935
exploration/Actions Std                  0.671521
exploration/Actions Max                  0.993757
exploration/Actions Min                 -0.999439
exploration/Num Paths                    5
exploration/Average Returns           -211.919
evaluation/num steps total          101304
evaluation/num paths total             504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.07703
evaluation/Rewards Std                   0.152523
evaluation/Rewards Max                  -0.768285
evaluation/Rewards Min                  -1.57132
evaluation/Returns Mean               -216.483
evaluation/Returns Std                  24.5662
evaluation/Returns Max                -182.597
evaluation/Returns Min                -259.152
evaluation/Actions Mean                 -0.290474
evaluation/Actions Std                   0.668799
evaluation/Actions Max                   0.997343
evaluation/Actions Min                  -0.999639
evaluation/Num Paths                    24
evaluation/Average Returns            -216.483
time/data storing (s)                    0.00933296
time/evaluation sampling (s)           677.575
time/exploration sampling (s)          134.491
time/logging (s)                         0.0621433
time/sac training (s)                   10.1875
time/saving (s)                          0.0570858
time/training (s)                        0.000126996
time/epoch (s)                         822.382
time/total (s)                       13982.9
Epoch                                   20
----------------------------------  ----------------
2020-11-01 13:19:44.554908 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 21 finished
----------------------------------  ----------------
replay_buffer/size                   23000
trainer/num train calls              22000
trainer/QF1 Loss                        12.6474
trainer/QF2 Loss                        16.5948
trainer/Policy Loss                     67.9873
trainer/Q1 Predictions Mean            -67.7088
trainer/Q1 Predictions Std              18.7942
trainer/Q1 Predictions Max             -21.3744
trainer/Q1 Predictions Min            -103.542
trainer/Q2 Predictions Mean            -67.8593
trainer/Q2 Predictions Std              18.9044
trainer/Q2 Predictions Max             -20.9953
trainer/Q2 Predictions Min            -103.522
trainer/Q Targets Mean                 -67.6395
trainer/Q Targets Std                   19.5979
trainer/Q Targets Max                   -0.928092
trainer/Q Targets Min                 -104.352
trainer/Log Pis Mean                     2.47386
trainer/Log Pis Std                      2.88041
trainer/Log Pis Max                     10.5561
trainer/Log Pis Min                     -5.28141
trainer/policy/mean Mean                -0.434
trainer/policy/mean Std                  0.71677
trainer/policy/mean Max                  0.998873
trainer/policy/mean Min                 -0.999564
trainer/policy/normal/std Mean           0.662045
trainer/policy/normal/std Std            0.107861
trainer/policy/normal/std Max            1.00559
trainer/policy/normal/std Min            0.405722
trainer/policy/normal/log_std Mean      -0.426071
trainer/policy/normal/log_std Std        0.166819
trainer/policy/normal/log_std Max        0.00557333
trainer/policy/normal/log_std Min       -0.902088
trainer/Alpha                            0.0418115
trainer/Alpha Loss                       1.5043
exploration/num steps total          23000
exploration/num paths total            115
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00195
exploration/Rewards Std                  0.136299
exploration/Rewards Max                 -0.743694
exploration/Rewards Min                 -1.45059
exploration/Returns Mean              -200.39
exploration/Returns Std                 11.5658
exploration/Returns Max               -185.908
exploration/Returns Min               -221.162
exploration/Actions Mean                -0.654843
exploration/Actions Std                  0.560514
exploration/Actions Max                  0.979137
exploration/Actions Min                 -0.999759
exploration/Num Paths                    5
exploration/Average Returns           -200.39
evaluation/num steps total          106128
evaluation/num paths total             528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.03295
evaluation/Rewards Std                   0.189788
evaluation/Rewards Max                  -0.658011
evaluation/Rewards Min                  -1.91635
evaluation/Returns Mean               -207.623
evaluation/Returns Std                  31.3934
evaluation/Returns Max                -157.297
evaluation/Returns Min                -299.032
evaluation/Actions Mean                 -0.253654
evaluation/Actions Std                   0.63514
evaluation/Actions Max                   0.996804
evaluation/Actions Min                  -0.998455
evaluation/Num Paths                    24
evaluation/Average Returns            -207.623
time/data storing (s)                    0.184575
time/evaluation sampling (s)           671.319
time/exploration sampling (s)          165.731
time/logging (s)                         0.961275
time/sac training (s)                   24.7654
time/saving (s)                          1.28325
time/training (s)                        0.000262137
time/epoch (s)                         864.245
time/total (s)                       14849.4
Epoch                                   21
----------------------------------  ----------------
2020-11-01 13:32:36.783594 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 22 finished
----------------------------------  ----------------
replay_buffer/size                   24000
trainer/num train calls              23000
trainer/QF1 Loss                        15.4303
trainer/QF2 Loss                        15.3834
trainer/Policy Loss                     69.5868
trainer/Q1 Predictions Mean            -69.4033
trainer/Q1 Predictions Std              19.0898
trainer/Q1 Predictions Max             -18.9903
trainer/Q1 Predictions Min            -101.042
trainer/Q2 Predictions Mean            -69.3678
trainer/Q2 Predictions Std              19.0289
trainer/Q2 Predictions Max             -19.563
trainer/Q2 Predictions Min            -101.794
trainer/Q Targets Mean                 -69.4976
trainer/Q Targets Std                   19.4429
trainer/Q Targets Max                   -0.930493
trainer/Q Targets Min                 -103.081
trainer/Log Pis Mean                     2.34034
trainer/Log Pis Std                      2.393
trainer/Log Pis Max                     10.4196
trainer/Log Pis Min                     -3.55577
trainer/policy/mean Mean                -0.0953917
trainer/policy/mean Std                  0.843754
trainer/policy/mean Max                  0.999594
trainer/policy/mean Min                 -0.998389
trainer/policy/normal/std Mean           0.677156
trainer/policy/normal/std Std            0.112007
trainer/policy/normal/std Max            1.16724
trainer/policy/normal/std Min            0.428988
trainer/policy/normal/log_std Mean      -0.403292
trainer/policy/normal/log_std Std        0.163969
trainer/policy/normal/log_std Max        0.154638
trainer/policy/normal/log_std Min       -0.846326
trainer/Alpha                            0.041965
trainer/Alpha Loss                       1.07918
exploration/num steps total          24000
exploration/num paths total            120
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.06597
exploration/Rewards Std                  0.186353
exploration/Rewards Max                 -0.7355
exploration/Rewards Min                 -1.7306
exploration/Returns Mean              -213.193
exploration/Returns Std                 19.7151
exploration/Returns Max               -187.777
exploration/Returns Min               -235.978
exploration/Actions Mean                -0.14844
exploration/Actions Std                  0.743381
exploration/Actions Max                  0.999423
exploration/Actions Min                 -0.999124
exploration/Num Paths                    5
exploration/Average Returns           -213.193
evaluation/num steps total          110952
evaluation/num paths total             552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.04547
evaluation/Rewards Std                   0.165817
evaluation/Rewards Max                  -0.668128
evaluation/Rewards Min                  -1.68426
evaluation/Returns Mean               -210.14
evaluation/Returns Std                  22.3546
evaluation/Returns Max                -161.037
evaluation/Returns Min                -249.899
evaluation/Actions Mean                 -0.275245
evaluation/Actions Std                   0.659042
evaluation/Actions Max                   0.998598
evaluation/Actions Min                  -0.996793
evaluation/Num Paths                    24
evaluation/Average Returns            -210.14
time/data storing (s)                    0.0487219
time/evaluation sampling (s)           645.242
time/exploration sampling (s)          115.137
time/logging (s)                         0.0678974
time/sac training (s)                    9.71068
time/saving (s)                          0.166263
time/training (s)                        0.000120007
time/epoch (s)                         770.373
time/total (s)                       15620.8
Epoch                                   22
----------------------------------  ----------------
2020-11-01 13:42:58.808288 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 23 finished
----------------------------------  ----------------
replay_buffer/size                   25000
trainer/num train calls              24000
trainer/QF1 Loss                        23.1369
trainer/QF2 Loss                        18.7045
trainer/Policy Loss                     72.4351
trainer/Q1 Predictions Mean            -72.0147
trainer/Q1 Predictions Std              20.4787
trainer/Q1 Predictions Max              -7.2015
trainer/Q1 Predictions Min            -109.996
trainer/Q2 Predictions Mean            -72.267
trainer/Q2 Predictions Std              20.1066
trainer/Q2 Predictions Max             -17.6629
trainer/Q2 Predictions Min            -109.793
trainer/Q Targets Mean                 -72.2449
trainer/Q Targets Std                   20.1223
trainer/Q Targets Max                   -0.922597
trainer/Q Targets Min                 -110.421
trainer/Log Pis Mean                     2.43337
trainer/Log Pis Std                      2.19215
trainer/Log Pis Max                      9.80539
trainer/Log Pis Min                     -2.92164
trainer/policy/mean Mean                -0.282205
trainer/policy/mean Std                  0.797473
trainer/policy/mean Max                  0.997862
trainer/policy/mean Min                 -0.995667
trainer/policy/normal/std Mean           0.654898
trainer/policy/normal/std Std            0.104869
trainer/policy/normal/std Max            1.00218
trainer/policy/normal/std Min            0.418066
trainer/policy/normal/log_std Mean      -0.436246
trainer/policy/normal/log_std Std        0.161898
trainer/policy/normal/log_std Max        0.00218225
trainer/policy/normal/log_std Min       -0.872117
trainer/Alpha                            0.040991
trainer/Alpha Loss                       1.38435
exploration/num steps total          25000
exploration/num paths total            125
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.10505
exploration/Rewards Std                  0.188284
exploration/Rewards Max                 -0.778655
exploration/Rewards Min                 -1.57315
exploration/Returns Mean              -221.011
exploration/Returns Std                 30.6984
exploration/Returns Max               -185.458
exploration/Returns Min               -263.239
exploration/Actions Mean                -0.0862244
exploration/Actions Std                  0.757321
exploration/Actions Max                  0.999587
exploration/Actions Min                 -0.99923
exploration/Num Paths                    5
exploration/Average Returns           -221.011
evaluation/num steps total          115776
evaluation/num paths total             576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.979197
evaluation/Rewards Std                   0.191562
evaluation/Rewards Max                  -0.633633
evaluation/Rewards Min                  -1.71311
evaluation/Returns Mean               -196.819
evaluation/Returns Std                  28.0604
evaluation/Returns Max                -154.574
evaluation/Returns Min                -274.052
evaluation/Actions Mean                 -0.260722
evaluation/Actions Std                   0.701923
evaluation/Actions Max                   0.998657
evaluation/Actions Min                  -0.998311
evaluation/Num Paths                    24
evaluation/Average Returns            -196.819
time/data storing (s)                    0.00979286
time/evaluation sampling (s)           496.245
time/exploration sampling (s)          110.547
time/logging (s)                         0.0468913
time/sac training (s)                   14.1927
time/saving (s)                          0.0511051
time/training (s)                        0.000919147
time/epoch (s)                         621.094
time/total (s)                       16242.8
Epoch                                   23
----------------------------------  ----------------
2020-11-01 13:53:23.284184 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 24 finished
----------------------------------  ----------------
replay_buffer/size                   26000
trainer/num train calls              25000
trainer/QF1 Loss                        30.3979
trainer/QF2 Loss                        34.7768
trainer/Policy Loss                     74.404
trainer/Q1 Predictions Mean            -73.9448
trainer/Q1 Predictions Std              22.7051
trainer/Q1 Predictions Max              19.7225
trainer/Q1 Predictions Min            -112.507
trainer/Q2 Predictions Mean            -74.0011
trainer/Q2 Predictions Std              22.8531
trainer/Q2 Predictions Max              32.7354
trainer/Q2 Predictions Min            -112.057
trainer/Q Targets Mean                 -74.1052
trainer/Q Targets Std                   23.3525
trainer/Q Targets Max                   14.5489
trainer/Q Targets Min                 -113.806
trainer/Log Pis Mean                     1.8659
trainer/Log Pis Std                      2.21842
trainer/Log Pis Max                      7.73709
trainer/Log Pis Min                     -4.71778
trainer/policy/mean Mean                -0.271751
trainer/policy/mean Std                  0.788788
trainer/policy/mean Max                  0.997327
trainer/policy/mean Min                 -0.995507
trainer/policy/normal/std Mean           0.65785
trainer/policy/normal/std Std            0.0980432
trainer/policy/normal/std Max            0.96519
trainer/policy/normal/std Min            0.449322
trainer/policy/normal/log_std Mean      -0.429806
trainer/policy/normal/log_std Std        0.148503
trainer/policy/normal/log_std Max       -0.0354306
trainer/policy/normal/log_std Min       -0.800016
trainer/Alpha                            0.0428287
trainer/Alpha Loss                      -0.422489
exploration/num steps total          26000
exploration/num paths total            130
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.998812
exploration/Rewards Std                  0.153516
exploration/Rewards Max                 -0.639906
exploration/Rewards Min                 -1.45752
exploration/Returns Mean              -199.762
exploration/Returns Std                  5.06253
exploration/Returns Max               -193.059
exploration/Returns Min               -208.08
exploration/Actions Mean                -0.281506
exploration/Actions Std                  0.726478
exploration/Actions Max                  0.999895
exploration/Actions Min                 -0.999855
exploration/Num Paths                    5
exploration/Average Returns           -199.762
evaluation/num steps total          120600
evaluation/num paths total             600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.04565
evaluation/Rewards Std                   0.152869
evaluation/Rewards Max                  -0.685508
evaluation/Rewards Min                  -1.69909
evaluation/Returns Mean               -210.176
evaluation/Returns Std                  21.2343
evaluation/Returns Max                -175.11
evaluation/Returns Min                -254.079
evaluation/Actions Mean                 -0.310508
evaluation/Actions Std                   0.646468
evaluation/Actions Max                   0.998251
evaluation/Actions Min                  -0.997175
evaluation/Num Paths                    24
evaluation/Average Returns            -210.176
time/data storing (s)                    0.0156976
time/evaluation sampling (s)           507.164
time/exploration sampling (s)          106.874
time/logging (s)                         0.0345017
time/sac training (s)                    9.56527
time/saving (s)                          0.0392112
time/training (s)                        0.000127565
time/epoch (s)                         623.692
time/total (s)                       16867.2
Epoch                                   24
----------------------------------  ----------------
2020-11-01 14:03:19.174536 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 25 finished
----------------------------------  ----------------
replay_buffer/size                   27000
trainer/num train calls              26000
trainer/QF1 Loss                        22.4412
trainer/QF2 Loss                        23.0376
trainer/Policy Loss                     76.1997
trainer/Q1 Predictions Mean            -75.9203
trainer/Q1 Predictions Std              22.7174
trainer/Q1 Predictions Max              -9.42832
trainer/Q1 Predictions Min            -117.133
trainer/Q2 Predictions Mean            -75.9266
trainer/Q2 Predictions Std              22.124
trainer/Q2 Predictions Max              -6.01531
trainer/Q2 Predictions Min            -116.852
trainer/Q Targets Mean                 -76.3821
trainer/Q Targets Std                   22.8291
trainer/Q Targets Max                   -1.05572
trainer/Q Targets Min                 -116.623
trainer/Log Pis Mean                     2.25044
trainer/Log Pis Std                      2.34368
trainer/Log Pis Max                      8.3865
trainer/Log Pis Min                     -3.41779
trainer/policy/mean Mean                -0.0262062
trainer/policy/mean Std                  0.86199
trainer/policy/mean Max                  0.997693
trainer/policy/mean Min                 -0.994173
trainer/policy/normal/std Mean           0.671376
trainer/policy/normal/std Std            0.111864
trainer/policy/normal/std Max            1.16405
trainer/policy/normal/std Min            0.439611
trainer/policy/normal/log_std Mean      -0.411894
trainer/policy/normal/log_std Std        0.163393
trainer/policy/normal/log_std Max        0.151902
trainer/policy/normal/log_std Min       -0.821864
trainer/Alpha                            0.0423156
trainer/Alpha Loss                       0.792037
exploration/num steps total          27000
exploration/num paths total            135
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.02484
exploration/Rewards Std                  0.251853
exploration/Rewards Max                 -0.519942
exploration/Rewards Min                 -1.56473
exploration/Returns Mean              -204.968
exploration/Returns Std                 38.0397
exploration/Returns Max               -149.384
exploration/Returns Min               -260.3
exploration/Actions Mean                -0.00941015
exploration/Actions Std                  0.802044
exploration/Actions Max                  0.999534
exploration/Actions Min                 -0.999722
exploration/Num Paths                    5
exploration/Average Returns           -204.968
evaluation/num steps total          125424
evaluation/num paths total             624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.08743
evaluation/Rewards Std                   0.236739
evaluation/Rewards Max                  -0.673066
evaluation/Rewards Min                  -1.96504
evaluation/Returns Mean               -218.573
evaluation/Returns Std                  40.4256
evaluation/Returns Max                -163.853
evaluation/Returns Min                -308.98
evaluation/Actions Mean                 -0.171687
evaluation/Actions Std                   0.710581
evaluation/Actions Max                   0.999707
evaluation/Actions Min                  -0.99656
evaluation/Num Paths                    24
evaluation/Average Returns            -218.573
time/data storing (s)                    0.0112848
time/evaluation sampling (s)           494.962
time/exploration sampling (s)           90.8048
time/logging (s)                         0.0212682
time/sac training (s)                    9.39884
time/saving (s)                          0.0269803
time/training (s)                        0.000120564
time/epoch (s)                         595.226
time/total (s)                       17463.1
Epoch                                   25
----------------------------------  ----------------
2020-11-01 14:14:01.404532 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 26 finished
----------------------------------  ----------------
replay_buffer/size                   28000
trainer/num train calls              27000
trainer/QF1 Loss                         9.10384
trainer/QF2 Loss                         9.49247
trainer/Policy Loss                     82.6727
trainer/Q1 Predictions Mean            -82.4381
trainer/Q1 Predictions Std              22.3169
trainer/Q1 Predictions Max             -22.693
trainer/Q1 Predictions Min            -119.646
trainer/Q2 Predictions Mean            -82.2696
trainer/Q2 Predictions Std              22.2421
trainer/Q2 Predictions Max             -23.9266
trainer/Q2 Predictions Min            -118.868
trainer/Q Targets Mean                 -82.5457
trainer/Q Targets Std                   22.1588
trainer/Q Targets Max                  -23.0406
trainer/Q Targets Min                 -117.928
trainer/Log Pis Mean                     1.71337
trainer/Log Pis Std                      2.4275
trainer/Log Pis Max                     10.9109
trainer/Log Pis Min                     -6.57211
trainer/policy/mean Mean                -0.317782
trainer/policy/mean Std                  0.761443
trainer/policy/mean Max                  0.998444
trainer/policy/mean Min                 -0.998416
trainer/policy/normal/std Mean           0.675576
trainer/policy/normal/std Std            0.108189
trainer/policy/normal/std Max            1.0043
trainer/policy/normal/std Min            0.425325
trainer/policy/normal/log_std Mean      -0.405039
trainer/policy/normal/log_std Std        0.160822
trainer/policy/normal/log_std Max        0.00428852
trainer/policy/normal/log_std Min       -0.854901
trainer/Alpha                            0.0421923
trainer/Alpha Loss                      -0.907347
exploration/num steps total          28000
exploration/num paths total            140
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.10622
exploration/Rewards Std                  0.110788
exploration/Rewards Max                 -0.893979
exploration/Rewards Min                 -1.53403
exploration/Returns Mean              -221.244
exploration/Returns Std                 12.4781
exploration/Returns Max               -205.784
exploration/Returns Min               -243.637
exploration/Actions Mean                -0.168682
exploration/Actions Std                  0.713313
exploration/Actions Max                  0.999892
exploration/Actions Min                 -0.999406
exploration/Num Paths                    5
exploration/Average Returns           -221.244
evaluation/num steps total          130248
evaluation/num paths total             648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.999303
evaluation/Rewards Std                   0.17482
evaluation/Rewards Max                  -0.601517
evaluation/Rewards Min                  -1.52847
evaluation/Returns Mean               -200.86
evaluation/Returns Std                  26.2201
evaluation/Returns Max                -163.569
evaluation/Returns Min                -260.244
evaluation/Actions Mean                 -0.103492
evaluation/Actions Std                   0.671501
evaluation/Actions Max                   0.998348
evaluation/Actions Min                  -0.995374
evaluation/Num Paths                    24
evaluation/Average Returns            -200.86
time/data storing (s)                    0.0087878
time/evaluation sampling (s)           515.023
time/exploration sampling (s)          117.118
time/logging (s)                         0.0190898
time/sac training (s)                    9.34167
time/saving (s)                          0.0340201
time/training (s)                        0.000117361
time/epoch (s)                         641.545
time/total (s)                       18105.3
Epoch                                   26
----------------------------------  ----------------
2020-11-01 14:25:18.975444 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 27 finished
----------------------------------  ----------------
replay_buffer/size                   29000
trainer/num train calls              28000
trainer/QF1 Loss                        36.0142
trainer/QF2 Loss                        38.8471
trainer/Policy Loss                     83.6087
trainer/Q1 Predictions Mean            -83.1221
trainer/Q1 Predictions Std              22.2252
trainer/Q1 Predictions Max             -23.9206
trainer/Q1 Predictions Min            -121.999
trainer/Q2 Predictions Mean            -83.1306
trainer/Q2 Predictions Std              22.4067
trainer/Q2 Predictions Max             -21.3124
trainer/Q2 Predictions Min            -122.288
trainer/Q Targets Mean                 -82.8347
trainer/Q Targets Std                   22.7687
trainer/Q Targets Max                   -1.02291
trainer/Q Targets Min                 -121.4
trainer/Log Pis Mean                     2.00587
trainer/Log Pis Std                      2.31506
trainer/Log Pis Max                      9.17483
trainer/Log Pis Min                     -4.43738
trainer/policy/mean Mean                -0.28449
trainer/policy/mean Std                  0.795472
trainer/policy/mean Max                  0.996201
trainer/policy/mean Min                 -0.995852
trainer/policy/normal/std Mean           0.650742
trainer/policy/normal/std Std            0.0946861
trainer/policy/normal/std Max            0.974609
trainer/policy/normal/std Min            0.428797
trainer/policy/normal/log_std Mean      -0.440104
trainer/policy/normal/log_std Std        0.144523
trainer/policy/normal/log_std Max       -0.0257191
trainer/policy/normal/log_std Min       -0.846772
trainer/Alpha                            0.042752
trainer/Alpha Loss                       0.0184972
exploration/num steps total          29000
exploration/num paths total            145
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00757
exploration/Rewards Std                  0.19617
exploration/Rewards Max                 -0.677984
exploration/Rewards Min                 -1.52947
exploration/Returns Mean              -201.513
exploration/Returns Std                 26.4681
exploration/Returns Max               -173.211
exploration/Returns Min               -243.489
exploration/Actions Mean                -0.442805
exploration/Actions Std                  0.624132
exploration/Actions Max                  0.998666
exploration/Actions Min                 -0.999664
exploration/Num Paths                    5
exploration/Average Returns           -201.513
evaluation/num steps total          135072
evaluation/num paths total             672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.01302
evaluation/Rewards Std                   0.183358
evaluation/Rewards Max                  -0.577363
evaluation/Rewards Min                  -1.76668
evaluation/Returns Mean               -203.617
evaluation/Returns Std                  23.0725
evaluation/Returns Max                -161.288
evaluation/Returns Min                -240.81
evaluation/Actions Mean                 -0.328577
evaluation/Actions Std                   0.663611
evaluation/Actions Max                   0.997804
evaluation/Actions Min                  -0.998838
evaluation/Num Paths                    24
evaluation/Average Returns            -203.617
time/data storing (s)                    0.0356136
time/evaluation sampling (s)           529.666
time/exploration sampling (s)          130.975
time/logging (s)                         0.0494896
time/sac training (s)                   10.3146
time/saving (s)                          0.0982127
time/training (s)                        0.000139134
time/epoch (s)                         671.139
time/total (s)                       18777.2
Epoch                                   27
----------------------------------  ----------------
2020-11-01 14:35:56.045717 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 28 finished
----------------------------------  ----------------
replay_buffer/size                   30000
trainer/num train calls              29000
trainer/QF1 Loss                        37.1656
trainer/QF2 Loss                        38.1699
trainer/Policy Loss                     84.251
trainer/Q1 Predictions Mean            -84.0009
trainer/Q1 Predictions Std              23.71
trainer/Q1 Predictions Max             -25.1925
trainer/Q1 Predictions Min            -128.378
trainer/Q2 Predictions Mean            -84.0635
trainer/Q2 Predictions Std              23.8323
trainer/Q2 Predictions Max             -16.4062
trainer/Q2 Predictions Min            -131.376
trainer/Q Targets Mean                 -83.1391
trainer/Q Targets Std                   24.7752
trainer/Q Targets Max                   -1.04712
trainer/Q Targets Min                 -124.534
trainer/Log Pis Mean                     1.79461
trainer/Log Pis Std                      2.22871
trainer/Log Pis Max                      8.18478
trainer/Log Pis Min                     -3.3366
trainer/policy/mean Mean                -0.077959
trainer/policy/mean Std                  0.828511
trainer/policy/mean Max                  0.99738
trainer/policy/mean Min                 -0.988794
trainer/policy/normal/std Mean           0.671825
trainer/policy/normal/std Std            0.111183
trainer/policy/normal/std Max            1.09004
trainer/policy/normal/std Min            0.437708
trainer/policy/normal/log_std Mean      -0.411109
trainer/policy/normal/log_std Std        0.162857
trainer/policy/normal/log_std Max        0.0862121
trainer/policy/normal/log_std Min       -0.826202
trainer/Alpha                            0.0426062
trainer/Alpha Loss                      -0.648149
exploration/num steps total          30000
exploration/num paths total            150
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.991433
exploration/Rewards Std                  0.232777
exploration/Rewards Max                 -0.585767
exploration/Rewards Min                 -1.54142
exploration/Returns Mean              -198.287
exploration/Returns Std                 38.3118
exploration/Returns Max               -165.849
exploration/Returns Min               -264.407
exploration/Actions Mean                -0.0274826
exploration/Actions Std                  0.78262
exploration/Actions Max                  0.999964
exploration/Actions Min                 -0.999406
exploration/Num Paths                    5
exploration/Average Returns           -198.287
evaluation/num steps total          139896
evaluation/num paths total             696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.02675
evaluation/Rewards Std                   0.189573
evaluation/Rewards Max                  -0.663508
evaluation/Rewards Min                  -1.73811
evaluation/Returns Mean               -206.377
evaluation/Returns Std                  26.9232
evaluation/Returns Max                -166.197
evaluation/Returns Min                -277.987
evaluation/Actions Mean                 -0.152825
evaluation/Actions Std                   0.678374
evaluation/Actions Max                   0.999899
evaluation/Actions Min                  -0.995725
evaluation/Num Paths                    24
evaluation/Average Returns            -206.377
time/data storing (s)                    0.0113278
time/evaluation sampling (s)           506.811
time/exploration sampling (s)          118.979
time/logging (s)                         0.0239621
time/sac training (s)                   10.4284
time/saving (s)                          0.0361617
time/training (s)                        0.000147347
time/epoch (s)                         636.29
time/total (s)                       19414.2
Epoch                                   28
----------------------------------  ----------------
2020-11-01 14:48:19.411249 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 29 finished
----------------------------------  ----------------
replay_buffer/size                   31000
trainer/num train calls              30000
trainer/QF1 Loss                        36.9356
trainer/QF2 Loss                        38.2538
trainer/Policy Loss                     85.4093
trainer/Q1 Predictions Mean            -84.9261
trainer/Q1 Predictions Std              25.0045
trainer/Q1 Predictions Max             -23.0937
trainer/Q1 Predictions Min            -131.635
trainer/Q2 Predictions Mean            -84.9974
trainer/Q2 Predictions Std              24.7463
trainer/Q2 Predictions Max             -22.5264
trainer/Q2 Predictions Min            -132.25
trainer/Q Targets Mean                 -84.8523
trainer/Q Targets Std                   26.2389
trainer/Q Targets Max                   -0.585767
trainer/Q Targets Min                 -132.877
trainer/Log Pis Mean                     2.11191
trainer/Log Pis Std                      2.32965
trainer/Log Pis Max                      8.29383
trainer/Log Pis Min                     -3.43195
trainer/policy/mean Mean                -0.0828983
trainer/policy/mean Std                  0.832796
trainer/policy/mean Max                  0.998266
trainer/policy/mean Min                 -0.994287
trainer/policy/normal/std Mean           0.652581
trainer/policy/normal/std Std            0.103388
trainer/policy/normal/std Max            1.03077
trainer/policy/normal/std Min            0.395802
trainer/policy/normal/log_std Mean      -0.439284
trainer/policy/normal/log_std Std        0.15819
trainer/policy/normal/log_std Max        0.030308
trainer/policy/normal/log_std Min       -0.926841
trainer/Alpha                            0.0447876
trainer/Alpha Loss                       0.347577
exploration/num steps total          31000
exploration/num paths total            155
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.99349
exploration/Rewards Std                  0.140475
exploration/Rewards Max                 -0.659783
exploration/Rewards Min                 -1.54156
exploration/Returns Mean              -198.698
exploration/Returns Std                 15.0807
exploration/Returns Max               -172.143
exploration/Returns Min               -218.395
exploration/Actions Mean                -0.00696783
exploration/Actions Std                  0.740504
exploration/Actions Max                  0.998712
exploration/Actions Min                 -0.998964
exploration/Num Paths                    5
exploration/Average Returns           -198.698
evaluation/num steps total          144720
evaluation/num paths total             720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.05853
evaluation/Rewards Std                   0.186586
evaluation/Rewards Max                  -0.68049
evaluation/Rewards Min                  -1.77176
evaluation/Returns Mean               -212.765
evaluation/Returns Std                  27.1079
evaluation/Returns Max                -170.369
evaluation/Returns Min                -267.467
evaluation/Actions Mean                 -0.0574527
evaluation/Actions Std                   0.690366
evaluation/Actions Max                   0.999375
evaluation/Actions Min                  -0.99549
evaluation/Num Paths                    24
evaluation/Average Returns            -212.765
time/data storing (s)                    0.0263948
time/evaluation sampling (s)           570.268
time/exploration sampling (s)          155.114
time/logging (s)                         0.112375
time/sac training (s)                   16.8509
time/saving (s)                          0.0628162
time/training (s)                        0.000150892
time/epoch (s)                         742.435
time/total (s)                       20157.6
Epoch                                   29
----------------------------------  ----------------
2020-11-01 15:01:21.782641 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 30 finished
----------------------------------  ----------------
replay_buffer/size                   32000
trainer/num train calls              31000
trainer/QF1 Loss                        11.7246
trainer/QF2 Loss                        12.5488
trainer/Policy Loss                     89.4076
trainer/Q1 Predictions Mean            -88.8522
trainer/Q1 Predictions Std              25.9489
trainer/Q1 Predictions Max               4.4114
trainer/Q1 Predictions Min            -129.327
trainer/Q2 Predictions Mean            -89.2308
trainer/Q2 Predictions Std              25.9612
trainer/Q2 Predictions Max               3.49151
trainer/Q2 Predictions Min            -130.758
trainer/Q Targets Mean                 -88.8642
trainer/Q Targets Std                   25.7439
trainer/Q Targets Max                    2.16626
trainer/Q Targets Min                 -129.853
trainer/Log Pis Mean                     1.64205
trainer/Log Pis Std                      2.41213
trainer/Log Pis Max                     10.7796
trainer/Log Pis Min                     -4.80017
trainer/policy/mean Mean                -0.0904291
trainer/policy/mean Std                  0.814353
trainer/policy/mean Max                  0.999258
trainer/policy/mean Min                 -0.991571
trainer/policy/normal/std Mean           0.697187
trainer/policy/normal/std Std            0.0951704
trainer/policy/normal/std Max            1.12609
trainer/policy/normal/std Min            0.429339
trainer/policy/normal/log_std Mean      -0.369854
trainer/policy/normal/log_std Std        0.135084
trainer/policy/normal/log_std Max        0.118755
trainer/policy/normal/log_std Min       -0.845509
trainer/Alpha                            0.043785
trainer/Alpha Loss                      -1.11985
exploration/num steps total          32000
exploration/num paths total            160
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.999414
exploration/Rewards Std                  0.18889
exploration/Rewards Max                 -0.660877
exploration/Rewards Min                 -1.51621
exploration/Returns Mean              -199.883
exploration/Returns Std                 19.2066
exploration/Returns Max               -170.56
exploration/Returns Min               -227.763
exploration/Actions Mean                -0.327268
exploration/Actions Std                  0.654604
exploration/Actions Max                  0.999008
exploration/Actions Min                 -0.997261
exploration/Num Paths                    5
exploration/Average Returns           -199.883
evaluation/num steps total          149544
evaluation/num paths total             744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.06517
evaluation/Rewards Std                   0.185937
evaluation/Rewards Max                  -0.649162
evaluation/Rewards Min                  -1.79017
evaluation/Returns Mean               -214.099
evaluation/Returns Std                  28.9205
evaluation/Returns Max                -163.467
evaluation/Returns Min                -294.768
evaluation/Actions Mean                 -0.0629084
evaluation/Actions Std                   0.683194
evaluation/Actions Max                   0.997634
evaluation/Actions Min                  -0.995037
evaluation/Num Paths                    24
evaluation/Average Returns            -214.099
time/data storing (s)                    0.00904869
time/evaluation sampling (s)           634.084
time/exploration sampling (s)          137.613
time/logging (s)                         0.0535583
time/sac training (s)                    9.5938
time/saving (s)                          0.0665245
time/training (s)                        0.000159185
time/epoch (s)                         781.421
time/total (s)                       20939.9
Epoch                                   30
----------------------------------  ----------------
2020-11-01 15:54:21.228659 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 31 finished
----------------------------------  ----------------
replay_buffer/size                   33000
trainer/num train calls              32000
trainer/QF1 Loss                         9.54872
trainer/QF2 Loss                        11.2609
trainer/Policy Loss                     91.1327
trainer/Q1 Predictions Mean            -90.754
trainer/Q1 Predictions Std              23.9751
trainer/Q1 Predictions Max             -13.9498
trainer/Q1 Predictions Min            -131.693
trainer/Q2 Predictions Mean            -90.8153
trainer/Q2 Predictions Std              23.9666
trainer/Q2 Predictions Max             -16.1957
trainer/Q2 Predictions Min            -132.145
trainer/Q Targets Mean                 -91.2578
trainer/Q Targets Std                   23.8581
trainer/Q Targets Max                  -19.7209
trainer/Q Targets Min                 -132.877
trainer/Log Pis Mean                     2.67149
trainer/Log Pis Std                      2.41765
trainer/Log Pis Max                      9.75104
trainer/Log Pis Min                     -4.26986
trainer/policy/mean Mean                -0.362756
trainer/policy/mean Std                  0.77054
trainer/policy/mean Max                  0.99791
trainer/policy/mean Min                 -0.998273
trainer/policy/normal/std Mean           0.641586
trainer/policy/normal/std Std            0.0946811
trainer/policy/normal/std Max            0.992167
trainer/policy/normal/std Min            0.392521
trainer/policy/normal/log_std Mean      -0.454898
trainer/policy/normal/log_std Std        0.149911
trainer/policy/normal/log_std Max       -0.00786384
trainer/policy/normal/log_std Min       -0.935164
trainer/Alpha                            0.0433317
trainer/Alpha Loss                       2.10771
exploration/num steps total          33000
exploration/num paths total            165
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.939448
exploration/Rewards Std                  0.160974
exploration/Rewards Max                 -0.646689
exploration/Rewards Min                 -1.53373
exploration/Returns Mean              -187.89
exploration/Returns Std                 19.108
exploration/Returns Max               -165.092
exploration/Returns Min               -222.164
exploration/Actions Mean                -0.0788523
exploration/Actions Std                  0.714492
exploration/Actions Max                  0.999742
exploration/Actions Min                 -0.99898
exploration/Num Paths                    5
exploration/Average Returns           -187.89
evaluation/num steps total          154368
evaluation/num paths total             768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.0107
evaluation/Rewards Std                   0.169747
evaluation/Rewards Max                  -0.631721
evaluation/Rewards Min                  -1.66743
evaluation/Returns Mean               -203.151
evaluation/Returns Std                  22.2882
evaluation/Returns Max                -170.524
evaluation/Returns Min                -248.199
evaluation/Actions Mean                 -0.195206
evaluation/Actions Std                   0.697675
evaluation/Actions Max                   0.999719
evaluation/Actions Min                  -0.998339
evaluation/Num Paths                    24
evaluation/Average Returns            -203.151
time/data storing (s)                    0.0258053
time/evaluation sampling (s)           651.366
time/exploration sampling (s)          132.19
time/logging (s)                         0.0754385
time/sac training (s)                   12.0853
time/saving (s)                          0.151603
time/training (s)                        0.000119853
time/epoch (s)                         795.894
time/total (s)                       21736.6
Epoch                                   31
----------------------------------  ----------------
2020-11-01 16:07:01.703405 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 32 finished
----------------------------------  ----------------
replay_buffer/size                   34000
trainer/num train calls              33000
trainer/QF1 Loss                        47.4505
trainer/QF2 Loss                        47.2423
trainer/Policy Loss                     91.3115
trainer/Q1 Predictions Mean            -91.0367
trainer/Q1 Predictions Std              26.7543
trainer/Q1 Predictions Max              10.7904
trainer/Q1 Predictions Min            -138.68
trainer/Q2 Predictions Mean            -90.8469
trainer/Q2 Predictions Std              26.7843
trainer/Q2 Predictions Max               9.02783
trainer/Q2 Predictions Min            -138.239
trainer/Q Targets Mean                 -90.9881
trainer/Q Targets Std                   27.4135
trainer/Q Targets Max                    6.67009
trainer/Q Targets Min                 -139.678
trainer/Log Pis Mean                     1.72425
trainer/Log Pis Std                      2.47319
trainer/Log Pis Max                      8.71399
trainer/Log Pis Min                     -6.86582
trainer/policy/mean Mean                -0.0365181
trainer/policy/mean Std                  0.827542
trainer/policy/mean Max                  0.999538
trainer/policy/mean Min                 -0.995084
trainer/policy/normal/std Mean           0.651812
trainer/policy/normal/std Std            0.0928107
trainer/policy/normal/std Max            1.01181
trainer/policy/normal/std Min            0.397166
trainer/policy/normal/log_std Mean      -0.437906
trainer/policy/normal/log_std Std        0.140408
trainer/policy/normal/log_std Max        0.0117442
trainer/policy/normal/log_std Min       -0.923401
trainer/Alpha                            0.0435973
trainer/Alpha Loss                      -0.863846
exploration/num steps total          34000
exploration/num paths total            170
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.1106
exploration/Rewards Std                  0.172975
exploration/Rewards Max                 -0.872728
exploration/Rewards Min                 -1.65213
exploration/Returns Mean              -222.12
exploration/Returns Std                 21.6585
exploration/Returns Max               -201.66
exploration/Returns Min               -261.389
exploration/Actions Mean                 0.0270841
exploration/Actions Std                  0.750769
exploration/Actions Max                  0.99987
exploration/Actions Min                 -0.999239
exploration/Num Paths                    5
exploration/Average Returns           -222.12
evaluation/num steps total          159192
evaluation/num paths total             792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.08081
evaluation/Rewards Std                   0.187207
evaluation/Rewards Max                  -0.656455
evaluation/Rewards Min                  -1.68427
evaluation/Returns Mean               -217.243
evaluation/Returns Std                  27.9087
evaluation/Returns Max                -173.685
evaluation/Returns Min                -285.016
evaluation/Actions Mean                 -0.0602829
evaluation/Actions Std                   0.707137
evaluation/Actions Max                   0.998821
evaluation/Actions Min                  -0.998061
evaluation/Num Paths                    24
evaluation/Average Returns            -217.243
time/data storing (s)                    0.0118614
time/evaluation sampling (s)           625.223
time/exploration sampling (s)          122.938
time/logging (s)                         0.079345
time/sac training (s)                   11.169
time/saving (s)                          0.069563
time/training (s)                        0.000145814
time/epoch (s)                         759.491
time/total (s)                       22497.1
Epoch                                   32
----------------------------------  ----------------
2020-11-01 16:19:41.647179 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 33 finished
----------------------------------  ---------------
replay_buffer/size                   35000
trainer/num train calls              34000
trainer/QF1 Loss                        14.6925
trainer/QF2 Loss                        14.2585
trainer/Policy Loss                     93.9444
trainer/Q1 Predictions Mean            -93.5831
trainer/Q1 Predictions Std              25.666
trainer/Q1 Predictions Max             -13.3272
trainer/Q1 Predictions Min            -141.593
trainer/Q2 Predictions Mean            -93.4948
trainer/Q2 Predictions Std              25.6146
trainer/Q2 Predictions Max             -11.1474
trainer/Q2 Predictions Min            -141.432
trainer/Q Targets Mean                 -93.0923
trainer/Q Targets Std                   25.3324
trainer/Q Targets Max                  -12.4988
trainer/Q Targets Min                 -139.682
trainer/Log Pis Mean                     2.07661
trainer/Log Pis Std                      2.18148
trainer/Log Pis Max                      8.55144
trainer/Log Pis Min                     -5.03324
trainer/policy/mean Mean                -0.30901
trainer/policy/mean Std                  0.776301
trainer/policy/mean Max                  0.99382
trainer/policy/mean Min                 -0.995014
trainer/policy/normal/std Mean           0.64568
trainer/policy/normal/std Std            0.0982414
trainer/policy/normal/std Max            0.885225
trainer/policy/normal/std Min            0.363993
trainer/policy/normal/log_std Mean      -0.449238
trainer/policy/normal/log_std Std        0.154517
trainer/policy/normal/log_std Max       -0.121914
trainer/policy/normal/log_std Min       -1.01062
trainer/Alpha                            0.0442402
trainer/Alpha Loss                       0.238866
exploration/num steps total          35000
exploration/num paths total            175
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.945791
exploration/Rewards Std                  0.155325
exploration/Rewards Max                 -0.706505
exploration/Rewards Min                 -1.54998
exploration/Returns Mean              -189.158
exploration/Returns Std                 19.3772
exploration/Returns Max               -169.912
exploration/Returns Min               -225.642
exploration/Actions Mean                -0.267679
exploration/Actions Std                  0.675098
exploration/Actions Max                  0.999404
exploration/Actions Min                 -0.999312
exploration/Num Paths                    5
exploration/Average Returns           -189.158
evaluation/num steps total          164016
evaluation/num paths total             816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.04749
evaluation/Rewards Std                   0.211163
evaluation/Rewards Max                  -0.588548
evaluation/Rewards Min                  -1.74921
evaluation/Returns Mean               -210.545
evaluation/Returns Std                  32.5388
evaluation/Returns Max                -167.72
evaluation/Returns Min                -284.622
evaluation/Actions Mean                 -0.230606
evaluation/Actions Std                   0.685945
evaluation/Actions Max                   0.999474
evaluation/Actions Min                  -0.999454
evaluation/Num Paths                    24
evaluation/Average Returns            -210.545
time/data storing (s)                    0.0174368
time/evaluation sampling (s)           602.643
time/exploration sampling (s)          146.926
time/logging (s)                         0.0589143
time/sac training (s)                    9.36909
time/saving (s)                          0.0542206
time/training (s)                        0.00011331
time/epoch (s)                         759.069
time/total (s)                       23257
Epoch                                   33
----------------------------------  ---------------
2020-11-01 16:31:38.490277 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 34 finished
----------------------------------  ----------------
replay_buffer/size                   36000
trainer/num train calls              35000
trainer/QF1 Loss                        18.3513
trainer/QF2 Loss                        19.3617
trainer/Policy Loss                     96.5363
trainer/Q1 Predictions Mean            -96.0049
trainer/Q1 Predictions Std              24.905
trainer/Q1 Predictions Max               2.39228
trainer/Q1 Predictions Min            -143.672
trainer/Q2 Predictions Mean            -96.0579
trainer/Q2 Predictions Std              25.0468
trainer/Q2 Predictions Max               2.02783
trainer/Q2 Predictions Min            -141.557
trainer/Q Targets Mean                 -96.1538
trainer/Q Targets Std                   25.1688
trainer/Q Targets Max                   -0.639906
trainer/Q Targets Min                 -142.481
trainer/Log Pis Mean                     2.20549
trainer/Log Pis Std                      2.16459
trainer/Log Pis Max                      9.32142
trainer/Log Pis Min                     -3.06523
trainer/policy/mean Mean                -0.172126
trainer/policy/mean Std                  0.831892
trainer/policy/mean Max                  0.996076
trainer/policy/mean Min                 -0.995881
trainer/policy/normal/std Mean           0.624988
trainer/policy/normal/std Std            0.0931084
trainer/policy/normal/std Max            0.949415
trainer/policy/normal/std Min            0.346669
trainer/policy/normal/log_std Mean      -0.481297
trainer/policy/normal/log_std Std        0.15115
trainer/policy/normal/log_std Max       -0.0519092
trainer/policy/normal/log_std Min       -1.05938
trainer/Alpha                            0.0449155
trainer/Alpha Loss                       0.637632
exploration/num steps total          36000
exploration/num paths total            180
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.04169
exploration/Rewards Std                  0.144546
exploration/Rewards Max                 -0.760915
exploration/Rewards Min                 -1.53297
exploration/Returns Mean              -208.338
exploration/Returns Std                 14.3934
exploration/Returns Max               -185.053
exploration/Returns Min               -224.928
exploration/Actions Mean                -0.25784
exploration/Actions Std                  0.765372
exploration/Actions Max                  0.998399
exploration/Actions Min                 -0.999628
exploration/Num Paths                    5
exploration/Average Returns           -208.338
evaluation/num steps total          168840
evaluation/num paths total             840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.03616
evaluation/Rewards Std                   0.201611
evaluation/Rewards Max                  -0.555886
evaluation/Rewards Min                  -1.72533
evaluation/Returns Mean               -208.268
evaluation/Returns Std                  32.4379
evaluation/Returns Max                -160.396
evaluation/Returns Min                -281.918
evaluation/Actions Mean                 -0.0565655
evaluation/Actions Std                   0.728907
evaluation/Actions Max                   0.999497
evaluation/Actions Min                  -0.99882
evaluation/Num Paths                    24
evaluation/Average Returns            -208.268
time/data storing (s)                    0.0129231
time/evaluation sampling (s)           575.92
time/exploration sampling (s)          130.957
time/logging (s)                         0.0513292
time/sac training (s)                    8.9761
time/saving (s)                          0.0544338
time/training (s)                        0.000142472
time/epoch (s)                         715.973
time/total (s)                       23973.8
Epoch                                   34
----------------------------------  ----------------
2020-11-01 16:44:40.783388 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 35 finished
----------------------------------  ----------------
replay_buffer/size                   37000
trainer/num train calls              36000
trainer/QF1 Loss                        45.8644
trainer/QF2 Loss                        41.0738
trainer/Policy Loss                    102.041
trainer/Q1 Predictions Mean           -101.519
trainer/Q1 Predictions Std              26.0801
trainer/Q1 Predictions Max             -21.5927
trainer/Q1 Predictions Min            -145.523
trainer/Q2 Predictions Mean           -101.501
trainer/Q2 Predictions Std              26.0352
trainer/Q2 Predictions Max             -20.1321
trainer/Q2 Predictions Min            -145.462
trainer/Q Targets Mean                -101.221
trainer/Q Targets Std                   27.2057
trainer/Q Targets Max                   -0.70018
trainer/Q Targets Min                 -143.935
trainer/Log Pis Mean                     1.68029
trainer/Log Pis Std                      2.08061
trainer/Log Pis Max                      8.59849
trainer/Log Pis Min                     -3.39821
trainer/policy/mean Mean                -0.217014
trainer/policy/mean Std                  0.795073
trainer/policy/mean Max                  0.99629
trainer/policy/mean Min                 -0.994953
trainer/policy/normal/std Mean           0.663063
trainer/policy/normal/std Std            0.0996234
trainer/policy/normal/std Max            1.05909
trainer/policy/normal/std Min            0.335409
trainer/policy/normal/log_std Mean      -0.422459
trainer/policy/normal/log_std Std        0.153542
trainer/policy/normal/log_std Max        0.0574053
trainer/policy/normal/log_std Min       -1.09241
trainer/Alpha                            0.0465356
trainer/Alpha Loss                      -0.980707
exploration/num steps total          37000
exploration/num paths total            185
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01622
exploration/Rewards Std                  0.161624
exploration/Rewards Max                 -0.752145
exploration/Rewards Min                 -1.64283
exploration/Returns Mean              -203.244
exploration/Returns Std                 14.9032
exploration/Returns Max               -178.475
exploration/Returns Min               -223.396
exploration/Actions Mean                -0.061408
exploration/Actions Std                  0.732002
exploration/Actions Max                  0.998892
exploration/Actions Min                 -0.99784
exploration/Num Paths                    5
exploration/Average Returns           -203.244
evaluation/num steps total          173664
evaluation/num paths total             864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.01239
evaluation/Rewards Std                   0.169947
evaluation/Rewards Max                  -0.578416
evaluation/Rewards Min                  -1.617
evaluation/Returns Mean               -203.489
evaluation/Returns Std                  22.1082
evaluation/Returns Max                -163.197
evaluation/Returns Min                -260.786
evaluation/Actions Mean                 -0.0215255
evaluation/Actions Std                   0.684764
evaluation/Actions Max                   0.998554
evaluation/Actions Min                  -0.99482
evaluation/Num Paths                    24
evaluation/Average Returns            -203.489
time/data storing (s)                    0.034964
time/evaluation sampling (s)           636.249
time/exploration sampling (s)          134.662
time/logging (s)                         0.0783702
time/sac training (s)                   10.2205
time/saving (s)                          0.145013
time/training (s)                        0.000119639
time/epoch (s)                         781.39
time/total (s)                       24756
Epoch                                   35
----------------------------------  ----------------
2020-11-01 16:56:10.095502 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 36 finished
----------------------------------  ----------------
replay_buffer/size                   38000
trainer/num train calls              37000
trainer/QF1 Loss                        20.4261
trainer/QF2 Loss                        23.0119
trainer/Policy Loss                    100.413
trainer/Q1 Predictions Mean            -99.7791
trainer/Q1 Predictions Std              26.1886
trainer/Q1 Predictions Max             -28.5202
trainer/Q1 Predictions Min            -143.577
trainer/Q2 Predictions Mean           -100.107
trainer/Q2 Predictions Std              26.4084
trainer/Q2 Predictions Max             -32.0177
trainer/Q2 Predictions Min            -144.587
trainer/Q Targets Mean                -100.91
trainer/Q Targets Std                   26.411
trainer/Q Targets Max                   -0.967688
trainer/Q Targets Min                 -147.877
trainer/Log Pis Mean                     1.94465
trainer/Log Pis Std                      2.25399
trainer/Log Pis Max                      8.7453
trainer/Log Pis Min                     -4.15411
trainer/policy/mean Mean                -0.218306
trainer/policy/mean Std                  0.803258
trainer/policy/mean Max                  0.998559
trainer/policy/mean Min                 -0.995702
trainer/policy/normal/std Mean           0.650052
trainer/policy/normal/std Std            0.101856
trainer/policy/normal/std Max            1.04182
trainer/policy/normal/std Min            0.398945
trainer/policy/normal/log_std Mean      -0.443193
trainer/policy/normal/log_std Std        0.159168
trainer/policy/normal/log_std Max        0.0409656
trainer/policy/normal/log_std Min       -0.918931
trainer/Alpha                            0.0461389
trainer/Alpha Loss                      -0.170247
exploration/num steps total          38000
exploration/num paths total            190
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.12755
exploration/Rewards Std                  0.189007
exploration/Rewards Max                 -0.67314
exploration/Rewards Min                 -1.63364
exploration/Returns Mean              -225.511
exploration/Returns Std                 27.7964
exploration/Returns Max               -187.595
exploration/Returns Min               -266.814
exploration/Actions Mean                 0.029779
exploration/Actions Std                  0.729903
exploration/Actions Max                  0.999454
exploration/Actions Min                 -0.99815
exploration/Num Paths                    5
exploration/Average Returns           -225.511
evaluation/num steps total          178488
evaluation/num paths total             888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.04192
evaluation/Rewards Std                   0.183637
evaluation/Rewards Max                  -0.682958
evaluation/Rewards Min                  -1.69224
evaluation/Returns Mean               -209.426
evaluation/Returns Std                  28.1625
evaluation/Returns Max                -166.871
evaluation/Returns Min                -272.464
evaluation/Actions Mean                 -0.034519
evaluation/Actions Std                   0.717458
evaluation/Actions Max                   0.993027
evaluation/Actions Min                  -0.995387
evaluation/Num Paths                    24
evaluation/Average Returns            -209.426
time/data storing (s)                    0.0147438
time/evaluation sampling (s)           535.082
time/exploration sampling (s)          142.595
time/logging (s)                         0.0635646
time/sac training (s)                   10.5719
time/saving (s)                          0.0522553
time/training (s)                        0.000119053
time/epoch (s)                         688.379
time/total (s)                       25445.3
Epoch                                   36
----------------------------------  ----------------
2020-11-01 17:06:32.541688 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 37 finished
----------------------------------  ---------------
replay_buffer/size                   39000
trainer/num train calls              38000
trainer/QF1 Loss                        18.5161
trainer/QF2 Loss                        16.1194
trainer/Policy Loss                    102.138
trainer/Q1 Predictions Mean           -101.651
trainer/Q1 Predictions Std              28.3064
trainer/Q1 Predictions Max             -23.0925
trainer/Q1 Predictions Min            -151.017
trainer/Q2 Predictions Mean           -101.687
trainer/Q2 Predictions Std              28.3743
trainer/Q2 Predictions Max             -19.8097
trainer/Q2 Predictions Min            -150.249
trainer/Q Targets Mean                -100.799
trainer/Q Targets Std                   27.9676
trainer/Q Targets Max                  -19.9279
trainer/Q Targets Min                 -150.166
trainer/Log Pis Mean                     2.25184
trainer/Log Pis Std                      2.33856
trainer/Log Pis Max                      8.88131
trainer/Log Pis Min                     -3.76846
trainer/policy/mean Mean                -0.236899
trainer/policy/mean Std                  0.804405
trainer/policy/mean Max                  0.994806
trainer/policy/mean Min                 -0.998216
trainer/policy/normal/std Mean           0.634118
trainer/policy/normal/std Std            0.104403
trainer/policy/normal/std Max            0.859472
trainer/policy/normal/std Min            0.311666
trainer/policy/normal/log_std Mean      -0.469631
trainer/policy/normal/log_std Std        0.17011
trainer/policy/normal/log_std Max       -0.151437
trainer/policy/normal/log_std Min       -1.16582
trainer/Alpha                            0.0450997
trainer/Alpha Loss                       0.780415
exploration/num steps total          39000
exploration/num paths total            195
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.0012
exploration/Rewards Std                  0.19468
exploration/Rewards Max                 -0.657655
exploration/Rewards Min                 -1.53113
exploration/Returns Mean              -200.24
exploration/Returns Std                 12.1459
exploration/Returns Max               -184.616
exploration/Returns Min               -215.984
exploration/Actions Mean                -0.183554
exploration/Actions Std                  0.756906
exploration/Actions Max                  0.994796
exploration/Actions Min                 -0.999827
exploration/Num Paths                    5
exploration/Average Returns           -200.24
evaluation/num steps total          183312
evaluation/num paths total             912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.945175
evaluation/Rewards Std                   0.160324
evaluation/Rewards Max                  -0.621365
evaluation/Rewards Min                  -1.56215
evaluation/Returns Mean               -189.98
evaluation/Returns Std                  14.7779
evaluation/Returns Max                -163.869
evaluation/Returns Min                -219.368
evaluation/Actions Mean                 -0.166322
evaluation/Actions Std                   0.716502
evaluation/Actions Max                   0.998302
evaluation/Actions Min                  -0.998176
evaluation/Num Paths                    24
evaluation/Average Returns            -189.98
time/data storing (s)                    0.0119344
time/evaluation sampling (s)           504.615
time/exploration sampling (s)          105.454
time/logging (s)                         0.0776845
time/sac training (s)                   11.3987
time/saving (s)                          0.0564086
time/training (s)                        0.00011201
time/epoch (s)                         621.614
time/total (s)                       26067.7
Epoch                                   37
----------------------------------  ---------------
2020-11-01 17:17:47.817444 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 38 finished
----------------------------------  ----------------
replay_buffer/size                   40000
trainer/num train calls              39000
trainer/QF1 Loss                        17.4456
trainer/QF2 Loss                        18.1009
trainer/Policy Loss                    103.066
trainer/Q1 Predictions Mean           -102.509
trainer/Q1 Predictions Std              28.9046
trainer/Q1 Predictions Max             -30.9039
trainer/Q1 Predictions Min            -150.566
trainer/Q2 Predictions Mean           -102.422
trainer/Q2 Predictions Std              29.1047
trainer/Q2 Predictions Max             -19.8594
trainer/Q2 Predictions Min            -150.08
trainer/Q Targets Mean                -103.169
trainer/Q Targets Std                   29.0676
trainer/Q Targets Max                  -28.7288
trainer/Q Targets Min                 -153.024
trainer/Log Pis Mean                     1.91515
trainer/Log Pis Std                      2.2008
trainer/Log Pis Max                      8.19514
trainer/Log Pis Min                     -7.43713
trainer/policy/mean Mean                -0.119676
trainer/policy/mean Std                  0.829416
trainer/policy/mean Max                  0.994677
trainer/policy/mean Min                 -0.99233
trainer/policy/normal/std Mean           0.641548
trainer/policy/normal/std Std            0.091685
trainer/policy/normal/std Max            1.04268
trainer/policy/normal/std Min            0.377066
trainer/policy/normal/log_std Mean      -0.453974
trainer/policy/normal/log_std Std        0.142098
trainer/policy/normal/log_std Max        0.0417988
trainer/policy/normal/log_std Min       -0.975336
trainer/Alpha                            0.0482434
trainer/Alpha Loss                      -0.257216
exploration/num steps total          40000
exploration/num paths total            200
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.989551
exploration/Rewards Std                  0.158131
exploration/Rewards Max                 -0.666672
exploration/Rewards Min                 -1.42906
exploration/Returns Mean              -197.91
exploration/Returns Std                 16.1751
exploration/Returns Max               -182.858
exploration/Returns Min               -229.351
exploration/Actions Mean                 0.139625
exploration/Actions Std                  0.724474
exploration/Actions Max                  0.999812
exploration/Actions Min                 -0.999029
exploration/Num Paths                    5
exploration/Average Returns           -197.91
evaluation/num steps total          188136
evaluation/num paths total             936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.0159
evaluation/Rewards Std                   0.184913
evaluation/Rewards Max                  -0.704746
evaluation/Rewards Min                  -1.63818
evaluation/Returns Mean               -204.195
evaluation/Returns Std                  25.453
evaluation/Returns Max                -168.63
evaluation/Returns Min                -269.154
evaluation/Actions Mean                 -0.0941482
evaluation/Actions Std                   0.691472
evaluation/Actions Max                   0.998009
evaluation/Actions Min                  -0.994438
evaluation/Num Paths                    24
evaluation/Average Returns            -204.195
time/data storing (s)                    0.0121369
time/evaluation sampling (s)           525.745
time/exploration sampling (s)          138.623
time/logging (s)                         0.0379923
time/sac training (s)                    9.83498
time/saving (s)                          0.10291
time/training (s)                        0.000120892
time/epoch (s)                         674.356
time/total (s)                       26743
Epoch                                   38
----------------------------------  ----------------
2020-11-01 17:29:19.857907 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 39 finished
----------------------------------  ----------------
replay_buffer/size                   41000
trainer/num train calls              40000
trainer/QF1 Loss                        17.5091
trainer/QF2 Loss                        18.3033
trainer/Policy Loss                    105.477
trainer/Q1 Predictions Mean           -104.73
trainer/Q1 Predictions Std              28.5526
trainer/Q1 Predictions Max             -30.4495
trainer/Q1 Predictions Min            -152.869
trainer/Q2 Predictions Mean           -105.054
trainer/Q2 Predictions Std              28.8058
trainer/Q2 Predictions Max             -18.9394
trainer/Q2 Predictions Min            -154.203
trainer/Q Targets Mean                -105.121
trainer/Q Targets Std                   28.4226
trainer/Q Targets Max                  -30.6522
trainer/Q Targets Min                 -153.88
trainer/Log Pis Mean                     2.48454
trainer/Log Pis Std                      2.49484
trainer/Log Pis Max                      8.35427
trainer/Log Pis Min                     -3.65037
trainer/policy/mean Mean                -0.402588
trainer/policy/mean Std                  0.763537
trainer/policy/mean Max                  0.997271
trainer/policy/mean Min                 -0.998286
trainer/policy/normal/std Mean           0.649495
trainer/policy/normal/std Std            0.0987835
trainer/policy/normal/std Max            0.998925
trainer/policy/normal/std Min            0.362639
trainer/policy/normal/log_std Mean      -0.443258
trainer/policy/normal/log_std Std        0.153758
trainer/policy/normal/log_std Max       -0.00107591
trainer/policy/normal/log_std Min       -1.01435
trainer/Alpha                            0.0472983
trainer/Alpha Loss                       1.47848
exploration/num steps total          41000
exploration/num paths total            205
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.948464
exploration/Rewards Std                  0.153899
exploration/Rewards Max                 -0.632381
exploration/Rewards Min                 -1.54497
exploration/Returns Mean              -189.693
exploration/Returns Std                 13.7351
exploration/Returns Max               -178.315
exploration/Returns Min               -215.976
exploration/Actions Mean                -0.204503
exploration/Actions Std                  0.703986
exploration/Actions Max                  0.999627
exploration/Actions Min                 -0.999505
exploration/Num Paths                    5
exploration/Average Returns           -189.693
evaluation/num steps total          192960
evaluation/num paths total             960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.04162
evaluation/Rewards Std                   0.181951
evaluation/Rewards Max                  -0.611737
evaluation/Rewards Min                  -1.60124
evaluation/Returns Mean               -209.366
evaluation/Returns Std                  24.7473
evaluation/Returns Max                -165.279
evaluation/Returns Min                -266.661
evaluation/Actions Mean                 -0.127001
evaluation/Actions Std                   0.653458
evaluation/Actions Max                   0.990938
evaluation/Actions Min                  -0.995495
evaluation/Num Paths                    24
evaluation/Average Returns            -209.366
time/data storing (s)                    0.010067
time/evaluation sampling (s)           552.585
time/exploration sampling (s)          128.144
time/logging (s)                         0.0538529
time/sac training (s)                   10.2831
time/saving (s)                          0.0494366
time/training (s)                        0.000118937
time/epoch (s)                         691.125
time/total (s)                       27435
Epoch                                   39
----------------------------------  ----------------
2020-11-01 17:41:44.553227 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 40 finished
----------------------------------  ----------------
replay_buffer/size                   42000
trainer/num train calls              41000
trainer/QF1 Loss                        78.9729
trainer/QF2 Loss                        80.299
trainer/Policy Loss                    104.758
trainer/Q1 Predictions Mean           -104.265
trainer/Q1 Predictions Std              29.7518
trainer/Q1 Predictions Max             -11.0583
trainer/Q1 Predictions Min            -158.389
trainer/Q2 Predictions Mean           -104.441
trainer/Q2 Predictions Std              29.9794
trainer/Q2 Predictions Max             -10.4301
trainer/Q2 Predictions Min            -160.059
trainer/Q Targets Mean                -103.529
trainer/Q Targets Std                   32.2445
trainer/Q Targets Max                   -0.683104
trainer/Q Targets Min                 -158.711
trainer/Log Pis Mean                     1.83592
trainer/Log Pis Std                      2.46487
trainer/Log Pis Max                      9.57845
trainer/Log Pis Min                     -5.50224
trainer/policy/mean Mean                -0.22941
trainer/policy/mean Std                  0.803892
trainer/policy/mean Max                  0.999142
trainer/policy/mean Min                 -0.996159
trainer/policy/normal/std Mean           0.658471
trainer/policy/normal/std Std            0.101518
trainer/policy/normal/std Max            0.974879
trainer/policy/normal/std Min            0.386815
trainer/policy/normal/log_std Mean      -0.429861
trainer/policy/normal/log_std Std        0.155844
trainer/policy/normal/log_std Max       -0.0254415
trainer/policy/normal/log_std Min       -0.949809
trainer/Alpha                            0.0468541
trainer/Alpha Loss                      -0.502188
exploration/num steps total          42000
exploration/num paths total            210
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.984897
exploration/Rewards Std                  0.139976
exploration/Rewards Max                 -0.64363
exploration/Rewards Min                 -1.38765
exploration/Returns Mean              -196.979
exploration/Returns Std                 16.9831
exploration/Returns Max               -165.559
exploration/Returns Min               -214.172
exploration/Actions Mean                -0.111944
exploration/Actions Std                  0.729882
exploration/Actions Max                  0.999802
exploration/Actions Min                 -0.999319
exploration/Num Paths                    5
exploration/Average Returns           -196.979
evaluation/num steps total          197784
evaluation/num paths total             984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.977423
evaluation/Rewards Std                   0.236033
evaluation/Rewards Max                  -0.565511
evaluation/Rewards Min                  -1.96809
evaluation/Returns Mean               -196.462
evaluation/Returns Std                  37.9286
evaluation/Returns Max                -141.055
evaluation/Returns Min                -321.755
evaluation/Actions Mean                 -0.194967
evaluation/Actions Std                   0.687149
evaluation/Actions Max                   0.99837
evaluation/Actions Min                  -0.995374
evaluation/Num Paths                    24
evaluation/Average Returns            -196.462
time/data storing (s)                    0.0155955
time/evaluation sampling (s)           598.116
time/exploration sampling (s)          136.008
time/logging (s)                         0.0617698
time/sac training (s)                    9.55323
time/saving (s)                          0.0545114
time/training (s)                        0.000142615
time/epoch (s)                         743.809
time/total (s)                       28179.7
Epoch                                   40
----------------------------------  ----------------
2020-11-01 17:51:38.597573 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 41 finished
----------------------------------  ----------------
replay_buffer/size                   43000
trainer/num train calls              42000
trainer/QF1 Loss                        56.3174
trainer/QF2 Loss                        64.3235
trainer/Policy Loss                    105.42
trainer/Q1 Predictions Mean           -104.323
trainer/Q1 Predictions Std              29.8007
trainer/Q1 Predictions Max             -16.9089
trainer/Q1 Predictions Min            -159.213
trainer/Q2 Predictions Mean           -105.167
trainer/Q2 Predictions Std              29.8115
trainer/Q2 Predictions Max             -17.6104
trainer/Q2 Predictions Min            -161.101
trainer/Q Targets Mean                -103.641
trainer/Q Targets Std                   30.2562
trainer/Q Targets Max                   -0.610125
trainer/Q Targets Min                 -159.838
trainer/Log Pis Mean                     1.99503
trainer/Log Pis Std                      2.28711
trainer/Log Pis Max                      8.44918
trainer/Log Pis Min                     -3.9773
trainer/policy/mean Mean                -0.119639
trainer/policy/mean Std                  0.831861
trainer/policy/mean Max                  0.997755
trainer/policy/mean Min                 -0.997189
trainer/policy/normal/std Mean           0.657552
trainer/policy/normal/std Std            0.0928888
trainer/policy/normal/std Max            1.08083
trainer/policy/normal/std Min            0.40914
trainer/policy/normal/log_std Mean      -0.429001
trainer/policy/normal/log_std Std        0.139349
trainer/policy/normal/log_std Max        0.0777273
trainer/policy/normal/log_std Min       -0.893699
trainer/Alpha                            0.0478075
trainer/Alpha Loss                      -0.0150965
exploration/num steps total          43000
exploration/num paths total            215
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.04005
exploration/Rewards Std                  0.184036
exploration/Rewards Max                 -0.747455
exploration/Rewards Min                 -1.51081
exploration/Returns Mean              -208.01
exploration/Returns Std                 22.7888
exploration/Returns Max               -186.708
exploration/Returns Min               -248.606
exploration/Actions Mean                -0.052177
exploration/Actions Std                  0.745962
exploration/Actions Max                  0.99954
exploration/Actions Min                 -0.999761
exploration/Num Paths                    5
exploration/Average Returns           -208.01
evaluation/num steps total          202608
evaluation/num paths total            1008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.992282
evaluation/Rewards Std                   0.206591
evaluation/Rewards Max                  -0.602231
evaluation/Rewards Min                  -1.71158
evaluation/Returns Mean               -199.449
evaluation/Returns Std                  25.7602
evaluation/Returns Max                -158.112
evaluation/Returns Min                -283.412
evaluation/Actions Mean                 -0.223989
evaluation/Actions Std                   0.671962
evaluation/Actions Max                   0.996695
evaluation/Actions Min                  -0.999668
evaluation/Num Paths                    24
evaluation/Average Returns            -199.449
time/data storing (s)                    0.00958735
time/evaluation sampling (s)           479.607
time/exploration sampling (s)          104.471
time/logging (s)                         0.0223926
time/sac training (s)                    9.17509
time/saving (s)                          0.0295191
time/training (s)                        0.000140261
time/epoch (s)                         593.315
time/total (s)                       28773.6
Epoch                                   41
----------------------------------  ----------------
2020-11-01 18:02:33.949151 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 42 finished
----------------------------------  ----------------
replay_buffer/size                   44000
trainer/num train calls              43000
trainer/QF1 Loss                        20.5907
trainer/QF2 Loss                        22.8114
trainer/Policy Loss                    107.401
trainer/Q1 Predictions Mean           -107.116
trainer/Q1 Predictions Std              29.7896
trainer/Q1 Predictions Max             -19.672
trainer/Q1 Predictions Min            -159.695
trainer/Q2 Predictions Mean           -106.604
trainer/Q2 Predictions Std              29.6782
trainer/Q2 Predictions Max             -19.9651
trainer/Q2 Predictions Min            -159.412
trainer/Q Targets Mean                -107.848
trainer/Q Targets Std                   29.9271
trainer/Q Targets Max                  -24.5069
trainer/Q Targets Min                 -162.184
trainer/Log Pis Mean                     1.72412
trainer/Log Pis Std                      2.17457
trainer/Log Pis Max                      8.35703
trainer/Log Pis Min                     -4.92003
trainer/policy/mean Mean                -0.0928278
trainer/policy/mean Std                  0.82226
trainer/policy/mean Max                  0.999013
trainer/policy/mean Min                 -0.989152
trainer/policy/normal/std Mean           0.648004
trainer/policy/normal/std Std            0.0907009
trainer/policy/normal/std Max            0.929437
trainer/policy/normal/std Min            0.411581
trainer/policy/normal/log_std Mean      -0.443721
trainer/policy/normal/log_std Std        0.140929
trainer/policy/normal/log_std Max       -0.0731758
trainer/policy/normal/log_std Min       -0.88775
trainer/Alpha                            0.0466412
trainer/Alpha Loss                      -0.845653
exploration/num steps total          44000
exploration/num paths total            220
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.06398
exploration/Rewards Std                  0.15085
exploration/Rewards Max                 -0.719732
exploration/Rewards Min                 -1.59614
exploration/Returns Mean              -212.796
exploration/Returns Std                  1.95986
exploration/Returns Max               -209.049
exploration/Returns Min               -214.741
exploration/Actions Mean                -0.146233
exploration/Actions Std                  0.724851
exploration/Actions Max                  0.999418
exploration/Actions Min                 -0.998382
exploration/Num Paths                    5
exploration/Average Returns           -212.796
evaluation/num steps total          207432
evaluation/num paths total            1032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00854
evaluation/Rewards Std                   0.203225
evaluation/Rewards Max                  -0.621392
evaluation/Rewards Min                  -1.81225
evaluation/Returns Mean               -202.717
evaluation/Returns Std                  23.649
evaluation/Returns Max                -167.499
evaluation/Returns Min                -274.529
evaluation/Actions Mean                 -0.165768
evaluation/Actions Std                   0.704121
evaluation/Actions Max                   0.999044
evaluation/Actions Min                  -0.999013
evaluation/Num Paths                    24
evaluation/Average Returns            -202.717
time/data storing (s)                    0.012875
time/evaluation sampling (s)           494.466
time/exploration sampling (s)          148.151
time/logging (s)                         0.0581998
time/sac training (s)                   11.7465
time/saving (s)                          0.0547352
time/training (s)                        0.000116854
time/epoch (s)                         654.489
time/total (s)                       29429
Epoch                                   42
----------------------------------  ----------------
2020-11-01 18:13:51.522953 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 43 finished
----------------------------------  ----------------
replay_buffer/size                   45000
trainer/num train calls              44000
trainer/QF1 Loss                        19.1555
trainer/QF2 Loss                        21.1247
trainer/Policy Loss                    110.623
trainer/Q1 Predictions Mean           -110.301
trainer/Q1 Predictions Std              29.9735
trainer/Q1 Predictions Max             -14.0096
trainer/Q1 Predictions Min            -161.626
trainer/Q2 Predictions Mean           -109.905
trainer/Q2 Predictions Std              30.0827
trainer/Q2 Predictions Max             -13.2673
trainer/Q2 Predictions Min            -163.363
trainer/Q Targets Mean                -110.512
trainer/Q Targets Std                   29.9339
trainer/Q Targets Max                   -9.23231
trainer/Q Targets Min                 -163.706
trainer/Log Pis Mean                     2.37697
trainer/Log Pis Std                      2.33335
trainer/Log Pis Max                     10.4791
trainer/Log Pis Min                     -4.35784
trainer/policy/mean Mean                -0.0424607
trainer/policy/mean Std                  0.852863
trainer/policy/mean Max                  0.999595
trainer/policy/mean Min                 -0.997883
trainer/policy/normal/std Mean           0.634367
trainer/policy/normal/std Std            0.0901694
trainer/policy/normal/std Max            0.925859
trainer/policy/normal/std Min            0.389008
trainer/policy/normal/log_std Mean      -0.465371
trainer/policy/normal/log_std Std        0.143961
trainer/policy/normal/log_std Max       -0.0770331
trainer/policy/normal/log_std Min       -0.944154
trainer/Alpha                            0.0456604
trainer/Alpha Loss                       1.16353
exploration/num steps total          45000
exploration/num paths total            225
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00492
exploration/Rewards Std                  0.175581
exploration/Rewards Max                 -0.695327
exploration/Rewards Min                 -1.541
exploration/Returns Mean              -200.985
exploration/Returns Std                 23.6409
exploration/Returns Max               -171.4
exploration/Returns Min               -237.489
exploration/Actions Mean                 0.0146087
exploration/Actions Std                  0.807527
exploration/Actions Max                  0.999759
exploration/Actions Min                 -0.999693
exploration/Num Paths                    5
exploration/Average Returns           -200.985
evaluation/num steps total          212256
evaluation/num paths total            1056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.06167
evaluation/Rewards Std                   0.252385
evaluation/Rewards Max                  -0.613181
evaluation/Rewards Min                  -1.92775
evaluation/Returns Mean               -213.395
evaluation/Returns Std                  40.061
evaluation/Returns Max                -156.662
evaluation/Returns Min                -295.668
evaluation/Actions Mean                 -0.138804
evaluation/Actions Std                   0.748948
evaluation/Actions Max                   0.999845
evaluation/Actions Min                  -0.999788
evaluation/Num Paths                    24
evaluation/Average Returns            -213.395
time/data storing (s)                    0.0123096
time/evaluation sampling (s)           557.143
time/exploration sampling (s)          110.144
time/logging (s)                         0.0455654
time/sac training (s)                    9.15495
time/saving (s)                          0.0446117
time/training (s)                        0.000147181
time/epoch (s)                         676.545
time/total (s)                       30106.5
Epoch                                   43
----------------------------------  ----------------
2020-11-01 18:24:30.081140 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 44 finished
----------------------------------  ---------------
replay_buffer/size                   46000
trainer/num train calls              45000
trainer/QF1 Loss                        32.5508
trainer/QF2 Loss                        33.8095
trainer/Policy Loss                    110.273
trainer/Q1 Predictions Mean           -109.695
trainer/Q1 Predictions Std              31.7266
trainer/Q1 Predictions Max             -24.4911
trainer/Q1 Predictions Min            -165.905
trainer/Q2 Predictions Mean           -109.59
trainer/Q2 Predictions Std              31.3156
trainer/Q2 Predictions Max             -24.2794
trainer/Q2 Predictions Min            -167.805
trainer/Q Targets Mean                -110.292
trainer/Q Targets Std                   32.0776
trainer/Q Targets Max                   -0.771505
trainer/Q Targets Min                 -165.102
trainer/Log Pis Mean                     1.75001
trainer/Log Pis Std                      2.30825
trainer/Log Pis Max                      7.31272
trainer/Log Pis Min                     -4.57123
trainer/policy/mean Mean                -0.268189
trainer/policy/mean Std                  0.782899
trainer/policy/mean Max                  0.998376
trainer/policy/mean Min                 -0.994617
trainer/policy/normal/std Mean           0.646222
trainer/policy/normal/std Std            0.100861
trainer/policy/normal/std Max            0.910038
trainer/policy/normal/std Min            0.379486
trainer/policy/normal/log_std Mean      -0.449073
trainer/policy/normal/log_std Std        0.159111
trainer/policy/normal/log_std Max       -0.0942686
trainer/policy/normal/log_std Min       -0.968938
trainer/Alpha                            0.0461744
trainer/Alpha Loss                      -0.768789
exploration/num steps total          46000
exploration/num paths total            230
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.892783
exploration/Rewards Std                  0.222792
exploration/Rewards Max                 -0.588297
exploration/Rewards Min                 -1.55323
exploration/Returns Mean              -178.557
exploration/Returns Std                 22.4333
exploration/Returns Max               -163.702
exploration/Returns Min               -222.466
exploration/Actions Mean                -0.36269
exploration/Actions Std                  0.693136
exploration/Actions Max                  0.993735
exploration/Actions Min                 -0.999169
exploration/Num Paths                    5
exploration/Average Returns           -178.557
evaluation/num steps total          217080
evaluation/num paths total            1080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.01786
evaluation/Rewards Std                   0.212979
evaluation/Rewards Max                  -0.669558
evaluation/Rewards Min                  -2.08042
evaluation/Returns Mean               -204.59
evaluation/Returns Std                  28.6609
evaluation/Returns Max                -168.956
evaluation/Returns Min                -274.465
evaluation/Actions Mean                 -0.115658
evaluation/Actions Std                   0.727994
evaluation/Actions Max                   0.999085
evaluation/Actions Min                  -0.999962
evaluation/Num Paths                    24
evaluation/Average Returns            -204.59
time/data storing (s)                    0.0131815
time/evaluation sampling (s)           501.54
time/exploration sampling (s)          125.509
time/logging (s)                         0.0769726
time/sac training (s)                   10.3989
time/saving (s)                          0.152619
time/training (s)                        0.00015037
time/epoch (s)                         637.691
time/total (s)                       30745.1
Epoch                                   44
----------------------------------  ---------------
2020-11-01 18:35:39.465824 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 45 finished
----------------------------------  ----------------
replay_buffer/size                   47000
trainer/num train calls              46000
trainer/QF1 Loss                        64.1662
trainer/QF2 Loss                        62.6558
trainer/Policy Loss                    112.892
trainer/Q1 Predictions Mean           -112.314
trainer/Q1 Predictions Std              30.8263
trainer/Q1 Predictions Max             -12.9999
trainer/Q1 Predictions Min            -164.724
trainer/Q2 Predictions Mean           -112.303
trainer/Q2 Predictions Std              30.5613
trainer/Q2 Predictions Max             -17.4911
trainer/Q2 Predictions Min            -165.243
trainer/Q Targets Mean                -112.709
trainer/Q Targets Std                   31.9127
trainer/Q Targets Max                   -1.02291
trainer/Q Targets Min                 -166.883
trainer/Log Pis Mean                     1.99803
trainer/Log Pis Std                      2.19537
trainer/Log Pis Max                      8.05456
trainer/Log Pis Min                     -3.61212
trainer/policy/mean Mean                -0.181324
trainer/policy/mean Std                  0.822457
trainer/policy/mean Max                  0.999051
trainer/policy/mean Min                 -0.992976
trainer/policy/normal/std Mean           0.629886
trainer/policy/normal/std Std            0.0873642
trainer/policy/normal/std Max            0.926961
trainer/policy/normal/std Min            0.398701
trainer/policy/normal/log_std Mean      -0.472032
trainer/policy/normal/log_std Std        0.141107
trainer/policy/normal/log_std Max       -0.0758434
trainer/policy/normal/log_std Min       -0.919543
trainer/Alpha                            0.0479551
trainer/Alpha Loss                      -0.00598222
exploration/num steps total          47000
exploration/num paths total            235
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.944445
exploration/Rewards Std                  0.213944
exploration/Rewards Max                 -0.564824
exploration/Rewards Min                 -1.6462
exploration/Returns Mean              -188.889
exploration/Returns Std                 32.2915
exploration/Returns Max               -150.181
exploration/Returns Min               -245.791
exploration/Actions Mean                -0.268603
exploration/Actions Std                  0.702965
exploration/Actions Max                  0.999797
exploration/Actions Min                 -0.998285
exploration/Num Paths                    5
exploration/Average Returns           -188.889
evaluation/num steps total          221904
evaluation/num paths total            1104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95822
evaluation/Rewards Std                   0.17385
evaluation/Rewards Max                  -0.610764
evaluation/Rewards Min                  -1.62055
evaluation/Returns Mean               -192.602
evaluation/Returns Std                  15.98
evaluation/Returns Max                -173.416
evaluation/Returns Min                -237.486
evaluation/Actions Mean                 -0.227429
evaluation/Actions Std                   0.705261
evaluation/Actions Max                   0.999987
evaluation/Actions Min                  -0.998995
evaluation/Num Paths                    24
evaluation/Average Returns            -192.602
time/data storing (s)                    0.00973499
time/evaluation sampling (s)           536.368
time/exploration sampling (s)          121.141
time/logging (s)                         0.0718755
time/sac training (s)                   10.8386
time/saving (s)                          0.0509923
time/training (s)                        0.000118496
time/epoch (s)                         668.481
time/total (s)                       31414.4
Epoch                                   45
----------------------------------  ----------------
2020-11-01 18:48:23.062904 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 46 finished
----------------------------------  ----------------
replay_buffer/size                   48000
trainer/num train calls              47000
trainer/QF1 Loss                        36.1524
trainer/QF2 Loss                        38.6033
trainer/Policy Loss                    117.216
trainer/Q1 Predictions Mean           -116.562
trainer/Q1 Predictions Std              29.7945
trainer/Q1 Predictions Max             -22.9204
trainer/Q1 Predictions Min            -167.089
trainer/Q2 Predictions Mean           -116.701
trainer/Q2 Predictions Std              29.8286
trainer/Q2 Predictions Max             -23.7745
trainer/Q2 Predictions Min            -167.884
trainer/Q Targets Mean                -117.302
trainer/Q Targets Std                   30.4571
trainer/Q Targets Max                   -0.808026
trainer/Q Targets Min                 -171.382
trainer/Log Pis Mean                     1.64234
trainer/Log Pis Std                      2.27851
trainer/Log Pis Max                      8.64672
trainer/Log Pis Min                     -4.63367
trainer/policy/mean Mean                -0.217424
trainer/policy/mean Std                  0.794188
trainer/policy/mean Max                  0.996442
trainer/policy/mean Min                 -0.992325
trainer/policy/normal/std Mean           0.640971
trainer/policy/normal/std Std            0.0844352
trainer/policy/normal/std Max            0.879167
trainer/policy/normal/std Min            0.406059
trainer/policy/normal/log_std Mean      -0.453636
trainer/policy/normal/log_std Std        0.134127
trainer/policy/normal/log_std Max       -0.12878
trainer/policy/normal/log_std Min       -0.901257
trainer/Alpha                            0.0479278
trainer/Alpha Loss                      -1.0866
exploration/num steps total          48000
exploration/num paths total            240
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.02235
exploration/Rewards Std                  0.206874
exploration/Rewards Max                 -0.646993
exploration/Rewards Min                 -1.74009
exploration/Returns Mean              -204.471
exploration/Returns Std                 25.5464
exploration/Returns Max               -168.528
exploration/Returns Min               -244.207
exploration/Actions Mean                -0.157786
exploration/Actions Std                  0.754187
exploration/Actions Max                  0.998669
exploration/Actions Min                 -0.9999
exploration/Num Paths                    5
exploration/Average Returns           -204.471
evaluation/num steps total          226728
evaluation/num paths total            1128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.991715
evaluation/Rewards Std                   0.183066
evaluation/Rewards Max                  -0.624567
evaluation/Rewards Min                  -1.64978
evaluation/Returns Mean               -199.335
evaluation/Returns Std                  24.5555
evaluation/Returns Max                -159.217
evaluation/Returns Min                -249.13
evaluation/Actions Mean                 -0.114317
evaluation/Actions Std                   0.720829
evaluation/Actions Max                   0.99943
evaluation/Actions Min                  -0.996976
evaluation/Num Paths                    24
evaluation/Average Returns            -199.335
time/data storing (s)                    0.0331144
time/evaluation sampling (s)           624.321
time/exploration sampling (s)          126.869
time/logging (s)                         0.062176
time/sac training (s)                   11.1936
time/saving (s)                          0.13764
time/training (s)                        0.000116963
time/epoch (s)                         762.617
time/total (s)                       32178
Epoch                                   46
----------------------------------  ----------------
2020-11-01 18:59:02.052482 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 47 finished
----------------------------------  ----------------
replay_buffer/size                   49000
trainer/num train calls              48000
trainer/QF1 Loss                        26.4483
trainer/QF2 Loss                        31.663
trainer/Policy Loss                    117.905
trainer/Q1 Predictions Mean           -117.701
trainer/Q1 Predictions Std              32.8596
trainer/Q1 Predictions Max             -19.4409
trainer/Q1 Predictions Min            -171.248
trainer/Q2 Predictions Mean           -116.663
trainer/Q2 Predictions Std              32.4374
trainer/Q2 Predictions Max             -19.2863
trainer/Q2 Predictions Min            -168.404
trainer/Q Targets Mean                -117.37
trainer/Q Targets Std                   33.4832
trainer/Q Targets Max                   -1.13195
trainer/Q Targets Min                 -169.383
trainer/Log Pis Mean                     2.04139
trainer/Log Pis Std                      2.50162
trainer/Log Pis Max                     10.8285
trainer/Log Pis Min                     -5.95602
trainer/policy/mean Mean                -0.317343
trainer/policy/mean Std                  0.773989
trainer/policy/mean Max                  0.999442
trainer/policy/mean Min                 -0.998119
trainer/policy/normal/std Mean           0.636139
trainer/policy/normal/std Std            0.0905303
trainer/policy/normal/std Max            0.915862
trainer/policy/normal/std Min            0.364875
trainer/policy/normal/log_std Mean      -0.462711
trainer/policy/normal/log_std Std        0.145287
trainer/policy/normal/log_std Max       -0.0878901
trainer/policy/normal/log_std Min       -1.0082
trainer/Alpha                            0.0491017
trainer/Alpha Loss                       0.124729
exploration/num steps total          49000
exploration/num paths total            245
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.977977
exploration/Rewards Std                  0.207544
exploration/Rewards Max                 -0.613019
exploration/Rewards Min                 -1.70692
exploration/Returns Mean              -195.595
exploration/Returns Std                 19.2893
exploration/Returns Max               -168.131
exploration/Returns Min               -220.625
exploration/Actions Mean                -0.194215
exploration/Actions Std                  0.744102
exploration/Actions Max                  0.999899
exploration/Actions Min                 -0.999735
exploration/Num Paths                    5
exploration/Average Returns           -195.595
evaluation/num steps total          231552
evaluation/num paths total            1152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.01449
evaluation/Rewards Std                   0.207412
evaluation/Rewards Max                  -0.632943
evaluation/Rewards Min                  -1.61275
evaluation/Returns Mean               -203.913
evaluation/Returns Std                  30.6619
evaluation/Returns Max                -157.599
evaluation/Returns Min                -270.475
evaluation/Actions Mean                 -0.114979
evaluation/Actions Std                   0.707776
evaluation/Actions Max                   0.999464
evaluation/Actions Min                  -0.994623
evaluation/Num Paths                    24
evaluation/Average Returns            -203.913
time/data storing (s)                    0.00749059
time/evaluation sampling (s)           516.998
time/exploration sampling (s)          111.883
time/logging (s)                         0.0185646
time/sac training (s)                    9.18503
time/saving (s)                          0.0258388
time/training (s)                        0.000120323
time/epoch (s)                         638.117
time/total (s)                       32816.9
Epoch                                   47
----------------------------------  ----------------
2020-11-01 19:11:39.757258 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 48 finished
----------------------------------  ----------------
replay_buffer/size                   50000
trainer/num train calls              49000
trainer/QF1 Loss                        17.3248
trainer/QF2 Loss                        20.9924
trainer/Policy Loss                    114.667
trainer/Q1 Predictions Mean           -114.315
trainer/Q1 Predictions Std              33.1588
trainer/Q1 Predictions Max             -26.4096
trainer/Q1 Predictions Min            -171.318
trainer/Q2 Predictions Mean           -113.855
trainer/Q2 Predictions Std              32.8004
trainer/Q2 Predictions Max             -26.9225
trainer/Q2 Predictions Min            -171.349
trainer/Q Targets Mean                -115.345
trainer/Q Targets Std                   33.0634
trainer/Q Targets Max                  -26.1117
trainer/Q Targets Min                 -173.113
trainer/Log Pis Mean                     1.69949
trainer/Log Pis Std                      2.38496
trainer/Log Pis Max                      9.23752
trainer/Log Pis Min                     -5.30588
trainer/policy/mean Mean                -0.187889
trainer/policy/mean Std                  0.806122
trainer/policy/mean Max                  0.999931
trainer/policy/mean Min                 -0.993145
trainer/policy/normal/std Mean           0.649951
trainer/policy/normal/std Std            0.0875448
trainer/policy/normal/std Max            0.985184
trainer/policy/normal/std Min            0.436347
trainer/policy/normal/log_std Mean      -0.439848
trainer/policy/normal/log_std Std        0.133999
trainer/policy/normal/log_std Max       -0.0149264
trainer/policy/normal/log_std Min       -0.829317
trainer/Alpha                            0.0486762
trainer/Alpha Loss                      -0.908307
exploration/num steps total          50000
exploration/num paths total            250
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.994048
exploration/Rewards Std                  0.161944
exploration/Rewards Max                 -0.698187
exploration/Rewards Min                 -1.45716
exploration/Returns Mean              -198.81
exploration/Returns Std                 17.8955
exploration/Returns Max               -171.361
exploration/Returns Min               -226.894
exploration/Actions Mean                 0.00211545
exploration/Actions Std                  0.75652
exploration/Actions Max                  0.999758
exploration/Actions Min                 -0.99867
exploration/Num Paths                    5
exploration/Average Returns           -198.81
evaluation/num steps total          236376
evaluation/num paths total            1176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.09919
evaluation/Rewards Std                   0.178497
evaluation/Rewards Max                  -0.640563
evaluation/Rewards Min                  -1.76465
evaluation/Returns Mean               -220.937
evaluation/Returns Std                  26.4231
evaluation/Returns Max                -168.259
evaluation/Returns Min                -266.874
evaluation/Actions Mean                 -0.0771749
evaluation/Actions Std                   0.661664
evaluation/Actions Max                   0.995516
evaluation/Actions Min                  -0.995795
evaluation/Num Paths                    24
evaluation/Average Returns            -220.937
time/data storing (s)                    0.0145862
time/evaluation sampling (s)           622.381
time/exploration sampling (s)          125.115
time/logging (s)                         0.0300444
time/sac training (s)                    9.29138
time/saving (s)                          0.0401664
time/training (s)                        0.000140143
time/epoch (s)                         756.873
time/total (s)                       33574.6
Epoch                                   48
----------------------------------  ----------------
2020-11-01 19:21:43.336504 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 49 finished
----------------------------------  ----------------
replay_buffer/size                   51000
trainer/num train calls              50000
trainer/QF1 Loss                        25.5938
trainer/QF2 Loss                        24.7949
trainer/Policy Loss                    118.765
trainer/Q1 Predictions Mean           -118.296
trainer/Q1 Predictions Std              32.8514
trainer/Q1 Predictions Max             -18.1728
trainer/Q1 Predictions Min            -174.79
trainer/Q2 Predictions Mean           -118.257
trainer/Q2 Predictions Std              32.6144
trainer/Q2 Predictions Max             -18.0555
trainer/Q2 Predictions Min            -173.709
trainer/Q Targets Mean                -118.128
trainer/Q Targets Std                   32.8558
trainer/Q Targets Max                  -21.3313
trainer/Q Targets Min                 -174.115
trainer/Log Pis Mean                     1.79724
trainer/Log Pis Std                      2.26064
trainer/Log Pis Max                      7.86669
trainer/Log Pis Min                     -4.35166
trainer/policy/mean Mean                -0.319269
trainer/policy/mean Std                  0.756704
trainer/policy/mean Max                  0.99716
trainer/policy/mean Min                 -0.996468
trainer/policy/normal/std Mean           0.640884
trainer/policy/normal/std Std            0.0897304
trainer/policy/normal/std Max            0.954735
trainer/policy/normal/std Min            0.428976
trainer/policy/normal/log_std Mean      -0.45482
trainer/policy/normal/log_std Std        0.141437
trainer/policy/normal/log_std Max       -0.0463212
trainer/policy/normal/log_std Min       -0.846355
trainer/Alpha                            0.0459449
trainer/Alpha Loss                      -0.624557
exploration/num steps total          51000
exploration/num paths total            255
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.989369
exploration/Rewards Std                  0.232014
exploration/Rewards Max                 -0.565124
exploration/Rewards Min                 -1.69935
exploration/Returns Mean              -197.874
exploration/Returns Std                 30.6819
exploration/Returns Max               -155.965
exploration/Returns Min               -249.639
exploration/Actions Mean                -0.139366
exploration/Actions Std                  0.728435
exploration/Actions Max                  0.999625
exploration/Actions Min                 -0.99954
exploration/Num Paths                    5
exploration/Average Returns           -197.874
evaluation/num steps total          241200
evaluation/num paths total            1200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.985755
evaluation/Rewards Std                   0.196542
evaluation/Rewards Max                  -0.573796
evaluation/Rewards Min                  -1.59263
evaluation/Returns Mean               -198.137
evaluation/Returns Std                  25.469
evaluation/Returns Max                -153.633
evaluation/Returns Min                -254.57
evaluation/Actions Mean                 -0.191051
evaluation/Actions Std                   0.691506
evaluation/Actions Max                   0.988906
evaluation/Actions Min                  -0.999528
evaluation/Num Paths                    24
evaluation/Average Returns            -198.137
time/data storing (s)                    0.0107146
time/evaluation sampling (s)           475.726
time/exploration sampling (s)          117.981
time/logging (s)                         0.0285518
time/sac training (s)                    9.01002
time/saving (s)                          0.0329963
time/training (s)                        0.000111767
time/epoch (s)                         602.789
time/total (s)                       34178.1
Epoch                                   49
----------------------------------  ----------------
2020-11-01 19:31:44.172448 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 50 finished
----------------------------------  ----------------
replay_buffer/size                   52000
trainer/num train calls              51000
trainer/QF1 Loss                        20.2217
trainer/QF2 Loss                        20.3937
trainer/Policy Loss                    120.552
trainer/Q1 Predictions Mean           -120.295
trainer/Q1 Predictions Std              35.1282
trainer/Q1 Predictions Max             -19.3513
trainer/Q1 Predictions Min            -176.415
trainer/Q2 Predictions Mean           -119.592
trainer/Q2 Predictions Std              35.3075
trainer/Q2 Predictions Max             -14.2869
trainer/Q2 Predictions Min            -174.733
trainer/Q Targets Mean                -119.772
trainer/Q Targets Std                   34.7637
trainer/Q Targets Max                  -24.0657
trainer/Q Targets Min                 -176.951
trainer/Log Pis Mean                     1.88868
trainer/Log Pis Std                      2.42383
trainer/Log Pis Max                      9.21016
trainer/Log Pis Min                     -5.1035
trainer/policy/mean Mean                -0.312834
trainer/policy/mean Std                  0.783576
trainer/policy/mean Max                  0.99816
trainer/policy/mean Min                 -0.994891
trainer/policy/normal/std Mean           0.648458
trainer/policy/normal/std Std            0.0888626
trainer/policy/normal/std Max            0.876575
trainer/policy/normal/std Min            0.40375
trainer/policy/normal/log_std Mean      -0.442608
trainer/policy/normal/log_std Std        0.137901
trainer/policy/normal/log_std Max       -0.131733
trainer/policy/normal/log_std Min       -0.906958
trainer/Alpha                            0.0467817
trainer/Alpha Loss                      -0.340886
exploration/num steps total          52000
exploration/num paths total            260
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.03546
exploration/Rewards Std                  0.17305
exploration/Rewards Max                 -0.787707
exploration/Rewards Min                 -1.70528
exploration/Returns Mean              -207.092
exploration/Returns Std                 14.4808
exploration/Returns Max               -185.587
exploration/Returns Min               -227.439
exploration/Actions Mean                -0.364887
exploration/Actions Std                  0.704771
exploration/Actions Max                  0.998132
exploration/Actions Min                 -0.99912
exploration/Num Paths                    5
exploration/Average Returns           -207.092
evaluation/num steps total          246024
evaluation/num paths total            1224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.06718
evaluation/Rewards Std                   0.201387
evaluation/Rewards Max                  -0.651263
evaluation/Rewards Min                  -1.75634
evaluation/Returns Mean               -214.503
evaluation/Returns Std                  30.735
evaluation/Returns Max                -168.022
evaluation/Returns Min                -276.808
evaluation/Actions Mean                 -0.100427
evaluation/Actions Std                   0.69496
evaluation/Actions Max                   0.99752
evaluation/Actions Min                  -0.99358
evaluation/Num Paths                    24
evaluation/Average Returns            -214.503
time/data storing (s)                    0.00693026
time/evaluation sampling (s)           490.518
time/exploration sampling (s)          100.067
time/logging (s)                         0.0260588
time/sac training (s)                    9.54285
time/saving (s)                          0.0229435
time/training (s)                        0.000133874
time/epoch (s)                         600.184
time/total (s)                       34778.9
Epoch                                   50
----------------------------------  ----------------
2020-11-01 19:42:03.312478 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 51 finished
----------------------------------  ----------------
replay_buffer/size                   53000
trainer/num train calls              52000
trainer/QF1 Loss                        23.1729
trainer/QF2 Loss                        23.6867
trainer/Policy Loss                    121.165
trainer/Q1 Predictions Mean           -120.605
trainer/Q1 Predictions Std              31.7106
trainer/Q1 Predictions Max             -47.6178
trainer/Q1 Predictions Min            -175.729
trainer/Q2 Predictions Mean           -120.52
trainer/Q2 Predictions Std              32.0296
trainer/Q2 Predictions Max             -47.8393
trainer/Q2 Predictions Min            -177.174
trainer/Q Targets Mean                -120.807
trainer/Q Targets Std                   32.1541
trainer/Q Targets Max                  -45.9919
trainer/Q Targets Min                 -177.616
trainer/Log Pis Mean                     1.72626
trainer/Log Pis Std                      2.33328
trainer/Log Pis Max                     10.5638
trainer/Log Pis Min                     -7.47705
trainer/policy/mean Mean                -0.106277
trainer/policy/mean Std                  0.823919
trainer/policy/mean Max                  0.998355
trainer/policy/mean Min                 -0.992059
trainer/policy/normal/std Mean           0.651568
trainer/policy/normal/std Std            0.0824395
trainer/policy/normal/std Max            0.920408
trainer/policy/normal/std Min            0.394631
trainer/policy/normal/log_std Mean      -0.436559
trainer/policy/normal/log_std Std        0.12894
trainer/policy/normal/log_std Max       -0.0829381
trainer/policy/normal/log_std Min       -0.929804
trainer/Alpha                            0.0469473
trainer/Alpha Loss                      -0.837289
exploration/num steps total          53000
exploration/num paths total            265
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.989032
exploration/Rewards Std                  0.198528
exploration/Rewards Max                 -0.694213
exploration/Rewards Min                 -1.49231
exploration/Returns Mean              -197.806
exploration/Returns Std                 20.5525
exploration/Returns Max               -176.4
exploration/Returns Min               -234.093
exploration/Actions Mean                -0.135438
exploration/Actions Std                  0.724046
exploration/Actions Max                  0.998276
exploration/Actions Min                 -0.999754
exploration/Num Paths                    5
exploration/Average Returns           -197.806
evaluation/num steps total          250848
evaluation/num paths total            1248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.01975
evaluation/Rewards Std                   0.215758
evaluation/Rewards Max                  -0.557158
evaluation/Rewards Min                  -1.60675
evaluation/Returns Mean               -204.97
evaluation/Returns Std                  32.4239
evaluation/Returns Max                -141.824
evaluation/Returns Min                -279.662
evaluation/Actions Mean                 -0.117148
evaluation/Actions Std                   0.670209
evaluation/Actions Max                   0.998398
evaluation/Actions Min                  -0.995942
evaluation/Num Paths                    24
evaluation/Average Returns            -204.97
time/data storing (s)                    0.00718645
time/evaluation sampling (s)           502.505
time/exploration sampling (s)          106.867
time/logging (s)                         0.0206989
time/sac training (s)                    9.02958
time/saving (s)                          0.0267768
time/training (s)                        0.000118103
time/epoch (s)                         618.457
time/total (s)                       35398
Epoch                                   51
----------------------------------  ----------------
2020-11-01 19:52:55.308526 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 52 finished
----------------------------------  ----------------
replay_buffer/size                   54000
trainer/num train calls              53000
trainer/QF1 Loss                        48.3817
trainer/QF2 Loss                        48.2067
trainer/Policy Loss                    122.113
trainer/Q1 Predictions Mean           -121.352
trainer/Q1 Predictions Std              36.184
trainer/Q1 Predictions Max             -21.2638
trainer/Q1 Predictions Min            -182.773
trainer/Q2 Predictions Mean           -121.78
trainer/Q2 Predictions Std              36.3807
trainer/Q2 Predictions Max             -19.9261
trainer/Q2 Predictions Min            -182.128
trainer/Q Targets Mean                -120.644
trainer/Q Targets Std                   36.8388
trainer/Q Targets Max                   -0.692678
trainer/Q Targets Min                 -179.758
trainer/Log Pis Mean                     1.74859
trainer/Log Pis Std                      1.85721
trainer/Log Pis Max                      7.36158
trainer/Log Pis Min                     -3.38284
trainer/policy/mean Mean                -0.226535
trainer/policy/mean Std                  0.80033
trainer/policy/mean Max                  0.997384
trainer/policy/mean Min                 -0.993342
trainer/policy/normal/std Mean           0.656314
trainer/policy/normal/std Std            0.0838453
trainer/policy/normal/std Max            0.914043
trainer/policy/normal/std Min            0.340374
trainer/policy/normal/log_std Mean      -0.429631
trainer/policy/normal/log_std Std        0.132428
trainer/policy/normal/log_std Max       -0.0898774
trainer/policy/normal/log_std Min       -1.07771
trainer/Alpha                            0.0448744
trainer/Alpha Loss                      -0.780359
exploration/num steps total          54000
exploration/num paths total            270
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.959802
exploration/Rewards Std                  0.18671
exploration/Rewards Max                 -0.62554
exploration/Rewards Min                 -1.51501
exploration/Returns Mean              -191.96
exploration/Returns Std                 19.4306
exploration/Returns Max               -167.214
exploration/Returns Min               -213.138
exploration/Actions Mean                -0.109033
exploration/Actions Std                  0.722821
exploration/Actions Max                  0.999382
exploration/Actions Min                 -0.999004
exploration/Num Paths                    5
exploration/Average Returns           -191.96
evaluation/num steps total          255672
evaluation/num paths total            1272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.954349
evaluation/Rewards Std                   0.180079
evaluation/Rewards Max                  -0.591468
evaluation/Rewards Min                  -1.69753
evaluation/Returns Mean               -191.824
evaluation/Returns Std                  19.3759
evaluation/Returns Max                -156.244
evaluation/Returns Min                -228.08
evaluation/Actions Mean                 -0.232948
evaluation/Actions Std                   0.643928
evaluation/Actions Max                   0.991443
evaluation/Actions Min                  -0.998578
evaluation/Num Paths                    24
evaluation/Average Returns            -191.824
time/data storing (s)                    0.0109646
time/evaluation sampling (s)           523.531
time/exploration sampling (s)          118.083
time/logging (s)                         0.0260558
time/sac training (s)                    9.47938
time/saving (s)                          0.0417473
time/training (s)                        0.000116728
time/epoch (s)                         651.172
time/total (s)                       36050
Epoch                                   52
----------------------------------  ----------------
2020-11-01 20:06:50.449770 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 53 finished
----------------------------------  ---------------
replay_buffer/size                   55000
trainer/num train calls              54000
trainer/QF1 Loss                        93.3615
trainer/QF2 Loss                        91.0276
trainer/Policy Loss                    121.276
trainer/Q1 Predictions Mean           -120.958
trainer/Q1 Predictions Std              34.9825
trainer/Q1 Predictions Max             -33.6172
trainer/Q1 Predictions Min            -178.653
trainer/Q2 Predictions Mean           -120.722
trainer/Q2 Predictions Std              35.1775
trainer/Q2 Predictions Max             -30.0888
trainer/Q2 Predictions Min            -178.978
trainer/Q Targets Mean                -119.889
trainer/Q Targets Std                   37.2162
trainer/Q Targets Max                   -1.04712
trainer/Q Targets Min                 -180.763
trainer/Log Pis Mean                     1.71305
trainer/Log Pis Std                      2.61951
trainer/Log Pis Max                     10.8765
trainer/Log Pis Min                     -7.14733
trainer/policy/mean Mean                -0.250128
trainer/policy/mean Std                  0.777177
trainer/policy/mean Max                  0.999107
trainer/policy/mean Min                 -0.998422
trainer/policy/normal/std Mean           0.659786
trainer/policy/normal/std Std            0.0939779
trainer/policy/normal/std Max            0.95896
trainer/policy/normal/std Min            0.41273
trainer/policy/normal/log_std Mean      -0.42616
trainer/policy/normal/log_std Std        0.144612
trainer/policy/normal/log_std Max       -0.0419057
trainer/policy/normal/log_std Min       -0.884961
trainer/Alpha                            0.0441044
trainer/Alpha Loss                      -0.895624
exploration/num steps total          55000
exploration/num paths total            275
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.98474
exploration/Rewards Std                  0.157512
exploration/Rewards Max                 -0.600799
exploration/Rewards Min                 -1.36827
exploration/Returns Mean              -196.948
exploration/Returns Std                 14.4753
exploration/Returns Max               -174.482
exploration/Returns Min               -218.533
exploration/Actions Mean                -0.139121
exploration/Actions Std                  0.668637
exploration/Actions Max                  0.99697
exploration/Actions Min                 -0.998539
exploration/Num Paths                    5
exploration/Average Returns           -196.948
evaluation/num steps total          260496
evaluation/num paths total            1296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.979219
evaluation/Rewards Std                   0.202249
evaluation/Rewards Max                  -0.59005
evaluation/Rewards Min                  -1.62766
evaluation/Returns Mean               -196.823
evaluation/Returns Std                  26.3544
evaluation/Returns Max                -153.894
evaluation/Returns Min                -285.982
evaluation/Actions Mean                 -0.142347
evaluation/Actions Std                   0.668442
evaluation/Actions Max                   0.999689
evaluation/Actions Min                  -0.991351
evaluation/Num Paths                    24
evaluation/Average Returns            -196.823
time/data storing (s)                    0.0557009
time/evaluation sampling (s)           644.646
time/exploration sampling (s)          175.756
time/logging (s)                         0.0770367
time/sac training (s)                   13.3314
time/saving (s)                          0.134281
time/training (s)                        0.00018712
time/epoch (s)                         834
time/total (s)                       36885.2
Epoch                                   53
----------------------------------  ---------------
2020-11-01 20:22:13.120349 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 54 finished
----------------------------------  ----------------
replay_buffer/size                   56000
trainer/num train calls              55000
trainer/QF1 Loss                        68.0043
trainer/QF2 Loss                        65.8871
trainer/Policy Loss                    124.597
trainer/Q1 Predictions Mean           -124.254
trainer/Q1 Predictions Std              35.982
trainer/Q1 Predictions Max              -0.433556
trainer/Q1 Predictions Min            -181.491
trainer/Q2 Predictions Mean           -123.636
trainer/Q2 Predictions Std              35.5009
trainer/Q2 Predictions Max              -2.41682
trainer/Q2 Predictions Min            -179.881
trainer/Q Targets Mean                -123.395
trainer/Q Targets Std                   36.4797
trainer/Q Targets Max                   -1.14792
trainer/Q Targets Min                 -182.016
trainer/Log Pis Mean                     2.1639
trainer/Log Pis Std                      2.269
trainer/Log Pis Max                      8.74227
trainer/Log Pis Min                     -3.7862
trainer/policy/mean Mean                -0.108623
trainer/policy/mean Std                  0.842194
trainer/policy/mean Max                  0.994539
trainer/policy/mean Min                 -0.991484
trainer/policy/normal/std Mean           0.624876
trainer/policy/normal/std Std            0.0795199
trainer/policy/normal/std Max            0.85682
trainer/policy/normal/std Min            0.433106
trainer/policy/normal/log_std Mean      -0.478379
trainer/policy/normal/log_std Std        0.128407
trainer/policy/normal/log_std Max       -0.154528
trainer/policy/normal/log_std Min       -0.836772
trainer/Alpha                            0.0470545
trainer/Alpha Loss                       0.500948
exploration/num steps total          56000
exploration/num paths total            280
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00177
exploration/Rewards Std                  0.179715
exploration/Rewards Max                 -0.599896
exploration/Rewards Min                 -1.37268
exploration/Returns Mean              -200.355
exploration/Returns Std                 27.8413
exploration/Returns Max               -163.952
exploration/Returns Min               -242.665
exploration/Actions Mean                 0.066723
exploration/Actions Std                  0.761349
exploration/Actions Max                  0.999787
exploration/Actions Min                 -0.998226
exploration/Num Paths                    5
exploration/Average Returns           -200.355
evaluation/num steps total          265320
evaluation/num paths total            1320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.991124
evaluation/Rewards Std                   0.178424
evaluation/Rewards Max                  -0.599016
evaluation/Rewards Min                  -1.69302
evaluation/Returns Mean               -199.216
evaluation/Returns Std                  15.3599
evaluation/Returns Max                -167.871
evaluation/Returns Min                -223.964
evaluation/Actions Mean                 -0.223913
evaluation/Actions Std                   0.675322
evaluation/Actions Max                   0.997532
evaluation/Actions Min                  -0.998638
evaluation/Num Paths                    24
evaluation/Average Returns            -199.216
time/data storing (s)                    0.0180767
time/evaluation sampling (s)           755.978
time/exploration sampling (s)          153.397
time/logging (s)                         0.0625217
time/sac training (s)                   11.7243
time/saving (s)                          0.159433
time/training (s)                        0.000124322
time/epoch (s)                         921.34
time/total (s)                       37807.8
Epoch                                   54
----------------------------------  ----------------
2020-11-01 20:33:47.773701 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 55 finished
----------------------------------  ----------------
replay_buffer/size                   57000
trainer/num train calls              56000
trainer/QF1 Loss                        21.0304
trainer/QF2 Loss                        38.569
trainer/Policy Loss                    124.398
trainer/Q1 Predictions Mean           -124.019
trainer/Q1 Predictions Std              37.7595
trainer/Q1 Predictions Max              31.1232
trainer/Q1 Predictions Min            -183.007
trainer/Q2 Predictions Mean           -123.2
trainer/Q2 Predictions Std              39.5293
trainer/Q2 Predictions Max              78.0172
trainer/Q2 Predictions Min            -184.341
trainer/Q Targets Mean                -123.904
trainer/Q Targets Std                   37.8643
trainer/Q Targets Max                   28.4414
trainer/Q Targets Min                 -185.863
trainer/Log Pis Mean                     1.92062
trainer/Log Pis Std                      1.98108
trainer/Log Pis Max                      8.70382
trainer/Log Pis Min                     -4.2304
trainer/policy/mean Mean                -0.296822
trainer/policy/mean Std                  0.785378
trainer/policy/mean Max                  0.993341
trainer/policy/mean Min                 -0.995111
trainer/policy/normal/std Mean           0.630083
trainer/policy/normal/std Std            0.0876652
trainer/policy/normal/std Max            0.857755
trainer/policy/normal/std Min            0.341569
trainer/policy/normal/log_std Mean      -0.471837
trainer/policy/normal/log_std Std        0.142247
trainer/policy/normal/log_std Max       -0.153437
trainer/policy/normal/log_std Min       -1.0742
trainer/Alpha                            0.0459288
trainer/Alpha Loss                      -0.244539
exploration/num steps total          57000
exploration/num paths total            285
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.979427
exploration/Rewards Std                  0.246737
exploration/Rewards Max                 -0.590459
exploration/Rewards Min                 -1.75565
exploration/Returns Mean              -195.885
exploration/Returns Std                 18.0734
exploration/Returns Max               -164.81
exploration/Returns Min               -213.288
exploration/Actions Mean                -0.284636
exploration/Actions Std                  0.712857
exploration/Actions Max                  0.993805
exploration/Actions Min                 -0.999857
exploration/Num Paths                    5
exploration/Average Returns           -195.885
evaluation/num steps total          270144
evaluation/num paths total            1344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.934487
evaluation/Rewards Std                   0.192712
evaluation/Rewards Max                  -0.537221
evaluation/Rewards Min                  -1.6103
evaluation/Returns Mean               -187.832
evaluation/Returns Std                  20.0829
evaluation/Returns Max                -146.183
evaluation/Returns Min                -241.658
evaluation/Actions Mean                 -0.315195
evaluation/Actions Std                   0.644196
evaluation/Actions Max                   0.994836
evaluation/Actions Min                  -0.997824
evaluation/Num Paths                    24
evaluation/Average Returns            -187.832
time/data storing (s)                    0.0145565
time/evaluation sampling (s)           549.693
time/exploration sampling (s)          131.854
time/logging (s)                         0.0259283
time/sac training (s)                   11.8838
time/saving (s)                          0.040397
time/training (s)                        0.000154561
time/epoch (s)                         693.511
time/total (s)                       38502.4
Epoch                                   55
----------------------------------  ----------------
2020-11-01 20:46:44.532646 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 56 finished
----------------------------------  ----------------
replay_buffer/size                   58000
trainer/num train calls              57000
trainer/QF1 Loss                        31.7814
trainer/QF2 Loss                        29.2218
trainer/Policy Loss                    126.453
trainer/Q1 Predictions Mean           -125.926
trainer/Q1 Predictions Std              33.6488
trainer/Q1 Predictions Max             -36.0858
trainer/Q1 Predictions Min            -184.965
trainer/Q2 Predictions Mean           -125.851
trainer/Q2 Predictions Std              33.5893
trainer/Q2 Predictions Max             -35.717
trainer/Q2 Predictions Min            -184.826
trainer/Q Targets Mean                -127.121
trainer/Q Targets Std                   33.9326
trainer/Q Targets Max                   -1.07894
trainer/Q Targets Min                 -184.156
trainer/Log Pis Mean                     1.80062
trainer/Log Pis Std                      2.21382
trainer/Log Pis Max                      8.00756
trainer/Log Pis Min                     -3.91334
trainer/policy/mean Mean                -0.301596
trainer/policy/mean Std                  0.768821
trainer/policy/mean Max                  0.997702
trainer/policy/mean Min                 -0.997683
trainer/policy/normal/std Mean           0.644266
trainer/policy/normal/std Std            0.0831829
trainer/policy/normal/std Max            0.931162
trainer/policy/normal/std Min            0.388787
trainer/policy/normal/log_std Mean      -0.448069
trainer/policy/normal/log_std Std        0.13041
trainer/policy/normal/log_std Max       -0.0713218
trainer/policy/normal/log_std Min       -0.944723
trainer/Alpha                            0.0453886
trainer/Alpha Loss                      -0.61657
exploration/num steps total          58000
exploration/num paths total            290
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.02271
exploration/Rewards Std                  0.206744
exploration/Rewards Max                 -0.565289
exploration/Rewards Min                 -1.48399
exploration/Returns Mean              -204.542
exploration/Returns Std                 28.293
exploration/Returns Max               -169.34
exploration/Returns Min               -235.164
exploration/Actions Mean                -0.0598519
exploration/Actions Std                  0.729518
exploration/Actions Max                  0.999886
exploration/Actions Min                 -0.998005
exploration/Num Paths                    5
exploration/Average Returns           -204.542
evaluation/num steps total          274968
evaluation/num paths total            1368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.972557
evaluation/Rewards Std                   0.199286
evaluation/Rewards Max                  -0.534958
evaluation/Rewards Min                  -1.63524
evaluation/Returns Mean               -195.484
evaluation/Returns Std                  25.774
evaluation/Returns Max                -155.19
evaluation/Returns Min                -242.985
evaluation/Actions Mean                 -0.28383
evaluation/Actions Std                   0.649823
evaluation/Actions Max                   0.991563
evaluation/Actions Min                  -0.994507
evaluation/Num Paths                    24
evaluation/Average Returns            -195.484
time/data storing (s)                    0.0120575
time/evaluation sampling (s)           620.557
time/exploration sampling (s)          143.074
time/logging (s)                         0.0414531
time/sac training (s)                   11.8954
time/saving (s)                          0.0629306
time/training (s)                        0.000180533
time/epoch (s)                         775.643
time/total (s)                       39279.1
Epoch                                   56
----------------------------------  ----------------
2020-11-01 21:00:06.203113 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 57 finished
----------------------------------  ----------------
replay_buffer/size                   59000
trainer/num train calls              58000
trainer/QF1 Loss                        19.9891
trainer/QF2 Loss                        20.4498
trainer/Policy Loss                    127.445
trainer/Q1 Predictions Mean           -127.187
trainer/Q1 Predictions Std              34.4102
trainer/Q1 Predictions Max             -21.4122
trainer/Q1 Predictions Min            -185.674
trainer/Q2 Predictions Mean           -126.757
trainer/Q2 Predictions Std              34.3061
trainer/Q2 Predictions Max             -19.3961
trainer/Q2 Predictions Min            -183.79
trainer/Q Targets Mean                -127.374
trainer/Q Targets Std                   34.1954
trainer/Q Targets Max                  -25.3263
trainer/Q Targets Min                 -183.683
trainer/Log Pis Mean                     1.94918
trainer/Log Pis Std                      2.22043
trainer/Log Pis Max                      8.50609
trainer/Log Pis Min                     -5.08576
trainer/policy/mean Mean                -0.255163
trainer/policy/mean Std                  0.788344
trainer/policy/mean Max                  0.99955
trainer/policy/mean Min                 -0.995095
trainer/policy/normal/std Mean           0.652934
trainer/policy/normal/std Std            0.0845357
trainer/policy/normal/std Max            0.992096
trainer/policy/normal/std Min            0.3579
trainer/policy/normal/log_std Mean      -0.434671
trainer/policy/normal/log_std Std        0.129912
trainer/policy/normal/log_std Max       -0.0079357
trainer/policy/normal/log_std Min       -1.0275
trainer/Alpha                            0.0488167
trainer/Alpha Loss                      -0.153469
exploration/num steps total          59000
exploration/num paths total            295
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.0694
exploration/Rewards Std                  0.232975
exploration/Rewards Max                 -0.700158
exploration/Rewards Min                 -1.542
exploration/Returns Mean              -213.879
exploration/Returns Std                 39.7314
exploration/Returns Max               -162.942
exploration/Returns Min               -282.818
exploration/Actions Mean                -0.0872118
exploration/Actions Std                  0.739008
exploration/Actions Max                  0.999792
exploration/Actions Min                 -0.998965
exploration/Num Paths                    5
exploration/Average Returns           -213.879
evaluation/num steps total          279792
evaluation/num paths total            1392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.980957
evaluation/Rewards Std                   0.164532
evaluation/Rewards Max                  -0.66425
evaluation/Rewards Min                  -1.69721
evaluation/Returns Mean               -197.172
evaluation/Returns Std                  17.5981
evaluation/Returns Max                -167.919
evaluation/Returns Min                -226.154
evaluation/Actions Mean                 -0.148767
evaluation/Actions Std                   0.687134
evaluation/Actions Max                   0.999271
evaluation/Actions Min                  -0.996833
evaluation/Num Paths                    24
evaluation/Average Returns            -197.172
time/data storing (s)                    0.0112181
time/evaluation sampling (s)           640.996
time/exploration sampling (s)          147.753
time/logging (s)                         0.0409782
time/sac training (s)                   11.802
time/saving (s)                          0.0396916
time/training (s)                        0.000135847
time/epoch (s)                         800.643
time/total (s)                       40080.7
Epoch                                   57
----------------------------------  ----------------
2020-11-01 21:13:23.646202 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 58 finished
----------------------------------  ----------------
replay_buffer/size                   60000
trainer/num train calls              59000
trainer/QF1 Loss                        21.7071
trainer/QF2 Loss                        21.356
trainer/Policy Loss                    128.347
trainer/Q1 Predictions Mean           -127.783
trainer/Q1 Predictions Std              36.5683
trainer/Q1 Predictions Max              15.2922
trainer/Q1 Predictions Min            -188.059
trainer/Q2 Predictions Mean           -127.622
trainer/Q2 Predictions Std              36.557
trainer/Q2 Predictions Max              14.6103
trainer/Q2 Predictions Min            -189.547
trainer/Q Targets Mean                -127.201
trainer/Q Targets Std                   36.8027
trainer/Q Targets Max                   11.6506
trainer/Q Targets Min                 -186.304
trainer/Log Pis Mean                     1.96846
trainer/Log Pis Std                      2.19364
trainer/Log Pis Max                      7.82709
trainer/Log Pis Min                     -4.39989
trainer/policy/mean Mean                -0.300898
trainer/policy/mean Std                  0.789636
trainer/policy/mean Max                  0.999386
trainer/policy/mean Min                 -0.995466
trainer/policy/normal/std Mean           0.63538
trainer/policy/normal/std Std            0.0793843
trainer/policy/normal/std Max            0.99961
trainer/policy/normal/std Min            0.420314
trainer/policy/normal/log_std Mean      -0.461264
trainer/policy/normal/log_std Std        0.12432
trainer/policy/normal/log_std Max       -0.000390189
trainer/policy/normal/log_std Min       -0.866752
trainer/Alpha                            0.0507433
trainer/Alpha Loss                      -0.0940078
exploration/num steps total          60000
exploration/num paths total            300
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.874267
exploration/Rewards Std                  0.182021
exploration/Rewards Max                 -0.506033
exploration/Rewards Min                 -1.38145
exploration/Returns Mean              -174.853
exploration/Returns Std                 20.8868
exploration/Returns Max               -153.447
exploration/Returns Min               -204.554
exploration/Actions Mean                -0.175396
exploration/Actions Std                  0.761111
exploration/Actions Max                  0.999964
exploration/Actions Min                 -0.99954
exploration/Num Paths                    5
exploration/Average Returns           -174.853
evaluation/num steps total          284616
evaluation/num paths total            1416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.961584
evaluation/Rewards Std                   0.174925
evaluation/Rewards Max                  -0.628704
evaluation/Rewards Min                  -1.60053
evaluation/Returns Mean               -193.278
evaluation/Returns Std                  19.7577
evaluation/Returns Max                -161.182
evaluation/Returns Min                -236.343
evaluation/Actions Mean                 -0.185236
evaluation/Actions Std                   0.678437
evaluation/Actions Max                   0.999012
evaluation/Actions Min                  -0.99423
evaluation/Num Paths                    24
evaluation/Average Returns            -193.278
time/data storing (s)                    0.0151903
time/evaluation sampling (s)           654.06
time/exploration sampling (s)          129.602
time/logging (s)                         0.048336
time/sac training (s)                   12.5631
time/saving (s)                          0.0493951
time/training (s)                        0.000138209
time/epoch (s)                         796.339
time/total (s)                       40878.2
Epoch                                   58
----------------------------------  ----------------
2020-11-01 21:26:01.791857 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 59 finished
----------------------------------  ----------------
replay_buffer/size                   61000
trainer/num train calls              60000
trainer/QF1 Loss                        23.7968
trainer/QF2 Loss                        22.9672
trainer/Policy Loss                    128.147
trainer/Q1 Predictions Mean           -127.421
trainer/Q1 Predictions Std              33.2736
trainer/Q1 Predictions Max             -47.4083
trainer/Q1 Predictions Min            -184.872
trainer/Q2 Predictions Mean           -127.374
trainer/Q2 Predictions Std              33.2874
trainer/Q2 Predictions Max             -45.6639
trainer/Q2 Predictions Min            -186.118
trainer/Q Targets Mean                -128.845
trainer/Q Targets Std                   33.7078
trainer/Q Targets Max                  -44.0511
trainer/Q Targets Min                 -191.2
trainer/Log Pis Mean                     2.17482
trainer/Log Pis Std                      2.11757
trainer/Log Pis Max                      7.9864
trainer/Log Pis Min                     -5.37219
trainer/policy/mean Mean                -0.19243
trainer/policy/mean Std                  0.833106
trainer/policy/mean Max                  0.9924
trainer/policy/mean Min                 -0.996499
trainer/policy/normal/std Mean           0.633878
trainer/policy/normal/std Std            0.0861507
trainer/policy/normal/std Max            0.923065
trainer/policy/normal/std Min            0.425499
trainer/policy/normal/log_std Mean      -0.465193
trainer/policy/normal/log_std Std        0.136758
trainer/policy/normal/log_std Max       -0.0800561
trainer/policy/normal/log_std Min       -0.854493
trainer/Alpha                            0.0488218
trainer/Alpha Loss                       0.527886
exploration/num steps total          61000
exploration/num paths total            305
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01699
exploration/Rewards Std                  0.2207
exploration/Rewards Max                 -0.537572
exploration/Rewards Min                 -1.71029
exploration/Returns Mean              -203.397
exploration/Returns Std                 28.3993
exploration/Returns Max               -164.595
exploration/Returns Min               -239.529
exploration/Actions Mean                -0.434929
exploration/Actions Std                  0.651546
exploration/Actions Max                  0.999071
exploration/Actions Min                 -0.999873
exploration/Num Paths                    5
exploration/Average Returns           -203.397
evaluation/num steps total          289440
evaluation/num paths total            1440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95374
evaluation/Rewards Std                   0.189322
evaluation/Rewards Max                  -0.564912
evaluation/Rewards Min                  -1.63302
evaluation/Returns Mean               -191.702
evaluation/Returns Std                  20.9254
evaluation/Returns Max                -156.011
evaluation/Returns Min                -234.121
evaluation/Actions Mean                 -0.211625
evaluation/Actions Std                   0.664646
evaluation/Actions Max                   0.988366
evaluation/Actions Min                  -0.997587
evaluation/Num Paths                    24
evaluation/Average Returns            -191.702
time/data storing (s)                    0.015258
time/evaluation sampling (s)           610.057
time/exploration sampling (s)          134.136
time/logging (s)                         0.049331
time/sac training (s)                   12.7522
time/saving (s)                          0.0560318
time/training (s)                        0.000222197
time/epoch (s)                         757.066
time/total (s)                       41636.3
Epoch                                   59
----------------------------------  ----------------
2020-11-01 21:38:59.732908 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 60 finished
----------------------------------  ----------------
replay_buffer/size                   62000
trainer/num train calls              61000
trainer/QF1 Loss                        62.4822
trainer/QF2 Loss                        61.0434
trainer/Policy Loss                    128.726
trainer/Q1 Predictions Mean           -128.583
trainer/Q1 Predictions Std              36.7096
trainer/Q1 Predictions Max             -20.8002
trainer/Q1 Predictions Min            -191.249
trainer/Q2 Predictions Mean           -127.912
trainer/Q2 Predictions Std              36.6373
trainer/Q2 Predictions Max             -15.7302
trainer/Q2 Predictions Min            -189.2
trainer/Q Targets Mean                -128.685
trainer/Q Targets Std                   37.2948
trainer/Q Targets Max                   -0.868971
trainer/Q Targets Min                 -190.051
trainer/Log Pis Mean                     2.23823
trainer/Log Pis Std                      1.98623
trainer/Log Pis Max                      7.24985
trainer/Log Pis Min                     -6.58495
trainer/policy/mean Mean                -0.369163
trainer/policy/mean Std                  0.764917
trainer/policy/mean Max                  0.992256
trainer/policy/mean Min                 -0.994329
trainer/policy/normal/std Mean           0.637493
trainer/policy/normal/std Std            0.0949511
trainer/policy/normal/std Max            0.884389
trainer/policy/normal/std Min            0.436799
trainer/policy/normal/log_std Mean      -0.461336
trainer/policy/normal/log_std Std        0.149452
trainer/policy/normal/log_std Max       -0.122858
trainer/policy/normal/log_std Min       -0.828281
trainer/Alpha                            0.0497163
trainer/Alpha Loss                       0.715035
exploration/num steps total          62000
exploration/num paths total            310
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.882239
exploration/Rewards Std                  0.181578
exploration/Rewards Max                 -0.588772
exploration/Rewards Min                 -1.49676
exploration/Returns Mean              -176.448
exploration/Returns Std                 11.9096
exploration/Returns Max               -163.367
exploration/Returns Min               -194.882
exploration/Actions Mean                -0.208109
exploration/Actions Std                  0.723076
exploration/Actions Max                  0.999947
exploration/Actions Min                 -0.999685
exploration/Num Paths                    5
exploration/Average Returns           -176.448
evaluation/num steps total          294264
evaluation/num paths total            1464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.933444
evaluation/Rewards Std                   0.202387
evaluation/Rewards Max                  -0.562355
evaluation/Rewards Min                  -1.63699
evaluation/Returns Mean               -187.622
evaluation/Returns Std                  22.4479
evaluation/Returns Max                -153.584
evaluation/Returns Min                -241.487
evaluation/Actions Mean                 -0.311346
evaluation/Actions Std                   0.649553
evaluation/Actions Max                   0.997234
evaluation/Actions Min                  -0.999306
evaluation/Num Paths                    24
evaluation/Average Returns            -187.622
time/data storing (s)                    0.0125225
time/evaluation sampling (s)           635.804
time/exploration sampling (s)          128.978
time/logging (s)                         0.0486317
time/sac training (s)                   11.8913
time/saving (s)                          0.0473108
time/training (s)                        0.000151288
time/epoch (s)                         776.782
time/total (s)                       42414.2
Epoch                                   60
----------------------------------  ----------------
2020-11-01 21:51:14.873156 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 61 finished
----------------------------------  ----------------
replay_buffer/size                   63000
trainer/num train calls              62000
trainer/QF1 Loss                        24.5817
trainer/QF2 Loss                        31.9315
trainer/Policy Loss                    128.96
trainer/Q1 Predictions Mean           -128.53
trainer/Q1 Predictions Std              39.0251
trainer/Q1 Predictions Max               2.19067
trainer/Q1 Predictions Min            -193.063
trainer/Q2 Predictions Mean           -128.182
trainer/Q2 Predictions Std              39.317
trainer/Q2 Predictions Max               1.15927
trainer/Q2 Predictions Min            -192.88
trainer/Q Targets Mean                -127.725
trainer/Q Targets Std                   38.3767
trainer/Q Targets Max                   -0.760915
trainer/Q Targets Min                 -191.87
trainer/Log Pis Mean                     1.89297
trainer/Log Pis Std                      2.34305
trainer/Log Pis Max                      8.10399
trainer/Log Pis Min                     -5.33387
trainer/policy/mean Mean                -0.360032
trainer/policy/mean Std                  0.752383
trainer/policy/mean Max                  0.996849
trainer/policy/mean Min                 -0.9976
trainer/policy/normal/std Mean           0.648677
trainer/policy/normal/std Std            0.0830608
trainer/policy/normal/std Max            1.0125
trainer/policy/normal/std Min            0.415689
trainer/policy/normal/log_std Mean      -0.441001
trainer/policy/normal/log_std Std        0.128086
trainer/policy/normal/log_std Max        0.0124202
trainer/policy/normal/log_std Min       -0.877819
trainer/Alpha                            0.0480885
trainer/Alpha Loss                      -0.32482
exploration/num steps total          63000
exploration/num paths total            315
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.911817
exploration/Rewards Std                  0.217591
exploration/Rewards Max                 -0.535468
exploration/Rewards Min                 -1.41795
exploration/Returns Mean              -182.363
exploration/Returns Std                 28.4076
exploration/Returns Max               -143.045
exploration/Returns Min               -225.263
exploration/Actions Mean                -0.436276
exploration/Actions Std                  0.663104
exploration/Actions Max                  0.9989
exploration/Actions Min                 -0.999794
exploration/Num Paths                    5
exploration/Average Returns           -182.363
evaluation/num steps total          299088
evaluation/num paths total            1488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.968994
evaluation/Rewards Std                   0.202054
evaluation/Rewards Max                  -0.592738
evaluation/Rewards Min                  -1.63999
evaluation/Returns Mean               -194.768
evaluation/Returns Std                  25.0299
evaluation/Returns Max                -153.481
evaluation/Returns Min                -270.138
evaluation/Actions Mean                 -0.226374
evaluation/Actions Std                   0.678227
evaluation/Actions Max                   0.999976
evaluation/Actions Min                  -0.999874
evaluation/Num Paths                    24
evaluation/Average Returns            -194.768
time/data storing (s)                    0.0105696
time/evaluation sampling (s)           589.544
time/exploration sampling (s)          130.68
time/logging (s)                         0.0278429
time/sac training (s)                   13.6741
time/saving (s)                          0.0545249
time/training (s)                        0.000129324
time/epoch (s)                         733.99
time/total (s)                       43149.2
Epoch                                   61
----------------------------------  ----------------
2020-11-01 22:04:39.516553 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 62 finished
----------------------------------  ---------------
replay_buffer/size                   64000
trainer/num train calls              63000
trainer/QF1 Loss                        32.9879
trainer/QF2 Loss                        37.3439
trainer/Policy Loss                    129.456
trainer/Q1 Predictions Mean           -128.368
trainer/Q1 Predictions Std              37.0051
trainer/Q1 Predictions Max             -31.9454
trainer/Q1 Predictions Min            -191.123
trainer/Q2 Predictions Mean           -129.101
trainer/Q2 Predictions Std              37.2884
trainer/Q2 Predictions Max             -32.1557
trainer/Q2 Predictions Min            -192.092
trainer/Q Targets Mean                -129.642
trainer/Q Targets Std                   38.3322
trainer/Q Targets Max                   -0.724092
trainer/Q Targets Min                 -191.507
trainer/Log Pis Mean                     1.94662
trainer/Log Pis Std                      2.23117
trainer/Log Pis Max                      7.97408
trainer/Log Pis Min                     -3.4183
trainer/policy/mean Mean                -0.319774
trainer/policy/mean Std                  0.786725
trainer/policy/mean Max                  0.99626
trainer/policy/mean Min                 -0.996624
trainer/policy/normal/std Mean           0.65328
trainer/policy/normal/std Std            0.08455
trainer/policy/normal/std Max            0.960163
trainer/policy/normal/std Min            0.40246
trainer/policy/normal/log_std Mean      -0.434254
trainer/policy/normal/log_std Std        0.131268
trainer/policy/normal/log_std Max       -0.0406518
trainer/policy/normal/log_std Min       -0.91016
trainer/Alpha                            0.0510371
trainer/Alpha Loss                      -0.158803
exploration/num steps total          64000
exploration/num paths total            320
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.982359
exploration/Rewards Std                  0.151454
exploration/Rewards Max                 -0.637267
exploration/Rewards Min                 -1.56215
exploration/Returns Mean              -196.472
exploration/Returns Std                  6.50019
exploration/Returns Max               -190.518
exploration/Returns Min               -208.969
exploration/Actions Mean                -0.12253
exploration/Actions Std                  0.701607
exploration/Actions Max                  0.998143
exploration/Actions Min                 -0.999726
exploration/Num Paths                    5
exploration/Average Returns           -196.472
evaluation/num steps total          303912
evaluation/num paths total            1512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.950751
evaluation/Rewards Std                   0.190052
evaluation/Rewards Max                  -0.574021
evaluation/Rewards Min                  -1.7285
evaluation/Returns Mean               -191.101
evaluation/Returns Std                  20.295
evaluation/Returns Max                -156.316
evaluation/Returns Min                -240.399
evaluation/Actions Mean                 -0.23114
evaluation/Actions Std                   0.646837
evaluation/Actions Max                   0.999298
evaluation/Actions Min                  -0.996145
evaluation/Num Paths                    24
evaluation/Average Returns            -191.101
time/data storing (s)                    0.0131612
time/evaluation sampling (s)           638.777
time/exploration sampling (s)          153.047
time/logging (s)                         0.056554
time/sac training (s)                   11.6613
time/saving (s)                          0.0390143
time/training (s)                        0.00017332
time/epoch (s)                         803.595
time/total (s)                       43953.9
Epoch                                   62
----------------------------------  ---------------
2020-11-01 22:17:12.542013 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 63 finished
----------------------------------  ----------------
replay_buffer/size                   65000
trainer/num train calls              64000
trainer/QF1 Loss                       129.577
trainer/QF2 Loss                       138.526
trainer/Policy Loss                    132.295
trainer/Q1 Predictions Mean           -131.911
trainer/Q1 Predictions Std              35.6479
trainer/Q1 Predictions Max               2.19903
trainer/Q1 Predictions Min            -195.236
trainer/Q2 Predictions Mean           -131.098
trainer/Q2 Predictions Std              36.1872
trainer/Q2 Predictions Max               2.4308
trainer/Q2 Predictions Min            -193.301
trainer/Q Targets Mean                -130.126
trainer/Q Targets Std                   37.371
trainer/Q Targets Max                    2.26443
trainer/Q Targets Min                 -192.401
trainer/Log Pis Mean                     1.97142
trainer/Log Pis Std                      1.96489
trainer/Log Pis Max                      8.07775
trainer/Log Pis Min                     -5.82455
trainer/policy/mean Mean                -0.330869
trainer/policy/mean Std                  0.765398
trainer/policy/mean Max                  0.997021
trainer/policy/mean Min                 -0.995469
trainer/policy/normal/std Mean           0.634742
trainer/policy/normal/std Std            0.0853411
trainer/policy/normal/std Max            0.980502
trainer/policy/normal/std Min            0.409914
trainer/policy/normal/log_std Mean      -0.463487
trainer/policy/normal/log_std Std        0.133792
trainer/policy/normal/log_std Max       -0.0196907
trainer/policy/normal/log_std Min       -0.891808
trainer/Alpha                            0.0499399
trainer/Alpha Loss                      -0.0856608
exploration/num steps total          65000
exploration/num paths total            325
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.883131
exploration/Rewards Std                  0.211806
exploration/Rewards Max                 -0.48129
exploration/Rewards Min                 -1.61362
exploration/Returns Mean              -176.626
exploration/Returns Std                 22.6993
exploration/Returns Max               -149.286
exploration/Returns Min               -215.252
exploration/Actions Mean                -0.348423
exploration/Actions Std                  0.703793
exploration/Actions Max                  0.996414
exploration/Actions Min                 -0.99972
exploration/Num Paths                    5
exploration/Average Returns           -176.626
evaluation/num steps total          308736
evaluation/num paths total            1536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.938586
evaluation/Rewards Std                   0.188543
evaluation/Rewards Max                  -0.554262
evaluation/Rewards Min                  -1.68177
evaluation/Returns Mean               -188.656
evaluation/Returns Std                  19.5566
evaluation/Returns Max                -153.915
evaluation/Returns Min                -249.868
evaluation/Actions Mean                 -0.24507
evaluation/Actions Std                   0.667608
evaluation/Actions Max                   0.998096
evaluation/Actions Min                  -0.996274
evaluation/Num Paths                    24
evaluation/Average Returns            -188.656
time/data storing (s)                    0.0125967
time/evaluation sampling (s)           619.253
time/exploration sampling (s)          120.538
time/logging (s)                         0.0416917
time/sac training (s)                   12.0588
time/saving (s)                          0.0402006
time/training (s)                        0.000133137
time/epoch (s)                         751.945
time/total (s)                       44706.9
Epoch                                   63
----------------------------------  ----------------
2020-11-01 22:29:42.010721 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 64 finished
----------------------------------  ----------------
replay_buffer/size                   66000
trainer/num train calls              65000
trainer/QF1 Loss                        24.0325
trainer/QF2 Loss                        20.4842
trainer/Policy Loss                    130.162
trainer/Q1 Predictions Mean           -129.576
trainer/Q1 Predictions Std              35.1277
trainer/Q1 Predictions Max             -33.5246
trainer/Q1 Predictions Min            -193.172
trainer/Q2 Predictions Mean           -129.424
trainer/Q2 Predictions Std              35.1321
trainer/Q2 Predictions Max             -38.1103
trainer/Q2 Predictions Min            -191.114
trainer/Q Targets Mean                -129.843
trainer/Q Targets Std                   35.5272
trainer/Q Targets Max                  -31.6261
trainer/Q Targets Min                 -195.487
trainer/Log Pis Mean                     1.68261
trainer/Log Pis Std                      2.19261
trainer/Log Pis Max                      7.24697
trainer/Log Pis Min                     -4.70971
trainer/policy/mean Mean                -0.281203
trainer/policy/mean Std                  0.775682
trainer/policy/mean Max                  0.999472
trainer/policy/mean Min                 -0.991554
trainer/policy/normal/std Mean           0.660536
trainer/policy/normal/std Std            0.0793692
trainer/policy/normal/std Max            0.966098
trainer/policy/normal/std Min            0.40641
trainer/policy/normal/log_std Mean      -0.422024
trainer/policy/normal/log_std Std        0.121749
trainer/policy/normal/log_std Max       -0.0344901
trainer/policy/normal/log_std Min       -0.900392
trainer/Alpha                            0.0487721
trainer/Alpha Loss                      -0.958719
exploration/num steps total          66000
exploration/num paths total            330
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.880888
exploration/Rewards Std                  0.189167
exploration/Rewards Max                 -0.540423
exploration/Rewards Min                 -1.47383
exploration/Returns Mean              -176.178
exploration/Returns Std                 13.8386
exploration/Returns Max               -159.06
exploration/Returns Min               -200.887
exploration/Actions Mean                -0.36339
exploration/Actions Std                  0.675909
exploration/Actions Max                  0.999169
exploration/Actions Min                 -0.9987
exploration/Num Paths                    5
exploration/Average Returns           -176.178
evaluation/num steps total          313560
evaluation/num paths total            1560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.968576
evaluation/Rewards Std                   0.207748
evaluation/Rewards Max                  -0.552824
evaluation/Rewards Min                  -1.69974
evaluation/Returns Mean               -194.684
evaluation/Returns Std                  21.4497
evaluation/Returns Max                -160.625
evaluation/Returns Min                -250.826
evaluation/Actions Mean                 -0.240415
evaluation/Actions Std                   0.687025
evaluation/Actions Max                   0.99388
evaluation/Actions Min                  -0.995023
evaluation/Num Paths                    24
evaluation/Average Returns            -194.684
time/data storing (s)                    0.0131752
time/evaluation sampling (s)           596.258
time/exploration sampling (s)          140.212
time/logging (s)                         0.0316173
time/sac training (s)                   11.8535
time/saving (s)                          0.0580321
time/training (s)                        0.000138345
time/epoch (s)                         748.427
time/total (s)                       45456.3
Epoch                                   64
----------------------------------  ----------------
2020-11-01 22:42:32.695008 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 65 finished
----------------------------------  ----------------
replay_buffer/size                   67000
trainer/num train calls              66000
trainer/QF1 Loss                        59.2311
trainer/QF2 Loss                        61.8675
trainer/Policy Loss                    131.743
trainer/Q1 Predictions Mean           -130.987
trainer/Q1 Predictions Std              39.6437
trainer/Q1 Predictions Max             -14.5516
trainer/Q1 Predictions Min            -198.868
trainer/Q2 Predictions Mean           -131.247
trainer/Q2 Predictions Std              39.6777
trainer/Q2 Predictions Max             -16.1478
trainer/Q2 Predictions Min            -196.832
trainer/Q Targets Mean                -130.699
trainer/Q Targets Std                   40.7379
trainer/Q Targets Max                   -0.917497
trainer/Q Targets Min                 -194.846
trainer/Log Pis Mean                     2.15832
trainer/Log Pis Std                      2.26737
trainer/Log Pis Max                      9.65969
trainer/Log Pis Min                     -3.16333
trainer/policy/mean Mean                -0.0557312
trainer/policy/mean Std                  0.848629
trainer/policy/mean Max                  0.999222
trainer/policy/mean Min                 -0.990237
trainer/policy/normal/std Mean           0.645081
trainer/policy/normal/std Std            0.078433
trainer/policy/normal/std Max            0.970151
trainer/policy/normal/std Min            0.42222
trainer/policy/normal/log_std Mean      -0.445721
trainer/policy/normal/log_std Std        0.121275
trainer/policy/normal/log_std Max       -0.0303037
trainer/policy/normal/log_std Min       -0.862228
trainer/Alpha                            0.0498967
trainer/Alpha Loss                       0.474626
exploration/num steps total          67000
exploration/num paths total            335
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.09602
exploration/Rewards Std                  0.187793
exploration/Rewards Max                 -0.806727
exploration/Rewards Min                 -1.71695
exploration/Returns Mean              -219.204
exploration/Returns Std                 17.8363
exploration/Returns Max               -194.053
exploration/Returns Min               -243.164
exploration/Actions Mean                 0.0703909
exploration/Actions Std                  0.719127
exploration/Actions Max                  0.999809
exploration/Actions Min                 -0.998051
exploration/Num Paths                    5
exploration/Average Returns           -219.204
evaluation/num steps total          318384
evaluation/num paths total            1584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.988723
evaluation/Rewards Std                   0.20509
evaluation/Rewards Max                  -0.567895
evaluation/Rewards Min                  -1.72862
evaluation/Returns Mean               -198.733
evaluation/Returns Std                  22.3922
evaluation/Returns Max                -166.37
evaluation/Returns Min                -242.955
evaluation/Actions Mean                 -0.221482
evaluation/Actions Std                   0.68641
evaluation/Actions Max                   0.999177
evaluation/Actions Min                  -0.996854
evaluation/Num Paths                    24
evaluation/Average Returns            -198.733
time/data storing (s)                    0.0100349
time/evaluation sampling (s)           613.225
time/exploration sampling (s)          144.654
time/logging (s)                         0.028207
time/sac training (s)                   11.6988
time/saving (s)                          0.0423222
time/training (s)                        0.000162321
time/epoch (s)                         769.659
time/total (s)                       46226.9
Epoch                                   65
----------------------------------  ----------------
2020-11-01 22:54:54.788873 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 66 finished
----------------------------------  ----------------
replay_buffer/size                   68000
trainer/num train calls              67000
trainer/QF1 Loss                        30.1988
trainer/QF2 Loss                        27.8784
trainer/Policy Loss                    131.185
trainer/Q1 Predictions Mean           -130.571
trainer/Q1 Predictions Std              37.9491
trainer/Q1 Predictions Max              12.2853
trainer/Q1 Predictions Min            -195.562
trainer/Q2 Predictions Mean           -130.4
trainer/Q2 Predictions Std              37.8852
trainer/Q2 Predictions Max               8.60252
trainer/Q2 Predictions Min            -198.734
trainer/Q Targets Mean                -130.311
trainer/Q Targets Std                   37.7099
trainer/Q Targets Max                   12.234
trainer/Q Targets Min                 -195.744
trainer/Log Pis Mean                     1.87244
trainer/Log Pis Std                      1.97165
trainer/Log Pis Max                      6.98278
trainer/Log Pis Min                     -3.4313
trainer/policy/mean Mean                -0.376605
trainer/policy/mean Std                  0.721218
trainer/policy/mean Max                  0.998983
trainer/policy/mean Min                 -0.992041
trainer/policy/normal/std Mean           0.636473
trainer/policy/normal/std Std            0.0859967
trainer/policy/normal/std Max            0.969707
trainer/policy/normal/std Min            0.377348
trainer/policy/normal/log_std Mean      -0.46094
trainer/policy/normal/log_std Std        0.135473
trainer/policy/normal/log_std Max       -0.0307615
trainer/policy/normal/log_std Min       -0.974587
trainer/Alpha                            0.0487903
trainer/Alpha Loss                      -0.385274
exploration/num steps total          68000
exploration/num paths total            340
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.996846
exploration/Rewards Std                  0.239468
exploration/Rewards Max                 -0.508127
exploration/Rewards Min                 -1.5347
exploration/Returns Mean              -199.369
exploration/Returns Std                 32.2571
exploration/Returns Max               -157.621
exploration/Returns Min               -242.803
exploration/Actions Mean                -0.25993
exploration/Actions Std                  0.662416
exploration/Actions Max                  0.999144
exploration/Actions Min                 -0.999654
exploration/Num Paths                    5
exploration/Average Returns           -199.369
evaluation/num steps total          323208
evaluation/num paths total            1608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.964493
evaluation/Rewards Std                   0.23457
evaluation/Rewards Max                  -0.564801
evaluation/Rewards Min                  -1.92163
evaluation/Returns Mean               -193.863
evaluation/Returns Std                  36.2753
evaluation/Returns Max                -155.751
evaluation/Returns Min                -313.618
evaluation/Actions Mean                 -0.269853
evaluation/Actions Std                   0.673493
evaluation/Actions Max                   0.999008
evaluation/Actions Min                  -0.995355
evaluation/Num Paths                    24
evaluation/Average Returns            -193.863
time/data storing (s)                    0.0107824
time/evaluation sampling (s)           581.766
time/exploration sampling (s)          147.533
time/logging (s)                         0.0322373
time/sac training (s)                   11.8896
time/saving (s)                          0.0279449
time/training (s)                        0.000163604
time/epoch (s)                         741.259
time/total (s)                       46969
Epoch                                   66
----------------------------------  ----------------
2020-11-01 23:08:21.073196 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 67 finished
----------------------------------  ----------------
replay_buffer/size                   69000
trainer/num train calls              68000
trainer/QF1 Loss                        52.2766
trainer/QF2 Loss                        52.0302
trainer/Policy Loss                    132.23
trainer/Q1 Predictions Mean           -131.648
trainer/Q1 Predictions Std              36.1872
trainer/Q1 Predictions Max             -36.5123
trainer/Q1 Predictions Min            -197.211
trainer/Q2 Predictions Mean           -131.355
trainer/Q2 Predictions Std              36.2678
trainer/Q2 Predictions Max             -37.7293
trainer/Q2 Predictions Min            -197.99
trainer/Q Targets Mean                -130.647
trainer/Q Targets Std                   36.4007
trainer/Q Targets Max                   -1.11032
trainer/Q Targets Min                 -201.428
trainer/Log Pis Mean                     1.8262
trainer/Log Pis Std                      2.28853
trainer/Log Pis Max                      9.8932
trainer/Log Pis Min                     -4.59148
trainer/policy/mean Mean                -0.267281
trainer/policy/mean Std                  0.769539
trainer/policy/mean Max                  0.999534
trainer/policy/mean Min                 -0.99631
trainer/policy/normal/std Mean           0.640002
trainer/policy/normal/std Std            0.0870765
trainer/policy/normal/std Max            0.968334
trainer/policy/normal/std Min            0.44538
trainer/policy/normal/log_std Mean      -0.455523
trainer/policy/normal/log_std Std        0.136091
trainer/policy/normal/log_std Max       -0.0321784
trainer/policy/normal/log_std Min       -0.808828
trainer/Alpha                            0.0465021
trainer/Alpha Loss                      -0.533275
exploration/num steps total          69000
exploration/num paths total            345
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.05221
exploration/Rewards Std                  0.179235
exploration/Rewards Max                 -0.806702
exploration/Rewards Min                 -1.51616
exploration/Returns Mean              -210.443
exploration/Returns Std                 24.7761
exploration/Returns Max               -191.164
exploration/Returns Min               -257.145
exploration/Actions Mean                 0.0989584
exploration/Actions Std                  0.714825
exploration/Actions Max                  0.999852
exploration/Actions Min                 -0.997766
exploration/Num Paths                    5
exploration/Average Returns           -210.443
evaluation/num steps total          328032
evaluation/num paths total            1632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.975123
evaluation/Rewards Std                   0.189964
evaluation/Rewards Max                  -0.568577
evaluation/Rewards Min                  -1.63652
evaluation/Returns Mean               -196
evaluation/Returns Std                  23.838
evaluation/Returns Max                -158.331
evaluation/Returns Min                -240.424
evaluation/Actions Mean                 -0.170227
evaluation/Actions Std                   0.695661
evaluation/Actions Max                   0.999945
evaluation/Actions Min                  -0.993785
evaluation/Num Paths                    24
evaluation/Average Returns            -196
time/data storing (s)                    0.0140016
time/evaluation sampling (s)           643.933
time/exploration sampling (s)          151.339
time/logging (s)                         0.0382125
time/sac training (s)                    9.98906
time/saving (s)                          0.0365975
time/training (s)                        0.000138661
time/epoch (s)                         805.35
time/total (s)                       47775.3
Epoch                                   67
----------------------------------  ----------------
2020-11-01 23:19:05.450674 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 68 finished
----------------------------------  ----------------
replay_buffer/size                   70000
trainer/num train calls              69000
trainer/QF1 Loss                        54.3418
trainer/QF2 Loss                        56.1706
trainer/Policy Loss                    131.253
trainer/Q1 Predictions Mean           -130.75
trainer/Q1 Predictions Std              40.606
trainer/Q1 Predictions Max               0.333245
trainer/Q1 Predictions Min            -200.545
trainer/Q2 Predictions Mean           -130.402
trainer/Q2 Predictions Std              40.3789
trainer/Q2 Predictions Max              -1.06513
trainer/Q2 Predictions Min            -200.978
trainer/Q Targets Mean                -131.192
trainer/Q Targets Std                   41.748
trainer/Q Targets Max                    5.753
trainer/Q Targets Min                 -198.344
trainer/Log Pis Mean                     2.44539
trainer/Log Pis Std                      2.13685
trainer/Log Pis Max                      8.95184
trainer/Log Pis Min                     -2.67713
trainer/policy/mean Mean                -0.0455046
trainer/policy/mean Std                  0.865587
trainer/policy/mean Max                  0.998909
trainer/policy/mean Min                 -0.998148
trainer/policy/normal/std Mean           0.638714
trainer/policy/normal/std Std            0.0703163
trainer/policy/normal/std Max            0.998852
trainer/policy/normal/std Min            0.417631
trainer/policy/normal/log_std Mean      -0.45437
trainer/policy/normal/log_std Std        0.11058
trainer/policy/normal/log_std Max       -0.0011487
trainer/policy/normal/log_std Min       -0.873157
trainer/Alpha                            0.0478046
trainer/Alpha Loss                       1.35426
exploration/num steps total          70000
exploration/num paths total            350
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.983286
exploration/Rewards Std                  0.194182
exploration/Rewards Max                 -0.650259
exploration/Rewards Min                 -1.55767
exploration/Returns Mean              -196.657
exploration/Returns Std                 17.8533
exploration/Returns Max               -175.588
exploration/Returns Min               -219.72
exploration/Actions Mean                -0.183414
exploration/Actions Std                  0.719957
exploration/Actions Max                  0.995986
exploration/Actions Min                 -0.998877
exploration/Num Paths                    5
exploration/Average Returns           -196.657
evaluation/num steps total          332856
evaluation/num paths total            1656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.999024
evaluation/Rewards Std                   0.211427
evaluation/Rewards Max                  -0.530565
evaluation/Rewards Min                  -1.6401
evaluation/Returns Mean               -200.804
evaluation/Returns Std                  24.328
evaluation/Returns Max                -168.993
evaluation/Returns Min                -243.345
evaluation/Actions Mean                 -0.264779
evaluation/Actions Std                   0.688204
evaluation/Actions Max                   0.999463
evaluation/Actions Min                  -0.99318
evaluation/Num Paths                    24
evaluation/Average Returns            -200.804
time/data storing (s)                    0.00964759
time/evaluation sampling (s)           519.529
time/exploration sampling (s)          114.443
time/logging (s)                         0.0392725
time/sac training (s)                    9.3443
time/saving (s)                          0.0442317
time/training (s)                        0.000135399
time/epoch (s)                         643.41
time/total (s)                       48419.6
Epoch                                   68
----------------------------------  ----------------
2020-11-01 23:29:22.835454 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 69 finished
----------------------------------  ----------------
replay_buffer/size                   71000
trainer/num train calls              70000
trainer/QF1 Loss                        96.2187
trainer/QF2 Loss                        99.8751
trainer/Policy Loss                    134.601
trainer/Q1 Predictions Mean           -134.19
trainer/Q1 Predictions Std              38.4206
trainer/Q1 Predictions Max             -19.1832
trainer/Q1 Predictions Min            -196.489
trainer/Q2 Predictions Mean           -133.944
trainer/Q2 Predictions Std              38.4734
trainer/Q2 Predictions Max             -18.5529
trainer/Q2 Predictions Min            -197.509
trainer/Q Targets Mean                -134.646
trainer/Q Targets Std                   39.4724
trainer/Q Targets Max                   -0.965207
trainer/Q Targets Min                 -200.858
trainer/Log Pis Mean                     2.2201
trainer/Log Pis Std                      2.21696
trainer/Log Pis Max                      8.66395
trainer/Log Pis Min                     -4.12141
trainer/policy/mean Mean                -0.1864
trainer/policy/mean Std                  0.819266
trainer/policy/mean Max                  0.995874
trainer/policy/mean Min                 -0.994035
trainer/policy/normal/std Mean           0.629753
trainer/policy/normal/std Std            0.0797577
trainer/policy/normal/std Max            0.948751
trainer/policy/normal/std Min            0.429396
trainer/policy/normal/log_std Mean      -0.470288
trainer/policy/normal/log_std Std        0.125033
trainer/policy/normal/log_std Max       -0.0526085
trainer/policy/normal/log_std Min       -0.845377
trainer/Alpha                            0.0477687
trainer/Alpha Loss                       0.669404
exploration/num steps total          71000
exploration/num paths total            355
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.966028
exploration/Rewards Std                  0.226874
exploration/Rewards Max                 -0.611391
exploration/Rewards Min                 -1.60033
exploration/Returns Mean              -193.206
exploration/Returns Std                 19.7859
exploration/Returns Max               -167.71
exploration/Returns Min               -227.615
exploration/Actions Mean                -0.404457
exploration/Actions Std                  0.683221
exploration/Actions Max                  0.997288
exploration/Actions Min                 -0.999791
exploration/Num Paths                    5
exploration/Average Returns           -193.206
evaluation/num steps total          337680
evaluation/num paths total            1680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.985036
evaluation/Rewards Std                   0.214217
evaluation/Rewards Max                  -0.583746
evaluation/Rewards Min                  -1.74369
evaluation/Returns Mean               -197.992
evaluation/Returns Std                  29.4315
evaluation/Returns Max                -162.497
evaluation/Returns Min                -294.486
evaluation/Actions Mean                 -0.238045
evaluation/Actions Std                   0.666671
evaluation/Actions Max                   0.999981
evaluation/Actions Min                  -0.995566
evaluation/Num Paths                    24
evaluation/Average Returns            -197.992
time/data storing (s)                    0.00879754
time/evaluation sampling (s)           506.839
time/exploration sampling (s)           95.9754
time/logging (s)                         0.0370466
time/sac training (s)                   13.295
time/saving (s)                          0.0465506
time/training (s)                        0.000160988
time/epoch (s)                         616.202
time/total (s)                       49037
Epoch                                   69
----------------------------------  ----------------
2020-11-01 23:39:38.922766 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 70 finished
----------------------------------  ----------------
replay_buffer/size                   72000
trainer/num train calls              71000
trainer/QF1 Loss                       161.753
trainer/QF2 Loss                       167.546
trainer/Policy Loss                    137.9
trainer/Q1 Predictions Mean           -136.87
trainer/Q1 Predictions Std              37.727
trainer/Q1 Predictions Max             -32.3922
trainer/Q1 Predictions Min            -199.812
trainer/Q2 Predictions Mean           -137.452
trainer/Q2 Predictions Std              37.9577
trainer/Q2 Predictions Max             -34.1045
trainer/Q2 Predictions Min            -201.426
trainer/Q Targets Mean                -136.617
trainer/Q Targets Std                   40.9076
trainer/Q Targets Max                   -0.837349
trainer/Q Targets Min                 -203.984
trainer/Log Pis Mean                     2.03056
trainer/Log Pis Std                      1.945
trainer/Log Pis Max                      8.85949
trainer/Log Pis Min                     -3.88608
trainer/policy/mean Mean                -0.118047
trainer/policy/mean Std                  0.813952
trainer/policy/mean Max                  0.997956
trainer/policy/mean Min                 -0.993464
trainer/policy/normal/std Mean           0.635399
trainer/policy/normal/std Std            0.0867207
trainer/policy/normal/std Max            0.967283
trainer/policy/normal/std Min            0.424444
trainer/policy/normal/log_std Mean      -0.462696
trainer/policy/normal/log_std Std        0.135433
trainer/policy/normal/log_std Max       -0.0332645
trainer/policy/normal/log_std Min       -0.856976
trainer/Alpha                            0.045739
trainer/Alpha Loss                       0.0942736
exploration/num steps total          72000
exploration/num paths total            360
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.91809
exploration/Rewards Std                  0.174266
exploration/Rewards Max                 -0.673835
exploration/Rewards Min                 -1.55451
exploration/Returns Mean              -183.618
exploration/Returns Std                 17.441
exploration/Returns Max               -167.959
exploration/Returns Min               -217.628
exploration/Actions Mean                -0.188373
exploration/Actions Std                  0.749489
exploration/Actions Max                  0.998239
exploration/Actions Min                 -0.999727
exploration/Num Paths                    5
exploration/Average Returns           -183.618
evaluation/num steps total          342504
evaluation/num paths total            1704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.05605
evaluation/Rewards Std                   0.220218
evaluation/Rewards Max                  -0.611143
evaluation/Rewards Min                  -1.75331
evaluation/Returns Mean               -212.267
evaluation/Returns Std                  34.8021
evaluation/Returns Max                -156.401
evaluation/Returns Min                -309.195
evaluation/Actions Mean                 -0.102043
evaluation/Actions Std                   0.708747
evaluation/Actions Max                   0.999637
evaluation/Actions Min                  -0.998601
evaluation/Num Paths                    24
evaluation/Average Returns            -212.267
time/data storing (s)                    0.0103304
time/evaluation sampling (s)           499.009
time/exploration sampling (s)          106.857
time/logging (s)                         0.0249132
time/sac training (s)                    9.23493
time/saving (s)                          0.0362383
time/training (s)                        0.000136351
time/epoch (s)                         615.172
time/total (s)                       49653
Epoch                                   70
----------------------------------  ----------------
2020-11-01 23:48:51.613953 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 71 finished
----------------------------------  ----------------
replay_buffer/size                   73000
trainer/num train calls              72000
trainer/QF1 Loss                        26.2489
trainer/QF2 Loss                        24.2408
trainer/Policy Loss                    135.18
trainer/Q1 Predictions Mean           -134.266
trainer/Q1 Predictions Std              40.9572
trainer/Q1 Predictions Max               6.86565
trainer/Q1 Predictions Min            -201.073
trainer/Q2 Predictions Mean           -134.903
trainer/Q2 Predictions Std              41.0558
trainer/Q2 Predictions Max              -6.47207
trainer/Q2 Predictions Min            -203.307
trainer/Q Targets Mean                -134.626
trainer/Q Targets Std                   40.4382
trainer/Q Targets Max                   -1.24003
trainer/Q Targets Min                 -199.837
trainer/Log Pis Mean                     2.06812
trainer/Log Pis Std                      1.99436
trainer/Log Pis Max                      8.79342
trainer/Log Pis Min                     -4.21345
trainer/policy/mean Mean                -0.324052
trainer/policy/mean Std                  0.775295
trainer/policy/mean Max                  0.998604
trainer/policy/mean Min                 -0.992539
trainer/policy/normal/std Mean           0.624611
trainer/policy/normal/std Std            0.0829241
trainer/policy/normal/std Max            0.8466
trainer/policy/normal/std Min            0.414576
trainer/policy/normal/log_std Mean      -0.47947
trainer/policy/normal/log_std Std        0.133261
trainer/policy/normal/log_std Max       -0.166527
trainer/policy/normal/log_std Min       -0.880498
trainer/Alpha                            0.0452221
trainer/Alpha Loss                       0.210922
exploration/num steps total          73000
exploration/num paths total            365
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.963578
exploration/Rewards Std                  0.181844
exploration/Rewards Max                 -0.648906
exploration/Rewards Min                 -1.50605
exploration/Returns Mean              -192.716
exploration/Returns Std                 19.8102
exploration/Returns Max               -164.268
exploration/Returns Min               -221.847
exploration/Actions Mean                -0.124067
exploration/Actions Std                  0.746199
exploration/Actions Max                  0.998737
exploration/Actions Min                 -0.999792
exploration/Num Paths                    5
exploration/Average Returns           -192.716
evaluation/num steps total          347328
evaluation/num paths total            1728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.925636
evaluation/Rewards Std                   0.217855
evaluation/Rewards Max                  -0.535012
evaluation/Rewards Min                  -1.78076
evaluation/Returns Mean               -186.053
evaluation/Returns Std                  27.5932
evaluation/Returns Max                -147.628
evaluation/Returns Min                -279.181
evaluation/Actions Mean                 -0.367491
evaluation/Actions Std                   0.636949
evaluation/Actions Max                   0.996977
evaluation/Actions Min                  -0.994591
evaluation/Num Paths                    24
evaluation/Average Returns            -186.053
time/data storing (s)                    0.0121377
time/evaluation sampling (s)           437.745
time/exploration sampling (s)          104.788
time/logging (s)                         0.0273185
time/sac training (s)                    9.43999
time/saving (s)                          0.0282024
time/training (s)                        0.000127053
time/epoch (s)                         552.041
time/total (s)                       50205.7
Epoch                                   71
----------------------------------  ----------------
2020-11-01 23:57:56.036969 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 72 finished
----------------------------------  ---------------
replay_buffer/size                   74000
trainer/num train calls              73000
trainer/QF1 Loss                        90.3992
trainer/QF2 Loss                        87.9165
trainer/Policy Loss                    136.927
trainer/Q1 Predictions Mean           -136.231
trainer/Q1 Predictions Std              38.0083
trainer/Q1 Predictions Max             -33.9404
trainer/Q1 Predictions Min            -202.63
trainer/Q2 Predictions Mean           -136.355
trainer/Q2 Predictions Std              37.7924
trainer/Q2 Predictions Max             -39.669
trainer/Q2 Predictions Min            -201.773
trainer/Q Targets Mean                -136.539
trainer/Q Targets Std                   38.6281
trainer/Q Targets Max                   -0.957261
trainer/Q Targets Min                 -202.666
trainer/Log Pis Mean                     2.28426
trainer/Log Pis Std                      2.31545
trainer/Log Pis Max                      8.014
trainer/Log Pis Min                     -9.68182
trainer/policy/mean Mean                -0.519073
trainer/policy/mean Std                  0.666063
trainer/policy/mean Max                  0.994552
trainer/policy/mean Min                 -0.998274
trainer/policy/normal/std Mean           0.624714
trainer/policy/normal/std Std            0.0873896
trainer/policy/normal/std Max            0.94023
trainer/policy/normal/std Min            0.373103
trainer/policy/normal/log_std Mean      -0.480305
trainer/policy/normal/log_std Std        0.140814
trainer/policy/normal/log_std Max       -0.061631
trainer/policy/normal/log_std Min       -0.985901
trainer/Alpha                            0.0471788
trainer/Alpha Loss                       0.868079
exploration/num steps total          74000
exploration/num paths total            370
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.867136
exploration/Rewards Std                  0.191953
exploration/Rewards Max                 -0.517914
exploration/Rewards Min                 -1.55493
exploration/Returns Mean              -173.427
exploration/Returns Std                 11.9469
exploration/Returns Max               -157.493
exploration/Returns Min               -187.551
exploration/Actions Mean                -0.481483
exploration/Actions Std                  0.621713
exploration/Actions Max                  0.997595
exploration/Actions Min                 -0.999524
exploration/Num Paths                    5
exploration/Average Returns           -173.427
evaluation/num steps total          352152
evaluation/num paths total            1752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.977554
evaluation/Rewards Std                   0.200354
evaluation/Rewards Max                  -0.608103
evaluation/Rewards Min                  -1.65535
evaluation/Returns Mean               -196.488
evaluation/Returns Std                  26.5517
evaluation/Returns Max                -154.55
evaluation/Returns Min                -260.104
evaluation/Actions Mean                 -0.304071
evaluation/Actions Std                   0.652886
evaluation/Actions Max                   0.997781
evaluation/Actions Min                  -0.997433
evaluation/Num Paths                    24
evaluation/Average Returns            -196.488
time/data storing (s)                    0.00643762
time/evaluation sampling (s)           437.648
time/exploration sampling (s)           96.6517
time/logging (s)                         0.0212016
time/sac training (s)                    9.40105
time/saving (s)                          0.0253089
time/training (s)                        0.00011928
time/epoch (s)                         543.754
time/total (s)                       50750.1
Epoch                                   72
----------------------------------  ---------------
2020-11-02 00:07:35.851710 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 73 finished
----------------------------------  ----------------
replay_buffer/size                   75000
trainer/num train calls              74000
trainer/QF1 Loss                        79.9354
trainer/QF2 Loss                        77.5989
trainer/Policy Loss                    138.949
trainer/Q1 Predictions Mean           -138.198
trainer/Q1 Predictions Std              41.4273
trainer/Q1 Predictions Max              -6.92531
trainer/Q1 Predictions Min            -203.712
trainer/Q2 Predictions Mean           -138.437
trainer/Q2 Predictions Std              41.4278
trainer/Q2 Predictions Max              -8.76163
trainer/Q2 Predictions Min            -203.06
trainer/Q Targets Mean                -137.661
trainer/Q Targets Std                   42.2137
trainer/Q Targets Max                   -0.850849
trainer/Q Targets Min                 -203.883
trainer/Log Pis Mean                     2.46233
trainer/Log Pis Std                      2.19532
trainer/Log Pis Max                      9.29839
trainer/Log Pis Min                     -3.35344
trainer/policy/mean Mean                -0.201872
trainer/policy/mean Std                  0.826471
trainer/policy/mean Max                  0.99916
trainer/policy/mean Min                 -0.996149
trainer/policy/normal/std Mean           0.608161
trainer/policy/normal/std Std            0.0854789
trainer/policy/normal/std Max            0.861154
trainer/policy/normal/std Min            0.338977
trainer/policy/normal/log_std Mean      -0.507395
trainer/policy/normal/log_std Std        0.143089
trainer/policy/normal/log_std Max       -0.149482
trainer/policy/normal/log_std Min       -1.08182
trainer/Alpha                            0.0454251
trainer/Alpha Loss                       1.42939
exploration/num steps total          75000
exploration/num paths total            375
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01376
exploration/Rewards Std                  0.218191
exploration/Rewards Max                 -0.646129
exploration/Rewards Min                 -1.67311
exploration/Returns Mean              -202.752
exploration/Returns Std                 30.0293
exploration/Returns Max               -161.87
exploration/Returns Min               -239.848
exploration/Actions Mean                -0.129757
exploration/Actions Std                  0.787485
exploration/Actions Max                  0.99991
exploration/Actions Min                 -0.998885
exploration/Num Paths                    5
exploration/Average Returns           -202.752
evaluation/num steps total          356976
evaluation/num paths total            1776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.962719
evaluation/Rewards Std                   0.214697
evaluation/Rewards Max                  -0.612934
evaluation/Rewards Min                  -1.78592
evaluation/Returns Mean               -193.507
evaluation/Returns Std                  27.4772
evaluation/Returns Max                -156.927
evaluation/Returns Min                -261.864
evaluation/Actions Mean                 -0.255988
evaluation/Actions Std                   0.689022
evaluation/Actions Max                   0.998162
evaluation/Actions Min                  -0.997298
evaluation/Num Paths                    24
evaluation/Average Returns            -193.507
time/data storing (s)                    0.00945296
time/evaluation sampling (s)           463.918
time/exploration sampling (s)          105.36
time/logging (s)                         0.0291114
time/sac training (s)                    9.49523
time/saving (s)                          0.0437022
time/training (s)                        0.000123717
time/epoch (s)                         578.856
time/total (s)                       51329.9
Epoch                                   73
----------------------------------  ----------------
2020-11-02 00:17:19.325144 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 74 finished
----------------------------------  ----------------
replay_buffer/size                   76000
trainer/num train calls              75000
trainer/QF1 Loss                       100.128
trainer/QF2 Loss                       103.847
trainer/Policy Loss                    141.676
trainer/Q1 Predictions Mean           -140.76
trainer/Q1 Predictions Std              37.8596
trainer/Q1 Predictions Max              -6.80809
trainer/Q1 Predictions Min            -213.064
trainer/Q2 Predictions Mean           -141.401
trainer/Q2 Predictions Std              38.0632
trainer/Q2 Predictions Max             -10.8395
trainer/Q2 Predictions Min            -210.352
trainer/Q Targets Mean                -140.326
trainer/Q Targets Std                   39.725
trainer/Q Targets Max                   -0.957261
trainer/Q Targets Min                 -212.243
trainer/Log Pis Mean                     1.77728
trainer/Log Pis Std                      2.03965
trainer/Log Pis Max                      6.73561
trainer/Log Pis Min                     -4.41724
trainer/policy/mean Mean                -0.302339
trainer/policy/mean Std                  0.771165
trainer/policy/mean Max                  0.996598
trainer/policy/mean Min                 -0.997141
trainer/policy/normal/std Mean           0.635188
trainer/policy/normal/std Std            0.0930697
trainer/policy/normal/std Max            0.915286
trainer/policy/normal/std Min            0.430591
trainer/policy/normal/log_std Mean      -0.464597
trainer/policy/normal/log_std Std        0.146985
trainer/policy/normal/log_std Max       -0.0885186
trainer/policy/normal/log_std Min       -0.842597
trainer/Alpha                            0.0454377
trainer/Alpha Loss                      -0.688528
exploration/num steps total          76000
exploration/num paths total            380
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.07901
exploration/Rewards Std                  0.263042
exploration/Rewards Max                 -0.713702
exploration/Rewards Min                 -1.71899
exploration/Returns Mean              -215.802
exploration/Returns Std                 45.6043
exploration/Returns Max               -169.55
exploration/Returns Min               -294.105
exploration/Actions Mean                -0.0124321
exploration/Actions Std                  0.780404
exploration/Actions Max                  0.999983
exploration/Actions Min                 -0.999245
exploration/Num Paths                    5
exploration/Average Returns           -215.802
evaluation/num steps total          361800
evaluation/num paths total            1800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.983237
evaluation/Rewards Std                   0.209576
evaluation/Rewards Max                  -0.559913
evaluation/Rewards Min                  -1.71948
evaluation/Returns Mean               -197.631
evaluation/Returns Std                  29.1921
evaluation/Returns Max                -155.804
evaluation/Returns Min                -254.965
evaluation/Actions Mean                 -0.184959
evaluation/Actions Std                   0.721301
evaluation/Actions Max                   0.999474
evaluation/Actions Min                  -0.997263
evaluation/Num Paths                    24
evaluation/Average Returns            -197.631
time/data storing (s)                    0.00833564
time/evaluation sampling (s)           464.573
time/exploration sampling (s)          108.826
time/logging (s)                         0.0192203
time/sac training (s)                    9.35885
time/saving (s)                          0.0242176
time/training (s)                        0.000122375
time/epoch (s)                         582.81
time/total (s)                       51913.3
Epoch                                   74
----------------------------------  ----------------
2020-11-02 00:27:22.746364 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 75 finished
----------------------------------  ----------------
replay_buffer/size                   77000
trainer/num train calls              76000
trainer/QF1 Loss                       117.986
trainer/QF2 Loss                       114.99
trainer/Policy Loss                    141.316
trainer/Q1 Predictions Mean           -140.161
trainer/Q1 Predictions Std              37.7071
trainer/Q1 Predictions Max             -19.9673
trainer/Q1 Predictions Min            -202.771
trainer/Q2 Predictions Mean           -140.859
trainer/Q2 Predictions Std              37.9185
trainer/Q2 Predictions Max             -20.6932
trainer/Q2 Predictions Min            -204.296
trainer/Q Targets Mean                -140.627
trainer/Q Targets Std                   38.8883
trainer/Q Targets Max                   -0.875841
trainer/Q Targets Min                 -205.899
trainer/Log Pis Mean                     2.02169
trainer/Log Pis Std                      2.35909
trainer/Log Pis Max                      8.88431
trainer/Log Pis Min                     -5.01995
trainer/policy/mean Mean                -0.207885
trainer/policy/mean Std                  0.820252
trainer/policy/mean Max                  0.999943
trainer/policy/mean Min                 -0.996709
trainer/policy/normal/std Mean           0.622018
trainer/policy/normal/std Std            0.0837134
trainer/policy/normal/std Max            0.825023
trainer/policy/normal/std Min            0.437472
trainer/policy/normal/log_std Mean      -0.483913
trainer/policy/normal/log_std Std        0.135544
trainer/policy/normal/log_std Max       -0.192344
trainer/policy/normal/log_std Min       -0.826743
trainer/Alpha                            0.0458746
trainer/Alpha Loss                       0.066844
exploration/num steps total          77000
exploration/num paths total            385
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.930726
exploration/Rewards Std                  0.16172
exploration/Rewards Max                 -0.622753
exploration/Rewards Min                 -1.42182
exploration/Returns Mean              -186.145
exploration/Returns Std                 10.9076
exploration/Returns Max               -168.885
exploration/Returns Min               -200.742
exploration/Actions Mean                -0.147691
exploration/Actions Std                  0.759893
exploration/Actions Max                  0.996532
exploration/Actions Min                 -0.999598
exploration/Num Paths                    5
exploration/Average Returns           -186.145
evaluation/num steps total          366624
evaluation/num paths total            1824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.958176
evaluation/Rewards Std                   0.167168
evaluation/Rewards Max                  -0.654096
evaluation/Rewards Min                  -1.58674
evaluation/Returns Mean               -192.593
evaluation/Returns Std                  16.5343
evaluation/Returns Max                -169.567
evaluation/Returns Min                -235.222
evaluation/Actions Mean                 -0.177704
evaluation/Actions Std                   0.681366
evaluation/Actions Max                   0.997709
evaluation/Actions Min                  -0.99652
evaluation/Num Paths                    24
evaluation/Average Returns            -192.593
time/data storing (s)                    0.00692887
time/evaluation sampling (s)           483.64
time/exploration sampling (s)          109.532
time/logging (s)                         0.0274312
time/sac training (s)                    9.31627
time/saving (s)                          0.0327434
time/training (s)                        0.000122247
time/epoch (s)                         602.555
time/total (s)                       52516.7
Epoch                                   75
----------------------------------  ----------------
2020-11-02 00:37:01.274669 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 76 finished
----------------------------------  ----------------
replay_buffer/size                   78000
trainer/num train calls              77000
trainer/QF1 Loss                        77.9889
trainer/QF2 Loss                        94.431
trainer/Policy Loss                    141.364
trainer/Q1 Predictions Mean           -140.171
trainer/Q1 Predictions Std              37.9932
trainer/Q1 Predictions Max             -38.1331
trainer/Q1 Predictions Min            -202.841
trainer/Q2 Predictions Mean           -140.802
trainer/Q2 Predictions Std              37.8959
trainer/Q2 Predictions Max             -40.468
trainer/Q2 Predictions Min            -205.409
trainer/Q Targets Mean                -140.181
trainer/Q Targets Std                   38.6752
trainer/Q Targets Max                   -0.922597
trainer/Q Targets Min                 -206.647
trainer/Log Pis Mean                     2.00555
trainer/Log Pis Std                      2.17949
trainer/Log Pis Max                      8.69366
trainer/Log Pis Min                     -5.72488
trainer/policy/mean Mean                -0.246165
trainer/policy/mean Std                  0.794542
trainer/policy/mean Max                  0.998025
trainer/policy/mean Min                 -0.994371
trainer/policy/normal/std Mean           0.634961
trainer/policy/normal/std Std            0.0812615
trainer/policy/normal/std Max            0.87999
trainer/policy/normal/std Min            0.405648
trainer/policy/normal/log_std Mean      -0.462333
trainer/policy/normal/log_std Std        0.127623
trainer/policy/normal/log_std Max       -0.127845
trainer/policy/normal/log_std Min       -0.902269
trainer/Alpha                            0.0489163
trainer/Alpha Loss                       0.0167519
exploration/num steps total          78000
exploration/num paths total            390
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01254
exploration/Rewards Std                  0.177972
exploration/Rewards Max                 -0.706382
exploration/Rewards Min                 -1.58423
exploration/Returns Mean              -202.507
exploration/Returns Std                 24.0189
exploration/Returns Max               -174.145
exploration/Returns Min               -243.465
exploration/Actions Mean                -0.0828929
exploration/Actions Std                  0.742182
exploration/Actions Max                  0.99955
exploration/Actions Min                 -0.998762
exploration/Num Paths                    5
exploration/Average Returns           -202.507
evaluation/num steps total          371448
evaluation/num paths total            1848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.971909
evaluation/Rewards Std                   0.167413
evaluation/Rewards Max                  -0.595407
evaluation/Rewards Min                  -1.60654
evaluation/Returns Mean               -195.354
evaluation/Returns Std                  19.014
evaluation/Returns Max                -157.964
evaluation/Returns Min                -238.705
evaluation/Actions Mean                 -0.115002
evaluation/Actions Std                   0.727645
evaluation/Actions Max                   0.998877
evaluation/Actions Min                  -0.99182
evaluation/Num Paths                    24
evaluation/Average Returns            -195.354
time/data storing (s)                    0.0074326
time/evaluation sampling (s)           466.369
time/exploration sampling (s)          102.135
time/logging (s)                         0.0263892
time/sac training (s)                    9.31488
time/saving (s)                          0.0277172
time/training (s)                        0.000150968
time/epoch (s)                         577.88
time/total (s)                       53095.2
Epoch                                   76
----------------------------------  ----------------
2020-11-02 00:46:43.253605 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 77 finished
----------------------------------  ----------------
replay_buffer/size                   79000
trainer/num train calls              78000
trainer/QF1 Loss                       126.573
trainer/QF2 Loss                       131.358
trainer/Policy Loss                    140.324
trainer/Q1 Predictions Mean           -139.6
trainer/Q1 Predictions Std              39.8675
trainer/Q1 Predictions Max               4.70179
trainer/Q1 Predictions Min            -204.739
trainer/Q2 Predictions Mean           -139.668
trainer/Q2 Predictions Std              40.2645
trainer/Q2 Predictions Max              13.2914
trainer/Q2 Predictions Min            -204.762
trainer/Q Targets Mean                -139.204
trainer/Q Targets Std                   42.4435
trainer/Q Targets Max                    6.30659
trainer/Q Targets Min                 -208.063
trainer/Log Pis Mean                     2.44133
trainer/Log Pis Std                      2.34589
trainer/Log Pis Max                      9.79113
trainer/Log Pis Min                     -4.52586
trainer/policy/mean Mean                -0.146458
trainer/policy/mean Std                  0.841586
trainer/policy/mean Max                  0.997479
trainer/policy/mean Min                 -0.997272
trainer/policy/normal/std Mean           0.607954
trainer/policy/normal/std Std            0.0852005
trainer/policy/normal/std Max            0.877615
trainer/policy/normal/std Min            0.367301
trainer/policy/normal/log_std Mean      -0.507634
trainer/policy/normal/log_std Std        0.142126
trainer/policy/normal/log_std Max       -0.130547
trainer/policy/normal/log_std Min       -1.00157
trainer/Alpha                            0.0495938
trainer/Alpha Loss                       1.3257
exploration/num steps total          79000
exploration/num paths total            395
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.980163
exploration/Rewards Std                  0.240018
exploration/Rewards Max                 -0.595096
exploration/Rewards Min                 -1.66876
exploration/Returns Mean              -196.033
exploration/Returns Std                 34.3055
exploration/Returns Max               -161.433
exploration/Returns Min               -254.105
exploration/Actions Mean                -0.218664
exploration/Actions Std                  0.813868
exploration/Actions Max                  0.998996
exploration/Actions Min                 -0.999754
exploration/Num Paths                    5
exploration/Average Returns           -196.033
evaluation/num steps total          376272
evaluation/num paths total            1872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.998331
evaluation/Rewards Std                   0.223882
evaluation/Rewards Max                  -0.565917
evaluation/Rewards Min                  -1.69659
evaluation/Returns Mean               -200.664
evaluation/Returns Std                  32.7636
evaluation/Returns Max                -157.893
evaluation/Returns Min                -266.97
evaluation/Actions Mean                 -0.127568
evaluation/Actions Std                   0.713987
evaluation/Actions Max                   0.999971
evaluation/Actions Min                  -0.994532
evaluation/Num Paths                    24
evaluation/Average Returns            -200.664
time/data storing (s)                    0.0084404
time/evaluation sampling (s)           484.524
time/exploration sampling (s)           87.3952
time/logging (s)                         0.0209328
time/sac training (s)                    9.33281
time/saving (s)                          0.0279133
time/training (s)                        0.000137924
time/epoch (s)                         581.31
time/total (s)                       53677.1
Epoch                                   77
----------------------------------  ----------------
2020-11-02 00:56:51.429801 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 78 finished
----------------------------------  ---------------
replay_buffer/size                   80000
trainer/num train calls              79000
trainer/QF1 Loss                        28.494
trainer/QF2 Loss                        27.8137
trainer/Policy Loss                    141.993
trainer/Q1 Predictions Mean           -140.963
trainer/Q1 Predictions Std              39.1008
trainer/Q1 Predictions Max             -27.2881
trainer/Q1 Predictions Min            -207.456
trainer/Q2 Predictions Mean           -141.27
trainer/Q2 Predictions Std              38.719
trainer/Q2 Predictions Max             -29.9472
trainer/Q2 Predictions Min            -206.589
trainer/Q Targets Mean                -141.841
trainer/Q Targets Std                   38.9191
trainer/Q Targets Max                  -40.2331
trainer/Q Targets Min                 -209.816
trainer/Log Pis Mean                     2.41149
trainer/Log Pis Std                      2.32213
trainer/Log Pis Max                      8.94988
trainer/Log Pis Min                     -4.83017
trainer/policy/mean Mean                -0.0899446
trainer/policy/mean Std                  0.84559
trainer/policy/mean Max                  0.997943
trainer/policy/mean Min                 -0.996839
trainer/policy/normal/std Mean           0.618974
trainer/policy/normal/std Std            0.0765289
trainer/policy/normal/std Max            0.797466
trainer/policy/normal/std Min            0.411011
trainer/policy/normal/log_std Mean      -0.487465
trainer/policy/normal/log_std Std        0.125361
trainer/policy/normal/log_std Max       -0.226316
trainer/policy/normal/log_std Min       -0.889134
trainer/Alpha                            0.0485017
trainer/Alpha Loss                       1.24525
exploration/num steps total          80000
exploration/num paths total            400
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.930664
exploration/Rewards Std                  0.195559
exploration/Rewards Max                 -0.522844
exploration/Rewards Min                 -1.41925
exploration/Returns Mean              -186.133
exploration/Returns Std                 17.446
exploration/Returns Max               -159.313
exploration/Returns Min               -208.245
exploration/Actions Mean                -0.219317
exploration/Actions Std                  0.741543
exploration/Actions Max                  0.998634
exploration/Actions Min                 -0.999755
exploration/Num Paths                    5
exploration/Average Returns           -186.133
evaluation/num steps total          381096
evaluation/num paths total            1896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.981661
evaluation/Rewards Std                   0.198279
evaluation/Rewards Max                  -0.566631
evaluation/Rewards Min                  -1.54996
evaluation/Returns Mean               -197.314
evaluation/Returns Std                  26.5552
evaluation/Returns Max                -156.777
evaluation/Returns Min                -258.641
evaluation/Actions Mean                 -0.173911
evaluation/Actions Std                   0.694908
evaluation/Actions Max                   0.999191
evaluation/Actions Min                  -0.998602
evaluation/Num Paths                    24
evaluation/Average Returns            -197.314
time/data storing (s)                    0.00602447
time/evaluation sampling (s)           499.957
time/exploration sampling (s)           98.1778
time/logging (s)                         0.0199415
time/sac training (s)                    9.3373
time/saving (s)                          0.0232834
time/training (s)                        0.00015055
time/epoch (s)                         607.522
time/total (s)                       54285.3
Epoch                                   78
----------------------------------  ---------------
2020-11-02 01:06:05.236281 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 79 finished
----------------------------------  ----------------
replay_buffer/size                   81000
trainer/num train calls              80000
trainer/QF1 Loss                        59.5149
trainer/QF2 Loss                        68.5477
trainer/Policy Loss                    141.521
trainer/Q1 Predictions Mean           -141.113
trainer/Q1 Predictions Std              41.7155
trainer/Q1 Predictions Max             -24.0591
trainer/Q1 Predictions Min            -214.364
trainer/Q2 Predictions Mean           -140.771
trainer/Q2 Predictions Std              41.5503
trainer/Q2 Predictions Max             -22.9644
trainer/Q2 Predictions Min            -217.028
trainer/Q Targets Mean                -140.734
trainer/Q Targets Std                   42.72
trainer/Q Targets Max                   -0.907198
trainer/Q Targets Min                 -211.902
trainer/Log Pis Mean                     2.5453
trainer/Log Pis Std                      2.30042
trainer/Log Pis Max                      8.94236
trainer/Log Pis Min                     -5.11433
trainer/policy/mean Mean                -0.0473884
trainer/policy/mean Std                  0.872764
trainer/policy/mean Max                  0.998141
trainer/policy/mean Min                 -0.993911
trainer/policy/normal/std Mean           0.601637
trainer/policy/normal/std Std            0.0754718
trainer/policy/normal/std Max            0.87529
trainer/policy/normal/std Min            0.418829
trainer/policy/normal/log_std Mean      -0.515942
trainer/policy/normal/log_std Std        0.125311
trainer/policy/normal/log_std Max       -0.1332
trainer/policy/normal/log_std Min       -0.870292
trainer/Alpha                            0.049039
trainer/Alpha Loss                       1.64414
exploration/num steps total          81000
exploration/num paths total            405
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.957597
exploration/Rewards Std                  0.186643
exploration/Rewards Max                 -0.683332
exploration/Rewards Min                 -1.52057
exploration/Returns Mean              -191.519
exploration/Returns Std                 12.953
exploration/Returns Max               -172.873
exploration/Returns Min               -211.385
exploration/Actions Mean                -0.100652
exploration/Actions Std                  0.745785
exploration/Actions Max                  0.999583
exploration/Actions Min                 -0.999596
exploration/Num Paths                    5
exploration/Average Returns           -191.519
evaluation/num steps total          385920
evaluation/num paths total            1920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95896
evaluation/Rewards Std                   0.195244
evaluation/Rewards Max                  -0.552088
evaluation/Rewards Min                  -1.60342
evaluation/Returns Mean               -192.751
evaluation/Returns Std                  23.4735
evaluation/Returns Max                -147.613
evaluation/Returns Min                -246.196
evaluation/Actions Mean                 -0.21679
evaluation/Actions Std                   0.719047
evaluation/Actions Max                   0.999022
evaluation/Actions Min                  -0.99885
evaluation/Num Paths                    24
evaluation/Average Returns            -192.751
time/data storing (s)                    0.00740477
time/evaluation sampling (s)           440.321
time/exploration sampling (s)          103.544
time/logging (s)                         0.0210364
time/sac training (s)                    9.24503
time/saving (s)                          0.0261737
time/training (s)                        0.000120118
time/epoch (s)                         553.164
time/total (s)                       54839.1
Epoch                                   79
----------------------------------  ----------------
2020-11-02 01:15:25.867789 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 80 finished
----------------------------------  ----------------
replay_buffer/size                   82000
trainer/num train calls              81000
trainer/QF1 Loss                        59.9096
trainer/QF2 Loss                        73.4326
trainer/Policy Loss                    140.233
trainer/Q1 Predictions Mean           -139.526
trainer/Q1 Predictions Std              39.5237
trainer/Q1 Predictions Max             -28.6296
trainer/Q1 Predictions Min            -207.131
trainer/Q2 Predictions Mean           -139.589
trainer/Q2 Predictions Std              39.2531
trainer/Q2 Predictions Max             -21.134
trainer/Q2 Predictions Min            -203.854
trainer/Q Targets Mean                -140.556
trainer/Q Targets Std                   40.5056
trainer/Q Targets Max                   -0.907198
trainer/Q Targets Min                 -208.421
trainer/Log Pis Mean                     1.97352
trainer/Log Pis Std                      2.05511
trainer/Log Pis Max                      8.63474
trainer/Log Pis Min                     -4.21567
trainer/policy/mean Mean                -0.320072
trainer/policy/mean Std                  0.766864
trainer/policy/mean Max                  0.997164
trainer/policy/mean Min                 -0.994614
trainer/policy/normal/std Mean           0.623635
trainer/policy/normal/std Std            0.0832757
trainer/policy/normal/std Max            0.875574
trainer/policy/normal/std Min            0.403943
trainer/policy/normal/log_std Mean      -0.481092
trainer/policy/normal/log_std Std        0.133588
trainer/policy/normal/log_std Max       -0.132876
trainer/policy/normal/log_std Min       -0.906482
trainer/Alpha                            0.0473387
trainer/Alpha Loss                      -0.0807773
exploration/num steps total          82000
exploration/num paths total            410
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.10692
exploration/Rewards Std                  0.219391
exploration/Rewards Max                 -0.720058
exploration/Rewards Min                 -1.69426
exploration/Returns Mean              -221.384
exploration/Returns Std                 33.5135
exploration/Returns Max               -182.941
exploration/Returns Min               -262.893
exploration/Actions Mean                 0.0346614
exploration/Actions Std                  0.763519
exploration/Actions Max                  0.999962
exploration/Actions Min                 -0.998824
exploration/Num Paths                    5
exploration/Average Returns           -221.384
evaluation/num steps total          390744
evaluation/num paths total            1944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.939808
evaluation/Rewards Std                   0.185549
evaluation/Rewards Max                  -0.55325
evaluation/Rewards Min                  -1.75524
evaluation/Returns Mean               -188.901
evaluation/Returns Std                  17.3178
evaluation/Returns Max                -156.904
evaluation/Returns Min                -228.249
evaluation/Actions Mean                 -0.270355
evaluation/Actions Std                   0.702364
evaluation/Actions Max                   0.999683
evaluation/Actions Min                  -0.9968
evaluation/Num Paths                    24
evaluation/Average Returns            -188.901
time/data storing (s)                    0.00725218
time/evaluation sampling (s)           440.603
time/exploration sampling (s)          109.956
time/logging (s)                         0.0173839
time/sac training (s)                    9.37073
time/saving (s)                          0.0272846
time/training (s)                        0.000125442
time/epoch (s)                         559.982
time/total (s)                       55399.7
Epoch                                   80
----------------------------------  ----------------
2020-11-02 01:25:15.320868 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 81 finished
----------------------------------  ----------------
replay_buffer/size                   83000
trainer/num train calls              82000
trainer/QF1 Loss                        96.4514
trainer/QF2 Loss                       101.089
trainer/Policy Loss                    141.858
trainer/Q1 Predictions Mean           -141.158
trainer/Q1 Predictions Std              35.1621
trainer/Q1 Predictions Max             -60.7105
trainer/Q1 Predictions Min            -205.861
trainer/Q2 Predictions Mean           -141.044
trainer/Q2 Predictions Std              35.409
trainer/Q2 Predictions Max             -62.2114
trainer/Q2 Predictions Min            -208.355
trainer/Q Targets Mean                -141.526
trainer/Q Targets Std                   36.8653
trainer/Q Targets Max                   -0.937105
trainer/Q Targets Min                 -210.152
trainer/Log Pis Mean                     1.6506
trainer/Log Pis Std                      2.08876
trainer/Log Pis Max                      6.45778
trainer/Log Pis Min                     -3.68796
trainer/policy/mean Mean                -0.228846
trainer/policy/mean Std                  0.779417
trainer/policy/mean Max                  0.997145
trainer/policy/mean Min                 -0.995396
trainer/policy/normal/std Mean           0.644549
trainer/policy/normal/std Std            0.088084
trainer/policy/normal/std Max            0.914035
trainer/policy/normal/std Min            0.409015
trainer/policy/normal/log_std Mean      -0.448488
trainer/policy/normal/log_std Std        0.136224
trainer/policy/normal/log_std Max       -0.0898869
trainer/policy/normal/log_std Min       -0.894003
trainer/Alpha                            0.0480874
trainer/Alpha Loss                      -1.06033
exploration/num steps total          83000
exploration/num paths total            415
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.970121
exploration/Rewards Std                  0.18684
exploration/Rewards Max                 -0.623976
exploration/Rewards Min                 -1.46038
exploration/Returns Mean              -194.024
exploration/Returns Std                 20.5104
exploration/Returns Max               -176.115
exploration/Returns Min               -225.263
exploration/Actions Mean                -0.0795803
exploration/Actions Std                  0.728356
exploration/Actions Max                  0.999359
exploration/Actions Min                 -0.999683
exploration/Num Paths                    5
exploration/Average Returns           -194.024
evaluation/num steps total          395568
evaluation/num paths total            1968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00964
evaluation/Rewards Std                   0.23859
evaluation/Rewards Max                  -0.541425
evaluation/Rewards Min                  -1.98216
evaluation/Returns Mean               -202.937
evaluation/Returns Std                  31.5408
evaluation/Returns Max                -152.692
evaluation/Returns Min                -273.392
evaluation/Actions Mean                 -0.269464
evaluation/Actions Std                   0.673022
evaluation/Actions Max                   0.998765
evaluation/Actions Min                  -0.998307
evaluation/Num Paths                    24
evaluation/Average Returns            -202.937
time/data storing (s)                    0.00595634
time/evaluation sampling (s)           468.161
time/exploration sampling (s)          111.258
time/logging (s)                         0.0191432
time/sac training (s)                    9.3405
time/saving (s)                          0.0301415
time/training (s)                        0.000166221
time/epoch (s)                         588.815
time/total (s)                       55989.1
Epoch                                   81
----------------------------------  ----------------
2020-11-02 01:34:58.581372 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 82 finished
----------------------------------  ----------------
replay_buffer/size                   84000
trainer/num train calls              83000
trainer/QF1 Loss                        66.9828
trainer/QF2 Loss                        68.6818
trainer/Policy Loss                    141.147
trainer/Q1 Predictions Mean           -140.711
trainer/Q1 Predictions Std              40.745
trainer/Q1 Predictions Max             -32.8061
trainer/Q1 Predictions Min            -217.837
trainer/Q2 Predictions Mean           -140.027
trainer/Q2 Predictions Std              40.2656
trainer/Q2 Predictions Max             -27.1468
trainer/Q2 Predictions Min            -213.233
trainer/Q Targets Mean                -141.243
trainer/Q Targets Std                   41.2578
trainer/Q Targets Max                   -0.929385
trainer/Q Targets Min                 -217.729
trainer/Log Pis Mean                     2.06825
trainer/Log Pis Std                      2.38912
trainer/Log Pis Max                     11.1235
trainer/Log Pis Min                     -3.35328
trainer/policy/mean Mean                -0.342336
trainer/policy/mean Std                  0.747998
trainer/policy/mean Max                  0.999853
trainer/policy/mean Min                 -0.996835
trainer/policy/normal/std Mean           0.641938
trainer/policy/normal/std Std            0.0869102
trainer/policy/normal/std Max            0.890238
trainer/policy/normal/std Min            0.357119
trainer/policy/normal/log_std Mean      -0.452398
trainer/policy/normal/log_std Std        0.135363
trainer/policy/normal/log_std Max       -0.116267
trainer/policy/normal/log_std Min       -1.02969
trainer/Alpha                            0.0455899
trainer/Alpha Loss                       0.210775
exploration/num steps total          84000
exploration/num paths total            420
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.07087
exploration/Rewards Std                  0.223051
exploration/Rewards Max                 -0.668528
exploration/Rewards Min                 -1.6601
exploration/Returns Mean              -214.174
exploration/Returns Std                 22.9311
exploration/Returns Max               -185.711
exploration/Returns Min               -248.421
exploration/Actions Mean                -0.426358
exploration/Actions Std                  0.643334
exploration/Actions Max                  0.992647
exploration/Actions Min                 -0.999522
exploration/Num Paths                    5
exploration/Average Returns           -214.174
evaluation/num steps total          400392
evaluation/num paths total            1992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.952884
evaluation/Rewards Std                   0.20544
evaluation/Rewards Max                  -0.575069
evaluation/Rewards Min                  -1.76594
evaluation/Returns Mean               -191.53
evaluation/Returns Std                  25.3884
evaluation/Returns Max                -164.254
evaluation/Returns Min                -253.973
evaluation/Actions Mean                 -0.347139
evaluation/Actions Std                   0.62524
evaluation/Actions Max                   0.997317
evaluation/Actions Min                  -0.995756
evaluation/Num Paths                    24
evaluation/Average Returns            -191.53
time/data storing (s)                    0.00619275
time/evaluation sampling (s)           461.026
time/exploration sampling (s)          112.291
time/logging (s)                         0.0229441
time/sac training (s)                    9.23928
time/saving (s)                          0.0350049
time/training (s)                        0.000113447
time/epoch (s)                         582.621
time/total (s)                       56572.3
Epoch                                   82
----------------------------------  ----------------
2020-11-02 01:44:03.895840 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 83 finished
----------------------------------  ----------------
replay_buffer/size                   85000
trainer/num train calls              84000
trainer/QF1 Loss                       117.195
trainer/QF2 Loss                       125.383
trainer/Policy Loss                    150.821
trainer/Q1 Predictions Mean           -150.021
trainer/Q1 Predictions Std              38.6311
trainer/Q1 Predictions Max             -33.6603
trainer/Q1 Predictions Min            -214.214
trainer/Q2 Predictions Mean           -150.139
trainer/Q2 Predictions Std              38.7001
trainer/Q2 Predictions Max             -31.7529
trainer/Q2 Predictions Min            -216.527
trainer/Q Targets Mean                -148.998
trainer/Q Targets Std                   41.0738
trainer/Q Targets Max                   -0.842656
trainer/Q Targets Min                 -216.895
trainer/Log Pis Mean                     2.07654
trainer/Log Pis Std                      2.17689
trainer/Log Pis Max                      7.99277
trainer/Log Pis Min                     -5.46153
trainer/policy/mean Mean                -0.423741
trainer/policy/mean Std                  0.72979
trainer/policy/mean Max                  0.991282
trainer/policy/mean Min                 -0.99539
trainer/policy/normal/std Mean           0.639488
trainer/policy/normal/std Std            0.0804606
trainer/policy/normal/std Max            0.849443
trainer/policy/normal/std Min            0.440055
trainer/policy/normal/log_std Mean      -0.454964
trainer/policy/normal/log_std Std        0.125484
trainer/policy/normal/log_std Max       -0.163174
trainer/policy/normal/log_std Min       -0.820855
trainer/Alpha                            0.0453446
trainer/Alpha Loss                       0.236765
exploration/num steps total          85000
exploration/num paths total            425
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.877718
exploration/Rewards Std                  0.189497
exploration/Rewards Max                 -0.579837
exploration/Rewards Min                 -1.50877
exploration/Returns Mean              -175.544
exploration/Returns Std                  8.72874
exploration/Returns Max               -161.585
exploration/Returns Min               -185.653
exploration/Actions Mean                -0.32453
exploration/Actions Std                  0.70587
exploration/Actions Max                  0.996345
exploration/Actions Min                 -0.999475
exploration/Num Paths                    5
exploration/Average Returns           -175.544
evaluation/num steps total          405216
evaluation/num paths total            2016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.93081
evaluation/Rewards Std                   0.221082
evaluation/Rewards Max                  -0.505966
evaluation/Rewards Min                  -1.61849
evaluation/Returns Mean               -187.093
evaluation/Returns Std                  28.6083
evaluation/Returns Max                -146.259
evaluation/Returns Min                -256.526
evaluation/Actions Mean                 -0.269984
evaluation/Actions Std                   0.676876
evaluation/Actions Max                   0.998476
evaluation/Actions Min                  -0.998416
evaluation/Num Paths                    24
evaluation/Average Returns            -187.093
time/data storing (s)                    0.0104866
time/evaluation sampling (s)           441.009
time/exploration sampling (s)           94.2733
time/logging (s)                         0.0198693
time/sac training (s)                    9.3152
time/saving (s)                          0.0246911
time/training (s)                        0.000114313
time/epoch (s)                         544.653
time/total (s)                       57117.6
Epoch                                   83
----------------------------------  ----------------
2020-11-02 01:54:08.010779 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 84 finished
----------------------------------  ----------------
replay_buffer/size                   86000
trainer/num train calls              85000
trainer/QF1 Loss                        28.3863
trainer/QF2 Loss                        23.9324
trainer/Policy Loss                    152.615
trainer/Q1 Predictions Mean           -151.23
trainer/Q1 Predictions Std              36.2294
trainer/Q1 Predictions Max             -51.4174
trainer/Q1 Predictions Min            -210.161
trainer/Q2 Predictions Mean           -152.157
trainer/Q2 Predictions Std              36.3397
trainer/Q2 Predictions Max             -49.8992
trainer/Q2 Predictions Min            -209.447
trainer/Q Targets Mean                -153.303
trainer/Q Targets Std                   35.7669
trainer/Q Targets Max                  -50.3063
trainer/Q Targets Min                 -212.512
trainer/Log Pis Mean                     1.75551
trainer/Log Pis Std                      2.01164
trainer/Log Pis Max                      9.47343
trainer/Log Pis Min                     -3.69401
trainer/policy/mean Mean                -0.216402
trainer/policy/mean Std                  0.799273
trainer/policy/mean Max                  0.999694
trainer/policy/mean Min                 -0.991974
trainer/policy/normal/std Mean           0.630057
trainer/policy/normal/std Std            0.081118
trainer/policy/normal/std Max            0.884284
trainer/policy/normal/std Min            0.379817
trainer/policy/normal/log_std Mean      -0.470345
trainer/policy/normal/log_std Std        0.130307
trainer/policy/normal/log_std Max       -0.122977
trainer/policy/normal/log_std Min       -0.968065
trainer/Alpha                            0.0440857
trainer/Alpha Loss                      -0.763196
exploration/num steps total          86000
exploration/num paths total            430
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.915155
exploration/Rewards Std                  0.18707
exploration/Rewards Max                 -0.570132
exploration/Rewards Min                 -1.55296
exploration/Returns Mean              -183.031
exploration/Returns Std                 16.4067
exploration/Returns Max               -171.007
exploration/Returns Min               -214.767
exploration/Actions Mean                -0.217746
exploration/Actions Std                  0.662027
exploration/Actions Max                  0.995645
exploration/Actions Min                 -0.997968
exploration/Num Paths                    5
exploration/Average Returns           -183.031
evaluation/num steps total          410040
evaluation/num paths total            2040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.965173
evaluation/Rewards Std                   0.192569
evaluation/Rewards Max                  -0.564643
evaluation/Rewards Min                  -1.69362
evaluation/Returns Mean               -194
evaluation/Returns Std                  23.1062
evaluation/Returns Max                -161.743
evaluation/Returns Min                -245.867
evaluation/Actions Mean                 -0.184548
evaluation/Actions Std                   0.701462
evaluation/Actions Max                   0.999221
evaluation/Actions Min                  -0.994959
evaluation/Num Paths                    24
evaluation/Average Returns            -194
time/data storing (s)                    0.00897612
time/evaluation sampling (s)           487.417
time/exploration sampling (s)          106.71
time/logging (s)                         0.0183636
time/sac training (s)                    9.29547
time/saving (s)                          0.025361
time/training (s)                        0.000140064
time/epoch (s)                         603.475
time/total (s)                       57721.7
Epoch                                   84
----------------------------------  ----------------
2020-11-02 02:03:35.863280 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 85 finished
----------------------------------  ----------------
replay_buffer/size                   87000
trainer/num train calls              86000
trainer/QF1 Loss                        24.0137
trainer/QF2 Loss                        22.0342
trainer/Policy Loss                    145.935
trainer/Q1 Predictions Mean           -145.404
trainer/Q1 Predictions Std              40.6028
trainer/Q1 Predictions Max             -31.1443
trainer/Q1 Predictions Min            -213.048
trainer/Q2 Predictions Mean           -145.144
trainer/Q2 Predictions Std              40.7844
trainer/Q2 Predictions Max             -32.635
trainer/Q2 Predictions Min            -212.88
trainer/Q Targets Mean                -145.262
trainer/Q Targets Std                   40.4038
trainer/Q Targets Max                  -29.1063
trainer/Q Targets Min                 -212.137
trainer/Log Pis Mean                     2.03096
trainer/Log Pis Std                      2.02972
trainer/Log Pis Max                     10.1935
trainer/Log Pis Min                     -4.43667
trainer/policy/mean Mean                -0.383272
trainer/policy/mean Std                  0.748903
trainer/policy/mean Max                  0.999247
trainer/policy/mean Min                 -0.999185
trainer/policy/normal/std Mean           0.625114
trainer/policy/normal/std Std            0.0820232
trainer/policy/normal/std Max            0.841768
trainer/policy/normal/std Min            0.418301
trainer/policy/normal/log_std Mean      -0.478455
trainer/policy/normal/log_std Std        0.131697
trainer/policy/normal/log_std Max       -0.172251
trainer/policy/normal/log_std Min       -0.871554
trainer/Alpha                            0.0446172
trainer/Alpha Loss                       0.0962702
exploration/num steps total          87000
exploration/num paths total            435
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00343
exploration/Rewards Std                  0.197536
exploration/Rewards Max                 -0.599
exploration/Rewards Min                 -1.54668
exploration/Returns Mean              -200.686
exploration/Returns Std                 17.8589
exploration/Returns Max               -176.862
exploration/Returns Min               -225.737
exploration/Actions Mean                -0.0957679
exploration/Actions Std                  0.720274
exploration/Actions Max                  0.999561
exploration/Actions Min                 -0.999241
exploration/Num Paths                    5
exploration/Average Returns           -200.686
evaluation/num steps total          414864
evaluation/num paths total            2064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.941692
evaluation/Rewards Std                   0.209832
evaluation/Rewards Max                  -0.568303
evaluation/Rewards Min                  -1.70457
evaluation/Returns Mean               -189.28
evaluation/Returns Std                  19.654
evaluation/Returns Max                -152.912
evaluation/Returns Min                -224.556
evaluation/Actions Mean                 -0.255343
evaluation/Actions Std                   0.695311
evaluation/Actions Max                   0.99111
evaluation/Actions Min                  -0.999948
evaluation/Num Paths                    24
evaluation/Average Returns            -189.28
time/data storing (s)                    0.00873723
time/evaluation sampling (s)           441.803
time/exploration sampling (s)          114.494
time/logging (s)                         0.0389511
time/sac training (s)                   10.5593
time/saving (s)                          0.0341403
time/training (s)                        0.000113927
time/epoch (s)                         566.938
time/total (s)                       58289.6
Epoch                                   85
----------------------------------  ----------------
2020-11-02 02:14:16.899815 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 86 finished
----------------------------------  ----------------
replay_buffer/size                   88000
trainer/num train calls              87000
trainer/QF1 Loss                        83.1819
trainer/QF2 Loss                        86.1346
trainer/Policy Loss                    150.191
trainer/Q1 Predictions Mean           -149.491
trainer/Q1 Predictions Std              38.848
trainer/Q1 Predictions Max             -13.0907
trainer/Q1 Predictions Min            -213.414
trainer/Q2 Predictions Mean           -149.331
trainer/Q2 Predictions Std              39.0558
trainer/Q2 Predictions Max             -17.5782
trainer/Q2 Predictions Min            -212.861
trainer/Q Targets Mean                -148.81
trainer/Q Targets Std                   39.5903
trainer/Q Targets Max                   -0.962089
trainer/Q Targets Min                 -213.392
trainer/Log Pis Mean                     1.81371
trainer/Log Pis Std                      2.28765
trainer/Log Pis Max                      8.66269
trainer/Log Pis Min                     -3.41973
trainer/policy/mean Mean                -0.243091
trainer/policy/mean Std                  0.805991
trainer/policy/mean Max                  0.997943
trainer/policy/mean Min                 -0.996374
trainer/policy/normal/std Mean           0.627756
trainer/policy/normal/std Std            0.0764176
trainer/policy/normal/std Max            0.844312
trainer/policy/normal/std Min            0.352774
trainer/policy/normal/log_std Mean      -0.473183
trainer/policy/normal/log_std Std        0.12407
trainer/policy/normal/log_std Max       -0.169233
trainer/policy/normal/log_std Min       -1.04193
trainer/Alpha                            0.0442256
trainer/Alpha Loss                      -0.580928
exploration/num steps total          88000
exploration/num paths total            440
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.09298
exploration/Rewards Std                  0.156403
exploration/Rewards Max                 -0.705256
exploration/Rewards Min                 -1.61175
exploration/Returns Mean              -218.596
exploration/Returns Std                 21.1101
exploration/Returns Max               -183.044
exploration/Returns Min               -247.199
exploration/Actions Mean                 0.0344248
exploration/Actions Std                  0.764539
exploration/Actions Max                  0.999986
exploration/Actions Min                 -0.996919
exploration/Num Paths                    5
exploration/Average Returns           -218.596
evaluation/num steps total          419688
evaluation/num paths total            2088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00605
evaluation/Rewards Std                   0.213375
evaluation/Rewards Max                  -0.570321
evaluation/Rewards Min                  -1.76989
evaluation/Returns Mean               -202.216
evaluation/Returns Std                  28.4721
evaluation/Returns Max                -157.99
evaluation/Returns Min                -279.194
evaluation/Actions Mean                 -0.220171
evaluation/Actions Std                   0.684482
evaluation/Actions Max                   0.998898
evaluation/Actions Min                  -0.996002
evaluation/Num Paths                    24
evaluation/Average Returns            -202.216
time/data storing (s)                    0.00725503
time/evaluation sampling (s)           508.424
time/exploration sampling (s)          121.996
time/logging (s)                         0.023388
time/sac training (s)                    9.64255
time/saving (s)                          0.0314739
time/training (s)                        0.000119414
time/epoch (s)                         640.125
time/total (s)                       58930.5
Epoch                                   86
----------------------------------  ----------------
2020-11-02 02:23:41.971539 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 87 finished
----------------------------------  ----------------
replay_buffer/size                   89000
trainer/num train calls              88000
trainer/QF1 Loss                        99.4756
trainer/QF2 Loss                       101.545
trainer/Policy Loss                    144.912
trainer/Q1 Predictions Mean           -144.746
trainer/Q1 Predictions Std              41.3945
trainer/Q1 Predictions Max              36.0163
trainer/Q1 Predictions Min            -215.248
trainer/Q2 Predictions Mean           -143.634
trainer/Q2 Predictions Std              40.8374
trainer/Q2 Predictions Max              43.1002
trainer/Q2 Predictions Min            -212.096
trainer/Q Targets Mean                -143.986
trainer/Q Targets Std                   42.8259
trainer/Q Targets Max                   34.1999
trainer/Q Targets Min                 -213.09
trainer/Log Pis Mean                     1.94691
trainer/Log Pis Std                      2.30051
trainer/Log Pis Max                      9.63835
trainer/Log Pis Min                     -4.90391
trainer/policy/mean Mean                -0.341372
trainer/policy/mean Std                  0.773944
trainer/policy/mean Max                  0.996549
trainer/policy/mean Min                 -0.997608
trainer/policy/normal/std Mean           0.631257
trainer/policy/normal/std Std            0.0813917
trainer/policy/normal/std Max            0.843776
trainer/policy/normal/std Min            0.380033
trainer/policy/normal/log_std Mean      -0.468436
trainer/policy/normal/log_std Std        0.13007
trainer/policy/normal/log_std Max       -0.169868
trainer/policy/normal/log_std Min       -0.967496
trainer/Alpha                            0.0422098
trainer/Alpha Loss                      -0.168038
exploration/num steps total          89000
exploration/num paths total            445
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.963031
exploration/Rewards Std                  0.22689
exploration/Rewards Max                 -0.606908
exploration/Rewards Min                 -1.44131
exploration/Returns Mean              -192.606
exploration/Returns Std                 34.3851
exploration/Returns Max               -161.484
exploration/Returns Min               -259.322
exploration/Actions Mean                -0.276036
exploration/Actions Std                  0.68268
exploration/Actions Max                  0.998429
exploration/Actions Min                 -0.999103
exploration/Num Paths                    5
exploration/Average Returns           -192.606
evaluation/num steps total          424512
evaluation/num paths total            2112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.938894
evaluation/Rewards Std                   0.18711
evaluation/Rewards Max                  -0.573508
evaluation/Rewards Min                  -1.61418
evaluation/Returns Mean               -188.718
evaluation/Returns Std                  17.5476
evaluation/Returns Max                -152.821
evaluation/Returns Min                -219.67
evaluation/Actions Mean                 -0.243611
evaluation/Actions Std                   0.682796
evaluation/Actions Max                   0.998888
evaluation/Actions Min                  -0.992984
evaluation/Num Paths                    24
evaluation/Average Returns            -188.718
time/data storing (s)                    0.00731422
time/evaluation sampling (s)           440.543
time/exploration sampling (s)          114.639
time/logging (s)                         0.0250276
time/sac training (s)                    9.19827
time/saving (s)                          0.0264846
time/training (s)                        0.000115859
time/epoch (s)                         564.439
time/total (s)                       59495.6
Epoch                                   87
----------------------------------  ----------------
2020-11-02 02:33:36.541518 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 88 finished
----------------------------------  ----------------
replay_buffer/size                   90000
trainer/num train calls              89000
trainer/QF1 Loss                        27.5453
trainer/QF2 Loss                        28.369
trainer/Policy Loss                    147.314
trainer/Q1 Predictions Mean           -146.64
trainer/Q1 Predictions Std              40.0058
trainer/Q1 Predictions Max             -19.4059
trainer/Q1 Predictions Min            -213.231
trainer/Q2 Predictions Mean           -146.403
trainer/Q2 Predictions Std              39.7958
trainer/Q2 Predictions Max             -21.7332
trainer/Q2 Predictions Min            -212.797
trainer/Q Targets Mean                -147.348
trainer/Q Targets Std                   39.6508
trainer/Q Targets Max                  -22.3472
trainer/Q Targets Min                 -217.477
trainer/Log Pis Mean                     1.7646
trainer/Log Pis Std                      2.09004
trainer/Log Pis Max                      7.0548
trainer/Log Pis Min                     -5.35529
trainer/policy/mean Mean                -0.219586
trainer/policy/mean Std                  0.809571
trainer/policy/mean Max                  0.999255
trainer/policy/mean Min                 -0.994228
trainer/policy/normal/std Mean           0.62859
trainer/policy/normal/std Std            0.0767978
trainer/policy/normal/std Max            0.826074
trainer/policy/normal/std Min            0.406946
trainer/policy/normal/log_std Mean      -0.471792
trainer/policy/normal/log_std Std        0.122983
trainer/policy/normal/log_std Max       -0.191071
trainer/policy/normal/log_std Min       -0.899074
trainer/Alpha                            0.0447228
trainer/Alpha Loss                      -0.731461
exploration/num steps total          90000
exploration/num paths total            450
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00761
exploration/Rewards Std                  0.198884
exploration/Rewards Max                 -0.573821
exploration/Rewards Min                 -1.62764
exploration/Returns Mean              -201.522
exploration/Returns Std                 25.7479
exploration/Returns Max               -168.297
exploration/Returns Min               -241.11
exploration/Actions Mean                -0.0397477
exploration/Actions Std                  0.74948
exploration/Actions Max                  0.999666
exploration/Actions Min                 -0.999564
exploration/Num Paths                    5
exploration/Average Returns           -201.522
evaluation/num steps total          429336
evaluation/num paths total            2136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.979603
evaluation/Rewards Std                   0.233846
evaluation/Rewards Max                  -0.555509
evaluation/Rewards Min                  -1.65625
evaluation/Returns Mean               -196.9
evaluation/Returns Std                  35.0152
evaluation/Returns Max                -151.37
evaluation/Returns Min                -277.531
evaluation/Actions Mean                 -0.216284
evaluation/Actions Std                   0.700705
evaluation/Actions Max                   0.999825
evaluation/Actions Min                  -0.999032
evaluation/Num Paths                    24
evaluation/Average Returns            -196.9
time/data storing (s)                    0.00632171
time/evaluation sampling (s)           477.074
time/exploration sampling (s)          106.888
time/logging (s)                         0.0255554
time/sac training (s)                    9.61667
time/saving (s)                          0.0330855
time/training (s)                        0.000127496
time/epoch (s)                         593.644
time/total (s)                       60090.1
Epoch                                   88
----------------------------------  ----------------
2020-11-02 02:42:27.661108 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 89 finished
----------------------------------  ----------------
replay_buffer/size                   91000
trainer/num train calls              90000
trainer/QF1 Loss                        60.1541
trainer/QF2 Loss                        50.3811
trainer/Policy Loss                    147.617
trainer/Q1 Predictions Mean           -146.471
trainer/Q1 Predictions Std              41.7312
trainer/Q1 Predictions Max              17.5242
trainer/Q1 Predictions Min            -213.82
trainer/Q2 Predictions Mean           -147.068
trainer/Q2 Predictions Std              41.3296
trainer/Q2 Predictions Max              19.9213
trainer/Q2 Predictions Min            -214.311
trainer/Q Targets Mean                -147.467
trainer/Q Targets Std                   42.5318
trainer/Q Targets Max                   31.6003
trainer/Q Targets Min                 -216.734
trainer/Log Pis Mean                     2.03473
trainer/Log Pis Std                      2.13526
trainer/Log Pis Max                      8.29742
trainer/Log Pis Min                     -3.86093
trainer/policy/mean Mean                -0.223263
trainer/policy/mean Std                  0.797038
trainer/policy/mean Max                  0.998665
trainer/policy/mean Min                 -0.995114
trainer/policy/normal/std Mean           0.616509
trainer/policy/normal/std Std            0.0870108
trainer/policy/normal/std Max            0.845047
trainer/policy/normal/std Min            0.405999
trainer/policy/normal/log_std Mean      -0.493646
trainer/policy/normal/log_std Std        0.141322
trainer/policy/normal/log_std Max       -0.168363
trainer/policy/normal/log_std Min       -0.901404
trainer/Alpha                            0.0428659
trainer/Alpha Loss                       0.109391
exploration/num steps total          91000
exploration/num paths total            455
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.954057
exploration/Rewards Std                  0.202569
exploration/Rewards Max                 -0.554417
exploration/Rewards Min                 -1.52209
exploration/Returns Mean              -190.811
exploration/Returns Std                 19.1998
exploration/Returns Max               -162.537
exploration/Returns Min               -210.541
exploration/Actions Mean                -0.278616
exploration/Actions Std                  0.735195
exploration/Actions Max                  0.998187
exploration/Actions Min                 -0.999732
exploration/Num Paths                    5
exploration/Average Returns           -190.811
evaluation/num steps total          434160
evaluation/num paths total            2160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.960052
evaluation/Rewards Std                   0.211377
evaluation/Rewards Max                  -0.565396
evaluation/Rewards Min                  -1.60434
evaluation/Returns Mean               -192.97
evaluation/Returns Std                  25.5536
evaluation/Returns Max                -154.193
evaluation/Returns Min                -247.385
evaluation/Actions Mean                 -0.199222
evaluation/Actions Std                   0.723716
evaluation/Actions Max                   0.99977
evaluation/Actions Min                  -0.999109
evaluation/Num Paths                    24
evaluation/Average Returns            -192.97
time/data storing (s)                    0.00986249
time/evaluation sampling (s)           426.219
time/exploration sampling (s)           94.9666
time/logging (s)                         0.0183885
time/sac training (s)                    9.22991
time/saving (s)                          0.0292559
time/training (s)                        0.000114231
time/epoch (s)                         530.473
time/total (s)                       60621.2
Epoch                                   89
----------------------------------  ----------------
2020-11-02 02:52:20.295053 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 90 finished
----------------------------------  ----------------
replay_buffer/size                   92000
trainer/num train calls              91000
trainer/QF1 Loss                       111.541
trainer/QF2 Loss                       127.607
trainer/Policy Loss                    152.718
trainer/Q1 Predictions Mean           -151.945
trainer/Q1 Predictions Std              40.0294
trainer/Q1 Predictions Max             -50.3976
trainer/Q1 Predictions Min            -215.435
trainer/Q2 Predictions Mean           -151.788
trainer/Q2 Predictions Std              39.9123
trainer/Q2 Predictions Max             -54.28
trainer/Q2 Predictions Min            -216.116
trainer/Q Targets Mean                -151.847
trainer/Q Targets Std                   40.4641
trainer/Q Targets Max                   -1.15012
trainer/Q Targets Min                 -217.489
trainer/Log Pis Mean                     1.51979
trainer/Log Pis Std                      2.13615
trainer/Log Pis Max                      7.75531
trainer/Log Pis Min                     -6.22152
trainer/policy/mean Mean                -0.295804
trainer/policy/mean Std                  0.762552
trainer/policy/mean Max                  0.998192
trainer/policy/mean Min                 -0.994478
trainer/policy/normal/std Mean           0.636355
trainer/policy/normal/std Std            0.0813939
trainer/policy/normal/std Max            0.919403
trainer/policy/normal/std Min            0.434975
trainer/policy/normal/log_std Mean      -0.460149
trainer/policy/normal/log_std Std        0.127722
trainer/policy/normal/log_std Max       -0.0840308
trainer/policy/normal/log_std Min       -0.832466
trainer/Alpha                            0.0422429
trainer/Alpha Loss                      -1.51954
exploration/num steps total          92000
exploration/num paths total            460
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.934706
exploration/Rewards Std                  0.246969
exploration/Rewards Max                 -0.617104
exploration/Rewards Min                 -1.73967
exploration/Returns Mean              -186.941
exploration/Returns Std                 37.4095
exploration/Returns Max               -164.215
exploration/Returns Min               -261.464
exploration/Actions Mean                -0.344682
exploration/Actions Std                  0.650603
exploration/Actions Max                  0.997452
exploration/Actions Min                 -0.998491
exploration/Num Paths                    5
exploration/Average Returns           -186.941
evaluation/num steps total          438984
evaluation/num paths total            2184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.974216
evaluation/Rewards Std                   0.210742
evaluation/Rewards Max                  -0.552146
evaluation/Rewards Min                  -1.65025
evaluation/Returns Mean               -195.817
evaluation/Returns Std                  28.1134
evaluation/Returns Max                -157.175
evaluation/Returns Min                -271.841
evaluation/Actions Mean                 -0.252918
evaluation/Actions Std                   0.689709
evaluation/Actions Max                   0.998171
evaluation/Actions Min                  -0.99868
evaluation/Num Paths                    24
evaluation/Average Returns            -195.817
time/data storing (s)                    0.00766873
time/evaluation sampling (s)           472.429
time/exploration sampling (s)          109.745
time/logging (s)                         0.0220094
time/sac training (s)                    9.76364
time/saving (s)                          0.0265643
time/training (s)                        0.000125702
time/epoch (s)                         591.994
time/total (s)                       61213.8
Epoch                                   90
----------------------------------  ----------------
2020-11-02 03:00:59.699752 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 91 finished
----------------------------------  ----------------
replay_buffer/size                   93000
trainer/num train calls              92000
trainer/QF1 Loss                       114.651
trainer/QF2 Loss                       114.375
trainer/Policy Loss                    152.602
trainer/Q1 Predictions Mean           -151.754
trainer/Q1 Predictions Std              43.0287
trainer/Q1 Predictions Max              13.3508
trainer/Q1 Predictions Min            -222.36
trainer/Q2 Predictions Mean           -151.796
trainer/Q2 Predictions Std              43.137
trainer/Q2 Predictions Max              21.1362
trainer/Q2 Predictions Min            -220.46
trainer/Q Targets Mean                -150.87
trainer/Q Targets Std                   43.8378
trainer/Q Targets Max                   13.6043
trainer/Q Targets Min                 -221.343
trainer/Log Pis Mean                     2.37353
trainer/Log Pis Std                      2.15965
trainer/Log Pis Max                      9.50907
trainer/Log Pis Min                     -6.08503
trainer/policy/mean Mean                -0.329468
trainer/policy/mean Std                  0.772285
trainer/policy/mean Max                  0.999075
trainer/policy/mean Min                 -0.997956
trainer/policy/normal/std Mean           0.624706
trainer/policy/normal/std Std            0.0883392
trainer/policy/normal/std Max            0.950148
trainer/policy/normal/std Min            0.44329
trainer/policy/normal/log_std Mean      -0.480374
trainer/policy/normal/log_std Std        0.140499
trainer/policy/normal/log_std Max       -0.0511378
trainer/policy/normal/log_std Min       -0.813532
trainer/Alpha                            0.0430733
trainer/Alpha Loss                       1.17471
exploration/num steps total          93000
exploration/num paths total            465
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.946887
exploration/Rewards Std                  0.232629
exploration/Rewards Max                 -0.609537
exploration/Rewards Min                 -1.74473
exploration/Returns Mean              -189.377
exploration/Returns Std                 19.4258
exploration/Returns Max               -170.174
exploration/Returns Min               -220.493
exploration/Actions Mean                -0.353721
exploration/Actions Std                  0.712423
exploration/Actions Max                  0.995239
exploration/Actions Min                 -0.999852
exploration/Num Paths                    5
exploration/Average Returns           -189.377
evaluation/num steps total          443808
evaluation/num paths total            2208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.946838
evaluation/Rewards Std                   0.211377
evaluation/Rewards Max                  -0.571383
evaluation/Rewards Min                  -1.68201
evaluation/Returns Mean               -190.314
evaluation/Returns Std                  25.1273
evaluation/Returns Max                -157.195
evaluation/Returns Min                -262.131
evaluation/Actions Mean                 -0.270347
evaluation/Actions Std                   0.71596
evaluation/Actions Max                   0.999584
evaluation/Actions Min                  -0.997172
evaluation/Num Paths                    24
evaluation/Average Returns            -190.314
time/data storing (s)                    0.00885267
time/evaluation sampling (s)           415.213
time/exploration sampling (s)           94.2023
time/logging (s)                         0.0209831
time/sac training (s)                    9.2792
time/saving (s)                          0.0230138
time/training (s)                        0.000122304
time/epoch (s)                         518.747
time/total (s)                       61733.2
Epoch                                   91
----------------------------------  ----------------
2020-11-02 03:11:04.305254 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 92 finished
----------------------------------  ----------------
replay_buffer/size                   94000
trainer/num train calls              93000
trainer/QF1 Loss                        27.5292
trainer/QF2 Loss                        23.4544
trainer/Policy Loss                    148.601
trainer/Q1 Predictions Mean           -147.76
trainer/Q1 Predictions Std              40.6933
trainer/Q1 Predictions Max               7.6294
trainer/Q1 Predictions Min            -215.063
trainer/Q2 Predictions Mean           -148.014
trainer/Q2 Predictions Std              40.3854
trainer/Q2 Predictions Max               4.29286
trainer/Q2 Predictions Min            -214.559
trainer/Q Targets Mean                -149.167
trainer/Q Targets Std                   40.3661
trainer/Q Targets Max                    7.93932
trainer/Q Targets Min                 -217.859
trainer/Log Pis Mean                     1.99018
trainer/Log Pis Std                      1.9503
trainer/Log Pis Max                      9.69878
trainer/Log Pis Min                     -3.65578
trainer/policy/mean Mean                -0.268192
trainer/policy/mean Std                  0.782555
trainer/policy/mean Max                  0.999698
trainer/policy/mean Min                 -0.9946
trainer/policy/normal/std Mean           0.624176
trainer/policy/normal/std Std            0.0848875
trainer/policy/normal/std Max            0.841036
trainer/policy/normal/std Min            0.378776
trainer/policy/normal/log_std Mean      -0.480693
trainer/policy/normal/log_std Std        0.137529
trainer/policy/normal/log_std Max       -0.173121
trainer/policy/normal/log_std Min       -0.97081
trainer/Alpha                            0.0428351
trainer/Alpha Loss                      -0.0309334
exploration/num steps total          94000
exploration/num paths total            470
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.08944
exploration/Rewards Std                  0.128664
exploration/Rewards Max                 -0.783494
exploration/Rewards Min                 -1.56179
exploration/Returns Mean              -217.889
exploration/Returns Std                 10.3817
exploration/Returns Max               -206.723
exploration/Returns Min               -234.154
exploration/Actions Mean                -0.136691
exploration/Actions Std                  0.723772
exploration/Actions Max                  0.999587
exploration/Actions Min                 -0.999451
exploration/Num Paths                    5
exploration/Average Returns           -217.889
evaluation/num steps total          448632
evaluation/num paths total            2232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95833
evaluation/Rewards Std                   0.216409
evaluation/Rewards Max                  -0.561689
evaluation/Rewards Min                  -1.73037
evaluation/Returns Mean               -192.624
evaluation/Returns Std                  26.8725
evaluation/Returns Max                -160.971
evaluation/Returns Min                -270.618
evaluation/Actions Mean                 -0.233686
evaluation/Actions Std                   0.695905
evaluation/Actions Max                   0.999574
evaluation/Actions Min                  -0.996406
evaluation/Num Paths                    24
evaluation/Average Returns            -192.624
time/data storing (s)                    0.00948837
time/evaluation sampling (s)           476.968
time/exploration sampling (s)          117.645
time/logging (s)                         0.023426
time/sac training (s)                    9.28068
time/saving (s)                          0.0247601
time/training (s)                        0.000118003
time/epoch (s)                         603.951
time/total (s)                       62337.8
Epoch                                   92
----------------------------------  ----------------
2020-11-02 03:20:54.798198 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 93 finished
----------------------------------  ----------------
replay_buffer/size                   95000
trainer/num train calls              94000
trainer/QF1 Loss                        27.3872
trainer/QF2 Loss                        27.1113
trainer/Policy Loss                    148.041
trainer/Q1 Predictions Mean           -147.49
trainer/Q1 Predictions Std              43.2112
trainer/Q1 Predictions Max             -12.4867
trainer/Q1 Predictions Min            -220.153
trainer/Q2 Predictions Mean           -147.24
trainer/Q2 Predictions Std              43.2775
trainer/Q2 Predictions Max             -11.3592
trainer/Q2 Predictions Min            -217.418
trainer/Q Targets Mean                -148.208
trainer/Q Targets Std                   43.9423
trainer/Q Targets Max                  -19.4731
trainer/Q Targets Min                 -217.819
trainer/Log Pis Mean                     1.73085
trainer/Log Pis Std                      2.36867
trainer/Log Pis Max                      8.35151
trainer/Log Pis Min                     -5.163
trainer/policy/mean Mean                -0.154141
trainer/policy/mean Std                  0.805113
trainer/policy/mean Max                  0.998122
trainer/policy/mean Min                 -0.989318
trainer/policy/normal/std Mean           0.628455
trainer/policy/normal/std Std            0.0757921
trainer/policy/normal/std Max            0.872959
trainer/policy/normal/std Min            0.43832
trainer/policy/normal/log_std Mean      -0.47181
trainer/policy/normal/log_std Std        0.121319
trainer/policy/normal/log_std Max       -0.135866
trainer/policy/normal/log_std Min       -0.824805
trainer/Alpha                            0.0426194
trainer/Alpha Loss                      -0.84929
exploration/num steps total          95000
exploration/num paths total            475
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.960171
exploration/Rewards Std                  0.150703
exploration/Rewards Max                 -0.702568
exploration/Rewards Min                 -1.43836
exploration/Returns Mean              -192.034
exploration/Returns Std                 10.1915
exploration/Returns Max               -176.541
exploration/Returns Min               -203.162
exploration/Actions Mean                -0.216818
exploration/Actions Std                  0.716368
exploration/Actions Max                  0.999048
exploration/Actions Min                 -0.998926
exploration/Num Paths                    5
exploration/Average Returns           -192.034
evaluation/num steps total          453456
evaluation/num paths total            2256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.984587
evaluation/Rewards Std                   0.201986
evaluation/Rewards Max                  -0.548145
evaluation/Rewards Min                  -1.73843
evaluation/Returns Mean               -197.902
evaluation/Returns Std                  27.671
evaluation/Returns Max                -154.092
evaluation/Returns Min                -283.958
evaluation/Actions Mean                 -0.172397
evaluation/Actions Std                   0.673646
evaluation/Actions Max                   0.996858
evaluation/Actions Min                  -0.995684
evaluation/Num Paths                    24
evaluation/Average Returns            -197.902
time/data storing (s)                    0.00730683
time/evaluation sampling (s)           469.591
time/exploration sampling (s)          110.654
time/logging (s)                         0.0205314
time/sac training (s)                    9.25184
time/saving (s)                          0.032196
time/training (s)                        0.000115692
time/epoch (s)                         589.557
time/total (s)                       62928.3
Epoch                                   93
----------------------------------  ----------------
2020-11-02 03:31:03.867029 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 94 finished
----------------------------------  ----------------
replay_buffer/size                   96000
trainer/num train calls              95000
trainer/QF1 Loss                        30.4295
trainer/QF2 Loss                        36.6243
trainer/Policy Loss                    148.608
trainer/Q1 Predictions Mean           -147.958
trainer/Q1 Predictions Std              39.3664
trainer/Q1 Predictions Max             -32.2607
trainer/Q1 Predictions Min            -220.265
trainer/Q2 Predictions Mean           -147.612
trainer/Q2 Predictions Std              39.5956
trainer/Q2 Predictions Max             -35.0903
trainer/Q2 Predictions Min            -221.865
trainer/Q Targets Mean                -148.542
trainer/Q Targets Std                   39.3952
trainer/Q Targets Max                  -42.4229
trainer/Q Targets Min                 -216.096
trainer/Log Pis Mean                     1.57321
trainer/Log Pis Std                      2.07029
trainer/Log Pis Max                      7.84559
trainer/Log Pis Min                     -4.74135
trainer/policy/mean Mean                -0.296811
trainer/policy/mean Std                  0.764436
trainer/policy/mean Max                  0.999911
trainer/policy/mean Min                 -0.996753
trainer/policy/normal/std Mean           0.633963
trainer/policy/normal/std Std            0.0821291
trainer/policy/normal/std Max            1.09043
trainer/policy/normal/std Min            0.350881
trainer/policy/normal/log_std Mean      -0.464034
trainer/policy/normal/log_std Std        0.128566
trainer/policy/normal/log_std Max        0.0865685
trainer/policy/normal/log_std Min       -1.04731
trainer/Alpha                            0.0444757
trainer/Alpha Loss                      -1.32853
exploration/num steps total          96000
exploration/num paths total            480
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.909724
exploration/Rewards Std                  0.177738
exploration/Rewards Max                 -0.620865
exploration/Rewards Min                 -1.54932
exploration/Returns Mean              -181.945
exploration/Returns Std                 16.192
exploration/Returns Max               -159.121
exploration/Returns Min               -209.529
exploration/Actions Mean                -0.241789
exploration/Actions Std                  0.706347
exploration/Actions Max                  0.998789
exploration/Actions Min                 -0.999414
exploration/Num Paths                    5
exploration/Average Returns           -181.945
evaluation/num steps total          458280
evaluation/num paths total            2280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00027
evaluation/Rewards Std                   0.217864
evaluation/Rewards Max                  -0.598828
evaluation/Rewards Min                  -2.07004
evaluation/Returns Mean               -201.055
evaluation/Returns Std                  29.8827
evaluation/Returns Max                -156.501
evaluation/Returns Min                -288.35
evaluation/Actions Mean                 -0.191781
evaluation/Actions Std                   0.714492
evaluation/Actions Max                   0.999989
evaluation/Actions Min                  -0.998939
evaluation/Num Paths                    24
evaluation/Average Returns            -201.055
time/data storing (s)                    0.00605385
time/evaluation sampling (s)           486.805
time/exploration sampling (s)          112.305
time/logging (s)                         0.0223146
time/sac training (s)                    9.24337
time/saving (s)                          0.0323012
time/training (s)                        0.000120409
time/epoch (s)                         608.414
time/total (s)                       63537.3
Epoch                                   94
----------------------------------  ----------------
2020-11-02 03:42:51.224116 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 95 finished
----------------------------------  ----------------
replay_buffer/size                   97000
trainer/num train calls              96000
trainer/QF1 Loss                        33.9951
trainer/QF2 Loss                        35.589
trainer/Policy Loss                    148.005
trainer/Q1 Predictions Mean           -146.96
trainer/Q1 Predictions Std              44.878
trainer/Q1 Predictions Max              39.5516
trainer/Q1 Predictions Min            -217.089
trainer/Q2 Predictions Mean           -147.413
trainer/Q2 Predictions Std              45.0698
trainer/Q2 Predictions Max              41.7317
trainer/Q2 Predictions Min            -218.1
trainer/Q Targets Mean                -147.233
trainer/Q Targets Std                   45.322
trainer/Q Targets Max                   49.401
trainer/Q Targets Min                 -217.754
trainer/Log Pis Mean                     1.82901
trainer/Log Pis Std                      2.09865
trainer/Log Pis Max                      8.23543
trainer/Log Pis Min                     -4.90794
trainer/policy/mean Mean                -0.345553
trainer/policy/mean Std                  0.766124
trainer/policy/mean Max                  0.998356
trainer/policy/mean Min                 -0.9928
trainer/policy/normal/std Mean           0.631576
trainer/policy/normal/std Std            0.0907771
trainer/policy/normal/std Max            0.901274
trainer/policy/normal/std Min            0.408085
trainer/policy/normal/log_std Mean      -0.469895
trainer/policy/normal/log_std Std        0.144259
trainer/policy/normal/log_std Max       -0.103945
trainer/policy/normal/log_std Min       -0.89628
trainer/Alpha                            0.045327
trainer/Alpha Loss                      -0.529013
exploration/num steps total          97000
exploration/num paths total            485
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01939
exploration/Rewards Std                  0.196
exploration/Rewards Max                 -0.634341
exploration/Rewards Min                 -1.87733
exploration/Returns Mean              -203.877
exploration/Returns Std                 25.0156
exploration/Returns Max               -179.749
exploration/Returns Min               -248.965
exploration/Actions Mean                -0.159576
exploration/Actions Std                  0.745672
exploration/Actions Max                  0.999864
exploration/Actions Min                 -0.998652
exploration/Num Paths                    5
exploration/Average Returns           -203.877
evaluation/num steps total          463104
evaluation/num paths total            2304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948016
evaluation/Rewards Std                   0.219225
evaluation/Rewards Max                  -0.575062
evaluation/Rewards Min                  -1.64654
evaluation/Returns Mean               -190.551
evaluation/Returns Std                  26.691
evaluation/Returns Max                -155.352
evaluation/Returns Min                -273.108
evaluation/Actions Mean                 -0.340418
evaluation/Actions Std                   0.646522
evaluation/Actions Max                   0.997195
evaluation/Actions Min                  -0.998753
evaluation/Num Paths                    24
evaluation/Average Returns            -190.551
time/data storing (s)                    0.1096
time/evaluation sampling (s)           534.184
time/exploration sampling (s)          157.059
time/logging (s)                         0.267159
time/sac training (s)                   13.7153
time/saving (s)                          0.712785
time/training (s)                        0.000148455
time/epoch (s)                         706.049
time/total (s)                       64244.8
Epoch                                   95
----------------------------------  ----------------
2020-11-02 03:52:12.878880 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 96 finished
----------------------------------  ----------------
replay_buffer/size                   98000
trainer/num train calls              97000
trainer/QF1 Loss                        29.0753
trainer/QF2 Loss                        27.4942
trainer/Policy Loss                    148.324
trainer/Q1 Predictions Mean           -147.359
trainer/Q1 Predictions Std              45.2493
trainer/Q1 Predictions Max               7.91842
trainer/Q1 Predictions Min            -220.386
trainer/Q2 Predictions Mean           -147.75
trainer/Q2 Predictions Std              45.5487
trainer/Q2 Predictions Max              -1.48104
trainer/Q2 Predictions Min            -222.029
trainer/Q Targets Mean                -147.427
trainer/Q Targets Std                   45.2128
trainer/Q Targets Max                    1.28042
trainer/Q Targets Min                 -220.234
trainer/Log Pis Mean                     2.16497
trainer/Log Pis Std                      2.04562
trainer/Log Pis Max                      7.77294
trainer/Log Pis Min                     -3.87878
trainer/policy/mean Mean                -0.422084
trainer/policy/mean Std                  0.73982
trainer/policy/mean Max                  0.996641
trainer/policy/mean Min                 -0.99421
trainer/policy/normal/std Mean           0.610669
trainer/policy/normal/std Std            0.0900668
trainer/policy/normal/std Max            0.989159
trainer/policy/normal/std Min            0.308993
trainer/policy/normal/log_std Mean      -0.50417
trainer/policy/normal/log_std Std        0.14887
trainer/policy/normal/log_std Max       -0.0109005
trainer/policy/normal/log_std Min       -1.17444
trainer/Alpha                            0.0463574
trainer/Alpha Loss                       0.506693
exploration/num steps total          98000
exploration/num paths total            490
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.944661
exploration/Rewards Std                  0.208809
exploration/Rewards Max                 -0.616231
exploration/Rewards Min                 -1.54975
exploration/Returns Mean              -188.932
exploration/Returns Std                 11.8987
exploration/Returns Max               -175.591
exploration/Returns Min               -205.555
exploration/Actions Mean                -0.379035
exploration/Actions Std                  0.696795
exploration/Actions Max                  0.999831
exploration/Actions Min                 -0.999541
exploration/Num Paths                    5
exploration/Average Returns           -188.932
evaluation/num steps total          467928
evaluation/num paths total            2328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.910719
evaluation/Rewards Std                   0.210849
evaluation/Rewards Max                  -0.555927
evaluation/Rewards Min                  -1.6476
evaluation/Returns Mean               -183.055
evaluation/Returns Std                  19.7925
evaluation/Returns Max                -150.292
evaluation/Returns Min                -227.264
evaluation/Actions Mean                 -0.32023
evaluation/Actions Std                   0.691963
evaluation/Actions Max                   0.99943
evaluation/Actions Min                  -0.99964
evaluation/Num Paths                    24
evaluation/Average Returns            -183.055
time/data storing (s)                    0.0144433
time/evaluation sampling (s)           446.199
time/exploration sampling (s)          104.395
time/logging (s)                         0.0555362
time/sac training (s)                    9.57302
time/saving (s)                          0.0593661
time/training (s)                        0.000141635
time/epoch (s)                         560.297
time/total (s)                       64806.2
Epoch                                   96
----------------------------------  ----------------
2020-11-02 04:02:27.179909 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 97 finished
----------------------------------  ----------------
replay_buffer/size                   99000
trainer/num train calls              98000
trainer/QF1 Loss                        38.6215
trainer/QF2 Loss                        36.2565
trainer/Policy Loss                    148.335
trainer/Q1 Predictions Mean           -147.473
trainer/Q1 Predictions Std              41.922
trainer/Q1 Predictions Max             -20.2777
trainer/Q1 Predictions Min            -221.323
trainer/Q2 Predictions Mean           -147.716
trainer/Q2 Predictions Std              42.0236
trainer/Q2 Predictions Max             -19.6784
trainer/Q2 Predictions Min            -222.784
trainer/Q Targets Mean                -148.452
trainer/Q Targets Std                   42.6193
trainer/Q Targets Max                   -0.74331
trainer/Q Targets Min                 -221.265
trainer/Log Pis Mean                     1.89605
trainer/Log Pis Std                      2.18372
trainer/Log Pis Max                      9.3678
trainer/Log Pis Min                     -4.37645
trainer/policy/mean Mean                -0.243945
trainer/policy/mean Std                  0.795371
trainer/policy/mean Max                  0.998856
trainer/policy/mean Min                 -0.991647
trainer/policy/normal/std Mean           0.63727
trainer/policy/normal/std Std            0.0861975
trainer/policy/normal/std Max            0.882621
trainer/policy/normal/std Min            0.315746
trainer/policy/normal/log_std Mean      -0.459782
trainer/policy/normal/log_std Std        0.136402
trainer/policy/normal/log_std Max       -0.124859
trainer/policy/normal/log_std Min       -1.15282
trainer/Alpha                            0.0450275
trainer/Alpha Loss                      -0.322303
exploration/num steps total          99000
exploration/num paths total            495
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.938546
exploration/Rewards Std                  0.202205
exploration/Rewards Max                 -0.563942
exploration/Rewards Min                 -1.51312
exploration/Returns Mean              -187.709
exploration/Returns Std                 12.4467
exploration/Returns Max               -164.885
exploration/Returns Min               -197.565
exploration/Actions Mean                -0.172739
exploration/Actions Std                  0.745363
exploration/Actions Max                  0.999765
exploration/Actions Min                 -0.999147
exploration/Num Paths                    5
exploration/Average Returns           -187.709
evaluation/num steps total          472752
evaluation/num paths total            2352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.966251
evaluation/Rewards Std                   0.194813
evaluation/Rewards Max                  -0.591673
evaluation/Rewards Min                  -1.57025
evaluation/Returns Mean               -194.216
evaluation/Returns Std                  22.2879
evaluation/Returns Max                -155.401
evaluation/Returns Min                -241.205
evaluation/Actions Mean                 -0.242326
evaluation/Actions Std                   0.652963
evaluation/Actions Max                   0.997562
evaluation/Actions Min                  -0.994535
evaluation/Num Paths                    24
evaluation/Average Returns            -194.216
time/data storing (s)                    0.0106309
time/evaluation sampling (s)           497.791
time/exploration sampling (s)          106.159
time/logging (s)                         0.0317716
time/sac training (s)                    9.26699
time/saving (s)                          0.0354809
time/training (s)                        0.000128765
time/epoch (s)                         613.295
time/total (s)                       65420.5
Epoch                                   97
----------------------------------  ----------------
2020-11-02 04:11:55.302043 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 98 finished
----------------------------------  ----------------
replay_buffer/size                  100000
trainer/num train calls              99000
trainer/QF1 Loss                        77.7424
trainer/QF2 Loss                        80.7952
trainer/Policy Loss                    146.977
trainer/Q1 Predictions Mean           -146.384
trainer/Q1 Predictions Std              46.4072
trainer/Q1 Predictions Max              14.0285
trainer/Q1 Predictions Min            -223.788
trainer/Q2 Predictions Mean           -146.331
trainer/Q2 Predictions Std              46.8493
trainer/Q2 Predictions Max              17.7282
trainer/Q2 Predictions Min            -223.41
trainer/Q Targets Mean                -145.698
trainer/Q Targets Std                   46.9053
trainer/Q Targets Max                   11.9832
trainer/Q Targets Min                 -219.069
trainer/Log Pis Mean                     2.15073
trainer/Log Pis Std                      2.10466
trainer/Log Pis Max                      6.8798
trainer/Log Pis Min                     -4.8701
trainer/policy/mean Mean                -0.33205
trainer/policy/mean Std                  0.780248
trainer/policy/mean Max                  0.99858
trainer/policy/mean Min                 -0.998065
trainer/policy/normal/std Mean           0.610948
trainer/policy/normal/std Std            0.0870602
trainer/policy/normal/std Max            0.869614
trainer/policy/normal/std Min            0.317631
trainer/policy/normal/log_std Mean      -0.503136
trainer/policy/normal/log_std Std        0.145481
trainer/policy/normal/log_std Max       -0.139706
trainer/policy/normal/log_std Min       -1.14686
trainer/Alpha                            0.0419684
trainer/Alpha Loss                       0.477931
exploration/num steps total         100000
exploration/num paths total            500
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.912938
exploration/Rewards Std                  0.17101
exploration/Rewards Max                 -0.622654
exploration/Rewards Min                 -1.49312
exploration/Returns Mean              -182.588
exploration/Returns Std                 12.633
exploration/Returns Max               -164.365
exploration/Returns Min               -195.051
exploration/Actions Mean                -0.164219
exploration/Actions Std                  0.725375
exploration/Actions Max                  0.998296
exploration/Actions Min                 -0.999362
exploration/Num Paths                    5
exploration/Average Returns           -182.588
evaluation/num steps total          477576
evaluation/num paths total            2376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.950932
evaluation/Rewards Std                   0.219461
evaluation/Rewards Max                  -0.574264
evaluation/Rewards Min                  -1.80485
evaluation/Returns Mean               -191.137
evaluation/Returns Std                  25.0345
evaluation/Returns Max                -160.854
evaluation/Returns Min                -256.057
evaluation/Actions Mean                 -0.273231
evaluation/Actions Std                   0.716972
evaluation/Actions Max                   0.999998
evaluation/Actions Min                  -0.998245
evaluation/Num Paths                    24
evaluation/Average Returns            -191.137
time/data storing (s)                    0.00644501
time/evaluation sampling (s)           455.838
time/exploration sampling (s)          102.301
time/logging (s)                         0.0192532
time/sac training (s)                    9.26734
time/saving (s)                          0.0251447
time/training (s)                        0.000130277
time/epoch (s)                         567.457
time/total (s)                       65988.6
Epoch                                   98
----------------------------------  ----------------
2020-11-02 04:21:02.509841 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 99 finished
----------------------------------  ----------------
replay_buffer/size                  101000
trainer/num train calls             100000
trainer/QF1 Loss                        30.0721
trainer/QF2 Loss                        26.4407
trainer/Policy Loss                    151.502
trainer/Q1 Predictions Mean           -150.992
trainer/Q1 Predictions Std              42.942
trainer/Q1 Predictions Max               7.27219
trainer/Q1 Predictions Min            -223.35
trainer/Q2 Predictions Mean           -150.855
trainer/Q2 Predictions Std              42.9439
trainer/Q2 Predictions Max              12.2157
trainer/Q2 Predictions Min            -221.9
trainer/Q Targets Mean                -151.223
trainer/Q Targets Std                   43.7364
trainer/Q Targets Max                    2.46295
trainer/Q Targets Min                 -224.078
trainer/Log Pis Mean                     2.04769
trainer/Log Pis Std                      2.24674
trainer/Log Pis Max                      8.50542
trainer/Log Pis Min                     -3.92837
trainer/policy/mean Mean                -0.496877
trainer/policy/mean Std                  0.685479
trainer/policy/mean Max                  0.997336
trainer/policy/mean Min                 -0.999683
trainer/policy/normal/std Mean           0.646903
trainer/policy/normal/std Std            0.0866145
trainer/policy/normal/std Max            0.878299
trainer/policy/normal/std Min            0.446506
trainer/policy/normal/log_std Mean      -0.444495
trainer/policy/normal/log_std Std        0.13374
trainer/policy/normal/log_std Max       -0.129768
trainer/policy/normal/log_std Min       -0.806302
trainer/Alpha                            0.0457935
trainer/Alpha Loss                       0.147054
exploration/num steps total         101000
exploration/num paths total            505
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.948678
exploration/Rewards Std                  0.178184
exploration/Rewards Max                 -0.530774
exploration/Rewards Min                 -1.44777
exploration/Returns Mean              -189.736
exploration/Returns Std                 22.4915
exploration/Returns Max               -152.981
exploration/Returns Min               -216.148
exploration/Actions Mean                -0.278431
exploration/Actions Std                  0.658924
exploration/Actions Max                  0.999068
exploration/Actions Min                 -0.999135
exploration/Num Paths                    5
exploration/Average Returns           -189.736
evaluation/num steps total          482400
evaluation/num paths total            2400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.933241
evaluation/Rewards Std                   0.213464
evaluation/Rewards Max                  -0.496856
evaluation/Rewards Min                  -1.65077
evaluation/Returns Mean               -187.581
evaluation/Returns Std                  24.4885
evaluation/Returns Max                -147.389
evaluation/Returns Min                -244.627
evaluation/Actions Mean                 -0.392568
evaluation/Actions Std                   0.624087
evaluation/Actions Max                   0.998724
evaluation/Actions Min                  -0.998011
evaluation/Num Paths                    24
evaluation/Average Returns            -187.581
time/data storing (s)                    0.00909735
time/evaluation sampling (s)           428.544
time/exploration sampling (s)          108.657
time/logging (s)                         0.0256143
time/sac training (s)                    9.3212
time/saving (s)                          0.0285247
time/training (s)                        0.000121739
time/epoch (s)                         546.585
time/total (s)                       66535.7
Epoch                                   99
----------------------------------  ----------------
2020-11-02 04:30:08.880303 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 100 finished
----------------------------------  ----------------
replay_buffer/size                  102000
trainer/num train calls             101000
trainer/QF1 Loss                        27.7218
trainer/QF2 Loss                        28.9062
trainer/Policy Loss                    158.129
trainer/Q1 Predictions Mean           -157.228
trainer/Q1 Predictions Std              39.1737
trainer/Q1 Predictions Max             -55.4713
trainer/Q1 Predictions Min            -222.36
trainer/Q2 Predictions Mean           -157.503
trainer/Q2 Predictions Std              39.4213
trainer/Q2 Predictions Max             -53.0313
trainer/Q2 Predictions Min            -224.226
trainer/Q Targets Mean                -156.864
trainer/Q Targets Std                   39.4599
trainer/Q Targets Max                  -35.4275
trainer/Q Targets Min                 -221.71
trainer/Log Pis Mean                     1.9458
trainer/Log Pis Std                      2.10582
trainer/Log Pis Max                      7.33303
trainer/Log Pis Min                     -5.22718
trainer/policy/mean Mean                -0.422669
trainer/policy/mean Std                  0.723888
trainer/policy/mean Max                  0.998602
trainer/policy/mean Min                 -0.996324
trainer/policy/normal/std Mean           0.631434
trainer/policy/normal/std Std            0.0944312
trainer/policy/normal/std Max            0.868717
trainer/policy/normal/std Min            0.394086
trainer/policy/normal/log_std Mean      -0.470701
trainer/policy/normal/log_std Std        0.147305
trainer/policy/normal/log_std Max       -0.140738
trainer/policy/normal/log_std Min       -0.931186
trainer/Alpha                            0.0467433
trainer/Alpha Loss                      -0.166027
exploration/num steps total         102000
exploration/num paths total            510
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.974141
exploration/Rewards Std                  0.23537
exploration/Rewards Max                 -0.544608
exploration/Rewards Min                 -1.62737
exploration/Returns Mean              -194.828
exploration/Returns Std                 27.2537
exploration/Returns Max               -164.914
exploration/Returns Min               -245.126
exploration/Actions Mean                -0.403206
exploration/Actions Std                  0.640608
exploration/Actions Max                  0.996903
exploration/Actions Min                 -0.999803
exploration/Num Paths                    5
exploration/Average Returns           -194.828
evaluation/num steps total          487224
evaluation/num paths total            2424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.928421
evaluation/Rewards Std                   0.218811
evaluation/Rewards Max                  -0.540889
evaluation/Rewards Min                  -2.1056
evaluation/Returns Mean               -186.613
evaluation/Returns Std                  26.8636
evaluation/Returns Max                -148.733
evaluation/Returns Min                -283.137
evaluation/Actions Mean                 -0.359503
evaluation/Actions Std                   0.631238
evaluation/Actions Max                   0.998789
evaluation/Actions Min                  -0.992918
evaluation/Num Paths                    24
evaluation/Average Returns            -186.613
time/data storing (s)                    0.0103194
time/evaluation sampling (s)           434.912
time/exploration sampling (s)          101.327
time/logging (s)                         0.0211058
time/sac training (s)                    9.4078
time/saving (s)                          0.0225568
time/training (s)                        0.000119416
time/epoch (s)                         545.701
time/total (s)                       67082.1
Epoch                                  100
----------------------------------  ----------------
2020-11-02 04:39:32.375616 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 101 finished
----------------------------------  ----------------
replay_buffer/size                  103000
trainer/num train calls             102000
trainer/QF1 Loss                        29.7078
trainer/QF2 Loss                        28.7846
trainer/Policy Loss                    151.604
trainer/Q1 Predictions Mean           -150.769
trainer/Q1 Predictions Std              43.7437
trainer/Q1 Predictions Max              28.1664
trainer/Q1 Predictions Min            -220.555
trainer/Q2 Predictions Mean           -150.794
trainer/Q2 Predictions Std              43.2051
trainer/Q2 Predictions Max              19.4448
trainer/Q2 Predictions Min            -220.715
trainer/Q Targets Mean                -150.611
trainer/Q Targets Std                   44.3228
trainer/Q Targets Max                   27.9726
trainer/Q Targets Min                 -224.808
trainer/Log Pis Mean                     1.98464
trainer/Log Pis Std                      2.30787
trainer/Log Pis Max                      7.21821
trainer/Log Pis Min                     -5.25129
trainer/policy/mean Mean                -0.513324
trainer/policy/mean Std                  0.677432
trainer/policy/mean Max                  0.999239
trainer/policy/mean Min                 -0.997205
trainer/policy/normal/std Mean           0.627188
trainer/policy/normal/std Std            0.0793966
trainer/policy/normal/std Max            0.899797
trainer/policy/normal/std Min            0.397301
trainer/policy/normal/log_std Mean      -0.474609
trainer/policy/normal/log_std Std        0.127917
trainer/policy/normal/log_std Max       -0.105586
trainer/policy/normal/log_std Min       -0.923061
trainer/Alpha                            0.043994
trainer/Alpha Loss                      -0.0479697
exploration/num steps total         103000
exploration/num paths total            515
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.907252
exploration/Rewards Std                  0.167802
exploration/Rewards Max                 -0.678832
exploration/Rewards Min                 -1.40589
exploration/Returns Mean              -181.45
exploration/Returns Std                  4.76946
exploration/Returns Max               -174.963
exploration/Returns Min               -187.305
exploration/Actions Mean                -0.225206
exploration/Actions Std                  0.76335
exploration/Actions Max                  0.999832
exploration/Actions Min                 -0.999761
exploration/Num Paths                    5
exploration/Average Returns           -181.45
evaluation/num steps total          492048
evaluation/num paths total            2448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.904343
evaluation/Rewards Std                   0.186621
evaluation/Rewards Max                  -0.518953
evaluation/Rewards Min                  -1.59076
evaluation/Returns Mean               -181.773
evaluation/Returns Std                  16.1312
evaluation/Returns Max                -153.693
evaluation/Returns Min                -216.893
evaluation/Actions Mean                 -0.337503
evaluation/Actions Std                   0.657597
evaluation/Actions Max                   0.998219
evaluation/Actions Min                  -0.996436
evaluation/Num Paths                    24
evaluation/Average Returns            -181.773
time/data storing (s)                    0.00968131
time/evaluation sampling (s)           447.655
time/exploration sampling (s)          105.253
time/logging (s)                         0.0371838
time/sac training (s)                    9.50244
time/saving (s)                          0.0336588
time/training (s)                        0.000116626
time/epoch (s)                         562.491
time/total (s)                       67645.6
Epoch                                  101
----------------------------------  ----------------
2020-11-02 04:49:02.623812 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 102 finished
----------------------------------  ----------------
replay_buffer/size                  104000
trainer/num train calls             103000
trainer/QF1 Loss                        35.9907
trainer/QF2 Loss                        34.8186
trainer/Policy Loss                    153.826
trainer/Q1 Predictions Mean           -153.073
trainer/Q1 Predictions Std              45.122
trainer/Q1 Predictions Max              -8.98081
trainer/Q1 Predictions Min            -219.451
trainer/Q2 Predictions Mean           -153.176
trainer/Q2 Predictions Std              45.4588
trainer/Q2 Predictions Max             -10.8107
trainer/Q2 Predictions Min            -220.274
trainer/Q Targets Mean                -154.478
trainer/Q Targets Std                   45.276
trainer/Q Targets Max                   -0.659741
trainer/Q Targets Min                 -223.038
trainer/Log Pis Mean                     1.9936
trainer/Log Pis Std                      2.26142
trainer/Log Pis Max                      8.46691
trainer/Log Pis Min                     -5.98871
trainer/policy/mean Mean                -0.251637
trainer/policy/mean Std                  0.785092
trainer/policy/mean Max                  0.999059
trainer/policy/mean Min                 -0.996651
trainer/policy/normal/std Mean           0.61989
trainer/policy/normal/std Std            0.0877184
trainer/policy/normal/std Max            0.908292
trainer/policy/normal/std Min            0.288742
trainer/policy/normal/log_std Mean      -0.488496
trainer/policy/normal/log_std Std        0.144982
trainer/policy/normal/log_std Max       -0.0961895
trainer/policy/normal/log_std Min       -1.24222
trainer/Alpha                            0.0430764
trainer/Alpha Loss                      -0.0201418
exploration/num steps total         104000
exploration/num paths total            520
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.918352
exploration/Rewards Std                  0.182794
exploration/Rewards Max                 -0.598335
exploration/Rewards Min                 -1.45662
exploration/Returns Mean              -183.67
exploration/Returns Std                 15.8867
exploration/Returns Max               -160.54
exploration/Returns Min               -201.243
exploration/Actions Mean                -0.175741
exploration/Actions Std                  0.720125
exploration/Actions Max                  0.999001
exploration/Actions Min                 -0.998755
exploration/Num Paths                    5
exploration/Average Returns           -183.67
evaluation/num steps total          496872
evaluation/num paths total            2472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.90786
evaluation/Rewards Std                   0.196242
evaluation/Rewards Max                  -0.58277
evaluation/Rewards Min                  -1.68089
evaluation/Returns Mean               -182.48
evaluation/Returns Std                  17.8605
evaluation/Returns Max                -152.48
evaluation/Returns Min                -224.989
evaluation/Actions Mean                 -0.350135
evaluation/Actions Std                   0.650521
evaluation/Actions Max                   0.999456
evaluation/Actions Min                  -0.994368
evaluation/Num Paths                    24
evaluation/Average Returns            -182.48
time/data storing (s)                    0.0109044
time/evaluation sampling (s)           455.754
time/exploration sampling (s)          104.496
time/logging (s)                         0.0188681
time/sac training (s)                    9.27569
time/saving (s)                          0.026073
time/training (s)                        0.000120266
time/epoch (s)                         569.582
time/total (s)                       68215.8
Epoch                                  102
----------------------------------  ----------------
2020-11-02 04:57:36.183432 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 103 finished
----------------------------------  ----------------
replay_buffer/size                  105000
trainer/num train calls             104000
trainer/QF1 Loss                        28.8839
trainer/QF2 Loss                        24.3289
trainer/Policy Loss                    153.581
trainer/Q1 Predictions Mean           -152.935
trainer/Q1 Predictions Std              43.1072
trainer/Q1 Predictions Max               5.04831
trainer/Q1 Predictions Min            -221.876
trainer/Q2 Predictions Mean           -152.95
trainer/Q2 Predictions Std              43.1954
trainer/Q2 Predictions Max               8.32191
trainer/Q2 Predictions Min            -221.874
trainer/Q Targets Mean                -153.028
trainer/Q Targets Std                   44.1319
trainer/Q Targets Max                   19.285
trainer/Q Targets Min                 -223.999
trainer/Log Pis Mean                     2.23545
trainer/Log Pis Std                      2.22926
trainer/Log Pis Max                      8.51577
trainer/Log Pis Min                     -4.06998
trainer/policy/mean Mean                -0.523701
trainer/policy/mean Std                  0.664157
trainer/policy/mean Max                  0.999
trainer/policy/mean Min                 -0.998204
trainer/policy/normal/std Mean           0.631314
trainer/policy/normal/std Std            0.0891355
trainer/policy/normal/std Max            0.887712
trainer/policy/normal/std Min            0.430193
trainer/policy/normal/log_std Mean      -0.469656
trainer/policy/normal/log_std Std        0.138564
trainer/policy/normal/log_std Max       -0.119107
trainer/policy/normal/log_std Min       -0.84352
trainer/Alpha                            0.0472879
trainer/Alpha Loss                       0.718461
exploration/num steps total         105000
exploration/num paths total            525
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.937685
exploration/Rewards Std                  0.17975
exploration/Rewards Max                 -0.703831
exploration/Rewards Min                 -1.54527
exploration/Returns Mean              -187.537
exploration/Returns Std                 11.3038
exploration/Returns Max               -176.4
exploration/Returns Min               -208.035
exploration/Actions Mean                -0.46876
exploration/Actions Std                  0.623521
exploration/Actions Max                  0.999619
exploration/Actions Min                 -0.999484
exploration/Num Paths                    5
exploration/Average Returns           -187.537
evaluation/num steps total          501696
evaluation/num paths total            2496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.944318
evaluation/Rewards Std                   0.218825
evaluation/Rewards Max                  -0.58369
evaluation/Rewards Min                  -1.78213
evaluation/Returns Mean               -189.808
evaluation/Returns Std                  23.3268
evaluation/Returns Max                -157.897
evaluation/Returns Min                -246.087
evaluation/Actions Mean                 -0.411691
evaluation/Actions Std                   0.644144
evaluation/Actions Max                   0.999326
evaluation/Actions Min                  -0.99733
evaluation/Num Paths                    24
evaluation/Average Returns            -189.808
time/data storing (s)                    0.00819438
time/evaluation sampling (s)           396.589
time/exploration sampling (s)          107.06
time/logging (s)                         0.0193532
time/sac training (s)                    9.20618
time/saving (s)                          0.0238702
time/training (s)                        0.000134796
time/epoch (s)                         512.907
time/total (s)                       68729.3
Epoch                                  103
----------------------------------  ----------------
2020-11-02 05:08:07.315752 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 104 finished
----------------------------------  ----------------
replay_buffer/size                  106000
trainer/num train calls             105000
trainer/QF1 Loss                        57.8099
trainer/QF2 Loss                        58.0644
trainer/Policy Loss                    156.382
trainer/Q1 Predictions Mean           -155.845
trainer/Q1 Predictions Std              42.4938
trainer/Q1 Predictions Max              22.9527
trainer/Q1 Predictions Min            -230.918
trainer/Q2 Predictions Mean           -155.436
trainer/Q2 Predictions Std              42.2819
trainer/Q2 Predictions Max              25.5957
trainer/Q2 Predictions Min            -226.397
trainer/Q Targets Mean                -154.632
trainer/Q Targets Std                   42.9964
trainer/Q Targets Max                   16.0017
trainer/Q Targets Min                 -229.144
trainer/Log Pis Mean                     1.81041
trainer/Log Pis Std                      2.02081
trainer/Log Pis Max                      8.2661
trainer/Log Pis Min                     -3.82404
trainer/policy/mean Mean                -0.226865
trainer/policy/mean Std                  0.787635
trainer/policy/mean Max                  0.999456
trainer/policy/mean Min                 -0.987632
trainer/policy/normal/std Mean           0.636386
trainer/policy/normal/std Std            0.0827303
trainer/policy/normal/std Max            0.899527
trainer/policy/normal/std Min            0.425052
trainer/policy/normal/log_std Mean      -0.460489
trainer/policy/normal/log_std Std        0.131233
trainer/policy/normal/log_std Max       -0.105886
trainer/policy/normal/log_std Min       -0.855545
trainer/Alpha                            0.043181
trainer/Alpha Loss                      -0.595772
exploration/num steps total         106000
exploration/num paths total            530
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.03589
exploration/Rewards Std                  0.244463
exploration/Rewards Max                 -0.598518
exploration/Rewards Min                 -1.67505
exploration/Returns Mean              -207.178
exploration/Returns Std                 34.5759
exploration/Returns Max               -158.256
exploration/Returns Min               -254.28
exploration/Actions Mean                -0.350357
exploration/Actions Std                  0.645226
exploration/Actions Max                  0.992954
exploration/Actions Min                 -0.998756
exploration/Num Paths                    5
exploration/Average Returns           -207.178
evaluation/num steps total          506520
evaluation/num paths total            2520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00495
evaluation/Rewards Std                   0.216649
evaluation/Rewards Max                  -0.524314
evaluation/Rewards Min                  -1.83442
evaluation/Returns Mean               -201.995
evaluation/Returns Std                  30.4401
evaluation/Returns Max                -159.924
evaluation/Returns Min                -289.538
evaluation/Actions Mean                 -0.213841
evaluation/Actions Std                   0.683109
evaluation/Actions Max                   0.999849
evaluation/Actions Min                  -0.999578
evaluation/Num Paths                    24
evaluation/Average Returns            -201.995
time/data storing (s)                    0.00740948
time/evaluation sampling (s)           511.195
time/exploration sampling (s)          109.28
time/logging (s)                         0.0332065
time/sac training (s)                    9.58904
time/saving (s)                          0.0395944
time/training (s)                        0.000109127
time/epoch (s)                         630.145
time/total (s)                       69360.4
Epoch                                  104
----------------------------------  ----------------
2020-11-02 05:17:17.191512 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 105 finished
----------------------------------  ----------------
replay_buffer/size                  107000
trainer/num train calls             106000
trainer/QF1 Loss                       121.485
trainer/QF2 Loss                       147.652
trainer/Policy Loss                    155.566
trainer/Q1 Predictions Mean           -154.411
trainer/Q1 Predictions Std              40.3403
trainer/Q1 Predictions Max               3.42264
trainer/Q1 Predictions Min            -225.076
trainer/Q2 Predictions Mean           -155.208
trainer/Q2 Predictions Std              40.3293
trainer/Q2 Predictions Max               3.15977
trainer/Q2 Predictions Min            -226.127
trainer/Q Targets Mean                -153.12
trainer/Q Targets Std                   42.7565
trainer/Q Targets Max                    0.167108
trainer/Q Targets Min                 -225.65
trainer/Log Pis Mean                     2.09716
trainer/Log Pis Std                      2.09307
trainer/Log Pis Max                      7.62004
trainer/Log Pis Min                     -6.96112
trainer/policy/mean Mean                -0.373677
trainer/policy/mean Std                  0.746059
trainer/policy/mean Max                  0.995684
trainer/policy/mean Min                 -0.994653
trainer/policy/normal/std Mean           0.628455
trainer/policy/normal/std Std            0.0975579
trainer/policy/normal/std Max            0.881886
trainer/policy/normal/std Min            0.366796
trainer/policy/normal/log_std Mean      -0.476512
trainer/policy/normal/log_std Std        0.155258
trainer/policy/normal/log_std Max       -0.125693
trainer/policy/normal/log_std Min       -1.00295
trainer/Alpha                            0.0426778
trainer/Alpha Loss                       0.306464
exploration/num steps total         107000
exploration/num paths total            535
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.950353
exploration/Rewards Std                  0.18316
exploration/Rewards Max                 -0.644877
exploration/Rewards Min                 -1.45692
exploration/Returns Mean              -190.071
exploration/Returns Std                 14.3851
exploration/Returns Max               -172.223
exploration/Returns Min               -214.079
exploration/Actions Mean                -0.0196917
exploration/Actions Std                  0.77094
exploration/Actions Max                  0.999953
exploration/Actions Min                 -0.998863
exploration/Num Paths                    5
exploration/Average Returns           -190.071
evaluation/num steps total          511344
evaluation/num paths total            2544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948792
evaluation/Rewards Std                   0.20285
evaluation/Rewards Max                  -0.591375
evaluation/Rewards Min                  -1.73729
evaluation/Returns Mean               -190.707
evaluation/Returns Std                  20.5696
evaluation/Returns Max                -161.588
evaluation/Returns Min                -231.934
evaluation/Actions Mean                 -0.265528
evaluation/Actions Std                   0.696475
evaluation/Actions Max                   0.995538
evaluation/Actions Min                  -0.999927
evaluation/Num Paths                    24
evaluation/Average Returns            -190.707
time/data storing (s)                    0.00611853
time/evaluation sampling (s)           435.906
time/exploration sampling (s)          104.006
time/logging (s)                         0.0203031
time/sac training (s)                    9.25718
time/saving (s)                          0.0219217
time/training (s)                        0.000118207
time/epoch (s)                         549.217
time/total (s)                       69910.3
Epoch                                  105
----------------------------------  ----------------
2020-11-02 05:26:21.998936 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 106 finished
----------------------------------  ----------------
replay_buffer/size                  108000
trainer/num train calls             107000
trainer/QF1 Loss                        32.6814
trainer/QF2 Loss                        30.0416
trainer/Policy Loss                    153.411
trainer/Q1 Predictions Mean           -152.61
trainer/Q1 Predictions Std              41.3943
trainer/Q1 Predictions Max              -5.60231
trainer/Q1 Predictions Min            -221.894
trainer/Q2 Predictions Mean           -152.659
trainer/Q2 Predictions Std              41.3309
trainer/Q2 Predictions Max              -9.45352
trainer/Q2 Predictions Min            -223.932
trainer/Q Targets Mean                -152.529
trainer/Q Targets Std                   41.6881
trainer/Q Targets Max                   -5.79906
trainer/Q Targets Min                 -224.372
trainer/Log Pis Mean                     2.4375
trainer/Log Pis Std                      2.59344
trainer/Log Pis Max                     11.6534
trainer/Log Pis Min                     -6.7702
trainer/policy/mean Mean                -0.557567
trainer/policy/mean Std                  0.647788
trainer/policy/mean Max                  0.99954
trainer/policy/mean Min                 -0.999837
trainer/policy/normal/std Mean           0.636763
trainer/policy/normal/std Std            0.0774127
trainer/policy/normal/std Max            0.898265
trainer/policy/normal/std Min            0.396054
trainer/policy/normal/log_std Mean      -0.458743
trainer/policy/normal/log_std Std        0.121754
trainer/policy/normal/log_std Max       -0.10729
trainer/policy/normal/log_std Min       -0.926206
trainer/Alpha                            0.0425886
trainer/Alpha Loss                       1.38084
exploration/num steps total         108000
exploration/num paths total            540
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.892555
exploration/Rewards Std                  0.189566
exploration/Rewards Max                 -0.533562
exploration/Rewards Min                 -1.38523
exploration/Returns Mean              -178.511
exploration/Returns Std                 16.7314
exploration/Returns Max               -150.651
exploration/Returns Min               -195.53
exploration/Actions Mean                -0.30036
exploration/Actions Std                  0.672243
exploration/Actions Max                  0.992729
exploration/Actions Min                 -0.999921
exploration/Num Paths                    5
exploration/Average Returns           -178.511
evaluation/num steps total          516168
evaluation/num paths total            2568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.93608
evaluation/Rewards Std                   0.238042
evaluation/Rewards Max                  -0.512738
evaluation/Rewards Min                  -2.09685
evaluation/Returns Mean               -188.152
evaluation/Returns Std                  26.1447
evaluation/Returns Max                -146.647
evaluation/Returns Min                -261.915
evaluation/Actions Mean                 -0.4467
evaluation/Actions Std                   0.595311
evaluation/Actions Max                   0.999517
evaluation/Actions Min                  -0.999779
evaluation/Num Paths                    24
evaluation/Average Returns            -188.152
time/data storing (s)                    0.00988311
time/evaluation sampling (s)           425.1
time/exploration sampling (s)          109.346
time/logging (s)                         0.0212954
time/sac training (s)                    9.3099
time/saving (s)                          0.0306814
time/training (s)                        0.000118251
time/epoch (s)                         543.818
time/total (s)                       70455
Epoch                                  106
----------------------------------  ----------------
2020-11-02 05:36:16.982517 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 107 finished
----------------------------------  ----------------
replay_buffer/size                  109000
trainer/num train calls             108000
trainer/QF1 Loss                       125.219
trainer/QF2 Loss                       139.987
trainer/Policy Loss                    156.657
trainer/Q1 Predictions Mean           -156.211
trainer/Q1 Predictions Std              44.0435
trainer/Q1 Predictions Max              27.0353
trainer/Q1 Predictions Min            -228.487
trainer/Q2 Predictions Mean           -155.405
trainer/Q2 Predictions Std              44.2434
trainer/Q2 Predictions Max              34.7306
trainer/Q2 Predictions Min            -229.102
trainer/Q Targets Mean                -154.797
trainer/Q Targets Std                   45.721
trainer/Q Targets Max                   35.4109
trainer/Q Targets Min                 -223.96
trainer/Log Pis Mean                     2.01124
trainer/Log Pis Std                      2.16934
trainer/Log Pis Max                     10.6121
trainer/Log Pis Min                     -4.80832
trainer/policy/mean Mean                -0.351993
trainer/policy/mean Std                  0.767198
trainer/policy/mean Max                  0.997817
trainer/policy/mean Min                 -0.997422
trainer/policy/normal/std Mean           0.623349
trainer/policy/normal/std Std            0.079452
trainer/policy/normal/std Max            0.952598
trainer/policy/normal/std Min            0.248391
trainer/policy/normal/log_std Mean      -0.480994
trainer/policy/normal/log_std Std        0.130743
trainer/policy/normal/log_std Max       -0.0485622
trainer/policy/normal/log_std Min       -1.39275
trainer/Alpha                            0.0436222
trainer/Alpha Loss                       0.0352074
exploration/num steps total         109000
exploration/num paths total            545
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.953562
exploration/Rewards Std                  0.130964
exploration/Rewards Max                 -0.728117
exploration/Rewards Min                 -1.34344
exploration/Returns Mean              -190.712
exploration/Returns Std                 10.5378
exploration/Returns Max               -181.403
exploration/Returns Min               -210.244
exploration/Actions Mean                -0.20123
exploration/Actions Std                  0.721042
exploration/Actions Max                  0.999157
exploration/Actions Min                 -0.999139
exploration/Num Paths                    5
exploration/Average Returns           -190.712
evaluation/num steps total          520992
evaluation/num paths total            2592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.947321
evaluation/Rewards Std                   0.201378
evaluation/Rewards Max                  -0.536161
evaluation/Rewards Min                  -1.6892
evaluation/Returns Mean               -190.412
evaluation/Returns Std                  22.2143
evaluation/Returns Max                -147.495
evaluation/Returns Min                -246.95
evaluation/Actions Mean                 -0.299195
evaluation/Actions Std                   0.6713
evaluation/Actions Max                   0.999207
evaluation/Actions Min                  -0.998816
evaluation/Num Paths                    24
evaluation/Average Returns            -190.412
time/data storing (s)                    0.00609721
time/evaluation sampling (s)           475.996
time/exploration sampling (s)          108.448
time/logging (s)                         0.0182554
time/sac training (s)                    9.85098
time/saving (s)                          0.0237993
time/training (s)                        0.000116519
time/epoch (s)                         594.343
time/total (s)                       71050
Epoch                                  107
----------------------------------  ----------------
2020-11-02 05:44:45.438530 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 108 finished
----------------------------------  ----------------
replay_buffer/size                  110000
trainer/num train calls             109000
trainer/QF1 Loss                        30.0693
trainer/QF2 Loss                        24.7229
trainer/Policy Loss                    151.299
trainer/Q1 Predictions Mean           -150.44
trainer/Q1 Predictions Std              41.9154
trainer/Q1 Predictions Max              48.1227
trainer/Q1 Predictions Min            -222.95
trainer/Q2 Predictions Mean           -150.519
trainer/Q2 Predictions Std              41.7208
trainer/Q2 Predictions Max              45.2965
trainer/Q2 Predictions Min            -223.264
trainer/Q Targets Mean                -151.444
trainer/Q Targets Std                   41.9672
trainer/Q Targets Max                   49.6417
trainer/Q Targets Min                 -223.051
trainer/Log Pis Mean                     2.32671
trainer/Log Pis Std                      2.15167
trainer/Log Pis Max                      7.33641
trainer/Log Pis Min                     -7.7715
trainer/policy/mean Mean                -0.468919
trainer/policy/mean Std                  0.710075
trainer/policy/mean Max                  0.997405
trainer/policy/mean Min                 -0.996229
trainer/policy/normal/std Mean           0.628041
trainer/policy/normal/std Std            0.0855717
trainer/policy/normal/std Max            0.88776
trainer/policy/normal/std Min            0.302743
trainer/policy/normal/log_std Mean      -0.474624
trainer/policy/normal/log_std Std        0.138838
trainer/policy/normal/log_std Max       -0.119054
trainer/policy/normal/log_std Min       -1.19487
trainer/Alpha                            0.0436499
trainer/Alpha Loss                       1.0231
exploration/num steps total         110000
exploration/num paths total            550
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.977393
exploration/Rewards Std                  0.19219
exploration/Rewards Max                 -0.586499
exploration/Rewards Min                 -1.5896
exploration/Returns Mean              -195.479
exploration/Returns Std                 24.9521
exploration/Returns Max               -165.968
exploration/Returns Min               -241.114
exploration/Actions Mean                -0.164561
exploration/Actions Std                  0.736172
exploration/Actions Max                  0.999891
exploration/Actions Min                 -0.999595
exploration/Num Paths                    5
exploration/Average Returns           -195.479
evaluation/num steps total          525816
evaluation/num paths total            2616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.907983
evaluation/Rewards Std                   0.221783
evaluation/Rewards Max                  -0.551946
evaluation/Rewards Min                  -1.76233
evaluation/Returns Mean               -182.505
evaluation/Returns Std                  22.0572
evaluation/Returns Max                -159.062
evaluation/Returns Min                -244.401
evaluation/Actions Mean                 -0.455469
evaluation/Actions Std                   0.627087
evaluation/Actions Max                   0.997492
evaluation/Actions Min                  -0.99973
evaluation/Num Paths                    24
evaluation/Average Returns            -182.505
time/data storing (s)                    0.0105482
time/evaluation sampling (s)           394.31
time/exploration sampling (s)          103.778
time/logging (s)                         0.0212131
time/sac training (s)                    9.66299
time/saving (s)                          0.0247147
time/training (s)                        0.000109586
time/epoch (s)                         507.807
time/total (s)                       71558.4
Epoch                                  108
----------------------------------  ----------------
2020-11-02 05:54:34.765440 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 109 finished
----------------------------------  ---------------
replay_buffer/size                  111000
trainer/num train calls             110000
trainer/QF1 Loss                        30.1573
trainer/QF2 Loss                        24.9526
trainer/Policy Loss                    157.286
trainer/Q1 Predictions Mean           -156.361
trainer/Q1 Predictions Std              42.6266
trainer/Q1 Predictions Max              42.858
trainer/Q1 Predictions Min            -228.743
trainer/Q2 Predictions Mean           -156.524
trainer/Q2 Predictions Std              42.7411
trainer/Q2 Predictions Max              44.8881
trainer/Q2 Predictions Min            -224.943
trainer/Q Targets Mean                -156.474
trainer/Q Targets Std                   42.135
trainer/Q Targets Max                   44.1057
trainer/Q Targets Min                 -224.982
trainer/Log Pis Mean                     1.89285
trainer/Log Pis Std                      2.21834
trainer/Log Pis Max                      9.09249
trainer/Log Pis Min                     -5.03063
trainer/policy/mean Mean                -0.273483
trainer/policy/mean Std                  0.779143
trainer/policy/mean Max                  0.999891
trainer/policy/mean Min                 -0.997671
trainer/policy/normal/std Mean           0.643649
trainer/policy/normal/std Std            0.0897879
trainer/policy/normal/std Max            0.981295
trainer/policy/normal/std Min            0.300895
trainer/policy/normal/log_std Mean      -0.450502
trainer/policy/normal/log_std Std        0.141832
trainer/policy/normal/log_std Max       -0.0188817
trainer/policy/normal/log_std Min       -1.201
trainer/Alpha                            0.0453736
trainer/Alpha Loss                      -0.331401
exploration/num steps total         111000
exploration/num paths total            555
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.916425
exploration/Rewards Std                  0.151084
exploration/Rewards Max                 -0.600552
exploration/Rewards Min                 -1.28166
exploration/Returns Mean              -183.285
exploration/Returns Std                 20.1277
exploration/Returns Max               -157.644
exploration/Returns Min               -208.904
exploration/Actions Mean                -0.179833
exploration/Actions Std                  0.695838
exploration/Actions Max                  0.998837
exploration/Actions Min                 -0.999369
exploration/Num Paths                    5
exploration/Average Returns           -183.285
evaluation/num steps total          530640
evaluation/num paths total            2640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.946128
evaluation/Rewards Std                   0.198732
evaluation/Rewards Max                  -0.557174
evaluation/Rewards Min                  -1.7149
evaluation/Returns Mean               -190.172
evaluation/Returns Std                  20.8216
evaluation/Returns Max                -154.503
evaluation/Returns Min                -231.697
evaluation/Actions Mean                 -0.204509
evaluation/Actions Std                   0.681655
evaluation/Actions Max                   0.999498
evaluation/Actions Min                  -0.999868
evaluation/Num Paths                    24
evaluation/Average Returns            -190.172
time/data storing (s)                    0.00943835
time/evaluation sampling (s)           468.944
time/exploration sampling (s)          110.489
time/logging (s)                         0.0278993
time/sac training (s)                    9.18981
time/saving (s)                          0.02682
time/training (s)                        0.00011378
time/epoch (s)                         588.687
time/total (s)                       72147.7
Epoch                                  109
----------------------------------  ---------------
2020-11-02 06:03:37.540459 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 110 finished
----------------------------------  ----------------
replay_buffer/size                  112000
trainer/num train calls             111000
trainer/QF1 Loss                        30.6044
trainer/QF2 Loss                        26.2611
trainer/Policy Loss                    152.399
trainer/Q1 Predictions Mean           -151.355
trainer/Q1 Predictions Std              42.0368
trainer/Q1 Predictions Max              -3.13808
trainer/Q1 Predictions Min            -223.749
trainer/Q2 Predictions Mean           -151.92
trainer/Q2 Predictions Std              42.0089
trainer/Q2 Predictions Max               4.09361
trainer/Q2 Predictions Min            -224.982
trainer/Q Targets Mean                -151.911
trainer/Q Targets Std                   41.6108
trainer/Q Targets Max                  -10.4921
trainer/Q Targets Min                 -223.045
trainer/Log Pis Mean                     2.71511
trainer/Log Pis Std                      2.34996
trainer/Log Pis Max                      9.03986
trainer/Log Pis Min                     -3.45435
trainer/policy/mean Mean                -0.566154
trainer/policy/mean Std                  0.656034
trainer/policy/mean Max                  0.999253
trainer/policy/mean Min                 -0.999352
trainer/policy/normal/std Mean           0.623117
trainer/policy/normal/std Std            0.086257
trainer/policy/normal/std Max            0.998902
trainer/policy/normal/std Min            0.408907
trainer/policy/normal/log_std Mean      -0.482493
trainer/policy/normal/log_std Std        0.137516
trainer/policy/normal/log_std Max       -0.001099
trainer/policy/normal/log_std Min       -0.894267
trainer/Alpha                            0.0435332
trainer/Alpha Loss                       2.24132
exploration/num steps total         112000
exploration/num paths total            560
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.847702
exploration/Rewards Std                  0.173083
exploration/Rewards Max                 -0.567735
exploration/Rewards Min                 -1.39951
exploration/Returns Mean              -169.54
exploration/Returns Std                 11.3208
exploration/Returns Max               -158.361
exploration/Returns Min               -191.092
exploration/Actions Mean                -0.602783
exploration/Actions Std                  0.539132
exploration/Actions Max                  0.991837
exploration/Actions Min                 -0.998753
exploration/Num Paths                    5
exploration/Average Returns           -169.54
evaluation/num steps total          535464
evaluation/num paths total            2664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.974696
evaluation/Rewards Std                   0.196819
evaluation/Rewards Max                  -0.594188
evaluation/Rewards Min                  -1.79845
evaluation/Returns Mean               -195.914
evaluation/Returns Std                  23.2879
evaluation/Returns Max                -166.005
evaluation/Returns Min                -259.629
evaluation/Actions Mean                 -0.3631
evaluation/Actions Std                   0.616297
evaluation/Actions Max                   0.998135
evaluation/Actions Min                  -0.999873
evaluation/Num Paths                    24
evaluation/Average Returns            -195.914
time/data storing (s)                    0.00820127
time/evaluation sampling (s)           436.534
time/exploration sampling (s)           96.0156
time/logging (s)                         0.0286897
time/sac training (s)                    9.16443
time/saving (s)                          0.0326551
time/training (s)                        0.000131231
time/epoch (s)                         541.784
time/total (s)                       72690.5
Epoch                                  110
----------------------------------  ----------------
2020-11-02 06:12:19.696780 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 111 finished
----------------------------------  ----------------
replay_buffer/size                  113000
trainer/num train calls             112000
trainer/QF1 Loss                       185.018
trainer/QF2 Loss                       191.465
trainer/Policy Loss                    157.861
trainer/Q1 Predictions Mean           -157.044
trainer/Q1 Predictions Std              40.0284
trainer/Q1 Predictions Max               4.74635
trainer/Q1 Predictions Min            -221.58
trainer/Q2 Predictions Mean           -157.142
trainer/Q2 Predictions Std              40.4979
trainer/Q2 Predictions Max              10.2793
trainer/Q2 Predictions Min            -223.244
trainer/Q Targets Mean                -157.864
trainer/Q Targets Std                   43.0436
trainer/Q Targets Max                    9.47497
trainer/Q Targets Min                 -226.686
trainer/Log Pis Mean                     2.41826
trainer/Log Pis Std                      2.32363
trainer/Log Pis Max                      8.90522
trainer/Log Pis Min                     -8.30985
trainer/policy/mean Mean                -0.564944
trainer/policy/mean Std                  0.655453
trainer/policy/mean Max                  0.999196
trainer/policy/mean Min                 -0.998619
trainer/policy/normal/std Mean           0.624339
trainer/policy/normal/std Std            0.0863344
trainer/policy/normal/std Max            1.17355
trainer/policy/normal/std Min            0.392143
trainer/policy/normal/log_std Mean      -0.480367
trainer/policy/normal/log_std Std        0.135955
trainer/policy/normal/log_std Max        0.160031
trainer/policy/normal/log_std Min       -0.936128
trainer/Alpha                            0.0436447
trainer/Alpha Loss                       1.30986
exploration/num steps total         113000
exploration/num paths total            565
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.876999
exploration/Rewards Std                  0.174492
exploration/Rewards Max                 -0.639936
exploration/Rewards Min                 -1.37998
exploration/Returns Mean              -175.4
exploration/Returns Std                  3.05371
exploration/Returns Max               -171.549
exploration/Returns Min               -178.878
exploration/Actions Mean                -0.396544
exploration/Actions Std                  0.659703
exploration/Actions Max                  0.995946
exploration/Actions Min                 -0.999024
exploration/Num Paths                    5
exploration/Average Returns           -175.4
evaluation/num steps total          540288
evaluation/num paths total            2688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.918491
evaluation/Rewards Std                   0.209794
evaluation/Rewards Max                  -0.575733
evaluation/Rewards Min                  -1.69531
evaluation/Returns Mean               -184.617
evaluation/Returns Std                  22.563
evaluation/Returns Max                -145.981
evaluation/Returns Min                -252.63
evaluation/Actions Mean                 -0.484002
evaluation/Actions Std                   0.603406
evaluation/Actions Max                   0.997236
evaluation/Actions Min                  -0.999118
evaluation/Num Paths                    24
evaluation/Average Returns            -184.617
time/data storing (s)                    0.00911384
time/evaluation sampling (s)           409.89
time/exploration sampling (s)          102.375
time/logging (s)                         0.021405
time/sac training (s)                    9.18374
time/saving (s)                          0.0253429
time/training (s)                        0.000141941
time/epoch (s)                         521.505
time/total (s)                       73212.6
Epoch                                  111
----------------------------------  ----------------
2020-11-02 06:21:28.722861 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 112 finished
----------------------------------  ----------------
replay_buffer/size                  114000
trainer/num train calls             113000
trainer/QF1 Loss                       111.63
trainer/QF2 Loss                       107.143
trainer/Policy Loss                    156.471
trainer/Q1 Predictions Mean           -155.97
trainer/Q1 Predictions Std              43.1701
trainer/Q1 Predictions Max              29.7531
trainer/Q1 Predictions Min            -225.833
trainer/Q2 Predictions Mean           -155.486
trainer/Q2 Predictions Std              42.8328
trainer/Q2 Predictions Max              37.5001
trainer/Q2 Predictions Min            -225.761
trainer/Q Targets Mean                -155.39
trainer/Q Targets Std                   43.9217
trainer/Q Targets Max                   33.2462
trainer/Q Targets Min                 -224.646
trainer/Log Pis Mean                     1.83095
trainer/Log Pis Std                      2.12073
trainer/Log Pis Max                      8.15414
trainer/Log Pis Min                     -5.95612
trainer/policy/mean Mean                -0.283212
trainer/policy/mean Std                  0.782164
trainer/policy/mean Max                  0.999449
trainer/policy/mean Min                 -0.994816
trainer/policy/normal/std Mean           0.642162
trainer/policy/normal/std Std            0.078476
trainer/policy/normal/std Max            0.922763
trainer/policy/normal/std Min            0.420841
trainer/policy/normal/log_std Mean      -0.450362
trainer/policy/normal/log_std Std        0.122118
trainer/policy/normal/log_std Max       -0.080383
trainer/policy/normal/log_std Min       -0.8655
trainer/Alpha                            0.043037
trainer/Alpha Loss                      -0.531767
exploration/num steps total         114000
exploration/num paths total            570
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.869516
exploration/Rewards Std                  0.147441
exploration/Rewards Max                 -0.688503
exploration/Rewards Min                 -1.38532
exploration/Returns Mean              -173.903
exploration/Returns Std                  5.36596
exploration/Returns Max               -168.8
exploration/Returns Min               -180.552
exploration/Actions Mean                -0.382228
exploration/Actions Std                  0.631283
exploration/Actions Max                  0.996347
exploration/Actions Min                 -0.999466
exploration/Num Paths                    5
exploration/Average Returns           -173.903
evaluation/num steps total          545112
evaluation/num paths total            2712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.955294
evaluation/Rewards Std                   0.21156
evaluation/Rewards Max                  -0.539189
evaluation/Rewards Min                  -1.77321
evaluation/Returns Mean               -192.014
evaluation/Returns Std                  24.2847
evaluation/Returns Max                -157.722
evaluation/Returns Min                -270.168
evaluation/Actions Mean                 -0.241036
evaluation/Actions Std                   0.723432
evaluation/Actions Max                   0.999968
evaluation/Actions Min                  -0.993461
evaluation/Num Paths                    24
evaluation/Average Returns            -192.014
time/data storing (s)                    0.0100401
time/evaluation sampling (s)           430.395
time/exploration sampling (s)          108.29
time/logging (s)                         0.0253544
time/sac training (s)                    9.27426
time/saving (s)                          0.0376576
time/training (s)                        0.000116889
time/epoch (s)                         548.032
time/total (s)                       73761.6
Epoch                                  112
----------------------------------  ----------------
2020-11-02 06:30:34.344944 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 113 finished
----------------------------------  ----------------
replay_buffer/size                  115000
trainer/num train calls             114000
trainer/QF1 Loss                       144.957
trainer/QF2 Loss                       142.228
trainer/Policy Loss                    158.437
trainer/Q1 Predictions Mean           -157.825
trainer/Q1 Predictions Std              40.0688
trainer/Q1 Predictions Max             -45.3283
trainer/Q1 Predictions Min            -224.237
trainer/Q2 Predictions Mean           -157.176
trainer/Q2 Predictions Std              40.0689
trainer/Q2 Predictions Max             -47.2863
trainer/Q2 Predictions Min            -229.949
trainer/Q Targets Mean                -157.775
trainer/Q Targets Std                   41.6655
trainer/Q Targets Max                   -0.792275
trainer/Q Targets Min                 -225.838
trainer/Log Pis Mean                     2.10808
trainer/Log Pis Std                      2.07612
trainer/Log Pis Max                      7.61264
trainer/Log Pis Min                     -4.07127
trainer/policy/mean Mean                -0.553834
trainer/policy/mean Std                  0.641703
trainer/policy/mean Max                  0.99661
trainer/policy/mean Min                 -0.996507
trainer/policy/normal/std Mean           0.638393
trainer/policy/normal/std Std            0.087585
trainer/policy/normal/std Max            0.913858
trainer/policy/normal/std Min            0.332601
trainer/policy/normal/log_std Mean      -0.458158
trainer/policy/normal/log_std Std        0.136871
trainer/policy/normal/log_std Max       -0.0900801
trainer/policy/normal/log_std Min       -1.10081
trainer/Alpha                            0.0434474
trainer/Alpha Loss                       0.338949
exploration/num steps total         115000
exploration/num paths total            575
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.958267
exploration/Rewards Std                  0.181379
exploration/Rewards Max                 -0.607485
exploration/Rewards Min                 -1.67326
exploration/Returns Mean              -191.653
exploration/Returns Std                 12.6014
exploration/Returns Max               -176.473
exploration/Returns Min               -211.224
exploration/Actions Mean                -0.193801
exploration/Actions Std                  0.737825
exploration/Actions Max                  0.999725
exploration/Actions Min                 -0.999422
exploration/Num Paths                    5
exploration/Average Returns           -191.653
evaluation/num steps total          549936
evaluation/num paths total            2736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.919077
evaluation/Rewards Std                   0.1973
evaluation/Rewards Max                  -0.602005
evaluation/Rewards Min                  -1.6443
evaluation/Returns Mean               -184.734
evaluation/Returns Std                  21.3954
evaluation/Returns Max                -156.847
evaluation/Returns Min                -238.268
evaluation/Actions Mean                 -0.31432
evaluation/Actions Std                   0.67293
evaluation/Actions Max                   0.998729
evaluation/Actions Min                  -0.996401
evaluation/Num Paths                    24
evaluation/Average Returns            -184.734
time/data storing (s)                    0.00961618
time/evaluation sampling (s)           425.08
time/exploration sampling (s)          110.671
time/logging (s)                         0.0246204
time/sac training (s)                    9.18563
time/saving (s)                          0.0303725
time/training (s)                        0.000138865
time/epoch (s)                         545.002
time/total (s)                       74307.2
Epoch                                  113
----------------------------------  ----------------
2020-11-02 06:40:15.643998 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 114 finished
----------------------------------  ---------------
replay_buffer/size                  116000
trainer/num train calls             115000
trainer/QF1 Loss                        60.4233
trainer/QF2 Loss                        69.1097
trainer/Policy Loss                    154.698
trainer/Q1 Predictions Mean           -153.412
trainer/Q1 Predictions Std              44.3426
trainer/Q1 Predictions Max              26.1202
trainer/Q1 Predictions Min            -226.834
trainer/Q2 Predictions Mean           -154.403
trainer/Q2 Predictions Std              44.3292
trainer/Q2 Predictions Max              23.4361
trainer/Q2 Predictions Min            -227.558
trainer/Q Targets Mean                -153.058
trainer/Q Targets Std                   44.8869
trainer/Q Targets Max                   26.1426
trainer/Q Targets Min                 -224.768
trainer/Log Pis Mean                     2.5283
trainer/Log Pis Std                      2.2757
trainer/Log Pis Max                     10.3142
trainer/Log Pis Min                     -4.58823
trainer/policy/mean Mean                -0.257708
trainer/policy/mean Std                  0.813682
trainer/policy/mean Max                  0.999655
trainer/policy/mean Min                 -0.999304
trainer/policy/normal/std Mean           0.615315
trainer/policy/normal/std Std            0.0835694
trainer/policy/normal/std Max            0.893648
trainer/policy/normal/std Min            0.349085
trainer/policy/normal/log_std Mean      -0.494986
trainer/policy/normal/log_std Std        0.137734
trainer/policy/normal/log_std Max       -0.112444
trainer/policy/normal/log_std Min       -1.05244
trainer/Alpha                            0.0408286
trainer/Alpha Loss                       1.68971
exploration/num steps total         116000
exploration/num paths total            580
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.908521
exploration/Rewards Std                  0.176952
exploration/Rewards Max                 -0.606004
exploration/Rewards Min                 -1.37506
exploration/Returns Mean              -181.704
exploration/Returns Std                 11.6834
exploration/Returns Max               -170.458
exploration/Returns Min               -204.291
exploration/Actions Mean                -0.256362
exploration/Actions Std                  0.736338
exploration/Actions Max                  0.997039
exploration/Actions Min                 -0.999809
exploration/Num Paths                    5
exploration/Average Returns           -181.704
evaluation/num steps total          554760
evaluation/num paths total            2760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.973951
evaluation/Rewards Std                   0.212087
evaluation/Rewards Max                  -0.541866
evaluation/Rewards Min                  -1.79842
evaluation/Returns Mean               -195.764
evaluation/Returns Std                  26.3756
evaluation/Returns Max                -154.129
evaluation/Returns Min                -260.335
evaluation/Actions Mean                 -0.155795
evaluation/Actions Std                   0.718462
evaluation/Actions Max                   0.999968
evaluation/Actions Min                  -0.996668
evaluation/Num Paths                    24
evaluation/Average Returns            -195.764
time/data storing (s)                    0.00669269
time/evaluation sampling (s)           478.506
time/exploration sampling (s)           92.8591
time/logging (s)                         0.0251071
time/sac training (s)                    9.22525
time/saving (s)                          0.023641
time/training (s)                        0.00011896
time/epoch (s)                         580.646
time/total (s)                       74888.5
Epoch                                  114
----------------------------------  ---------------
2020-11-02 06:49:33.145156 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 115 finished
----------------------------------  ----------------
replay_buffer/size                  117000
trainer/num train calls             116000
trainer/QF1 Loss                        32.7527
trainer/QF2 Loss                        32.0145
trainer/Policy Loss                    156.426
trainer/Q1 Predictions Mean           -155.589
trainer/Q1 Predictions Std              40.4205
trainer/Q1 Predictions Max             -12.1205
trainer/Q1 Predictions Min            -226.325
trainer/Q2 Predictions Mean           -155.801
trainer/Q2 Predictions Std              40.2026
trainer/Q2 Predictions Max             -19.2168
trainer/Q2 Predictions Min            -224.727
trainer/Q Targets Mean                -157.091
trainer/Q Targets Std                   40.2517
trainer/Q Targets Max                  -28.118
trainer/Q Targets Min                 -227.694
trainer/Log Pis Mean                     2.24127
trainer/Log Pis Std                      2.22483
trainer/Log Pis Max                     10.668
trainer/Log Pis Min                     -5.7725
trainer/policy/mean Mean                -0.457351
trainer/policy/mean Std                  0.711044
trainer/policy/mean Max                  0.999772
trainer/policy/mean Min                 -0.999647
trainer/policy/normal/std Mean           0.641309
trainer/policy/normal/std Std            0.0953355
trainer/policy/normal/std Max            0.970214
trainer/policy/normal/std Min            0.404861
trainer/policy/normal/log_std Mean      -0.455254
trainer/policy/normal/log_std Std        0.148527
trainer/policy/normal/log_std Max       -0.0302388
trainer/policy/normal/log_std Min       -0.904212
trainer/Alpha                            0.0427466
trainer/Alpha Loss                       0.760601
exploration/num steps total         117000
exploration/num paths total            585
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.911879
exploration/Rewards Std                  0.22497
exploration/Rewards Max                 -0.541515
exploration/Rewards Min                 -1.8041
exploration/Returns Mean              -182.376
exploration/Returns Std                 21.9036
exploration/Returns Max               -152.01
exploration/Returns Min               -210.247
exploration/Actions Mean                -0.226475
exploration/Actions Std                  0.730148
exploration/Actions Max                  0.999993
exploration/Actions Min                 -0.999883
exploration/Num Paths                    5
exploration/Average Returns           -182.376
evaluation/num steps total          559584
evaluation/num paths total            2784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.953451
evaluation/Rewards Std                   0.205597
evaluation/Rewards Max                  -0.601262
evaluation/Rewards Min                  -1.86031
evaluation/Returns Mean               -191.644
evaluation/Returns Std                  22.0993
evaluation/Returns Max                -156.445
evaluation/Returns Min                -249.475
evaluation/Actions Mean                 -0.2748
evaluation/Actions Std                   0.676891
evaluation/Actions Max                   0.999865
evaluation/Actions Min                  -0.998767
evaluation/Num Paths                    24
evaluation/Average Returns            -191.644
time/data storing (s)                    0.00681876
time/evaluation sampling (s)           438.482
time/exploration sampling (s)          108.996
time/logging (s)                         0.020456
time/sac training (s)                    9.309
time/saving (s)                          0.0290507
time/training (s)                        0.000116529
time/epoch (s)                         556.844
time/total (s)                       75445.9
Epoch                                  115
----------------------------------  ----------------
2020-11-02 06:58:26.234197 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 116 finished
----------------------------------  ----------------
replay_buffer/size                  118000
trainer/num train calls             117000
trainer/QF1 Loss                        36.2571
trainer/QF2 Loss                        29.7594
trainer/Policy Loss                    160.733
trainer/Q1 Predictions Mean           -159.938
trainer/Q1 Predictions Std              42.1716
trainer/Q1 Predictions Max              28.977
trainer/Q1 Predictions Min            -225.839
trainer/Q2 Predictions Mean           -159.933
trainer/Q2 Predictions Std              42.079
trainer/Q2 Predictions Max              31.5571
trainer/Q2 Predictions Min            -224.753
trainer/Q Targets Mean                -161.3
trainer/Q Targets Std                   42.8581
trainer/Q Targets Max                   41.096
trainer/Q Targets Min                 -227.219
trainer/Log Pis Mean                     1.97805
trainer/Log Pis Std                      1.90871
trainer/Log Pis Max                      6.73149
trainer/Log Pis Min                     -3.32409
trainer/policy/mean Mean                -0.412212
trainer/policy/mean Std                  0.736791
trainer/policy/mean Max                  0.997959
trainer/policy/mean Min                 -0.994978
trainer/policy/normal/std Mean           0.627525
trainer/policy/normal/std Std            0.0735762
trainer/policy/normal/std Max            0.896245
trainer/policy/normal/std Min            0.329869
trainer/policy/normal/log_std Mean      -0.472878
trainer/policy/normal/log_std Std        0.117998
trainer/policy/normal/log_std Max       -0.109541
trainer/policy/normal/log_std Min       -1.10906
trainer/Alpha                            0.0411881
trainer/Alpha Loss                      -0.0700005
exploration/num steps total         118000
exploration/num paths total            590
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.975884
exploration/Rewards Std                  0.196703
exploration/Rewards Max                 -0.657898
exploration/Rewards Min                 -1.58128
exploration/Returns Mean              -195.177
exploration/Returns Std                 11.9587
exploration/Returns Max               -180.981
exploration/Returns Min               -214.252
exploration/Actions Mean                -0.192773
exploration/Actions Std                  0.75869
exploration/Actions Max                  0.999972
exploration/Actions Min                 -0.99977
exploration/Num Paths                    5
exploration/Average Returns           -195.177
evaluation/num steps total          564408
evaluation/num paths total            2808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.901159
evaluation/Rewards Std                   0.195997
evaluation/Rewards Max                  -0.556349
evaluation/Rewards Min                  -1.69716
evaluation/Returns Mean               -181.133
evaluation/Returns Std                  19.1858
evaluation/Returns Max                -151.012
evaluation/Returns Min                -248.662
evaluation/Actions Mean                 -0.297239
evaluation/Actions Std                   0.682505
evaluation/Actions Max                   0.9997
evaluation/Actions Min                  -0.996819
evaluation/Num Paths                    24
evaluation/Average Returns            -181.133
time/data storing (s)                    0.0086436
time/evaluation sampling (s)           423.842
time/exploration sampling (s)           99.2068
time/logging (s)                         0.0225463
time/sac training (s)                    9.33273
time/saving (s)                          0.0278094
time/training (s)                        0.000120877
time/epoch (s)                         532.441
time/total (s)                       75979
Epoch                                  116
----------------------------------  ----------------
2020-11-02 07:08:44.727774 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 117 finished
----------------------------------  ----------------
replay_buffer/size                  119000
trainer/num train calls             118000
trainer/QF1 Loss                       177.056
trainer/QF2 Loss                       163.629
trainer/Policy Loss                    157.445
trainer/Q1 Predictions Mean           -157.005
trainer/Q1 Predictions Std              41.2989
trainer/Q1 Predictions Max             -36.5826
trainer/Q1 Predictions Min            -225.178
trainer/Q2 Predictions Mean           -156.336
trainer/Q2 Predictions Std              41.2638
trainer/Q2 Predictions Max             -32.682
trainer/Q2 Predictions Min            -223.105
trainer/Q Targets Mean                -156.825
trainer/Q Targets Std                   43.9534
trainer/Q Targets Max                   -0.639283
trainer/Q Targets Min                 -224.391
trainer/Log Pis Mean                     1.879
trainer/Log Pis Std                      2.30731
trainer/Log Pis Max                      8.41152
trainer/Log Pis Min                     -4.33234
trainer/policy/mean Mean                -0.315387
trainer/policy/mean Std                  0.767657
trainer/policy/mean Max                  0.998893
trainer/policy/mean Min                 -0.994704
trainer/policy/normal/std Mean           0.632608
trainer/policy/normal/std Std            0.0818574
trainer/policy/normal/std Max            0.966502
trainer/policy/normal/std Min            0.384134
trainer/policy/normal/log_std Mean      -0.466227
trainer/policy/normal/log_std Std        0.129105
trainer/policy/normal/log_std Max       -0.0340721
trainer/policy/normal/log_std Min       -0.956763
trainer/Alpha                            0.0390882
trainer/Alpha Loss                      -0.392261
exploration/num steps total         119000
exploration/num paths total            595
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.03235
exploration/Rewards Std                  0.210628
exploration/Rewards Max                 -0.660738
exploration/Rewards Min                 -1.99111
exploration/Returns Mean              -206.471
exploration/Returns Std                 28.2292
exploration/Returns Max               -179.599
exploration/Returns Min               -259.275
exploration/Actions Mean                 0.124273
exploration/Actions Std                  0.741745
exploration/Actions Max                  0.999993
exploration/Actions Min                 -0.998789
exploration/Num Paths                    5
exploration/Average Returns           -206.471
evaluation/num steps total          569232
evaluation/num paths total            2832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.922067
evaluation/Rewards Std                   0.197344
evaluation/Rewards Max                  -0.552884
evaluation/Rewards Min                  -1.70664
evaluation/Returns Mean               -185.335
evaluation/Returns Std                  18.085
evaluation/Returns Max                -160.008
evaluation/Returns Min                -220.064
evaluation/Actions Mean                 -0.276333
evaluation/Actions Std                   0.677955
evaluation/Actions Max                   0.999477
evaluation/Actions Min                  -0.998983
evaluation/Num Paths                    24
evaluation/Average Returns            -185.335
time/data storing (s)                    0.0164055
time/evaluation sampling (s)           499.4
time/exploration sampling (s)          108.437
time/logging (s)                         0.0239083
time/sac training (s)                    9.38051
time/saving (s)                          0.103515
time/training (s)                        0.000115763
time/epoch (s)                         617.362
time/total (s)                       76597.5
Epoch                                  117
----------------------------------  ----------------
2020-11-02 07:18:58.152110 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 118 finished
----------------------------------  ----------------
replay_buffer/size                  120000
trainer/num train calls             119000
trainer/QF1 Loss                        27.3549
trainer/QF2 Loss                        29.0871
trainer/Policy Loss                    157.187
trainer/Q1 Predictions Mean           -156.664
trainer/Q1 Predictions Std              42.3461
trainer/Q1 Predictions Max             -18.8445
trainer/Q1 Predictions Min            -229.047
trainer/Q2 Predictions Mean           -156.454
trainer/Q2 Predictions Std              42.5434
trainer/Q2 Predictions Max              -9.30934
trainer/Q2 Predictions Min            -226.634
trainer/Q Targets Mean                -156.907
trainer/Q Targets Std                   42.3371
trainer/Q Targets Max                  -17.6711
trainer/Q Targets Min                 -225.984
trainer/Log Pis Mean                     2.05977
trainer/Log Pis Std                      2.14
trainer/Log Pis Max                      8.85899
trainer/Log Pis Min                     -3.05728
trainer/policy/mean Mean                -0.172958
trainer/policy/mean Std                  0.828024
trainer/policy/mean Max                  0.998864
trainer/policy/mean Min                 -0.997422
trainer/policy/normal/std Mean           0.632658
trainer/policy/normal/std Std            0.0813335
trainer/policy/normal/std Max            0.873841
trainer/policy/normal/std Min            0.36757
trainer/policy/normal/log_std Mean      -0.466207
trainer/policy/normal/log_std Std        0.130153
trainer/policy/normal/log_std Max       -0.134857
trainer/policy/normal/log_std Min       -1.00084
trainer/Alpha                            0.0414989
trainer/Alpha Loss                       0.190206
exploration/num steps total         120000
exploration/num paths total            600
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.04999
exploration/Rewards Std                  0.195179
exploration/Rewards Max                 -0.546106
exploration/Rewards Min                 -1.68491
exploration/Returns Mean              -209.997
exploration/Returns Std                 19.2185
exploration/Returns Max               -178.382
exploration/Returns Min               -231.261
exploration/Actions Mean                 0.0196609
exploration/Actions Std                  0.76112
exploration/Actions Max                  0.999793
exploration/Actions Min                 -0.999481
exploration/Num Paths                    5
exploration/Average Returns           -209.997
evaluation/num steps total          574056
evaluation/num paths total            2856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.960541
evaluation/Rewards Std                   0.241625
evaluation/Rewards Max                  -0.530699
evaluation/Rewards Min                  -1.72279
evaluation/Returns Mean               -193.069
evaluation/Returns Std                  31.625
evaluation/Returns Max                -142.511
evaluation/Returns Min                -258.245
evaluation/Actions Mean                 -0.286085
evaluation/Actions Std                   0.697118
evaluation/Actions Max                   0.998714
evaluation/Actions Min                  -0.997858
evaluation/Num Paths                    24
evaluation/Average Returns            -193.069
time/data storing (s)                    0.0214537
time/evaluation sampling (s)           493.622
time/exploration sampling (s)          108.652
time/logging (s)                         0.0361559
time/sac training (s)                    9.98661
time/saving (s)                          0.0594675
time/training (s)                        0.000117526
time/epoch (s)                         612.378
time/total (s)                       77210.9
Epoch                                  118
----------------------------------  ----------------
2020-11-02 07:28:25.882069 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 119 finished
----------------------------------  ----------------
replay_buffer/size                  121000
trainer/num train calls             120000
trainer/QF1 Loss                        31.9813
trainer/QF2 Loss                        28.9532
trainer/Policy Loss                    159.072
trainer/Q1 Predictions Mean           -158.732
trainer/Q1 Predictions Std              43.3081
trainer/Q1 Predictions Max             -36.0433
trainer/Q1 Predictions Min            -228.822
trainer/Q2 Predictions Mean           -157.727
trainer/Q2 Predictions Std              43.6415
trainer/Q2 Predictions Max             -26.0783
trainer/Q2 Predictions Min            -231.343
trainer/Q Targets Mean                -158.038
trainer/Q Targets Std                   43.8556
trainer/Q Targets Max                  -35.1279
trainer/Q Targets Min                 -228.657
trainer/Log Pis Mean                     1.69268
trainer/Log Pis Std                      2.10963
trainer/Log Pis Max                      7.42501
trainer/Log Pis Min                     -5.74903
trainer/policy/mean Mean                -0.384755
trainer/policy/mean Std                  0.725689
trainer/policy/mean Max                  0.999173
trainer/policy/mean Min                 -0.996936
trainer/policy/normal/std Mean           0.621678
trainer/policy/normal/std Std            0.0735096
trainer/policy/normal/std Max            0.856116
trainer/policy/normal/std Min            0.36466
trainer/policy/normal/log_std Mean      -0.482325
trainer/policy/normal/log_std Std        0.118481
trainer/policy/normal/log_std Max       -0.155349
trainer/policy/normal/log_std Min       -1.00879
trainer/Alpha                            0.0405313
trainer/Alpha Loss                      -0.985154
exploration/num steps total         121000
exploration/num paths total            605
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.970019
exploration/Rewards Std                  0.238803
exploration/Rewards Max                 -0.575302
exploration/Rewards Min                 -1.70397
exploration/Returns Mean              -194.004
exploration/Returns Std                 33.7988
exploration/Returns Max               -162.104
exploration/Returns Min               -259.041
exploration/Actions Mean                -0.288803
exploration/Actions Std                  0.678066
exploration/Actions Max                  0.997958
exploration/Actions Min                 -0.999932
exploration/Num Paths                    5
exploration/Average Returns           -194.004
evaluation/num steps total          578880
evaluation/num paths total            2880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95171
evaluation/Rewards Std                   0.194417
evaluation/Rewards Max                  -0.574112
evaluation/Rewards Min                  -1.74424
evaluation/Returns Mean               -191.294
evaluation/Returns Std                  22.5631
evaluation/Returns Max                -159.351
evaluation/Returns Min                -235.611
evaluation/Actions Mean                 -0.265482
evaluation/Actions Std                   0.67088
evaluation/Actions Max                   0.999634
evaluation/Actions Min                  -0.997365
evaluation/Num Paths                    24
evaluation/Average Returns            -191.294
time/data storing (s)                    0.00962514
time/evaluation sampling (s)           458.467
time/exploration sampling (s)           99.1663
time/logging (s)                         0.0193192
time/sac training (s)                    9.37296
time/saving (s)                          0.0266495
time/training (s)                        0.000137723
time/epoch (s)                         567.062
time/total (s)                       77778.6
Epoch                                  119
----------------------------------  ----------------
2020-11-02 07:37:47.048185 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 120 finished
----------------------------------  ----------------
replay_buffer/size                  122000
trainer/num train calls             121000
trainer/QF1 Loss                        30.9195
trainer/QF2 Loss                        31.4424
trainer/Policy Loss                    158.763
trainer/Q1 Predictions Mean           -157.812
trainer/Q1 Predictions Std              41.4823
trainer/Q1 Predictions Max             -26.0922
trainer/Q1 Predictions Min            -225.684
trainer/Q2 Predictions Mean           -158.1
trainer/Q2 Predictions Std              41.5037
trainer/Q2 Predictions Max             -10.2852
trainer/Q2 Predictions Min            -226.307
trainer/Q Targets Mean                -158.977
trainer/Q Targets Std                   41.3856
trainer/Q Targets Max                  -29.6535
trainer/Q Targets Min                 -230.306
trainer/Log Pis Mean                     1.8765
trainer/Log Pis Std                      2.20444
trainer/Log Pis Max                      7.65188
trainer/Log Pis Min                     -3.83371
trainer/policy/mean Mean                -0.273367
trainer/policy/mean Std                  0.785507
trainer/policy/mean Max                  0.999681
trainer/policy/mean Min                 -0.996992
trainer/policy/normal/std Mean           0.635944
trainer/policy/normal/std Std            0.0881605
trainer/policy/normal/std Max            0.99651
trainer/policy/normal/std Min            0.417519
trainer/policy/normal/log_std Mean      -0.462289
trainer/policy/normal/log_std Std        0.13929
trainer/policy/normal/log_std Max       -0.00349608
trainer/policy/normal/log_std Min       -0.873425
trainer/Alpha                            0.0419722
trainer/Alpha Loss                      -0.391588
exploration/num steps total         122000
exploration/num paths total            610
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.953453
exploration/Rewards Std                  0.220472
exploration/Rewards Max                 -0.571193
exploration/Rewards Min                 -1.82955
exploration/Returns Mean              -190.691
exploration/Returns Std                 21.1959
exploration/Returns Max               -165.332
exploration/Returns Min               -218.869
exploration/Actions Mean                -0.322475
exploration/Actions Std                  0.662198
exploration/Actions Max                  0.997812
exploration/Actions Min                 -0.999048
exploration/Num Paths                    5
exploration/Average Returns           -190.691
evaluation/num steps total          583704
evaluation/num paths total            2904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.955147
evaluation/Rewards Std                   0.212364
evaluation/Rewards Max                  -0.542947
evaluation/Rewards Min                  -1.62256
evaluation/Returns Mean               -191.985
evaluation/Returns Std                  23.9928
evaluation/Returns Max                -154.047
evaluation/Returns Min                -257.576
evaluation/Actions Mean                 -0.298758
evaluation/Actions Std                   0.667282
evaluation/Actions Max                   0.999554
evaluation/Actions Min                  -0.99725
evaluation/Num Paths                    24
evaluation/Average Returns            -191.985
time/data storing (s)                    0.00729772
time/evaluation sampling (s)           438.575
time/exploration sampling (s)          112.134
time/logging (s)                         0.0277188
time/sac training (s)                    9.35453
time/saving (s)                          0.0495616
time/training (s)                        0.000115331
time/epoch (s)                         560.149
time/total (s)                       78339.7
Epoch                                  120
----------------------------------  ----------------
2020-11-02 07:47:39.205167 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 121 finished
----------------------------------  ----------------
replay_buffer/size                  123000
trainer/num train calls             122000
trainer/QF1 Loss                       158.98
trainer/QF2 Loss                       182.721
trainer/Policy Loss                    158.835
trainer/Q1 Predictions Mean           -157.706
trainer/Q1 Predictions Std              45.0617
trainer/Q1 Predictions Max             -48.5839
trainer/Q1 Predictions Min            -226.973
trainer/Q2 Predictions Mean           -157.98
trainer/Q2 Predictions Std              44.3081
trainer/Q2 Predictions Max             -45.9686
trainer/Q2 Predictions Min            -230.067
trainer/Q Targets Mean                -157.541
trainer/Q Targets Std                   46.2739
trainer/Q Targets Max                   -0.931859
trainer/Q Targets Min                 -229.414
trainer/Log Pis Mean                     1.70354
trainer/Log Pis Std                      2.30452
trainer/Log Pis Max                      7.61295
trainer/Log Pis Min                     -5.30926
trainer/policy/mean Mean                -0.313431
trainer/policy/mean Std                  0.764457
trainer/policy/mean Max                  0.999629
trainer/policy/mean Min                 -0.997068
trainer/policy/normal/std Mean           0.629703
trainer/policy/normal/std Std            0.0837508
trainer/policy/normal/std Max            0.967094
trainer/policy/normal/std Min            0.352616
trainer/policy/normal/log_std Mean      -0.471408
trainer/policy/normal/log_std Std        0.134026
trainer/policy/normal/log_std Max       -0.0334595
trainer/policy/normal/log_std Min       -1.04238
trainer/Alpha                            0.0414946
trainer/Alpha Loss                      -0.943403
exploration/num steps total         123000
exploration/num paths total            615
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.867674
exploration/Rewards Std                  0.196521
exploration/Rewards Max                 -0.540687
exploration/Rewards Min                 -1.35479
exploration/Returns Mean              -173.535
exploration/Returns Std                 17.5246
exploration/Returns Max               -153.811
exploration/Returns Min               -196.47
exploration/Actions Mean                -0.297916
exploration/Actions Std                  0.659135
exploration/Actions Max                  0.997756
exploration/Actions Min                 -0.998398
exploration/Num Paths                    5
exploration/Average Returns           -173.535
evaluation/num steps total          588528
evaluation/num paths total            2928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00171
evaluation/Rewards Std                   0.211564
evaluation/Rewards Max                  -0.558482
evaluation/Rewards Min                  -1.65316
evaluation/Returns Mean               -201.343
evaluation/Returns Std                  26.9559
evaluation/Returns Max                -159.436
evaluation/Returns Min                -266.401
evaluation/Actions Mean                 -0.297214
evaluation/Actions Std                   0.667803
evaluation/Actions Max                   0.99812
evaluation/Actions Min                  -0.999804
evaluation/Num Paths                    24
evaluation/Average Returns            -201.343
time/data storing (s)                    0.011143
time/evaluation sampling (s)           467.491
time/exploration sampling (s)          114.708
time/logging (s)                         0.0229004
time/sac training (s)                    9.22709
time/saving (s)                          0.0248524
time/training (s)                        0.000118356
time/epoch (s)                         591.485
time/total (s)                       78931.8
Epoch                                  121
----------------------------------  ----------------
2020-11-02 07:57:42.168415 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 122 finished
----------------------------------  ----------------
replay_buffer/size                  124000
trainer/num train calls             123000
trainer/QF1 Loss                       136.215
trainer/QF2 Loss                       163.937
trainer/Policy Loss                    155.232
trainer/Q1 Predictions Mean           -154.067
trainer/Q1 Predictions Std              41.2982
trainer/Q1 Predictions Max             -25.6969
trainer/Q1 Predictions Min            -229.453
trainer/Q2 Predictions Mean           -154.558
trainer/Q2 Predictions Std              41.427
trainer/Q2 Predictions Max             -22.1182
trainer/Q2 Predictions Min            -228.607
trainer/Q Targets Mean                -153.349
trainer/Q Targets Std                   43.8698
trainer/Q Targets Max                   -0.910317
trainer/Q Targets Min                 -230.573
trainer/Log Pis Mean                     2.23128
trainer/Log Pis Std                      2.05132
trainer/Log Pis Max                      8.30991
trainer/Log Pis Min                     -3.03223
trainer/policy/mean Mean                -0.27857
trainer/policy/mean Std                  0.794491
trainer/policy/mean Max                  0.998694
trainer/policy/mean Min                 -0.997994
trainer/policy/normal/std Mean           0.622665
trainer/policy/normal/std Std            0.0817219
trainer/policy/normal/std Max            0.873097
trainer/policy/normal/std Min            0.352557
trainer/policy/normal/log_std Mean      -0.482578
trainer/policy/normal/log_std Std        0.134106
trainer/policy/normal/log_std Max       -0.135709
trainer/policy/normal/log_std Min       -1.04254
trainer/Alpha                            0.0417519
trainer/Alpha Loss                       0.734535
exploration/num steps total         124000
exploration/num paths total            620
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.959751
exploration/Rewards Std                  0.200694
exploration/Rewards Max                 -0.604097
exploration/Rewards Min                 -1.50879
exploration/Returns Mean              -191.95
exploration/Returns Std                 18.2709
exploration/Returns Max               -164.666
exploration/Returns Min               -207.948
exploration/Actions Mean                -0.277501
exploration/Actions Std                  0.73683
exploration/Actions Max                  0.999986
exploration/Actions Min                 -0.999634
exploration/Num Paths                    5
exploration/Average Returns           -191.95
evaluation/num steps total          593352
evaluation/num paths total            2952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948968
evaluation/Rewards Std                   0.200606
evaluation/Rewards Max                  -0.601547
evaluation/Rewards Min                  -1.60519
evaluation/Returns Mean               -190.743
evaluation/Returns Std                  20.7145
evaluation/Returns Max                -159.845
evaluation/Returns Min                -228.771
evaluation/Actions Mean                 -0.292763
evaluation/Actions Std                   0.664011
evaluation/Actions Max                   0.999146
evaluation/Actions Min                  -0.998241
evaluation/Num Paths                    24
evaluation/Average Returns            -190.743
time/data storing (s)                    0.00690483
time/evaluation sampling (s)           486.77
time/exploration sampling (s)          105.437
time/logging (s)                         0.0360557
time/sac training (s)                    9.54441
time/saving (s)                          0.0452289
time/training (s)                        0.000139207
time/epoch (s)                         601.839
time/total (s)                       79534.8
Epoch                                  122
----------------------------------  ----------------
2020-11-02 08:07:09.967573 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 123 finished
----------------------------------  ----------------
replay_buffer/size                  125000
trainer/num train calls             124000
trainer/QF1 Loss                        34.057
trainer/QF2 Loss                        31.6295
trainer/Policy Loss                    152.56
trainer/Q1 Predictions Mean           -151.777
trainer/Q1 Predictions Std              45.4186
trainer/Q1 Predictions Max              30.7182
trainer/Q1 Predictions Min            -230.187
trainer/Q2 Predictions Mean           -151.923
trainer/Q2 Predictions Std              44.8877
trainer/Q2 Predictions Max              32.5215
trainer/Q2 Predictions Min            -228.818
trainer/Q Targets Mean                -152.223
trainer/Q Targets Std                   45.0315
trainer/Q Targets Max                   34.5414
trainer/Q Targets Min                 -227.466
trainer/Log Pis Mean                     2.13328
trainer/Log Pis Std                      2.24316
trainer/Log Pis Max                      9.74605
trainer/Log Pis Min                     -6.56618
trainer/policy/mean Mean                -0.412758
trainer/policy/mean Std                  0.738857
trainer/policy/mean Max                  0.999772
trainer/policy/mean Min                 -0.99615
trainer/policy/normal/std Mean           0.627789
trainer/policy/normal/std Std            0.107774
trainer/policy/normal/std Max            0.897583
trainer/policy/normal/std Min            0.326737
trainer/policy/normal/log_std Mean      -0.480767
trainer/policy/normal/log_std Std        0.176302
trainer/policy/normal/log_std Max       -0.10805
trainer/policy/normal/log_std Min       -1.1186
trainer/Alpha                            0.0393049
trainer/Alpha Loss                       0.431351
exploration/num steps total         125000
exploration/num paths total            625
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.07147
exploration/Rewards Std                  0.186824
exploration/Rewards Max                 -0.78075
exploration/Rewards Min                 -1.57591
exploration/Returns Mean              -214.294
exploration/Returns Std                 24.224
exploration/Returns Max               -181.213
exploration/Returns Min               -242.658
exploration/Actions Mean                -0.285519
exploration/Actions Std                  0.735111
exploration/Actions Max                  0.999953
exploration/Actions Min                 -0.999132
exploration/Num Paths                    5
exploration/Average Returns           -214.294
evaluation/num steps total          598176
evaluation/num paths total            2976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.922052
evaluation/Rewards Std                   0.204684
evaluation/Rewards Max                  -0.525014
evaluation/Rewards Min                  -1.79536
evaluation/Returns Mean               -185.332
evaluation/Returns Std                  23.357
evaluation/Returns Max                -151.948
evaluation/Returns Min                -262.599
evaluation/Actions Mean                 -0.334985
evaluation/Actions Std                   0.64676
evaluation/Actions Max                   0.995081
evaluation/Actions Min                  -0.999867
evaluation/Num Paths                    24
evaluation/Average Returns            -185.332
time/data storing (s)                    0.00892808
time/evaluation sampling (s)           444.275
time/exploration sampling (s)          112.955
time/logging (s)                         0.0339017
time/sac training (s)                    9.40204
time/saving (s)                          0.0522179
time/training (s)                        0.000116866
time/epoch (s)                         566.728
time/total (s)                       80102.5
Epoch                                  123
----------------------------------  ----------------
2020-11-02 08:16:45.154286 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 124 finished
----------------------------------  ----------------
replay_buffer/size                  126000
trainer/num train calls             125000
trainer/QF1 Loss                        33.7052
trainer/QF2 Loss                        36.1765
trainer/Policy Loss                    161.481
trainer/Q1 Predictions Mean           -161.126
trainer/Q1 Predictions Std              41.8151
trainer/Q1 Predictions Max             -40.1636
trainer/Q1 Predictions Min            -228.044
trainer/Q2 Predictions Mean           -160.496
trainer/Q2 Predictions Std              41.7704
trainer/Q2 Predictions Max             -36.8348
trainer/Q2 Predictions Min            -228.688
trainer/Q Targets Mean                -161.545
trainer/Q Targets Std                   41.8176
trainer/Q Targets Max                  -37.8905
trainer/Q Targets Min                 -228.167
trainer/Log Pis Mean                     1.60125
trainer/Log Pis Std                      2.06041
trainer/Log Pis Max                      7.23189
trainer/Log Pis Min                     -3.58136
trainer/policy/mean Mean                -0.352999
trainer/policy/mean Std                  0.742458
trainer/policy/mean Max                  0.999187
trainer/policy/mean Min                 -0.9926
trainer/policy/normal/std Mean           0.638548
trainer/policy/normal/std Std            0.0771946
trainer/policy/normal/std Max            0.855718
trainer/policy/normal/std Min            0.448264
trainer/policy/normal/log_std Mean      -0.45589
trainer/policy/normal/log_std Std        0.12135
trainer/policy/normal/log_std Max       -0.155814
trainer/policy/normal/log_std Min       -0.802374
trainer/Alpha                            0.0407172
trainer/Alpha Loss                      -1.27646
exploration/num steps total         126000
exploration/num paths total            630
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.921973
exploration/Rewards Std                  0.192434
exploration/Rewards Max                 -0.56782
exploration/Rewards Min                 -1.42963
exploration/Returns Mean              -184.395
exploration/Returns Std                 17.975
exploration/Returns Max               -162.595
exploration/Returns Min               -216.977
exploration/Actions Mean                -0.444382
exploration/Actions Std                  0.640627
exploration/Actions Max                  0.999763
exploration/Actions Min                 -0.999157
exploration/Num Paths                    5
exploration/Average Returns           -184.395
evaluation/num steps total          603000
evaluation/num paths total            3000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.897146
evaluation/Rewards Std                   0.192873
evaluation/Rewards Max                  -0.540129
evaluation/Rewards Min                  -1.61123
evaluation/Returns Mean               -180.326
evaluation/Returns Std                  19.6222
evaluation/Returns Max                -145.46
evaluation/Returns Min                -223.453
evaluation/Actions Mean                 -0.308377
evaluation/Actions Std                   0.658472
evaluation/Actions Max                   0.999046
evaluation/Actions Min                  -0.990671
evaluation/Num Paths                    24
evaluation/Average Returns            -180.326
time/data storing (s)                    0.0105905
time/evaluation sampling (s)           452.875
time/exploration sampling (s)          111.84
time/logging (s)                         0.0309743
time/sac training (s)                    9.33198
time/saving (s)                          0.0395654
time/training (s)                        0.000115684
time/epoch (s)                         574.129
time/total (s)                       80677.7
Epoch                                  124
----------------------------------  ----------------
2020-11-02 08:25:45.579485 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 125 finished
----------------------------------  ----------------
replay_buffer/size                  127000
trainer/num train calls             126000
trainer/QF1 Loss                       125.981
trainer/QF2 Loss                       128.268
trainer/Policy Loss                    164.45
trainer/Q1 Predictions Mean           -163.433
trainer/Q1 Predictions Std              41.3089
trainer/Q1 Predictions Max             -25.3339
trainer/Q1 Predictions Min            -230.846
trainer/Q2 Predictions Mean           -163.845
trainer/Q2 Predictions Std              41.3073
trainer/Q2 Predictions Max             -28.2108
trainer/Q2 Predictions Min            -231.918
trainer/Q Targets Mean                -162.641
trainer/Q Targets Std                   42.7345
trainer/Q Targets Max                   -0.724351
trainer/Q Targets Min                 -230.062
trainer/Log Pis Mean                     2.08764
trainer/Log Pis Std                      2.20073
trainer/Log Pis Max                      7.31099
trainer/Log Pis Min                     -2.89676
trainer/policy/mean Mean                -0.520868
trainer/policy/mean Std                  0.654941
trainer/policy/mean Max                  0.99841
trainer/policy/mean Min                 -0.997752
trainer/policy/normal/std Mean           0.636973
trainer/policy/normal/std Std            0.0752827
trainer/policy/normal/std Max            0.847808
trainer/policy/normal/std Min            0.437053
trainer/policy/normal/log_std Mean      -0.458007
trainer/policy/normal/log_std Std        0.118257
trainer/policy/normal/log_std Max       -0.165101
trainer/policy/normal/log_std Min       -0.8277
trainer/Alpha                            0.0378944
trainer/Alpha Loss                       0.286843
exploration/num steps total         127000
exploration/num paths total            635
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.877467
exploration/Rewards Std                  0.178249
exploration/Rewards Max                 -0.574798
exploration/Rewards Min                 -1.46194
exploration/Returns Mean              -175.493
exploration/Returns Std                  5.10336
exploration/Returns Max               -167.674
exploration/Returns Min               -182.054
exploration/Actions Mean                -0.265422
exploration/Actions Std                  0.702769
exploration/Actions Max                  0.999754
exploration/Actions Min                 -0.999373
exploration/Num Paths                    5
exploration/Average Returns           -175.493
evaluation/num steps total          607824
evaluation/num paths total            3024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.927955
evaluation/Rewards Std                   0.21098
evaluation/Rewards Max                  -0.501124
evaluation/Rewards Min                  -1.74254
evaluation/Returns Mean               -186.519
evaluation/Returns Std                  21.2766
evaluation/Returns Max                -147.094
evaluation/Returns Min                -231.792
evaluation/Actions Mean                 -0.311204
evaluation/Actions Std                   0.67915
evaluation/Actions Max                   0.999998
evaluation/Actions Min                  -0.999699
evaluation/Num Paths                    24
evaluation/Average Returns            -186.519
time/data storing (s)                    0.0060591
time/evaluation sampling (s)           426.428
time/exploration sampling (s)          104.075
time/logging (s)                         0.0236454
time/sac training (s)                    9.1933
time/saving (s)                          0.0263168
time/training (s)                        0.000119797
time/epoch (s)                         539.753
time/total (s)                       81218.1
Epoch                                  125
----------------------------------  ----------------
2020-11-02 08:35:25.429352 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 126 finished
----------------------------------  ----------------
replay_buffer/size                  128000
trainer/num train calls             127000
trainer/QF1 Loss                       108.073
trainer/QF2 Loss                       102.077
trainer/Policy Loss                    160.746
trainer/Q1 Predictions Mean           -159.967
trainer/Q1 Predictions Std              46.0666
trainer/Q1 Predictions Max              56.1045
trainer/Q1 Predictions Min            -230.187
trainer/Q2 Predictions Mean           -159.892
trainer/Q2 Predictions Std              45.744
trainer/Q2 Predictions Max              56.1931
trainer/Q2 Predictions Min            -231.167
trainer/Q Targets Mean                -159.274
trainer/Q Targets Std                   47.0035
trainer/Q Targets Max                   75.1497
trainer/Q Targets Min                 -230.529
trainer/Log Pis Mean                     1.75475
trainer/Log Pis Std                      2.23335
trainer/Log Pis Max                      8.15299
trainer/Log Pis Min                     -7.02263
trainer/policy/mean Mean                -0.240035
trainer/policy/mean Std                  0.782373
trainer/policy/mean Max                  0.999913
trainer/policy/mean Min                 -0.995195
trainer/policy/normal/std Mean           0.624761
trainer/policy/normal/std Std            0.0882879
trainer/policy/normal/std Max            0.88587
trainer/policy/normal/std Min            0.375319
trainer/policy/normal/log_std Mean      -0.48065
trainer/policy/normal/log_std Std        0.144588
trainer/policy/normal/log_std Max       -0.121185
trainer/policy/normal/log_std Min       -0.979979
trainer/Alpha                            0.0387478
trainer/Alpha Loss                      -0.797229
exploration/num steps total         128000
exploration/num paths total            640
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.02033
exploration/Rewards Std                  0.157792
exploration/Rewards Max                 -0.769288
exploration/Rewards Min                 -1.54808
exploration/Returns Mean              -204.065
exploration/Returns Std                 19.0603
exploration/Returns Max               -177.134
exploration/Returns Min               -235.964
exploration/Actions Mean                -0.0736777
exploration/Actions Std                  0.717576
exploration/Actions Max                  0.999746
exploration/Actions Min                 -0.998192
exploration/Num Paths                    5
exploration/Average Returns           -204.065
evaluation/num steps total          612648
evaluation/num paths total            3048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.978443
evaluation/Rewards Std                   0.204455
evaluation/Rewards Max                  -0.548363
evaluation/Rewards Min                  -1.66977
evaluation/Returns Mean               -196.667
evaluation/Returns Std                  22.466
evaluation/Returns Max                -158.101
evaluation/Returns Min                -233.964
evaluation/Actions Mean                 -0.329353
evaluation/Actions Std                   0.657681
evaluation/Actions Max                   0.999975
evaluation/Actions Min                  -0.998056
evaluation/Num Paths                    24
evaluation/Average Returns            -196.667
time/data storing (s)                    0.00846201
time/evaluation sampling (s)           452.374
time/exploration sampling (s)          116.231
time/logging (s)                         0.0203994
time/sac training (s)                   10.083
time/saving (s)                          0.0365696
time/training (s)                        0.000124271
time/epoch (s)                         578.754
time/total (s)                       81797.9
Epoch                                  126
----------------------------------  ----------------
2020-11-02 08:44:25.595719 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 127 finished
----------------------------------  ----------------
replay_buffer/size                  129000
trainer/num train calls             128000
trainer/QF1 Loss                       196.196
trainer/QF2 Loss                       185.27
trainer/Policy Loss                    157.716
trainer/Q1 Predictions Mean           -156.994
trainer/Q1 Predictions Std              43.6615
trainer/Q1 Predictions Max              10.3354
trainer/Q1 Predictions Min            -232.703
trainer/Q2 Predictions Mean           -157.115
trainer/Q2 Predictions Std              43.641
trainer/Q2 Predictions Max               6.80121
trainer/Q2 Predictions Min            -231.666
trainer/Q Targets Mean                -156.457
trainer/Q Targets Std                   45.7997
trainer/Q Targets Max                    2.00349
trainer/Q Targets Min                 -236.069
trainer/Log Pis Mean                     2.00746
trainer/Log Pis Std                      2.23031
trainer/Log Pis Max                      8.57336
trainer/Log Pis Min                     -4.4207
trainer/policy/mean Mean                -0.406182
trainer/policy/mean Std                  0.727893
trainer/policy/mean Max                  0.998942
trainer/policy/mean Min                 -0.997071
trainer/policy/normal/std Mean           0.614998
trainer/policy/normal/std Std            0.0766624
trainer/policy/normal/std Max            0.855695
trainer/policy/normal/std Min            0.41644
trainer/policy/normal/log_std Mean      -0.493965
trainer/policy/normal/log_std Std        0.125531
trainer/policy/normal/log_std Max       -0.155842
trainer/policy/normal/log_std Min       -0.876012
trainer/Alpha                            0.0390123
trainer/Alpha Loss                       0.0241937
exploration/num steps total         129000
exploration/num paths total            645
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.960617
exploration/Rewards Std                  0.254834
exploration/Rewards Max                 -0.59873
exploration/Rewards Min                 -2.03247
exploration/Returns Mean              -192.123
exploration/Returns Std                 40.9348
exploration/Returns Max               -152.153
exploration/Returns Min               -270.773
exploration/Actions Mean                -0.387792
exploration/Actions Std                  0.641554
exploration/Actions Max                  0.995239
exploration/Actions Min                 -0.999989
exploration/Num Paths                    5
exploration/Average Returns           -192.123
evaluation/num steps total          617472
evaluation/num paths total            3072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.908435
evaluation/Rewards Std                   0.215188
evaluation/Rewards Max                  -0.533783
evaluation/Rewards Min                  -1.60711
evaluation/Returns Mean               -182.595
evaluation/Returns Std                  19.2469
evaluation/Returns Max                -153.42
evaluation/Returns Min                -220.996
evaluation/Actions Mean                 -0.359063
evaluation/Actions Std                   0.662482
evaluation/Actions Max                   0.9983
evaluation/Actions Min                  -0.999453
evaluation/Num Paths                    24
evaluation/Average Returns            -182.595
time/data storing (s)                    0.00828483
time/evaluation sampling (s)           428.572
time/exploration sampling (s)          101.522
time/logging (s)                         0.0198392
time/sac training (s)                    9.35263
time/saving (s)                          0.0310752
time/training (s)                        0.000117765
time/epoch (s)                         539.506
time/total (s)                       82338
Epoch                                  127
----------------------------------  ----------------
2020-11-02 08:54:52.447931 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 128 finished
----------------------------------  ----------------
replay_buffer/size                  130000
trainer/num train calls             129000
trainer/QF1 Loss                        27.6637
trainer/QF2 Loss                        28.1414
trainer/Policy Loss                    155.431
trainer/Q1 Predictions Mean           -154.619
trainer/Q1 Predictions Std              44.4272
trainer/Q1 Predictions Max             -40.0696
trainer/Q1 Predictions Min            -228.539
trainer/Q2 Predictions Mean           -154.804
trainer/Q2 Predictions Std              44.6959
trainer/Q2 Predictions Max             -36.4496
trainer/Q2 Predictions Min            -229.485
trainer/Q Targets Mean                -155.643
trainer/Q Targets Std                   44.8117
trainer/Q Targets Max                  -41.849
trainer/Q Targets Min                 -229.025
trainer/Log Pis Mean                     1.65738
trainer/Log Pis Std                      2.16148
trainer/Log Pis Max                      8.91339
trainer/Log Pis Min                     -4.95157
trainer/policy/mean Mean                -0.218574
trainer/policy/mean Std                  0.794809
trainer/policy/mean Max                  0.999543
trainer/policy/mean Min                 -0.993658
trainer/policy/normal/std Mean           0.62988
trainer/policy/normal/std Std            0.0818543
trainer/policy/normal/std Max            0.903953
trainer/policy/normal/std Min            0.358758
trainer/policy/normal/log_std Mean      -0.47097
trainer/policy/normal/log_std Std        0.133809
trainer/policy/normal/log_std Max       -0.100978
trainer/policy/normal/log_std Min       -1.02511
trainer/Alpha                            0.0390527
trainer/Alpha Loss                      -1.11108
exploration/num steps total         130000
exploration/num paths total            650
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.05131
exploration/Rewards Std                  0.216147
exploration/Rewards Max                 -0.552176
exploration/Rewards Min                 -1.6616
exploration/Returns Mean              -210.261
exploration/Returns Std                 35.6792
exploration/Returns Max               -157.586
exploration/Returns Min               -267.649
exploration/Actions Mean                -0.127936
exploration/Actions Std                  0.723694
exploration/Actions Max                  0.999708
exploration/Actions Min                 -0.999147
exploration/Num Paths                    5
exploration/Average Returns           -210.261
evaluation/num steps total          622296
evaluation/num paths total            3096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00178
evaluation/Rewards Std                   0.219187
evaluation/Rewards Max                  -0.546414
evaluation/Rewards Min                  -1.68827
evaluation/Returns Mean               -201.357
evaluation/Returns Std                  27.4852
evaluation/Returns Max                -153.151
evaluation/Returns Min                -272.125
evaluation/Actions Mean                 -0.228947
evaluation/Actions Std                   0.677509
evaluation/Actions Max                   0.998266
evaluation/Actions Min                  -0.999513
evaluation/Num Paths                    24
evaluation/Average Returns            -201.357
time/data storing (s)                    0.0116062
time/evaluation sampling (s)           498.043
time/exploration sampling (s)          118.344
time/logging (s)                         0.0302799
time/sac training (s)                    9.32739
time/saving (s)                          0.0427319
time/training (s)                        0.000116346
time/epoch (s)                         625.798
time/total (s)                       82964.9
Epoch                                  128
----------------------------------  ----------------
2020-11-02 09:06:08.209211 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 129 finished
----------------------------------  ----------------
replay_buffer/size                  131000
trainer/num train calls             130000
trainer/QF1 Loss                        66.9919
trainer/QF2 Loss                        68.8919
trainer/Policy Loss                    160.244
trainer/Q1 Predictions Mean           -159.301
trainer/Q1 Predictions Std              43.2284
trainer/Q1 Predictions Max               7.37737
trainer/Q1 Predictions Min            -228.329
trainer/Q2 Predictions Mean           -159.438
trainer/Q2 Predictions Std              42.506
trainer/Q2 Predictions Max               0.559928
trainer/Q2 Predictions Min            -227.155
trainer/Q Targets Mean                -159.347
trainer/Q Targets Std                   43.2993
trainer/Q Targets Max                    5.25364
trainer/Q Targets Min                 -227.161
trainer/Log Pis Mean                     2.04851
trainer/Log Pis Std                      2.26167
trainer/Log Pis Max                      9.3608
trainer/Log Pis Min                     -6.84936
trainer/policy/mean Mean                -0.309854
trainer/policy/mean Std                  0.769165
trainer/policy/mean Max                  0.996809
trainer/policy/mean Min                 -0.997747
trainer/policy/normal/std Mean           0.624273
trainer/policy/normal/std Std            0.0793746
trainer/policy/normal/std Max            0.87801
trainer/policy/normal/std Min            0.342956
trainer/policy/normal/log_std Mean      -0.479339
trainer/policy/normal/log_std Std        0.128469
trainer/policy/normal/log_std Max       -0.130097
trainer/policy/normal/log_std Min       -1.07015
trainer/Alpha                            0.0397745
trainer/Alpha Loss                       0.156421
exploration/num steps total         131000
exploration/num paths total            655
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.912553
exploration/Rewards Std                  0.220202
exploration/Rewards Max                 -0.627204
exploration/Rewards Min                 -1.59487
exploration/Returns Mean              -182.511
exploration/Returns Std                 17.7803
exploration/Returns Max               -159.761
exploration/Returns Min               -206.884
exploration/Actions Mean                -0.250408
exploration/Actions Std                  0.700577
exploration/Actions Max                  0.999223
exploration/Actions Min                 -0.999709
exploration/Num Paths                    5
exploration/Average Returns           -182.511
evaluation/num steps total          627120
evaluation/num paths total            3120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.96309
evaluation/Rewards Std                   0.222582
evaluation/Rewards Max                  -0.555929
evaluation/Rewards Min                  -1.94392
evaluation/Returns Mean               -193.581
evaluation/Returns Std                  25.0302
evaluation/Returns Max                -162.573
evaluation/Returns Min                -263.174
evaluation/Actions Mean                 -0.247527
evaluation/Actions Std                   0.703115
evaluation/Actions Max                   0.999221
evaluation/Actions Min                  -0.998821
evaluation/Num Paths                    24
evaluation/Average Returns            -193.581
time/data storing (s)                    0.0362574
time/evaluation sampling (s)           562.355
time/exploration sampling (s)          102.174
time/logging (s)                         0.0589351
time/sac training (s)                    9.7284
time/saving (s)                          0.16913
time/training (s)                        0.000120681
time/epoch (s)                         674.522
time/total (s)                       83640.6
Epoch                                  129
----------------------------------  ----------------
2020-11-02 09:21:46.925601 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 130 finished
----------------------------------  ----------------
replay_buffer/size                  132000
trainer/num train calls             131000
trainer/QF1 Loss                       113.461
trainer/QF2 Loss                       119.607
trainer/Policy Loss                    159.794
trainer/Q1 Predictions Mean           -159.253
trainer/Q1 Predictions Std              39.8643
trainer/Q1 Predictions Max             -41.2547
trainer/Q1 Predictions Min            -226.976
trainer/Q2 Predictions Mean           -158.711
trainer/Q2 Predictions Std              39.6166
trainer/Q2 Predictions Max             -39.9305
trainer/Q2 Predictions Min            -228.153
trainer/Q Targets Mean                -159.244
trainer/Q Targets Std                   42.2944
trainer/Q Targets Max                   -0.697145
trainer/Q Targets Min                 -229.617
trainer/Log Pis Mean                     2.23642
trainer/Log Pis Std                      2.46302
trainer/Log Pis Max                      8.63232
trainer/Log Pis Min                     -4.64441
trainer/policy/mean Mean                -0.595149
trainer/policy/mean Std                  0.613177
trainer/policy/mean Max                  0.994197
trainer/policy/mean Min                 -0.998069
trainer/policy/normal/std Mean           0.660693
trainer/policy/normal/std Std            0.0923991
trainer/policy/normal/std Max            0.966635
trainer/policy/normal/std Min            0.40848
trainer/policy/normal/log_std Mean      -0.424243
trainer/policy/normal/log_std Std        0.140031
trainer/policy/normal/log_std Max       -0.0339347
trainer/policy/normal/log_std Min       -0.895313
trainer/Alpha                            0.041273
trainer/Alpha Loss                       0.753597
exploration/num steps total         132000
exploration/num paths total            660
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.961253
exploration/Rewards Std                  0.206378
exploration/Rewards Max                 -0.658256
exploration/Rewards Min                 -1.59064
exploration/Returns Mean              -192.251
exploration/Returns Std                 31.0572
exploration/Returns Max               -165.286
exploration/Returns Min               -250.601
exploration/Actions Mean                -0.338836
exploration/Actions Std                  0.646171
exploration/Actions Max                  0.99998
exploration/Actions Min                 -0.999363
exploration/Num Paths                    5
exploration/Average Returns           -192.251
evaluation/num steps total          631944
evaluation/num paths total            3144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948816
evaluation/Rewards Std                   0.219648
evaluation/Rewards Max                  -0.578387
evaluation/Rewards Min                  -1.68581
evaluation/Returns Mean               -190.712
evaluation/Returns Std                  29.5242
evaluation/Returns Max                -154.214
evaluation/Returns Min                -262.763
evaluation/Actions Mean                 -0.421245
evaluation/Actions Std                   0.589528
evaluation/Actions Max                   0.999903
evaluation/Actions Min                  -0.998794
evaluation/Num Paths                    24
evaluation/Average Returns            -190.712
time/data storing (s)                    0.0151727
time/evaluation sampling (s)           800.027
time/exploration sampling (s)          127.804
time/logging (s)                         0.0842598
time/sac training (s)                    9.24361
time/saving (s)                          0.190301
time/training (s)                        0.000118171
time/epoch (s)                         937.364
time/total (s)                       84579.3
Epoch                                  130
----------------------------------  ----------------
2020-11-02 09:32:09.456659 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 131 finished
----------------------------------  ----------------
replay_buffer/size                  133000
trainer/num train calls             132000
trainer/QF1 Loss                        33.0386
trainer/QF2 Loss                        31.8775
trainer/Policy Loss                    155.541
trainer/Q1 Predictions Mean           -154.552
trainer/Q1 Predictions Std              45.4359
trainer/Q1 Predictions Max              54.0154
trainer/Q1 Predictions Min            -231.449
trainer/Q2 Predictions Mean           -154.842
trainer/Q2 Predictions Std              45.1463
trainer/Q2 Predictions Max              53.1944
trainer/Q2 Predictions Min            -230.4
trainer/Q Targets Mean                -154.44
trainer/Q Targets Std                   45.7265
trainer/Q Targets Max                   61.103
trainer/Q Targets Min                 -236.956
trainer/Log Pis Mean                     1.66009
trainer/Log Pis Std                      2.20662
trainer/Log Pis Max                      8.53327
trainer/Log Pis Min                     -5.09564
trainer/policy/mean Mean                -0.215932
trainer/policy/mean Std                  0.80059
trainer/policy/mean Max                  0.999188
trainer/policy/mean Min                 -0.997133
trainer/policy/normal/std Mean           0.667868
trainer/policy/normal/std Std            0.0926005
trainer/policy/normal/std Max            0.919821
trainer/policy/normal/std Min            0.338856
trainer/policy/normal/log_std Mean      -0.413631
trainer/policy/normal/log_std Std        0.142753
trainer/policy/normal/log_std Max       -0.0835765
trainer/policy/normal/log_std Min       -1.08218
trainer/Alpha                            0.040584
trainer/Alpha Loss                      -1.0892
exploration/num steps total         133000
exploration/num paths total            665
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.895562
exploration/Rewards Std                  0.195471
exploration/Rewards Max                 -0.55937
exploration/Rewards Min                 -1.50622
exploration/Returns Mean              -179.112
exploration/Returns Std                  8.38349
exploration/Returns Max               -163.318
exploration/Returns Min               -186.876
exploration/Actions Mean                -0.365551
exploration/Actions Std                  0.699375
exploration/Actions Max                  0.99962
exploration/Actions Min                 -0.99983
exploration/Num Paths                    5
exploration/Average Returns           -179.112
evaluation/num steps total          636768
evaluation/num paths total            3168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.03602
evaluation/Rewards Std                   0.241817
evaluation/Rewards Max                  -0.588345
evaluation/Rewards Min                  -1.79467
evaluation/Returns Mean               -208.241
evaluation/Returns Std                  32.868
evaluation/Returns Max                -161.366
evaluation/Returns Min                -305.998
evaluation/Actions Mean                 -0.169608
evaluation/Actions Std                   0.712192
evaluation/Actions Max                   0.999801
evaluation/Actions Min                  -0.999345
evaluation/Num Paths                    24
evaluation/Average Returns            -208.241
time/data storing (s)                    0.02372
time/evaluation sampling (s)           496.71
time/exploration sampling (s)          114.812
time/logging (s)                         0.0560548
time/sac training (s)                    9.50115
time/saving (s)                          0.13607
time/training (s)                        0.000128958
time/epoch (s)                         621.24
time/total (s)                       85201.8
Epoch                                  131
----------------------------------  ----------------
2020-11-02 09:42:00.409766 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 132 finished
----------------------------------  ----------------
replay_buffer/size                  134000
trainer/num train calls             133000
trainer/QF1 Loss                       108.618
trainer/QF2 Loss                       103.976
trainer/Policy Loss                    163.102
trainer/Q1 Predictions Mean           -162.708
trainer/Q1 Predictions Std              43.7082
trainer/Q1 Predictions Max              25.2264
trainer/Q1 Predictions Min            -231.08
trainer/Q2 Predictions Mean           -162.251
trainer/Q2 Predictions Std              44.0829
trainer/Q2 Predictions Max              30.21
trainer/Q2 Predictions Min            -232.21
trainer/Q Targets Mean                -161.629
trainer/Q Targets Std                   45.222
trainer/Q Targets Max                   23.1899
trainer/Q Targets Min                 -229.586
trainer/Log Pis Mean                     1.88246
trainer/Log Pis Std                      2.20079
trainer/Log Pis Max                     12.1161
trainer/Log Pis Min                     -5.19703
trainer/policy/mean Mean                -0.335843
trainer/policy/mean Std                  0.76024
trainer/policy/mean Max                  0.999733
trainer/policy/mean Min                 -0.997867
trainer/policy/normal/std Mean           0.641207
trainer/policy/normal/std Std            0.0783846
trainer/policy/normal/std Max            0.93106
trainer/policy/normal/std Min            0.365521
trainer/policy/normal/log_std Mean      -0.452009
trainer/policy/normal/log_std Std        0.124168
trainer/policy/normal/log_std Max       -0.0714317
trainer/policy/normal/log_std Min       -1.00643
trainer/Alpha                            0.0380089
trainer/Alpha Loss                      -0.384334
exploration/num steps total         134000
exploration/num paths total            670
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.901456
exploration/Rewards Std                  0.220427
exploration/Rewards Max                 -0.533351
exploration/Rewards Min                 -1.53659
exploration/Returns Mean              -180.291
exploration/Returns Std                 26.7155
exploration/Returns Max               -156.439
exploration/Returns Min               -229.537
exploration/Actions Mean                -0.378641
exploration/Actions Std                  0.67618
exploration/Actions Max                  0.998146
exploration/Actions Min                 -0.99965
exploration/Num Paths                    5
exploration/Average Returns           -180.291
evaluation/num steps total          641592
evaluation/num paths total            3192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.95812
evaluation/Rewards Std                   0.213403
evaluation/Rewards Max                  -0.591032
evaluation/Rewards Min                  -1.95088
evaluation/Returns Mean               -192.582
evaluation/Returns Std                  22.2574
evaluation/Returns Max                -156.43
evaluation/Returns Min                -234.776
evaluation/Actions Mean                 -0.317826
evaluation/Actions Std                   0.662298
evaluation/Actions Max                   0.998744
evaluation/Actions Min                  -0.99986
evaluation/Num Paths                    24
evaluation/Average Returns            -192.582
time/data storing (s)                    0.0133213
time/evaluation sampling (s)           474.421
time/exploration sampling (s)          104.805
time/logging (s)                         0.0283554
time/sac training (s)                   10.4546
time/saving (s)                          0.0652349
time/training (s)                        0.000155026
time/epoch (s)                         589.788
time/total (s)                       85792.7
Epoch                                  132
----------------------------------  ----------------
2020-11-02 09:51:11.258118 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 133 finished
----------------------------------  ----------------
replay_buffer/size                  135000
trainer/num train calls             134000
trainer/QF1 Loss                        26.6285
trainer/QF2 Loss                        23.597
trainer/Policy Loss                    162.465
trainer/Q1 Predictions Mean           -161.952
trainer/Q1 Predictions Std              43.7705
trainer/Q1 Predictions Max              27.7254
trainer/Q1 Predictions Min            -230.229
trainer/Q2 Predictions Mean           -161.276
trainer/Q2 Predictions Std              43.5562
trainer/Q2 Predictions Max              27.5133
trainer/Q2 Predictions Min            -229.567
trainer/Q Targets Mean                -161.483
trainer/Q Targets Std                   43.3448
trainer/Q Targets Max                   18.3588
trainer/Q Targets Min                 -227.618
trainer/Log Pis Mean                     1.99697
trainer/Log Pis Std                      2.01896
trainer/Log Pis Max                      7.35766
trainer/Log Pis Min                     -6.907
trainer/policy/mean Mean                -0.347377
trainer/policy/mean Std                  0.761855
trainer/policy/mean Max                  0.998055
trainer/policy/mean Min                 -0.995454
trainer/policy/normal/std Mean           0.61767
trainer/policy/normal/std Std            0.0753514
trainer/policy/normal/std Max            0.806634
trainer/policy/normal/std Min            0.355578
trainer/policy/normal/log_std Mean      -0.489333
trainer/policy/normal/log_std Std        0.123308
trainer/policy/normal/log_std Max       -0.214885
trainer/policy/normal/log_std Min       -1.03401
trainer/Alpha                            0.038544
trainer/Alpha Loss                      -0.00985778
exploration/num steps total         135000
exploration/num paths total            675
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.961814
exploration/Rewards Std                  0.308314
exploration/Rewards Max                 -0.587423
exploration/Rewards Min                 -1.74487
exploration/Returns Mean              -192.363
exploration/Returns Std                 50.532
exploration/Returns Max               -153.748
exploration/Returns Min               -290.606
exploration/Actions Mean                -0.225953
exploration/Actions Std                  0.726405
exploration/Actions Max                  0.995573
exploration/Actions Min                 -0.999677
exploration/Num Paths                    5
exploration/Average Returns           -192.363
evaluation/num steps total          646416
evaluation/num paths total            3216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.96087
evaluation/Rewards Std                   0.230919
evaluation/Rewards Max                  -0.567356
evaluation/Rewards Min                  -1.84127
evaluation/Returns Mean               -193.135
evaluation/Returns Std                  31.9539
evaluation/Returns Max                -152.043
evaluation/Returns Min                -300.629
evaluation/Actions Mean                 -0.273554
evaluation/Actions Std                   0.697727
evaluation/Actions Max                   0.997394
evaluation/Actions Min                  -0.999444
evaluation/Num Paths                    24
evaluation/Average Returns            -193.135
time/data storing (s)                    0.00684813
time/evaluation sampling (s)           449.009
time/exploration sampling (s)           91.2441
time/logging (s)                         0.0256822
time/sac training (s)                    9.71446
time/saving (s)                          0.0382794
time/training (s)                        0.000127238
time/epoch (s)                         550.038
time/total (s)                       86343.5
Epoch                                  133
----------------------------------  ----------------
2020-11-02 10:00:23.451415 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 134 finished
----------------------------------  ----------------
replay_buffer/size                  136000
trainer/num train calls             135000
trainer/QF1 Loss                        69.597
trainer/QF2 Loss                        72.5031
trainer/Policy Loss                    164.413
trainer/Q1 Predictions Mean           -164.133
trainer/Q1 Predictions Std              45.0099
trainer/Q1 Predictions Max              21.4623
trainer/Q1 Predictions Min            -233.067
trainer/Q2 Predictions Mean           -163.395
trainer/Q2 Predictions Std              45.0768
trainer/Q2 Predictions Max              23.7329
trainer/Q2 Predictions Min            -231.512
trainer/Q Targets Mean                -162.754
trainer/Q Targets Std                   45.8128
trainer/Q Targets Max                   31.6882
trainer/Q Targets Min                 -229.603
trainer/Log Pis Mean                     2.51143
trainer/Log Pis Std                      2.4862
trainer/Log Pis Max                     10.6431
trainer/Log Pis Min                     -4.01351
trainer/policy/mean Mean                -0.113451
trainer/policy/mean Std                  0.836681
trainer/policy/mean Max                  0.99962
trainer/policy/mean Min                 -0.994925
trainer/policy/normal/std Mean           0.633577
trainer/policy/normal/std Std            0.100661
trainer/policy/normal/std Max            0.86793
trainer/policy/normal/std Min            0.361618
trainer/policy/normal/log_std Mean      -0.469326
trainer/policy/normal/log_std Std        0.162249
trainer/policy/normal/log_std Max       -0.141645
trainer/policy/normal/log_std Min       -1.01717
trainer/Alpha                            0.0391587
trainer/Alpha Loss                       1.65712
exploration/num steps total         136000
exploration/num paths total            680
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.951349
exploration/Rewards Std                  0.216119
exploration/Rewards Max                 -0.680059
exploration/Rewards Min                 -1.50946
exploration/Returns Mean              -190.27
exploration/Returns Std                 34.0035
exploration/Returns Max               -167.363
exploration/Returns Min               -257.368
exploration/Actions Mean                -0.0833132
exploration/Actions Std                  0.781249
exploration/Actions Max                  0.999995
exploration/Actions Min                 -0.999182
exploration/Num Paths                    5
exploration/Average Returns           -190.27
evaluation/num steps total          651240
evaluation/num paths total            3240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.954049
evaluation/Rewards Std                   0.195758
evaluation/Rewards Max                  -0.594839
evaluation/Rewards Min                  -1.68988
evaluation/Returns Mean               -191.764
evaluation/Returns Std                  20.0406
evaluation/Returns Max                -159.769
evaluation/Returns Min                -238.932
evaluation/Actions Mean                 -0.214087
evaluation/Actions Std                   0.731242
evaluation/Actions Max                   0.99963
evaluation/Actions Min                  -0.998367
evaluation/Num Paths                    24
evaluation/Average Returns            -191.764
time/data storing (s)                    0.0119965
time/evaluation sampling (s)           434.581
time/exploration sampling (s)          105.846
time/logging (s)                         0.0299157
time/sac training (s)                   10.5236
time/saving (s)                          0.0458049
time/training (s)                        0.000146831
time/epoch (s)                         551.038
time/total (s)                       86895.7
Epoch                                  134
----------------------------------  ----------------
2020-11-02 10:10:22.836989 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 135 finished
----------------------------------  ----------------
replay_buffer/size                  137000
trainer/num train calls             136000
trainer/QF1 Loss                        25.4327
trainer/QF2 Loss                        27.2259
trainer/Policy Loss                    158.945
trainer/Q1 Predictions Mean           -158.324
trainer/Q1 Predictions Std              40.5459
trainer/Q1 Predictions Max             -13.5062
trainer/Q1 Predictions Min            -227.047
trainer/Q2 Predictions Mean           -158.11
trainer/Q2 Predictions Std              40.3398
trainer/Q2 Predictions Max             -14.6569
trainer/Q2 Predictions Min            -225.918
trainer/Q Targets Mean                -159.427
trainer/Q Targets Std                   41.0262
trainer/Q Targets Max                   -3.76396
trainer/Q Targets Min                 -228.819
trainer/Log Pis Mean                     3.1579
trainer/Log Pis Std                      2.38942
trainer/Log Pis Max                     10.5876
trainer/Log Pis Min                     -4.61579
trainer/policy/mean Mean                -0.715683
trainer/policy/mean Std                  0.520298
trainer/policy/mean Max                  0.99552
trainer/policy/mean Min                 -0.999192
trainer/policy/normal/std Mean           0.632927
trainer/policy/normal/std Std            0.0977789
trainer/policy/normal/std Max            0.897623
trainer/policy/normal/std Min            0.3988
trainer/policy/normal/log_std Mean      -0.469265
trainer/policy/normal/log_std Std        0.154036
trainer/policy/normal/log_std Max       -0.108006
trainer/policy/normal/log_std Min       -0.919296
trainer/Alpha                            0.0400685
trainer/Alpha Loss                       3.72515
exploration/num steps total         137000
exploration/num paths total            685
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.853753
exploration/Rewards Std                  0.201373
exploration/Rewards Max                 -0.499256
exploration/Rewards Min                 -1.59499
exploration/Returns Mean              -170.751
exploration/Returns Std                 13.4721
exploration/Returns Max               -151.249
exploration/Returns Min               -191.838
exploration/Actions Mean                -0.518883
exploration/Actions Std                  0.608676
exploration/Actions Max                  0.995288
exploration/Actions Min                 -0.999984
exploration/Num Paths                    5
exploration/Average Returns           -170.751
evaluation/num steps total          656064
evaluation/num paths total            3264
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.93267
evaluation/Rewards Std                   0.190911
evaluation/Rewards Max                  -0.615915
evaluation/Rewards Min                  -1.65775
evaluation/Returns Mean               -187.467
evaluation/Returns Std                  22.9156
evaluation/Returns Max                -156.696
evaluation/Returns Min                -247.083
evaluation/Actions Mean                 -0.41884
evaluation/Actions Std                   0.595129
evaluation/Actions Max                   0.99497
evaluation/Actions Min                  -0.998924
evaluation/Num Paths                    24
evaluation/Average Returns            -187.467
time/data storing (s)                    0.014098
time/evaluation sampling (s)           482.791
time/exploration sampling (s)          103.824
time/logging (s)                         0.0363937
time/sac training (s)                   11.3347
time/saving (s)                          0.0686592
time/training (s)                        0.000143741
time/epoch (s)                         598.069
time/total (s)                       87495
Epoch                                  135
----------------------------------  ----------------
2020-11-02 10:20:10.432362 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 136 finished
----------------------------------  ----------------
replay_buffer/size                  138000
trainer/num train calls             137000
trainer/QF1 Loss                        74.8071
trainer/QF2 Loss                        94.5207
trainer/Policy Loss                    159.304
trainer/Q1 Predictions Mean           -158.745
trainer/Q1 Predictions Std              43.2028
trainer/Q1 Predictions Max               9.3779
trainer/Q1 Predictions Min            -231.49
trainer/Q2 Predictions Mean           -158.219
trainer/Q2 Predictions Std              43.3186
trainer/Q2 Predictions Max               7.89089
trainer/Q2 Predictions Min            -230.506
trainer/Q Targets Mean                -157.836
trainer/Q Targets Std                   44.1235
trainer/Q Targets Max                   24.4128
trainer/Q Targets Min                 -230.564
trainer/Log Pis Mean                     1.77023
trainer/Log Pis Std                      2.00884
trainer/Log Pis Max                      9.5302
trainer/Log Pis Min                     -5.28391
trainer/policy/mean Mean                -0.321248
trainer/policy/mean Std                  0.766871
trainer/policy/mean Max                  0.997431
trainer/policy/mean Min                 -0.997167
trainer/policy/normal/std Mean           0.616951
trainer/policy/normal/std Std            0.0792035
trainer/policy/normal/std Max            0.962583
trainer/policy/normal/std Min            0.373279
trainer/policy/normal/log_std Mean      -0.491219
trainer/policy/normal/log_std Std        0.128791
trainer/policy/normal/log_std Max       -0.0381346
trainer/policy/normal/log_std Min       -0.985429
trainer/Alpha                            0.0372473
trainer/Alpha Loss                      -0.755977
exploration/num steps total         138000
exploration/num paths total            690
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.970643
exploration/Rewards Std                  0.253048
exploration/Rewards Max                 -0.642515
exploration/Rewards Min                 -1.76466
exploration/Returns Mean              -194.129
exploration/Returns Std                 34.9245
exploration/Returns Max               -168.959
exploration/Returns Min               -263.38
exploration/Actions Mean                -0.203222
exploration/Actions Std                  0.689766
exploration/Actions Max                  0.998904
exploration/Actions Min                 -0.998511
exploration/Num Paths                    5
exploration/Average Returns           -194.129
evaluation/num steps total          660888
evaluation/num paths total            3288
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.945052
evaluation/Rewards Std                   0.232379
evaluation/Rewards Max                  -0.553649
evaluation/Rewards Min                  -1.84263
evaluation/Returns Mean               -189.955
evaluation/Returns Std                  26.8047
evaluation/Returns Max                -151.154
evaluation/Returns Min                -291.591
evaluation/Actions Mean                 -0.346166
evaluation/Actions Std                   0.637592
evaluation/Actions Max                   0.999559
evaluation/Actions Min                  -0.993838
evaluation/Num Paths                    24
evaluation/Average Returns            -189.955
time/data storing (s)                    0.00919987
time/evaluation sampling (s)           468.149
time/exploration sampling (s)          108.761
time/logging (s)                         0.0469428
time/sac training (s)                    9.28196
time/saving (s)                          0.0486097
time/training (s)                        0.000123718
time/epoch (s)                         586.297
time/total (s)                       88082.6
Epoch                                  136
----------------------------------  ----------------
2020-11-02 10:30:39.120163 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 137 finished
----------------------------------  ---------------
replay_buffer/size                  139000
trainer/num train calls             138000
trainer/QF1 Loss                        27.5375
trainer/QF2 Loss                        29.6014
trainer/Policy Loss                    161.768
trainer/Q1 Predictions Mean           -160.903
trainer/Q1 Predictions Std              43.0243
trainer/Q1 Predictions Max             -39.1659
trainer/Q1 Predictions Min            -233.821
trainer/Q2 Predictions Mean           -161.052
trainer/Q2 Predictions Std              42.4679
trainer/Q2 Predictions Max             -38.8575
trainer/Q2 Predictions Min            -236.924
trainer/Q Targets Mean                -160.747
trainer/Q Targets Std                   42.3654
trainer/Q Targets Max                  -32.0155
trainer/Q Targets Min                 -234.023
trainer/Log Pis Mean                     2.08121
trainer/Log Pis Std                      2.15405
trainer/Log Pis Max                      8.95616
trainer/Log Pis Min                     -4.27673
trainer/policy/mean Mean                -0.298508
trainer/policy/mean Std                  0.783239
trainer/policy/mean Max                  0.997677
trainer/policy/mean Min                 -0.998297
trainer/policy/normal/std Mean           0.63099
trainer/policy/normal/std Std            0.0863296
trainer/policy/normal/std Max            0.913161
trainer/policy/normal/std Min            0.394263
trainer/policy/normal/log_std Mean      -0.469874
trainer/policy/normal/log_std Std        0.137569
trainer/policy/normal/log_std Max       -0.0908432
trainer/policy/normal/log_std Min       -0.930738
trainer/Alpha                            0.0389504
trainer/Alpha Loss                       0.263558
exploration/num steps total         139000
exploration/num paths total            695
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.05387
exploration/Rewards Std                  0.209237
exploration/Rewards Max                 -0.67435
exploration/Rewards Min                 -1.64628
exploration/Returns Mean              -210.774
exploration/Returns Std                 26.9352
exploration/Returns Max               -180.925
exploration/Returns Min               -258.102
exploration/Actions Mean                -0.222823
exploration/Actions Std                  0.724794
exploration/Actions Max                  0.999373
exploration/Actions Min                 -0.999875
exploration/Num Paths                    5
exploration/Average Returns           -210.774
evaluation/num steps total          665712
evaluation/num paths total            3312
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.920314
evaluation/Rewards Std                   0.215046
evaluation/Rewards Max                  -0.521326
evaluation/Rewards Min                  -1.72334
evaluation/Returns Mean               -184.983
evaluation/Returns Std                  25.4501
evaluation/Returns Max                -149.014
evaluation/Returns Min                -262.146
evaluation/Actions Mean                 -0.332803
evaluation/Actions Std                   0.669179
evaluation/Actions Max                   0.999819
evaluation/Actions Min                  -0.998878
evaluation/Num Paths                    24
evaluation/Average Returns            -184.983
time/data storing (s)                    0.00817535
time/evaluation sampling (s)           504.606
time/exploration sampling (s)          113.2
time/logging (s)                         0.0279842
time/sac training (s)                    9.57083
time/saving (s)                          0.0583515
time/training (s)                        0.00013209
time/epoch (s)                         627.472
time/total (s)                       88711.3
Epoch                                  137
----------------------------------  ---------------
2020-11-02 10:41:20.115873 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 138 finished
----------------------------------  ----------------
replay_buffer/size                  140000
trainer/num train calls             139000
trainer/QF1 Loss                        31.7613
trainer/QF2 Loss                        31.7131
trainer/Policy Loss                    156.181
trainer/Q1 Predictions Mean           -155.376
trainer/Q1 Predictions Std              41.3145
trainer/Q1 Predictions Max             -61.7475
trainer/Q1 Predictions Min            -237.035
trainer/Q2 Predictions Mean           -155.72
trainer/Q2 Predictions Std              41.3318
trainer/Q2 Predictions Max             -54.5385
trainer/Q2 Predictions Min            -233.307
trainer/Q Targets Mean                -155.54
trainer/Q Targets Std                   41.2404
trainer/Q Targets Max                  -48.342
trainer/Q Targets Min                 -233.494
trainer/Log Pis Mean                     2.02308
trainer/Log Pis Std                      2.30323
trainer/Log Pis Max                      7.24606
trainer/Log Pis Min                     -7.96572
trainer/policy/mean Mean                -0.359159
trainer/policy/mean Std                  0.745474
trainer/policy/mean Max                  0.999501
trainer/policy/mean Min                 -0.99655
trainer/policy/normal/std Mean           0.621629
trainer/policy/normal/std Std            0.0813493
trainer/policy/normal/std Max            0.936244
trainer/policy/normal/std Min            0.339792
trainer/policy/normal/log_std Mean      -0.484
trainer/policy/normal/log_std Std        0.131381
trainer/policy/normal/log_std Max       -0.0658795
trainer/policy/normal/log_std Min       -1.07942
trainer/Alpha                            0.0389164
trainer/Alpha Loss                       0.0749301
exploration/num steps total         140000
exploration/num paths total            700
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.910686
exploration/Rewards Std                  0.204051
exploration/Rewards Max                 -0.554347
exploration/Rewards Min                 -1.69816
exploration/Returns Mean              -182.137
exploration/Returns Std                 19.6112
exploration/Returns Max               -152.419
exploration/Returns Min               -210.446
exploration/Actions Mean                -0.325369
exploration/Actions Std                  0.651416
exploration/Actions Max                  0.998381
exploration/Actions Min                 -0.998991
exploration/Num Paths                    5
exploration/Average Returns           -182.137
evaluation/num steps total          670536
evaluation/num paths total            3336
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.925491
evaluation/Rewards Std                   0.195984
evaluation/Rewards Max                  -0.519655
evaluation/Rewards Min                  -1.59377
evaluation/Returns Mean               -186.024
evaluation/Returns Std                  21.3732
evaluation/Returns Max                -151.194
evaluation/Returns Min                -233.277
evaluation/Actions Mean                 -0.290141
evaluation/Actions Std                   0.669858
evaluation/Actions Max                   0.999876
evaluation/Actions Min                  -0.999237
evaluation/Num Paths                    24
evaluation/Average Returns            -186.024
time/data storing (s)                    0.0135399
time/evaluation sampling (s)           523.55
time/exploration sampling (s)          106.685
time/logging (s)                         0.0500707
time/sac training (s)                    9.30661
time/saving (s)                          0.084477
time/training (s)                        0.000120387
time/epoch (s)                         639.69
time/total (s)                       89352.2
Epoch                                  138
----------------------------------  ----------------
2020-11-02 10:50:29.650542 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 139 finished
----------------------------------  ----------------
replay_buffer/size                  141000
trainer/num train calls             140000
trainer/QF1 Loss                       102.139
trainer/QF2 Loss                       103.24
trainer/Policy Loss                    158.475
trainer/Q1 Predictions Mean           -157.872
trainer/Q1 Predictions Std              46.2542
trainer/Q1 Predictions Max              69.1138
trainer/Q1 Predictions Min            -228.578
trainer/Q2 Predictions Mean           -157.615
trainer/Q2 Predictions Std              46.5139
trainer/Q2 Predictions Max              73.9055
trainer/Q2 Predictions Min            -228.204
trainer/Q Targets Mean                -157.494
trainer/Q Targets Std                   46.9507
trainer/Q Targets Max                   -0.837349
trainer/Q Targets Min                 -230.666
trainer/Log Pis Mean                     1.892
trainer/Log Pis Std                      2.17112
trainer/Log Pis Max                      9.46391
trainer/Log Pis Min                     -4.01511
trainer/policy/mean Mean                -0.345018
trainer/policy/mean Std                  0.757688
trainer/policy/mean Max                  0.99941
trainer/policy/mean Min                 -0.9958
trainer/policy/normal/std Mean           0.635509
trainer/policy/normal/std Std            0.0747424
trainer/policy/normal/std Max            0.820591
trainer/policy/normal/std Min            0.42638
trainer/policy/normal/log_std Mean      -0.460332
trainer/policy/normal/log_std Std        0.118862
trainer/policy/normal/log_std Max       -0.197731
trainer/policy/normal/log_std Min       -0.852424
trainer/Alpha                            0.0372759
trainer/Alpha Loss                      -0.355252
exploration/num steps total         141000
exploration/num paths total            705
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.899491
exploration/Rewards Std                  0.168316
exploration/Rewards Max                 -0.637234
exploration/Rewards Min                 -1.47817
exploration/Returns Mean              -179.898
exploration/Returns Std                  8.53983
exploration/Returns Max               -169.409
exploration/Returns Min               -191.138
exploration/Actions Mean                -0.356727
exploration/Actions Std                  0.683911
exploration/Actions Max                  0.998929
exploration/Actions Min                 -0.998941
exploration/Num Paths                    5
exploration/Average Returns           -179.898
evaluation/num steps total          675360
evaluation/num paths total            3360
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.936967
evaluation/Rewards Std                   0.200607
evaluation/Rewards Max                  -0.577271
evaluation/Rewards Min                  -1.68776
evaluation/Returns Mean               -188.33
evaluation/Returns Std                  21.2122
evaluation/Returns Max                -162.737
evaluation/Returns Min                -249.657
evaluation/Actions Mean                 -0.261633
evaluation/Actions Std                   0.689808
evaluation/Actions Max                   0.999941
evaluation/Actions Min                  -0.995861
evaluation/Num Paths                    24
evaluation/Average Returns            -188.33
time/data storing (s)                    0.0079193
time/evaluation sampling (s)           444.705
time/exploration sampling (s)           94.4957
time/logging (s)                         0.0258661
time/sac training (s)                    9.02986
time/saving (s)                          0.0364647
time/training (s)                        0.000116913
time/epoch (s)                         548.301
time/total (s)                       89901.7
Epoch                                  139
----------------------------------  ----------------
2020-11-02 11:00:34.260371 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 140 finished
----------------------------------  ----------------
replay_buffer/size                  142000
trainer/num train calls             141000
trainer/QF1 Loss                       220.132
trainer/QF2 Loss                       222.507
trainer/Policy Loss                    159.59
trainer/Q1 Predictions Mean           -158.395
trainer/Q1 Predictions Std              48.1026
trainer/Q1 Predictions Max              98.3286
trainer/Q1 Predictions Min            -233.373
trainer/Q2 Predictions Mean           -158.942
trainer/Q2 Predictions Std              48.4065
trainer/Q2 Predictions Max              89.9582
trainer/Q2 Predictions Min            -232.943
trainer/Q Targets Mean                -156.681
trainer/Q Targets Std                   51.0627
trainer/Q Targets Max                   91.9657
trainer/Q Targets Min                 -229.432
trainer/Log Pis Mean                     2.34785
trainer/Log Pis Std                      2.67925
trainer/Log Pis Max                     13.2336
trainer/Log Pis Min                     -6.38276
trainer/policy/mean Mean                -0.105858
trainer/policy/mean Std                  0.83502
trainer/policy/mean Max                  0.999941
trainer/policy/mean Min                 -0.997184
trainer/policy/normal/std Mean           0.606787
trainer/policy/normal/std Std            0.0773692
trainer/policy/normal/std Max            0.854569
trainer/policy/normal/std Min            0.343384
trainer/policy/normal/log_std Mean      -0.507905
trainer/policy/normal/log_std Std        0.130124
trainer/policy/normal/log_std Max       -0.157158
trainer/policy/normal/log_std Min       -1.0689
trainer/Alpha                            0.0375073
trainer/Alpha Loss                       1.14206
exploration/num steps total         142000
exploration/num paths total            710
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.95167
exploration/Rewards Std                  0.176339
exploration/Rewards Max                 -0.674887
exploration/Rewards Min                 -1.45596
exploration/Returns Mean              -190.334
exploration/Returns Std                 21.6136
exploration/Returns Max               -162.556
exploration/Returns Min               -221.845
exploration/Actions Mean                -0.0217938
exploration/Actions Std                  0.779992
exploration/Actions Max                  0.999176
exploration/Actions Min                 -0.998419
exploration/Num Paths                    5
exploration/Average Returns           -190.334
evaluation/num steps total          680184
evaluation/num paths total            3384
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.979721
evaluation/Rewards Std                   0.219648
evaluation/Rewards Max                  -0.60014
evaluation/Rewards Min                  -1.71444
evaluation/Returns Mean               -196.924
evaluation/Returns Std                  25.6844
evaluation/Returns Max                -158.705
evaluation/Returns Min                -256.435
evaluation/Actions Mean                 -0.266386
evaluation/Actions Std                   0.68574
evaluation/Actions Max                   0.99701
evaluation/Actions Min                  -0.999196
evaluation/Num Paths                    24
evaluation/Average Returns            -196.924
time/data storing (s)                    0.0183317
time/evaluation sampling (s)           442.919
time/exploration sampling (s)          150.304
time/logging (s)                         0.059386
time/sac training (s)                   10.1389
time/saving (s)                          0.0522344
time/training (s)                        0.000117143
time/epoch (s)                         603.493
time/total (s)                       90506.3
Epoch                                  140
----------------------------------  ----------------
2020-11-02 11:10:13.969596 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 141 finished
----------------------------------  ----------------
replay_buffer/size                  143000
trainer/num train calls             142000
trainer/QF1 Loss                        29.5527
trainer/QF2 Loss                        25.378
trainer/Policy Loss                    163.329
trainer/Q1 Predictions Mean           -162.528
trainer/Q1 Predictions Std              42.1509
trainer/Q1 Predictions Max             -37.6224
trainer/Q1 Predictions Min            -230.943
trainer/Q2 Predictions Mean           -162.76
trainer/Q2 Predictions Std              42.1326
trainer/Q2 Predictions Max             -36.0855
trainer/Q2 Predictions Min            -229.934
trainer/Q Targets Mean                -162.916
trainer/Q Targets Std                   42.3774
trainer/Q Targets Max                  -26.5254
trainer/Q Targets Min                 -232.293
trainer/Log Pis Mean                     2.3126
trainer/Log Pis Std                      1.969
trainer/Log Pis Max                      7.52381
trainer/Log Pis Min                     -3.66151
trainer/policy/mean Mean                -0.372086
trainer/policy/mean Std                  0.737321
trainer/policy/mean Max                  0.999349
trainer/policy/mean Min                 -0.99819
trainer/policy/normal/std Mean           0.614528
trainer/policy/normal/std Std            0.0826352
trainer/policy/normal/std Max            0.892426
trainer/policy/normal/std Min            0.396338
trainer/policy/normal/log_std Mean      -0.496099
trainer/policy/normal/log_std Std        0.136405
trainer/policy/normal/log_std Max       -0.113812
trainer/policy/normal/log_std Min       -0.925489
trainer/Alpha                            0.0385026
trainer/Alpha Loss                       1.01816
exploration/num steps total         143000
exploration/num paths total            715
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.996779
exploration/Rewards Std                  0.265352
exploration/Rewards Max                 -0.652639
exploration/Rewards Min                 -1.96054
exploration/Returns Mean              -199.356
exploration/Returns Std                 21.9624
exploration/Returns Max               -174.243
exploration/Returns Min               -236.349
exploration/Actions Mean                -0.424727
exploration/Actions Std                  0.657973
exploration/Actions Max                  0.999478
exploration/Actions Min                 -0.999892
exploration/Num Paths                    5
exploration/Average Returns           -199.356
evaluation/num steps total          685008
evaluation/num paths total            3408
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.919155
evaluation/Rewards Std                   0.214969
evaluation/Rewards Max                  -0.526728
evaluation/Rewards Min                  -1.67259
evaluation/Returns Mean               -184.75
evaluation/Returns Std                  23.0149
evaluation/Returns Max                -150.099
evaluation/Returns Min                -233.828
evaluation/Actions Mean                 -0.35695
evaluation/Actions Std                   0.663552
evaluation/Actions Max                   0.996723
evaluation/Actions Min                  -0.999868
evaluation/Num Paths                    24
evaluation/Average Returns            -184.75
time/data storing (s)                    0.014317
time/evaluation sampling (s)           421.435
time/exploration sampling (s)          146.669
time/logging (s)                         0.0356397
time/sac training (s)                   10.1014
time/saving (s)                          0.0580604
time/training (s)                        0.000121097
time/epoch (s)                         578.313
time/total (s)                       91086
Epoch                                  141
----------------------------------  ----------------
2020-11-02 11:21:24.642560 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 142 finished
----------------------------------  ----------------
replay_buffer/size                  144000
trainer/num train calls             143000
trainer/QF1 Loss                        25.8203
trainer/QF2 Loss                        26.3822
trainer/Policy Loss                    161.98
trainer/Q1 Predictions Mean           -161.036
trainer/Q1 Predictions Std              45.3398
trainer/Q1 Predictions Max               5.72358
trainer/Q1 Predictions Min            -227.706
trainer/Q2 Predictions Mean           -161.515
trainer/Q2 Predictions Std              45.8541
trainer/Q2 Predictions Max               0.853554
trainer/Q2 Predictions Min            -228.906
trainer/Q Targets Mean                -161.935
trainer/Q Targets Std                   46.1683
trainer/Q Targets Max                   18.3454
trainer/Q Targets Min                 -230.421
trainer/Log Pis Mean                     1.59818
trainer/Log Pis Std                      2.22624
trainer/Log Pis Max                      8.94997
trainer/Log Pis Min                     -6.21309
trainer/policy/mean Mean                -0.292161
trainer/policy/mean Std                  0.759806
trainer/policy/mean Max                  0.999098
trainer/policy/mean Min                 -0.996758
trainer/policy/normal/std Mean           0.630949
trainer/policy/normal/std Std            0.0909203
trainer/policy/normal/std Max            1.02252
trainer/policy/normal/std Min            0.324053
trainer/policy/normal/log_std Mean      -0.47084
trainer/policy/normal/log_std Std        0.143834
trainer/policy/normal/log_std Max        0.0222666
trainer/policy/normal/log_std Min       -1.12685
trainer/Alpha                            0.0371561
trainer/Alpha Loss                      -1.32306
exploration/num steps total         144000
exploration/num paths total            720
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.979207
exploration/Rewards Std                  0.216697
exploration/Rewards Max                 -0.650207
exploration/Rewards Min                 -1.66076
exploration/Returns Mean              -195.841
exploration/Returns Std                 16.6503
exploration/Returns Max               -164.852
exploration/Returns Min               -210.684
exploration/Actions Mean                -0.269252
exploration/Actions Std                  0.703784
exploration/Actions Max                  0.999977
exploration/Actions Min                 -0.99934
exploration/Num Paths                    5
exploration/Average Returns           -195.841
evaluation/num steps total          689832
evaluation/num paths total            3432
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.91639
evaluation/Rewards Std                   0.189084
evaluation/Rewards Max                  -0.560338
evaluation/Rewards Min                  -1.57086
evaluation/Returns Mean               -184.194
evaluation/Returns Std                  18.6679
evaluation/Returns Max                -163.535
evaluation/Returns Min                -243.331
evaluation/Actions Mean                 -0.337123
evaluation/Actions Std                   0.653324
evaluation/Actions Max                   0.999885
evaluation/Actions Min                  -0.999581
evaluation/Num Paths                    24
evaluation/Average Returns            -184.194
time/data storing (s)                    0.0122955
time/evaluation sampling (s)           518.819
time/exploration sampling (s)          139.954
time/logging (s)                         0.0519092
time/sac training (s)                   10.0835
time/saving (s)                          0.0573678
time/training (s)                        0.000114138
time/epoch (s)                         668.979
time/total (s)                       91756.6
Epoch                                  142
----------------------------------  ----------------
2020-11-02 11:31:44.633933 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 143 finished
----------------------------------  ----------------
replay_buffer/size                  145000
trainer/num train calls             144000
trainer/QF1 Loss                       145.718
trainer/QF2 Loss                       149.509
trainer/Policy Loss                    160.639
trainer/Q1 Predictions Mean           -160.2
trainer/Q1 Predictions Std              44.6671
trainer/Q1 Predictions Max              51.9314
trainer/Q1 Predictions Min            -230.834
trainer/Q2 Predictions Mean           -159.503
trainer/Q2 Predictions Std              44.1782
trainer/Q2 Predictions Max              49.1091
trainer/Q2 Predictions Min            -229.299
trainer/Q Targets Mean                -159.426
trainer/Q Targets Std                   46.0186
trainer/Q Targets Max                   55.7145
trainer/Q Targets Min                 -231.261
trainer/Log Pis Mean                     2.20338
trainer/Log Pis Std                      2.43297
trainer/Log Pis Max                     12.1677
trainer/Log Pis Min                     -7.74519
trainer/policy/mean Mean                -0.220727
trainer/policy/mean Std                  0.802467
trainer/policy/mean Max                  0.999832
trainer/policy/mean Min                 -0.995808
trainer/policy/normal/std Mean           0.632904
trainer/policy/normal/std Std            0.0738073
trainer/policy/normal/std Max            0.801195
trainer/policy/normal/std Min            0.36566
trainer/policy/normal/log_std Mean      -0.464344
trainer/policy/normal/log_std Std        0.118217
trainer/policy/normal/log_std Max       -0.221651
trainer/policy/normal/log_std Min       -1.00605
trainer/Alpha                            0.0383062
trainer/Alpha Loss                       0.66346
exploration/num steps total         145000
exploration/num paths total            725
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.977087
exploration/Rewards Std                  0.184311
exploration/Rewards Max                 -0.660135
exploration/Rewards Min                 -1.53585
exploration/Returns Mean              -195.417
exploration/Returns Std                 22.1137
exploration/Returns Max               -165.171
exploration/Returns Min               -233.561
exploration/Actions Mean                -0.0884004
exploration/Actions Std                  0.723274
exploration/Actions Max                  0.999342
exploration/Actions Min                 -0.998652
exploration/Num Paths                    5
exploration/Average Returns           -195.417
evaluation/num steps total          694656
evaluation/num paths total            3456
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.926905
evaluation/Rewards Std                   0.197811
evaluation/Rewards Max                  -0.558175
evaluation/Rewards Min                  -1.64867
evaluation/Returns Mean               -186.308
evaluation/Returns Std                  20.4353
evaluation/Returns Max                -149.094
evaluation/Returns Min                -232.737
evaluation/Actions Mean                 -0.260082
evaluation/Actions Std                   0.689032
evaluation/Actions Max                   1
evaluation/Actions Min                  -0.998147
evaluation/Num Paths                    24
evaluation/Average Returns            -186.308
time/data storing (s)                    0.0338401
time/evaluation sampling (s)           488.139
time/exploration sampling (s)          119.424
time/logging (s)                         0.0864374
time/sac training (s)                   10.496
time/saving (s)                          0.133907
time/training (s)                        0.000121458
time/epoch (s)                         618.313
time/total (s)                       92376.6
Epoch                                  143
----------------------------------  ----------------
2020-11-02 11:40:56.582997 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 144 finished
----------------------------------  ----------------
replay_buffer/size                  146000
trainer/num train calls             145000
trainer/QF1 Loss                        22.8137
trainer/QF2 Loss                        29.5986
trainer/Policy Loss                    162.559
trainer/Q1 Predictions Mean           -161.919
trainer/Q1 Predictions Std              43.3716
trainer/Q1 Predictions Max              37.8087
trainer/Q1 Predictions Min            -234.905
trainer/Q2 Predictions Mean           -161.757
trainer/Q2 Predictions Std              43.7911
trainer/Q2 Predictions Max              38.1517
trainer/Q2 Predictions Min            -230.53
trainer/Q Targets Mean                -162.676
trainer/Q Targets Std                   43.5658
trainer/Q Targets Max                   40.6153
trainer/Q Targets Min                 -232.737
trainer/Log Pis Mean                     1.98126
trainer/Log Pis Std                      1.94856
trainer/Log Pis Max                      7.5681
trainer/Log Pis Min                     -4.4539
trainer/policy/mean Mean                -0.424859
trainer/policy/mean Std                  0.727072
trainer/policy/mean Max                  0.998486
trainer/policy/mean Min                 -0.997518
trainer/policy/normal/std Mean           0.633662
trainer/policy/normal/std Std            0.079493
trainer/policy/normal/std Max            0.896746
trainer/policy/normal/std Min            0.426964
trainer/policy/normal/log_std Mean      -0.464076
trainer/policy/normal/log_std Std        0.125229
trainer/policy/normal/log_std Max       -0.108983
trainer/policy/normal/log_std Min       -0.851056
trainer/Alpha                            0.0392618
trainer/Alpha Loss                      -0.0606667
exploration/num steps total         146000
exploration/num paths total            730
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.974455
exploration/Rewards Std                  0.200096
exploration/Rewards Max                 -0.676719
exploration/Rewards Min                 -1.48861
exploration/Returns Mean              -194.891
exploration/Returns Std                 25.0486
exploration/Returns Max               -170.951
exploration/Returns Min               -231.65
exploration/Actions Mean                -0.220274
exploration/Actions Std                  0.715615
exploration/Actions Max                  0.999679
exploration/Actions Min                 -0.999283
exploration/Num Paths                    5
exploration/Average Returns           -194.891
evaluation/num steps total          699480
evaluation/num paths total            3480
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.924991
evaluation/Rewards Std                   0.210987
evaluation/Rewards Max                  -0.549163
evaluation/Rewards Min                  -1.7773
evaluation/Returns Mean               -185.923
evaluation/Returns Std                  20.9512
evaluation/Returns Max                -156.848
evaluation/Returns Min                -240.354
evaluation/Actions Mean                 -0.337811
evaluation/Actions Std                   0.65382
evaluation/Actions Max                   0.999901
evaluation/Actions Min                  -0.997817
evaluation/Num Paths                    24
evaluation/Average Returns            -185.923
time/data storing (s)                    0.0148666
time/evaluation sampling (s)           422.63
time/exploration sampling (s)          114.569
time/logging (s)                         0.0352093
time/sac training (s)                   13.0647
time/saving (s)                          0.0433584
time/training (s)                        0.000124678
time/epoch (s)                         550.357
time/total (s)                       92928.5
Epoch                                  144
----------------------------------  ----------------
2020-11-02 11:51:27.983732 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 145 finished
----------------------------------  ----------------
replay_buffer/size                  147000
trainer/num train calls             146000
trainer/QF1 Loss                        44.5188
trainer/QF2 Loss                        32.5638
trainer/Policy Loss                    161.757
trainer/Q1 Predictions Mean           -160.974
trainer/Q1 Predictions Std              41.1049
trainer/Q1 Predictions Max              17.9768
trainer/Q1 Predictions Min            -229.616
trainer/Q2 Predictions Mean           -160.739
trainer/Q2 Predictions Std              40.5131
trainer/Q2 Predictions Max              13.232
trainer/Q2 Predictions Min            -229.28
trainer/Q Targets Mean                -161.447
trainer/Q Targets Std                   40.0287
trainer/Q Targets Max                   38.8403
trainer/Q Targets Min                 -227.028
trainer/Log Pis Mean                     2.04598
trainer/Log Pis Std                      1.98129
trainer/Log Pis Max                      9.44985
trainer/Log Pis Min                     -3.06725
trainer/policy/mean Mean                -0.226406
trainer/policy/mean Std                  0.804049
trainer/policy/mean Max                  0.999082
trainer/policy/mean Min                 -0.995381
trainer/policy/normal/std Mean           0.627844
trainer/policy/normal/std Std            0.079152
trainer/policy/normal/std Max            0.860863
trainer/policy/normal/std Min            0.309936
trainer/policy/normal/log_std Mean      -0.473584
trainer/policy/normal/log_std Std        0.128558
trainer/policy/normal/log_std Max       -0.14982
trainer/policy/normal/log_std Min       -1.17139
trainer/Alpha                            0.037234
trainer/Alpha Loss                       0.151283
exploration/num steps total         147000
exploration/num paths total            735
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.929096
exploration/Rewards Std                  0.150103
exploration/Rewards Max                 -0.635402
exploration/Rewards Min                 -1.57453
exploration/Returns Mean              -185.819
exploration/Returns Std                  8.92192
exploration/Returns Max               -170.109
exploration/Returns Min               -192.869
exploration/Actions Mean                -0.0835074
exploration/Actions Std                  0.706834
exploration/Actions Max                  0.999565
exploration/Actions Min                 -0.998914
exploration/Num Paths                    5
exploration/Average Returns           -185.819
evaluation/num steps total          704304
evaluation/num paths total            3504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.916137
evaluation/Rewards Std                   0.176361
evaluation/Rewards Max                  -0.553974
evaluation/Rewards Min                  -1.51344
evaluation/Returns Mean               -184.144
evaluation/Returns Std                  15.4805
evaluation/Returns Max                -153.765
evaluation/Returns Min                -212.046
evaluation/Actions Mean                 -0.299095
evaluation/Actions Std                   0.657376
evaluation/Actions Max                   0.999784
evaluation/Actions Min                  -0.996259
evaluation/Num Paths                    24
evaluation/Average Returns            -184.144
time/data storing (s)                    0.0158009
time/evaluation sampling (s)           469.848
time/exploration sampling (s)          149.046
time/logging (s)                         0.0941593
time/sac training (s)                   10.7751
time/saving (s)                          0.0718489
time/training (s)                        0.000139653
time/epoch (s)                         629.85
time/total (s)                       93559.9
Epoch                                  145
----------------------------------  ----------------
2020-11-02 12:00:53.689897 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 146 finished
----------------------------------  ----------------
replay_buffer/size                  148000
trainer/num train calls             147000
trainer/QF1 Loss                        84.8228
trainer/QF2 Loss                        82.7042
trainer/Policy Loss                    159.642
trainer/Q1 Predictions Mean           -158.639
trainer/Q1 Predictions Std              47.8519
trainer/Q1 Predictions Max              50.0046
trainer/Q1 Predictions Min            -231.338
trainer/Q2 Predictions Mean           -159.138
trainer/Q2 Predictions Std              48.4655
trainer/Q2 Predictions Max              45.7433
trainer/Q2 Predictions Min            -235.073
trainer/Q Targets Mean                -159.444
trainer/Q Targets Std                   50.3372
trainer/Q Targets Max                   61.1359
trainer/Q Targets Min                 -233.432
trainer/Log Pis Mean                     2.4839
trainer/Log Pis Std                      2.21645
trainer/Log Pis Max                      9.14895
trainer/Log Pis Min                     -3.90447
trainer/policy/mean Mean                -0.202575
trainer/policy/mean Std                  0.82765
trainer/policy/mean Max                  0.999929
trainer/policy/mean Min                 -0.998769
trainer/policy/normal/std Mean           0.639498
trainer/policy/normal/std Std            0.0784743
trainer/policy/normal/std Max            0.88787
trainer/policy/normal/std Min            0.436119
trainer/policy/normal/log_std Mean      -0.454546
trainer/policy/normal/log_std Std        0.12221
trainer/policy/normal/log_std Max       -0.11893
trainer/policy/normal/log_std Min       -0.829841
trainer/Alpha                            0.0394331
trainer/Alpha Loss                       1.56452
exploration/num steps total         148000
exploration/num paths total            740
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.93065
exploration/Rewards Std                  0.235726
exploration/Rewards Max                 -0.565254
exploration/Rewards Min                 -1.71827
exploration/Returns Mean              -186.13
exploration/Returns Std                 27.4288
exploration/Returns Max               -155.631
exploration/Returns Min               -225.028
exploration/Actions Mean                -0.411654
exploration/Actions Std                  0.680009
exploration/Actions Max                  0.999521
exploration/Actions Min                 -0.999766
exploration/Num Paths                    5
exploration/Average Returns           -186.13
evaluation/num steps total          709128
evaluation/num paths total            3528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.924558
evaluation/Rewards Std                   0.232136
evaluation/Rewards Max                  -0.531077
evaluation/Rewards Min                  -1.73199
evaluation/Returns Mean               -185.836
evaluation/Returns Std                  27.5219
evaluation/Returns Max                -153.766
evaluation/Returns Min                -247.873
evaluation/Actions Mean                 -0.349469
evaluation/Actions Std                   0.662502
evaluation/Actions Max                   0.996868
evaluation/Actions Min                  -0.999086
evaluation/Num Paths                    24
evaluation/Average Returns            -185.836
time/data storing (s)                    0.0117823
time/evaluation sampling (s)           456.649
time/exploration sampling (s)           97.7171
time/logging (s)                         0.0299222
time/sac training (s)                    9.85421
time/saving (s)                          0.0418565
time/training (s)                        0.000118906
time/epoch (s)                         564.304
time/total (s)                       94125.5
Epoch                                  146
----------------------------------  ----------------
2020-11-02 12:10:58.286733 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 147 finished
----------------------------------  ----------------
replay_buffer/size                  149000
trainer/num train calls             148000
trainer/QF1 Loss                        30.5036
trainer/QF2 Loss                        32.024
trainer/Policy Loss                    159.776
trainer/Q1 Predictions Mean           -159.215
trainer/Q1 Predictions Std              39.6356
trainer/Q1 Predictions Max             -46.0611
trainer/Q1 Predictions Min            -229.732
trainer/Q2 Predictions Mean           -158.914
trainer/Q2 Predictions Std              39.6845
trainer/Q2 Predictions Max             -40.7481
trainer/Q2 Predictions Min            -230.468
trainer/Q Targets Mean                -159.693
trainer/Q Targets Std                   39.2173
trainer/Q Targets Max                  -54.114
trainer/Q Targets Min                 -231.253
trainer/Log Pis Mean                     1.97046
trainer/Log Pis Std                      2.13013
trainer/Log Pis Max                      7.97578
trainer/Log Pis Min                     -4.4753
trainer/policy/mean Mean                -0.431721
trainer/policy/mean Std                  0.710405
trainer/policy/mean Max                  0.999141
trainer/policy/mean Min                 -0.99836
trainer/policy/normal/std Mean           0.654967
trainer/policy/normal/std Std            0.106283
trainer/policy/normal/std Max            0.949814
trainer/policy/normal/std Min            0.303133
trainer/policy/normal/log_std Mean      -0.436522
trainer/policy/normal/log_std Std        0.164472
trainer/policy/normal/log_std Max       -0.0514887
trainer/policy/normal/log_std Min       -1.19359
trainer/Alpha                            0.0412374
trainer/Alpha Loss                      -0.0941964
exploration/num steps total         149000
exploration/num paths total            745
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.930969
exploration/Rewards Std                  0.161436
exploration/Rewards Max                 -0.654271
exploration/Rewards Min                 -1.50624
exploration/Returns Mean              -186.194
exploration/Returns Std                  8.55165
exploration/Returns Max               -175.228
exploration/Returns Min               -199.252
exploration/Actions Mean                -0.252736
exploration/Actions Std                  0.690905
exploration/Actions Max                  0.999525
exploration/Actions Min                 -0.998693
exploration/Num Paths                    5
exploration/Average Returns           -186.194
evaluation/num steps total          713952
evaluation/num paths total            3552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.890482
evaluation/Rewards Std                   0.193252
evaluation/Rewards Max                  -0.5381
evaluation/Rewards Min                  -1.69125
evaluation/Returns Mean               -178.987
evaluation/Returns Std                  15.5605
evaluation/Returns Max                -154.565
evaluation/Returns Min                -213.376
evaluation/Actions Mean                 -0.40318
evaluation/Actions Std                   0.632003
evaluation/Actions Max                   0.980197
evaluation/Actions Min                  -0.998784
evaluation/Num Paths                    24
evaluation/Average Returns            -178.987
time/data storing (s)                    0.0125719
time/evaluation sampling (s)           487.437
time/exploration sampling (s)          105.72
time/logging (s)                         0.0550314
time/sac training (s)                   10.0005
time/saving (s)                          0.0710229
time/training (s)                        0.000140462
time/epoch (s)                         603.296
time/total (s)                       94730.1
Epoch                                  147
----------------------------------  ----------------
2020-11-02 12:19:54.749210 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 148 finished
----------------------------------  ----------------
replay_buffer/size                  150000
trainer/num train calls             149000
trainer/QF1 Loss                        26.5381
trainer/QF2 Loss                        31.5099
trainer/Policy Loss                    164.993
trainer/Q1 Predictions Mean           -164.664
trainer/Q1 Predictions Std              44.9239
trainer/Q1 Predictions Max              61.0424
trainer/Q1 Predictions Min            -229.492
trainer/Q2 Predictions Mean           -163.637
trainer/Q2 Predictions Std              45.1888
trainer/Q2 Predictions Max              56.2414
trainer/Q2 Predictions Min            -228.019
trainer/Q Targets Mean                -164.722
trainer/Q Targets Std                   45.6314
trainer/Q Targets Max                   62.8484
trainer/Q Targets Min                 -228.463
trainer/Log Pis Mean                     1.66375
trainer/Log Pis Std                      2.04399
trainer/Log Pis Max                      7.18105
trainer/Log Pis Min                     -4.7397
trainer/policy/mean Mean                -0.443557
trainer/policy/mean Std                  0.691507
trainer/policy/mean Max                  0.996962
trainer/policy/mean Min                 -0.997216
trainer/policy/normal/std Mean           0.648957
trainer/policy/normal/std Std            0.0871977
trainer/policy/normal/std Max            0.833528
trainer/policy/normal/std Min            0.411948
trainer/policy/normal/log_std Mean      -0.441438
trainer/policy/normal/log_std Std        0.134792
trainer/policy/normal/log_std Max       -0.182088
trainer/policy/normal/log_std Min       -0.886858
trainer/Alpha                            0.040232
trainer/Alpha Loss                      -1.08039
exploration/num steps total         150000
exploration/num paths total            750
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.969816
exploration/Rewards Std                  0.199973
exploration/Rewards Max                 -0.614057
exploration/Rewards Min                 -1.59106
exploration/Returns Mean              -193.963
exploration/Returns Std                 26.2385
exploration/Returns Max               -158.197
exploration/Returns Min               -226.897
exploration/Actions Mean                -0.00196918
exploration/Actions Std                  0.795702
exploration/Actions Max                  1
exploration/Actions Min                 -0.999276
exploration/Num Paths                    5
exploration/Average Returns           -193.963
evaluation/num steps total          718776
evaluation/num paths total            3576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.971568
evaluation/Rewards Std                   0.215567
evaluation/Rewards Max                  -0.544897
evaluation/Rewards Min                  -1.81774
evaluation/Returns Mean               -195.285
evaluation/Returns Std                  29.574
evaluation/Returns Max                -149.24
evaluation/Returns Min                -275.372
evaluation/Actions Mean                 -0.386575
evaluation/Actions Std                   0.619969
evaluation/Actions Max                   0.991401
evaluation/Actions Min                  -0.999847
evaluation/Num Paths                    24
evaluation/Average Returns            -195.285
time/data storing (s)                    0.00844082
time/evaluation sampling (s)           418.576
time/exploration sampling (s)          107.135
time/logging (s)                         0.0197435
time/sac training (s)                    9.47837
time/saving (s)                          0.0445533
time/training (s)                        0.000120101
time/epoch (s)                         535.262
time/total (s)                       95266.5
Epoch                                  148
----------------------------------  ----------------
2020-11-02 12:29:43.645350 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 149 finished
----------------------------------  ----------------
replay_buffer/size                  151000
trainer/num train calls             150000
trainer/QF1 Loss                       147.477
trainer/QF2 Loss                       148.194
trainer/Policy Loss                    156.277
trainer/Q1 Predictions Mean           -155.302
trainer/Q1 Predictions Std              41.5653
trainer/Q1 Predictions Max             -27.1187
trainer/Q1 Predictions Min            -225.781
trainer/Q2 Predictions Mean           -155.671
trainer/Q2 Predictions Std              41.9515
trainer/Q2 Predictions Max             -34.1043
trainer/Q2 Predictions Min            -227.248
trainer/Q Targets Mean                -155.022
trainer/Q Targets Std                   43.9276
trainer/Q Targets Max                   -0.706654
trainer/Q Targets Min                 -227.14
trainer/Log Pis Mean                     2.14135
trainer/Log Pis Std                      2.15754
trainer/Log Pis Max                      8.12715
trainer/Log Pis Min                     -3.59806
trainer/policy/mean Mean                -0.247436
trainer/policy/mean Std                  0.80839
trainer/policy/mean Max                  0.999118
trainer/policy/mean Min                 -0.998256
trainer/policy/normal/std Mean           0.614804
trainer/policy/normal/std Std            0.0796492
trainer/policy/normal/std Max            0.933663
trainer/policy/normal/std Min            0.375778
trainer/policy/normal/log_std Mean      -0.494837
trainer/policy/normal/log_std Std        0.129776
trainer/policy/normal/log_std Max       -0.0686396
trainer/policy/normal/log_std Min       -0.978756
trainer/Alpha                            0.0364497
trainer/Alpha Loss                       0.468121
exploration/num steps total         151000
exploration/num paths total            755
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.886693
exploration/Rewards Std                  0.235465
exploration/Rewards Max                 -0.498319
exploration/Rewards Min                 -1.54873
exploration/Returns Mean              -177.339
exploration/Returns Std                 24.3431
exploration/Returns Max               -152.327
exploration/Returns Min               -218.834
exploration/Actions Mean                -0.397119
exploration/Actions Std                  0.705473
exploration/Actions Max                  0.999433
exploration/Actions Min                 -0.999715
exploration/Num Paths                    5
exploration/Average Returns           -177.339
evaluation/num steps total          723600
evaluation/num paths total            3600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.943477
evaluation/Rewards Std                   0.211593
evaluation/Rewards Max                  -0.546113
evaluation/Rewards Min                  -1.81054
evaluation/Returns Mean               -189.639
evaluation/Returns Std                  22.8707
evaluation/Returns Max                -164.698
evaluation/Returns Min                -260.013
evaluation/Actions Mean                 -0.233454
evaluation/Actions Std                   0.704019
evaluation/Actions Max                   0.998869
evaluation/Actions Min                  -0.997769
evaluation/Num Paths                    24
evaluation/Average Returns            -189.639
time/data storing (s)                    0.016769
time/evaluation sampling (s)           470.318
time/exploration sampling (s)          107.79
time/logging (s)                         0.0795777
time/sac training (s)                    9.47845
time/saving (s)                          0.0477317
time/training (s)                        0.000112005
time/epoch (s)                         587.731
time/total (s)                       95855.4
Epoch                                  149
----------------------------------  ----------------
2020-11-02 12:41:13.311948 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 150 finished
----------------------------------  ----------------
replay_buffer/size                  152000
trainer/num train calls             151000
trainer/QF1 Loss                        26.7864
trainer/QF2 Loss                        30.8947
trainer/Policy Loss                    165.478
trainer/Q1 Predictions Mean           -164.667
trainer/Q1 Predictions Std              42.6541
trainer/Q1 Predictions Max              63.7245
trainer/Q1 Predictions Min            -228.42
trainer/Q2 Predictions Mean           -164.643
trainer/Q2 Predictions Std              42.7636
trainer/Q2 Predictions Max              56.2136
trainer/Q2 Predictions Min            -227.159
trainer/Q Targets Mean                -164.876
trainer/Q Targets Std                   43.1417
trainer/Q Targets Max                   75.4737
trainer/Q Targets Min                 -230.517
trainer/Log Pis Mean                     2.01878
trainer/Log Pis Std                      2.02161
trainer/Log Pis Max                     11.3849
trainer/Log Pis Min                     -4.0697
trainer/policy/mean Mean                -0.378128
trainer/policy/mean Std                  0.758208
trainer/policy/mean Max                  0.999671
trainer/policy/mean Min                 -0.993589
trainer/policy/normal/std Mean           0.616763
trainer/policy/normal/std Std            0.0771454
trainer/policy/normal/std Max            0.854772
trainer/policy/normal/std Min            0.367962
trainer/policy/normal/log_std Mean      -0.491181
trainer/policy/normal/log_std Std        0.126385
trainer/policy/normal/log_std Max       -0.15692
trainer/policy/normal/log_std Min       -0.999776
trainer/Alpha                            0.0382281
trainer/Alpha Loss                       0.0612899
exploration/num steps total         152000
exploration/num paths total            760
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.937046
exploration/Rewards Std                  0.210697
exploration/Rewards Max                 -0.607319
exploration/Rewards Min                 -1.54999
exploration/Returns Mean              -187.409
exploration/Returns Std                 20.4167
exploration/Returns Max               -165.733
exploration/Returns Min               -218.786
exploration/Actions Mean                -0.420061
exploration/Actions Std                  0.661406
exploration/Actions Max                  0.999393
exploration/Actions Min                 -0.999584
exploration/Num Paths                    5
exploration/Average Returns           -187.409
evaluation/num steps total          728424
evaluation/num paths total            3624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.903635
evaluation/Rewards Std                   0.218238
evaluation/Rewards Max                  -0.554182
evaluation/Rewards Min                  -1.78416
evaluation/Returns Mean               -181.631
evaluation/Returns Std                  20.5201
evaluation/Returns Max                -154.294
evaluation/Returns Min                -238.302
evaluation/Actions Mean                 -0.381221
evaluation/Actions Std                   0.67096
evaluation/Actions Max                   0.999614
evaluation/Actions Min                  -0.999445
evaluation/Num Paths                    24
evaluation/Average Returns            -181.631
time/data storing (s)                    0.0175516
time/evaluation sampling (s)           547.308
time/exploration sampling (s)          130.636
time/logging (s)                         0.109757
time/sac training (s)                   10.2131
time/saving (s)                          0.0788612
time/training (s)                        0.000121261
time/epoch (s)                         688.363
time/total (s)                       96545.1
Epoch                                  150
----------------------------------  ----------------
2020-11-02 12:51:28.689509 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 151 finished
----------------------------------  ----------------
replay_buffer/size                  153000
trainer/num train calls             152000
trainer/QF1 Loss                        99.359
trainer/QF2 Loss                       109.901
trainer/Policy Loss                    160.763
trainer/Q1 Predictions Mean           -159.948
trainer/Q1 Predictions Std              47.2056
trainer/Q1 Predictions Max             100.665
trainer/Q1 Predictions Min            -232.844
trainer/Q2 Predictions Mean           -160.243
trainer/Q2 Predictions Std              47.1257
trainer/Q2 Predictions Max              94.0189
trainer/Q2 Predictions Min            -236.381
trainer/Q Targets Mean                -158.714
trainer/Q Targets Std                   47.875
trainer/Q Targets Max                   92.4298
trainer/Q Targets Min                 -232.754
trainer/Log Pis Mean                     1.97583
trainer/Log Pis Std                      2.29221
trainer/Log Pis Max                      8.57912
trainer/Log Pis Min                     -4.40079
trainer/policy/mean Mean                -0.299421
trainer/policy/mean Std                  0.784689
trainer/policy/mean Max                  0.996164
trainer/policy/mean Min                 -0.996652
trainer/policy/normal/std Mean           0.643394
trainer/policy/normal/std Std            0.0949231
trainer/policy/normal/std Max            0.880075
trainer/policy/normal/std Min            0.36326
trainer/policy/normal/log_std Mean      -0.45199
trainer/policy/normal/log_std Std        0.148868
trainer/policy/normal/log_std Max       -0.127748
trainer/policy/normal/log_std Min       -1.01264
trainer/Alpha                            0.0380345
trainer/Alpha Loss                      -0.0790129
exploration/num steps total         153000
exploration/num paths total            765
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.888258
exploration/Rewards Std                  0.218942
exploration/Rewards Max                 -0.623615
exploration/Rewards Min                 -1.53998
exploration/Returns Mean              -177.652
exploration/Returns Std                 14.0666
exploration/Returns Max               -161.939
exploration/Returns Min               -196.607
exploration/Actions Mean                -0.399536
exploration/Actions Std                  0.653503
exploration/Actions Max                  0.995826
exploration/Actions Min                 -0.999791
exploration/Num Paths                    5
exploration/Average Returns           -177.652
evaluation/num steps total          733248
evaluation/num paths total            3648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.950374
evaluation/Rewards Std                   0.215425
evaluation/Rewards Max                  -0.579893
evaluation/Rewards Min                  -1.85901
evaluation/Returns Mean               -191.025
evaluation/Returns Std                  24.9891
evaluation/Returns Max                -156.357
evaluation/Returns Min                -249.521
evaluation/Actions Mean                 -0.293804
evaluation/Actions Std                   0.7079
evaluation/Actions Max                   0.999938
evaluation/Actions Min                  -0.998955
evaluation/Num Paths                    24
evaluation/Average Returns            -191.025
time/data storing (s)                    0.0139884
time/evaluation sampling (s)           495.437
time/exploration sampling (s)          108.811
time/logging (s)                         0.0838432
time/sac training (s)                    9.56788
time/saving (s)                          0.0593571
time/training (s)                        0.000114399
time/epoch (s)                         613.973
time/total (s)                       97160.4
Epoch                                  151
----------------------------------  ----------------
2020-11-02 13:01:39.201763 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 152 finished
----------------------------------  ----------------
replay_buffer/size                  154000
trainer/num train calls             153000
trainer/QF1 Loss                        33.9196
trainer/QF2 Loss                        38.9827
trainer/Policy Loss                    163.25
trainer/Q1 Predictions Mean           -162.394
trainer/Q1 Predictions Std              42.3918
trainer/Q1 Predictions Max              69.8328
trainer/Q1 Predictions Min            -228.545
trainer/Q2 Predictions Mean           -162.117
trainer/Q2 Predictions Std              42.6553
trainer/Q2 Predictions Max              67.4203
trainer/Q2 Predictions Min            -227.523
trainer/Q Targets Mean                -163.512
trainer/Q Targets Std                   42.7901
trainer/Q Targets Max                   57.8723
trainer/Q Targets Min                 -230.89
trainer/Log Pis Mean                     1.89299
trainer/Log Pis Std                      2.12905
trainer/Log Pis Max                      8.43537
trainer/Log Pis Min                     -3.59623
trainer/policy/mean Mean                -0.384245
trainer/policy/mean Std                  0.727381
trainer/policy/mean Max                  0.998609
trainer/policy/mean Min                 -0.994218
trainer/policy/normal/std Mean           0.652043
trainer/policy/normal/std Std            0.103886
trainer/policy/normal/std Max            0.91116
trainer/policy/normal/std Min            0.424963
trainer/policy/normal/log_std Mean      -0.440243
trainer/policy/normal/log_std Std        0.15862
trainer/policy/normal/log_std Max       -0.0930372
trainer/policy/normal/log_std Min       -0.855754
trainer/Alpha                            0.0375917
trainer/Alpha Loss                      -0.35111
exploration/num steps total         154000
exploration/num paths total            770
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.964921
exploration/Rewards Std                  0.21716
exploration/Rewards Max                 -0.589151
exploration/Rewards Min                 -1.824
exploration/Returns Mean              -192.984
exploration/Returns Std                 23.4081
exploration/Returns Max               -166.796
exploration/Returns Min               -224.906
exploration/Actions Mean                -0.313786
exploration/Actions Std                  0.650398
exploration/Actions Max                  0.995725
exploration/Actions Min                 -0.999156
exploration/Num Paths                    5
exploration/Average Returns           -192.984
evaluation/num steps total          738072
evaluation/num paths total            3672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.960445
evaluation/Rewards Std                   0.229776
evaluation/Rewards Max                  -0.590844
evaluation/Rewards Min                  -2.106
evaluation/Returns Mean               -193.05
evaluation/Returns Std                  33.574
evaluation/Returns Max                -150.975
evaluation/Returns Min                -317.297
evaluation/Actions Mean                 -0.419537
evaluation/Actions Std                   0.618709
evaluation/Actions Max                   0.967007
evaluation/Actions Min                  -0.996528
evaluation/Num Paths                    24
evaluation/Average Returns            -193.05
time/data storing (s)                    0.0111886
time/evaluation sampling (s)           469.761
time/exploration sampling (s)          124.712
time/logging (s)                         0.0962377
time/sac training (s)                   14.2772
time/saving (s)                          0.0707904
time/training (s)                        0.000170969
time/epoch (s)                         608.929
time/total (s)                       97770.9
Epoch                                  152
----------------------------------  ----------------
2020-11-02 13:13:32.488349 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 153 finished
----------------------------------  ----------------
replay_buffer/size                  155000
trainer/num train calls             154000
trainer/QF1 Loss                        27.2238
trainer/QF2 Loss                        28.1882
trainer/Policy Loss                    159.39
trainer/Q1 Predictions Mean           -158.969
trainer/Q1 Predictions Std              49.2792
trainer/Q1 Predictions Max              91.6996
trainer/Q1 Predictions Min            -232.289
trainer/Q2 Predictions Mean           -158.428
trainer/Q2 Predictions Std              48.601
trainer/Q2 Predictions Max              80.1136
trainer/Q2 Predictions Min            -229.102
trainer/Q Targets Mean                -158.324
trainer/Q Targets Std                   48.9317
trainer/Q Targets Max                   89.07
trainer/Q Targets Min                 -230.825
trainer/Log Pis Mean                     2.34308
trainer/Log Pis Std                      2.73904
trainer/Log Pis Max                     11.3685
trainer/Log Pis Min                     -5.3086
trainer/policy/mean Mean                -0.514042
trainer/policy/mean Std                  0.666315
trainer/policy/mean Max                  0.999957
trainer/policy/mean Min                 -0.999635
trainer/policy/normal/std Mean           0.632019
trainer/policy/normal/std Std            0.0946444
trainer/policy/normal/std Max            1.23001
trainer/policy/normal/std Min            0.268813
trainer/policy/normal/log_std Mean      -0.470132
trainer/policy/normal/log_std Std        0.151775
trainer/policy/normal/log_std Max        0.207019
trainer/policy/normal/log_std Min       -1.31374
trainer/Alpha                            0.0365444
trainer/Alpha Loss                       1.13533
exploration/num steps total         155000
exploration/num paths total            775
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.993096
exploration/Rewards Std                  0.182306
exploration/Rewards Max                 -0.644835
exploration/Rewards Min                 -1.55731
exploration/Returns Mean              -198.619
exploration/Returns Std                 18.4165
exploration/Returns Max               -171.12
exploration/Returns Min               -228.16
exploration/Actions Mean                -0.423677
exploration/Actions Std                  0.633904
exploration/Actions Max                  0.990331
exploration/Actions Min                 -0.999255
exploration/Num Paths                    5
exploration/Average Returns           -198.619
evaluation/num steps total          742896
evaluation/num paths total            3696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.933459
evaluation/Rewards Std                   0.195118
evaluation/Rewards Max                  -0.539663
evaluation/Rewards Min                  -1.67296
evaluation/Returns Mean               -187.625
evaluation/Returns Std                  20.4389
evaluation/Returns Max                -160.845
evaluation/Returns Min                -238.69
evaluation/Actions Mean                 -0.349305
evaluation/Actions Std                   0.624055
evaluation/Actions Max                   0.999946
evaluation/Actions Min                  -0.996684
evaluation/Num Paths                    24
evaluation/Average Returns            -187.625
time/data storing (s)                    0.014402
time/evaluation sampling (s)           561.148
time/exploration sampling (s)          136.623
time/logging (s)                         0.0401943
time/sac training (s)                   13.5104
time/saving (s)                          0.0437723
time/training (s)                        0.000122905
time/epoch (s)                         711.38
time/total (s)                       98484.1
Epoch                                  153
----------------------------------  ----------------
2020-11-02 13:23:40.350300 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 154 finished
----------------------------------  ----------------
replay_buffer/size                  156000
trainer/num train calls             155000
trainer/QF1 Loss                        22.7605
trainer/QF2 Loss                        21.966
trainer/Policy Loss                    160.594
trainer/Q1 Predictions Mean           -159.941
trainer/Q1 Predictions Std              43.2768
trainer/Q1 Predictions Max             -38.8784
trainer/Q1 Predictions Min            -235.915
trainer/Q2 Predictions Mean           -159.675
trainer/Q2 Predictions Std              42.9542
trainer/Q2 Predictions Max             -34.7262
trainer/Q2 Predictions Min            -233.129
trainer/Q Targets Mean                -160.635
trainer/Q Targets Std                   43.1553
trainer/Q Targets Max                  -42.5999
trainer/Q Targets Min                 -236.442
trainer/Log Pis Mean                     1.8457
trainer/Log Pis Std                      2.08894
trainer/Log Pis Max                      8.41787
trainer/Log Pis Min                     -5.03796
trainer/policy/mean Mean                -0.343101
trainer/policy/mean Std                  0.740046
trainer/policy/mean Max                  0.999614
trainer/policy/mean Min                 -0.996235
trainer/policy/normal/std Mean           0.646424
trainer/policy/normal/std Std            0.0925636
trainer/policy/normal/std Max            0.865979
trainer/policy/normal/std Min            0.309377
trainer/policy/normal/log_std Mean      -0.446728
trainer/policy/normal/log_std Std        0.145426
trainer/policy/normal/log_std Max       -0.143895
trainer/policy/normal/log_std Min       -1.17319
trainer/Alpha                            0.0386166
trainer/Alpha Loss                      -0.502109
exploration/num steps total         156000
exploration/num paths total            780
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.88908
exploration/Rewards Std                  0.182502
exploration/Rewards Max                 -0.558588
exploration/Rewards Min                 -1.41488
exploration/Returns Mean              -177.816
exploration/Returns Std                 14.8652
exploration/Returns Max               -157.725
exploration/Returns Min               -199.988
exploration/Actions Mean                -0.225097
exploration/Actions Std                  0.729078
exploration/Actions Max                  0.997918
exploration/Actions Min                 -0.999526
exploration/Num Paths                    5
exploration/Average Returns           -177.816
evaluation/num steps total          747720
evaluation/num paths total            3720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.966266
evaluation/Rewards Std                   0.235282
evaluation/Rewards Max                  -0.577943
evaluation/Rewards Min                  -2.00286
evaluation/Returns Mean               -194.219
evaluation/Returns Std                  31.175
evaluation/Returns Max                -153.576
evaluation/Returns Min                -292.956
evaluation/Actions Mean                 -0.288014
evaluation/Actions Std                   0.718764
evaluation/Actions Max                   0.998921
evaluation/Actions Min                  -0.999743
evaluation/Num Paths                    24
evaluation/Average Returns            -194.219
time/data storing (s)                    0.0122835
time/evaluation sampling (s)           473.952
time/exploration sampling (s)          121.905
time/logging (s)                         0.061631
time/sac training (s)                   10.2064
time/saving (s)                          0.0549868
time/training (s)                        0.000112783
time/epoch (s)                         606.193
time/total (s)                       99091.9
Epoch                                  154
----------------------------------  ----------------
2020-11-02 13:34:53.523405 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 155 finished
----------------------------------  ----------------
replay_buffer/size                  157000
trainer/num train calls             156000
trainer/QF1 Loss                        67.1345
trainer/QF2 Loss                        64.0117
trainer/Policy Loss                    160.231
trainer/Q1 Predictions Mean           -160.024
trainer/Q1 Predictions Std              42.8611
trainer/Q1 Predictions Max              82.9124
trainer/Q1 Predictions Min            -231.151
trainer/Q2 Predictions Mean           -159.04
trainer/Q2 Predictions Std              42.7846
trainer/Q2 Predictions Max              85.303
trainer/Q2 Predictions Min            -229.817
trainer/Q Targets Mean                -160.286
trainer/Q Targets Std                   44.8921
trainer/Q Targets Max                   92.048
trainer/Q Targets Min                 -231.807
trainer/Log Pis Mean                     2.09665
trainer/Log Pis Std                      2.33262
trainer/Log Pis Max                      9.13352
trainer/Log Pis Min                     -7.46348
trainer/policy/mean Mean                -0.305641
trainer/policy/mean Std                  0.781293
trainer/policy/mean Max                  0.999668
trainer/policy/mean Min                 -0.994147
trainer/policy/normal/std Mean           0.631611
trainer/policy/normal/std Std            0.0836703
trainer/policy/normal/std Max            0.930438
trainer/policy/normal/std Min            0.35862
trainer/policy/normal/log_std Mean      -0.468441
trainer/policy/normal/log_std Std        0.134965
trainer/policy/normal/log_std Max       -0.0720994
trainer/policy/normal/log_std Min       -1.02549
trainer/Alpha                            0.0362849
trainer/Alpha Loss                       0.32051
exploration/num steps total         157000
exploration/num paths total            785
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.891353
exploration/Rewards Std                  0.19385
exploration/Rewards Max                 -0.594023
exploration/Rewards Min                 -1.60705
exploration/Returns Mean              -178.271
exploration/Returns Std                 18.804
exploration/Returns Max               -163.149
exploration/Returns Min               -214.216
exploration/Actions Mean                -0.289739
exploration/Actions Std                  0.708952
exploration/Actions Max                  0.999712
exploration/Actions Min                 -0.998787
exploration/Num Paths                    5
exploration/Average Returns           -178.271
evaluation/num steps total          752544
evaluation/num paths total            3744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.94301
evaluation/Rewards Std                   0.213221
evaluation/Rewards Max                  -0.576388
evaluation/Rewards Min                  -1.94999
evaluation/Returns Mean               -189.545
evaluation/Returns Std                  26.8303
evaluation/Returns Max                -154.45
evaluation/Returns Min                -267.316
evaluation/Actions Mean                 -0.327282
evaluation/Actions Std                   0.682346
evaluation/Actions Max                   0.998567
evaluation/Actions Min                  -0.99964
evaluation/Num Paths                    24
evaluation/Average Returns            -189.545
time/data storing (s)                    0.00851546
time/evaluation sampling (s)           532.157
time/exploration sampling (s)          129.221
time/logging (s)                         0.0816026
time/sac training (s)                   10.1313
time/saving (s)                          0.0584561
time/training (s)                        0.000133794
time/epoch (s)                         671.658
time/total (s)                       99765.1
Epoch                                  155
----------------------------------  ----------------
2020-11-02 13:47:39.170935 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 156 finished
----------------------------------  ----------------
replay_buffer/size                  158000
trainer/num train calls             157000
trainer/QF1 Loss                       280.902
trainer/QF2 Loss                       274.095
trainer/Policy Loss                    156.769
trainer/Q1 Predictions Mean           -155.867
trainer/Q1 Predictions Std              46.1641
trainer/Q1 Predictions Max              93.0505
trainer/Q1 Predictions Min            -229.544
trainer/Q2 Predictions Mean           -156.189
trainer/Q2 Predictions Std              46.2653
trainer/Q2 Predictions Max              86.4039
trainer/Q2 Predictions Min            -230.273
trainer/Q Targets Mean                -154.465
trainer/Q Targets Std                   49.3335
trainer/Q Targets Max                   79.1357
trainer/Q Targets Min                 -227.975
trainer/Log Pis Mean                     2.06508
trainer/Log Pis Std                      2.20171
trainer/Log Pis Max                     10.4907
trainer/Log Pis Min                     -4.69065
trainer/policy/mean Mean                -0.336433
trainer/policy/mean Std                  0.750273
trainer/policy/mean Max                  0.997404
trainer/policy/mean Min                 -0.996014
trainer/policy/normal/std Mean           0.634972
trainer/policy/normal/std Std            0.0941055
trainer/policy/normal/std Max            0.870445
trainer/policy/normal/std Min            0.354569
trainer/policy/normal/log_std Mean      -0.465184
trainer/policy/normal/log_std Std        0.148773
trainer/policy/normal/log_std Max       -0.13875
trainer/policy/normal/log_std Min       -1.03685
trainer/Alpha                            0.0374202
trainer/Alpha Loss                       0.213814
exploration/num steps total         158000
exploration/num paths total            790
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.802777
exploration/Rewards Std                  0.181351
exploration/Rewards Max                 -0.49042
exploration/Rewards Min                 -1.28831
exploration/Returns Mean              -160.555
exploration/Returns Std                  9.01204
exploration/Returns Max               -148.258
exploration/Returns Min               -174.042
exploration/Actions Mean                -0.427358
exploration/Actions Std                  0.652001
exploration/Actions Max                  0.993582
exploration/Actions Min                 -0.999724
exploration/Num Paths                    5
exploration/Average Returns           -160.555
evaluation/num steps total          757368
evaluation/num paths total            3768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.947445
evaluation/Rewards Std                   0.207715
evaluation/Rewards Max                  -0.590069
evaluation/Rewards Min                  -1.68865
evaluation/Returns Mean               -190.436
evaluation/Returns Std                  19.4829
evaluation/Returns Max                -156.589
evaluation/Returns Min                -229.53
evaluation/Actions Mean                 -0.366141
evaluation/Actions Std                   0.669368
evaluation/Actions Max                   0.999787
evaluation/Actions Min                  -0.999997
evaluation/Num Paths                    24
evaluation/Average Returns            -190.436
time/data storing (s)                    0.0174569
time/evaluation sampling (s)           605.013
time/exploration sampling (s)          145.421
time/logging (s)                         0.0580726
time/sac training (s)                   13.6825
time/saving (s)                          0.0576851
time/training (s)                        0.000140849
time/epoch (s)                         764.25
time/total (s)                      100531
Epoch                                  156
----------------------------------  ----------------
2020-11-02 14:02:49.968588 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 157 finished
----------------------------------  ----------------
replay_buffer/size                  159000
trainer/num train calls             158000
trainer/QF1 Loss                       149.155
trainer/QF2 Loss                       151.537
trainer/Policy Loss                    162.275
trainer/Q1 Predictions Mean           -161.313
trainer/Q1 Predictions Std              45.1259
trainer/Q1 Predictions Max             -11.9858
trainer/Q1 Predictions Min            -234.904
trainer/Q2 Predictions Mean           -161.696
trainer/Q2 Predictions Std              45.1576
trainer/Q2 Predictions Max             -13.067
trainer/Q2 Predictions Min            -236.513
trainer/Q Targets Mean                -161.394
trainer/Q Targets Std                   47.6595
trainer/Q Targets Max                   -0.885628
trainer/Q Targets Min                 -233.831
trainer/Log Pis Mean                     1.38611
trainer/Log Pis Std                      2.12745
trainer/Log Pis Max                     10.1645
trainer/Log Pis Min                     -5.85555
trainer/policy/mean Mean                -0.296886
trainer/policy/mean Std                  0.75901
trainer/policy/mean Max                  0.999817
trainer/policy/mean Min                 -0.997907
trainer/policy/normal/std Mean           0.662583
trainer/policy/normal/std Std            0.0947289
trainer/policy/normal/std Max            0.936193
trainer/policy/normal/std Min            0.371898
trainer/policy/normal/log_std Mean      -0.421905
trainer/policy/normal/log_std Std        0.144102
trainer/policy/normal/log_std Max       -0.0659338
trainer/policy/normal/log_std Min       -0.989135
trainer/Alpha                            0.0377419
trainer/Alpha Loss                      -2.0117
exploration/num steps total         159000
exploration/num paths total            795
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.925918
exploration/Rewards Std                  0.185131
exploration/Rewards Max                 -0.583659
exploration/Rewards Min                 -1.60471
exploration/Returns Mean              -185.184
exploration/Returns Std                 16.1217
exploration/Returns Max               -168.72
exploration/Returns Min               -205.815
exploration/Actions Mean                -0.220438
exploration/Actions Std                  0.708122
exploration/Actions Max                  0.999967
exploration/Actions Min                 -0.99996
exploration/Num Paths                    5
exploration/Average Returns           -185.184
evaluation/num steps total          762192
evaluation/num paths total            3792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.950936
evaluation/Rewards Std                   0.228495
evaluation/Rewards Max                  -0.551584
evaluation/Rewards Min                  -1.93867
evaluation/Returns Mean               -191.138
evaluation/Returns Std                  30.1854
evaluation/Returns Max                -147.457
evaluation/Returns Min                -301.688
evaluation/Actions Mean                 -0.345719
evaluation/Actions Std                   0.64001
evaluation/Actions Max                   0.999937
evaluation/Actions Min                  -0.999983
evaluation/Num Paths                    24
evaluation/Average Returns            -191.138
time/data storing (s)                    0.0205843
time/evaluation sampling (s)           733.14
time/exploration sampling (s)          161.913
time/logging (s)                         0.0488551
time/sac training (s)                   14.1599
time/saving (s)                          0.0583233
time/training (s)                        0.000177834
time/epoch (s)                         909.341
time/total (s)                      101441
Epoch                                  157
----------------------------------  ----------------
2020-11-02 14:17:18.277595 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 158 finished
----------------------------------  ----------------
replay_buffer/size                  160000
trainer/num train calls             159000
trainer/QF1 Loss                        32.2508
trainer/QF2 Loss                        31.6348
trainer/Policy Loss                    157.657
trainer/Q1 Predictions Mean           -156.952
trainer/Q1 Predictions Std              44.6055
trainer/Q1 Predictions Max              64.6606
trainer/Q1 Predictions Min            -230.473
trainer/Q2 Predictions Mean           -156.95
trainer/Q2 Predictions Std              44.3972
trainer/Q2 Predictions Max              64.7137
trainer/Q2 Predictions Min            -233.467
trainer/Q Targets Mean                -158.318
trainer/Q Targets Std                   45.187
trainer/Q Targets Max                   66.864
trainer/Q Targets Min                 -235.589
trainer/Log Pis Mean                     2.2492
trainer/Log Pis Std                      2.5864
trainer/Log Pis Max                      8.96638
trainer/Log Pis Min                     -4.80274
trainer/policy/mean Mean                -0.429404
trainer/policy/mean Std                  0.726715
trainer/policy/mean Max                  0.998235
trainer/policy/mean Min                 -0.999393
trainer/policy/normal/std Mean           0.645158
trainer/policy/normal/std Std            0.0970836
trainer/policy/normal/std Max            0.911997
trainer/policy/normal/std Min            0.377346
trainer/policy/normal/log_std Mean      -0.449787
trainer/policy/normal/log_std Std        0.152865
trainer/policy/normal/log_std Max       -0.0921182
trainer/policy/normal/log_std Min       -0.974592
trainer/Alpha                            0.0347084
trainer/Alpha Loss                       0.837494
exploration/num steps total         160000
exploration/num paths total            800
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.864558
exploration/Rewards Std                  0.174138
exploration/Rewards Max                 -0.528121
exploration/Rewards Min                 -1.46794
exploration/Returns Mean              -172.912
exploration/Returns Std                 13.4938
exploration/Returns Max               -152.928
exploration/Returns Min               -187.707
exploration/Actions Mean                -0.343678
exploration/Actions Std                  0.647928
exploration/Actions Max                  0.996091
exploration/Actions Min                 -0.999772
exploration/Num Paths                    5
exploration/Average Returns           -172.912
evaluation/num steps total          767016
evaluation/num paths total            3816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.962394
evaluation/Rewards Std                   0.23299
evaluation/Rewards Max                  -0.547111
evaluation/Rewards Min                  -1.86728
evaluation/Returns Mean               -193.441
evaluation/Returns Std                  31.4421
evaluation/Returns Max                -154.012
evaluation/Returns Min                -321.049
evaluation/Actions Mean                 -0.462273
evaluation/Actions Std                   0.599379
evaluation/Actions Max                   0.996985
evaluation/Actions Min                  -0.999747
evaluation/Num Paths                    24
evaluation/Average Returns            -193.441
time/data storing (s)                    0.0113298
time/evaluation sampling (s)           739.558
time/exploration sampling (s)          115.003
time/logging (s)                         0.0749187
time/sac training (s)                   11.835
time/saving (s)                          0.092101
time/training (s)                        0.000147056
time/epoch (s)                         866.575
time/total (s)                      102310
Epoch                                  158
----------------------------------  ----------------
2020-11-02 14:27:05.572518 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 159 finished
----------------------------------  ----------------
replay_buffer/size                  161000
trainer/num train calls             160000
trainer/QF1 Loss                        30.4174
trainer/QF2 Loss                        28.2607
trainer/Policy Loss                    158.177
trainer/Q1 Predictions Mean           -157.067
trainer/Q1 Predictions Std              45.8482
trainer/Q1 Predictions Max               2.61345
trainer/Q1 Predictions Min            -229.571
trainer/Q2 Predictions Mean           -157.701
trainer/Q2 Predictions Std              45.7719
trainer/Q2 Predictions Max              -1.71829
trainer/Q2 Predictions Min            -229.012
trainer/Q Targets Mean                -157.233
trainer/Q Targets Std                   45.3611
trainer/Q Targets Max                   -1.64399
trainer/Q Targets Min                 -227.577
trainer/Log Pis Mean                     2.03817
trainer/Log Pis Std                      2.11323
trainer/Log Pis Max                      6.50229
trainer/Log Pis Min                     -4.83449
trainer/policy/mean Mean                -0.281167
trainer/policy/mean Std                  0.789938
trainer/policy/mean Max                  0.994499
trainer/policy/mean Min                 -0.996071
trainer/policy/normal/std Mean           0.608388
trainer/policy/normal/std Std            0.0739094
trainer/policy/normal/std Max            0.886615
trainer/policy/normal/std Min            0.333404
trainer/policy/normal/log_std Mean      -0.504634
trainer/policy/normal/log_std Std        0.125827
trainer/policy/normal/log_std Max       -0.120344
trainer/policy/normal/log_std Min       -1.0984
trainer/Alpha                            0.0335691
trainer/Alpha Loss                       0.12955
exploration/num steps total         161000
exploration/num paths total            805
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.878713
exploration/Rewards Std                  0.176064
exploration/Rewards Max                 -0.575119
exploration/Rewards Min                 -1.46607
exploration/Returns Mean              -175.743
exploration/Returns Std                 13.5137
exploration/Returns Max               -153.19
exploration/Returns Min               -194.431
exploration/Actions Mean                -0.37316
exploration/Actions Std                  0.729809
exploration/Actions Max                  0.997327
exploration/Actions Min                 -0.999902
exploration/Num Paths                    5
exploration/Average Returns           -175.743
evaluation/num steps total          771840
evaluation/num paths total            3840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.924243
evaluation/Rewards Std                   0.220888
evaluation/Rewards Max                  -0.57791
evaluation/Rewards Min                  -1.79116
evaluation/Returns Mean               -185.773
evaluation/Returns Std                  21.8119
evaluation/Returns Max                -154.539
evaluation/Returns Min                -250.327
evaluation/Actions Mean                 -0.36586
evaluation/Actions Std                   0.644345
evaluation/Actions Max                   0.997592
evaluation/Actions Min                  -0.997949
evaluation/Num Paths                    24
evaluation/Average Returns            -185.773
time/data storing (s)                    0.0154115
time/evaluation sampling (s)           455.603
time/exploration sampling (s)          119.271
time/logging (s)                         0.0531476
time/sac training (s)                   10.7278
time/saving (s)                          0.0488693
time/training (s)                        0.000126395
time/epoch (s)                         585.72
time/total (s)                      102897
Epoch                                  159
----------------------------------  ----------------
2020-11-02 14:38:05.867164 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 160 finished
----------------------------------  ----------------
replay_buffer/size                  162000
trainer/num train calls             161000
trainer/QF1 Loss                        76.7285
trainer/QF2 Loss                        71.7388
trainer/Policy Loss                    162.329
trainer/Q1 Predictions Mean           -161.781
trainer/Q1 Predictions Std              45.1072
trainer/Q1 Predictions Max              48.2156
trainer/Q1 Predictions Min            -230.183
trainer/Q2 Predictions Mean           -161.318
trainer/Q2 Predictions Std              44.8538
trainer/Q2 Predictions Max              35.8143
trainer/Q2 Predictions Min            -229.874
trainer/Q Targets Mean                -161.329
trainer/Q Targets Std                   45.4207
trainer/Q Targets Max                   44.837
trainer/Q Targets Min                 -230.036
trainer/Log Pis Mean                     2.06836
trainer/Log Pis Std                      2.07697
trainer/Log Pis Max                      9.64152
trainer/Log Pis Min                     -3.1352
trainer/policy/mean Mean                -0.3077
trainer/policy/mean Std                  0.77276
trainer/policy/mean Max                  0.999458
trainer/policy/mean Min                 -0.998663
trainer/policy/normal/std Mean           0.617528
trainer/policy/normal/std Std            0.0847114
trainer/policy/normal/std Max            0.843426
trainer/policy/normal/std Min            0.354417
trainer/policy/normal/log_std Mean      -0.491577
trainer/policy/normal/log_std Std        0.138963
trainer/policy/normal/log_std Max       -0.170284
trainer/policy/normal/log_std Min       -1.03728
trainer/Alpha                            0.0360746
trainer/Alpha Loss                       0.227091
exploration/num steps total         162000
exploration/num paths total            810
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.941444
exploration/Rewards Std                  0.197049
exploration/Rewards Max                 -0.654352
exploration/Rewards Min                 -1.4913
exploration/Returns Mean              -188.289
exploration/Returns Std                 19.3167
exploration/Returns Max               -165.976
exploration/Returns Min               -216.044
exploration/Actions Mean                -0.273218
exploration/Actions Std                  0.699399
exploration/Actions Max                  0.999737
exploration/Actions Min                 -0.999952
exploration/Num Paths                    5
exploration/Average Returns           -188.289
evaluation/num steps total          776664
evaluation/num paths total            3864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.940283
evaluation/Rewards Std                   0.234671
evaluation/Rewards Max                  -0.563943
evaluation/Rewards Min                  -1.76298
evaluation/Returns Mean               -188.997
evaluation/Returns Std                  27.4647
evaluation/Returns Max                -157.251
evaluation/Returns Min                -269.033
evaluation/Actions Mean                 -0.367854
evaluation/Actions Std                   0.659795
evaluation/Actions Max                   0.99996
evaluation/Actions Min                  -0.999175
evaluation/Num Paths                    24
evaluation/Average Returns            -188.997
time/data storing (s)                    0.0119404
time/evaluation sampling (s)           520.592
time/exploration sampling (s)          127.558
time/logging (s)                         0.0458396
time/sac training (s)                   10.7732
time/saving (s)                          0.0522918
time/training (s)                        0.000129135
time/epoch (s)                         659.033
time/total (s)                      103557
Epoch                                  160
----------------------------------  ----------------
2020-11-02 14:48:34.925264 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 161 finished
----------------------------------  ----------------
replay_buffer/size                  163000
trainer/num train calls             162000
trainer/QF1 Loss                       189.07
trainer/QF2 Loss                       197.673
trainer/Policy Loss                    155.745
trainer/Q1 Predictions Mean           -154.515
trainer/Q1 Predictions Std              43.6771
trainer/Q1 Predictions Max             -30.606
trainer/Q1 Predictions Min            -228.788
trainer/Q2 Predictions Mean           -155.102
trainer/Q2 Predictions Std              43.39
trainer/Q2 Predictions Max             -36.1542
trainer/Q2 Predictions Min            -230.064
trainer/Q Targets Mean                -153.533
trainer/Q Targets Std                   46.2059
trainer/Q Targets Max                   -0.689295
trainer/Q Targets Min                 -228.771
trainer/Log Pis Mean                     2.08158
trainer/Log Pis Std                      2.31261
trainer/Log Pis Max                      9.57043
trainer/Log Pis Min                     -5.40859
trainer/policy/mean Mean                -0.401348
trainer/policy/mean Std                  0.739315
trainer/policy/mean Max                  0.999538
trainer/policy/mean Min                 -0.998451
trainer/policy/normal/std Mean           0.631614
trainer/policy/normal/std Std            0.0887479
trainer/policy/normal/std Max            0.919836
trainer/policy/normal/std Min            0.415926
trainer/policy/normal/log_std Mean      -0.469179
trainer/policy/normal/log_std Std        0.138875
trainer/policy/normal/log_std Max       -0.0835602
trainer/policy/normal/log_std Min       -0.877248
trainer/Alpha                            0.0362048
trainer/Alpha Loss                       0.270729
exploration/num steps total         163000
exploration/num paths total            815
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.98833
exploration/Rewards Std                  0.209648
exploration/Rewards Max                 -0.684418
exploration/Rewards Min                 -1.58063
exploration/Returns Mean              -197.666
exploration/Returns Std                 26.9781
exploration/Returns Max               -171.084
exploration/Returns Min               -249.39
exploration/Actions Mean                -0.253475
exploration/Actions Std                  0.689558
exploration/Actions Max                  0.999311
exploration/Actions Min                 -0.999184
exploration/Num Paths                    5
exploration/Average Returns           -197.666
evaluation/num steps total          781488
evaluation/num paths total            3888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.91175
evaluation/Rewards Std                   0.205197
evaluation/Rewards Max                  -0.5882
evaluation/Rewards Min                  -1.80766
evaluation/Returns Mean               -183.262
evaluation/Returns Std                  23.2457
evaluation/Returns Max                -152.607
evaluation/Returns Min                -247.793
evaluation/Actions Mean                 -0.307416
evaluation/Actions Std                   0.680771
evaluation/Actions Max                   0.999704
evaluation/Actions Min                  -0.999501
evaluation/Num Paths                    24
evaluation/Average Returns            -183.262
time/data storing (s)                    0.0101297
time/evaluation sampling (s)           488.046
time/exploration sampling (s)          130.028
time/logging (s)                         0.0199115
time/sac training (s)                   10.1889
time/saving (s)                          0.0263068
time/training (s)                        0.000126175
time/epoch (s)                         628.319
time/total (s)                      104186
Epoch                                  161
----------------------------------  ----------------
2020-11-02 14:59:38.775973 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 162 finished
----------------------------------  ----------------
replay_buffer/size                  164000
trainer/num train calls             163000
trainer/QF1 Loss                       101.606
trainer/QF2 Loss                        96.6867
trainer/Policy Loss                    161.454
trainer/Q1 Predictions Mean           -160.939
trainer/Q1 Predictions Std              45.1416
trainer/Q1 Predictions Max              72.6793
trainer/Q1 Predictions Min            -231.48
trainer/Q2 Predictions Mean           -160.671
trainer/Q2 Predictions Std              45.0571
trainer/Q2 Predictions Max              68.6235
trainer/Q2 Predictions Min            -230.994
trainer/Q Targets Mean                -161.205
trainer/Q Targets Std                   45.5519
trainer/Q Targets Max                   56.8949
trainer/Q Targets Min                 -229.397
trainer/Log Pis Mean                     2.12863
trainer/Log Pis Std                      2.40475
trainer/Log Pis Max                     10.3416
trainer/Log Pis Min                     -5.28553
trainer/policy/mean Mean                -0.177609
trainer/policy/mean Std                  0.824505
trainer/policy/mean Max                  0.999594
trainer/policy/mean Min                 -0.998702
trainer/policy/normal/std Mean           0.620366
trainer/policy/normal/std Std            0.0759011
trainer/policy/normal/std Max            0.956687
trainer/policy/normal/std Min            0.345219
trainer/policy/normal/log_std Mean      -0.485004
trainer/policy/normal/log_std Std        0.123603
trainer/policy/normal/log_std Max       -0.044279
trainer/policy/normal/log_std Min       -1.06358
trainer/Alpha                            0.0366231
trainer/Alpha Loss                       0.425385
exploration/num steps total         164000
exploration/num paths total            820
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.932887
exploration/Rewards Std                  0.169721
exploration/Rewards Max                 -0.587495
exploration/Rewards Min                 -1.48746
exploration/Returns Mean              -186.577
exploration/Returns Std                 16.8195
exploration/Returns Max               -158.491
exploration/Returns Min               -206.008
exploration/Actions Mean                -0.118191
exploration/Actions Std                  0.75654
exploration/Actions Max                  0.999995
exploration/Actions Min                 -0.999454
exploration/Num Paths                    5
exploration/Average Returns           -186.577
evaluation/num steps total          786312
evaluation/num paths total            3912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.974281
evaluation/Rewards Std                   0.23486
evaluation/Rewards Max                  -0.549337
evaluation/Rewards Min                  -1.79246
evaluation/Returns Mean               -195.83
evaluation/Returns Std                  27.8068
evaluation/Returns Max                -162.108
evaluation/Returns Min                -258.219
evaluation/Actions Mean                 -0.330845
evaluation/Actions Std                   0.701247
evaluation/Actions Max                   0.999431
evaluation/Actions Min                  -0.999542
evaluation/Num Paths                    24
evaluation/Average Returns            -195.83
time/data storing (s)                    0.0102269
time/evaluation sampling (s)           506.305
time/exploration sampling (s)          145.234
time/logging (s)                         0.0333281
time/sac training (s)                   10.7851
time/saving (s)                          0.0429095
time/training (s)                        0.000334028
time/epoch (s)                         662.412
time/total (s)                      104850
Epoch                                  162
----------------------------------  ----------------
2020-11-02 15:08:29.702028 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 163 finished
----------------------------------  ---------------
replay_buffer/size                  165000
trainer/num train calls             164000
trainer/QF1 Loss                        56.1444
trainer/QF2 Loss                        58.8838
trainer/Policy Loss                    156.802
trainer/Q1 Predictions Mean           -155.977
trainer/Q1 Predictions Std              43.8134
trainer/Q1 Predictions Max              71.1657
trainer/Q1 Predictions Min            -231.801
trainer/Q2 Predictions Mean           -156.082
trainer/Q2 Predictions Std              43.4006
trainer/Q2 Predictions Max              65.2533
trainer/Q2 Predictions Min            -231.366
trainer/Q Targets Mean                -155.413
trainer/Q Targets Std                   44.1137
trainer/Q Targets Max                   52.2574
trainer/Q Targets Min                 -228.782
trainer/Log Pis Mean                     1.84688
trainer/Log Pis Std                      2.15501
trainer/Log Pis Max                     10.1201
trainer/Log Pis Min                     -3.87568
trainer/policy/mean Mean                -0.271134
trainer/policy/mean Std                  0.766422
trainer/policy/mean Max                  0.999856
trainer/policy/mean Min                 -0.994097
trainer/policy/normal/std Mean           0.659272
trainer/policy/normal/std Std            0.103176
trainer/policy/normal/std Max            0.911507
trainer/policy/normal/std Min            0.355476
trainer/policy/normal/log_std Mean      -0.4289
trainer/policy/normal/log_std Std        0.15719
trainer/policy/normal/log_std Max       -0.0926564
trainer/policy/normal/log_std Min       -1.0343
trainer/Alpha                            0.0344284
trainer/Alpha Loss                      -0.515857
exploration/num steps total         165000
exploration/num paths total            825
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.896439
exploration/Rewards Std                  0.172712
exploration/Rewards Max                 -0.620793
exploration/Rewards Min                 -1.44057
exploration/Returns Mean              -179.288
exploration/Returns Std                 11.4157
exploration/Returns Max               -164.769
exploration/Returns Min               -193.538
exploration/Actions Mean                -0.36376
exploration/Actions Std                  0.62041
exploration/Actions Max                  0.992281
exploration/Actions Min                 -0.999548
exploration/Num Paths                    5
exploration/Average Returns           -179.288
evaluation/num steps total          791136
evaluation/num paths total            3936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.943059
evaluation/Rewards Std                   0.206477
evaluation/Rewards Max                  -0.582214
evaluation/Rewards Min                  -1.71405
evaluation/Returns Mean               -189.555
evaluation/Returns Std                  20.8745
evaluation/Returns Max                -157.483
evaluation/Returns Min                -247.005
evaluation/Actions Mean                 -0.390232
evaluation/Actions Std                   0.633134
evaluation/Actions Max                   0.997402
evaluation/Actions Min                  -0.997064
evaluation/Num Paths                    24
evaluation/Average Returns            -189.555
time/data storing (s)                    0.00799662
time/evaluation sampling (s)           422.347
time/exploration sampling (s)           99.0439
time/logging (s)                         0.0222406
time/sac training (s)                    8.20689
time/saving (s)                          0.0433347
time/training (s)                        9.9581e-05
time/epoch (s)                         529.671
time/total (s)                      105381
Epoch                                  163
----------------------------------  ---------------
2020-11-02 15:16:12.575648 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 164 finished
----------------------------------  ----------------
replay_buffer/size                  166000
trainer/num train calls             165000
trainer/QF1 Loss                        99.6484
trainer/QF2 Loss                       115.667
trainer/Policy Loss                    163.874
trainer/Q1 Predictions Mean           -163.27
trainer/Q1 Predictions Std              45.4279
trainer/Q1 Predictions Max             114.903
trainer/Q1 Predictions Min            -229.455
trainer/Q2 Predictions Mean           -162.83
trainer/Q2 Predictions Std              45.0872
trainer/Q2 Predictions Max             112.278
trainer/Q2 Predictions Min            -229.213
trainer/Q Targets Mean                -163.056
trainer/Q Targets Std                   47.0267
trainer/Q Targets Max                  100.194
trainer/Q Targets Min                 -231.359
trainer/Log Pis Mean                     1.92947
trainer/Log Pis Std                      2.27429
trainer/Log Pis Max                     12.1121
trainer/Log Pis Min                     -4.83195
trainer/policy/mean Mean                -0.201347
trainer/policy/mean Std                  0.803896
trainer/policy/mean Max                  0.999955
trainer/policy/mean Min                 -0.995851
trainer/policy/normal/std Mean           0.62463
trainer/policy/normal/std Std            0.0895955
trainer/policy/normal/std Max            0.848279
trainer/policy/normal/std Min            0.324987
trainer/policy/normal/log_std Mean      -0.481109
trainer/policy/normal/log_std Std        0.14623
trainer/policy/normal/log_std Max       -0.164545
trainer/policy/normal/log_std Min       -1.12397
trainer/Alpha                            0.0336596
trainer/Alpha Loss                      -0.239194
exploration/num steps total         166000
exploration/num paths total            830
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.04046
exploration/Rewards Std                  0.158621
exploration/Rewards Max                 -0.657251
exploration/Rewards Min                 -1.56652
exploration/Returns Mean              -208.092
exploration/Returns Std                 14.5163
exploration/Returns Max               -189.667
exploration/Returns Min               -232.935
exploration/Actions Mean                -0.0577361
exploration/Actions Std                  0.710381
exploration/Actions Max                  0.999367
exploration/Actions Min                 -0.999431
exploration/Num Paths                    5
exploration/Average Returns           -208.092
evaluation/num steps total          795960
evaluation/num paths total            3960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.957961
evaluation/Rewards Std                   0.216693
evaluation/Rewards Max                  -0.594003
evaluation/Rewards Min                  -1.7558
evaluation/Returns Mean               -192.55
evaluation/Returns Std                  23.261
evaluation/Returns Max                -164.019
evaluation/Returns Min                -247.812
evaluation/Actions Mean                 -0.353919
evaluation/Actions Std                   0.643442
evaluation/Actions Max                   0.989514
evaluation/Actions Min                  -0.996788
evaluation/Num Paths                    24
evaluation/Average Returns            -192.55
time/data storing (s)                    0.00629758
time/evaluation sampling (s)           362.198
time/exploration sampling (s)           90.7539
time/logging (s)                         0.0175355
time/sac training (s)                    9.20618
time/saving (s)                          0.0221027
time/training (s)                        0.000112081
time/epoch (s)                         462.204
time/total (s)                      105844
Epoch                                  164
----------------------------------  ----------------
2020-11-02 15:25:14.370655 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 165 finished
----------------------------------  ----------------
replay_buffer/size                  167000
trainer/num train calls             166000
trainer/QF1 Loss                        28.7797
trainer/QF2 Loss                        35.0102
trainer/Policy Loss                    154.618
trainer/Q1 Predictions Mean           -153.922
trainer/Q1 Predictions Std              43.6693
trainer/Q1 Predictions Max             -19.5287
trainer/Q1 Predictions Min            -230.586
trainer/Q2 Predictions Mean           -153.706
trainer/Q2 Predictions Std              44.4167
trainer/Q2 Predictions Max             -10.2997
trainer/Q2 Predictions Min            -230.209
trainer/Q Targets Mean                -154.293
trainer/Q Targets Std                   43.688
trainer/Q Targets Max                   -9.91116
trainer/Q Targets Min                 -230.479
trainer/Log Pis Mean                     1.96017
trainer/Log Pis Std                      2.31766
trainer/Log Pis Max                     10.5758
trainer/Log Pis Min                     -4.43066
trainer/policy/mean Mean                -0.0151448
trainer/policy/mean Std                  0.815604
trainer/policy/mean Max                  0.9998
trainer/policy/mean Min                 -0.99845
trainer/policy/normal/std Mean           0.620342
trainer/policy/normal/std Std            0.0807901
trainer/policy/normal/std Max            0.948572
trainer/policy/normal/std Min            0.285414
trainer/policy/normal/log_std Mean      -0.486433
trainer/policy/normal/log_std Std        0.136394
trainer/policy/normal/log_std Max       -0.0527972
trainer/policy/normal/log_std Min       -1.25381
trainer/Alpha                            0.0369573
trainer/Alpha Loss                      -0.131367
exploration/num steps total         167000
exploration/num paths total            835
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.08749
exploration/Rewards Std                  0.157723
exploration/Rewards Max                 -0.821359
exploration/Rewards Min                 -1.63535
exploration/Returns Mean              -217.497
exploration/Returns Std                 21.8772
exploration/Returns Max               -186.361
exploration/Returns Min               -253.01
exploration/Actions Mean                 0.118599
exploration/Actions Std                  0.743204
exploration/Actions Max                  0.999873
exploration/Actions Min                 -0.997439
exploration/Num Paths                    5
exploration/Average Returns           -217.497
evaluation/num steps total          800784
evaluation/num paths total            3984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.00668
evaluation/Rewards Std                   0.207169
evaluation/Rewards Max                  -0.56983
evaluation/Rewards Min                  -1.68154
evaluation/Returns Mean               -202.342
evaluation/Returns Std                  26.8803
evaluation/Returns Max                -153.46
evaluation/Returns Min                -250.178
evaluation/Actions Mean                 -0.251654
evaluation/Actions Std                   0.645177
evaluation/Actions Max                   0.999299
evaluation/Actions Min                  -0.994303
evaluation/Num Paths                    24
evaluation/Average Returns            -202.342
time/data storing (s)                    0.0073059
time/evaluation sampling (s)           430.061
time/exploration sampling (s)          101.969
time/logging (s)                         0.0243384
time/sac training (s)                    8.50078
time/saving (s)                          0.0374297
time/training (s)                        9.37611e-05
time/epoch (s)                         540.6
time/total (s)                      106386
Epoch                                  165
----------------------------------  ----------------
2020-11-02 15:35:29.300415 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 166 finished
----------------------------------  ----------------
replay_buffer/size                  168000
trainer/num train calls             167000
trainer/QF1 Loss                        37.0947
trainer/QF2 Loss                        65.3229
trainer/Policy Loss                    162.189
trainer/Q1 Predictions Mean           -161.415
trainer/Q1 Predictions Std              40.4449
trainer/Q1 Predictions Max             -42.9946
trainer/Q1 Predictions Min            -233.386
trainer/Q2 Predictions Mean           -161.501
trainer/Q2 Predictions Std              40.2109
trainer/Q2 Predictions Max             -49.4377
trainer/Q2 Predictions Min            -232.29
trainer/Q Targets Mean                -161.213
trainer/Q Targets Std                   42.0443
trainer/Q Targets Max                   -1.18606
trainer/Q Targets Min                 -231.864
trainer/Log Pis Mean                     1.63458
trainer/Log Pis Std                      2.4609
trainer/Log Pis Max                     11.2443
trainer/Log Pis Min                     -7.67149
trainer/policy/mean Mean                -0.299213
trainer/policy/mean Std                  0.770349
trainer/policy/mean Max                  0.999776
trainer/policy/mean Min                 -0.995585
trainer/policy/normal/std Mean           0.648742
trainer/policy/normal/std Std            0.0876861
trainer/policy/normal/std Max            0.971515
trainer/policy/normal/std Min            0.397828
trainer/policy/normal/log_std Mean      -0.441915
trainer/policy/normal/log_std Std        0.136174
trainer/policy/normal/log_std Max       -0.0288987
trainer/policy/normal/log_std Min       -0.921736
trainer/Alpha                            0.0356797
trainer/Alpha Loss                      -1.218
exploration/num steps total         168000
exploration/num paths total            840
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.92292
exploration/Rewards Std                  0.21768
exploration/Rewards Max                 -0.563376
exploration/Rewards Min                 -1.60257
exploration/Returns Mean              -184.584
exploration/Returns Std                 32.5769
exploration/Returns Max               -152.227
exploration/Returns Min               -242.536
exploration/Actions Mean                -0.170791
exploration/Actions Std                  0.678815
exploration/Actions Max                  0.997089
exploration/Actions Min                 -0.99797
exploration/Num Paths                    5
exploration/Average Returns           -184.584
evaluation/num steps total          805608
evaluation/num paths total            4008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.954823
evaluation/Rewards Std                   0.199544
evaluation/Rewards Max                  -0.595023
evaluation/Rewards Min                  -1.72826
evaluation/Returns Mean               -191.919
evaluation/Returns Std                  23.9817
evaluation/Returns Max                -154.215
evaluation/Returns Min                -237.156
evaluation/Actions Mean                 -0.295493
evaluation/Actions Std                   0.656217
evaluation/Actions Max                   0.999956
evaluation/Actions Min                  -0.998684
evaluation/Num Paths                    24
evaluation/Average Returns            -191.919
time/data storing (s)                    0.0147247
time/evaluation sampling (s)           463.672
time/exploration sampling (s)          141.565
time/logging (s)                         0.0966578
time/sac training (s)                    8.29274
time/saving (s)                          0.135952
time/training (s)                        0.000107493
time/epoch (s)                         613.777
time/total (s)                      107001
Epoch                                  166
----------------------------------  ----------------
2020-11-02 15:45:14.467328 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 167 finished
----------------------------------  ----------------
replay_buffer/size                  169000
trainer/num train calls             168000
trainer/QF1 Loss                       233.354
trainer/QF2 Loss                       233.92
trainer/Policy Loss                    162.494
trainer/Q1 Predictions Mean           -161.777
trainer/Q1 Predictions Std              42.1165
trainer/Q1 Predictions Max             -33.7496
trainer/Q1 Predictions Min            -231.575
trainer/Q2 Predictions Mean           -161.717
trainer/Q2 Predictions Std              42.0209
trainer/Q2 Predictions Max             -25.9153
trainer/Q2 Predictions Min            -230.963
trainer/Q Targets Mean                -161.279
trainer/Q Targets Std                   45.0242
trainer/Q Targets Max                   -0.955737
trainer/Q Targets Min                 -230.545
trainer/Log Pis Mean                     1.18093
trainer/Log Pis Std                      2.12311
trainer/Log Pis Max                      9.10516
trainer/Log Pis Min                     -4.2802
trainer/policy/mean Mean                -0.22853
trainer/policy/mean Std                  0.758907
trainer/policy/mean Max                  0.997526
trainer/policy/mean Min                 -0.99164
trainer/policy/normal/std Mean           0.657693
trainer/policy/normal/std Std            0.0887118
trainer/policy/normal/std Max            0.93637
trainer/policy/normal/std Min            0.399696
trainer/policy/normal/log_std Mean      -0.428225
trainer/policy/normal/log_std Std        0.136411
trainer/policy/normal/log_std Max       -0.0657441
trainer/policy/normal/log_std Min       -0.917051
trainer/Alpha                            0.0354845
trainer/Alpha Loss                      -2.73459
exploration/num steps total         169000
exploration/num paths total            845
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.959507
exploration/Rewards Std                  0.182512
exploration/Rewards Max                 -0.617694
exploration/Rewards Min                 -1.58302
exploration/Returns Mean              -191.901
exploration/Returns Std                 20.1857
exploration/Returns Max               -166.462
exploration/Returns Min               -219.237
exploration/Actions Mean                -0.161924
exploration/Actions Std                  0.659342
exploration/Actions Max                  0.999519
exploration/Actions Min                 -0.997587
exploration/Num Paths                    5
exploration/Average Returns           -191.901
evaluation/num steps total          810432
evaluation/num paths total            4032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.962114
evaluation/Rewards Std                   0.184109
evaluation/Rewards Max                  -0.595574
evaluation/Rewards Min                  -1.53628
evaluation/Returns Mean               -193.385
evaluation/Returns Std                  18.8763
evaluation/Returns Max                -162.081
evaluation/Returns Min                -235.795
evaluation/Actions Mean                 -0.348742
evaluation/Actions Std                   0.607088
evaluation/Actions Max                   0.998586
evaluation/Actions Min                  -0.992543
evaluation/Num Paths                    24
evaluation/Average Returns            -193.385
time/data storing (s)                    0.00835223
time/evaluation sampling (s)           465.016
time/exploration sampling (s)          109.656
time/logging (s)                         0.0306843
time/sac training (s)                    8.97607
time/saving (s)                          0.0380147
time/training (s)                        0.000111528
time/epoch (s)                         583.725
time/total (s)                      107586
Epoch                                  167
----------------------------------  ----------------
2020-11-02 15:56:10.129163 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 168 finished
----------------------------------  ----------------
replay_buffer/size                  170000
trainer/num train calls             169000
trainer/QF1 Loss                        25.3798
trainer/QF2 Loss                        25.7265
trainer/Policy Loss                    165.355
trainer/Q1 Predictions Mean           -164.314
trainer/Q1 Predictions Std              45.6931
trainer/Q1 Predictions Max              53.1366
trainer/Q1 Predictions Min            -233.04
trainer/Q2 Predictions Mean           -164.659
trainer/Q2 Predictions Std              45.8596
trainer/Q2 Predictions Max              49.8346
trainer/Q2 Predictions Min            -234.993
trainer/Q Targets Mean                -164.994
trainer/Q Targets Std                   45.2154
trainer/Q Targets Max                   50.0648
trainer/Q Targets Min                 -230.295
trainer/Log Pis Mean                     1.73789
trainer/Log Pis Std                      1.98331
trainer/Log Pis Max                     10.0314
trainer/Log Pis Min                     -5.07759
trainer/policy/mean Mean                -0.410075
trainer/policy/mean Std                  0.719706
trainer/policy/mean Max                  0.999949
trainer/policy/mean Min                 -0.996425
trainer/policy/normal/std Mean           0.639203
trainer/policy/normal/std Std            0.0906905
trainer/policy/normal/std Max            0.943308
trainer/policy/normal/std Min            0.369745
trainer/policy/normal/log_std Mean      -0.457442
trainer/policy/normal/log_std Std        0.140483
trainer/policy/normal/log_std Max       -0.0583625
trainer/policy/normal/log_std Min       -0.994943
trainer/Alpha                            0.036277
trainer/Alpha Loss                      -0.869303
exploration/num steps total         170000
exploration/num paths total            850
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.91048
exploration/Rewards Std                  0.198256
exploration/Rewards Max                 -0.553143
exploration/Rewards Min                 -1.44555
exploration/Returns Mean              -182.096
exploration/Returns Std                 18.6742
exploration/Returns Max               -154.534
exploration/Returns Min               -212.295
exploration/Actions Mean                -0.376956
exploration/Actions Std                  0.664018
exploration/Actions Max                  0.999536
exploration/Actions Min                 -0.999627
exploration/Num Paths                    5
exploration/Average Returns           -182.096
evaluation/num steps total          815256
evaluation/num paths total            4056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.961894
evaluation/Rewards Std                   0.198401
evaluation/Rewards Max                  -0.591346
evaluation/Rewards Min                  -1.84111
evaluation/Returns Mean               -193.341
evaluation/Returns Std                  18.8058
evaluation/Returns Max                -153.382
evaluation/Returns Min                -233
evaluation/Actions Mean                 -0.362564
evaluation/Actions Std                   0.610779
evaluation/Actions Max                   0.999757
evaluation/Actions Min                  -0.999292
evaluation/Num Paths                    24
evaluation/Average Returns            -193.341
time/data storing (s)                    0.0370698
time/evaluation sampling (s)           542.103
time/exploration sampling (s)          100.204
time/logging (s)                         0.0762683
time/sac training (s)                   11.4962
time/saving (s)                          0.163037
time/training (s)                        0.000112853
time/epoch (s)                         654.079
time/total (s)                      108241
Epoch                                  168
----------------------------------  ----------------
2020-11-02 16:05:13.851126 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 169 finished
----------------------------------  ----------------
replay_buffer/size                  171000
trainer/num train calls             170000
trainer/QF1 Loss                        27.7183
trainer/QF2 Loss                        30.2028
trainer/Policy Loss                    160.696
trainer/Q1 Predictions Mean           -159.94
trainer/Q1 Predictions Std              44.6948
trainer/Q1 Predictions Max              63.0377
trainer/Q1 Predictions Min            -230.174
trainer/Q2 Predictions Mean           -159.95
trainer/Q2 Predictions Std              44.7803
trainer/Q2 Predictions Max              50.152
trainer/Q2 Predictions Min            -230.881
trainer/Q Targets Mean                -159.582
trainer/Q Targets Std                   44.1011
trainer/Q Targets Max                   42.0044
trainer/Q Targets Min                 -231.497
trainer/Log Pis Mean                     2.17927
trainer/Log Pis Std                      2.28481
trainer/Log Pis Max                      9.59248
trainer/Log Pis Min                     -5.23203
trainer/policy/mean Mean                -0.386444
trainer/policy/mean Std                  0.739201
trainer/policy/mean Max                  0.990729
trainer/policy/mean Min                 -0.999201
trainer/policy/normal/std Mean           0.662635
trainer/policy/normal/std Std            0.104553
trainer/policy/normal/std Max            0.985626
trainer/policy/normal/std Min            0.348316
trainer/policy/normal/log_std Mean      -0.423956
trainer/policy/normal/log_std Std        0.157851
trainer/policy/normal/log_std Max       -0.0144787
trainer/policy/normal/log_std Min       -1.05465
trainer/Alpha                            0.0367111
trainer/Alpha Loss                       0.59244
exploration/num steps total         171000
exploration/num paths total            855
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.938033
exploration/Rewards Std                  0.190089
exploration/Rewards Max                 -0.526963
exploration/Rewards Min                 -1.53228
exploration/Returns Mean              -187.607
exploration/Returns Std                 14.9661
exploration/Returns Max               -164.871
exploration/Returns Min               -203.339
exploration/Actions Mean                -0.267476
exploration/Actions Std                  0.687287
exploration/Actions Max                  0.996936
exploration/Actions Min                 -0.999672
exploration/Num Paths                    5
exploration/Average Returns           -187.607
evaluation/num steps total          820080
evaluation/num paths total            4080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.924479
evaluation/Rewards Std                   0.205636
evaluation/Rewards Max                  -0.548897
evaluation/Rewards Min                  -1.7001
evaluation/Returns Mean               -185.82
evaluation/Returns Std                  18.8835
evaluation/Returns Max                -154.248
evaluation/Returns Min                -221.021
evaluation/Actions Mean                 -0.35413
evaluation/Actions Std                   0.66282
evaluation/Actions Max                   0.997407
evaluation/Actions Min                  -0.999964
evaluation/Num Paths                    24
evaluation/Average Returns            -185.82
time/data storing (s)                    0.0113771
time/evaluation sampling (s)           385.169
time/exploration sampling (s)          142.966
time/logging (s)                         0.0687685
time/sac training (s)                   13.9353
time/saving (s)                          0.0574144
time/training (s)                        0.000123314
time/epoch (s)                         542.208
time/total (s)                      108785
Epoch                                  169
----------------------------------  ----------------
2020-11-02 16:19:46.761534 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 170 finished
----------------------------------  ----------------
replay_buffer/size                  172000
trainer/num train calls             171000
trainer/QF1 Loss                        24.0178
trainer/QF2 Loss                        25.1187
trainer/Policy Loss                    161.499
trainer/Q1 Predictions Mean           -161.059
trainer/Q1 Predictions Std              44.5824
trainer/Q1 Predictions Max              31.8429
trainer/Q1 Predictions Min            -230.843
trainer/Q2 Predictions Mean           -160.554
trainer/Q2 Predictions Std              44.3556
trainer/Q2 Predictions Max              31.7693
trainer/Q2 Predictions Min            -230.424
trainer/Q Targets Mean                -160.733
trainer/Q Targets Std                   44.7642
trainer/Q Targets Max                   39.8797
trainer/Q Targets Min                 -233.948
trainer/Log Pis Mean                     2.29066
trainer/Log Pis Std                      2.50796
trainer/Log Pis Max                     10.8243
trainer/Log Pis Min                     -4.74834
trainer/policy/mean Mean                -0.055282
trainer/policy/mean Std                  0.857878
trainer/policy/mean Max                  0.999352
trainer/policy/mean Min                 -0.991071
trainer/policy/normal/std Mean           0.590088
trainer/policy/normal/std Std            0.0700493
trainer/policy/normal/std Max            0.921333
trainer/policy/normal/std Min            0.288659
trainer/policy/normal/log_std Mean      -0.534655
trainer/policy/normal/log_std Std        0.12089
trainer/policy/normal/log_std Max       -0.0819339
trainer/policy/normal/log_std Min       -1.24251
trainer/Alpha                            0.036607
trainer/Alpha Loss                       0.961366
exploration/num steps total         172000
exploration/num paths total            860
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.901606
exploration/Rewards Std                  0.191566
exploration/Rewards Max                 -0.563358
exploration/Rewards Min                 -1.43026
exploration/Returns Mean              -180.321
exploration/Returns Std                 13.8952
exploration/Returns Max               -168.677
exploration/Returns Min               -206.423
exploration/Actions Mean                -0.250417
exploration/Actions Std                  0.703337
exploration/Actions Max                  0.999647
exploration/Actions Min                 -0.999314
exploration/Num Paths                    5
exploration/Average Returns           -180.321
evaluation/num steps total          824904
evaluation/num paths total            4104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -1.03131
evaluation/Rewards Std                   0.230218
evaluation/Rewards Max                  -0.551989
evaluation/Rewards Min                  -1.75567
evaluation/Returns Mean               -207.294
evaluation/Returns Std                  27.3016
evaluation/Returns Max                -159.891
evaluation/Returns Min                -257.335
evaluation/Actions Mean                 -0.274329
evaluation/Actions Std                   0.699494
evaluation/Actions Max                   0.999769
evaluation/Actions Min                  -0.993959
evaluation/Num Paths                    24
evaluation/Average Returns            -207.294
time/data storing (s)                    0.0175711
time/evaluation sampling (s)           715.289
time/exploration sampling (s)          141.807
time/logging (s)                         0.126482
time/sac training (s)                   14.0132
time/saving (s)                          0.0837114
time/training (s)                        0.000146531
time/epoch (s)                         871.337
time/total (s)                      109658
Epoch                                  170
----------------------------------  ----------------
2020-11-02 16:32:09.475920 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 171 finished
----------------------------------  ----------------
replay_buffer/size                  173000
trainer/num train calls             172000
trainer/QF1 Loss                       223.519
trainer/QF2 Loss                       249.587
trainer/Policy Loss                    160.502
trainer/Q1 Predictions Mean           -159.166
trainer/Q1 Predictions Std              44.1316
trainer/Q1 Predictions Max              74.9302
trainer/Q1 Predictions Min            -232.1
trainer/Q2 Predictions Mean           -160.011
trainer/Q2 Predictions Std              44.513
trainer/Q2 Predictions Max              75.2909
trainer/Q2 Predictions Min            -230.921
trainer/Q Targets Mean                -157.83
trainer/Q Targets Std                   47.3412
trainer/Q Targets Max                   95.4762
trainer/Q Targets Min                 -228.042
trainer/Log Pis Mean                     1.75692
trainer/Log Pis Std                      2.15051
trainer/Log Pis Max                      9.04978
trainer/Log Pis Min                     -5.16276
trainer/policy/mean Mean                -0.346029
trainer/policy/mean Std                  0.74879
trainer/policy/mean Max                  0.999851
trainer/policy/mean Min                 -0.999396
trainer/policy/normal/std Mean           0.636106
trainer/policy/normal/std Std            0.0926913
trainer/policy/normal/std Max            0.948842
trainer/policy/normal/std Min            0.354257
trainer/policy/normal/log_std Mean      -0.463033
trainer/policy/normal/log_std Std        0.146474
trainer/policy/normal/log_std Max       -0.0525132
trainer/policy/normal/log_std Min       -1.03773
trainer/Alpha                            0.0353784
trainer/Alpha Loss                      -0.812283
exploration/num steps total         173000
exploration/num paths total            865
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.996261
exploration/Rewards Std                  0.195726
exploration/Rewards Max                 -0.661206
exploration/Rewards Min                 -1.59098
exploration/Returns Mean              -199.252
exploration/Returns Std                 11.3655
exploration/Returns Max               -183.919
exploration/Returns Min               -211.022
exploration/Actions Mean                -0.338915
exploration/Actions Std                  0.668586
exploration/Actions Max                  0.999422
exploration/Actions Min                 -0.998541
exploration/Num Paths                    5
exploration/Average Returns           -199.252
evaluation/num steps total          829728
evaluation/num paths total            4128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.919217
evaluation/Rewards Std                   0.199312
evaluation/Rewards Max                  -0.564415
evaluation/Rewards Min                  -1.68658
evaluation/Returns Mean               -184.763
evaluation/Returns Std                  21.177
evaluation/Returns Max                -152.257
evaluation/Returns Min                -220.301
evaluation/Actions Mean                 -0.345771
evaluation/Actions Std                   0.643981
evaluation/Actions Max                   0.99963
evaluation/Actions Min                  -0.999374
evaluation/Num Paths                    24
evaluation/Average Returns            -184.763
time/data storing (s)                    0.0092418
time/evaluation sampling (s)           577.808
time/exploration sampling (s)          142.753
time/logging (s)                         0.0796593
time/sac training (s)                   19.1229
time/saving (s)                          0.0818612
time/training (s)                        0.000151438
time/epoch (s)                         739.854
time/total (s)                      110400
Epoch                                  171
----------------------------------  ----------------
2020-11-02 16:43:03.416676 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 172 finished
----------------------------------  ----------------
replay_buffer/size                  174000
trainer/num train calls             173000
trainer/QF1 Loss                       128.56
trainer/QF2 Loss                       115.154
trainer/Policy Loss                    162.046
trainer/Q1 Predictions Mean           -161.171
trainer/Q1 Predictions Std              40.714
trainer/Q1 Predictions Max             -13.0233
trainer/Q1 Predictions Min            -236.963
trainer/Q2 Predictions Mean           -161.349
trainer/Q2 Predictions Std              40.3125
trainer/Q2 Predictions Max             -10.7763
trainer/Q2 Predictions Min            -234.234
trainer/Q Targets Mean                -161.37
trainer/Q Targets Std                   41.208
trainer/Q Targets Max                   -1.05572
trainer/Q Targets Min                 -233.039
trainer/Log Pis Mean                     1.8642
trainer/Log Pis Std                      2.23796
trainer/Log Pis Max                      8.06223
trainer/Log Pis Min                     -4.64156
trainer/policy/mean Mean                -0.482185
trainer/policy/mean Std                  0.673366
trainer/policy/mean Max                  0.999326
trainer/policy/mean Min                 -0.997298
trainer/policy/normal/std Mean           0.642709
trainer/policy/normal/std Std            0.0950565
trainer/policy/normal/std Max            0.960455
trainer/policy/normal/std Min            0.391809
trainer/policy/normal/log_std Mean      -0.453062
trainer/policy/normal/log_std Std        0.148907
trainer/policy/normal/log_std Max       -0.0403483
trainer/policy/normal/log_std Min       -0.936982
trainer/Alpha                            0.034917
trainer/Alpha Loss                      -0.45557
exploration/num steps total         174000
exploration/num paths total            870
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.06202
exploration/Rewards Std                  0.249761
exploration/Rewards Max                 -0.673476
exploration/Rewards Min                 -1.90763
exploration/Returns Mean              -212.404
exploration/Returns Std                 28.062
exploration/Returns Max               -182.43
exploration/Returns Min               -259.927
exploration/Actions Mean                -0.268007
exploration/Actions Std                  0.678736
exploration/Actions Max                  0.997486
exploration/Actions Min                 -0.999327
exploration/Num Paths                    5
exploration/Average Returns           -212.404
evaluation/num steps total          834552
evaluation/num paths total            4152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.919666
evaluation/Rewards Std                   0.188024
evaluation/Rewards Max                  -0.589597
evaluation/Rewards Min                  -1.68368
evaluation/Returns Mean               -184.853
evaluation/Returns Std                  17.4313
evaluation/Returns Max                -161.244
evaluation/Returns Min                -222.931
evaluation/Actions Mean                 -0.461431
evaluation/Actions Std                   0.552647
evaluation/Actions Max                   0.943521
evaluation/Actions Min                  -0.99956
evaluation/Num Paths                    24
evaluation/Average Returns            -184.853
time/data storing (s)                    0.0158078
time/evaluation sampling (s)           490.121
time/exploration sampling (s)          148.714
time/logging (s)                         0.081935
time/sac training (s)                   12.4494
time/saving (s)                          0.068629
time/training (s)                        0.000136053
time/epoch (s)                         651.452
time/total (s)                      111054
Epoch                                  172
----------------------------------  ----------------
2020-11-02 16:53:30.863568 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 173 finished
----------------------------------  ----------------
replay_buffer/size                  175000
trainer/num train calls             174000
trainer/QF1 Loss                        31.2975
trainer/QF2 Loss                        31.0586
trainer/Policy Loss                    160.42
trainer/Q1 Predictions Mean           -159.691
trainer/Q1 Predictions Std              41.8892
trainer/Q1 Predictions Max              52.461
trainer/Q1 Predictions Min            -227.191
trainer/Q2 Predictions Mean           -159.372
trainer/Q2 Predictions Std              41.9984
trainer/Q2 Predictions Max              53.2497
trainer/Q2 Predictions Min            -226.398
trainer/Q Targets Mean                -160.298
trainer/Q Targets Std                   41.8837
trainer/Q Targets Max                   59.9446
trainer/Q Targets Min                 -229.085
trainer/Log Pis Mean                     1.97286
trainer/Log Pis Std                      2.10065
trainer/Log Pis Max                      7.85519
trainer/Log Pis Min                     -3.17849
trainer/policy/mean Mean                -0.419781
trainer/policy/mean Std                  0.720672
trainer/policy/mean Max                  0.993991
trainer/policy/mean Min                 -0.994488
trainer/policy/normal/std Mean           0.631673
trainer/policy/normal/std Std            0.0954132
trainer/policy/normal/std Max            0.868464
trainer/policy/normal/std Min            0.271291
trainer/policy/normal/log_std Mean      -0.470817
trainer/policy/normal/log_std Std        0.151814
trainer/policy/normal/log_std Max       -0.141029
trainer/policy/normal/log_std Min       -1.30456
trainer/Alpha                            0.0328343
trainer/Alpha Loss                      -0.0927175
exploration/num steps total         175000
exploration/num paths total            875
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.914909
exploration/Rewards Std                  0.181616
exploration/Rewards Max                 -0.558133
exploration/Rewards Min                 -1.51247
exploration/Returns Mean              -182.982
exploration/Returns Std                  9.55982
exploration/Returns Max               -167.024
exploration/Returns Min               -194.279
exploration/Actions Mean                -0.437445
exploration/Actions Std                  0.646906
exploration/Actions Max                  0.997045
exploration/Actions Min                 -0.999743
exploration/Num Paths                    5
exploration/Average Returns           -182.982
evaluation/num steps total          839376
evaluation/num paths total            4176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.939979
evaluation/Rewards Std                   0.219529
evaluation/Rewards Max                  -0.543451
evaluation/Rewards Min                  -1.76273
evaluation/Returns Mean               -188.936
evaluation/Returns Std                  23.5313
evaluation/Returns Max                -153.621
evaluation/Returns Min                -243.816
evaluation/Actions Mean                 -0.42605
evaluation/Actions Std                   0.630425
evaluation/Actions Max                   0.990588
evaluation/Actions Min                  -0.999629
evaluation/Num Paths                    24
evaluation/Average Returns            -188.936
time/data storing (s)                    0.0157247
time/evaluation sampling (s)           491.043
time/exploration sampling (s)          114.676
time/logging (s)                         0.0506308
time/sac training (s)                   19.8954
time/saving (s)                          0.0494697
time/training (s)                        0.000126035
time/epoch (s)                         625.73
time/total (s)                      111682
Epoch                                  173
----------------------------------  ----------------
2020-11-02 17:05:11.056849 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 174 finished
----------------------------------  ----------------
replay_buffer/size                  176000
trainer/num train calls             175000
trainer/QF1 Loss                        30.4797
trainer/QF2 Loss                        32.6824
trainer/Policy Loss                    156.146
trainer/Q1 Predictions Mean           -155.53
trainer/Q1 Predictions Std              45.8856
trainer/Q1 Predictions Max              39.0775
trainer/Q1 Predictions Min            -224.165
trainer/Q2 Predictions Mean           -155.335
trainer/Q2 Predictions Std              46.4065
trainer/Q2 Predictions Max              41.1561
trainer/Q2 Predictions Min            -226.379
trainer/Q Targets Mean                -156.908
trainer/Q Targets Std                   46.3536
trainer/Q Targets Max                   30.5768
trainer/Q Targets Min                 -229.389
trainer/Log Pis Mean                     2.40476
trainer/Log Pis Std                      2.25802
trainer/Log Pis Max                      9.19506
trainer/Log Pis Min                     -3.59524
trainer/policy/mean Mean                -0.374201
trainer/policy/mean Std                  0.762786
trainer/policy/mean Max                  0.999338
trainer/policy/mean Min                 -0.999499
trainer/policy/normal/std Mean           0.654601
trainer/policy/normal/std Std            0.104294
trainer/policy/normal/std Max            1.022
trainer/policy/normal/std Min            0.4045
trainer/policy/normal/log_std Mean      -0.436247
trainer/policy/normal/log_std Std        0.158008
trainer/policy/normal/log_std Max        0.0217644
trainer/policy/normal/log_std Min       -0.905105
trainer/Alpha                            0.0345102
trainer/Alpha Loss                       1.36263
exploration/num steps total         176000
exploration/num paths total            880
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.989828
exploration/Rewards Std                  0.155387
exploration/Rewards Max                 -0.633216
exploration/Rewards Min                 -1.56016
exploration/Returns Mean              -197.966
exploration/Returns Std                 20.7981
exploration/Returns Max               -165.1
exploration/Returns Min               -227.241
exploration/Actions Mean                 0.0192424
exploration/Actions Std                  0.756751
exploration/Actions Max                  0.999981
exploration/Actions Min                 -0.998207
exploration/Num Paths                    5
exploration/Average Returns           -197.966
evaluation/num steps total          844200
evaluation/num paths total            4200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.955977
evaluation/Rewards Std                   0.235936
evaluation/Rewards Max                  -0.533711
evaluation/Rewards Min                  -1.83573
evaluation/Returns Mean               -192.151
evaluation/Returns Std                  29.6175
evaluation/Returns Max                -162.56
evaluation/Returns Min                -271.684
evaluation/Actions Mean                 -0.362795
evaluation/Actions Std                   0.642282
evaluation/Actions Max                   0.99786
evaluation/Actions Min                  -0.999439
evaluation/Num Paths                    24
evaluation/Average Returns            -192.151
time/data storing (s)                    0.0125201
time/evaluation sampling (s)           534.06
time/exploration sampling (s)          151.393
time/logging (s)                         0.0503227
time/sac training (s)                   12.95
time/saving (s)                          0.0670269
time/training (s)                        0.000127753
time/epoch (s)                         698.533
time/total (s)                      112382
Epoch                                  174
----------------------------------  ----------------
2020-11-02 17:18:01.859315 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 175 finished
----------------------------------  ----------------
replay_buffer/size                  177000
trainer/num train calls             176000
trainer/QF1 Loss                       132.37
trainer/QF2 Loss                       131.221
trainer/Policy Loss                    160.48
trainer/Q1 Predictions Mean           -159.742
trainer/Q1 Predictions Std              41.4883
trainer/Q1 Predictions Max             -16.4589
trainer/Q1 Predictions Min            -228.54
trainer/Q2 Predictions Mean           -159.468
trainer/Q2 Predictions Std              41.2311
trainer/Q2 Predictions Max             -20.2205
trainer/Q2 Predictions Min            -227.053
trainer/Q Targets Mean                -158.536
trainer/Q Targets Std                   42.473
trainer/Q Targets Max                   -1.10193
trainer/Q Targets Min                 -229.027
trainer/Log Pis Mean                     1.53496
trainer/Log Pis Std                      2.10577
trainer/Log Pis Max                      8.84233
trainer/Log Pis Min                     -4.83675
trainer/policy/mean Mean                -0.483883
trainer/policy/mean Std                  0.648978
trainer/policy/mean Max                  0.999927
trainer/policy/mean Min                 -0.997755
trainer/policy/normal/std Mean           0.653183
trainer/policy/normal/std Std            0.0937654
trainer/policy/normal/std Max            0.908504
trainer/policy/normal/std Min            0.331808
trainer/policy/normal/log_std Mean      -0.436259
trainer/policy/normal/log_std Std        0.144704
trainer/policy/normal/log_std Max       -0.0959564
trainer/policy/normal/log_std Min       -1.1032
trainer/Alpha                            0.0358904
trainer/Alpha Loss                      -1.54731
exploration/num steps total         177000
exploration/num paths total            885
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.997561
exploration/Rewards Std                  0.185413
exploration/Rewards Max                 -0.654625
exploration/Rewards Min                 -1.5284
exploration/Returns Mean              -199.512
exploration/Returns Std                 18.2376
exploration/Returns Max               -176.641
exploration/Returns Min               -218.828
exploration/Actions Mean                -0.219212
exploration/Actions Std                  0.667892
exploration/Actions Max                  0.997529
exploration/Actions Min                 -0.999227
exploration/Num Paths                    5
exploration/Average Returns           -199.512
evaluation/num steps total          849024
evaluation/num paths total            4224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.941405
evaluation/Rewards Std                   0.182478
evaluation/Rewards Max                  -0.561359
evaluation/Rewards Min                  -1.64431
evaluation/Returns Mean               -189.222
evaluation/Returns Std                  17.1604
evaluation/Returns Max                -154.548
evaluation/Returns Min                -223.88
evaluation/Actions Mean                 -0.419974
evaluation/Actions Std                   0.550606
evaluation/Actions Max                   0.983696
evaluation/Actions Min                  -0.987642
evaluation/Num Paths                    24
evaluation/Average Returns            -189.222
time/data storing (s)                    0.0144568
time/evaluation sampling (s)           593.109
time/exploration sampling (s)          158.9
time/logging (s)                         0.0897251
time/sac training (s)                   16.8854
time/saving (s)                          0.134057
time/training (s)                        0.000130318
time/epoch (s)                         769.133
time/total (s)                      113153
Epoch                                  175
----------------------------------  ----------------
2020-11-02 17:29:22.307749 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 176 finished
----------------------------------  ---------------
replay_buffer/size                  178000
trainer/num train calls             177000
trainer/QF1 Loss                        23.8417
trainer/QF2 Loss                        25.1895
trainer/Policy Loss                    163.461
trainer/Q1 Predictions Mean           -162.636
trainer/Q1 Predictions Std              39.6491
trainer/Q1 Predictions Max             -29.7512
trainer/Q1 Predictions Min            -228.192
trainer/Q2 Predictions Mean           -162.867
trainer/Q2 Predictions Std              39.8384
trainer/Q2 Predictions Max             -29.9865
trainer/Q2 Predictions Min            -229.429
trainer/Q Targets Mean                -163.016
trainer/Q Targets Std                   39.4869
trainer/Q Targets Max                  -26.3744
trainer/Q Targets Min                 -228.922
trainer/Log Pis Mean                     2.00171
trainer/Log Pis Std                      2.052
trainer/Log Pis Max                      9.04836
trainer/Log Pis Min                     -3.50657
trainer/policy/mean Mean                -0.248398
trainer/policy/mean Std                  0.801121
trainer/policy/mean Max                  0.997747
trainer/policy/mean Min                 -0.997127
trainer/policy/normal/std Mean           0.651747
trainer/policy/normal/std Std            0.093734
trainer/policy/normal/std Max            0.942078
trainer/policy/normal/std Min            0.386139
trainer/policy/normal/log_std Mean      -0.438574
trainer/policy/normal/log_std Std        0.14547
trainer/policy/normal/log_std Max       -0.0596672
trainer/policy/normal/log_std Min       -0.951558
trainer/Alpha                            0.0361215
trainer/Alpha Loss                       0.00568889
exploration/num steps total         178000
exploration/num paths total            890
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.86242
exploration/Rewards Std                  0.19975
exploration/Rewards Max                 -0.586217
exploration/Rewards Min                 -1.4702
exploration/Returns Mean              -172.484
exploration/Returns Std                  9.53418
exploration/Returns Max               -159.782
exploration/Returns Min               -184.2
exploration/Actions Mean                -0.501248
exploration/Actions Std                  0.593788
exploration/Actions Max                  0.993078
exploration/Actions Min                 -0.999674
exploration/Num Paths                    5
exploration/Average Returns           -172.484
evaluation/num steps total          853848
evaluation/num paths total            4248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.926941
evaluation/Rewards Std                   0.229862
evaluation/Rewards Max                  -0.55232
evaluation/Rewards Min                  -2.06137
evaluation/Returns Mean               -186.315
evaluation/Returns Std                  21.4971
evaluation/Returns Max                -160.451
evaluation/Returns Min                -247.375
evaluation/Actions Mean                 -0.349153
evaluation/Actions Std                   0.676548
evaluation/Actions Max                   0.99979
evaluation/Actions Min                  -0.999877
evaluation/Num Paths                    24
evaluation/Average Returns            -186.315
time/data storing (s)                    0.0134401
time/evaluation sampling (s)           550.835
time/exploration sampling (s)          117.769
time/logging (s)                         0.0325403
time/sac training (s)                   10.2513
time/saving (s)                          0.046397
time/training (s)                        0.00012823
time/epoch (s)                         678.948
time/total (s)                      113833
Epoch                                  176
----------------------------------  ---------------
2020-11-02 17:39:31.757786 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 177 finished
----------------------------------  ----------------
replay_buffer/size                  179000
trainer/num train calls             178000
trainer/QF1 Loss                        56.0779
trainer/QF2 Loss                        51.9062
trainer/Policy Loss                    164.099
trainer/Q1 Predictions Mean           -163.074
trainer/Q1 Predictions Std              42.1981
trainer/Q1 Predictions Max               9.96649
trainer/Q1 Predictions Min            -235.009
trainer/Q2 Predictions Mean           -163.607
trainer/Q2 Predictions Std              42.4988
trainer/Q2 Predictions Max              16.1401
trainer/Q2 Predictions Min            -230.568
trainer/Q Targets Mean                -162.846
trainer/Q Targets Std                   43.7815
trainer/Q Targets Max                    6.4463
trainer/Q Targets Min                 -232.539
trainer/Log Pis Mean                     1.57703
trainer/Log Pis Std                      1.97758
trainer/Log Pis Max                      7.1369
trainer/Log Pis Min                     -4.00173
trainer/policy/mean Mean                -0.445489
trainer/policy/mean Std                  0.696941
trainer/policy/mean Max                  0.995981
trainer/policy/mean Min                 -0.998532
trainer/policy/normal/std Mean           0.651922
trainer/policy/normal/std Std            0.107241
trainer/policy/normal/std Max            0.980679
trainer/policy/normal/std Min            0.326248
trainer/policy/normal/log_std Mean      -0.441189
trainer/policy/normal/log_std Std        0.163438
trainer/policy/normal/log_std Max       -0.0195096
trainer/policy/normal/log_std Min       -1.1201
trainer/Alpha                            0.0353831
trainer/Alpha Loss                      -1.41336
exploration/num steps total         179000
exploration/num paths total            895
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.874683
exploration/Rewards Std                  0.178626
exploration/Rewards Max                 -0.555784
exploration/Rewards Min                 -1.39701
exploration/Returns Mean              -174.937
exploration/Returns Std                 12.5366
exploration/Returns Max               -153.522
exploration/Returns Min               -188.378
exploration/Actions Mean                -0.377162
exploration/Actions Std                  0.670665
exploration/Actions Max                  0.999333
exploration/Actions Min                 -0.998737
exploration/Num Paths                    5
exploration/Average Returns           -174.937
evaluation/num steps total          858672
evaluation/num paths total            4272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.887201
evaluation/Rewards Std                   0.188708
evaluation/Rewards Max                  -0.543251
evaluation/Rewards Min                  -1.59615
evaluation/Returns Mean               -178.327
evaluation/Returns Std                  15.1313
evaluation/Returns Max                -142.456
evaluation/Returns Min                -217.138
evaluation/Actions Mean                 -0.394159
evaluation/Actions Std                   0.626354
evaluation/Actions Max                   0.994431
evaluation/Actions Min                  -0.99623
evaluation/Num Paths                    24
evaluation/Average Returns            -178.327
time/data storing (s)                    0.009316
time/evaluation sampling (s)           478.221
time/exploration sampling (s)          120.09
time/logging (s)                         0.0182648
time/sac training (s)                   10.365
time/saving (s)                          0.0308343
time/training (s)                        0.000122189
time/epoch (s)                         608.734
time/total (s)                      114443
Epoch                                  177
----------------------------------  ----------------
2020-11-02 17:49:10.039081 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 178 finished
----------------------------------  ----------------
replay_buffer/size                  180000
trainer/num train calls             179000
trainer/QF1 Loss                        24.26
trainer/QF2 Loss                        27.3542
trainer/Policy Loss                    160.872
trainer/Q1 Predictions Mean           -160.281
trainer/Q1 Predictions Std              37.3119
trainer/Q1 Predictions Max             -39.682
trainer/Q1 Predictions Min            -229.074
trainer/Q2 Predictions Mean           -160.029
trainer/Q2 Predictions Std              37.5957
trainer/Q2 Predictions Max             -42.8341
trainer/Q2 Predictions Min            -227.879
trainer/Q Targets Mean                -161.238
trainer/Q Targets Std                   37.7555
trainer/Q Targets Max                  -41.3568
trainer/Q Targets Min                 -231.498
trainer/Log Pis Mean                     2.04603
trainer/Log Pis Std                      2.1534
trainer/Log Pis Max                      9.27043
trainer/Log Pis Min                     -5.76117
trainer/policy/mean Mean                -0.307983
trainer/policy/mean Std                  0.769358
trainer/policy/mean Max                  0.997297
trainer/policy/mean Min                 -0.995494
trainer/policy/normal/std Mean           0.639929
trainer/policy/normal/std Std            0.0836411
trainer/policy/normal/std Max            0.862454
trainer/policy/normal/std Min            0.385715
trainer/policy/normal/log_std Mean      -0.454906
trainer/policy/normal/log_std Std        0.130619
trainer/policy/normal/log_std Max       -0.147973
trainer/policy/normal/log_std Min       -0.952658
trainer/Alpha                            0.032781
trainer/Alpha Loss                       0.157339
exploration/num steps total         180000
exploration/num paths total            900
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.914793
exploration/Rewards Std                  0.19759
exploration/Rewards Max                 -0.593847
exploration/Rewards Min                 -1.50061
exploration/Returns Mean              -182.959
exploration/Returns Std                 14.1781
exploration/Returns Max               -163.948
exploration/Returns Min               -207.404
exploration/Actions Mean                -0.178862
exploration/Actions Std                  0.736891
exploration/Actions Max                  0.998519
exploration/Actions Min                 -0.99935
exploration/Num Paths                    5
exploration/Average Returns           -182.959
evaluation/num steps total          863496
evaluation/num paths total            4296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.902504
evaluation/Rewards Std                   0.207953
evaluation/Rewards Max                  -0.549201
evaluation/Rewards Min                  -1.70559
evaluation/Returns Mean               -181.403
evaluation/Returns Std                  17.0578
evaluation/Returns Max                -154.357
evaluation/Returns Min                -220.06
evaluation/Actions Mean                 -0.339596
evaluation/Actions Std                   0.68411
evaluation/Actions Max                   0.992338
evaluation/Actions Min                  -0.998537
evaluation/Num Paths                    24
evaluation/Average Returns            -181.403
time/data storing (s)                    0.0114508
time/evaluation sampling (s)           457.347
time/exploration sampling (s)          109.615
time/logging (s)                         0.0296813
time/sac training (s)                    9.98903
time/saving (s)                          0.0354243
time/training (s)                        0.000127132
time/epoch (s)                         577.028
time/total (s)                      115021
Epoch                                  178
----------------------------------  ----------------
2020-11-02 18:02:44.754412 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 179 finished
----------------------------------  ----------------
replay_buffer/size                  181000
trainer/num train calls             180000
trainer/QF1 Loss                        26.6324
trainer/QF2 Loss                        24.7758
trainer/Policy Loss                    163.225
trainer/Q1 Predictions Mean           -162.197
trainer/Q1 Predictions Std              39.4428
trainer/Q1 Predictions Max             -24.9728
trainer/Q1 Predictions Min            -227.295
trainer/Q2 Predictions Mean           -162.893
trainer/Q2 Predictions Std              39.9053
trainer/Q2 Predictions Max             -19.2536
trainer/Q2 Predictions Min            -228.705
trainer/Q Targets Mean                -162.332
trainer/Q Targets Std                   40.1789
trainer/Q Targets Max                  -13.197
trainer/Q Targets Min                 -229.735
trainer/Log Pis Mean                     2.04878
trainer/Log Pis Std                      2.17386
trainer/Log Pis Max                     11.0452
trainer/Log Pis Min                     -6.26668
trainer/policy/mean Mean                -0.159801
trainer/policy/mean Std                  0.825668
trainer/policy/mean Max                  0.998876
trainer/policy/mean Min                 -0.992474
trainer/policy/normal/std Mean           0.621531
trainer/policy/normal/std Std            0.0783031
trainer/policy/normal/std Max            0.932854
trainer/policy/normal/std Min            0.354583
trainer/policy/normal/log_std Mean      -0.483464
trainer/policy/normal/log_std Std        0.125791
trainer/policy/normal/log_std Max       -0.0695068
trainer/policy/normal/log_std Min       -1.03681
trainer/Alpha                            0.0354984
trainer/Alpha Loss                       0.162832
exploration/num steps total         181000
exploration/num paths total            905
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.846558
exploration/Rewards Std                  0.189051
exploration/Rewards Max                 -0.55474
exploration/Rewards Min                 -1.42686
exploration/Returns Mean              -169.312
exploration/Returns Std                  8.63737
exploration/Returns Max               -154.038
exploration/Returns Min               -178.779
exploration/Actions Mean                -0.329777
exploration/Actions Std                  0.720326
exploration/Actions Max                  0.995566
exploration/Actions Min                 -0.999998
exploration/Num Paths                    5
exploration/Average Returns           -169.312
evaluation/num steps total          868320
evaluation/num paths total            4320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.980739
evaluation/Rewards Std                   0.230904
evaluation/Rewards Max                  -0.537358
evaluation/Rewards Min                  -1.78775
evaluation/Returns Mean               -197.128
evaluation/Returns Std                  26.2738
evaluation/Returns Max                -154.282
evaluation/Returns Min                -265.058
evaluation/Actions Mean                 -0.327716
evaluation/Actions Std                   0.646685
evaluation/Actions Max                   0.99535
evaluation/Actions Min                  -0.997567
evaluation/Num Paths                    24
evaluation/Average Returns            -197.128
time/data storing (s)                    0.016989
time/evaluation sampling (s)           672.557
time/exploration sampling (s)          127.425
time/logging (s)                         0.0726475
time/sac training (s)                   13.1287
time/saving (s)                          0.108705
time/training (s)                        0.000141165
time/epoch (s)                         813.31
time/total (s)                      115835
Epoch                                  179
----------------------------------  ----------------
2020-11-02 18:15:45.457167 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 180 finished
----------------------------------  ---------------
replay_buffer/size                  182000
trainer/num train calls             181000
trainer/QF1 Loss                        72.1956
trainer/QF2 Loss                        85.5915
trainer/Policy Loss                    164.11
trainer/Q1 Predictions Mean           -162.992
trainer/Q1 Predictions Std              42.9567
trainer/Q1 Predictions Max              12.8085
trainer/Q1 Predictions Min            -230.019
trainer/Q2 Predictions Mean           -163.369
trainer/Q2 Predictions Std              43.2936
trainer/Q2 Predictions Max              -0.546341
trainer/Q2 Predictions Min            -232.533
trainer/Q Targets Mean                -161.726
trainer/Q Targets Std                   43.6592
trainer/Q Targets Max                   11.4299
trainer/Q Targets Min                 -228.317
trainer/Log Pis Mean                     1.73555
trainer/Log Pis Std                      2.2925
trainer/Log Pis Max                      8.247
trainer/Log Pis Min                     -5.41524
trainer/policy/mean Mean                -0.294865
trainer/policy/mean Std                  0.767602
trainer/policy/mean Max                  0.999802
trainer/policy/mean Min                 -0.996764
trainer/policy/normal/std Mean           0.653348
trainer/policy/normal/std Std            0.0969991
trainer/policy/normal/std Max            0.900373
trainer/policy/normal/std Min            0.377721
trainer/policy/normal/log_std Mean      -0.436757
trainer/policy/normal/log_std Std        0.149801
trainer/policy/normal/log_std Max       -0.104946
trainer/policy/normal/log_std Min       -0.9736
trainer/Alpha                            0.0347569
trainer/Alpha Loss                      -0.888377
exploration/num steps total         182000
exploration/num paths total            910
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00639
exploration/Rewards Std                  0.147436
exploration/Rewards Max                 -0.807908
exploration/Rewards Min                 -1.48602
exploration/Returns Mean              -201.278
exploration/Returns Std                 11.1839
exploration/Returns Max               -186.57
exploration/Returns Min               -217.959
exploration/Actions Mean                 0.0583064
exploration/Actions Std                  0.72756
exploration/Actions Max                  0.999861
exploration/Actions Min                 -0.998985
exploration/Num Paths                    5
exploration/Average Returns           -201.278
evaluation/num steps total          873144
evaluation/num paths total            4344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.943442
evaluation/Rewards Std                   0.196666
evaluation/Rewards Max                  -0.616191
evaluation/Rewards Min                  -1.59872
evaluation/Returns Mean               -189.632
evaluation/Returns Std                  19.1322
evaluation/Returns Max                -155.605
evaluation/Returns Min                -224.463
evaluation/Actions Mean                 -0.267301
evaluation/Actions Std                   0.706168
evaluation/Actions Max                   0.998448
evaluation/Actions Min                  -0.998184
evaluation/Num Paths                    24
evaluation/Average Returns            -189.632
time/data storing (s)                    0.0227276
time/evaluation sampling (s)           622.239
time/exploration sampling (s)          145.34
time/logging (s)                         0.0662296
time/sac training (s)                   11.3337
time/saving (s)                          0.059974
time/training (s)                        0.00017489
time/epoch (s)                         779.062
time/total (s)                      116616
Epoch                                  180
----------------------------------  ---------------
2020-11-02 18:26:39.640346 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 181 finished
----------------------------------  ----------------
replay_buffer/size                  183000
trainer/num train calls             182000
trainer/QF1 Loss                       136.343
trainer/QF2 Loss                       164.019
trainer/Policy Loss                    160.767
trainer/Q1 Predictions Mean           -159.423
trainer/Q1 Predictions Std              39.2839
trainer/Q1 Predictions Max              27.4969
trainer/Q1 Predictions Min            -227.55
trainer/Q2 Predictions Mean           -160.209
trainer/Q2 Predictions Std              39.994
trainer/Q2 Predictions Max              31.1791
trainer/Q2 Predictions Min            -230.249
trainer/Q Targets Mean                -159.263
trainer/Q Targets Std                   40.6345
trainer/Q Targets Max                   23.1272
trainer/Q Targets Min                 -226.959
trainer/Log Pis Mean                     2.04251
trainer/Log Pis Std                      2.09586
trainer/Log Pis Max                      9.03767
trainer/Log Pis Min                     -2.5554
trainer/policy/mean Mean                -0.281217
trainer/policy/mean Std                  0.773445
trainer/policy/mean Max                  0.993958
trainer/policy/mean Min                 -0.998669
trainer/policy/normal/std Mean           0.648869
trainer/policy/normal/std Std            0.0970853
trainer/policy/normal/std Max            0.97692
trainer/policy/normal/std Min            0.372718
trainer/policy/normal/log_std Mean      -0.443713
trainer/policy/normal/log_std Std        0.14996
trainer/policy/normal/log_std Max       -0.0233508
trainer/policy/normal/log_std Min       -0.986934
trainer/Alpha                            0.0331365
trainer/Alpha Loss                       0.144843
exploration/num steps total         183000
exploration/num paths total            915
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.906539
exploration/Rewards Std                  0.190156
exploration/Rewards Max                 -0.574433
exploration/Rewards Min                 -1.49973
exploration/Returns Mean              -181.308
exploration/Returns Std                 12.1484
exploration/Returns Max               -165.251
exploration/Returns Min               -196.124
exploration/Actions Mean                -0.177772
exploration/Actions Std                  0.766659
exploration/Actions Max                  0.999585
exploration/Actions Min                 -0.999536
exploration/Num Paths                    5
exploration/Average Returns           -181.308
evaluation/num steps total          877968
evaluation/num paths total            4368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.946158
evaluation/Rewards Std                   0.225397
evaluation/Rewards Max                  -0.5843
evaluation/Rewards Min                  -1.68189
evaluation/Returns Mean               -190.178
evaluation/Returns Std                  18.3047
evaluation/Returns Max                -149.847
evaluation/Returns Min                -234.655
evaluation/Actions Mean                 -0.416038
evaluation/Actions Std                   0.658997
evaluation/Actions Max                   0.985629
evaluation/Actions Min                  -0.999925
evaluation/Num Paths                    24
evaluation/Average Returns            -190.178
time/data storing (s)                    0.00804926
time/evaluation sampling (s)           559.202
time/exploration sampling (s)           84.2672
time/logging (s)                         0.0346897
time/sac training (s)                    9.10901
time/saving (s)                          0.0437731
time/training (s)                        0.000121316
time/epoch (s)                         652.665
time/total (s)                      117270
Epoch                                  181
----------------------------------  ----------------
2020-11-02 18:34:19.414876 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 182 finished
----------------------------------  ----------------
replay_buffer/size                  184000
trainer/num train calls             183000
trainer/QF1 Loss                        60.8279
trainer/QF2 Loss                        50.4648
trainer/Policy Loss                    164.296
trainer/Q1 Predictions Mean           -163.362
trainer/Q1 Predictions Std              39.7975
trainer/Q1 Predictions Max               0.699651
trainer/Q1 Predictions Min            -226.055
trainer/Q2 Predictions Mean           -163.481
trainer/Q2 Predictions Std              40.6193
trainer/Q2 Predictions Max               8.45729
trainer/Q2 Predictions Min            -227.366
trainer/Q Targets Mean                -163.892
trainer/Q Targets Std                   40.9957
trainer/Q Targets Max                    9.22802
trainer/Q Targets Min                 -228.088
trainer/Log Pis Mean                     1.9042
trainer/Log Pis Std                      2.28872
trainer/Log Pis Max                     12.7102
trainer/Log Pis Min                     -3.55152
trainer/policy/mean Mean                -0.315493
trainer/policy/mean Std                  0.771339
trainer/policy/mean Max                  0.999997
trainer/policy/mean Min                 -0.997277
trainer/policy/normal/std Mean           0.650971
trainer/policy/normal/std Std            0.103819
trainer/policy/normal/std Max            0.98213
trainer/policy/normal/std Min            0.327172
trainer/policy/normal/log_std Mean      -0.441977
trainer/policy/normal/log_std Std        0.159719
trainer/policy/normal/log_std Max       -0.0180313
trainer/policy/normal/log_std Min       -1.11727
trainer/Alpha                            0.0334351
trainer/Alpha Loss                      -0.325527
exploration/num steps total         184000
exploration/num paths total            920
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.01158
exploration/Rewards Std                  0.176971
exploration/Rewards Max                 -0.635715
exploration/Rewards Min                 -1.67651
exploration/Returns Mean              -202.317
exploration/Returns Std                 20.2657
exploration/Returns Max               -171.659
exploration/Returns Min               -224.909
exploration/Actions Mean                -0.249552
exploration/Actions Std                  0.738761
exploration/Actions Max                  0.999921
exploration/Actions Min                 -0.999756
exploration/Num Paths                    5
exploration/Average Returns           -202.317
evaluation/num steps total          882792
evaluation/num paths total            4392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.895329
evaluation/Rewards Std                   0.192265
evaluation/Rewards Max                  -0.539096
evaluation/Rewards Min                  -1.57474
evaluation/Returns Mean               -179.961
evaluation/Returns Std                  17.3592
evaluation/Returns Max                -150.636
evaluation/Returns Min                -235.22
evaluation/Actions Mean                 -0.374613
evaluation/Actions Std                   0.633481
evaluation/Actions Max                   0.986591
evaluation/Actions Min                  -0.999626
evaluation/Num Paths                    24
evaluation/Average Returns            -179.961
time/data storing (s)                    0.0100605
time/evaluation sampling (s)           344.519
time/exploration sampling (s)          103.941
time/logging (s)                         0.043986
time/sac training (s)                    9.90193
time/saving (s)                          0.0380613
time/training (s)                        0.000113874
time/epoch (s)                         458.455
time/total (s)                      117730
Epoch                                  182
----------------------------------  ----------------
2020-11-02 18:42:40.906848 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 183 finished
----------------------------------  ----------------
replay_buffer/size                  185000
trainer/num train calls             184000
trainer/QF1 Loss                        72.3823
trainer/QF2 Loss                        80.2373
trainer/Policy Loss                    161.793
trainer/Q1 Predictions Mean           -161.182
trainer/Q1 Predictions Std              39.666
trainer/Q1 Predictions Max               1.4437
trainer/Q1 Predictions Min            -229.353
trainer/Q2 Predictions Mean           -161.007
trainer/Q2 Predictions Std              39.3033
trainer/Q2 Predictions Max               0.564935
trainer/Q2 Predictions Min            -227.637
trainer/Q Targets Mean                -160.886
trainer/Q Targets Std                   40.6266
trainer/Q Targets Max                   13.8994
trainer/Q Targets Min                 -229.139
trainer/Log Pis Mean                     1.78074
trainer/Log Pis Std                      2.28251
trainer/Log Pis Max                      9.33077
trainer/Log Pis Min                     -4.2921
trainer/policy/mean Mean                -0.103964
trainer/policy/mean Std                  0.815084
trainer/policy/mean Max                  0.999589
trainer/policy/mean Min                 -0.996471
trainer/policy/normal/std Mean           0.635979
trainer/policy/normal/std Std            0.0820698
trainer/policy/normal/std Max            0.903401
trainer/policy/normal/std Min            0.423118
trainer/policy/normal/log_std Mean      -0.460876
trainer/policy/normal/log_std Std        0.128794
trainer/policy/normal/log_std Max       -0.101588
trainer/policy/normal/log_std Min       -0.860104
trainer/Alpha                            0.0326923
trainer/Alpha Loss                      -0.750019
exploration/num steps total         185000
exploration/num paths total            925
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.904454
exploration/Rewards Std                  0.203368
exploration/Rewards Max                 -0.575469
exploration/Rewards Min                 -1.51021
exploration/Returns Mean              -180.891
exploration/Returns Std                 18.2595
exploration/Returns Max               -162.093
exploration/Returns Min               -208.629
exploration/Actions Mean                -0.13741
exploration/Actions Std                  0.77301
exploration/Actions Max                  0.999687
exploration/Actions Min                 -0.999995
exploration/Num Paths                    5
exploration/Average Returns           -180.891
evaluation/num steps total          887616
evaluation/num paths total            4416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948694
evaluation/Rewards Std                   0.21556
evaluation/Rewards Max                  -0.521982
evaluation/Rewards Min                  -1.65425
evaluation/Returns Mean               -190.688
evaluation/Returns Std                  25.5644
evaluation/Returns Max                -151.849
evaluation/Returns Min                -248.903
evaluation/Actions Mean                 -0.296093
evaluation/Actions Std                   0.672366
evaluation/Actions Max                   0.999945
evaluation/Actions Min                  -0.998036
evaluation/Num Paths                    24
evaluation/Average Returns            -190.688
time/data storing (s)                    0.00774834
time/evaluation sampling (s)           396.972
time/exploration sampling (s)           93.9943
time/logging (s)                         0.0274802
time/sac training (s)                    8.92673
time/saving (s)                          0.0553595
time/training (s)                        0.000111647
time/epoch (s)                         499.984
time/total (s)                      118231
Epoch                                  183
----------------------------------  ----------------
2020-11-02 18:49:54.060246 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 184 finished
----------------------------------  ----------------
replay_buffer/size                  186000
trainer/num train calls             185000
trainer/QF1 Loss                        30.9817
trainer/QF2 Loss                        25.7378
trainer/Policy Loss                    160.256
trainer/Q1 Predictions Mean           -159.651
trainer/Q1 Predictions Std              41.4177
trainer/Q1 Predictions Max              38.382
trainer/Q1 Predictions Min            -228.139
trainer/Q2 Predictions Mean           -159.507
trainer/Q2 Predictions Std              41.0052
trainer/Q2 Predictions Max              33.4004
trainer/Q2 Predictions Min            -229.022
trainer/Q Targets Mean                -160.428
trainer/Q Targets Std                   41.0738
trainer/Q Targets Max                   28.091
trainer/Q Targets Min                 -233.6
trainer/Log Pis Mean                     1.92163
trainer/Log Pis Std                      2.24755
trainer/Log Pis Max                      9.97797
trainer/Log Pis Min                     -4.9363
trainer/policy/mean Mean                -0.458336
trainer/policy/mean Std                  0.678781
trainer/policy/mean Max                  0.996656
trainer/policy/mean Min                 -0.998825
trainer/policy/normal/std Mean           0.642851
trainer/policy/normal/std Std            0.0905392
trainer/policy/normal/std Max            0.861882
trainer/policy/normal/std Min            0.305705
trainer/policy/normal/log_std Mean      -0.451966
trainer/policy/normal/log_std Std        0.143574
trainer/policy/normal/log_std Max       -0.148637
trainer/policy/normal/log_std Min       -1.18514
trainer/Alpha                            0.0319808
trainer/Alpha Loss                      -0.269791
exploration/num steps total         186000
exploration/num paths total            930
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.978284
exploration/Rewards Std                  0.207217
exploration/Rewards Max                 -0.626656
exploration/Rewards Min                 -1.60263
exploration/Returns Mean              -195.657
exploration/Returns Std                 18.4405
exploration/Returns Max               -165.147
exploration/Returns Min               -213.882
exploration/Actions Mean                -0.114574
exploration/Actions Std                  0.742659
exploration/Actions Max                  0.999995
exploration/Actions Min                 -0.99974
exploration/Num Paths                    5
exploration/Average Returns           -195.657
evaluation/num steps total          892440
evaluation/num paths total            4440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.948509
evaluation/Rewards Std                   0.204962
evaluation/Rewards Max                  -0.595213
evaluation/Rewards Min                  -1.83177
evaluation/Returns Mean               -190.65
evaluation/Returns Std                  19.0055
evaluation/Returns Max                -158.786
evaluation/Returns Min                -240.402
evaluation/Actions Mean                 -0.408313
evaluation/Actions Std                   0.632862
evaluation/Actions Max                   0.999949
evaluation/Actions Min                  -0.999998
evaluation/Num Paths                    24
evaluation/Average Returns            -190.65
time/data storing (s)                    0.0100818
time/evaluation sampling (s)           323.063
time/exploration sampling (s)          100.059
time/logging (s)                         0.0277106
time/sac training (s)                    8.58786
time/saving (s)                          0.0289109
time/training (s)                        0.000121427
time/epoch (s)                         431.777
time/total (s)                      118665
Epoch                                  184
----------------------------------  ----------------
2020-11-02 18:56:45.757205 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 185 finished
----------------------------------  ----------------
replay_buffer/size                  187000
trainer/num train calls             186000
trainer/QF1 Loss                        25.0039
trainer/QF2 Loss                        23.6207
trainer/Policy Loss                    158.596
trainer/Q1 Predictions Mean           -157.647
trainer/Q1 Predictions Std              39.4584
trainer/Q1 Predictions Max              21.5169
trainer/Q1 Predictions Min            -224.309
trainer/Q2 Predictions Mean           -158.075
trainer/Q2 Predictions Std              39.449
trainer/Q2 Predictions Max              20.0155
trainer/Q2 Predictions Min            -226.459
trainer/Q Targets Mean                -158.793
trainer/Q Targets Std                   39.6833
trainer/Q Targets Max                   26.8603
trainer/Q Targets Min                 -227.122
trainer/Log Pis Mean                     2.44157
trainer/Log Pis Std                      2.2479
trainer/Log Pis Max                      9.03759
trainer/Log Pis Min                     -4.41079
trainer/policy/mean Mean                -0.519061
trainer/policy/mean Std                  0.667132
trainer/policy/mean Max                  0.998276
trainer/policy/mean Min                 -0.997429
trainer/policy/normal/std Mean           0.624204
trainer/policy/normal/std Std            0.0952229
trainer/policy/normal/std Max            0.868814
trainer/policy/normal/std Min            0.349913
trainer/policy/normal/log_std Mean      -0.482621
trainer/policy/normal/log_std Std        0.149943
trainer/policy/normal/log_std Max       -0.140627
trainer/policy/normal/log_std Min       -1.05007
trainer/Alpha                            0.0315102
trainer/Alpha Loss                       1.52672
exploration/num steps total         187000
exploration/num paths total            935
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.949995
exploration/Rewards Std                  0.214117
exploration/Rewards Max                 -0.621541
exploration/Rewards Min                 -1.72803
exploration/Returns Mean              -189.999
exploration/Returns Std                 18.7947
exploration/Returns Max               -171.036
exploration/Returns Min               -218.001
exploration/Actions Mean                -0.149063
exploration/Actions Std                  0.76519
exploration/Actions Max                  0.999985
exploration/Actions Min                 -0.999448
exploration/Num Paths                    5
exploration/Average Returns           -189.999
evaluation/num steps total          897264
evaluation/num paths total            4464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.89283
evaluation/Rewards Std                   0.191633
evaluation/Rewards Max                  -0.550163
evaluation/Rewards Min                  -1.62623
evaluation/Returns Mean               -179.459
evaluation/Returns Std                  14.4919
evaluation/Returns Max                -152.97
evaluation/Returns Min                -211.73
evaluation/Actions Mean                 -0.464429
evaluation/Actions Std                   0.612358
evaluation/Actions Max                   0.998358
evaluation/Actions Min                  -0.999848
evaluation/Num Paths                    24
evaluation/Average Returns            -179.459
time/data storing (s)                    0.00859421
time/evaluation sampling (s)           317.267
time/exploration sampling (s)           85.0234
time/logging (s)                         0.0185793
time/sac training (s)                    8.12646
time/saving (s)                          0.0275296
time/training (s)                        0.000106632
time/epoch (s)                         410.472
time/total (s)                      119076
Epoch                                  185
----------------------------------  ----------------
2020-11-02 19:04:19.313549 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 186 finished
----------------------------------  ----------------
replay_buffer/size                  188000
trainer/num train calls             187000
trainer/QF1 Loss                        78.3463
trainer/QF2 Loss                        78.6198
trainer/Policy Loss                    162.544
trainer/Q1 Predictions Mean           -161.797
trainer/Q1 Predictions Std              41.2831
trainer/Q1 Predictions Max             -20.184
trainer/Q1 Predictions Min            -227.297
trainer/Q2 Predictions Mean           -161.769
trainer/Q2 Predictions Std              41.369
trainer/Q2 Predictions Max             -21.3732
trainer/Q2 Predictions Min            -227.645
trainer/Q Targets Mean                -161.167
trainer/Q Targets Std                   42.4861
trainer/Q Targets Max                    7.70507
trainer/Q Targets Min                 -224.211
trainer/Log Pis Mean                     2.05409
trainer/Log Pis Std                      2.19281
trainer/Log Pis Max                     10.1042
trainer/Log Pis Min                     -4.35228
trainer/policy/mean Mean                -0.14768
trainer/policy/mean Std                  0.820117
trainer/policy/mean Max                  0.999753
trainer/policy/mean Min                 -0.995908
trainer/policy/normal/std Mean           0.641413
trainer/policy/normal/std Std            0.0969213
trainer/policy/normal/std Max            1.063
trainer/policy/normal/std Min            0.337799
trainer/policy/normal/log_std Mean      -0.455564
trainer/policy/normal/log_std Std        0.15218
trainer/policy/normal/log_std Max        0.0610951
trainer/policy/normal/log_std Min       -1.0853
trainer/Alpha                            0.029868
trainer/Alpha Loss                       0.189919
exploration/num steps total         188000
exploration/num paths total            940
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00675
exploration/Rewards Std                  0.187224
exploration/Rewards Max                 -0.616762
exploration/Rewards Min                 -1.52304
exploration/Returns Mean              -201.35
exploration/Returns Std                 28.3067
exploration/Returns Max               -160.429
exploration/Returns Min               -237.087
exploration/Actions Mean                -0.0129591
exploration/Actions Std                  0.742629
exploration/Actions Max                  0.999727
exploration/Actions Min                 -0.999351
exploration/Num Paths                    5
exploration/Average Returns           -201.35
evaluation/num steps total          902088
evaluation/num paths total            4488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.923949
evaluation/Rewards Std                   0.214538
evaluation/Rewards Max                  -0.537877
evaluation/Rewards Min                  -1.70705
evaluation/Returns Mean               -185.714
evaluation/Returns Std                  20.9673
evaluation/Returns Max                -146.337
evaluation/Returns Min                -234.941
evaluation/Actions Mean                 -0.340881
evaluation/Actions Std                   0.688801
evaluation/Actions Max                   0.998216
evaluation/Actions Min                  -0.998685
evaluation/Num Paths                    24
evaluation/Average Returns            -185.714
time/data storing (s)                    0.00777995
time/evaluation sampling (s)           341.568
time/exploration sampling (s)          102.488
time/logging (s)                         0.0220138
time/sac training (s)                    8.20048
time/saving (s)                          0.0298132
time/training (s)                        0.000111801
time/epoch (s)                         452.316
time/total (s)                      119530
Epoch                                  186
----------------------------------  ----------------
2020-11-02 19:11:15.103081 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 187 finished
----------------------------------  ----------------
replay_buffer/size                  189000
trainer/num train calls             188000
trainer/QF1 Loss                        26.8748
trainer/QF2 Loss                        28.4413
trainer/Policy Loss                    163.85
trainer/Q1 Predictions Mean           -163.03
trainer/Q1 Predictions Std              39.9553
trainer/Q1 Predictions Max             -57.1183
trainer/Q1 Predictions Min            -226.766
trainer/Q2 Predictions Mean           -162.962
trainer/Q2 Predictions Std              40.1807
trainer/Q2 Predictions Max             -56.3684
trainer/Q2 Predictions Min            -227.137
trainer/Q Targets Mean                -163.159
trainer/Q Targets Std                   40.0864
trainer/Q Targets Max                  -58.2984
trainer/Q Targets Min                 -228.56
trainer/Log Pis Mean                     1.94292
trainer/Log Pis Std                      2.26411
trainer/Log Pis Max                      9.58357
trainer/Log Pis Min                     -5.88493
trainer/policy/mean Mean                -0.178942
trainer/policy/mean Std                  0.799983
trainer/policy/mean Max                  0.995698
trainer/policy/mean Min                 -0.998194
trainer/policy/normal/std Mean           0.651741
trainer/policy/normal/std Std            0.0936637
trainer/policy/normal/std Max            0.907693
trainer/policy/normal/std Min            0.430984
trainer/policy/normal/log_std Mean      -0.438337
trainer/policy/normal/log_std Std        0.142895
trainer/policy/normal/log_std Max       -0.0968494
trainer/policy/normal/log_std Min       -0.841684
trainer/Alpha                            0.0305302
trainer/Alpha Loss                      -0.199168
exploration/num steps total         189000
exploration/num paths total            945
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.877977
exploration/Rewards Std                  0.193476
exploration/Rewards Max                 -0.548914
exploration/Rewards Min                 -1.44308
exploration/Returns Mean              -175.595
exploration/Returns Std                 16.9638
exploration/Returns Max               -150.19
exploration/Returns Min               -202.935
exploration/Actions Mean                -0.294078
exploration/Actions Std                  0.707871
exploration/Actions Max                  0.998318
exploration/Actions Min                 -0.999863
exploration/Num Paths                    5
exploration/Average Returns           -175.595
evaluation/num steps total          906912
evaluation/num paths total            4512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.931678
evaluation/Rewards Std                   0.192285
evaluation/Rewards Max                  -0.577686
evaluation/Rewards Min                  -1.90016
evaluation/Returns Mean               -187.267
evaluation/Returns Std                  17.3555
evaluation/Returns Max                -164.202
evaluation/Returns Min                -223.419
evaluation/Actions Mean                 -0.352062
evaluation/Actions Std                   0.682934
evaluation/Actions Max                   0.998581
evaluation/Actions Min                  -0.999494
evaluation/Num Paths                    24
evaluation/Average Returns            -187.267
time/data storing (s)                    0.00611042
time/evaluation sampling (s)           332.154
time/exploration sampling (s)           74.9154
time/logging (s)                         0.0194435
time/sac training (s)                    8.05807
time/saving (s)                          0.0196413
time/training (s)                        0.000110511
time/epoch (s)                         415.173
time/total (s)                      119946
Epoch                                  187
----------------------------------  ----------------
2020-11-02 19:18:07.531762 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 188 finished
----------------------------------  ----------------
replay_buffer/size                  190000
trainer/num train calls             189000
trainer/QF1 Loss                        29.9676
trainer/QF2 Loss                        27.0779
trainer/Policy Loss                    159.257
trainer/Q1 Predictions Mean           -158.796
trainer/Q1 Predictions Std              43.3961
trainer/Q1 Predictions Max               6.22127
trainer/Q1 Predictions Min            -228.456
trainer/Q2 Predictions Mean           -158.363
trainer/Q2 Predictions Std              43.0856
trainer/Q2 Predictions Max               4.03291
trainer/Q2 Predictions Min            -226.641
trainer/Q Targets Mean                -158.995
trainer/Q Targets Std                   43.4108
trainer/Q Targets Max                    3.35792
trainer/Q Targets Min                 -227.551
trainer/Log Pis Mean                     2.07146
trainer/Log Pis Std                      2.21112
trainer/Log Pis Max                      8.90594
trainer/Log Pis Min                     -6.29843
trainer/policy/mean Mean                -0.377722
trainer/policy/mean Std                  0.740279
trainer/policy/mean Max                  0.998207
trainer/policy/mean Min                 -0.998617
trainer/policy/normal/std Mean           0.657662
trainer/policy/normal/std Std            0.101623
trainer/policy/normal/std Max            0.933932
trainer/policy/normal/std Min            0.287203
trainer/policy/normal/log_std Mean      -0.430973
trainer/policy/normal/log_std Std        0.154756
trainer/policy/normal/log_std Max       -0.0683516
trainer/policy/normal/log_std Min       -1.24757
trainer/Alpha                            0.0320196
trainer/Alpha Loss                       0.245917
exploration/num steps total         190000
exploration/num paths total            950
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.921176
exploration/Rewards Std                  0.244426
exploration/Rewards Max                 -0.584377
exploration/Rewards Min                 -1.60656
exploration/Returns Mean              -184.235
exploration/Returns Std                 31.0966
exploration/Returns Max               -159.876
exploration/Returns Min               -243.734
exploration/Actions Mean                -0.355891
exploration/Actions Std                  0.728437
exploration/Actions Max                  0.999792
exploration/Actions Min                 -0.999813
exploration/Num Paths                    5
exploration/Average Returns           -184.235
evaluation/num steps total          911736
evaluation/num paths total            4536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.885055
evaluation/Rewards Std                   0.189275
evaluation/Rewards Max                  -0.607186
evaluation/Rewards Min                  -1.49605
evaluation/Returns Mean               -177.896
evaluation/Returns Std                  11.7793
evaluation/Returns Max                -156.945
evaluation/Returns Min                -202.5
evaluation/Actions Mean                 -0.347749
evaluation/Actions Std                   0.666978
evaluation/Actions Max                   0.999831
evaluation/Actions Min                  -0.999622
evaluation/Num Paths                    24
evaluation/Average Returns            -177.896
time/data storing (s)                    0.00637179
time/evaluation sampling (s)           321.119
time/exploration sampling (s)           82.1316
time/logging (s)                         0.0186742
time/sac training (s)                    8.46624
time/saving (s)                          0.0252784
time/training (s)                        0.000108645
time/epoch (s)                         411.768
time/total (s)                      120358
Epoch                                  188
----------------------------------  ----------------
2020-11-02 19:25:32.683887 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 189 finished
----------------------------------  ----------------
replay_buffer/size                  191000
trainer/num train calls             190000
trainer/QF1 Loss                       107.094
trainer/QF2 Loss                       107.05
trainer/Policy Loss                    155.992
trainer/Q1 Predictions Mean           -155.577
trainer/Q1 Predictions Std              45.9986
trainer/Q1 Predictions Max              36.253
trainer/Q1 Predictions Min            -235.797
trainer/Q2 Predictions Mean           -155.19
trainer/Q2 Predictions Std              46.2764
trainer/Q2 Predictions Max              45.5321
trainer/Q2 Predictions Min            -233.817
trainer/Q Targets Mean                -155.827
trainer/Q Targets Std                   48.2618
trainer/Q Targets Max                   47.9947
trainer/Q Targets Min                 -231.631
trainer/Log Pis Mean                     1.76287
trainer/Log Pis Std                      2.25705
trainer/Log Pis Max                     11.0869
trainer/Log Pis Min                     -4.11055
trainer/policy/mean Mean                -0.293187
trainer/policy/mean Std                  0.7723
trainer/policy/mean Max                  0.999781
trainer/policy/mean Min                 -0.996585
trainer/policy/normal/std Mean           0.61874
trainer/policy/normal/std Std            0.088679
trainer/policy/normal/std Max            0.833723
trainer/policy/normal/std Min            0.328012
trainer/policy/normal/log_std Mean      -0.4905
trainer/policy/normal/log_std Std        0.14544
trainer/policy/normal/log_std Max       -0.181854
trainer/policy/normal/log_std Min       -1.11471
trainer/Alpha                            0.0333796
trainer/Alpha Loss                      -0.806201
exploration/num steps total         191000
exploration/num paths total            955
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.923801
exploration/Rewards Std                  0.190812
exploration/Rewards Max                 -0.593011
exploration/Rewards Min                 -1.55746
exploration/Returns Mean              -184.76
exploration/Returns Std                 20.332
exploration/Returns Max               -163.199
exploration/Returns Min               -212.274
exploration/Actions Mean                -0.275188
exploration/Actions Std                  0.65922
exploration/Actions Max                  0.998859
exploration/Actions Min                 -0.998106
exploration/Num Paths                    5
exploration/Average Returns           -184.76
evaluation/num steps total          916560
evaluation/num paths total            4560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.902105
evaluation/Rewards Std                   0.192581
evaluation/Rewards Max                  -0.562594
evaluation/Rewards Min                  -1.55396
evaluation/Returns Mean               -181.323
evaluation/Returns Std                  15.0603
evaluation/Returns Max                -151.257
evaluation/Returns Min                -205.067
evaluation/Actions Mean                 -0.400752
evaluation/Actions Std                   0.640421
evaluation/Actions Max                   0.999865
evaluation/Actions Min                  -0.998354
evaluation/Num Paths                    24
evaluation/Average Returns            -181.323
time/data storing (s)                    0.0119148
time/evaluation sampling (s)           333.083
time/exploration sampling (s)           99.9
time/logging (s)                         0.0440603
time/sac training (s)                   10.4096
time/saving (s)                          0.0472402
time/training (s)                        0.000110608
time/epoch (s)                         443.496
time/total (s)                      120803
Epoch                                  189
----------------------------------  ----------------
2020-11-02 19:33:21.472547 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 190 finished
----------------------------------  ----------------
replay_buffer/size                  192000
trainer/num train calls             191000
trainer/QF1 Loss                        70.9102
trainer/QF2 Loss                        79.6836
trainer/Policy Loss                    162.139
trainer/Q1 Predictions Mean           -161.297
trainer/Q1 Predictions Std              40.0981
trainer/Q1 Predictions Max             -68.4632
trainer/Q1 Predictions Min            -227.576
trainer/Q2 Predictions Mean           -161.156
trainer/Q2 Predictions Std              40.3697
trainer/Q2 Predictions Max             -69.8005
trainer/Q2 Predictions Min            -227.673
trainer/Q Targets Mean                -162.386
trainer/Q Targets Std                   41.1444
trainer/Q Targets Max                   -0.68699
trainer/Q Targets Min                 -229.493
trainer/Log Pis Mean                     2.0056
trainer/Log Pis Std                      2.37272
trainer/Log Pis Max                      9.19238
trainer/Log Pis Min                     -4.75988
trainer/policy/mean Mean                -0.498092
trainer/policy/mean Std                  0.669197
trainer/policy/mean Max                  0.997078
trainer/policy/mean Min                 -0.999328
trainer/policy/normal/std Mean           0.655495
trainer/policy/normal/std Std            0.104782
trainer/policy/normal/std Max            0.943663
trainer/policy/normal/std Min            0.376388
trainer/policy/normal/log_std Mean      -0.434986
trainer/policy/normal/log_std Std        0.158806
trainer/policy/normal/log_std Max       -0.0579867
trainer/policy/normal/log_std Min       -0.977135
trainer/Alpha                            0.0329121
trainer/Alpha Loss                       0.0191124
exploration/num steps total         192000
exploration/num paths total            960
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.915647
exploration/Rewards Std                  0.184285
exploration/Rewards Max                 -0.621325
exploration/Rewards Min                 -1.46972
exploration/Returns Mean              -183.129
exploration/Returns Std                 14.9098
exploration/Returns Max               -159.648
exploration/Returns Min               -206.721
exploration/Actions Mean                -0.266086
exploration/Actions Std                  0.700953
exploration/Actions Max                  0.997812
exploration/Actions Min                 -0.999699
exploration/Num Paths                    5
exploration/Average Returns           -183.129
evaluation/num steps total          921384
evaluation/num paths total            4584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.952957
evaluation/Rewards Std                   0.215044
evaluation/Rewards Max                  -0.561978
evaluation/Rewards Min                  -1.71421
evaluation/Returns Mean               -191.544
evaluation/Returns Std                  24.4387
evaluation/Returns Max                -165.696
evaluation/Returns Min                -251.053
evaluation/Actions Mean                 -0.375617
evaluation/Actions Std                   0.655421
evaluation/Actions Max                   0.998485
evaluation/Actions Min                  -0.998559
evaluation/Num Paths                    24
evaluation/Average Returns            -191.544
time/data storing (s)                    0.0123618
time/evaluation sampling (s)           359.223
time/exploration sampling (s)           99.0394
time/logging (s)                         0.0719806
time/sac training (s)                    8.38615
time/saving (s)                          0.0703128
time/training (s)                        0.000109399
time/epoch (s)                         466.803
time/total (s)                      121272
Epoch                                  190
----------------------------------  ----------------
2020-11-02 19:40:56.824515 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 191 finished
----------------------------------  ----------------
replay_buffer/size                  193000
trainer/num train calls             192000
trainer/QF1 Loss                        26.431
trainer/QF2 Loss                        28.4276
trainer/Policy Loss                    160.051
trainer/Q1 Predictions Mean           -159.486
trainer/Q1 Predictions Std              42.6364
trainer/Q1 Predictions Max              53.1455
trainer/Q1 Predictions Min            -234.717
trainer/Q2 Predictions Mean           -158.885
trainer/Q2 Predictions Std              42.6841
trainer/Q2 Predictions Max              53.0211
trainer/Q2 Predictions Min            -227.665
trainer/Q Targets Mean                -160.144
trainer/Q Targets Std                   43.4361
trainer/Q Targets Max                   47.3618
trainer/Q Targets Min                 -234.874
trainer/Log Pis Mean                     2.10414
trainer/Log Pis Std                      2.28255
trainer/Log Pis Max                      9.94817
trainer/Log Pis Min                     -3.23927
trainer/policy/mean Mean                -0.395849
trainer/policy/mean Std                  0.717921
trainer/policy/mean Max                  0.999884
trainer/policy/mean Min                 -0.995735
trainer/policy/normal/std Mean           0.646225
trainer/policy/normal/std Std            0.106829
trainer/policy/normal/std Max            0.91842
trainer/policy/normal/std Min            0.25688
trainer/policy/normal/log_std Mean      -0.450913
trainer/policy/normal/log_std Std        0.172185
trainer/policy/normal/log_std Max       -0.0851003
trainer/policy/normal/log_std Min       -1.35915
trainer/Alpha                            0.0318658
trainer/Alpha Loss                       0.358889
exploration/num steps total         193000
exploration/num paths total            965
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.946693
exploration/Rewards Std                  0.175499
exploration/Rewards Max                 -0.611627
exploration/Rewards Min                 -1.47573
exploration/Returns Mean              -189.339
exploration/Returns Std                 12.6467
exploration/Returns Max               -174.778
exploration/Returns Min               -212.201
exploration/Actions Mean                -0.223423
exploration/Actions Std                  0.722066
exploration/Actions Max                  0.999245
exploration/Actions Min                 -0.998158
exploration/Num Paths                    5
exploration/Average Returns           -189.339
evaluation/num steps total          926208
evaluation/num paths total            4608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.930885
evaluation/Rewards Std                   0.198477
evaluation/Rewards Max                  -0.564324
evaluation/Rewards Min                  -1.58309
evaluation/Returns Mean               -187.108
evaluation/Returns Std                  18.0429
evaluation/Returns Max                -152.402
evaluation/Returns Min                -229.52
evaluation/Actions Mean                 -0.396092
evaluation/Actions Std                   0.624594
evaluation/Actions Max                   0.999632
evaluation/Actions Min                  -0.997696
evaluation/Num Paths                    24
evaluation/Average Returns            -187.108
time/data storing (s)                    0.0346318
time/evaluation sampling (s)           353.754
time/exploration sampling (s)           89.8423
time/logging (s)                         0.0330046
time/sac training (s)                   10.0111
time/saving (s)                          0.0309947
time/training (s)                        0.000125255
time/epoch (s)                         453.706
time/total (s)                      121727
Epoch                                  191
----------------------------------  ----------------
2020-11-02 19:49:04.135131 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 192 finished
----------------------------------  ---------------
replay_buffer/size                  194000
trainer/num train calls             193000
trainer/QF1 Loss                        28.0506
trainer/QF2 Loss                        25.295
trainer/Policy Loss                    164.98
trainer/Q1 Predictions Mean           -164.276
trainer/Q1 Predictions Std              41.0692
trainer/Q1 Predictions Max             -39.5029
trainer/Q1 Predictions Min            -235.39
trainer/Q2 Predictions Mean           -164.118
trainer/Q2 Predictions Std              40.5863
trainer/Q2 Predictions Max             -39.7696
trainer/Q2 Predictions Min            -235.395
trainer/Q Targets Mean                -163.731
trainer/Q Targets Std                   40.5198
trainer/Q Targets Max                  -45.1453
trainer/Q Targets Min                 -232.002
trainer/Log Pis Mean                     1.88709
trainer/Log Pis Std                      2.4074
trainer/Log Pis Max                      9.75523
trainer/Log Pis Min                     -4.11049
trainer/policy/mean Mean                -0.165962
trainer/policy/mean Std                  0.813311
trainer/policy/mean Max                  0.999741
trainer/policy/mean Min                 -0.993764
trainer/policy/normal/std Mean           0.644766
trainer/policy/normal/std Std            0.105704
trainer/policy/normal/std Max            0.959691
trainer/policy/normal/std Min            0.308305
trainer/policy/normal/log_std Mean      -0.452483
trainer/policy/normal/log_std Std        0.16618
trainer/policy/normal/log_std Max       -0.0411434
trainer/policy/normal/log_std Min       -1.17667
trainer/Alpha                            0.0308825
trainer/Alpha Loss                      -0.392637
exploration/num steps total         194000
exploration/num paths total            970
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.03837
exploration/Rewards Std                  0.131295
exploration/Rewards Max                 -0.712644
exploration/Rewards Min                 -1.49412
exploration/Returns Mean              -207.673
exploration/Returns Std                 18.188
exploration/Returns Max               -174.302
exploration/Returns Min               -228.268
exploration/Actions Mean                -0.0337239
exploration/Actions Std                  0.770449
exploration/Actions Max                  0.999873
exploration/Actions Min                 -0.997436
exploration/Num Paths                    5
exploration/Average Returns           -207.673
evaluation/num steps total          931032
evaluation/num paths total            4632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.933054
evaluation/Rewards Std                   0.224915
evaluation/Rewards Max                  -0.582892
evaluation/Rewards Min                  -1.82207
evaluation/Returns Mean               -187.544
evaluation/Returns Std                  21.1179
evaluation/Returns Max                -162.648
evaluation/Returns Min                -235.268
evaluation/Actions Mean                 -0.384156
evaluation/Actions Std                   0.643363
evaluation/Actions Max                   0.991549
evaluation/Actions Min                  -0.994766
evaluation/Num Paths                    24
evaluation/Average Returns            -187.544
time/data storing (s)                    0.00679332
time/evaluation sampling (s)           373.435
time/exploration sampling (s)          103.366
time/logging (s)                         0.026469
time/sac training (s)                    8.86655
time/saving (s)                          0.0409439
time/training (s)                        0.00011068
time/epoch (s)                         485.742
time/total (s)                      122214
Epoch                                  192
----------------------------------  ---------------
2020-11-02 19:56:05.534718 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 193 finished
----------------------------------  ----------------
replay_buffer/size                  195000
trainer/num train calls             194000
trainer/QF1 Loss                        72.8459
trainer/QF2 Loss                        69.8645
trainer/Policy Loss                    165.897
trainer/Q1 Predictions Mean           -164.819
trainer/Q1 Predictions Std              36.8235
trainer/Q1 Predictions Max             -70.7299
trainer/Q1 Predictions Min            -230.565
trainer/Q2 Predictions Mean           -165.218
trainer/Q2 Predictions Std              36.8914
trainer/Q2 Predictions Max             -72.5314
trainer/Q2 Predictions Min            -230.884
trainer/Q Targets Mean                -164.486
trainer/Q Targets Std                   37.5335
trainer/Q Targets Max                   -0.756539
trainer/Q Targets Min                 -231.666
trainer/Log Pis Mean                     1.45739
trainer/Log Pis Std                      2.07875
trainer/Log Pis Max                      8.77965
trainer/Log Pis Min                     -5.98572
trainer/policy/mean Mean                -0.316193
trainer/policy/mean Std                  0.736392
trainer/policy/mean Max                  0.999901
trainer/policy/mean Min                 -0.991573
trainer/policy/normal/std Mean           0.696957
trainer/policy/normal/std Std            0.130437
trainer/policy/normal/std Max            1.05122
trainer/policy/normal/std Min            0.433304
trainer/policy/normal/log_std Mean      -0.378363
trainer/policy/normal/log_std Std        0.185954
trainer/policy/normal/log_std Max        0.0499521
trainer/policy/normal/log_std Min       -0.836315
trainer/Alpha                            0.0306052
trainer/Alpha Loss                      -1.89186
exploration/num steps total         195000
exploration/num paths total            975
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.923591
exploration/Rewards Std                  0.182494
exploration/Rewards Max                 -0.603076
exploration/Rewards Min                 -1.49094
exploration/Returns Mean              -184.718
exploration/Returns Std                 17.8512
exploration/Returns Max               -170.014
exploration/Returns Min               -210.948
exploration/Actions Mean                -0.177298
exploration/Actions Std                  0.707349
exploration/Actions Max                  0.999077
exploration/Actions Min                 -0.999751
exploration/Num Paths                    5
exploration/Average Returns           -184.718
evaluation/num steps total          935856
evaluation/num paths total            4656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.978186
evaluation/Rewards Std                   0.20576
evaluation/Rewards Max                  -0.551439
evaluation/Rewards Min                  -1.81036
evaluation/Returns Mean               -196.615
evaluation/Returns Std                  26.4494
evaluation/Returns Max                -164.011
evaluation/Returns Min                -259.351
evaluation/Actions Mean                 -0.415254
evaluation/Actions Std                   0.609981
evaluation/Actions Max                   0.98929
evaluation/Actions Min                  -0.99912
evaluation/Num Paths                    24
evaluation/Average Returns            -196.615
time/data storing (s)                    0.0114679
time/evaluation sampling (s)           312.9
time/exploration sampling (s)           98.229
time/logging (s)                         0.0440153
time/sac training (s)                    8.78347
time/saving (s)                          0.0441142
time/training (s)                        0.000107205
time/epoch (s)                         420.012
time/total (s)                      122636
Epoch                                  193
----------------------------------  ----------------
2020-11-02 20:04:25.218190 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 194 finished
----------------------------------  ----------------
replay_buffer/size                  196000
trainer/num train calls             195000
trainer/QF1 Loss                        32.1255
trainer/QF2 Loss                        29.496
trainer/Policy Loss                    162.793
trainer/Q1 Predictions Mean           -162.084
trainer/Q1 Predictions Std              43.0801
trainer/Q1 Predictions Max             -19.4905
trainer/Q1 Predictions Min            -231.803
trainer/Q2 Predictions Mean           -161.776
trainer/Q2 Predictions Std              42.2827
trainer/Q2 Predictions Max             -24.156
trainer/Q2 Predictions Min            -230.403
trainer/Q Targets Mean                -162.082
trainer/Q Targets Std                   42.4035
trainer/Q Targets Max                  -25.3358
trainer/Q Targets Min                 -228.933
trainer/Log Pis Mean                     1.4716
trainer/Log Pis Std                      2.23018
trainer/Log Pis Max                      9.36891
trainer/Log Pis Min                     -4.55035
trainer/policy/mean Mean                -0.121104
trainer/policy/mean Std                  0.795147
trainer/policy/mean Max                  0.999979
trainer/policy/mean Min                 -0.993845
trainer/policy/normal/std Mean           0.641331
trainer/policy/normal/std Std            0.0878363
trainer/policy/normal/std Max            0.893113
trainer/policy/normal/std Min            0.390883
trainer/policy/normal/log_std Mean      -0.453478
trainer/policy/normal/log_std Std        0.13599
trainer/policy/normal/log_std Max       -0.113042
trainer/policy/normal/log_std Min       -0.939346
trainer/Alpha                            0.0322961
trainer/Alpha Loss                      -1.81389
exploration/num steps total         196000
exploration/num paths total            980
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.883732
exploration/Rewards Std                  0.175483
exploration/Rewards Max                 -0.544177
exploration/Rewards Min                 -1.40718
exploration/Returns Mean              -176.746
exploration/Returns Std                 18.5511
exploration/Returns Max               -159.678
exploration/Returns Min               -212.493
exploration/Actions Mean                -0.276258
exploration/Actions Std                  0.679203
exploration/Actions Max                  0.999022
exploration/Actions Min                 -0.99936
exploration/Num Paths                    5
exploration/Average Returns           -176.746
evaluation/num steps total          940680
evaluation/num paths total            4680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.897974
evaluation/Rewards Std                   0.201524
evaluation/Rewards Max                  -0.507725
evaluation/Rewards Min                  -1.5663
evaluation/Returns Mean               -180.493
evaluation/Returns Std                  17.2417
evaluation/Returns Max                -150.29
evaluation/Returns Min                -211.074
evaluation/Actions Mean                 -0.275676
evaluation/Actions Std                   0.683962
evaluation/Actions Max                   0.999994
evaluation/Actions Min                  -0.999062
evaluation/Num Paths                    24
evaluation/Average Returns            -180.493
time/data storing (s)                    0.0175228
time/evaluation sampling (s)           372.319
time/exploration sampling (s)          116.038
time/logging (s)                         0.0352512
time/sac training (s)                    9.36273
time/saving (s)                          0.0407249
time/training (s)                        0.000115288
time/epoch (s)                         497.813
time/total (s)                      123135
Epoch                                  194
----------------------------------  ----------------
2020-11-02 20:13:15.992760 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 195 finished
----------------------------------  ---------------
replay_buffer/size                  197000
trainer/num train calls             196000
trainer/QF1 Loss                       102.474
trainer/QF2 Loss                        95.567
trainer/Policy Loss                    155.582
trainer/Q1 Predictions Mean           -154.968
trainer/Q1 Predictions Std              45.241
trainer/Q1 Predictions Max               5.35567
trainer/Q1 Predictions Min            -230.222
trainer/Q2 Predictions Mean           -154.796
trainer/Q2 Predictions Std              45.4071
trainer/Q2 Predictions Max               6.05397
trainer/Q2 Predictions Min            -230.548
trainer/Q Targets Mean                -153.252
trainer/Q Targets Std                   46.861
trainer/Q Targets Max                   17.241
trainer/Q Targets Min                 -228.429
trainer/Log Pis Mean                     2.12001
trainer/Log Pis Std                      2.19802
trainer/Log Pis Max                      8.17723
trainer/Log Pis Min                     -5.21819
trainer/policy/mean Mean                -0.221901
trainer/policy/mean Std                  0.810483
trainer/policy/mean Max                  0.999552
trainer/policy/mean Min                 -0.998422
trainer/policy/normal/std Mean           0.630005
trainer/policy/normal/std Std            0.10145
trainer/policy/normal/std Max            1.00312
trainer/policy/normal/std Min            0.390718
trainer/policy/normal/log_std Mean      -0.474837
trainer/policy/normal/log_std Std        0.159868
trainer/policy/normal/log_std Max        0.00311901
trainer/policy/normal/log_std Min       -0.93977
trainer/Alpha                            0.0311099
trainer/Alpha Loss                       0.416458
exploration/num steps total         197000
exploration/num paths total            985
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.893281
exploration/Rewards Std                  0.185848
exploration/Rewards Max                 -0.62742
exploration/Rewards Min                 -1.5107
exploration/Returns Mean              -178.656
exploration/Returns Std                 15.5586
exploration/Returns Max               -161.021
exploration/Returns Min               -203.091
exploration/Actions Mean                -0.320629
exploration/Actions Std                  0.701556
exploration/Actions Max                  0.999595
exploration/Actions Min                 -0.99909
exploration/Num Paths                    5
exploration/Average Returns           -178.656
evaluation/num steps total          945504
evaluation/num paths total            4704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.966033
evaluation/Rewards Std                   0.210283
evaluation/Rewards Max                  -0.570499
evaluation/Rewards Min                  -1.61227
evaluation/Returns Mean               -194.173
evaluation/Returns Std                  25.1545
evaluation/Returns Max                -162.971
evaluation/Returns Min                -260.156
evaluation/Actions Mean                 -0.329998
evaluation/Actions Std                   0.672189
evaluation/Actions Max                   0.999559
evaluation/Actions Min                  -0.998889
evaluation/Num Paths                    24
evaluation/Average Returns            -194.173
time/data storing (s)                    0.0153939
time/evaluation sampling (s)           410.932
time/exploration sampling (s)          107.031
time/logging (s)                         0.0528407
time/sac training (s)                   10.9815
time/saving (s)                          0.0706335
time/training (s)                        0.00011444
time/epoch (s)                         529.083
time/total (s)                      123666
Epoch                                  195
----------------------------------  ---------------
2020-11-02 20:21:28.140669 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 196 finished
----------------------------------  ----------------
replay_buffer/size                  198000
trainer/num train calls             197000
trainer/QF1 Loss                       161.386
trainer/QF2 Loss                       158.185
trainer/Policy Loss                    160.657
trainer/Q1 Predictions Mean           -160.063
trainer/Q1 Predictions Std              40.0949
trainer/Q1 Predictions Max             -54.1632
trainer/Q1 Predictions Min            -226.529
trainer/Q2 Predictions Mean           -159.9
trainer/Q2 Predictions Std              40.4431
trainer/Q2 Predictions Max             -52.5083
trainer/Q2 Predictions Min            -226.237
trainer/Q Targets Mean                -158.486
trainer/Q Targets Std                   43.1406
trainer/Q Targets Max                   -0.580229
trainer/Q Targets Min                 -226.724
trainer/Log Pis Mean                     1.93047
trainer/Log Pis Std                      2.09773
trainer/Log Pis Max                      8.2263
trainer/Log Pis Min                     -4.77008
trainer/policy/mean Mean                -0.285417
trainer/policy/mean Std                  0.764738
trainer/policy/mean Max                  0.998974
trainer/policy/mean Min                 -0.997593
trainer/policy/normal/std Mean           0.646563
trainer/policy/normal/std Std            0.100722
trainer/policy/normal/std Max            0.894828
trainer/policy/normal/std Min            0.387408
trainer/policy/normal/log_std Mean      -0.44831
trainer/policy/normal/log_std Std        0.156994
trainer/policy/normal/log_std Max       -0.111123
trainer/policy/normal/log_std Min       -0.948277
trainer/Alpha                            0.0312065
trainer/Alpha Loss                      -0.241076
exploration/num steps total         198000
exploration/num paths total            990
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.899352
exploration/Rewards Std                  0.214266
exploration/Rewards Max                 -0.554567
exploration/Rewards Min                 -1.41352
exploration/Returns Mean              -179.87
exploration/Returns Std                 25.7356
exploration/Returns Max               -159.444
exploration/Returns Min               -229.104
exploration/Actions Mean                -0.359438
exploration/Actions Std                  0.714366
exploration/Actions Max                  0.998508
exploration/Actions Min                 -0.99941
exploration/Num Paths                    5
exploration/Average Returns           -179.87
evaluation/num steps total          950328
evaluation/num paths total            4728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.921764
evaluation/Rewards Std                   0.209926
evaluation/Rewards Max                  -0.543131
evaluation/Rewards Min                  -1.74564
evaluation/Returns Mean               -185.275
evaluation/Returns Std                  19.0893
evaluation/Returns Max                -157.001
evaluation/Returns Min                -239.842
evaluation/Actions Mean                 -0.399107
evaluation/Actions Std                   0.650203
evaluation/Actions Max                   0.999167
evaluation/Actions Min                  -0.999977
evaluation/Num Paths                    24
evaluation/Average Returns            -185.275
time/data storing (s)                    0.0120664
time/evaluation sampling (s)           382.23
time/exploration sampling (s)           93.0175
time/logging (s)                         0.120973
time/sac training (s)                   14.918
time/saving (s)                          0.079264
time/training (s)                        0.000106053
time/epoch (s)                         490.378
time/total (s)                      124158
Epoch                                  196
----------------------------------  ----------------
2020-11-02 20:29:40.395457 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 197 finished
----------------------------------  ----------------
replay_buffer/size                  199000
trainer/num train calls             198000
trainer/QF1 Loss                        25.9694
trainer/QF2 Loss                        23.7329
trainer/Policy Loss                    162.315
trainer/Q1 Predictions Mean           -161.822
trainer/Q1 Predictions Std              38.6226
trainer/Q1 Predictions Max             -30.4001
trainer/Q1 Predictions Min            -227.578
trainer/Q2 Predictions Mean           -161.263
trainer/Q2 Predictions Std              38.4342
trainer/Q2 Predictions Max             -28.6113
trainer/Q2 Predictions Min            -228.214
trainer/Q Targets Mean                -161.215
trainer/Q Targets Std                   38.4428
trainer/Q Targets Max                  -25.9709
trainer/Q Targets Min                 -226.339
trainer/Log Pis Mean                     2.08097
trainer/Log Pis Std                      2.26105
trainer/Log Pis Max                     10.3951
trainer/Log Pis Min                     -6.60473
trainer/policy/mean Mean                -0.33277
trainer/policy/mean Std                  0.757917
trainer/policy/mean Max                  0.99973
trainer/policy/mean Min                 -0.999195
trainer/policy/normal/std Mean           0.645872
trainer/policy/normal/std Std            0.0903241
trainer/policy/normal/std Max            0.926753
trainer/policy/normal/std Min            0.351675
trainer/policy/normal/log_std Mean      -0.446767
trainer/policy/normal/log_std Std        0.13838
trainer/policy/normal/log_std Max       -0.076068
trainer/policy/normal/log_std Min       -1.04505
trainer/Alpha                            0.0310502
trainer/Alpha Loss                       0.281138
exploration/num steps total         199000
exploration/num paths total            995
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.942432
exploration/Rewards Std                  0.201325
exploration/Rewards Max                 -0.65569
exploration/Rewards Min                 -1.54299
exploration/Returns Mean              -188.486
exploration/Returns Std                 18.0971
exploration/Returns Max               -170.431
exploration/Returns Min               -222.347
exploration/Actions Mean                -0.318418
exploration/Actions Std                  0.676375
exploration/Actions Max                  0.998059
exploration/Actions Min                 -0.999756
exploration/Num Paths                    5
exploration/Average Returns           -188.486
evaluation/num steps total          955152
evaluation/num paths total            4752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.912988
evaluation/Rewards Std                   0.215149
evaluation/Rewards Max                  -0.551648
evaluation/Rewards Min                  -1.78109
evaluation/Returns Mean               -183.511
evaluation/Returns Std                  16.0468
evaluation/Returns Max                -158.263
evaluation/Returns Min                -222.038
evaluation/Actions Mean                 -0.427514
evaluation/Actions Std                   0.651002
evaluation/Actions Max                   0.993792
evaluation/Actions Min                  -0.999995
evaluation/Num Paths                    24
evaluation/Average Returns            -183.511
time/data storing (s)                    0.0129233
time/evaluation sampling (s)           395.545
time/exploration sampling (s)           85.7738
time/logging (s)                         0.058
time/sac training (s)                    8.85211
time/saving (s)                          0.0517718
time/training (s)                        0.000103731
time/epoch (s)                         490.294
time/total (s)                      124651
Epoch                                  197
----------------------------------  ----------------
2020-11-02 20:37:29.981104 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 198 finished
----------------------------------  ----------------
replay_buffer/size                  200000
trainer/num train calls             199000
trainer/QF1 Loss                       120.578
trainer/QF2 Loss                       116.085
trainer/Policy Loss                    159.976
trainer/Q1 Predictions Mean           -159.343
trainer/Q1 Predictions Std              43.8479
trainer/Q1 Predictions Max               8.65867
trainer/Q1 Predictions Min            -230.222
trainer/Q2 Predictions Mean           -159.111
trainer/Q2 Predictions Std              43.6214
trainer/Q2 Predictions Max               2.24651
trainer/Q2 Predictions Min            -231.019
trainer/Q Targets Mean                -158.177
trainer/Q Targets Std                   44.2184
trainer/Q Targets Max                    5.7525
trainer/Q Targets Min                 -227.413
trainer/Log Pis Mean                     1.56878
trainer/Log Pis Std                      2.19348
trainer/Log Pis Max                      8.71832
trainer/Log Pis Min                     -4.73441
trainer/policy/mean Mean                -0.319299
trainer/policy/mean Std                  0.737897
trainer/policy/mean Max                  0.998333
trainer/policy/mean Min                 -0.998077
trainer/policy/normal/std Mean           0.660642
trainer/policy/normal/std Std            0.08932
trainer/policy/normal/std Max            0.937192
trainer/policy/normal/std Min            0.453326
trainer/policy/normal/log_std Mean      -0.42358
trainer/policy/normal/log_std Std        0.134253
trainer/policy/normal/log_std Max       -0.0648671
trainer/policy/normal/log_std Min       -0.791145
trainer/Alpha                            0.0290693
trainer/Alpha Loss                      -1.52567
exploration/num steps total         200000
exploration/num paths total           1000
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.05973
exploration/Rewards Std                  0.188789
exploration/Rewards Max                 -0.725643
exploration/Rewards Min                 -1.67466
exploration/Returns Mean              -211.946
exploration/Returns Std                 23.6145
exploration/Returns Max               -177.364
exploration/Returns Min               -235.268
exploration/Actions Mean                -0.207515
exploration/Actions Std                  0.663631
exploration/Actions Max                  0.998694
exploration/Actions Min                 -0.99906
exploration/Num Paths                    5
exploration/Average Returns           -211.946
evaluation/num steps total          959976
evaluation/num paths total            4776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.940339
evaluation/Rewards Std                   0.211905
evaluation/Rewards Max                  -0.560818
evaluation/Rewards Min                  -1.81861
evaluation/Returns Mean               -189.008
evaluation/Returns Std                  19.2208
evaluation/Returns Max                -154.874
evaluation/Returns Min                -236.142
evaluation/Actions Mean                 -0.369579
evaluation/Actions Std                   0.655754
evaluation/Actions Max                   0.999551
evaluation/Actions Min                  -0.999844
evaluation/Num Paths                    24
evaluation/Average Returns            -189.008
time/data storing (s)                    0.0114575
time/evaluation sampling (s)           356.604
time/exploration sampling (s)          102.464
time/logging (s)                         0.0472572
time/sac training (s)                    9.01796
time/saving (s)                          0.0523638
time/training (s)                        0.000114949
time/epoch (s)                         468.197
time/total (s)                      125120
Epoch                                  198
----------------------------------  ----------------
2020-11-02 20:44:32.560426 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 199 finished
----------------------------------  ----------------
replay_buffer/size                  201000
trainer/num train calls             200000
trainer/QF1 Loss                        93.3262
trainer/QF2 Loss                        95.1034
trainer/Policy Loss                    161.82
trainer/Q1 Predictions Mean           -161.103
trainer/Q1 Predictions Std              40.3102
trainer/Q1 Predictions Max             -58.8537
trainer/Q1 Predictions Min            -227.68
trainer/Q2 Predictions Mean           -161.012
trainer/Q2 Predictions Std              40.1651
trainer/Q2 Predictions Max             -52.0628
trainer/Q2 Predictions Min            -226.086
trainer/Q Targets Mean                -161.474
trainer/Q Targets Std                   41.2397
trainer/Q Targets Max                   -0.993716
trainer/Q Targets Min                 -228.084
trainer/Log Pis Mean                     2.51111
trainer/Log Pis Std                      2.26323
trainer/Log Pis Max                      8.91999
trainer/Log Pis Min                     -5.84162
trainer/policy/mean Mean                -0.614522
trainer/policy/mean Std                  0.591811
trainer/policy/mean Max                  0.991427
trainer/policy/mean Min                 -0.999784
trainer/policy/normal/std Mean           0.60711
trainer/policy/normal/std Std            0.0764755
trainer/policy/normal/std Max            0.841024
trainer/policy/normal/std Min            0.377837
trainer/policy/normal/log_std Mean      -0.50693
trainer/policy/normal/log_std Std        0.125617
trainer/policy/normal/log_std Max       -0.173135
trainer/policy/normal/log_std Min       -0.973293
trainer/Alpha                            0.0294715
trainer/Alpha Loss                       1.80133
exploration/num steps total         201000
exploration/num paths total           1005
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.938614
exploration/Rewards Std                  0.213765
exploration/Rewards Max                 -0.576187
exploration/Rewards Min                 -1.5454
exploration/Returns Mean              -187.723
exploration/Returns Std                 14.7824
exploration/Returns Max               -166.851
exploration/Returns Min               -210.654
exploration/Actions Mean                -0.405019
exploration/Actions Std                  0.717831
exploration/Actions Max                  0.999951
exploration/Actions Min                 -0.99992
exploration/Num Paths                    5
exploration/Average Returns           -187.723
evaluation/num steps total          964800
evaluation/num paths total            4800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.882026
evaluation/Rewards Std                   0.176301
evaluation/Rewards Max                  -0.564329
evaluation/Rewards Min                  -1.45673
evaluation/Returns Mean               -177.287
evaluation/Returns Std                  11.8787
evaluation/Returns Max                -158.553
evaluation/Returns Min                -210.94
evaluation/Actions Mean                 -0.350087
evaluation/Actions Std                   0.685204
evaluation/Actions Max                   0.993563
evaluation/Actions Min                  -0.999484
evaluation/Num Paths                    24
evaluation/Average Returns            -177.287
time/data storing (s)                    0.00908361
time/evaluation sampling (s)           334.45
time/exploration sampling (s)           77.762
time/logging (s)                         0.0230286
time/sac training (s)                    8.92494
time/saving (s)                          0.0338608
time/training (s)                        0.000108387
time/epoch (s)                         421.203
time/total (s)                      125543
Epoch                                  199
----------------------------------  ----------------
2020-11-02 20:52:36.036367 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 200 finished
----------------------------------  ----------------
replay_buffer/size                  202000
trainer/num train calls             201000
trainer/QF1 Loss                        96.5949
trainer/QF2 Loss                       107.989
trainer/Policy Loss                    162.391
trainer/Q1 Predictions Mean           -161.703
trainer/Q1 Predictions Std              39.7386
trainer/Q1 Predictions Max             -49.9318
trainer/Q1 Predictions Min            -227.395
trainer/Q2 Predictions Mean           -161.701
trainer/Q2 Predictions Std              39.5703
trainer/Q2 Predictions Max             -49.4699
trainer/Q2 Predictions Min            -227.902
trainer/Q Targets Mean                -161.238
trainer/Q Targets Std                   41.0947
trainer/Q Targets Max                   -0.971666
trainer/Q Targets Min                 -228.551
trainer/Log Pis Mean                     1.86272
trainer/Log Pis Std                      2.09083
trainer/Log Pis Max                     10.7692
trainer/Log Pis Min                     -3.55483
trainer/policy/mean Mean                -0.373053
trainer/policy/mean Std                  0.729578
trainer/policy/mean Max                  0.999367
trainer/policy/mean Min                 -0.996362
trainer/policy/normal/std Mean           0.666943
trainer/policy/normal/std Std            0.105591
trainer/policy/normal/std Max            0.99036
trainer/policy/normal/std Min            0.434591
trainer/policy/normal/log_std Mean      -0.417201
trainer/policy/normal/log_std Std        0.154933
trainer/policy/normal/log_std Max       -0.00968638
trainer/policy/normal/log_std Min       -0.83335
trainer/Alpha                            0.0307174
trainer/Alpha Loss                      -0.478131
exploration/num steps total         202000
exploration/num paths total           1010
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.938922
exploration/Rewards Std                  0.165973
exploration/Rewards Max                 -0.550135
exploration/Rewards Min                 -1.51105
exploration/Returns Mean              -187.784
exploration/Returns Std                 21.203
exploration/Returns Max               -159.83
exploration/Returns Min               -224.434
exploration/Actions Mean                -0.122169
exploration/Actions Std                  0.699984
exploration/Actions Max                  0.999464
exploration/Actions Min                 -0.997738
exploration/Num Paths                    5
exploration/Average Returns           -187.784
evaluation/num steps total          969624
evaluation/num paths total            4824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.930468
evaluation/Rewards Std                   0.221185
evaluation/Rewards Max                  -0.593672
evaluation/Rewards Min                  -1.83343
evaluation/Returns Mean               -187.024
evaluation/Returns Std                  24.328
evaluation/Returns Max                -162.448
evaluation/Returns Min                -286.039
evaluation/Actions Mean                 -0.339895
evaluation/Actions Std                   0.673062
evaluation/Actions Max                   0.999362
evaluation/Actions Min                  -0.998209
evaluation/Num Paths                    24
evaluation/Average Returns            -187.024
time/data storing (s)                    0.0206926
time/evaluation sampling (s)           373.952
time/exploration sampling (s)           98.8047
time/logging (s)                         0.10203
time/sac training (s)                    9.0663
time/saving (s)                          0.128682
time/training (s)                        0.000104621
time/epoch (s)                         482.074
time/total (s)                      126026
Epoch                                  200
----------------------------------  ----------------
2020-11-02 21:00:29.348556 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 201 finished
----------------------------------  ----------------
replay_buffer/size                  203000
trainer/num train calls             202000
trainer/QF1 Loss                        29.952
trainer/QF2 Loss                        30.7536
trainer/Policy Loss                    159.924
trainer/Q1 Predictions Mean           -159.189
trainer/Q1 Predictions Std              39.3648
trainer/Q1 Predictions Max             -35.4955
trainer/Q1 Predictions Min            -230.662
trainer/Q2 Predictions Mean           -159.225
trainer/Q2 Predictions Std              39.4112
trainer/Q2 Predictions Max             -39.6475
trainer/Q2 Predictions Min            -228.413
trainer/Q Targets Mean                -161.032
trainer/Q Targets Std                   39.7878
trainer/Q Targets Max                  -26.6504
trainer/Q Targets Min                 -231.96
trainer/Log Pis Mean                     1.83511
trainer/Log Pis Std                      2.15157
trainer/Log Pis Max                      8.90093
trainer/Log Pis Min                     -5.42363
trainer/policy/mean Mean                -0.389508
trainer/policy/mean Std                  0.724044
trainer/policy/mean Max                  0.997639
trainer/policy/mean Min                 -0.999026
trainer/policy/normal/std Mean           0.642759
trainer/policy/normal/std Std            0.0976942
trainer/policy/normal/std Max            0.910342
trainer/policy/normal/std Min            0.372866
trainer/policy/normal/log_std Mean      -0.453383
trainer/policy/normal/log_std Std        0.150734
trainer/policy/normal/log_std Max       -0.0939353
trainer/policy/normal/log_std Min       -0.986537
trainer/Alpha                            0.0301771
trainer/Alpha Loss                      -0.577227
exploration/num steps total         203000
exploration/num paths total           1015
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -1.00861
exploration/Rewards Std                  0.237181
exploration/Rewards Max                 -0.617865
exploration/Rewards Min                 -1.58594
exploration/Returns Mean              -201.722
exploration/Returns Std                 34.3539
exploration/Returns Max               -165.216
exploration/Returns Min               -244.129
exploration/Actions Mean                -0.217481
exploration/Actions Std                  0.736755
exploration/Actions Max                  0.998491
exploration/Actions Min                 -0.999861
exploration/Num Paths                    5
exploration/Average Returns           -201.722
evaluation/num steps total          974448
evaluation/num paths total            4848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.905115
evaluation/Rewards Std                   0.204245
evaluation/Rewards Max                  -0.550628
evaluation/Rewards Min                  -1.61196
evaluation/Returns Mean               -181.928
evaluation/Returns Std                  13.9377
evaluation/Returns Max                -150.839
evaluation/Returns Min                -205.08
evaluation/Actions Mean                 -0.421557
evaluation/Actions Std                   0.646676
evaluation/Actions Max                   0.999916
evaluation/Actions Min                  -0.99833
evaluation/Num Paths                    24
evaluation/Average Returns            -181.928
time/data storing (s)                    0.0121843
time/evaluation sampling (s)           342.741
time/exploration sampling (s)          117.105
time/logging (s)                         0.0735166
time/sac training (s)                   11.4926
time/saving (s)                          0.0933467
time/training (s)                        0.000160832
time/epoch (s)                         471.518
time/total (s)                      126499
Epoch                                  201
----------------------------------  ----------------
2020-11-02 21:08:45.224247 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 202 finished
----------------------------------  ----------------
replay_buffer/size                  204000
trainer/num train calls             203000
trainer/QF1 Loss                        26.5665
trainer/QF2 Loss                        24.8738
trainer/Policy Loss                    157.227
trainer/Q1 Predictions Mean           -156.202
trainer/Q1 Predictions Std              47.81
trainer/Q1 Predictions Max              31.3956
trainer/Q1 Predictions Min            -229.382
trainer/Q2 Predictions Mean           -156.537
trainer/Q2 Predictions Std              47.8145
trainer/Q2 Predictions Max              27.9971
trainer/Q2 Predictions Min            -228.187
trainer/Q Targets Mean                -156.842
trainer/Q Targets Std                   47.1171
trainer/Q Targets Max                   31.8216
trainer/Q Targets Min                 -227.547
trainer/Log Pis Mean                     1.58116
trainer/Log Pis Std                      2.34499
trainer/Log Pis Max                     13.6039
trainer/Log Pis Min                     -5.38068
trainer/policy/mean Mean                -0.282536
trainer/policy/mean Std                  0.757647
trainer/policy/mean Max                  0.999884
trainer/policy/mean Min                 -0.995136
trainer/policy/normal/std Mean           0.654303
trainer/policy/normal/std Std            0.100637
trainer/policy/normal/std Max            0.910706
trainer/policy/normal/std Min            0.291415
trainer/policy/normal/log_std Mean      -0.436192
trainer/policy/normal/log_std Std        0.156048
trainer/policy/normal/log_std Max       -0.093535
trainer/policy/normal/log_std Min       -1.23301
trainer/Alpha                            0.0307651
trainer/Alpha Loss                      -1.45812
exploration/num steps total         204000
exploration/num paths total           1020
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.958915
exploration/Rewards Std                  0.208568
exploration/Rewards Max                 -0.575071
exploration/Rewards Min                 -1.55311
exploration/Returns Mean              -191.783
exploration/Returns Std                 26.095
exploration/Returns Max               -152.502
exploration/Returns Min               -227.972
exploration/Actions Mean                -0.362569
exploration/Actions Std                  0.67048
exploration/Actions Max                  0.997919
exploration/Actions Min                 -0.99915
exploration/Num Paths                    5
exploration/Average Returns           -191.783
evaluation/num steps total          979272
evaluation/num paths total            4872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.941259
evaluation/Rewards Std                   0.205818
evaluation/Rewards Max                  -0.568051
evaluation/Rewards Min                  -1.75814
evaluation/Returns Mean               -189.193
evaluation/Returns Std                  17.6012
evaluation/Returns Max                -155.987
evaluation/Returns Min                -229.505
evaluation/Actions Mean                 -0.356197
evaluation/Actions Std                   0.617083
evaluation/Actions Max                   0.995396
evaluation/Actions Min                  -0.997052
evaluation/Num Paths                    24
evaluation/Average Returns            -189.193
time/data storing (s)                    0.00822022
time/evaluation sampling (s)           395.878
time/exploration sampling (s)           89.3262
time/logging (s)                         0.0332289
time/sac training (s)                    9.00449
time/saving (s)                          0.0340168
time/training (s)                        0.000115564
time/epoch (s)                         494.285
time/total (s)                      126995
Epoch                                  202
----------------------------------  ----------------
2020-11-02 21:18:49.921961 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 203 finished
----------------------------------  ---------------
replay_buffer/size                  205000
trainer/num train calls             204000
trainer/QF1 Loss                        26.3446
trainer/QF2 Loss                        25.1161
trainer/Policy Loss                    162.839
trainer/Q1 Predictions Mean           -161.78
trainer/Q1 Predictions Std              40.7082
trainer/Q1 Predictions Max              13.4543
trainer/Q1 Predictions Min            -231.464
trainer/Q2 Predictions Mean           -162.27
trainer/Q2 Predictions Std              40.7561
trainer/Q2 Predictions Max               7.98938
trainer/Q2 Predictions Min            -234.613
trainer/Q Targets Mean                -161.629
trainer/Q Targets Std                   40.2077
trainer/Q Targets Max                   19.4228
trainer/Q Targets Min                 -232.589
trainer/Log Pis Mean                     1.73358
trainer/Log Pis Std                      2.13902
trainer/Log Pis Max                     10.6129
trainer/Log Pis Min                     -4.56303
trainer/policy/mean Mean                -0.381411
trainer/policy/mean Std                  0.718083
trainer/policy/mean Max                  0.998907
trainer/policy/mean Min                 -0.999021
trainer/policy/normal/std Mean           0.659716
trainer/policy/normal/std Std            0.105823
trainer/policy/normal/std Max            0.945586
trainer/policy/normal/std Min            0.397033
trainer/policy/normal/log_std Mean      -0.428604
trainer/policy/normal/log_std Std        0.158794
trainer/policy/normal/log_std Max       -0.0559504
trainer/policy/normal/log_std Min       -0.923737
trainer/Alpha                            0.0313806
trainer/Alpha Loss                      -0.922245
exploration/num steps total         205000
exploration/num paths total           1025
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.900144
exploration/Rewards Std                  0.171706
exploration/Rewards Max                 -0.64406
exploration/Rewards Min                 -1.41843
exploration/Returns Mean              -180.029
exploration/Returns Std                 13.3138
exploration/Returns Max               -168.614
exploration/Returns Min               -205.973
exploration/Actions Mean                -0.303687
exploration/Actions Std                  0.718064
exploration/Actions Max                  0.998686
exploration/Actions Min                 -0.999654
exploration/Num Paths                    5
exploration/Average Returns           -180.029
evaluation/num steps total          984096
evaluation/num paths total            4896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.911684
evaluation/Rewards Std                   0.204975
evaluation/Rewards Max                  -0.560554
evaluation/Rewards Min                  -1.64135
evaluation/Returns Mean               -183.249
evaluation/Returns Std                  17.9804
evaluation/Returns Max                -149.183
evaluation/Returns Min                -227.406
evaluation/Actions Mean                 -0.396177
evaluation/Actions Std                   0.649005
evaluation/Actions Max                   0.997232
evaluation/Actions Min                  -0.999358
evaluation/Num Paths                    24
evaluation/Average Returns            -183.249
time/data storing (s)                    0.0477848
time/evaluation sampling (s)           493.209
time/exploration sampling (s)           96.3829
time/logging (s)                         0.0992249
time/sac training (s)                   12.89
time/saving (s)                          0.158642
time/training (s)                        9.2909e-05
time/epoch (s)                         602.787
time/total (s)                      127600
Epoch                                  203
----------------------------------  ---------------
2020-11-02 21:26:26.682825 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 204 finished
----------------------------------  ---------------
replay_buffer/size                  206000
trainer/num train calls             205000
trainer/QF1 Loss                        24.1781
trainer/QF2 Loss                        23.9544
trainer/Policy Loss                    160.528
trainer/Q1 Predictions Mean           -159.698
trainer/Q1 Predictions Std              39.4991
trainer/Q1 Predictions Max             -71.3316
trainer/Q1 Predictions Min            -225.437
trainer/Q2 Predictions Mean           -160.065
trainer/Q2 Predictions Std              39.3605
trainer/Q2 Predictions Max             -72.5597
trainer/Q2 Predictions Min            -224.383
trainer/Q Targets Mean                -159.944
trainer/Q Targets Std                   39.9059
trainer/Q Targets Max                  -68.2312
trainer/Q Targets Min                 -225.837
trainer/Log Pis Mean                     1.91887
trainer/Log Pis Std                      2.21808
trainer/Log Pis Max                     13.4578
trainer/Log Pis Min                     -3.53574
trainer/policy/mean Mean                -0.394459
trainer/policy/mean Std                  0.71785
trainer/policy/mean Max                  0.999925
trainer/policy/mean Min                 -0.997533
trainer/policy/normal/std Mean           0.644478
trainer/policy/normal/std Std            0.102771
trainer/policy/normal/std Max            0.933724
trainer/policy/normal/std Min            0.415864
trainer/policy/normal/log_std Mean      -0.451789
trainer/policy/normal/log_std Std        0.157396
trainer/policy/normal/log_std Max       -0.0685744
trainer/policy/normal/log_std Min       -0.877397
trainer/Alpha                            0.0305807
trainer/Alpha Loss                      -0.28293
exploration/num steps total         206000
exploration/num paths total           1030
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.941183
exploration/Rewards Std                  0.216194
exploration/Rewards Max                 -0.574372
exploration/Rewards Min                 -1.60469
exploration/Returns Mean              -188.237
exploration/Returns Std                 26.1224
exploration/Returns Max               -155.852
exploration/Returns Min               -231.675
exploration/Actions Mean                -0.327132
exploration/Actions Std                  0.654999
exploration/Actions Max                  0.997746
exploration/Actions Min                 -0.998464
exploration/Num Paths                    5
exploration/Average Returns           -188.237
evaluation/num steps total          988920
evaluation/num paths total            4920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.906338
evaluation/Rewards Std                   0.197038
evaluation/Rewards Max                  -0.580038
evaluation/Rewards Min                  -1.61499
evaluation/Returns Mean               -182.174
evaluation/Returns Std                  16.4448
evaluation/Returns Max                -159.224
evaluation/Returns Min                -225.717
evaluation/Actions Mean                 -0.383923
evaluation/Actions Std                   0.665341
evaluation/Actions Max                   0.995404
evaluation/Actions Min                  -0.999959
evaluation/Num Paths                    24
evaluation/Average Returns            -182.174
time/data storing (s)                    0.0117935
time/evaluation sampling (s)           344.519
time/exploration sampling (s)           97.0019
time/logging (s)                         0.0465793
time/sac training (s)                   12.8814
time/saving (s)                          0.0569392
time/training (s)                        0.00010202
time/epoch (s)                         454.518
time/total (s)                      128057
Epoch                                  204
----------------------------------  ---------------
2020-11-02 21:35:33.187412 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 205 finished
----------------------------------  ----------------
replay_buffer/size                  207000
trainer/num train calls             206000
trainer/QF1 Loss                        20.3146
trainer/QF2 Loss                        22.7523
trainer/Policy Loss                    158.854
trainer/Q1 Predictions Mean           -158.281
trainer/Q1 Predictions Std              39.703
trainer/Q1 Predictions Max             -16.7865
trainer/Q1 Predictions Min            -225.635
trainer/Q2 Predictions Mean           -158.187
trainer/Q2 Predictions Std              40.0728
trainer/Q2 Predictions Max             -16.3454
trainer/Q2 Predictions Min            -223.295
trainer/Q Targets Mean                -158.845
trainer/Q Targets Std                   40.581
trainer/Q Targets Max                  -18.9399
trainer/Q Targets Min                 -225.098
trainer/Log Pis Mean                     1.7499
trainer/Log Pis Std                      2.04734
trainer/Log Pis Max                      7.28398
trainer/Log Pis Min                     -3.53917
trainer/policy/mean Mean                -0.370912
trainer/policy/mean Std                  0.72933
trainer/policy/mean Max                  0.996266
trainer/policy/mean Min                 -0.996431
trainer/policy/normal/std Mean           0.64939
trainer/policy/normal/std Std            0.0977879
trainer/policy/normal/std Max            0.938471
trainer/policy/normal/std Min            0.447629
trainer/policy/normal/log_std Mean      -0.442656
trainer/policy/normal/log_std Std        0.146733
trainer/policy/normal/log_std Max       -0.0635028
trainer/policy/normal/log_std Min       -0.803792
trainer/Alpha                            0.0326272
trainer/Alpha Loss                      -0.855982
exploration/num steps total         207000
exploration/num paths total           1035
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.906878
exploration/Rewards Std                  0.225976
exploration/Rewards Max                 -0.594879
exploration/Rewards Min                 -1.50568
exploration/Returns Mean              -181.376
exploration/Returns Std                 29.6646
exploration/Returns Max               -160.371
exploration/Returns Min               -239.614
exploration/Actions Mean                -0.214849
exploration/Actions Std                  0.731947
exploration/Actions Max                  0.999883
exploration/Actions Min                 -0.998609
exploration/Num Paths                    5
exploration/Average Returns           -181.376
evaluation/num steps total          993744
evaluation/num paths total            4944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.890566
evaluation/Rewards Std                   0.222654
evaluation/Rewards Max                  -0.521932
evaluation/Rewards Min                  -1.76192
evaluation/Returns Mean               -179.004
evaluation/Returns Std                  26.4789
evaluation/Returns Max                -141.309
evaluation/Returns Min                -290.005
evaluation/Actions Mean                 -0.390652
evaluation/Actions Std                   0.639929
evaluation/Actions Max                   0.980955
evaluation/Actions Min                  -0.99867
evaluation/Num Paths                    24
evaluation/Average Returns            -179.004
time/data storing (s)                    0.0146717
time/evaluation sampling (s)           417.305
time/exploration sampling (s)          114.269
time/logging (s)                         0.169505
time/sac training (s)                   12.0414
time/saving (s)                          0.0918137
time/training (s)                        0.000110139
time/epoch (s)                         543.892
time/total (s)                      128603
Epoch                                  205
----------------------------------  ----------------
2020-11-02 21:44:33.027157 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 206 finished
----------------------------------  ----------------
replay_buffer/size                  208000
trainer/num train calls             207000
trainer/QF1 Loss                        23.0301
trainer/QF2 Loss                        23.5435
trainer/Policy Loss                    162.338
trainer/Q1 Predictions Mean           -161.534
trainer/Q1 Predictions Std              35.9356
trainer/Q1 Predictions Max             -74.5328
trainer/Q1 Predictions Min            -227.184
trainer/Q2 Predictions Mean           -161.796
trainer/Q2 Predictions Std              36.0331
trainer/Q2 Predictions Max             -76.4692
trainer/Q2 Predictions Min            -228.742
trainer/Q Targets Mean                -161.999
trainer/Q Targets Std                   36.0073
trainer/Q Targets Max                  -71.498
trainer/Q Targets Min                 -227.204
trainer/Log Pis Mean                     1.81728
trainer/Log Pis Std                      2.55436
trainer/Log Pis Max                      9.36938
trainer/Log Pis Min                     -6.98365
trainer/policy/mean Mean                -0.202923
trainer/policy/mean Std                  0.794757
trainer/policy/mean Max                  0.999208
trainer/policy/mean Min                 -0.997676
trainer/policy/normal/std Mean           0.636276
trainer/policy/normal/std Std            0.0776864
trainer/policy/normal/std Max            0.8999
trainer/policy/normal/std Min            0.447659
trainer/policy/normal/log_std Mean      -0.459429
trainer/policy/normal/log_std Std        0.120432
trainer/policy/normal/log_std Max       -0.105471
trainer/policy/normal/log_std Min       -0.803724
trainer/Alpha                            0.0313794
trainer/Alpha Loss                      -0.632506
exploration/num steps total         208000
exploration/num paths total           1040
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.927898
exploration/Rewards Std                  0.21633
exploration/Rewards Max                 -0.557684
exploration/Rewards Min                 -1.56243
exploration/Returns Mean              -185.58
exploration/Returns Std                 23.339
exploration/Returns Max               -153.343
exploration/Returns Min               -215.62
exploration/Actions Mean                -0.36006
exploration/Actions Std                  0.706675
exploration/Actions Max                  0.99748
exploration/Actions Min                 -0.999615
exploration/Num Paths                    5
exploration/Average Returns           -185.58
evaluation/num steps total          998568
evaluation/num paths total            4968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.925323
evaluation/Rewards Std                   0.21361
evaluation/Rewards Max                  -0.571277
evaluation/Rewards Min                  -1.5954
evaluation/Returns Mean               -185.99
evaluation/Returns Std                  23.5366
evaluation/Returns Max                -153.59
evaluation/Returns Min                -257.36
evaluation/Actions Mean                 -0.346755
evaluation/Actions Std                   0.690444
evaluation/Actions Max                   0.997518
evaluation/Actions Min                  -0.999903
evaluation/Num Paths                    24
evaluation/Average Returns            -185.99
time/data storing (s)                    0.052013
time/evaluation sampling (s)           417.772
time/exploration sampling (s)          108.383
time/logging (s)                         0.0931104
time/sac training (s)                   10.9177
time/saving (s)                          0.148674
time/training (s)                        0.000105923
time/epoch (s)                         537.367
time/total (s)                      129143
Epoch                                  206
----------------------------------  ----------------
2020-11-02 21:53:13.686933 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 207 finished
----------------------------------  ----------------
replay_buffer/size                  209000
trainer/num train calls             208000
trainer/QF1 Loss                        29.0648
trainer/QF2 Loss                        27.6947
trainer/Policy Loss                    155.417
trainer/Q1 Predictions Mean           -154.48
trainer/Q1 Predictions Std              39.9293
trainer/Q1 Predictions Max             -57.3162
trainer/Q1 Predictions Min            -225.802
trainer/Q2 Predictions Mean           -154.523
trainer/Q2 Predictions Std              39.3616
trainer/Q2 Predictions Max             -54.925
trainer/Q2 Predictions Min            -224.819
trainer/Q Targets Mean                -155.627
trainer/Q Targets Std                   39.6524
trainer/Q Targets Max                  -65.4379
trainer/Q Targets Min                 -224.977
trainer/Log Pis Mean                     1.76012
trainer/Log Pis Std                      2.36436
trainer/Log Pis Max                      8.92167
trainer/Log Pis Min                     -4.05914
trainer/policy/mean Mean                -0.0655489
trainer/policy/mean Std                  0.82181
trainer/policy/mean Max                  0.999938
trainer/policy/mean Min                 -0.998529
trainer/policy/normal/std Mean           0.671338
trainer/policy/normal/std Std            0.0905131
trainer/policy/normal/std Max            0.973789
trainer/policy/normal/std Min            0.379877
trainer/policy/normal/log_std Mean      -0.407565
trainer/policy/normal/log_std Std        0.134996
trainer/policy/normal/log_std Max       -0.0265606
trainer/policy/normal/log_std Min       -0.967907
trainer/Alpha                            0.0318464
trainer/Alpha Loss                      -0.826843
exploration/num steps total         209000
exploration/num paths total           1045
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.901307
exploration/Rewards Std                  0.157137
exploration/Rewards Max                 -0.573218
exploration/Rewards Min                 -1.46433
exploration/Returns Mean              -180.261
exploration/Returns Std                  7.47033
exploration/Returns Max               -168.696
exploration/Returns Min               -186.625
exploration/Actions Mean                -0.323943
exploration/Actions Std                  0.692388
exploration/Actions Max                  0.998366
exploration/Actions Min                 -0.998703
exploration/Num Paths                    5
exploration/Average Returns           -180.261
evaluation/num steps total               1.00339e+06
evaluation/num paths total            4992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.954518
evaluation/Rewards Std                   0.19592
evaluation/Rewards Max                  -0.543788
evaluation/Rewards Min                  -1.65236
evaluation/Returns Mean               -191.858
evaluation/Returns Std                  19.4348
evaluation/Returns Max                -165.997
evaluation/Returns Min                -237.108
evaluation/Actions Mean                 -0.247542
evaluation/Actions Std                   0.698012
evaluation/Actions Max                   0.99993
evaluation/Actions Min                  -0.999381
evaluation/Num Paths                    24
evaluation/Average Returns            -191.858
time/data storing (s)                    0.00762925
time/evaluation sampling (s)           413.634
time/exploration sampling (s)           95.3685
time/logging (s)                         0.0625564
time/sac training (s)                    8.98707
time/saving (s)                          0.0352785
time/training (s)                        9.30668e-05
time/epoch (s)                         518.095
time/total (s)                      129664
Epoch                                  207
----------------------------------  ----------------
2020-11-02 21:59:23.818313 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 208 finished
----------------------------------  ----------------
replay_buffer/size                  210000
trainer/num train calls             209000
trainer/QF1 Loss                       112.222
trainer/QF2 Loss                       122.313
trainer/Policy Loss                    161.772
trainer/Q1 Predictions Mean           -161.185
trainer/Q1 Predictions Std              43.7676
trainer/Q1 Predictions Max              17.0228
trainer/Q1 Predictions Min            -227.259
trainer/Q2 Predictions Mean           -161.118
trainer/Q2 Predictions Std              43.7745
trainer/Q2 Predictions Max              20.5624
trainer/Q2 Predictions Min            -227.265
trainer/Q Targets Mean                -160.385
trainer/Q Targets Std                   45.382
trainer/Q Targets Max                   31.3766
trainer/Q Targets Min                 -227.03
trainer/Log Pis Mean                     2.35258
trainer/Log Pis Std                      2.02967
trainer/Log Pis Max                      8.53642
trainer/Log Pis Min                     -4.23587
trainer/policy/mean Mean                -0.371095
trainer/policy/mean Std                  0.734223
trainer/policy/mean Max                  0.99921
trainer/policy/mean Min                 -0.998906
trainer/policy/normal/std Mean           0.647454
trainer/policy/normal/std Std            0.111828
trainer/policy/normal/std Max            0.928394
trainer/policy/normal/std Min            0.376885
trainer/policy/normal/log_std Mean      -0.449543
trainer/policy/normal/log_std Std        0.172339
trainer/policy/normal/log_std Max       -0.0742996
trainer/policy/normal/log_std Min       -0.975814
trainer/Alpha                            0.0310202
trainer/Alpha Loss                       1.22455
exploration/num steps total         210000
exploration/num paths total           1050
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.873765
exploration/Rewards Std                  0.228216
exploration/Rewards Max                 -0.550048
exploration/Rewards Min                 -1.44238
exploration/Returns Mean              -174.753
exploration/Returns Std                 23.027
exploration/Returns Max               -157.1
exploration/Returns Min               -220.334
exploration/Actions Mean                -0.339339
exploration/Actions Std                  0.693083
exploration/Actions Max                  0.999871
exploration/Actions Min                 -0.999992
exploration/Num Paths                    5
exploration/Average Returns           -174.753
evaluation/num steps total               1.00822e+06
evaluation/num paths total            5016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.918977
evaluation/Rewards Std                   0.220398
evaluation/Rewards Max                  -0.534541
evaluation/Rewards Min                  -1.73583
evaluation/Returns Mean               -184.714
evaluation/Returns Std                  18.3203
evaluation/Returns Max                -149.15
evaluation/Returns Min                -213.443
evaluation/Actions Mean                 -0.410889
evaluation/Actions Std                   0.666828
evaluation/Actions Max                   0.984625
evaluation/Actions Min                  -0.99949
evaluation/Num Paths                    24
evaluation/Average Returns            -184.714
time/data storing (s)                    0.00702905
time/evaluation sampling (s)           290.4
time/exploration sampling (s)           69.7616
time/logging (s)                         0.0186559
time/sac training (s)                    8.47975
time/saving (s)                          0.0253744
time/training (s)                        0.000125482
time/epoch (s)                         368.693
time/total (s)                      130034
Epoch                                  208
----------------------------------  ----------------
2020-11-02 22:08:05.344691 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 209 finished
----------------------------------  ----------------
replay_buffer/size                  211000
trainer/num train calls             210000
trainer/QF1 Loss                        94.2368
trainer/QF2 Loss                        87.7481
trainer/Policy Loss                    155.254
trainer/Q1 Predictions Mean           -154.602
trainer/Q1 Predictions Std              43.4145
trainer/Q1 Predictions Max              27.6304
trainer/Q1 Predictions Min            -226.974
trainer/Q2 Predictions Mean           -154.671
trainer/Q2 Predictions Std              43.6394
trainer/Q2 Predictions Max              30.6548
trainer/Q2 Predictions Min            -228.521
trainer/Q Targets Mean                -153.357
trainer/Q Targets Std                   44.1801
trainer/Q Targets Max                   23.3326
trainer/Q Targets Min                 -224.485
trainer/Log Pis Mean                     1.88119
trainer/Log Pis Std                      2.29015
trainer/Log Pis Max                     11.3284
trainer/Log Pis Min                     -4.37796
trainer/policy/mean Mean                -0.52628
trainer/policy/mean Std                  0.660106
trainer/policy/mean Max                  0.999733
trainer/policy/mean Min                 -0.999776
trainer/policy/normal/std Mean           0.624522
trainer/policy/normal/std Std            0.0762252
trainer/policy/normal/std Max            0.814372
trainer/policy/normal/std Min            0.394723
trainer/policy/normal/log_std Mean      -0.478205
trainer/policy/normal/log_std Std        0.122069
trainer/policy/normal/log_std Max       -0.205338
trainer/policy/normal/log_std Min       -0.929571
trainer/Alpha                            0.0316143
trainer/Alpha Loss                      -0.410377
exploration/num steps total         211000
exploration/num paths total           1055
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.923636
exploration/Rewards Std                  0.181233
exploration/Rewards Max                 -0.637034
exploration/Rewards Min                 -1.48865
exploration/Returns Mean              -184.727
exploration/Returns Std                 10.9219
exploration/Returns Max               -171.316
exploration/Returns Min               -203.796
exploration/Actions Mean                -0.39546
exploration/Actions Std                  0.652994
exploration/Actions Max                  0.999339
exploration/Actions Min                 -0.998293
exploration/Num Paths                    5
exploration/Average Returns           -184.727
evaluation/num steps total               1.01304e+06
evaluation/num paths total            5040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.942721
evaluation/Rewards Std                   0.207765
evaluation/Rewards Max                  -0.56503
evaluation/Rewards Min                  -1.8311
evaluation/Returns Mean               -189.487
evaluation/Returns Std                  20.6163
evaluation/Returns Max                -151.832
evaluation/Returns Min                -233.542
evaluation/Actions Mean                 -0.39447
evaluation/Actions Std                   0.638547
evaluation/Actions Max                   0.979214
evaluation/Actions Min                  -0.997368
evaluation/Num Paths                    24
evaluation/Average Returns            -189.487
time/data storing (s)                    0.0254995
time/evaluation sampling (s)           389.003
time/exploration sampling (s)          120.822
time/logging (s)                         0.12533
time/sac training (s)                    9.80375
time/saving (s)                          0.262237
time/training (s)                        9.69979e-05
time/epoch (s)                         520.041
time/total (s)                      130555
Epoch                                  209
----------------------------------  ----------------
2020-11-02 22:16:46.655534 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 210 finished
----------------------------------  ----------------
replay_buffer/size                  212000
trainer/num train calls             211000
trainer/QF1 Loss                        76.9134
trainer/QF2 Loss                        78.5081
trainer/Policy Loss                    161.019
trainer/Q1 Predictions Mean           -160.575
trainer/Q1 Predictions Std              39.5079
trainer/Q1 Predictions Max             -35.3643
trainer/Q1 Predictions Min            -223.618
trainer/Q2 Predictions Mean           -160.159
trainer/Q2 Predictions Std              39.5887
trainer/Q2 Predictions Max             -34.4939
trainer/Q2 Predictions Min            -224.264
trainer/Q Targets Mean                -161.201
trainer/Q Targets Std                   41.0726
trainer/Q Targets Max                   -0.782733
trainer/Q Targets Min                 -225.757
trainer/Log Pis Mean                     2.16921
trainer/Log Pis Std                      2.34634
trainer/Log Pis Max                     10.2635
trainer/Log Pis Min                     -4.61686
trainer/policy/mean Mean                -0.590015
trainer/policy/mean Std                  0.604389
trainer/policy/mean Max                  0.987038
trainer/policy/mean Min                 -0.999496
trainer/policy/normal/std Mean           0.645531
trainer/policy/normal/std Std            0.102504
trainer/policy/normal/std Max            0.973791
trainer/policy/normal/std Min            0.43973
trainer/policy/normal/log_std Mean      -0.450045
trainer/policy/normal/log_std Std        0.156652
trainer/policy/normal/log_std Max       -0.0265581
trainer/policy/normal/log_std Min       -0.821594
trainer/Alpha                            0.0301733
trainer/Alpha Loss                       0.592355
exploration/num steps total         212000
exploration/num paths total           1060
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.898367
exploration/Rewards Std                  0.19008
exploration/Rewards Max                 -0.626092
exploration/Rewards Min                 -1.53715
exploration/Returns Mean              -179.673
exploration/Returns Std                 11.7156
exploration/Returns Max               -165.283
exploration/Returns Min               -193.778
exploration/Actions Mean                -0.505639
exploration/Actions Std                  0.581643
exploration/Actions Max                  0.992697
exploration/Actions Min                 -0.999356
exploration/Num Paths                    5
exploration/Average Returns           -179.673
evaluation/num steps total               1.01786e+06
evaluation/num paths total            5064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.941505
evaluation/Rewards Std                   0.224593
evaluation/Rewards Max                  -0.537767
evaluation/Rewards Min                  -1.73289
evaluation/Returns Mean               -189.242
evaluation/Returns Std                  23.1191
evaluation/Returns Max                -151.485
evaluation/Returns Min                -245.126
evaluation/Actions Mean                 -0.470025
evaluation/Actions Std                   0.61169
evaluation/Actions Max                   0.965966
evaluation/Actions Min                  -0.999982
evaluation/Num Paths                    24
evaluation/Average Returns            -189.242
time/data storing (s)                    0.0672038
time/evaluation sampling (s)           406.501
time/exploration sampling (s)          101.062
time/logging (s)                         0.0793434
time/sac training (s)                   11.2235
time/saving (s)                          0.211275
time/training (s)                        9.4322e-05
time/epoch (s)                         519.144
time/total (s)                      131076
Epoch                                  210
----------------------------------  ----------------
2020-11-02 22:24:33.478108 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 211 finished
----------------------------------  ----------------
replay_buffer/size                  213000
trainer/num train calls             212000
trainer/QF1 Loss                       145.329
trainer/QF2 Loss                       146.857
trainer/Policy Loss                    154.786
trainer/Q1 Predictions Mean           -154.111
trainer/Q1 Predictions Std              42.334
trainer/Q1 Predictions Max               3.94391
trainer/Q1 Predictions Min            -223.765
trainer/Q2 Predictions Mean           -154.016
trainer/Q2 Predictions Std              42.2229
trainer/Q2 Predictions Max               8.04647
trainer/Q2 Predictions Min            -222.221
trainer/Q Targets Mean                -155.571
trainer/Q Targets Std                   44.328
trainer/Q Targets Max                    8.69587
trainer/Q Targets Min                 -225.968
trainer/Log Pis Mean                     1.71731
trainer/Log Pis Std                      2.46673
trainer/Log Pis Max                     12.5124
trainer/Log Pis Min                     -6.24542
trainer/policy/mean Mean                -0.34426
trainer/policy/mean Std                  0.73911
trainer/policy/mean Max                  0.99932
trainer/policy/mean Min                 -0.999425
trainer/policy/normal/std Mean           0.624023
trainer/policy/normal/std Std            0.0885572
trainer/policy/normal/std Max            0.89483
trainer/policy/normal/std Min            0.291506
trainer/policy/normal/log_std Mean      -0.481777
trainer/policy/normal/log_std Std        0.143994
trainer/policy/normal/log_std Max       -0.111122
trainer/policy/normal/log_std Min       -1.23269
trainer/Alpha                            0.0314217
trainer/Alpha Loss                      -0.978168
exploration/num steps total         213000
exploration/num paths total           1065
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.947706
exploration/Rewards Std                  0.144832
exploration/Rewards Max                 -0.669487
exploration/Rewards Min                 -1.41002
exploration/Returns Mean              -189.541
exploration/Returns Std                  8.28677
exploration/Returns Max               -173.862
exploration/Returns Min               -196.788
exploration/Actions Mean                -0.329417
exploration/Actions Std                  0.630422
exploration/Actions Max                  0.994465
exploration/Actions Min                 -0.997658
exploration/Num Paths                    5
exploration/Average Returns           -189.541
evaluation/num steps total               1.02269e+06
evaluation/num paths total            5088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.958226
evaluation/Rewards Std                   0.211235
evaluation/Rewards Max                  -0.594844
evaluation/Rewards Min                  -1.65753
evaluation/Returns Mean               -192.603
evaluation/Returns Std                  21.6928
evaluation/Returns Max                -161.332
evaluation/Returns Min                -234.005
evaluation/Actions Mean                 -0.364188
evaluation/Actions Std                   0.610098
evaluation/Actions Max                   0.97383
evaluation/Actions Min                  -0.998446
evaluation/Num Paths                    24
evaluation/Average Returns            -192.603
time/data storing (s)                    0.00625788
time/evaluation sampling (s)           370.223
time/exploration sampling (s)           87.2299
time/logging (s)                         0.0211051
time/sac training (s)                    8.19696
time/saving (s)                          0.0634339
time/training (s)                        0.000104469
time/epoch (s)                         465.741
time/total (s)                      131543
Epoch                                  211
----------------------------------  ----------------
2020-11-02 22:30:48.876673 EST | [name-of-experiment_2020_11_01_09_12_15_0000--s-0] Epoch 212 finished
----------------------------------  ----------------
replay_buffer/size                  214000
trainer/num train calls             213000
trainer/QF1 Loss                       148.1
trainer/QF2 Loss                       147.231
trainer/Policy Loss                    156.237
trainer/Q1 Predictions Mean           -155.469
trainer/Q1 Predictions Std              40.109
trainer/Q1 Predictions Max             -55.3008
trainer/Q1 Predictions Min            -225.278
trainer/Q2 Predictions Mean           -155.691
trainer/Q2 Predictions Std              40.0433
trainer/Q2 Predictions Max             -51.9733
trainer/Q2 Predictions Min            -225.258
trainer/Q Targets Mean                -154.822
trainer/Q Targets Std                   43.1036
trainer/Q Targets Max                   -0.574433
trainer/Q Targets Min                 -227.525
trainer/Log Pis Mean                     2.24716
trainer/Log Pis Std                      2.30727
trainer/Log Pis Max                      9.85798
trainer/Log Pis Min                     -5.79325
trainer/policy/mean Mean                -0.485675
trainer/policy/mean Std                  0.698342
trainer/policy/mean Max                  0.998528
trainer/policy/mean Min                 -0.998673
trainer/policy/normal/std Mean           0.639298
trainer/policy/normal/std Std            0.0902925
trainer/policy/normal/std Max            0.980565
trainer/policy/normal/std Min            0.402432
trainer/policy/normal/log_std Mean      -0.457189
trainer/policy/normal/log_std Std        0.139675
trainer/policy/normal/log_std Max       -0.0196264
trainer/policy/normal/log_std Min       -0.91023
trainer/Alpha                            0.0324476
trainer/Alpha Loss                       0.847293
exploration/num steps total         214000
exploration/num paths total           1070
exploration/path length Mean           200
exploration/path length Std              2
exploration/path length Max            201
exploration/path length Min            196
exploration/Rewards Mean                -0.969514
exploration/Rewards Std                  0.225449
exploration/Rewards Max                 -0.648792
exploration/Rewards Min                 -1.76464
exploration/Returns Mean              -193.903
exploration/Returns Std                 25.2675
exploration/Returns Max               -174.401
exploration/Returns Min               -243.808
exploration/Actions Mean                -0.448711
exploration/Actions Std                  0.650951
exploration/Actions Max                  0.997994
exploration/Actions Min                 -0.999929
exploration/Num Paths                    5
exploration/Average Returns           -193.903
evaluation/num steps total               1.02751e+06
evaluation/num paths total            5112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -0.904584
evaluation/Rewards Std                   0.212482
evaluation/Rewards Max                  -0.532073
evaluation/Rewards Min                  -1.66652
evaluation/Returns Mean               -181.821
evaluation/Returns Std                  18.2402
evaluation/Returns Max                -155.594
evaluation/Returns Min                -235.949
evaluation/Actions Mean                 -0.402691
evaluation/Actions Std                   0.659697
evaluation/Actions Max                   0.989958
evaluation/Actions Min                  -0.999019
evaluation/Num Paths                    24
evaluation/Average Returns            -181.821
time/data storing (s)                    0.00782143
time/evaluation sampling (s)           290.408
time/exploration sampling (s)           76.1873
time/logging (s)                         0.0366696
time/sac training (s)                    7.95016
time/saving (s)                          0.0583856
time/training (s)                        0.000105696
time/epoch (s)                         374.649
time/total (s)                      131919
Epoch                                  212
----------------------------------  ----------------
