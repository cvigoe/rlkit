2020-11-09 15:08:52.241231 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 0 finished
----------------------------------  ---------------
replay_buffer/size                   4000
trainer/num train calls              1000
trainer/QF1 Loss                        2.71164
trainer/QF2 Loss                        2.71176
trainer/Policy Loss                    -1.33867
trainer/Q1 Predictions Mean             7.79905e-05
trainer/Q1 Predictions Std              0.000224601
trainer/Q1 Predictions Max              0.000696239
trainer/Q1 Predictions Min             -0.000456552
trainer/Q2 Predictions Mean             0.000111859
trainer/Q2 Predictions Std              0.000175929
trainer/Q2 Predictions Max              0.000511581
trainer/Q2 Predictions Min             -0.000388422
trainer/Q Targets Mean                  0.0753246
trainer/Q Targets Std                   1.64501
trainer/Q Targets Max                   1.82378
trainer/Q Targets Min                  -5.12694
trainer/Log Pis Mean                   -1.3387
trainer/Log Pis Std                     0.323069
trainer/Log Pis Max                    -0.551054
trainer/Log Pis Min                    -1.83203
trainer/policy/mean Mean               -1.58935e-05
trainer/policy/mean Std                 7.13984e-05
trainer/policy/mean Max                 0.000156341
trainer/policy/mean Min                -0.000197864
trainer/policy/normal/std Mean          0.999585
trainer/policy/normal/std Std           0.000127852
trainer/policy/normal/std Max           0.999865
trainer/policy/normal/std Min           0.999376
trainer/policy/normal/log_std Mean     -0.000414826
trainer/policy/normal/log_std Std       0.000127904
trainer/policy/normal/log_std Max      -0.000134775
trainer/policy/normal/log_std Min      -0.000624494
trainer/Alpha                           1
trainer/Alpha Loss                     -0
exploration/num steps total          4000
exploration/num paths total            20
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -0.979582
exploration/Rewards Std                 1.58698
exploration/Rewards Max                -1.06426e-26
exploration/Rewards Min                -6.13283
exploration/Returns Mean             -195.916
exploration/Returns Std                59.5132
exploration/Returns Max               -80.8973
exploration/Returns Min              -282.499
exploration/Actions Mean               -0.00412523
exploration/Actions Std                 0.623487
exploration/Actions Max                 0.996225
exploration/Actions Min                -0.999732
exploration/Num Paths                  10
exploration/Average Returns          -195.916
evaluation/num steps total           4824
evaluation/num paths total             24
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.21242
evaluation/Rewards Std                  0.408643
evaluation/Rewards Max                 -4.51206
evaluation/Rewards Min                 -6.13578
evaluation/Returns Mean             -1047.7
evaluation/Returns Std                 73.7961
evaluation/Returns Max               -936.402
evaluation/Returns Min              -1115.75
evaluation/Actions Mean                -9.95311e-07
evaluation/Actions Std                  8.52041e-06
evaluation/Actions Max                  1.51858e-05
evaluation/Actions Min                 -1.88462e-05
evaluation/Num Paths                   24
evaluation/Average Returns          -1047.7
time/data storing (s)                   0.0360896
time/evaluation sampling (s)           25.5019
time/exploration sampling (s)           9.87915
time/logging (s)                        0.0231546
time/sac training (s)                  49.2106
time/saving (s)                         0.0329882
time/training (s)                       0.000143687
time/epoch (s)                         84.6841
time/total (s)                        103.348
Epoch                                   0
----------------------------------  ---------------
2020-11-09 15:10:43.107257 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 1 finished
----------------------------------  ---------------
replay_buffer/size                   6000
trainer/num train calls              2000
trainer/QF1 Loss                        2.19414
trainer/QF2 Loss                        2.22989
trainer/Policy Loss                    -1.59476
trainer/Q1 Predictions Mean             0.309324
trainer/Q1 Predictions Std              0.317134
trainer/Q1 Predictions Max              0.825458
trainer/Q1 Predictions Min             -0.0492107
trainer/Q2 Predictions Mean             0.308128
trainer/Q2 Predictions Std              0.305124
trainer/Q2 Predictions Max              0.859744
trainer/Q2 Predictions Min             -0.0403892
trainer/Q Targets Mean                  0.182571
trainer/Q Targets Std                   1.68421
trainer/Q Targets Max                   1.95039
trainer/Q Targets Min                  -4.63321
trainer/Log Pis Mean                   -1.35392
trainer/Log Pis Std                     0.177652
trainer/Log Pis Max                    -1.03075
trainer/Log Pis Min                    -2.75079
trainer/policy/mean Mean                0.00485639
trainer/policy/mean Std                 0.00247281
trainer/policy/mean Max                 0.00874952
trainer/policy/mean Min                 0.00175466
trainer/policy/normal/std Mean          0.879436
trainer/policy/normal/std Std           0.0112333
trainer/policy/normal/std Max           0.900972
trainer/policy/normal/std Min           0.855076
trainer/policy/normal/log_std Mean     -0.128556
trainer/policy/normal/log_std Std       0.012791
trainer/policy/normal/log_std Max      -0.104281
trainer/policy/normal/log_std Min      -0.156565
trainer/Alpha                           0.970386
trainer/Alpha Loss                     -0.100825
exploration/num steps total          6000
exploration/num paths total            30
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.23254
exploration/Rewards Std                 1.40677
exploration/Rewards Max                -2.50507e-17
exploration/Rewards Min                -6.11811
exploration/Returns Mean             -246.508
exploration/Returns Std                67.5961
exploration/Returns Max               -93.8786
exploration/Returns Min              -331.05
exploration/Actions Mean                0.000445395
exploration/Actions Std                 0.585608
exploration/Actions Max                 0.99854
exploration/Actions Min                -0.995619
exploration/Num Paths                  10
exploration/Average Returns          -246.508
evaluation/num steps total           9648
evaluation/num paths total             48
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.07571
evaluation/Rewards Std                  0.420487
evaluation/Rewards Max                 -4.65396
evaluation/Rewards Min                 -6.13571
evaluation/Returns Mean             -1020.22
evaluation/Returns Std                 70.2261
evaluation/Returns Max               -943.31
evaluation/Returns Min              -1111.67
evaluation/Actions Mean                 0.00425704
evaluation/Actions Std                  0.00215612
evaluation/Actions Max                  0.00659903
evaluation/Actions Min                  0.00205968
evaluation/Num Paths                   24
evaluation/Average Returns          -1020.22
time/data storing (s)                   0.0427626
time/evaluation sampling (s)           28.7427
time/exploration sampling (s)          10.8893
time/logging (s)                        0.0763677
time/sac training (s)                  69.3512
time/saving (s)                         0.0989264
time/training (s)                       0.000421002
time/epoch (s)                        109.202
time/total (s)                        214.235
Epoch                                   1
----------------------------------  ---------------
2020-11-09 15:12:15.542853 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 2 finished
----------------------------------  ---------------
replay_buffer/size                   8000
trainer/num train calls              3000
trainer/QF1 Loss                        1.8859
trainer/QF2 Loss                        1.94403
trainer/Policy Loss                    -2.50544
trainer/Q1 Predictions Mean             1.2728
trainer/Q1 Predictions Std              1.48835
trainer/Q1 Predictions Max              3.82036
trainer/Q1 Predictions Min             -0.339242
trainer/Q2 Predictions Mean             1.29619
trainer/Q2 Predictions Std              1.48252
trainer/Q2 Predictions Max              3.90864
trainer/Q2 Predictions Min             -0.280155
trainer/Q Targets Mean                  1.08978
trainer/Q Targets Std                   2.41747
trainer/Q Targets Max                   4.44566
trainer/Q Targets Min                  -5.08648
trainer/Log Pis Mean                   -1.35546
trainer/Log Pis Std                     0.17536
trainer/Log Pis Max                    -1.02674
trainer/Log Pis Min                    -2.86882
trainer/policy/mean Mean               -0.00424748
trainer/policy/mean Std                 0.00427655
trainer/policy/mean Max                 0.000560748
trainer/policy/mean Min                -0.0118218
trainer/policy/normal/std Mean          0.87341
trainer/policy/normal/std Std           0.0108795
trainer/policy/normal/std Max           0.893541
trainer/policy/normal/std Min           0.821994
trainer/policy/normal/log_std Mean     -0.135428
trainer/policy/normal/log_std Std       0.0125389
trainer/policy/normal/log_std Max      -0.112563
trainer/policy/normal/log_std Min      -0.196022
trainer/Alpha                           0.941684
trainer/Alpha Loss                     -0.201615
exploration/num steps total          8000
exploration/num paths total            40
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.43685
exploration/Rewards Std                 1.58117
exploration/Rewards Max                -3.4464e-27
exploration/Rewards Min                -6.14153
exploration/Returns Mean             -287.37
exploration/Returns Std               110.247
exploration/Returns Max              -130.392
exploration/Returns Min              -460.676
exploration/Actions Mean               -0.00536353
exploration/Actions Std                 0.593528
exploration/Actions Max                 0.993847
exploration/Actions Min                -0.993883
exploration/Num Paths                  10
exploration/Average Returns          -287.37
evaluation/num steps total          14472
evaluation/num paths total             72
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.20493
evaluation/Rewards Std                  0.360478
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.12307
evaluation/Returns Mean             -1046.19
evaluation/Returns Std                 64.3604
evaluation/Returns Max               -915.919
evaluation/Returns Min              -1109.19
evaluation/Actions Mean                -0.00397157
evaluation/Actions Std                  0.00391014
evaluation/Actions Max                 -3.50527e-05
evaluation/Actions Min                 -0.00791088
evaluation/Num Paths                   24
evaluation/Average Returns          -1046.19
time/data storing (s)                   0.0383961
time/evaluation sampling (s)           23.8629
time/exploration sampling (s)           9.24465
time/logging (s)                        0.0766704
time/sac training (s)                  57.4963
time/saving (s)                         0.0415413
time/training (s)                       0.000155505
time/epoch (s)                         90.7606
time/total (s)                        306.642
Epoch                                   2
----------------------------------  ---------------
2020-11-09 15:13:59.256978 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 3 finished
----------------------------------  ---------------
replay_buffer/size                  10000
trainer/num train calls              4000
trainer/QF1 Loss                        1.89234
trainer/QF2 Loss                        2.10551
trainer/Policy Loss                    -3.3568
trainer/Q1 Predictions Mean             2.15615
trainer/Q1 Predictions Std              3.06311
trainer/Q1 Predictions Max              8.20621
trainer/Q1 Predictions Min             -0.942477
trainer/Q2 Predictions Mean             2.24003
trainer/Q2 Predictions Std              2.98906
trainer/Q2 Predictions Max              8.22504
trainer/Q2 Predictions Min             -0.705854
trainer/Q Targets Mean                  1.75604
trainer/Q Targets Std                   3.81755
trainer/Q Targets Max                   8.46234
trainer/Q Targets Min                  -5.81691
trainer/Log Pis Mean                   -1.35581
trainer/Log Pis Std                     0.130451
trainer/Log Pis Max                    -1.02365
trainer/Log Pis Min                    -2.04788
trainer/policy/mean Mean               -0.0137691
trainer/policy/mean Std                 0.00590976
trainer/policy/mean Max                -0.0067309
trainer/policy/mean Min                -0.024472
trainer/policy/normal/std Mean          0.872158
trainer/policy/normal/std Std           0.00907806
trainer/policy/normal/std Max           0.889487
trainer/policy/normal/std Min           0.839887
trainer/policy/normal/log_std Mean     -0.13684
trainer/policy/normal/log_std Std       0.0104374
trainer/policy/normal/log_std Max      -0.117111
trainer/policy/normal/log_std Min      -0.174487
trainer/Alpha                           0.913845
trainer/Alpha Loss                     -0.302338
exploration/num steps total         10000
exploration/num paths total            50
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.16775
exploration/Rewards Std                 1.41607
exploration/Rewards Max                -2.8471e-27
exploration/Rewards Min                -6.11968
exploration/Returns Mean             -233.55
exploration/Returns Std               104.404
exploration/Returns Max               -93.2864
exploration/Returns Min              -423.136
exploration/Actions Mean               -0.0182606
exploration/Actions Std                 0.588675
exploration/Actions Max                 0.994056
exploration/Actions Min                -0.996107
exploration/Num Paths                  10
exploration/Average Returns          -233.55
evaluation/num steps total          19296
evaluation/num paths total             96
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.2624
evaluation/Rewards Std                  0.385632
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.13414
evaluation/Returns Mean             -1057.74
evaluation/Returns Std                 64.8315
evaluation/Returns Max               -911.076
evaluation/Returns Min              -1112.22
evaluation/Actions Mean                -0.0130251
evaluation/Actions Std                  0.00548542
evaluation/Actions Max                 -0.00734092
evaluation/Actions Min                 -0.0186168
evaluation/Num Paths                   24
evaluation/Average Returns          -1057.74
time/data storing (s)                   0.0330077
time/evaluation sampling (s)           31.8802
time/exploration sampling (s)          10.8964
time/logging (s)                        0.034236
time/sac training (s)                  59.0511
time/saving (s)                         0.0413674
time/training (s)                       0.000172633
time/epoch (s)                        101.936
time/total (s)                        410.262
Epoch                                   3
----------------------------------  ---------------
2020-11-09 15:15:38.195903 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 4 finished
----------------------------------  ---------------
replay_buffer/size                  12000
trainer/num train calls              5000
trainer/QF1 Loss                        1.92162
trainer/QF2 Loss                        2.24569
trainer/Policy Loss                    -4.57646
trainer/Q1 Predictions Mean             3.39024
trainer/Q1 Predictions Std              5.04454
trainer/Q1 Predictions Max             12.9907
trainer/Q1 Predictions Min             -1.94182
trainer/Q2 Predictions Mean             3.55042
trainer/Q2 Predictions Std              4.89009
trainer/Q2 Predictions Max             13.0004
trainer/Q2 Predictions Min             -1.48996
trainer/Q Targets Mean                  3.0705
trainer/Q Targets Std                   5.65278
trainer/Q Targets Max                  13.2183
trainer/Q Targets Min                  -6.46568
trainer/Log Pis Mean                   -1.36963
trainer/Log Pis Std                     0.161687
trainer/Log Pis Max                    -0.997261
trainer/Log Pis Min                    -2.11306
trainer/policy/mean Mean               -0.027402
trainer/policy/mean Std                 0.010107
trainer/policy/mean Max                -0.0140056
trainer/policy/mean Min                -0.0481846
trainer/policy/normal/std Mean          0.872539
trainer/policy/normal/std Std           0.0103712
trainer/policy/normal/std Max           0.898159
trainer/policy/normal/std Min           0.833803
trainer/policy/normal/log_std Mean     -0.136419
trainer/policy/normal/log_std Std       0.0119858
trainer/policy/normal/log_std Max      -0.107408
trainer/policy/normal/log_std Min      -0.181758
trainer/Alpha                           0.886837
trainer/Alpha Loss                     -0.404672
exploration/num steps total         12000
exploration/num paths total            60
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.06643
exploration/Rewards Std                 1.41602
exploration/Rewards Max                -5.54598e-27
exploration/Rewards Min                -6.12958
exploration/Returns Mean             -213.287
exploration/Returns Std               104.052
exploration/Returns Max               -46.785
exploration/Returns Min              -395.588
exploration/Actions Mean               -0.015346
exploration/Actions Std                 0.581797
exploration/Actions Max                 0.99261
exploration/Actions Min                -0.997839
exploration/Num Paths                  10
exploration/Average Returns          -213.287
evaluation/num steps total          24120
evaluation/num paths total            120
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.10734
evaluation/Rewards Std                  0.430017
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.13399
evaluation/Returns Mean             -1026.58
evaluation/Returns Std                 76.2198
evaluation/Returns Max               -912.655
evaluation/Returns Min              -1113.71
evaluation/Actions Mean                -0.0257165
evaluation/Actions Std                  0.00922468
evaluation/Actions Max                 -0.0160889
evaluation/Actions Min                 -0.0352775
evaluation/Num Paths                   24
evaluation/Average Returns          -1026.58
time/data storing (s)                   0.0426712
time/evaluation sampling (s)           24.0376
time/exploration sampling (s)           9.43739
time/logging (s)                        0.0445769
time/sac training (s)                  63.3161
time/saving (s)                         0.0569495
time/training (s)                       0.000171405
time/epoch (s)                         96.9355
time/total (s)                        509.177
Epoch                                   4
----------------------------------  ---------------
2020-11-09 15:17:16.461501 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 5 finished
----------------------------------  ---------------
replay_buffer/size                  14000
trainer/num train calls              6000
trainer/QF1 Loss                        1.42475
trainer/QF2 Loss                        2.02004
trainer/Policy Loss                    -4.1622
trainer/Q1 Predictions Mean             3.03871
trainer/Q1 Predictions Std              6.35753
trainer/Q1 Predictions Max             17.9492
trainer/Q1 Predictions Min             -3.26624
trainer/Q2 Predictions Mean             3.21378
trainer/Q2 Predictions Std              6.1775
trainer/Q2 Predictions Max             17.8927
trainer/Q2 Predictions Min             -2.60067
trainer/Q Targets Mean                  2.82723
trainer/Q Targets Std                   6.84097
trainer/Q Targets Max                  17.8896
trainer/Q Targets Min                  -7.68445
trainer/Log Pis Mean                   -1.39295
trainer/Log Pis Std                     0.196025
trainer/Log Pis Max                    -0.974456
trainer/Log Pis Min                    -3.45457
trainer/policy/mean Mean               -0.0353396
trainer/policy/mean Std                 0.0160694
trainer/policy/mean Max                -0.0158051
trainer/policy/mean Min                -0.0631004
trainer/policy/normal/std Mean          0.873975
trainer/policy/normal/std Std           0.00998218
trainer/policy/normal/std Max           0.896866
trainer/policy/normal/std Min           0.845552
trainer/policy/normal/log_std Mean     -0.134769
trainer/policy/normal/log_std Std       0.011477
trainer/policy/normal/log_std Max      -0.108849
trainer/policy/normal/log_std Min      -0.167766
trainer/Alpha                           0.860629
trainer/Alpha Loss                     -0.509254
exploration/num steps total         14000
exploration/num paths total            70
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.2203
exploration/Rewards Std                 1.5242
exploration/Rewards Max                -3.20155e-11
exploration/Rewards Min                -6.12412
exploration/Returns Mean             -244.059
exploration/Returns Std               103.266
exploration/Returns Max              -124.501
exploration/Returns Min              -461.566
exploration/Actions Mean               -0.0326472
exploration/Actions Std                 0.578037
exploration/Actions Max                 0.996207
exploration/Actions Min                -0.995723
exploration/Num Paths                  10
exploration/Average Returns          -244.059
evaluation/num steps total          28944
evaluation/num paths total            144
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.1618
evaluation/Rewards Std                  0.394255
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.13406
evaluation/Returns Mean             -1037.52
evaluation/Returns Std                 67.8027
evaluation/Returns Max               -914.143
evaluation/Returns Min              -1107.41
evaluation/Actions Mean                -0.033156
evaluation/Actions Std                  0.0147842
evaluation/Actions Max                 -0.0179603
evaluation/Actions Min                 -0.0482893
evaluation/Num Paths                   24
evaluation/Average Returns          -1037.52
time/data storing (s)                   0.0293693
time/evaluation sampling (s)           22.0174
time/exploration sampling (s)           9.4505
time/logging (s)                        0.0749945
time/sac training (s)                  64.8293
time/saving (s)                         0.0722615
time/training (s)                       0.000161136
time/epoch (s)                         96.4739
time/total (s)                        607.441
Epoch                                   5
----------------------------------  ---------------
2020-11-09 15:18:59.858059 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 6 finished
----------------------------------  ---------------
replay_buffer/size                  16000
trainer/num train calls              7000
trainer/QF1 Loss                        2.07278
trainer/QF2 Loss                        2.82089
trainer/Policy Loss                    -4.29969
trainer/Q1 Predictions Mean             3.19085
trainer/Q1 Predictions Std              8.04649
trainer/Q1 Predictions Max             22.6585
trainer/Q1 Predictions Min             -5.14073
trainer/Q2 Predictions Mean             3.42348
trainer/Q2 Predictions Std              7.8253
trainer/Q2 Predictions Max             22.6556
trainer/Q2 Predictions Min             -4.24612
trainer/Q Targets Mean                  3.04264
trainer/Q Targets Std                   8.54607
trainer/Q Targets Max                  22.6097
trainer/Q Targets Min                  -9.17038
trainer/Log Pis Mean                   -1.3788
trainer/Log Pis Std                     0.220005
trainer/Log Pis Max                    -0.928933
trainer/Log Pis Min                    -3.7598
trainer/policy/mean Mean               -0.0374931
trainer/policy/mean Std                 0.0191546
trainer/policy/mean Max                -0.0146932
trainer/policy/mean Min                -0.073617
trainer/policy/normal/std Mean          0.872451
trainer/policy/normal/std Std           0.00976622
trainer/policy/normal/std Max           0.898587
trainer/policy/normal/std Min           0.834223
trainer/policy/normal/log_std Mean     -0.136512
trainer/policy/normal/log_std Std       0.0112388
trainer/policy/normal/log_std Max      -0.106932
trainer/policy/normal/log_std Min      -0.181255
trainer/Alpha                           0.835201
trainer/Alpha Loss                     -0.608464
exploration/num steps total         16000
exploration/num paths total            80
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.13224
exploration/Rewards Std                 1.53747
exploration/Rewards Max                -7.95389e-25
exploration/Rewards Min                -6.14125
exploration/Returns Mean             -226.449
exploration/Returns Std                48.7111
exploration/Returns Max              -142.972
exploration/Returns Min              -289.785
exploration/Actions Mean               -0.0361
exploration/Actions Std                 0.580349
exploration/Actions Max                 0.993973
exploration/Actions Min                -0.99521
exploration/Num Paths                  10
exploration/Average Returns          -226.449
evaluation/num steps total          33768
evaluation/num paths total            168
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.19215
evaluation/Rewards Std                  0.434115
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.13394
evaluation/Returns Mean             -1043.62
evaluation/Returns Std                 78.98
evaluation/Returns Max               -918.59
evaluation/Returns Min              -1109.72
evaluation/Actions Mean                -0.0352662
evaluation/Actions Std                  0.0177203
evaluation/Actions Max                 -0.017219
evaluation/Actions Min                 -0.0533868
evaluation/Num Paths                   24
evaluation/Average Returns          -1043.62
time/data storing (s)                   0.0702082
time/evaluation sampling (s)           24.0488
time/exploration sampling (s)          11.687
time/logging (s)                        0.0465786
time/sac training (s)                  65.57
time/saving (s)                         0.0736891
time/training (s)                       0.000144516
time/epoch (s)                        101.496
time/total (s)                        710.775
Epoch                                   6
----------------------------------  ---------------
2020-11-09 15:20:32.172045 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 7 finished
----------------------------------  ---------------
replay_buffer/size                  18000
trainer/num train calls              8000
trainer/QF1 Loss                        2.29764
trainer/QF2 Loss                        3.52935
trainer/Policy Loss                    -3.5712
trainer/Q1 Predictions Mean             2.52242
trainer/Q1 Predictions Std              9.76546
trainer/Q1 Predictions Max             27.6755
trainer/Q1 Predictions Min             -7.8019
trainer/Q2 Predictions Mean             2.86757
trainer/Q2 Predictions Std              9.43938
trainer/Q2 Predictions Max             27.7105
trainer/Q2 Predictions Min             -6.2116
trainer/Q Targets Mean                  2.22859
trainer/Q Targets Std                  10.2574
trainer/Q Targets Max                  27.7082
trainer/Q Targets Min                 -11.625
trainer/Log Pis Mean                   -1.36687
trainer/Log Pis Std                     0.171085
trainer/Log Pis Max                    -0.915652
trainer/Log Pis Min                    -2.12473
trainer/policy/mean Mean               -0.0441146
trainer/policy/mean Std                 0.0171425
trainer/policy/mean Max                -0.023186
trainer/policy/mean Min                -0.0731653
trainer/policy/normal/std Mean          0.874664
trainer/policy/normal/std Std           0.00807032
trainer/policy/normal/std Max           0.893423
trainer/policy/normal/std Min           0.849646
trainer/policy/normal/log_std Mean     -0.133958
trainer/policy/normal/log_std Std       0.0092602
trainer/policy/normal/log_std Max      -0.112696
trainer/policy/normal/log_std Min      -0.162936
trainer/Alpha                           0.810522
trainer/Alpha Loss                     -0.707299
exploration/num steps total         18000
exploration/num paths total            90
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.2249
exploration/Rewards Std                 1.5436
exploration/Rewards Max                -8.18361e-18
exploration/Rewards Min                -6.14085
exploration/Returns Mean             -244.979
exploration/Returns Std                95.5817
exploration/Returns Max               -39.2626
exploration/Returns Min              -377.03
exploration/Actions Mean               -0.0325588
exploration/Actions Std                 0.590078
exploration/Actions Max                 0.996428
exploration/Actions Min                -0.99757
exploration/Num Paths                  10
exploration/Average Returns          -244.979
evaluation/num steps total          38592
evaluation/num paths total            192
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.18081
evaluation/Rewards Std                  0.420627
evaluation/Rewards Max                 -4.51086
evaluation/Rewards Min                 -6.1337
evaluation/Returns Mean             -1041.34
evaluation/Returns Std                 77.9635
evaluation/Returns Max               -910.766
evaluation/Returns Min              -1117.36
evaluation/Actions Mean                -0.0420435
evaluation/Actions Std                  0.0160439
evaluation/Actions Max                 -0.0255573
evaluation/Actions Min                 -0.0584093
evaluation/Num Paths                   24
evaluation/Average Returns          -1041.34
time/data storing (s)                   0.0496941
time/evaluation sampling (s)           20.8049
time/exploration sampling (s)          12.2162
time/logging (s)                        0.0308721
time/sac training (s)                  57.5763
time/saving (s)                         0.0365424
time/training (s)                       0.000141353
time/epoch (s)                         90.7146
time/total (s)                        803.043
Epoch                                   7
----------------------------------  ---------------
2020-11-09 15:22:16.518501 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 8 finished
----------------------------------  ---------------
replay_buffer/size                  20000
trainer/num train calls              9000
trainer/QF1 Loss                        1.49705
trainer/QF2 Loss                        2.44355
trainer/Policy Loss                    -4.46271
trainer/Q1 Predictions Mean             3.46227
trainer/Q1 Predictions Std             12.2764
trainer/Q1 Predictions Max             32.368
trainer/Q1 Predictions Min            -10.2734
trainer/Q2 Predictions Mean             3.71416
trainer/Q2 Predictions Std             12.0165
trainer/Q2 Predictions Max             32.3901
trainer/Q2 Predictions Min             -9.15822
trainer/Q Targets Mean                  3.3549
trainer/Q Targets Std                  12.6055
trainer/Q Targets Max                  32.3021
trainer/Q Targets Min                 -13.9042
trainer/Log Pis Mean                   -1.35441
trainer/Log Pis Std                     0.189272
trainer/Log Pis Max                    -0.891644
trainer/Log Pis Min                    -2.34217
trainer/policy/mean Mean               -0.0561831
trainer/policy/mean Std                 0.0239374
trainer/policy/mean Max                -0.0284312
trainer/policy/mean Min                -0.0986464
trainer/policy/normal/std Mean          0.875316
trainer/policy/normal/std Std           0.00803393
trainer/policy/normal/std Max           0.890867
trainer/policy/normal/std Min           0.848194
trainer/policy/normal/log_std Mean     -0.133212
trainer/policy/normal/log_std Std       0.00920365
trainer/policy/normal/log_std Max      -0.115561
trainer/policy/normal/log_std Min      -0.164645
trainer/Alpha                           0.786572
trainer/Alpha Loss                     -0.805298
exploration/num steps total         20000
exploration/num paths total           100
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.23745
exploration/Rewards Std                 1.57326
exploration/Rewards Max                -3.40608e-23
exploration/Rewards Min                -6.10552
exploration/Returns Mean             -247.49
exploration/Returns Std                98.3272
exploration/Returns Max              -166.362
exploration/Returns Min              -470.062
exploration/Actions Mean               -0.0444546
exploration/Actions Std                 0.587782
exploration/Actions Max                 0.997876
exploration/Actions Min                -0.995141
exploration/Num Paths                  10
exploration/Average Returns          -247.49
evaluation/num steps total          43416
evaluation/num paths total            216
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.23387
evaluation/Rewards Std                  0.425091
evaluation/Rewards Max                 -4.35671
evaluation/Rewards Min                 -6.13178
evaluation/Returns Mean             -1052.01
evaluation/Returns Std                 77.9679
evaluation/Returns Max               -886.426
evaluation/Returns Min              -1106.59
evaluation/Actions Mean                -0.0531942
evaluation/Actions Std                  0.0222745
evaluation/Actions Max                 -0.0304859
evaluation/Actions Min                 -0.0758277
evaluation/Num Paths                   24
evaluation/Average Returns          -1052.01
time/data storing (s)                   0.13161
time/evaluation sampling (s)           28.5083
time/exploration sampling (s)          14.7529
time/logging (s)                        0.0545594
time/sac training (s)                  58.7784
time/saving (s)                         0.0406865
time/training (s)                       0.000144649
time/epoch (s)                        102.267
time/total (s)                        907.377
Epoch                                   8
----------------------------------  ---------------
2020-11-09 15:23:50.818416 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 9 finished
----------------------------------  ---------------
replay_buffer/size                  22000
trainer/num train calls             10000
trainer/QF1 Loss                        3.34675
trainer/QF2 Loss                        4.63605
trainer/Policy Loss                    -3.18377
trainer/Q1 Predictions Mean             2.21779
trainer/Q1 Predictions Std             14.0401
trainer/Q1 Predictions Max             36.5544
trainer/Q1 Predictions Min            -14.6262
trainer/Q2 Predictions Mean             2.52493
trainer/Q2 Predictions Std             13.7086
trainer/Q2 Predictions Max             36.5479
trainer/Q2 Predictions Min            -12.3797
trainer/Q Targets Mean                  2.02784
trainer/Q Targets Std                  14.4614
trainer/Q Targets Max                  36.4832
trainer/Q Targets Min                 -17.0593
trainer/Log Pis Mean                   -1.35957
trainer/Log Pis Std                     0.202987
trainer/Log Pis Max                    -0.83834
trainer/Log Pis Min                    -2.2631
trainer/policy/mean Mean               -0.0664183
trainer/policy/mean Std                 0.0300007
trainer/policy/mean Max                -0.0315624
trainer/policy/mean Min                -0.118542
trainer/policy/normal/std Mean          0.87198
trainer/policy/normal/std Std           0.00844553
trainer/policy/normal/std Max           0.89168
trainer/policy/normal/std Min           0.841759
trainer/policy/normal/log_std Mean     -0.137036
trainer/policy/normal/log_std Std       0.00971806
trainer/policy/normal/log_std Max      -0.114648
trainer/policy/normal/log_std Min      -0.172261
trainer/Alpha                           0.763335
trainer/Alpha Loss                     -0.907279
exploration/num steps total         22000
exploration/num paths total           110
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.26107
exploration/Rewards Std                 1.61062
exploration/Rewards Max                -2.42833e-26
exploration/Rewards Min                -6.14138
exploration/Returns Mean             -252.213
exploration/Returns Std                77.859
exploration/Returns Max              -135.767
exploration/Returns Min              -385.091
exploration/Actions Mean               -0.0438396
exploration/Actions Std                 0.581946
exploration/Actions Max                 0.996998
exploration/Actions Min                -0.998242
exploration/Num Paths                  10
exploration/Average Returns          -252.213
evaluation/num steps total          48240
evaluation/num paths total            240
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.091
evaluation/Rewards Std                  0.453501
evaluation/Rewards Max                 -4.35671
evaluation/Rewards Min                 -6.13189
evaluation/Returns Mean             -1023.29
evaluation/Returns Std                 77.6368
evaluation/Returns Max               -879.118
evaluation/Returns Min              -1109.95
evaluation/Actions Mean                -0.0624575
evaluation/Actions Std                  0.0277649
evaluation/Actions Max                 -0.0344064
evaluation/Actions Min                 -0.0905675
evaluation/Num Paths                   24
evaluation/Average Returns          -1023.29
time/data storing (s)                   0.0287712
time/evaluation sampling (s)           22.7201
time/exploration sampling (s)           9.27717
time/logging (s)                        0.0465355
time/sac training (s)                  60.283
time/saving (s)                         0.0632092
time/training (s)                       0.00024267
time/epoch (s)                         92.419
time/total (s)                       1001.64
Epoch                                   9
----------------------------------  ---------------
2020-11-09 15:25:30.464575 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 10 finished
----------------------------------  ---------------
replay_buffer/size                  24000
trainer/num train calls             11000
trainer/QF1 Loss                        2.86804
trainer/QF2 Loss                        4.36293
trainer/Policy Loss                    -2.23099
trainer/Q1 Predictions Mean             1.29506
trainer/Q1 Predictions Std             16.5134
trainer/Q1 Predictions Max             40.8527
trainer/Q1 Predictions Min            -18.5278
trainer/Q2 Predictions Mean             1.62653
trainer/Q2 Predictions Std             16.1491
trainer/Q2 Predictions Max             40.8938
trainer/Q2 Predictions Min            -15.8219
trainer/Q Targets Mean                  1.17294
trainer/Q Targets Std                  16.9197
trainer/Q Targets Max                  40.944
trainer/Q Targets Min                 -20.053
trainer/Log Pis Mean                   -1.35384
trainer/Log Pis Std                     0.199842
trainer/Log Pis Max                    -0.849863
trainer/Log Pis Min                    -2.48965
trainer/policy/mean Mean               -0.0672001
trainer/policy/mean Std                 0.0377708
trainer/policy/mean Max                -0.0265317
trainer/policy/mean Min                -0.134021
trainer/policy/normal/std Mean          0.869608
trainer/policy/normal/std Std           0.00798363
trainer/policy/normal/std Max           0.884785
trainer/policy/normal/std Min           0.833695
trainer/policy/normal/log_std Mean     -0.139755
trainer/policy/normal/log_std Std       0.00922444
trainer/policy/normal/log_std Max      -0.122411
trainer/policy/normal/log_std Min      -0.181888
trainer/Alpha                           0.740785
trainer/Alpha Loss                     -1.0063
exploration/num steps total         24000
exploration/num paths total           120
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.12455
exploration/Rewards Std                 1.40163
exploration/Rewards Max                -1.60902e-52
exploration/Rewards Min                -6.11658
exploration/Returns Mean             -224.91
exploration/Returns Std                84.075
exploration/Returns Max               -97.1646
exploration/Returns Min              -355.48
exploration/Actions Mean               -0.0353473
exploration/Actions Std                 0.583127
exploration/Actions Max                 0.991645
exploration/Actions Min                -0.995674
exploration/Num Paths                  10
exploration/Average Returns          -224.91
evaluation/num steps total          53064
evaluation/num paths total            264
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.1102
evaluation/Rewards Std                  0.457396
evaluation/Rewards Max                 -4.35671
evaluation/Rewards Min                 -6.13204
evaluation/Returns Mean             -1027.15
evaluation/Returns Std                 81.9563
evaluation/Returns Max               -889.356
evaluation/Returns Min              -1105.44
evaluation/Actions Mean                -0.0630483
evaluation/Actions Std                  0.0350689
evaluation/Actions Max                 -0.0278021
evaluation/Actions Min                 -0.0985051
evaluation/Num Paths                   24
evaluation/Average Returns          -1027.15
time/data storing (s)                   0.0277038
time/evaluation sampling (s)           26.7494
time/exploration sampling (s)          11.143
time/logging (s)                        0.033858
time/sac training (s)                  59.5904
time/saving (s)                         0.126209
time/training (s)                       0.000145532
time/epoch (s)                         97.6706
time/total (s)                       1101.24
Epoch                                  10
----------------------------------  ---------------
2020-11-09 15:27:15.088672 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 11 finished
----------------------------------  ---------------
replay_buffer/size                  26000
trainer/num train calls             12000
trainer/QF1 Loss                        2.4843
trainer/QF2 Loss                        3.786
trainer/Policy Loss                    -0.155273
trainer/Q1 Predictions Mean            -0.680405
trainer/Q1 Predictions Std             18.1691
trainer/Q1 Predictions Max             45.3853
trainer/Q1 Predictions Min            -21.7902
trainer/Q2 Predictions Mean            -0.484172
trainer/Q2 Predictions Std             17.9268
trainer/Q2 Predictions Max             45.4051
trainer/Q2 Predictions Min            -19.2986
trainer/Q Targets Mean                 -0.734761
trainer/Q Targets Std                  18.6598
trainer/Q Targets Max                  44.9923
trainer/Q Targets Min                 -23.4149
trainer/Log Pis Mean                   -1.36883
trainer/Log Pis Std                     0.211192
trainer/Log Pis Max                    -0.860327
trainer/Log Pis Min                    -2.6096
trainer/policy/mean Mean               -0.07757
trainer/policy/mean Std                 0.0415465
trainer/policy/mean Max                -0.032135
trainer/policy/mean Min                -0.145752
trainer/policy/normal/std Mean          0.874357
trainer/policy/normal/std Std           0.00865574
trainer/policy/normal/std Max           0.892474
trainer/policy/normal/std Min           0.845581
trainer/policy/normal/log_std Mean     -0.134316
trainer/policy/normal/log_std Std       0.00992522
trainer/policy/normal/log_std Max      -0.113758
trainer/policy/normal/log_std Min      -0.167732
trainer/Alpha                           0.718904
trainer/Alpha Loss                     -1.11181
exploration/num steps total         26000
exploration/num paths total           130
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.0268
exploration/Rewards Std                 1.53278
exploration/Rewards Max                -9.79272e-44
exploration/Rewards Min                -6.14183
exploration/Returns Mean             -205.359
exploration/Returns Std                64.3102
exploration/Returns Max               -95.2997
exploration/Returns Min              -319.399
exploration/Actions Mean               -0.0618951
exploration/Actions Std                 0.581383
exploration/Actions Max                 0.994613
exploration/Actions Min                -0.992032
exploration/Num Paths                  10
exploration/Average Returns          -205.359
evaluation/num steps total          57888
evaluation/num paths total            288
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.23285
evaluation/Rewards Std                  0.306416
evaluation/Rewards Max                 -4.35671
evaluation/Rewards Min                 -6.13204
evaluation/Returns Mean             -1051.8
evaluation/Returns Std                 53.9396
evaluation/Returns Max               -886.32
evaluation/Returns Min              -1120.98
evaluation/Actions Mean                -0.0724372
evaluation/Actions Std                  0.0383219
evaluation/Actions Max                 -0.0339028
evaluation/Actions Min                 -0.111437
evaluation/Num Paths                   24
evaluation/Average Returns          -1051.8
time/data storing (s)                   0.0260551
time/evaluation sampling (s)           20.6342
time/exploration sampling (s)           8.04395
time/logging (s)                        0.0568106
time/sac training (s)                  73.8081
time/saving (s)                         0.0758025
time/training (s)                       0.000182846
time/epoch (s)                        102.645
time/total (s)                       1205.86
Epoch                                  11
----------------------------------  ---------------
2020-11-09 15:28:58.273650 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 12 finished
----------------------------------  ---------------
replay_buffer/size                  28000
trainer/num train calls             13000
trainer/QF1 Loss                        2.7274
trainer/QF2 Loss                        4.2558
trainer/Policy Loss                     0.671747
trainer/Q1 Predictions Mean            -1.52219
trainer/Q1 Predictions Std             20.2091
trainer/Q1 Predictions Max             43.4794
trainer/Q1 Predictions Min            -26.0461
trainer/Q2 Predictions Mean            -1.30619
trainer/Q2 Predictions Std             19.9542
trainer/Q2 Predictions Max             43.5201
trainer/Q2 Predictions Min            -24.415
trainer/Q Targets Mean                 -1.72151
trainer/Q Targets Std                  20.7169
trainer/Q Targets Max                  43.6136
trainer/Q Targets Min                 -27.0099
trainer/Log Pis Mean                   -1.32935
trainer/Log Pis Std                     0.200123
trainer/Log Pis Max                    -0.811031
trainer/Log Pis Min                    -1.85953
trainer/policy/mean Mean               -0.084031
trainer/policy/mean Std                 0.0469059
trainer/policy/mean Max                -0.0324602
trainer/policy/mean Min                -0.163698
trainer/policy/normal/std Mean          0.871623
trainer/policy/normal/std Std           0.00951182
trainer/policy/normal/std Max           0.890586
trainer/policy/normal/std Min           0.840073
trainer/policy/normal/log_std Mean     -0.137458
trainer/policy/normal/log_std Std       0.010943
trainer/policy/normal/log_std Max      -0.115876
trainer/policy/normal/log_std Min      -0.174267
trainer/Alpha                           0.697678
trainer/Alpha Loss                     -1.19856
exploration/num steps total         28000
exploration/num paths total           140
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.34785
exploration/Rewards Std                 1.65799
exploration/Rewards Max                -1.49073e-32
exploration/Rewards Min                -6.13537
exploration/Returns Mean             -269.57
exploration/Returns Std                96.2736
exploration/Returns Max              -118.081
exploration/Returns Min              -449.682
exploration/Actions Mean               -0.0647561
exploration/Actions Std                 0.581579
exploration/Actions Max                 0.99959
exploration/Actions Min                -0.997417
exploration/Num Paths                  10
exploration/Average Returns          -269.57
evaluation/num steps total          62712
evaluation/num paths total            312
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.08763
evaluation/Rewards Std                  0.448244
evaluation/Rewards Max                 -4.35671
evaluation/Rewards Min                 -6.13186
evaluation/Returns Mean             -1022.61
evaluation/Returns Std                 74.0135
evaluation/Returns Max               -883.468
evaluation/Returns Min              -1105.57
evaluation/Actions Mean                -0.077637
evaluation/Actions Std                  0.042722
evaluation/Actions Max                 -0.0346002
evaluation/Actions Min                 -0.121496
evaluation/Num Paths                   24
evaluation/Average Returns          -1022.61
time/data storing (s)                   0.0439632
time/evaluation sampling (s)           24.8962
time/exploration sampling (s)           9.40319
time/logging (s)                        0.0350446
time/sac training (s)                  66.7015
time/saving (s)                         0.0681603
time/training (s)                       0.00017067
time/epoch (s)                        101.148
time/total (s)                       1308.99
Epoch                                  12
----------------------------------  ---------------
2020-11-09 15:30:30.924722 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 13 finished
----------------------------------  ---------------
replay_buffer/size                  30000
trainer/num train calls             14000
trainer/QF1 Loss                        4.01441
trainer/QF2 Loss                        5.52842
trainer/Policy Loss                     1.98997
trainer/Q1 Predictions Mean            -2.81377
trainer/Q1 Predictions Std             22.3249
trainer/Q1 Predictions Max             52.7101
trainer/Q1 Predictions Min            -30.2167
trainer/Q2 Predictions Mean            -2.62803
trainer/Q2 Predictions Std             22.1224
trainer/Q2 Predictions Max             52.7101
trainer/Q2 Predictions Min            -29.0214
trainer/Q Targets Mean                 -2.88156
trainer/Q Targets Std                  22.6626
trainer/Q Targets Max                  52.8
trainer/Q Targets Min                 -30.8238
trainer/Log Pis Mean                   -1.35176
trainer/Log Pis Std                     0.31464
trainer/Log Pis Max                    -0.713809
trainer/Log Pis Min                    -4.04008
trainer/policy/mean Mean               -0.106035
trainer/policy/mean Std                 0.0589688
trainer/policy/mean Max                -0.0398921
trainer/policy/mean Min                -0.206995
trainer/policy/normal/std Mean          0.872865
trainer/policy/normal/std Std           0.00955342
trainer/policy/normal/std Max           0.894781
trainer/policy/normal/std Min           0.840575
trainer/policy/normal/log_std Mean     -0.136035
trainer/policy/normal/log_std Std       0.0109769
trainer/policy/normal/log_std Max      -0.111177
trainer/policy/normal/log_std Min      -0.173669
trainer/Alpha                           0.677083
trainer/Alpha Loss                     -1.30706
exploration/num steps total         30000
exploration/num paths total           150
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.50456
exploration/Rewards Std                 1.5702
exploration/Rewards Max                -1.00159e-19
exploration/Rewards Min                -6.13309
exploration/Returns Mean             -300.911
exploration/Returns Std                76.4111
exploration/Returns Max              -165.801
exploration/Returns Min              -441.035
exploration/Actions Mean               -0.065801
exploration/Actions Std                 0.590806
exploration/Actions Max                 0.995566
exploration/Actions Min                -0.997223
exploration/Num Paths                  10
exploration/Average Returns          -300.911
evaluation/num steps total          67536
evaluation/num paths total            336
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.16398
evaluation/Rewards Std                  0.440295
evaluation/Rewards Max                 -4.18965
evaluation/Rewards Min                 -6.12936
evaluation/Returns Mean             -1037.96
evaluation/Returns Std                 79.5427
evaluation/Returns Max               -853.602
evaluation/Returns Min              -1105.28
evaluation/Actions Mean                -0.098437
evaluation/Actions Std                  0.0539954
evaluation/Actions Max                 -0.0439551
evaluation/Actions Min                 -0.154285
evaluation/Num Paths                   24
evaluation/Average Returns          -1037.96
time/data storing (s)                   0.0334316
time/evaluation sampling (s)           22.8252
time/exploration sampling (s)          10.2411
time/logging (s)                        0.0500274
time/sac training (s)                  57.6458
time/saving (s)                         0.0412704
time/training (s)                       0.000153287
time/epoch (s)                         90.837
time/total (s)                       1401.63
Epoch                                  13
----------------------------------  ---------------
2020-11-09 15:31:55.485691 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 14 finished
----------------------------------  ---------------
replay_buffer/size                  32000
trainer/num train calls             15000
trainer/QF1 Loss                       14.8698
trainer/QF2 Loss                       16.0906
trainer/Policy Loss                     5.94351
trainer/Q1 Predictions Mean            -6.68899
trainer/Q1 Predictions Std             23.85
trainer/Q1 Predictions Max             56.4518
trainer/Q1 Predictions Min            -35.0725
trainer/Q2 Predictions Mean            -6.46884
trainer/Q2 Predictions Std             23.5905
trainer/Q2 Predictions Max             56.4338
trainer/Q2 Predictions Min            -32.4776
trainer/Q Targets Mean                 -6.72521
trainer/Q Targets Std                  24.2062
trainer/Q Targets Max                  56.5905
trainer/Q Targets Min                 -35.3018
trainer/Log Pis Mean                   -1.32764
trainer/Log Pis Std                     0.269625
trainer/Log Pis Max                    -0.66505
trainer/Log Pis Min                    -1.85576
trainer/policy/mean Mean               -0.128109
trainer/policy/mean Std                 0.0667929
trainer/policy/mean Max                -0.0529959
trainer/policy/mean Min                -0.248653
trainer/policy/normal/std Mean          0.867151
trainer/policy/normal/std Std           0.0098019
trainer/policy/normal/std Max           0.886774
trainer/policy/normal/std Min           0.831744
trainer/policy/normal/log_std Mean     -0.142607
trainer/policy/normal/log_std Std       0.0113527
trainer/policy/normal/log_std Max      -0.120165
trainer/policy/normal/log_std Min      -0.18423
trainer/Alpha                           0.657101
trainer/Alpha Loss                     -1.39733
exploration/num steps total         32000
exploration/num paths total           160
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.18016
exploration/Rewards Std                 1.53503
exploration/Rewards Max                -1.77251e-34
exploration/Rewards Min                -6.14162
exploration/Returns Mean             -236.032
exploration/Returns Std                85.0832
exploration/Returns Max              -138.072
exploration/Returns Min              -374.275
exploration/Actions Mean               -0.089818
exploration/Actions Std                 0.582892
exploration/Actions Max                 0.997331
exploration/Actions Min                -0.997442
exploration/Num Paths                  10
exploration/Average Returns          -236.032
evaluation/num steps total          72360
evaluation/num paths total            360
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.15273
evaluation/Rewards Std                  0.445402
evaluation/Rewards Max                 -4.18965
evaluation/Rewards Min                 -6.12898
evaluation/Returns Mean             -1035.7
evaluation/Returns Std                 83.1438
evaluation/Returns Max               -855.3
evaluation/Returns Min              -1102.59
evaluation/Actions Mean                -0.12003
evaluation/Actions Std                  0.0616696
evaluation/Actions Max                 -0.0577327
evaluation/Actions Min                 -0.184098
evaluation/Num Paths                   24
evaluation/Average Returns          -1035.7
time/data storing (s)                   0.0405286
time/evaluation sampling (s)           21.4845
time/exploration sampling (s)           8.6398
time/logging (s)                        0.0320276
time/sac training (s)                  52.441
time/saving (s)                         0.0588922
time/training (s)                       0.000136407
time/epoch (s)                         82.6969
time/total (s)                       1486.14
Epoch                                  14
----------------------------------  ---------------
2020-11-09 15:33:30.285618 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 15 finished
----------------------------------  ---------------
replay_buffer/size                  34000
trainer/num train calls             16000
trainer/QF1 Loss                        2.77958
trainer/QF2 Loss                        3.69093
trainer/Policy Loss                     4.23821
trainer/Q1 Predictions Mean            -4.94083
trainer/Q1 Predictions Std             27.2332
trainer/Q1 Predictions Max             60.3927
trainer/Q1 Predictions Min            -39.3138
trainer/Q2 Predictions Mean            -4.85796
trainer/Q2 Predictions Std             27.0981
trainer/Q2 Predictions Max             60.4804
trainer/Q2 Predictions Min            -38.6734
trainer/Q Targets Mean                 -4.97896
trainer/Q Targets Std                  27.5494
trainer/Q Targets Max                  60.1882
trainer/Q Targets Min                 -39.8792
trainer/Log Pis Mean                   -1.32757
trainer/Log Pis Std                     0.335626
trainer/Log Pis Max                    -0.618901
trainer/Log Pis Min                    -3.91787
trainer/policy/mean Mean               -0.147095
trainer/policy/mean Std                 0.0666787
trainer/policy/mean Max                -0.0682513
trainer/policy/mean Min                -0.268221
trainer/policy/normal/std Mean          0.865241
trainer/policy/normal/std Std           0.0114917
trainer/policy/normal/std Max           0.891724
trainer/policy/normal/std Min           0.828185
trainer/policy/normal/log_std Mean     -0.144835
trainer/policy/normal/log_std Std       0.0133266
trainer/policy/normal/log_std Max      -0.114599
trainer/policy/normal/log_std Min      -0.188519
trainer/Alpha                           0.637714
trainer/Alpha Loss                     -1.49696
exploration/num steps total         34000
exploration/num paths total           170
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.0912
exploration/Rewards Std                 1.55767
exploration/Rewards Max                -8.85418e-37
exploration/Rewards Min                -6.12763
exploration/Returns Mean             -218.241
exploration/Returns Std                69.9811
exploration/Returns Max              -119.927
exploration/Returns Min              -329.091
exploration/Actions Mean               -0.0993443
exploration/Actions Std                 0.581019
exploration/Actions Max                 0.993872
exploration/Actions Min                -0.998779
exploration/Num Paths                  10
exploration/Average Returns          -218.241
evaluation/num steps total          77184
evaluation/num paths total            384
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.10688
evaluation/Rewards Std                  0.486445
evaluation/Rewards Max                 -4.18965
evaluation/Rewards Min                 -6.12819
evaluation/Returns Mean             -1026.48
evaluation/Returns Std                 90.7432
evaluation/Returns Max               -845.999
evaluation/Returns Min              -1097.81
evaluation/Actions Mean                -0.136945
evaluation/Actions Std                  0.0607438
evaluation/Actions Max                 -0.0752029
evaluation/Actions Min                 -0.198736
evaluation/Num Paths                   24
evaluation/Average Returns          -1026.48
time/data storing (s)                   0.0392289
time/evaluation sampling (s)           21.6135
time/exploration sampling (s)           8.60039
time/logging (s)                        0.0542848
time/sac training (s)                  61.911
time/saving (s)                         0.0443095
time/training (s)                       0.000149363
time/epoch (s)                         92.2628
time/total (s)                       1580.94
Epoch                                  15
----------------------------------  ---------------
2020-11-09 15:35:11.932326 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 16 finished
----------------------------------  ---------------
replay_buffer/size                  36000
trainer/num train calls             17000
trainer/QF1 Loss                        7.69488
trainer/QF2 Loss                        8.27146
trainer/Policy Loss                     7.93333
trainer/Q1 Predictions Mean            -8.66312
trainer/Q1 Predictions Std             28.8897
trainer/Q1 Predictions Max             63.9911
trainer/Q1 Predictions Min            -45.1957
trainer/Q2 Predictions Mean            -8.55958
trainer/Q2 Predictions Std             28.7445
trainer/Q2 Predictions Max             64.1223
trainer/Q2 Predictions Min            -44.3517
trainer/Q Targets Mean                 -8.57661
trainer/Q Targets Std                  29.2153
trainer/Q Targets Max                  63.5559
trainer/Q Targets Min                 -45.8945
trainer/Log Pis Mean                   -1.36357
trainer/Log Pis Std                     0.458968
trainer/Log Pis Max                    -0.485364
trainer/Log Pis Min                    -5.62714
trainer/policy/mean Mean               -0.170984
trainer/policy/mean Std                 0.076071
trainer/policy/mean Max                -0.0810666
trainer/policy/mean Min                -0.309581
trainer/policy/normal/std Mean          0.864709
trainer/policy/normal/std Std           0.0116353
trainer/policy/normal/std Max           0.889443
trainer/policy/normal/std Min           0.825998
trainer/policy/normal/log_std Mean     -0.145453
trainer/policy/normal/log_std Std       0.0135072
trainer/policy/normal/log_std Max      -0.117159
trainer/policy/normal/log_std Min      -0.191163
trainer/Alpha                           0.618914
trainer/Alpha Loss                     -1.6138
exploration/num steps total         36000
exploration/num paths total           180
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.03408
exploration/Rewards Std                 1.4066
exploration/Rewards Max                -1.46447e-32
exploration/Rewards Min                -6.1265
exploration/Returns Mean             -206.816
exploration/Returns Std                54.2688
exploration/Returns Max              -109.971
exploration/Returns Min              -284.814
exploration/Actions Mean               -0.11964
exploration/Actions Std                 0.571465
exploration/Actions Max                 0.989809
exploration/Actions Min                -0.99335
exploration/Num Paths                  10
exploration/Average Returns          -206.816
evaluation/num steps total          82008
evaluation/num paths total            408
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.1815
evaluation/Rewards Std                  0.448
evaluation/Rewards Max                 -4.00733
evaluation/Rewards Min                 -6.126
evaluation/Returns Mean             -1041.48
evaluation/Returns Std                 85.9297
evaluation/Returns Max               -816.377
evaluation/Returns Min              -1094.71
evaluation/Actions Mean                -0.161484
evaluation/Actions Std                  0.0702877
evaluation/Actions Max                 -0.0900952
evaluation/Actions Min                 -0.232982
evaluation/Num Paths                   24
evaluation/Average Returns          -1041.48
time/data storing (s)                   0.0355059
time/evaluation sampling (s)           28.6502
time/exploration sampling (s)          11.4339
time/logging (s)                        0.0771603
time/sac training (s)                  59.1463
time/saving (s)                         0.0355329
time/training (s)                       0.000151153
time/epoch (s)                         99.3787
time/total (s)                       1682.57
Epoch                                  16
----------------------------------  ---------------
2020-11-09 15:36:56.102910 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 17 finished
----------------------------------  ---------------
replay_buffer/size                  38000
trainer/num train calls             18000
trainer/QF1 Loss                       13.1033
trainer/QF2 Loss                       13.93
trainer/Policy Loss                    11.9199
trainer/Q1 Predictions Mean           -12.6226
trainer/Q1 Predictions Std             28.1637
trainer/Q1 Predictions Max             56.637
trainer/Q1 Predictions Min            -49.4542
trainer/Q2 Predictions Mean           -12.5796
trainer/Q2 Predictions Std             28.1159
trainer/Q2 Predictions Max             56.5919
trainer/Q2 Predictions Min            -48.5315
trainer/Q Targets Mean                -12.3675
trainer/Q Targets Std                  28.7394
trainer/Q Targets Max                  57.1551
trainer/Q Targets Min                 -48.6719
trainer/Log Pis Mean                   -1.30001
trainer/Log Pis Std                     0.31612
trainer/Log Pis Max                    -0.516151
trainer/Log Pis Min                    -2.22187
trainer/policy/mean Mean               -0.157517
trainer/policy/mean Std                 0.0899062
trainer/policy/mean Max                -0.0568763
trainer/policy/mean Min                -0.309113
trainer/policy/normal/std Mean          0.868261
trainer/policy/normal/std Std           0.0113105
trainer/policy/normal/std Max           0.891961
trainer/policy/normal/std Min           0.831477
trainer/policy/normal/log_std Mean     -0.141348
trainer/policy/normal/log_std Std       0.0130742
trainer/policy/normal/log_std Max      -0.114333
trainer/policy/normal/log_std Min      -0.184551
trainer/Alpha                           0.600666
trainer/Alpha Loss                     -1.68207
exploration/num steps total         38000
exploration/num paths total           190
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -0.830783
exploration/Rewards Std                 1.43204
exploration/Rewards Max                -8.76782e-28
exploration/Rewards Min                -6.14022
exploration/Returns Mean             -166.157
exploration/Returns Std                81.447
exploration/Returns Max               -56.4938
exploration/Returns Min              -307.654
exploration/Actions Mean               -0.101663
exploration/Actions Std                 0.584275
exploration/Actions Max                 0.99127
exploration/Actions Min                -0.998236
exploration/Num Paths                  10
exploration/Average Returns          -166.157
evaluation/num steps total          86832
evaluation/num paths total            432
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.30374
evaluation/Rewards Std                  0.296716
evaluation/Rewards Max                 -4.00733
evaluation/Rewards Min                 -6.12615
evaluation/Returns Mean             -1066.05
evaluation/Returns Std                 54.887
evaluation/Returns Max               -811.175
evaluation/Returns Min              -1094.45
evaluation/Actions Mean                -0.148876
evaluation/Actions Std                  0.0836986
evaluation/Actions Max                 -0.0638537
evaluation/Actions Min                 -0.233304
evaluation/Num Paths                   24
evaluation/Average Returns          -1066.05
time/data storing (s)                   0.0315453
time/evaluation sampling (s)           30.4719
time/exploration sampling (s)          12.0995
time/logging (s)                        0.048772
time/sac training (s)                  58.573
time/saving (s)                         0.0455464
time/training (s)                       0.000141342
time/epoch (s)                        101.27
time/total (s)                       1786.68
Epoch                                  17
----------------------------------  ---------------
2020-11-09 15:38:37.489882 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 18 finished
----------------------------------  ---------------
replay_buffer/size                  40000
trainer/num train calls             19000
trainer/QF1 Loss                       14.8597
trainer/QF2 Loss                       15.2495
trainer/Policy Loss                    16.1955
trainer/Q1 Predictions Mean           -16.8089
trainer/Q1 Predictions Std             31.7906
trainer/Q1 Predictions Max             59.2978
trainer/Q1 Predictions Min            -57.3913
trainer/Q2 Predictions Mean           -16.7543
trainer/Q2 Predictions Std             31.7265
trainer/Q2 Predictions Max             59.2783
trainer/Q2 Predictions Min            -59.8132
trainer/Q Targets Mean                -17.2626
trainer/Q Targets Std                  32.0168
trainer/Q Targets Max                  59.6039
trainer/Q Targets Min                 -57.7352
trainer/Log Pis Mean                   -1.32175
trainer/Log Pis Std                     0.369207
trainer/Log Pis Max                    -0.458027
trainer/Log Pis Min                    -2.57258
trainer/policy/mean Mean               -0.185924
trainer/policy/mean Std                 0.0967842
trainer/policy/mean Max                -0.0753567
trainer/policy/mean Min                -0.355232
trainer/policy/normal/std Mean          0.866734
trainer/policy/normal/std Std           0.0149858
trainer/policy/normal/std Max           0.895402
trainer/policy/normal/std Min           0.821225
trainer/policy/normal/log_std Mean     -0.143174
trainer/policy/normal/log_std Std       0.0173614
trainer/policy/normal/log_std Max      -0.110482
trainer/policy/normal/log_std Min      -0.196958
trainer/Alpha                           0.582974
trainer/Alpha Loss                     -1.79246
exploration/num steps total         40000
exploration/num paths total           200
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -1.21054
exploration/Rewards Std                 1.44394
exploration/Rewards Max                -1.81204e-20
exploration/Rewards Min                -6.1388
exploration/Returns Mean             -242.108
exploration/Returns Std                74.6433
exploration/Returns Max               -60.2539
exploration/Returns Min              -338.142
exploration/Actions Mean               -0.119945
exploration/Actions Std                 0.580294
exploration/Actions Max                 0.99728
exploration/Actions Min                -0.999179
exploration/Num Paths                  10
exploration/Average Returns          -242.108
evaluation/num steps total          91656
evaluation/num paths total            456
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.18222
evaluation/Rewards Std                  0.493768
evaluation/Rewards Max                 -3.86671
evaluation/Rewards Min                 -6.12256
evaluation/Returns Mean             -1041.63
evaluation/Returns Std                 95.9946
evaluation/Returns Max               -781.471
evaluation/Returns Min              -1085.63
evaluation/Actions Mean                -0.176901
evaluation/Actions Std                  0.0905797
evaluation/Actions Max                 -0.0847541
evaluation/Actions Min                 -0.26958
evaluation/Num Paths                   24
evaluation/Average Returns          -1041.63
time/data storing (s)                   0.0323762
time/evaluation sampling (s)           28.402
time/exploration sampling (s)          11.454
time/logging (s)                        0.0550362
time/sac training (s)                  59.0382
time/saving (s)                         0.0445837
time/training (s)                       0.000141807
time/epoch (s)                         99.0263
time/total (s)                       1888.05
Epoch                                  18
----------------------------------  ---------------
2020-11-09 15:40:38.788063 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 19 finished
----------------------------------  ---------------
replay_buffer/size                  42000
trainer/num train calls             20000
trainer/QF1 Loss                        3.81236
trainer/QF2 Loss                        4.19048
trainer/Policy Loss                    14.5027
trainer/Q1 Predictions Mean           -15.0959
trainer/Q1 Predictions Std             33.322
trainer/Q1 Predictions Max             73.8685
trainer/Q1 Predictions Min            -60.5667
trainer/Q2 Predictions Mean           -15.1359
trainer/Q2 Predictions Std             33.335
trainer/Q2 Predictions Max             74.0254
trainer/Q2 Predictions Min            -61.5615
trainer/Q Targets Mean                -15.2565
trainer/Q Targets Std                  33.8343
trainer/Q Targets Max                  73.544
trainer/Q Targets Min                 -60.3572
trainer/Log Pis Mean                   -1.33301
trainer/Log Pis Std                     0.451658
trainer/Log Pis Max                    -0.300927
trainer/Log Pis Min                    -2.53231
trainer/policy/mean Mean               -0.218984
trainer/policy/mean Std                 0.11477
trainer/policy/mean Max                -0.0884165
trainer/policy/mean Min                -0.402899
trainer/policy/normal/std Mean          0.857328
trainer/policy/normal/std Std           0.0160166
trainer/policy/normal/std Max           0.88988
trainer/policy/normal/std Min           0.813351
trainer/policy/normal/log_std Mean     -0.15411
trainer/policy/normal/log_std Std       0.018746
trainer/policy/normal/log_std Max      -0.116669
trainer/policy/normal/log_std Min      -0.206593
trainer/Alpha                           0.565793
trainer/Alpha Loss                     -1.89824
exploration/num steps total         42000
exploration/num paths total           210
exploration/path length Mean          200
exploration/path length Std             3
exploration/path length Max           201
exploration/path length Min           191
exploration/Rewards Mean               -0.804356
exploration/Rewards Std                 1.34339
exploration/Rewards Max                -5.66773e-37
exploration/Rewards Min                -6.08053
exploration/Returns Mean             -160.871
exploration/Returns Std                68.1404
exploration/Returns Max               -78.2461
exploration/Returns Min              -300.045
exploration/Actions Mean               -0.13745
exploration/Actions Std                 0.574808
exploration/Actions Max                 0.988699
exploration/Actions Min                -0.999143
exploration/Num Paths                  10
exploration/Average Returns          -160.871
evaluation/num steps total          96480
evaluation/num paths total            480
evaluation/path length Mean           201
evaluation/path length Std              0
evaluation/path length Max            201
evaluation/path length Min            201
evaluation/Rewards Mean                -5.2403
evaluation/Rewards Std                  0.439435
evaluation/Rewards Max                 -3.80666
evaluation/Rewards Min                 -6.12077
evaluation/Returns Mean             -1053.3
evaluation/Returns Std                 85.304
evaluation/Returns Max               -768.85
evaluation/Returns Min              -1084.42
evaluation/Actions Mean                -0.209455
evaluation/Actions Std                  0.108612
evaluation/Actions Max                 -0.0989045
evaluation/Actions Min                 -0.319778
evaluation/Num Paths                   24
evaluation/Average Returns          -1053.3
time/data storing (s)                   0.0386776
time/evaluation sampling (s)           31.0096
time/exploration sampling (s)          14.5532
time/logging (s)                        0.154126
time/sac training (s)                  71.7275
time/saving (s)                         0.151706
time/training (s)                       0.000156606
time/epoch (s)                        117.635
time/total (s)                       2009.4
Epoch                                  19
----------------------------------  ---------------
2020-11-09 15:42:30.309709 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 20 finished
----------------------------------  ----------------
replay_buffer/size                   44000
trainer/num train calls              21000
trainer/QF1 Loss                        16.9478
trainer/QF2 Loss                        17.2575
trainer/Policy Loss                     17.393
trainer/Q1 Predictions Mean            -18.0101
trainer/Q1 Predictions Std              35.2762
trainer/Q1 Predictions Max              61.6005
trainer/Q1 Predictions Min             -64.4493
trainer/Q2 Predictions Mean            -18.0143
trainer/Q2 Predictions Std              35.2241
trainer/Q2 Predictions Max              61.7126
trainer/Q2 Predictions Min             -64.2332
trainer/Q Targets Mean                 -17.9228
trainer/Q Targets Std                   35.6349
trainer/Q Targets Max                   62.6757
trainer/Q Targets Min                  -62.7394
trainer/Log Pis Mean                    -1.21523
trainer/Log Pis Std                      0.466437
trainer/Log Pis Max                     -0.316417
trainer/Log Pis Min                     -2.94055
trainer/policy/mean Mean                -0.229133
trainer/policy/mean Std                  0.138425
trainer/policy/mean Max                 -0.0750438
trainer/policy/mean Min                 -0.456443
trainer/policy/normal/std Mean           0.852425
trainer/policy/normal/std Std            0.0182627
trainer/policy/normal/std Max            0.889163
trainer/policy/normal/std Min            0.798835
trainer/policy/normal/log_std Mean      -0.159901
trainer/policy/normal/log_std Std        0.0214951
trainer/policy/normal/log_std Max       -0.117475
trainer/policy/normal/log_std Min       -0.224601
trainer/Alpha                            0.549131
trainer/Alpha Loss                      -1.92727
exploration/num steps total          44000
exploration/num paths total            220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.940965
exploration/Rewards Std                  1.41264
exploration/Rewards Max                 -5.41899e-31
exploration/Rewards Min                 -6.14045
exploration/Returns Mean              -188.193
exploration/Returns Std                 59.4397
exploration/Returns Max               -115.874
exploration/Returns Min               -329.073
exploration/Actions Mean                -0.154303
exploration/Actions Std                  0.570359
exploration/Actions Max                  0.990645
exploration/Actions Min                 -0.996034
exploration/Num Paths                   10
exploration/Average Returns           -188.193
evaluation/num steps total          101304
evaluation/num paths total             504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.22547
evaluation/Rewards Std                   0.497489
evaluation/Rewards Max                  -3.58352
evaluation/Rewards Min                  -6.11897
evaluation/Returns Mean              -1050.32
evaluation/Returns Std                  97.842
evaluation/Returns Max                -724.765
evaluation/Returns Min               -1097.06
evaluation/Actions Mean                 -0.223638
evaluation/Actions Std                   0.133883
evaluation/Actions Max                  -0.0882733
evaluation/Actions Min                  -0.360043
evaluation/Num Paths                    24
evaluation/Average Returns           -1050.32
time/data storing (s)                    0.0343753
time/evaluation sampling (s)            32.496
time/exploration sampling (s)            9.59554
time/logging (s)                         0.0505665
time/sac training (s)                   64.1398
time/saving (s)                          0.0586138
time/training (s)                        0.000173672
time/epoch (s)                         106.375
time/total (s)                        2120.78
Epoch                                   20
----------------------------------  ----------------
2020-11-09 15:44:05.947532 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 21 finished
----------------------------------  ----------------
replay_buffer/size                   46000
trainer/num train calls              22000
trainer/QF1 Loss                        30.5902
trainer/QF2 Loss                        29.7498
trainer/Policy Loss                     20.3432
trainer/Q1 Predictions Mean            -20.9627
trainer/Q1 Predictions Std              34.9916
trainer/Q1 Predictions Max              65.8254
trainer/Q1 Predictions Min             -72.8191
trainer/Q2 Predictions Mean            -20.8607
trainer/Q2 Predictions Std              34.8955
trainer/Q2 Predictions Max              65.647
trainer/Q2 Predictions Min             -73.2295
trainer/Q Targets Mean                 -21.3969
trainer/Q Targets Std                   35.4964
trainer/Q Targets Max                   65.3142
trainer/Q Targets Min                  -71.6385
trainer/Log Pis Mean                    -1.24019
trainer/Log Pis Std                      0.536098
trainer/Log Pis Max                     -0.149211
trainer/Log Pis Min                     -4.44222
trainer/policy/mean Mean                -0.258043
trainer/policy/mean Std                  0.127619
trainer/policy/mean Max                 -0.104847
trainer/policy/mean Min                 -0.476416
trainer/policy/normal/std Mean           0.849683
trainer/policy/normal/std Std            0.0161727
trainer/policy/normal/std Max            0.887715
trainer/policy/normal/std Min            0.798419
trainer/policy/normal/log_std Mean      -0.163074
trainer/policy/normal/log_std Std        0.0190793
trainer/policy/normal/log_std Max       -0.119105
trainer/policy/normal/log_std Min       -0.225122
trainer/Alpha                            0.532986
trainer/Alpha Loss                      -2.03892
exploration/num steps total          46000
exploration/num paths total            230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.761874
exploration/Rewards Std                  1.37122
exploration/Rewards Max                 -1.38577e-47
exploration/Rewards Min                 -6.13861
exploration/Returns Mean              -152.375
exploration/Returns Std                 66.5185
exploration/Returns Max                -50.1472
exploration/Returns Min               -283.983
exploration/Actions Mean                -0.184451
exploration/Actions Std                  0.569381
exploration/Actions Max                  0.997934
exploration/Actions Min                 -0.99741
exploration/Num Paths                   10
exploration/Average Returns           -152.375
evaluation/num steps total          106128
evaluation/num paths total             528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.32525
evaluation/Rewards Std                   0.377505
evaluation/Rewards Max                  -3.58352
evaluation/Rewards Min                  -6.1169
evaluation/Returns Mean              -1070.38
evaluation/Returns Std                  73.1852
evaluation/Returns Max                -726.432
evaluation/Returns Min               -1105.8
evaluation/Actions Mean                 -0.253166
evaluation/Actions Std                   0.123709
evaluation/Actions Max                  -0.126761
evaluation/Actions Min                  -0.379155
evaluation/Num Paths                    24
evaluation/Average Returns           -1070.38
time/data storing (s)                    0.0449058
time/evaluation sampling (s)            23.3261
time/exploration sampling (s)            9.3655
time/logging (s)                         0.0601546
time/sac training (s)                   60.2389
time/saving (s)                          0.0819632
time/training (s)                        0.000133282
time/epoch (s)                          93.1176
time/total (s)                        2216.39
Epoch                                   21
----------------------------------  ----------------
2020-11-09 15:45:49.875884 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 22 finished
----------------------------------  ----------------
replay_buffer/size                   48000
trainer/num train calls              23000
trainer/QF1 Loss                        28.3992
trainer/QF2 Loss                        28.7273
trainer/Policy Loss                     22.5889
trainer/Q1 Predictions Mean            -23.0825
trainer/Q1 Predictions Std              35.3476
trainer/Q1 Predictions Max              66.366
trainer/Q1 Predictions Min             -75.7228
trainer/Q2 Predictions Mean            -23.0892
trainer/Q2 Predictions Std              35.3175
trainer/Q2 Predictions Max              66.2037
trainer/Q2 Predictions Min             -75.1145
trainer/Q Targets Mean                 -23.2989
trainer/Q Targets Std                   35.1057
trainer/Q Targets Max                   65.375
trainer/Q Targets Min                  -73.9927
trainer/Log Pis Mean                    -1.21655
trainer/Log Pis Std                      0.503988
trainer/Log Pis Max                     -0.0365639
trainer/Log Pis Min                     -3.1543
trainer/policy/mean Mean                -0.268553
trainer/policy/mean Std                  0.138763
trainer/policy/mean Max                 -0.0966229
trainer/policy/mean Min                 -0.487189
trainer/policy/normal/std Mean           0.848249
trainer/policy/normal/std Std            0.0228863
trainer/policy/normal/std Max            0.899664
trainer/policy/normal/std Min            0.794482
trainer/policy/normal/log_std Mean      -0.164947
trainer/policy/normal/log_std Std        0.0270628
trainer/policy/normal/log_std Max       -0.105734
trainer/policy/normal/log_std Min       -0.230066
trainer/Alpha                            0.517329
trainer/Alpha Loss                      -2.11995
exploration/num steps total          48000
exploration/num paths total            240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.625382
exploration/Rewards Std                  1.17723
exploration/Rewards Max                 -1.06437e-26
exploration/Rewards Min                 -6.10504
exploration/Returns Mean              -125.076
exploration/Returns Std                 68.4594
exploration/Returns Max                 -6.79693
exploration/Returns Min               -264.319
exploration/Actions Mean                -0.181397
exploration/Actions Std                  0.572277
exploration/Actions Max                  0.993443
exploration/Actions Min                 -0.998275
exploration/Num Paths                   10
exploration/Average Returns           -125.076
evaluation/num steps total          110952
evaluation/num paths total             552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39739
evaluation/Rewards Std                   0.399018
evaluation/Rewards Max                  -3.55852
evaluation/Rewards Min                  -6.11606
evaluation/Returns Mean              -1084.88
evaluation/Returns Std                  78.5559
evaluation/Returns Max                -726.64
evaluation/Returns Min               -1115.99
evaluation/Actions Mean                 -0.26658
evaluation/Actions Std                   0.135849
evaluation/Actions Max                  -0.125773
evaluation/Actions Min                  -0.40387
evaluation/Num Paths                    24
evaluation/Average Returns           -1084.88
time/data storing (s)                    0.0468903
time/evaluation sampling (s)            24.9978
time/exploration sampling (s)           11.3817
time/logging (s)                         0.0704264
time/sac training (s)                   63.4006
time/saving (s)                          0.410397
time/training (s)                        0.000454533
time/epoch (s)                         100.308
time/total (s)                        2320.3
Epoch                                   22
----------------------------------  ----------------
2020-11-09 15:47:34.574905 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 23 finished
----------------------------------  ----------------
replay_buffer/size                   50000
trainer/num train calls              24000
trainer/QF1 Loss                        12.7229
trainer/QF2 Loss                        12.2139
trainer/Policy Loss                     22.6564
trainer/Q1 Predictions Mean            -23.2017
trainer/Q1 Predictions Std              37.0481
trainer/Q1 Predictions Max              67.026
trainer/Q1 Predictions Min             -75.3521
trainer/Q2 Predictions Mean            -23.2007
trainer/Q2 Predictions Std              37.0685
trainer/Q2 Predictions Max              66.9634
trainer/Q2 Predictions Min             -75.4094
trainer/Q Targets Mean                 -23.437
trainer/Q Targets Std                   37.5166
trainer/Q Targets Max                   67.1721
trainer/Q Targets Min                  -74.1816
trainer/Log Pis Mean                    -1.16367
trainer/Log Pis Std                      0.532155
trainer/Log Pis Max                     -0.0544052
trainer/Log Pis Min                     -2.80732
trainer/policy/mean Mean                -0.28047
trainer/policy/mean Std                  0.140569
trainer/policy/mean Max                 -0.0994674
trainer/policy/mean Min                 -0.536995
trainer/policy/normal/std Mean           0.852046
trainer/policy/normal/std Std            0.0248703
trainer/policy/normal/std Max            0.907507
trainer/policy/normal/std Min            0.782744
trainer/policy/normal/log_std Mean      -0.160543
trainer/policy/normal/log_std Std        0.0292966
trainer/policy/normal/log_std Max       -0.0970545
trainer/policy/normal/log_std Min       -0.24495
trainer/Alpha                            0.502135
trainer/Alpha Loss                      -2.1794
exploration/num steps total          50000
exploration/num paths total            250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.91398
exploration/Rewards Std                  1.52946
exploration/Rewards Max                 -2.05808e-68
exploration/Rewards Min                 -6.13488
exploration/Returns Mean              -182.796
exploration/Returns Std                 45.4476
exploration/Returns Max               -120.331
exploration/Returns Min               -268.705
exploration/Actions Mean                -0.202904
exploration/Actions Std                  0.567072
exploration/Actions Max                  0.994721
exploration/Actions Min                 -0.995238
exploration/Num Paths                   10
exploration/Average Returns           -182.796
evaluation/num steps total          115776
evaluation/num paths total             576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.94237
evaluation/Rewards Std                   0.914627
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.11108
evaluation/Returns Mean               -993.416
evaluation/Returns Std                 179.8
evaluation/Returns Max                -674.242
evaluation/Returns Min               -1115.91
evaluation/Actions Mean                 -0.279812
evaluation/Actions Std                   0.137808
evaluation/Actions Max                  -0.139626
evaluation/Actions Min                  -0.422367
evaluation/Num Paths                    24
evaluation/Average Returns            -993.416
time/data storing (s)                    0.0297711
time/evaluation sampling (s)            20.2711
time/exploration sampling (s)            9.72263
time/logging (s)                         0.0994283
time/sac training (s)                   70.564
time/saving (s)                          0.170742
time/training (s)                        0.000160875
time/epoch (s)                         100.858
time/total (s)                        2424.98
Epoch                                   23
----------------------------------  ----------------
2020-11-09 15:49:18.130845 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 24 finished
----------------------------------  ----------------
replay_buffer/size                   52000
trainer/num train calls              25000
trainer/QF1 Loss                        12.7698
trainer/QF2 Loss                        13.5341
trainer/Policy Loss                     22.2169
trainer/Q1 Predictions Mean            -22.6899
trainer/Q1 Predictions Std              39.0178
trainer/Q1 Predictions Max              68.6449
trainer/Q1 Predictions Min             -79.8611
trainer/Q2 Predictions Mean            -22.6977
trainer/Q2 Predictions Std              39.0135
trainer/Q2 Predictions Max              68.2846
trainer/Q2 Predictions Min             -79.7182
trainer/Q Targets Mean                 -22.5596
trainer/Q Targets Std                   39.5855
trainer/Q Targets Max                   67.4472
trainer/Q Targets Min                  -78.4761
trainer/Log Pis Mean                    -1.23927
trainer/Log Pis Std                      0.556385
trainer/Log Pis Max                     -0.0563166
trainer/Log Pis Min                     -3.33058
trainer/policy/mean Mean                -0.270489
trainer/policy/mean Std                  0.129107
trainer/policy/mean Max                 -0.0943189
trainer/policy/mean Min                 -0.492875
trainer/policy/normal/std Mean           0.850635
trainer/policy/normal/std Std            0.021021
trainer/policy/normal/std Max            0.907775
trainer/policy/normal/std Min            0.793063
trainer/policy/normal/log_std Mean      -0.162078
trainer/policy/normal/log_std Std        0.0247779
trainer/policy/normal/log_std Max       -0.0967582
trainer/policy/normal/log_std Min       -0.231853
trainer/Alpha                            0.487321
trainer/Alpha Loss                      -2.32849
exploration/num steps total          52000
exploration/num paths total            260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.991946
exploration/Rewards Std                  1.61367
exploration/Rewards Max                 -3.80978e-42
exploration/Rewards Min                 -6.13306
exploration/Returns Mean              -198.389
exploration/Returns Std                 70.0178
exploration/Returns Max               -111.927
exploration/Returns Min               -335.718
exploration/Actions Mean                -0.180613
exploration/Actions Std                  0.573371
exploration/Actions Max                  0.996752
exploration/Actions Min                 -0.995326
exploration/Num Paths                   10
exploration/Average Returns           -198.389
evaluation/num steps total          120600
evaluation/num paths total             600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.16651
evaluation/Rewards Std                   0.586286
evaluation/Rewards Max                  -3.58352
evaluation/Rewards Min                  -6.11874
evaluation/Returns Mean              -1038.47
evaluation/Returns Std                 113.8
evaluation/Returns Max                -726.982
evaluation/Returns Min               -1097.8
evaluation/Actions Mean                 -0.266922
evaluation/Actions Std                   0.125046
evaluation/Actions Max                  -0.138861
evaluation/Actions Min                  -0.395497
evaluation/Num Paths                    24
evaluation/Average Returns           -1038.47
time/data storing (s)                    0.0358116
time/evaluation sampling (s)            28.6186
time/exploration sampling (s)           10.553
time/logging (s)                         0.121682
time/sac training (s)                   60.8939
time/saving (s)                          0.0459932
time/training (s)                        0.000146591
time/epoch (s)                         100.269
time/total (s)                        2528.53
Epoch                                   24
----------------------------------  ----------------
2020-11-09 15:50:53.702569 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 25 finished
----------------------------------  ----------------
replay_buffer/size                   54000
trainer/num train calls              26000
trainer/QF1 Loss                         4.57749
trainer/QF2 Loss                         4.84241
trainer/Policy Loss                     24.7715
trainer/Q1 Predictions Mean            -25.2102
trainer/Q1 Predictions Std              40.6027
trainer/Q1 Predictions Max              89.0689
trainer/Q1 Predictions Min             -83.3242
trainer/Q2 Predictions Mean            -25.1994
trainer/Q2 Predictions Std              40.5426
trainer/Q2 Predictions Max              89.1729
trainer/Q2 Predictions Min             -83.7288
trainer/Q Targets Mean                 -25.1973
trainer/Q Targets Std                   41.0848
trainer/Q Targets Max                   89.0265
trainer/Q Targets Min                  -84.1047
trainer/Log Pis Mean                    -1.2138
trainer/Log Pis Std                      0.594788
trainer/Log Pis Max                     -0.0536809
trainer/Log Pis Min                     -2.79663
trainer/policy/mean Mean                -0.292563
trainer/policy/mean Std                  0.155796
trainer/policy/mean Max                 -0.0864253
trainer/policy/mean Min                 -0.578963
trainer/policy/normal/std Mean           0.843996
trainer/policy/normal/std Std            0.0257302
trainer/policy/normal/std Max            0.909252
trainer/policy/normal/std Min            0.768265
trainer/policy/normal/log_std Mean      -0.170074
trainer/policy/normal/log_std Std        0.0305854
trainer/policy/normal/log_std Max       -0.095133
trainer/policy/normal/log_std Min       -0.263621
trainer/Alpha                            0.47297
trainer/Alpha Loss                      -2.40625
exploration/num steps total          54000
exploration/num paths total            270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.810074
exploration/Rewards Std                  1.35036
exploration/Rewards Max                 -3.59011e-48
exploration/Rewards Min                 -6.12895
exploration/Returns Mean              -162.015
exploration/Returns Std                 71.7903
exploration/Returns Max                -98.868
exploration/Returns Min               -323.986
exploration/Actions Mean                -0.215829
exploration/Actions Std                  0.564474
exploration/Actions Max                  0.99053
exploration/Actions Min                 -0.995745
exploration/Num Paths                   10
exploration/Average Returns           -162.015
evaluation/num steps total          125424
evaluation/num paths total             624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.1913
evaluation/Rewards Std                   0.580378
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.11622
evaluation/Returns Mean              -1043.45
evaluation/Returns Std                 114.904
evaluation/Returns Max                -671.751
evaluation/Returns Min               -1115.87
evaluation/Actions Mean                 -0.295511
evaluation/Actions Std                   0.154143
evaluation/Actions Max                  -0.138085
evaluation/Actions Min                  -0.455512
evaluation/Num Paths                    24
evaluation/Average Returns           -1043.45
time/data storing (s)                    0.0333071
time/evaluation sampling (s)            26.0465
time/exploration sampling (s)           10.3318
time/logging (s)                         0.0522449
time/sac training (s)                   56.4724
time/saving (s)                          0.0514702
time/training (s)                        0.000147743
time/epoch (s)                          92.9878
time/total (s)                        2624
Epoch                                   25
----------------------------------  ----------------
2020-11-09 15:52:31.359000 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 26 finished
----------------------------------  ----------------
replay_buffer/size                   56000
trainer/num train calls              27000
trainer/QF1 Loss                        27.2542
trainer/QF2 Loss                        28.3275
trainer/Policy Loss                     27.6153
trainer/Q1 Predictions Mean            -28.0183
trainer/Q1 Predictions Std              41.5762
trainer/Q1 Predictions Max              71.157
trainer/Q1 Predictions Min             -97.626
trainer/Q2 Predictions Mean            -27.9987
trainer/Q2 Predictions Std              41.5762
trainer/Q2 Predictions Max              71.0071
trainer/Q2 Predictions Min             -96.9011
trainer/Q Targets Mean                 -27.8913
trainer/Q Targets Std                   42.0193
trainer/Q Targets Max                   70.8954
trainer/Q Targets Min                  -95.7204
trainer/Log Pis Mean                    -1.15502
trainer/Log Pis Std                      0.559835
trainer/Log Pis Max                     -0.0280361
trainer/Log Pis Min                     -2.65037
trainer/policy/mean Mean                -0.268577
trainer/policy/mean Std                  0.184911
trainer/policy/mean Max                 -0.0471451
trainer/policy/mean Min                 -0.561083
trainer/policy/normal/std Mean           0.847239
trainer/policy/normal/std Std            0.0268777
trainer/policy/normal/std Max            0.917253
trainer/policy/normal/std Min            0.781262
trainer/policy/normal/log_std Mean      -0.166277
trainer/policy/normal/log_std Std        0.0317841
trainer/policy/normal/log_std Max       -0.0863721
trainer/policy/normal/log_std Min       -0.246845
trainer/Alpha                            0.459033
trainer/Alpha Loss                      -2.4566
exploration/num steps total          56000
exploration/num paths total            280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.758729
exploration/Rewards Std                  1.36759
exploration/Rewards Max                 -7.06448e-47
exploration/Rewards Min                 -6.10286
exploration/Returns Mean              -151.746
exploration/Returns Std                 56.8583
exploration/Returns Max                -66.9875
exploration/Returns Min               -253.515
exploration/Actions Mean                -0.18103
exploration/Actions Std                  0.576916
exploration/Actions Max                  0.996854
exploration/Actions Min                 -0.997062
exploration/Num Paths                   10
exploration/Average Returns           -151.746
evaluation/num steps total          130248
evaluation/num paths total             648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.14149
evaluation/Rewards Std                   0.694245
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.11604
evaluation/Returns Mean              -1033.44
evaluation/Returns Std                 137.554
evaluation/Returns Max                -675.817
evaluation/Returns Min               -1115.12
evaluation/Actions Mean                 -0.270707
evaluation/Actions Std                   0.183439
evaluation/Actions Max                  -0.086175
evaluation/Actions Min                  -0.458205
evaluation/Num Paths                    24
evaluation/Average Returns           -1033.44
time/data storing (s)                    0.0509075
time/evaluation sampling (s)            25.8738
time/exploration sampling (s)           12.0946
time/logging (s)                         0.0558623
time/sac training (s)                   55.8795
time/saving (s)                          0.0435277
time/training (s)                        0.000193316
time/epoch (s)                          93.9984
time/total (s)                        2721.63
Epoch                                   26
----------------------------------  ----------------
2020-11-09 15:54:03.973204 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 27 finished
----------------------------------  ----------------
replay_buffer/size                   58000
trainer/num train calls              28000
trainer/QF1 Loss                        26.5591
trainer/QF2 Loss                        27.0585
trainer/Policy Loss                     30.1891
trainer/Q1 Predictions Mean            -30.6425
trainer/Q1 Predictions Std              42.7704
trainer/Q1 Predictions Max              75.4636
trainer/Q1 Predictions Min            -107.304
trainer/Q2 Predictions Mean            -30.6066
trainer/Q2 Predictions Std              42.7236
trainer/Q2 Predictions Max              75.4204
trainer/Q2 Predictions Min            -105.814
trainer/Q Targets Mean                 -30.6107
trainer/Q Targets Std                   42.7943
trainer/Q Targets Max                   74.4498
trainer/Q Targets Min                 -106.407
trainer/Log Pis Mean                    -1.17978
trainer/Log Pis Std                      0.554784
trainer/Log Pis Max                     -0.0583539
trainer/Log Pis Min                     -2.92516
trainer/policy/mean Mean                -0.270971
trainer/policy/mean Std                  0.191971
trainer/policy/mean Max                 -0.0417532
trainer/policy/mean Min                 -0.576155
trainer/policy/normal/std Mean           0.849409
trainer/policy/normal/std Std            0.0314164
trainer/policy/normal/std Max            0.922795
trainer/policy/normal/std Min            0.776274
trainer/policy/normal/log_std Mean      -0.163902
trainer/policy/normal/log_std Std        0.0371198
trainer/policy/normal/log_std Max       -0.0803484
trainer/policy/normal/log_std Min       -0.253249
trainer/Alpha                            0.445533
trainer/Alpha Loss                      -2.5708
exploration/num steps total          58000
exploration/num paths total            290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.985165
exploration/Rewards Std                  1.48638
exploration/Rewards Max                 -1.94667e-31
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -197.033
exploration/Returns Std                 69.3193
exploration/Returns Max               -107.227
exploration/Returns Min               -328.441
exploration/Actions Mean                -0.209839
exploration/Actions Std                  0.571845
exploration/Actions Max                  0.993085
exploration/Actions Min                 -0.993985
exploration/Num Paths                   10
exploration/Average Returns           -197.033
evaluation/num steps total          135072
evaluation/num paths total             672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.23554
evaluation/Rewards Std                   0.599379
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.11585
evaluation/Returns Mean              -1052.34
evaluation/Returns Std                 118.959
evaluation/Returns Max                -675.375
evaluation/Returns Min               -1130.75
evaluation/Actions Mean                 -0.274578
evaluation/Actions Std                   0.190882
evaluation/Actions Max                  -0.0821499
evaluation/Actions Min                  -0.470176
evaluation/Num Paths                    24
evaluation/Average Returns           -1052.34
time/data storing (s)                    0.0295918
time/evaluation sampling (s)            26.717
time/exploration sampling (s)            9.41112
time/logging (s)                         0.0576873
time/sac training (s)                   52.3414
time/saving (s)                          0.0415399
time/training (s)                        0.000156487
time/epoch (s)                          88.5985
time/total (s)                        2814.21
Epoch                                   27
----------------------------------  ----------------
2020-11-09 15:55:44.232259 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 28 finished
----------------------------------  ----------------
replay_buffer/size                   60000
trainer/num train calls              29000
trainer/QF1 Loss                        10.6922
trainer/QF2 Loss                        10.8518
trainer/Policy Loss                     30.5936
trainer/Q1 Predictions Mean            -30.9859
trainer/Q1 Predictions Std              43.4134
trainer/Q1 Predictions Max              75.5035
trainer/Q1 Predictions Min            -103.065
trainer/Q2 Predictions Mean            -30.9965
trainer/Q2 Predictions Std              43.4479
trainer/Q2 Predictions Max              75.3951
trainer/Q2 Predictions Min            -103.213
trainer/Q Targets Mean                 -31.0409
trainer/Q Targets Std                   43.8692
trainer/Q Targets Max                   74.587
trainer/Q Targets Min                 -101.053
trainer/Log Pis Mean                    -1.11518
trainer/Log Pis Std                      0.665511
trainer/Log Pis Max                      0.0831461
trainer/Log Pis Min                     -3.9602
trainer/policy/mean Mean                -0.322964
trainer/policy/mean Std                  0.183487
trainer/policy/mean Max                 -0.0760172
trainer/policy/mean Min                 -0.612894
trainer/policy/normal/std Mean           0.837368
trainer/policy/normal/std Std            0.0337297
trainer/policy/normal/std Max            0.915482
trainer/policy/normal/std Min            0.762158
trainer/policy/normal/log_std Mean      -0.178307
trainer/policy/normal/log_std Std        0.0404045
trainer/policy/normal/log_std Max       -0.0883048
trainer/policy/normal/log_std Min       -0.271602
trainer/Alpha                            0.432473
trainer/Alpha Loss                      -2.61125
exploration/num steps total          60000
exploration/num paths total            300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.751918
exploration/Rewards Std                  1.41593
exploration/Rewards Max                 -8.4706e-48
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -150.384
exploration/Returns Std                 38.3817
exploration/Returns Max                -94.5429
exploration/Returns Min               -212.337
exploration/Actions Mean                -0.238647
exploration/Actions Std                  0.566629
exploration/Actions Max                  0.990342
exploration/Actions Min                 -0.998347
exploration/Num Paths                   10
exploration/Average Returns           -150.384
evaluation/num steps total          139896
evaluation/num paths total             696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.21
evaluation/Rewards Std                   0.69634
evaluation/Rewards Max                  -3.04452
evaluation/Rewards Min                  -6.0999
evaluation/Returns Mean              -1047.21
evaluation/Returns Std                 138.251
evaluation/Returns Max                -613.514
evaluation/Returns Min               -1134.88
evaluation/Actions Mean                 -0.328377
evaluation/Actions Std                   0.181679
evaluation/Actions Max                  -0.14152
evaluation/Actions Min                  -0.516357
evaluation/Num Paths                    24
evaluation/Average Returns           -1047.21
time/data storing (s)                    0.122188
time/evaluation sampling (s)            31.0532
time/exploration sampling (s)           12.0609
time/logging (s)                         0.0870816
time/sac training (s)                   53.8385
time/saving (s)                          0.0499789
time/training (s)                        0.000151204
time/epoch (s)                          97.212
time/total (s)                        2914.47
Epoch                                   28
----------------------------------  ----------------
2020-11-09 15:57:22.789289 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 29 finished
----------------------------------  ----------------
replay_buffer/size                   62000
trainer/num train calls              30000
trainer/QF1 Loss                        57.4629
trainer/QF2 Loss                        59.9773
trainer/Policy Loss                     28.7119
trainer/Q1 Predictions Mean            -29.0391
trainer/Q1 Predictions Std              47.9703
trainer/Q1 Predictions Max              98.2517
trainer/Q1 Predictions Min            -105.004
trainer/Q2 Predictions Mean            -29.023
trainer/Q2 Predictions Std              47.9659
trainer/Q2 Predictions Max              98.2449
trainer/Q2 Predictions Min            -104.057
trainer/Q Targets Mean                 -28.6508
trainer/Q Targets Std                   48.6231
trainer/Q Targets Max                   98.2707
trainer/Q Targets Min                 -103.417
trainer/Log Pis Mean                    -1.1144
trainer/Log Pis Std                      0.647651
trainer/Log Pis Max                      0.0793681
trainer/Log Pis Min                     -3.4683
trainer/policy/mean Mean                -0.327649
trainer/policy/mean Std                  0.184083
trainer/policy/mean Max                 -0.0743023
trainer/policy/mean Min                 -0.62586
trainer/policy/normal/std Mean           0.835475
trainer/policy/normal/std Std            0.0343662
trainer/policy/normal/std Max            0.916432
trainer/policy/normal/std Min            0.755615
trainer/policy/normal/log_std Mean      -0.180605
trainer/policy/normal/log_std Std        0.0412679
trainer/policy/normal/log_std Max       -0.0872671
trainer/policy/normal/log_std Min       -0.280223
trainer/Alpha                            0.41974
trainer/Alpha Loss                      -2.70367
exploration/num steps total          62000
exploration/num paths total            310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.662939
exploration/Rewards Std                  1.31593
exploration/Rewards Max                 -1.22708e-51
exploration/Rewards Min                 -6.13821
exploration/Returns Mean              -132.588
exploration/Returns Std                 66.8002
exploration/Returns Max                -42.314
exploration/Returns Min               -269.869
exploration/Actions Mean                -0.233042
exploration/Actions Std                  0.571047
exploration/Actions Max                  0.980496
exploration/Actions Min                 -0.997644
exploration/Num Paths                   10
exploration/Average Returns           -132.588
evaluation/num steps total          144720
evaluation/num paths total             720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.3166
evaluation/Rewards Std                   0.529326
evaluation/Rewards Max                  -3.04452
evaluation/Rewards Min                  -6.11477
evaluation/Returns Mean              -1068.64
evaluation/Returns Std                 105.048
evaluation/Returns Max                -619.72
evaluation/Returns Min               -1132.37
evaluation/Actions Mean                 -0.333806
evaluation/Actions Std                   0.182328
evaluation/Actions Max                  -0.145222
evaluation/Actions Min                  -0.521107
evaluation/Num Paths                    24
evaluation/Average Returns           -1068.64
time/data storing (s)                    0.0456512
time/evaluation sampling (s)            27.6025
time/exploration sampling (s)           10.8828
time/logging (s)                         0.0702339
time/sac training (s)                   56.764
time/saving (s)                          0.0519943
time/training (s)                        0.000117355
time/epoch (s)                          95.4173
time/total (s)                        3012.98
Epoch                                   29
----------------------------------  ----------------
2020-11-09 15:58:59.445840 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 30 finished
----------------------------------  -----------------
replay_buffer/size                   64000
trainer/num train calls              31000
trainer/QF1 Loss                        13.7826
trainer/QF2 Loss                        13.706
trainer/Policy Loss                     30.2758
trainer/Q1 Predictions Mean            -30.5742
trainer/Q1 Predictions Std              43.6579
trainer/Q1 Predictions Max              77.1706
trainer/Q1 Predictions Min            -106.842
trainer/Q2 Predictions Mean            -30.6509
trainer/Q2 Predictions Std              43.755
trainer/Q2 Predictions Max              77.2991
trainer/Q2 Predictions Min            -106.588
trainer/Q Targets Mean                 -30.8017
trainer/Q Targets Std                   44.286
trainer/Q Targets Max                   77.7449
trainer/Q Targets Min                 -105.298
trainer/Log Pis Mean                    -1.16586
trainer/Log Pis Std                      0.74125
trainer/Log Pis Max                      0.0361242
trainer/Log Pis Min                     -5.48374
trainer/policy/mean Mean                -0.306195
trainer/policy/mean Std                  0.204603
trainer/policy/mean Max                 -0.0474118
trainer/policy/mean Min                 -0.638022
trainer/policy/normal/std Mean           0.840005
trainer/policy/normal/std Std            0.0360453
trainer/policy/normal/std Max            0.9211
trainer/policy/normal/std Min            0.756197
trainer/policy/normal/log_std Mean      -0.175274
trainer/policy/normal/log_std Std        0.0431381
trainer/policy/normal/log_std Max       -0.0821869
trainer/policy/normal/log_std Min       -0.279454
trainer/Alpha                            0.407442
trainer/Alpha Loss                      -2.84249
exploration/num steps total          64000
exploration/num paths total            320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.714747
exploration/Rewards Std                  1.40821
exploration/Rewards Max                 -1.04837e-106
exploration/Rewards Min                 -6.08945
exploration/Returns Mean              -142.949
exploration/Returns Std                 27.8651
exploration/Returns Max                -95.88
exploration/Returns Min               -193.788
exploration/Actions Mean                -0.22046
exploration/Actions Std                  0.571125
exploration/Actions Max                  0.99363
exploration/Actions Min                 -0.998867
exploration/Num Paths                   10
exploration/Average Returns           -142.949
evaluation/num steps total          149544
evaluation/num paths total             744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.36183
evaluation/Rewards Std                   0.25515
evaluation/Rewards Max                  -4.46169
evaluation/Rewards Min                  -6.11039
evaluation/Returns Mean              -1077.73
evaluation/Returns Std                  48.8079
evaluation/Returns Max               -1029.58
evaluation/Returns Min               -1133.77
evaluation/Actions Mean                 -0.312073
evaluation/Actions Std                   0.203244
evaluation/Actions Max                  -0.107098
evaluation/Actions Min                  -0.521431
evaluation/Num Paths                    24
evaluation/Average Returns           -1077.73
time/data storing (s)                    0.0884838
time/evaluation sampling (s)            28.0308
time/exploration sampling (s)           11.9058
time/logging (s)                         0.0465616
time/sac training (s)                   53.6554
time/saving (s)                          0.0415329
time/training (s)                        0.000144909
time/epoch (s)                          93.7687
time/total (s)                        3109.58
Epoch                                   30
----------------------------------  -----------------
2020-11-09 16:00:36.680885 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 31 finished
----------------------------------  ----------------
replay_buffer/size                   66000
trainer/num train calls              32000
trainer/QF1 Loss                        27.1072
trainer/QF2 Loss                        27.1686
trainer/Policy Loss                     29.9302
trainer/Q1 Predictions Mean            -30.3292
trainer/Q1 Predictions Std              46.2967
trainer/Q1 Predictions Max              73.4837
trainer/Q1 Predictions Min            -118.318
trainer/Q2 Predictions Mean            -30.2085
trainer/Q2 Predictions Std              46.2742
trainer/Q2 Predictions Max              73.6397
trainer/Q2 Predictions Min            -113.997
trainer/Q Targets Mean                 -30.6886
trainer/Q Targets Std                   46.3332
trainer/Q Targets Max                   74.1512
trainer/Q Targets Min                 -116.837
trainer/Log Pis Mean                    -1.05448
trainer/Log Pis Std                      0.685972
trainer/Log Pis Max                      0.199951
trainer/Log Pis Min                     -3.64117
trainer/policy/mean Mean                -0.341199
trainer/policy/mean Std                  0.194853
trainer/policy/mean Max                 -0.0702947
trainer/policy/mean Min                 -0.665712
trainer/policy/normal/std Mean           0.833981
trainer/policy/normal/std Std            0.0408823
trainer/policy/normal/std Max            0.919562
trainer/policy/normal/std Min            0.742514
trainer/policy/normal/log_std Mean      -0.182756
trainer/policy/normal/log_std Std        0.0493224
trainer/policy/normal/log_std Max       -0.0838582
trainer/policy/normal/log_std Min       -0.297713
trainer/Alpha                            0.39548
trainer/Alpha Loss                      -2.8335
exploration/num steps total          66000
exploration/num paths total            330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.815375
exploration/Rewards Std                  1.44884
exploration/Rewards Max                 -1.7817e-68
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -163.075
exploration/Returns Std                 71.9737
exploration/Returns Max                -55.4338
exploration/Returns Min               -310.694
exploration/Actions Mean                -0.247252
exploration/Actions Std                  0.563176
exploration/Actions Max                  0.991307
exploration/Actions Min                 -0.996694
exploration/Num Paths                   10
exploration/Average Returns           -163.075
evaluation/num steps total          154368
evaluation/num paths total             768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44253
evaluation/Rewards Std                   0.631019
evaluation/Rewards Max                  -2.70805
evaluation/Rewards Min                  -6.11562
evaluation/Returns Mean              -1093.95
evaluation/Returns Std                 125.845
evaluation/Returns Max                -551.015
evaluation/Returns Min               -1149.3
evaluation/Actions Mean                 -0.355352
evaluation/Actions Std                   0.194963
evaluation/Actions Max                  -0.156514
evaluation/Actions Min                  -0.552535
evaluation/Num Paths                    24
evaluation/Average Returns           -1093.95
time/data storing (s)                    0.0320443
time/evaluation sampling (s)            27.5394
time/exploration sampling (s)           11.4899
time/logging (s)                         0.0471721
time/sac training (s)                   53.5858
time/saving (s)                          0.142495
time/training (s)                        0.000183064
time/epoch (s)                          92.837
time/total (s)                        3206.79
Epoch                                   31
----------------------------------  ----------------
2020-11-09 16:02:21.427089 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 32 finished
----------------------------------  ----------------
replay_buffer/size                   68000
trainer/num train calls              33000
trainer/QF1 Loss                         7.5361
trainer/QF2 Loss                         8.2642
trainer/Policy Loss                     40.9096
trainer/Q1 Predictions Mean            -41.2505
trainer/Q1 Predictions Std              46.9729
trainer/Q1 Predictions Max              65.1366
trainer/Q1 Predictions Min            -113.182
trainer/Q2 Predictions Mean            -41.1278
trainer/Q2 Predictions Std              46.8773
trainer/Q2 Predictions Max              65.1447
trainer/Q2 Predictions Min            -110.686
trainer/Q Targets Mean                 -41.9036
trainer/Q Targets Std                   47.5923
trainer/Q Targets Max                   65.013
trainer/Q Targets Min                 -111.963
trainer/Log Pis Mean                    -1.03076
trainer/Log Pis Std                      0.712137
trainer/Log Pis Max                      0.365781
trainer/Log Pis Min                     -3.03365
trainer/policy/mean Mean                -0.369528
trainer/policy/mean Std                  0.207418
trainer/policy/mean Max                 -0.0757055
trainer/policy/mean Min                 -0.706573
trainer/policy/normal/std Mean           0.826032
trainer/policy/normal/std Std            0.0435396
trainer/policy/normal/std Max            0.915612
trainer/policy/normal/std Min            0.729762
trainer/policy/normal/log_std Mean      -0.192522
trainer/policy/normal/log_std Std        0.0530146
trainer/policy/normal/log_std Max       -0.0881622
trainer/policy/normal/log_std Min       -0.315036
trainer/Alpha                            0.383888
trainer/Alpha Loss                      -2.90166
exploration/num steps total          68000
exploration/num paths total            340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.827451
exploration/Rewards Std                  1.41574
exploration/Rewards Max                 -1.36165e-38
exploration/Rewards Min                 -6.11634
exploration/Returns Mean              -165.49
exploration/Returns Std                 37.9998
exploration/Returns Max                -99.7125
exploration/Returns Min               -225.132
exploration/Actions Mean                -0.27497
exploration/Actions Std                  0.56009
exploration/Actions Max                  0.994703
exploration/Actions Min                 -0.999235
exploration/Num Paths                   10
exploration/Average Returns           -165.49
evaluation/num steps total          159192
evaluation/num paths total             792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.43976
evaluation/Rewards Std                   0.632164
evaluation/Rewards Max                  -2.70805
evaluation/Rewards Min                  -6.11305
evaluation/Returns Mean              -1093.39
evaluation/Returns Std                 126.462
evaluation/Returns Max                -548.966
evaluation/Returns Min               -1148.03
evaluation/Actions Mean                 -0.383405
evaluation/Actions Std                   0.207123
evaluation/Actions Max                  -0.174042
evaluation/Actions Min                  -0.59229
evaluation/Num Paths                    24
evaluation/Average Returns           -1093.39
time/data storing (s)                    0.283572
time/evaluation sampling (s)            32.0501
time/exploration sampling (s)           13.8364
time/logging (s)                         0.0716215
time/sac training (s)                   55.2106
time/saving (s)                          0.0479195
time/training (s)                        0.000159213
time/epoch (s)                         101.5
time/total (s)                        3311.52
Epoch                                   32
----------------------------------  ----------------
2020-11-09 16:04:09.930158 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 33 finished
----------------------------------  ----------------
replay_buffer/size                   70000
trainer/num train calls              34000
trainer/QF1 Loss                        20.3507
trainer/QF2 Loss                        22.9049
trainer/Policy Loss                     35.7132
trainer/Q1 Predictions Mean            -35.9688
trainer/Q1 Predictions Std              48.6017
trainer/Q1 Predictions Max             105.331
trainer/Q1 Predictions Min            -119.987
trainer/Q2 Predictions Mean            -35.9841
trainer/Q2 Predictions Std              48.5258
trainer/Q2 Predictions Max             105.371
trainer/Q2 Predictions Min            -119.644
trainer/Q Targets Mean                 -35.8576
trainer/Q Targets Std                   49.4539
trainer/Q Targets Max                  105.31
trainer/Q Targets Min                 -118.877
trainer/Log Pis Mean                    -1.08641
trainer/Log Pis Std                      0.755709
trainer/Log Pis Max                      0.35198
trainer/Log Pis Min                     -3.8022
trainer/policy/mean Mean                -0.364384
trainer/policy/mean Std                  0.195313
trainer/policy/mean Max                 -0.0836301
trainer/policy/mean Min                 -0.663747
trainer/policy/normal/std Mean           0.827977
trainer/policy/normal/std Std            0.0414273
trainer/policy/normal/std Max            0.915654
trainer/policy/normal/std Min            0.745173
trainer/policy/normal/log_std Mean      -0.19003
trainer/policy/normal/log_std Std        0.0502988
trainer/policy/normal/log_std Max       -0.0881165
trainer/policy/normal/log_std Min       -0.294138
trainer/Alpha                            0.372584
trainer/Alpha Loss                      -3.0472
exploration/num steps total          70000
exploration/num paths total            350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.791656
exploration/Rewards Std                  1.45733
exploration/Rewards Max                 -1.73847e-68
exploration/Rewards Min                 -6.11613
exploration/Returns Mean              -158.331
exploration/Returns Std                 55.2387
exploration/Returns Max                -60.8741
exploration/Returns Min               -247.154
exploration/Actions Mean                -0.285132
exploration/Actions Std                  0.55136
exploration/Actions Max                  0.99175
exploration/Actions Min                 -0.995672
exploration/Num Paths                   10
exploration/Average Returns           -158.331
evaluation/num steps total          164016
evaluation/num paths total             816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44821
evaluation/Rewards Std                   0.336743
evaluation/Rewards Max                  -4.38689
evaluation/Rewards Min                  -6.1171
evaluation/Returns Mean              -1095.09
evaluation/Returns Std                  67.0046
evaluation/Returns Max               -1006.91
evaluation/Returns Min               -1147.87
evaluation/Actions Mean                 -0.376149
evaluation/Actions Std                   0.193599
evaluation/Actions Max                  -0.180917
evaluation/Actions Min                  -0.572028
evaluation/Num Paths                    24
evaluation/Average Returns           -1095.09
time/data storing (s)                    0.0360932
time/evaluation sampling (s)            31.5089
time/exploration sampling (s)           12.5613
time/logging (s)                         0.0544727
time/sac training (s)                   60.0934
time/saving (s)                          0.075026
time/training (s)                        0.000180681
time/epoch (s)                         104.329
time/total (s)                        3419.97
Epoch                                   33
----------------------------------  ----------------
2020-11-09 16:05:39.487806 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 34 finished
----------------------------------  -----------------
replay_buffer/size                   72000
trainer/num train calls              35000
trainer/QF1 Loss                        14.6746
trainer/QF2 Loss                        14.4032
trainer/Policy Loss                     31.7604
trainer/Q1 Predictions Mean            -32.1284
trainer/Q1 Predictions Std              50.041
trainer/Q1 Predictions Max              70.975
trainer/Q1 Predictions Min            -129.593
trainer/Q2 Predictions Mean            -32.1267
trainer/Q2 Predictions Std              49.9726
trainer/Q2 Predictions Max              70.9303
trainer/Q2 Predictions Min            -126.251
trainer/Q Targets Mean                 -32.2506
trainer/Q Targets Std                   50.4971
trainer/Q Targets Max                   71.034
trainer/Q Targets Min                 -127.994
trainer/Log Pis Mean                    -1.01102
trainer/Log Pis Std                      0.765444
trainer/Log Pis Max                      0.402607
trainer/Log Pis Min                     -3.50174
trainer/policy/mean Mean                -0.359028
trainer/policy/mean Std                  0.266561
trainer/policy/mean Max                 -0.0297098
trainer/policy/mean Min                 -0.738032
trainer/policy/normal/std Mean           0.814401
trainer/policy/normal/std Std            0.0556299
trainer/policy/normal/std Max            0.914027
trainer/policy/normal/std Min            0.708245
trainer/policy/normal/log_std Mean      -0.207662
trainer/policy/normal/log_std Std        0.0688903
trainer/policy/normal/log_std Max       -0.0898955
trainer/policy/normal/log_std Min       -0.344965
trainer/Alpha                            0.361668
trainer/Alpha Loss                      -3.06229
exploration/num steps total          72000
exploration/num paths total            360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.585421
exploration/Rewards Std                  1.3255
exploration/Rewards Max                 -2.66763e-115
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -117.084
exploration/Returns Std                 50.3724
exploration/Returns Max                -36.2966
exploration/Returns Min               -197.701
exploration/Actions Mean                -0.287493
exploration/Actions Std                  0.568764
exploration/Actions Max                  0.994208
exploration/Actions Min                 -0.997906
exploration/Num Paths                   10
exploration/Average Returns           -117.084
evaluation/num steps total          168840
evaluation/num paths total             840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.51826
evaluation/Rewards Std                   0.417854
evaluation/Rewards Max                  -3.70953
evaluation/Rewards Min                  -6.11688
evaluation/Returns Mean              -1109.17
evaluation/Returns Std                  83.5856
evaluation/Returns Max                -977.429
evaluation/Returns Min               -1163.7
evaluation/Actions Mean                 -0.373163
evaluation/Actions Std                   0.268671
evaluation/Actions Max                  -0.101116
evaluation/Actions Min                  -0.650199
evaluation/Num Paths                    24
evaluation/Average Returns           -1109.17
time/data storing (s)                    0.030462
time/evaluation sampling (s)            21.3423
time/exploration sampling (s)           10.1658
time/logging (s)                         0.082986
time/sac training (s)                   54.2411
time/saving (s)                          0.632063
time/training (s)                        0.000117957
time/epoch (s)                          86.4949
time/total (s)                        3509.53
Epoch                                   34
----------------------------------  -----------------
2020-11-09 16:07:28.580885 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 35 finished
----------------------------------  ----------------
replay_buffer/size                   74000
trainer/num train calls              36000
trainer/QF1 Loss                        94.8422
trainer/QF2 Loss                        95.7523
trainer/Policy Loss                     39.2698
trainer/Q1 Predictions Mean            -39.4995
trainer/Q1 Predictions Std              52.6413
trainer/Q1 Predictions Max              88.1934
trainer/Q1 Predictions Min            -130.434
trainer/Q2 Predictions Mean            -39.5291
trainer/Q2 Predictions Std              52.6062
trainer/Q2 Predictions Max              88.2515
trainer/Q2 Predictions Min            -127.869
trainer/Q Targets Mean                 -39.4608
trainer/Q Targets Std                   52.5177
trainer/Q Targets Max                   88.0644
trainer/Q Targets Min                 -129.565
trainer/Log Pis Mean                    -0.948109
trainer/Log Pis Std                      0.851333
trainer/Log Pis Max                      0.36885
trainer/Log Pis Min                     -4.29257
trainer/policy/mean Mean                -0.381221
trainer/policy/mean Std                  0.26343
trainer/policy/mean Max                 -0.0226119
trainer/policy/mean Min                 -0.747109
trainer/policy/normal/std Mean           0.808423
trainer/policy/normal/std Std            0.0567481
trainer/policy/normal/std Max            0.91895
trainer/policy/normal/std Min            0.705855
trainer/policy/normal/log_std Mean      -0.21516
trainer/policy/normal/log_std Std        0.0707708
trainer/policy/normal/log_std Max       -0.084524
trainer/policy/normal/log_std Min       -0.348346
trainer/Alpha                            0.351054
trainer/Alpha Loss                      -3.08613
exploration/num steps total          74000
exploration/num paths total            370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.555961
exploration/Rewards Std                  1.31994
exploration/Rewards Max                 -9.18992e-68
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -111.192
exploration/Returns Std                 46.2586
exploration/Returns Max                -53.5033
exploration/Returns Min               -207.572
exploration/Actions Mean                -0.281519
exploration/Actions Std                  0.562482
exploration/Actions Max                  0.98205
exploration/Actions Min                 -0.997218
exploration/Num Paths                   10
exploration/Average Returns           -111.192
evaluation/num steps total          173664
evaluation/num paths total             864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.25944
evaluation/Rewards Std                   0.966015
evaluation/Rewards Max                  -1.33975
evaluation/Rewards Min                  -6.12228
evaluation/Returns Mean              -1057.15
evaluation/Returns Std                 193.082
evaluation/Returns Max                -281.854
evaluation/Returns Min               -1173.02
evaluation/Actions Mean                 -0.399692
evaluation/Actions Std                   0.2662
evaluation/Actions Max                  -0.129035
evaluation/Actions Min                  -0.676319
evaluation/Num Paths                    24
evaluation/Average Returns           -1057.15
time/data storing (s)                    0.0431786
time/evaluation sampling (s)            31.6353
time/exploration sampling (s)           12.5978
time/logging (s)                         0.0581456
time/sac training (s)                   59.0089
time/saving (s)                          0.184348
time/training (s)                        0.000163413
time/epoch (s)                         103.528
time/total (s)                        3618.56
Epoch                                   35
----------------------------------  ----------------
2020-11-09 16:09:47.079180 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 36 finished
----------------------------------  ----------------
replay_buffer/size                   76000
trainer/num train calls              37000
trainer/QF1 Loss                         4.14993
trainer/QF2 Loss                         4.12095
trainer/Policy Loss                     34.8565
trainer/Q1 Predictions Mean            -35.0822
trainer/Q1 Predictions Std              54.3271
trainer/Q1 Predictions Max              83.6594
trainer/Q1 Predictions Min            -132.228
trainer/Q2 Predictions Mean            -35.0466
trainer/Q2 Predictions Std              54.2903
trainer/Q2 Predictions Max              83.642
trainer/Q2 Predictions Min            -130.134
trainer/Q Targets Mean                 -35.5116
trainer/Q Targets Std                   54.7149
trainer/Q Targets Max                   83.34
trainer/Q Targets Min                 -130.834
trainer/Log Pis Mean                    -0.923821
trainer/Log Pis Std                      0.845811
trainer/Log Pis Max                      0.926074
trainer/Log Pis Min                     -3.53857
trainer/policy/mean Mean                -0.404906
trainer/policy/mean Std                  0.235432
trainer/policy/mean Max                 -0.0366288
trainer/policy/mean Min                 -0.763438
trainer/policy/normal/std Mean           0.813979
trainer/policy/normal/std Std            0.0555533
trainer/policy/normal/std Max            0.923251
trainer/policy/normal/std Min            0.699902
trainer/policy/normal/log_std Mean      -0.208174
trainer/policy/normal/log_std Std        0.0687883
trainer/policy/normal/log_std Max       -0.0798541
trainer/policy/normal/log_std Min       -0.356815
trainer/Alpha                            0.340778
trainer/Alpha Loss                      -3.14756
exploration/num steps total          76000
exploration/num paths total            380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.792072
exploration/Rewards Std                  1.41539
exploration/Rewards Max                 -1.08488e-70
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -158.414
exploration/Returns Std                 43.6908
exploration/Returns Max               -113.782
exploration/Returns Min               -265.67
exploration/Actions Mean                -0.328981
exploration/Actions Std                  0.549687
exploration/Actions Max                  0.99642
exploration/Actions Min                 -0.997636
exploration/Num Paths                   10
exploration/Average Returns           -158.414
evaluation/num steps total          178488
evaluation/num paths total             888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.52059
evaluation/Rewards Std                   0.416558
evaluation/Rewards Max                  -4.86748
evaluation/Rewards Min                  -6.12036
evaluation/Returns Mean              -1109.64
evaluation/Returns Std                  83.0776
evaluation/Returns Max                -978.582
evaluation/Returns Min               -1163.93
evaluation/Actions Mean                 -0.421901
evaluation/Actions Std                   0.234149
evaluation/Actions Max                  -0.183971
evaluation/Actions Min                  -0.65891
evaluation/Num Paths                    24
evaluation/Average Returns           -1109.64
time/data storing (s)                    0.271176
time/evaluation sampling (s)            27.6751
time/exploration sampling (s)           11.9817
time/logging (s)                         0.168231
time/sac training (s)                   75.3995
time/saving (s)                          0.120979
time/training (s)                        0.000172306
time/epoch (s)                         115.617
time/total (s)                        3757.12
Epoch                                   36
----------------------------------  ----------------
2020-11-09 16:11:15.000057 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 37 finished
----------------------------------  ----------------
replay_buffer/size                   78000
trainer/num train calls              38000
trainer/QF1 Loss                        27.5357
trainer/QF2 Loss                        28.1854
trainer/Policy Loss                     38.6627
trainer/Q1 Predictions Mean            -38.9237
trainer/Q1 Predictions Std              54.133
trainer/Q1 Predictions Max              78.077
trainer/Q1 Predictions Min            -117.926
trainer/Q2 Predictions Mean            -38.8362
trainer/Q2 Predictions Std              54.0792
trainer/Q2 Predictions Max              77.8489
trainer/Q2 Predictions Min            -117.048
trainer/Q Targets Mean                 -38.9197
trainer/Q Targets Std                   54.4326
trainer/Q Targets Max                   77.4977
trainer/Q Targets Min                 -116.741
trainer/Log Pis Mean                    -1.00323
trainer/Log Pis Std                      0.841954
trainer/Log Pis Max                      0.724125
trainer/Log Pis Min                     -4.56374
trainer/policy/mean Mean                -0.357879
trainer/policy/mean Std                  0.268127
trainer/policy/mean Max                  0.0169096
trainer/policy/mean Min                 -0.758448
trainer/policy/normal/std Mean           0.817242
trainer/policy/normal/std Std            0.0538826
trainer/policy/normal/std Max            0.924729
trainer/policy/normal/std Min            0.703056
trainer/policy/normal/log_std Mean      -0.204018
trainer/policy/normal/log_std Std        0.0664876
trainer/policy/normal/log_std Max       -0.0782541
trainer/policy/normal/log_std Min       -0.352318
trainer/Alpha                            0.330775
trainer/Alpha Loss                      -3.32252
exploration/num steps total          78000
exploration/num paths total            390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.642642
exploration/Rewards Std                  1.31061
exploration/Rewards Max                 -6.46566e-76
exploration/Rewards Min                 -6.1014
exploration/Returns Mean              -128.528
exploration/Returns Std                 37.718
exploration/Returns Max                -58.05
exploration/Returns Min               -186.734
exploration/Actions Mean                -0.278123
exploration/Actions Std                  0.559436
exploration/Actions Max                  0.993662
exploration/Actions Min                 -0.9989
exploration/Num Paths                   10
exploration/Average Returns           -128.528
evaluation/num steps total          183312
evaluation/num paths total             912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.48259
evaluation/Rewards Std                   0.431796
evaluation/Rewards Max                  -4.86753
evaluation/Rewards Min                  -6.12067
evaluation/Returns Mean              -1102
evaluation/Returns Std                  86.0416
evaluation/Returns Max                -978.576
evaluation/Returns Min               -1163.24
evaluation/Actions Mean                 -0.376234
evaluation/Actions Std                   0.270588
evaluation/Actions Max                  -0.102892
evaluation/Actions Min                  -0.649671
evaluation/Num Paths                    24
evaluation/Average Returns           -1102
time/data storing (s)                    0.0301699
time/evaluation sampling (s)            22.8629
time/exploration sampling (s)            9.79944
time/logging (s)                         0.0612413
time/sac training (s)                   50.092
time/saving (s)                          0.251022
time/training (s)                        0.000143108
time/epoch (s)                          83.097
time/total (s)                        3844.9
Epoch                                   37
----------------------------------  ----------------
2020-11-09 16:12:38.999549 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 38 finished
----------------------------------  ----------------
replay_buffer/size                   80000
trainer/num train calls              39000
trainer/QF1 Loss                        53.8508
trainer/QF2 Loss                        55.2356
trainer/Policy Loss                     39.5487
trainer/Q1 Predictions Mean            -39.8128
trainer/Q1 Predictions Std              53.2154
trainer/Q1 Predictions Max              75.6474
trainer/Q1 Predictions Min            -118.688
trainer/Q2 Predictions Mean            -39.727
trainer/Q2 Predictions Std              53.2015
trainer/Q2 Predictions Max              75.9415
trainer/Q2 Predictions Min            -118.498
trainer/Q Targets Mean                 -39.7337
trainer/Q Targets Std                   53.5712
trainer/Q Targets Max                   75.4412
trainer/Q Targets Min                 -117.815
trainer/Log Pis Mean                    -0.934343
trainer/Log Pis Std                      0.915767
trainer/Log Pis Max                      0.454074
trainer/Log Pis Min                     -5.91306
trainer/policy/mean Mean                -0.37026
trainer/policy/mean Std                  0.278533
trainer/policy/mean Max                  0.00420349
trainer/policy/mean Min                 -0.759353
trainer/policy/normal/std Mean           0.809293
trainer/policy/normal/std Std            0.0582885
trainer/policy/normal/std Max            0.911784
trainer/policy/normal/std Min            0.701186
trainer/policy/normal/log_std Mean      -0.214217
trainer/policy/normal/log_std Std        0.0726282
trainer/policy/normal/log_std Max       -0.0923526
trainer/policy/normal/log_std Min       -0.354982
trainer/Alpha                            0.321089
trainer/Alpha Loss                      -3.33352
exploration/num steps total          80000
exploration/num paths total            400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.637322
exploration/Rewards Std                  1.30184
exploration/Rewards Max                 -8.04438e-56
exploration/Rewards Min                 -6.12933
exploration/Returns Mean              -127.464
exploration/Returns Std                 36.9247
exploration/Returns Max                -83.5313
exploration/Returns Min               -207.212
exploration/Actions Mean                -0.298946
exploration/Actions Std                  0.561093
exploration/Actions Max                  0.987036
exploration/Actions Min                 -0.999216
exploration/Num Paths                   10
exploration/Average Returns           -127.464
evaluation/num steps total          188136
evaluation/num paths total             936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56007
evaluation/Rewards Std                   0.6309
evaluation/Rewards Max                  -3.34282
evaluation/Rewards Min                  -6.0921
evaluation/Returns Mean              -1117.57
evaluation/Returns Std                 126.651
evaluation/Returns Max                -673.768
evaluation/Returns Min               -1178.29
evaluation/Actions Mean                 -0.392387
evaluation/Actions Std                   0.281735
evaluation/Actions Max                  -0.101048
evaluation/Actions Min                  -0.72084
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.57
time/data storing (s)                    0.0294403
time/evaluation sampling (s)            19.8194
time/exploration sampling (s)            8.31069
time/logging (s)                         0.0375948
time/sac training (s)                   52.1732
time/saving (s)                          0.0777588
time/training (s)                        0.000153434
time/epoch (s)                          80.4483
time/total (s)                        3928.84
Epoch                                   38
----------------------------------  ----------------
2020-11-09 16:14:05.221747 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 39 finished
----------------------------------  ----------------
replay_buffer/size                   82000
trainer/num train calls              40000
trainer/QF1 Loss                        78.8871
trainer/QF2 Loss                        78.8618
trainer/Policy Loss                     43.6479
trainer/Q1 Predictions Mean            -43.9296
trainer/Q1 Predictions Std              52.5373
trainer/Q1 Predictions Max              75.7726
trainer/Q1 Predictions Min            -119.656
trainer/Q2 Predictions Mean            -43.9158
trainer/Q2 Predictions Std              52.5859
trainer/Q2 Predictions Max              75.945
trainer/Q2 Predictions Min            -119.144
trainer/Q Targets Mean                 -43.4593
trainer/Q Targets Std                   52.6495
trainer/Q Targets Max                   75.8689
trainer/Q Targets Min                 -118.708
trainer/Log Pis Mean                    -0.887829
trainer/Log Pis Std                      0.785292
trainer/Log Pis Max                      0.66489
trainer/Log Pis Min                     -3.6039
trainer/policy/mean Mean                -0.391875
trainer/policy/mean Std                  0.253444
trainer/policy/mean Max                  0.0214726
trainer/policy/mean Min                 -0.786669
trainer/policy/normal/std Mean           0.809348
trainer/policy/normal/std Std            0.0583584
trainer/policy/normal/std Max            0.919668
trainer/policy/normal/std Min            0.684115
trainer/policy/normal/log_std Mean      -0.214157
trainer/policy/normal/log_std Std        0.0727432
trainer/policy/normal/log_std Max       -0.083742
trainer/policy/normal/log_std Min       -0.37963
trainer/Alpha                            0.311691
trainer/Alpha Loss                      -3.36647
exploration/num steps total          82000
exploration/num paths total            410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.55681
exploration/Rewards Std                  1.39158
exploration/Rewards Max                 -8.40518e-79
exploration/Rewards Min                 -6.11931
exploration/Returns Mean              -111.362
exploration/Returns Std                 43.6033
exploration/Returns Max                -36.6249
exploration/Returns Min               -183.711
exploration/Actions Mean                -0.305277
exploration/Actions Std                  0.555971
exploration/Actions Max                  0.990932
exploration/Actions Min                 -0.996858
exploration/Num Paths                   10
exploration/Average Returns           -111.362
evaluation/num steps total          192960
evaluation/num paths total             960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.51916
evaluation/Rewards Std                   0.41637
evaluation/Rewards Max                  -4.75468
evaluation/Rewards Min                  -6.1221
evaluation/Returns Mean              -1109.35
evaluation/Returns Std                  83.2555
evaluation/Returns Max                -978.406
evaluation/Returns Min               -1163.05
evaluation/Actions Mean                 -0.41245
evaluation/Actions Std                   0.250844
evaluation/Actions Max                  -0.157388
evaluation/Actions Min                  -0.66598
evaluation/Num Paths                    24
evaluation/Average Returns           -1109.35
time/data storing (s)                    0.0360035
time/evaluation sampling (s)            21.939
time/exploration sampling (s)            8.96769
time/logging (s)                         0.0837902
time/sac training (s)                   50.0818
time/saving (s)                          0.132189
time/training (s)                        0.000209196
time/epoch (s)                          81.2406
time/total (s)                        4015.08
Epoch                                   39
----------------------------------  ----------------
2020-11-09 16:15:41.362887 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 40 finished
----------------------------------  ----------------
replay_buffer/size                   84000
trainer/num train calls              41000
trainer/QF1 Loss                       146.741
trainer/QF2 Loss                       146.835
trainer/Policy Loss                     48.0742
trainer/Q1 Predictions Mean            -48.2962
trainer/Q1 Predictions Std              52.0271
trainer/Q1 Predictions Max              89.5863
trainer/Q1 Predictions Min            -137.104
trainer/Q2 Predictions Mean            -48.1657
trainer/Q2 Predictions Std              51.9249
trainer/Q2 Predictions Max              89.5392
trainer/Q2 Predictions Min            -136.167
trainer/Q Targets Mean                 -47.9558
trainer/Q Targets Std                   51.918
trainer/Q Targets Max                   88.8479
trainer/Q Targets Min                 -135.534
trainer/Log Pis Mean                    -0.737704
trainer/Log Pis Std                      0.928264
trainer/Log Pis Max                      0.776872
trainer/Log Pis Min                     -4.49024
trainer/policy/mean Mean                -0.422138
trainer/policy/mean Std                  0.265954
trainer/policy/mean Max                  0.0354693
trainer/policy/mean Min                 -0.795513
trainer/policy/normal/std Mean           0.794677
trainer/policy/normal/std Std            0.0641766
trainer/policy/normal/std Max            0.91415
trainer/policy/normal/std Min            0.673368
trainer/policy/normal/log_std Mean      -0.233119
trainer/policy/normal/log_std Std        0.0814731
trainer/policy/normal/log_std Max       -0.0897603
trainer/policy/normal/log_std Min       -0.395463
trainer/Alpha                            0.302601
trainer/Alpha Loss                      -3.27249
exploration/num steps total          84000
exploration/num paths total            420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.663434
exploration/Rewards Std                  1.29512
exploration/Rewards Max                 -1.06731e-47
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -132.687
exploration/Returns Std                 51.6933
exploration/Returns Max                -34.0984
exploration/Returns Min               -207.188
exploration/Actions Mean                -0.336593
exploration/Actions Std                  0.550809
exploration/Actions Max                  0.990022
exploration/Actions Min                 -0.997973
exploration/Num Paths                   10
exploration/Average Returns           -132.687
evaluation/num steps total          197784
evaluation/num paths total             984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39819
evaluation/Rewards Std                   0.905733
evaluation/Rewards Max                  -1.79176
evaluation/Rewards Min                  -6.12076
evaluation/Returns Mean              -1085.04
evaluation/Returns Std                 181.934
evaluation/Returns Max                -360.998
evaluation/Returns Min               -1178.38
evaluation/Actions Mean                 -0.435582
evaluation/Actions Std                   0.261986
evaluation/Actions Max                  -0.171979
evaluation/Actions Min                  -0.70144
evaluation/Num Paths                    24
evaluation/Average Returns           -1085.04
time/data storing (s)                    0.0334636
time/evaluation sampling (s)            19.2958
time/exploration sampling (s)            7.85555
time/logging (s)                         0.118976
time/sac training (s)                   60.3302
time/saving (s)                          0.110526
time/training (s)                        0.000152337
time/epoch (s)                          87.7447
time/total (s)                        4111.22
Epoch                                   40
----------------------------------  ----------------
2020-11-09 16:17:08.735631 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 41 finished
----------------------------------  ----------------
replay_buffer/size                   86000
trainer/num train calls              42000
trainer/QF1 Loss                         5.45552
trainer/QF2 Loss                         5.95044
trainer/Policy Loss                     40.5753
trainer/Q1 Predictions Mean            -40.7765
trainer/Q1 Predictions Std              57.9417
trainer/Q1 Predictions Max              76.0003
trainer/Q1 Predictions Min            -128.212
trainer/Q2 Predictions Mean            -40.747
trainer/Q2 Predictions Std              57.9119
trainer/Q2 Predictions Max              75.658
trainer/Q2 Predictions Min            -128.572
trainer/Q Targets Mean                 -41.3927
trainer/Q Targets Std                   58.5088
trainer/Q Targets Max                   75.6117
trainer/Q Targets Min                 -127.651
trainer/Log Pis Mean                    -0.805883
trainer/Log Pis Std                      0.894589
trainer/Log Pis Max                      0.579876
trainer/Log Pis Min                     -5.78722
trainer/policy/mean Mean                -0.402556
trainer/policy/mean Std                  0.283432
trainer/policy/mean Max                  0.0419539
trainer/policy/mean Min                 -0.776711
trainer/policy/normal/std Mean           0.800012
trainer/policy/normal/std Std            0.0629187
trainer/policy/normal/std Max            0.909933
trainer/policy/normal/std Min            0.690401
trainer/policy/normal/log_std Mean      -0.226256
trainer/policy/normal/log_std Std        0.079309
trainer/policy/normal/log_std Max       -0.0943844
trainer/policy/normal/log_std Min       -0.370483
trainer/Alpha                            0.293739
trainer/Alpha Loss                      -3.43739
exploration/num steps total          86000
exploration/num paths total            430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.680846
exploration/Rewards Std                  1.39044
exploration/Rewards Max                 -1.40861e-77
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -136.169
exploration/Returns Std                 62.5128
exploration/Returns Max                -40.3547
exploration/Returns Min               -242.814
exploration/Actions Mean                -0.338877
exploration/Actions Std                  0.547428
exploration/Actions Max                  0.989436
exploration/Actions Min                 -0.998804
exploration/Num Paths                   10
exploration/Average Returns           -136.169
evaluation/num steps total          202608
evaluation/num paths total            1008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.33048
evaluation/Rewards Std                   1.14356
evaluation/Rewards Max                  -1.79176
evaluation/Rewards Min                  -6.12104
evaluation/Returns Mean              -1071.43
evaluation/Returns Std                 228.829
evaluation/Returns Max                -365.558
evaluation/Returns Min               -1178.3
evaluation/Actions Mean                 -0.426254
evaluation/Actions Std                   0.275981
evaluation/Actions Max                  -0.1492
evaluation/Actions Min                  -0.707588
evaluation/Num Paths                    24
evaluation/Average Returns           -1071.43
time/data storing (s)                    0.0403331
time/evaluation sampling (s)            22.7621
time/exploration sampling (s)            9.72493
time/logging (s)                         0.0674024
time/sac training (s)                   50.1979
time/saving (s)                          0.0987285
time/training (s)                        0.000180461
time/epoch (s)                          82.8916
time/total (s)                        4198.51
Epoch                                   41
----------------------------------  ----------------
2020-11-09 16:18:52.968965 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 42 finished
----------------------------------  ----------------
replay_buffer/size                   88000
trainer/num train calls              43000
trainer/QF1 Loss                         8.61819
trainer/QF2 Loss                         8.93402
trainer/Policy Loss                     39.2363
trainer/Q1 Predictions Mean            -39.4055
trainer/Q1 Predictions Std              52.9778
trainer/Q1 Predictions Max              85.2769
trainer/Q1 Predictions Min            -136.709
trainer/Q2 Predictions Mean            -39.3875
trainer/Q2 Predictions Std              53.0248
trainer/Q2 Predictions Max              85.8103
trainer/Q2 Predictions Min            -139.201
trainer/Q Targets Mean                 -39.5984
trainer/Q Targets Std                   53.6006
trainer/Q Targets Max                   85.9136
trainer/Q Targets Min                 -138.659
trainer/Log Pis Mean                    -0.958777
trainer/Log Pis Std                      0.866079
trainer/Log Pis Max                      0.383946
trainer/Log Pis Min                     -4.86481
trainer/policy/mean Mean                -0.357558
trainer/policy/mean Std                  0.308304
trainer/policy/mean Max                  0.133385
trainer/policy/mean Min                 -0.763099
trainer/policy/normal/std Mean           0.807108
trainer/policy/normal/std Std            0.0612387
trainer/policy/normal/std Max            0.912741
trainer/policy/normal/std Min            0.700187
trainer/policy/normal/log_std Mean      -0.217209
trainer/policy/normal/log_std Std        0.0765141
trainer/policy/normal/log_std Max       -0.0913034
trainer/policy/normal/log_std Min       -0.356408
trainer/Alpha                            0.285097
trainer/Alpha Loss                      -3.71305
exploration/num steps total          88000
exploration/num paths total            440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.614942
exploration/Rewards Std                  1.34752
exploration/Rewards Max                 -6.92253e-83
exploration/Rewards Min                 -6.13972
exploration/Returns Mean              -122.988
exploration/Returns Std                 48.6037
exploration/Returns Max                -55.48
exploration/Returns Min               -198.18
exploration/Actions Mean                -0.303503
exploration/Actions Std                  0.566883
exploration/Actions Max                  0.995142
exploration/Actions Min                 -0.998008
exploration/Num Paths                   10
exploration/Average Returns           -122.988
evaluation/num steps total          207432
evaluation/num paths total            1032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61682
evaluation/Rewards Std                   0.478198
evaluation/Rewards Max                  -4.68213
evaluation/Rewards Min                  -6.12537
evaluation/Returns Mean              -1128.98
evaluation/Returns Std                  95.8697
evaluation/Returns Max                -941.28
evaluation/Returns Min               -1179.47
evaluation/Actions Mean                 -0.388327
evaluation/Actions Std                   0.300735
evaluation/Actions Max                  -0.0729211
evaluation/Actions Min                  -0.692307
evaluation/Num Paths                    24
evaluation/Average Returns           -1128.98
time/data storing (s)                    0.118432
time/evaluation sampling (s)            25.3366
time/exploration sampling (s)           17.9325
time/logging (s)                         0.0984958
time/sac training (s)                   53.9926
time/saving (s)                          0.567864
time/training (s)                        0.000148257
time/epoch (s)                          98.0466
time/total (s)                        4302.74
Epoch                                   42
----------------------------------  ----------------
2020-11-09 16:20:34.893100 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 43 finished
----------------------------------  ----------------
replay_buffer/size                   90000
trainer/num train calls              44000
trainer/QF1 Loss                        26.5689
trainer/QF2 Loss                        27.8019
trainer/Policy Loss                     37.5092
trainer/Q1 Predictions Mean            -37.6212
trainer/Q1 Predictions Std              58.0702
trainer/Q1 Predictions Max              86.721
trainer/Q1 Predictions Min            -139.327
trainer/Q2 Predictions Mean            -37.7002
trainer/Q2 Predictions Std              58.1187
trainer/Q2 Predictions Max              86.1771
trainer/Q2 Predictions Min            -138.869
trainer/Q Targets Mean                 -37.9083
trainer/Q Targets Std                   58.2457
trainer/Q Targets Max                   86.4226
trainer/Q Targets Min                 -138.023
trainer/Log Pis Mean                    -0.839388
trainer/Log Pis Std                      0.886843
trainer/Log Pis Max                      0.817058
trainer/Log Pis Min                     -4.08392
trainer/policy/mean Mean                -0.348846
trainer/policy/mean Std                  0.35624
trainer/policy/mean Max                  0.224086
trainer/policy/mean Min                 -0.802322
trainer/policy/normal/std Mean           0.793649
trainer/policy/normal/std Std            0.0693199
trainer/policy/normal/std Max            0.910706
trainer/policy/normal/std Min            0.672057
trainer/policy/normal/log_std Mean      -0.234987
trainer/policy/normal/log_std Std        0.0883267
trainer/policy/normal/log_std Max       -0.0935356
trainer/policy/normal/log_std Min       -0.397412
trainer/Alpha                            0.276772
trainer/Alpha Loss                      -3.64737
exploration/num steps total          90000
exploration/num paths total            450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.607085
exploration/Rewards Std                  1.35265
exploration/Rewards Max                 -1.31817e-77
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -121.417
exploration/Returns Std                 42.1289
exploration/Returns Max                -60.6312
exploration/Returns Min               -181.896
exploration/Actions Mean                -0.284035
exploration/Actions Std                  0.574164
exploration/Actions Max                  0.994528
exploration/Actions Min                 -0.997369
exploration/Num Paths                   10
exploration/Average Returns           -121.417
evaluation/num steps total          212256
evaluation/num paths total            1056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56821
evaluation/Rewards Std                   0.509063
evaluation/Rewards Max                  -4.68213
evaluation/Rewards Min                  -6.10644
evaluation/Returns Mean              -1119.21
evaluation/Returns Std                 101.982
evaluation/Returns Max                -941.801
evaluation/Returns Min               -1178.34
evaluation/Actions Mean                 -0.377653
evaluation/Actions Std                   0.352783
evaluation/Actions Max                  -0.0141838
evaluation/Actions Min                  -0.733093
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.21
time/data storing (s)                    0.0384038
time/evaluation sampling (s)            28.5362
time/exploration sampling (s)           11.0304
time/logging (s)                         0.0739548
time/sac training (s)                   55.0337
time/saving (s)                          0.0763086
time/training (s)                        0.000167248
time/epoch (s)                          94.789
time/total (s)                        4404.61
Epoch                                   43
----------------------------------  ----------------
2020-11-09 16:22:12.834693 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 44 finished
----------------------------------  ----------------
replay_buffer/size                   92000
trainer/num train calls              45000
trainer/QF1 Loss                         8.59836
trainer/QF2 Loss                         8.20669
trainer/Policy Loss                     42.7811
trainer/Q1 Predictions Mean            -42.9134
trainer/Q1 Predictions Std              53.8183
trainer/Q1 Predictions Max              87.1722
trainer/Q1 Predictions Min            -129.918
trainer/Q2 Predictions Mean            -42.946
trainer/Q2 Predictions Std              53.849
trainer/Q2 Predictions Max              87.0032
trainer/Q2 Predictions Min            -130.3
trainer/Q Targets Mean                 -43.3091
trainer/Q Targets Std                   54.1015
trainer/Q Targets Max                   86.8292
trainer/Q Targets Min                 -129.546
trainer/Log Pis Mean                    -0.778086
trainer/Log Pis Std                      0.892323
trainer/Log Pis Max                      0.85385
trainer/Log Pis Min                     -3.98231
trainer/policy/mean Mean                -0.396377
trainer/policy/mean Std                  0.315086
trainer/policy/mean Max                  0.187362
trainer/policy/mean Min                 -0.792715
trainer/policy/normal/std Mean           0.795887
trainer/policy/normal/std Std            0.065654
trainer/policy/normal/std Max            0.902835
trainer/policy/normal/std Min            0.683657
trainer/policy/normal/log_std Mean      -0.231739
trainer/policy/normal/log_std Std        0.0831743
trainer/policy/normal/log_std Max       -0.102216
trainer/policy/normal/log_std Min       -0.380299
trainer/Alpha                            0.26857
trainer/Alpha Loss                      -3.6522
exploration/num steps total          92000
exploration/num paths total            460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.7679
exploration/Rewards Std                  1.41462
exploration/Rewards Max                 -3.84146e-61
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -153.58
exploration/Returns Std                 49.9646
exploration/Returns Max                -88.7425
exploration/Returns Min               -271.759
exploration/Actions Mean                -0.325184
exploration/Actions Std                  0.554647
exploration/Actions Max                  0.992062
exploration/Actions Min                 -0.995363
exploration/Num Paths                   10
exploration/Average Returns           -153.58
evaluation/num steps total          217080
evaluation/num paths total            1080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.27416
evaluation/Rewards Std                   0.662046
evaluation/Rewards Max                  -3.35005
evaluation/Rewards Min                  -6.12307
evaluation/Returns Mean              -1060.11
evaluation/Returns Std                 132.614
evaluation/Returns Max                -677.263
evaluation/Returns Min               -1164.84
evaluation/Actions Mean                 -0.420023
evaluation/Actions Std                   0.294752
evaluation/Actions Max                  -0.10829
evaluation/Actions Min                  -0.730129
evaluation/Num Paths                    24
evaluation/Average Returns           -1060.11
time/data storing (s)                    0.0368764
time/evaluation sampling (s)            23.0082
time/exploration sampling (s)            9.4376
time/logging (s)                         0.169306
time/sac training (s)                   57.6139
time/saving (s)                          0.245185
time/training (s)                        0.000165902
time/epoch (s)                          90.5112
time/total (s)                        4502.6
Epoch                                   44
----------------------------------  ----------------
2020-11-09 16:23:50.185202 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 45 finished
----------------------------------  ----------------
replay_buffer/size                   94000
trainer/num train calls              46000
trainer/QF1 Loss                        29.3159
trainer/QF2 Loss                        29.5114
trainer/Policy Loss                     32.0855
trainer/Q1 Predictions Mean            -32.2781
trainer/Q1 Predictions Std              56.6124
trainer/Q1 Predictions Max              89.6318
trainer/Q1 Predictions Min            -127.829
trainer/Q2 Predictions Mean            -32.2801
trainer/Q2 Predictions Std              56.5629
trainer/Q2 Predictions Max              89.7654
trainer/Q2 Predictions Min            -127.671
trainer/Q Targets Mean                 -32.7714
trainer/Q Targets Std                   57.1843
trainer/Q Targets Max                   89.0463
trainer/Q Targets Min                 -126.824
trainer/Log Pis Mean                    -0.689163
trainer/Log Pis Std                      0.881974
trainer/Log Pis Max                      1.1118
trainer/Log Pis Min                     -4.55088
trainer/policy/mean Mean                -0.421086
trainer/policy/mean Std                  0.312902
trainer/policy/mean Max                  0.214346
trainer/policy/mean Min                 -0.842067
trainer/policy/normal/std Mean           0.788644
trainer/policy/normal/std Std            0.0696667
trainer/policy/normal/std Max            0.905758
trainer/policy/normal/std Min            0.646147
trainer/policy/normal/log_std Mean      -0.241395
trainer/policy/normal/log_std Std        0.0892368
trainer/policy/normal/log_std Max       -0.0989834
trainer/policy/normal/log_std Min       -0.436728
trainer/Alpha                            0.26077
trainer/Alpha Loss                      -3.61455
exploration/num steps total          94000
exploration/num paths total            470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.792425
exploration/Rewards Std                  1.50498
exploration/Rewards Max                 -3.93914e-68
exploration/Rewards Min                 -6.1388
exploration/Returns Mean              -158.485
exploration/Returns Std                 54.9467
exploration/Returns Max                -74.0264
exploration/Returns Min               -260.901
exploration/Actions Mean                -0.362501
exploration/Actions Std                  0.557548
exploration/Actions Max                  0.987264
exploration/Actions Min                 -0.998079
exploration/Num Paths                   10
exploration/Average Returns           -158.485
evaluation/num steps total          221904
evaluation/num paths total            1104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.43547
evaluation/Rewards Std                   0.708202
evaluation/Rewards Max                  -4.43082
evaluation/Rewards Min                  -6.10954
evaluation/Returns Mean              -1092.53
evaluation/Returns Std                 142.012
evaluation/Returns Max                -890.613
evaluation/Returns Min               -1193.14
evaluation/Actions Mean                 -0.456652
evaluation/Actions Std                   0.284208
evaluation/Actions Max                  -0.172271
evaluation/Actions Min                  -0.741977
evaluation/Num Paths                    24
evaluation/Average Returns           -1092.53
time/data storing (s)                    0.0354973
time/evaluation sampling (s)            24.0105
time/exploration sampling (s)            9.85113
time/logging (s)                         0.178868
time/sac training (s)                   52.5878
time/saving (s)                          0.132735
time/training (s)                        0.0002088
time/epoch (s)                          86.7967
time/total (s)                        4599.93
Epoch                                   45
----------------------------------  ----------------
2020-11-09 16:25:41.407888 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 46 finished
----------------------------------  ----------------
replay_buffer/size                   96000
trainer/num train calls              47000
trainer/QF1 Loss                       103.162
trainer/QF2 Loss                       103.364
trainer/Policy Loss                     46.6832
trainer/Q1 Predictions Mean            -46.8048
trainer/Q1 Predictions Std              57.4536
trainer/Q1 Predictions Max              73.088
trainer/Q1 Predictions Min            -141.21
trainer/Q2 Predictions Mean            -46.8165
trainer/Q2 Predictions Std              57.3942
trainer/Q2 Predictions Max              72.9243
trainer/Q2 Predictions Min            -142.583
trainer/Q Targets Mean                 -46.4576
trainer/Q Targets Std                   58.1155
trainer/Q Targets Max                   72.8909
trainer/Q Targets Min                 -141.487
trainer/Log Pis Mean                    -0.523691
trainer/Log Pis Std                      1.02797
trainer/Log Pis Max                      1.33434
trainer/Log Pis Min                     -3.9342
trainer/policy/mean Mean                -0.404829
trainer/policy/mean Std                  0.387993
trainer/policy/mean Max                  0.337689
trainer/policy/mean Min                 -0.854568
trainer/policy/normal/std Mean           0.770228
trainer/policy/normal/std Std            0.0871326
trainer/policy/normal/std Max            0.901297
trainer/policy/normal/std Min            0.633647
trainer/policy/normal/log_std Mean      -0.267565
trainer/policy/normal/log_std Std        0.114368
trainer/policy/normal/log_std Max       -0.10392
trainer/policy/normal/log_std Min       -0.456264
trainer/Alpha                            0.253238
trainer/Alpha Loss                      -3.4661
exploration/num steps total          96000
exploration/num paths total            480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.546243
exploration/Rewards Std                  1.28298
exploration/Rewards Max                 -8.35284e-83
exploration/Rewards Min                 -6.11537
exploration/Returns Mean              -109.249
exploration/Returns Std                 49.4981
exploration/Returns Max                -44.066
exploration/Returns Min               -209.167
exploration/Actions Mean                -0.371976
exploration/Actions Std                  0.561733
exploration/Actions Max                  0.983666
exploration/Actions Min                 -0.996435
exploration/Num Paths                   10
exploration/Average Returns           -109.249
evaluation/num steps total          226728
evaluation/num paths total            1128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.55949
evaluation/Rewards Std                   0.651009
evaluation/Rewards Max                  -4.43082
evaluation/Rewards Min                  -6.12427
evaluation/Returns Mean              -1117.46
evaluation/Returns Std                 130.8
evaluation/Returns Max                -890.613
evaluation/Returns Min               -1193.43
evaluation/Actions Mean                 -0.419787
evaluation/Actions Std                   0.373894
evaluation/Actions Max                  -0.0206452
evaluation/Actions Min                  -0.797154
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.46
time/data storing (s)                    0.038493
time/evaluation sampling (s)            26.5344
time/exploration sampling (s)           11.266
time/logging (s)                         0.140104
time/sac training (s)                   56.7128
time/saving (s)                          0.134285
time/training (s)                        0.000145237
time/epoch (s)                          94.8262
time/total (s)                        4711.08
Epoch                                   46
----------------------------------  ----------------
2020-11-09 16:27:57.097082 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 47 finished
----------------------------------  ----------------
replay_buffer/size                   98000
trainer/num train calls              48000
trainer/QF1 Loss                        87.0931
trainer/QF2 Loss                        88.3393
trainer/Policy Loss                     41.5836
trainer/Q1 Predictions Mean            -41.743
trainer/Q1 Predictions Std              56.1839
trainer/Q1 Predictions Max              82.2179
trainer/Q1 Predictions Min            -141.801
trainer/Q2 Predictions Mean            -41.7202
trainer/Q2 Predictions Std              56.1544
trainer/Q2 Predictions Max              82.2617
trainer/Q2 Predictions Min            -141.804
trainer/Q Targets Mean                 -41.4298
trainer/Q Targets Std                   56.2521
trainer/Q Targets Max                   82.097
trainer/Q Targets Min                 -140.96
trainer/Log Pis Mean                    -0.757315
trainer/Log Pis Std                      1.04602
trainer/Log Pis Max                      1.37766
trainer/Log Pis Min                     -5.9447
trainer/policy/mean Mean                -0.375137
trainer/policy/mean Std                  0.385392
trainer/policy/mean Max                  0.375029
trainer/policy/mean Min                 -0.841067
trainer/policy/normal/std Mean           0.777769
trainer/policy/normal/std Std            0.0789778
trainer/policy/normal/std Max            0.892006
trainer/policy/normal/std Min            0.642927
trainer/policy/normal/log_std Mean      -0.256571
trainer/policy/normal/log_std Std        0.102852
trainer/policy/normal/log_std Max       -0.114282
trainer/policy/normal/log_std Min       -0.441725
trainer/Alpha                            0.245844
trainer/Alpha Loss                      -3.86868
exploration/num steps total          98000
exploration/num paths total            490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.818441
exploration/Rewards Std                  1.43693
exploration/Rewards Max                 -1.1317e-84
exploration/Rewards Min                 -6.11363
exploration/Returns Mean              -163.688
exploration/Returns Std                 55.4514
exploration/Returns Max               -108.32
exploration/Returns Min               -321.246
exploration/Actions Mean                -0.302356
exploration/Actions Std                  0.586743
exploration/Actions Max                  0.992736
exploration/Actions Min                 -0.997451
exploration/Num Paths                   10
exploration/Average Returns           -163.688
evaluation/num steps total          231552
evaluation/num paths total            1152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.68545
evaluation/Rewards Std                   0.559254
evaluation/Rewards Max                  -4.43082
evaluation/Rewards Min                  -6.10581
evaluation/Returns Mean              -1142.78
evaluation/Returns Std                 112.086
evaluation/Returns Max                -890.673
evaluation/Returns Min               -1192.98
evaluation/Actions Mean                 -0.414177
evaluation/Actions Std                   0.358665
evaluation/Actions Max                  -0.0229321
evaluation/Actions Min                  -0.774977
evaluation/Num Paths                    24
evaluation/Average Returns           -1142.78
time/data storing (s)                    0.0378296
time/evaluation sampling (s)            22.7033
time/exploration sampling (s)            9.57308
time/logging (s)                         0.114365
time/sac training (s)                   83.7868
time/saving (s)                          0.109374
time/training (s)                        0.000126991
time/epoch (s)                         116.325
time/total (s)                        4846.7
Epoch                                   47
----------------------------------  ----------------
2020-11-09 16:30:28.951205 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 48 finished
----------------------------------  -----------------
replay_buffer/size                  100000
trainer/num train calls              49000
trainer/QF1 Loss                        15.2458
trainer/QF2 Loss                        15.1053
trainer/Policy Loss                     43.6599
trainer/Q1 Predictions Mean            -43.7614
trainer/Q1 Predictions Std              57.7442
trainer/Q1 Predictions Max             119.787
trainer/Q1 Predictions Min            -138.532
trainer/Q2 Predictions Mean            -43.7615
trainer/Q2 Predictions Std              57.7538
trainer/Q2 Predictions Max             119.865
trainer/Q2 Predictions Min            -139.419
trainer/Q Targets Mean                 -44.217
trainer/Q Targets Std                   57.8667
trainer/Q Targets Max                  119.1
trainer/Q Targets Min                 -138.548
trainer/Log Pis Mean                    -0.578404
trainer/Log Pis Std                      1.03161
trainer/Log Pis Max                      1.40187
trainer/Log Pis Min                     -4.25502
trainer/policy/mean Mean                -0.430256
trainer/policy/mean Std                  0.356907
trainer/policy/mean Max                  0.361649
trainer/policy/mean Min                 -0.865321
trainer/policy/normal/std Mean           0.770357
trainer/policy/normal/std Std            0.0821578
trainer/policy/normal/std Max            0.894937
trainer/policy/normal/std Min            0.625305
trainer/policy/normal/log_std Mean      -0.266694
trainer/policy/normal/log_std Std        0.108098
trainer/policy/normal/log_std Max       -0.111002
trainer/policy/normal/log_std Min       -0.469516
trainer/Alpha                            0.238609
trainer/Alpha Loss                      -3.69467
exploration/num steps total         100000
exploration/num paths total            500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.501776
exploration/Rewards Std                  1.23728
exploration/Rewards Max                 -1.61245e-124
exploration/Rewards Min                 -6.12239
exploration/Returns Mean              -100.355
exploration/Returns Std                 43.4621
exploration/Returns Max                -38.6976
exploration/Returns Min               -170.836
exploration/Actions Mean                -0.400788
exploration/Actions Std                  0.552081
exploration/Actions Max                  0.984024
exploration/Actions Min                 -0.999013
exploration/Num Paths                   10
exploration/Average Returns           -100.355
evaluation/num steps total          236376
evaluation/num paths total            1176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.62301
evaluation/Rewards Std                   0.609936
evaluation/Rewards Max                  -4.43082
evaluation/Rewards Min                  -6.1306
evaluation/Returns Mean              -1130.23
evaluation/Returns Std                 122.309
evaluation/Returns Max                -890.682
evaluation/Returns Min               -1193.12
evaluation/Actions Mean                 -0.469724
evaluation/Actions Std                   0.321233
evaluation/Actions Max                  -0.148264
evaluation/Actions Min                  -0.792639
evaluation/Num Paths                    24
evaluation/Average Returns           -1130.23
time/data storing (s)                    0.0507076
time/evaluation sampling (s)            26.6996
time/exploration sampling (s)           10.3918
time/logging (s)                         0.215451
time/sac training (s)                   72.3766
time/saving (s)                          0.0831243
time/training (s)                        0.000153617
time/epoch (s)                         109.817
time/total (s)                        4998.61
Epoch                                   48
----------------------------------  -----------------
2020-11-09 16:32:15.121661 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 49 finished
----------------------------------  ----------------
replay_buffer/size                  102000
trainer/num train calls              50000
trainer/QF1 Loss                         9.30688
trainer/QF2 Loss                        10.3778
trainer/Policy Loss                     43.7331
trainer/Q1 Predictions Mean            -43.8628
trainer/Q1 Predictions Std              55.5382
trainer/Q1 Predictions Max              85.4739
trainer/Q1 Predictions Min            -159.2
trainer/Q2 Predictions Mean            -43.8088
trainer/Q2 Predictions Std              55.5357
trainer/Q2 Predictions Max              85.7731
trainer/Q2 Predictions Min            -157.673
trainer/Q Targets Mean                 -44.0702
trainer/Q Targets Std                   56.0336
trainer/Q Targets Max                   85.593
trainer/Q Targets Min                 -158.39
trainer/Log Pis Mean                    -0.513702
trainer/Log Pis Std                      1.03896
trainer/Log Pis Max                      1.47337
trainer/Log Pis Min                     -4.83529
trainer/policy/mean Mean                -0.437021
trainer/policy/mean Std                  0.349142
trainer/policy/mean Max                  0.379114
trainer/policy/mean Min                 -0.841805
trainer/policy/normal/std Mean           0.778244
trainer/policy/normal/std Std            0.0794496
trainer/policy/normal/std Max            0.89356
trainer/policy/normal/std Min            0.648751
trainer/policy/normal/log_std Mean      -0.256016
trainer/policy/normal/log_std Std        0.103382
trainer/policy/normal/log_std Max       -0.112541
trainer/policy/normal/log_std Min       -0.432707
trainer/Alpha                            0.231664
trainer/Alpha Loss                      -3.6762
exploration/num steps total         102000
exploration/num paths total            510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.651149
exploration/Rewards Std                  1.34515
exploration/Rewards Max                 -1.33099e-61
exploration/Rewards Min                 -6.09455
exploration/Returns Mean              -130.23
exploration/Returns Std                 46.4474
exploration/Returns Max                -61.3991
exploration/Returns Min               -232.587
exploration/Actions Mean                -0.348849
exploration/Actions Std                  0.558748
exploration/Actions Max                  0.992309
exploration/Actions Min                 -0.996551
exploration/Num Paths                   10
exploration/Average Returns           -130.23
evaluation/num steps total          241200
evaluation/num paths total            1200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.19275
evaluation/Rewards Std                   1.65132
evaluation/Rewards Max                  -0.00598261
evaluation/Rewards Min                  -6.13536
evaluation/Returns Mean              -1043.74
evaluation/Returns Std                 331.88
evaluation/Returns Max                  -2.90865
evaluation/Returns Min               -1193.11
evaluation/Actions Mean                 -0.484553
evaluation/Actions Std                   0.291443
evaluation/Actions Max                  -0.0510682
evaluation/Actions Min                  -0.780192
evaluation/Num Paths                    24
evaluation/Average Returns           -1043.74
time/data storing (s)                    0.0371079
time/evaluation sampling (s)            21.6567
time/exploration sampling (s)            8.69237
time/logging (s)                         0.0739975
time/sac training (s)                   63.4585
time/saving (s)                          0.060209
time/training (s)                        0.000168041
time/epoch (s)                          93.9791
time/total (s)                        5104.6
Epoch                                   49
----------------------------------  ----------------
2020-11-09 16:34:13.976586 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 50 finished
----------------------------------  ----------------
replay_buffer/size                  104000
trainer/num train calls              51000
trainer/QF1 Loss                        24.399
trainer/QF2 Loss                        25.9131
trainer/Policy Loss                     47.628
trainer/Q1 Predictions Mean            -47.6484
trainer/Q1 Predictions Std              56.6727
trainer/Q1 Predictions Max              83.269
trainer/Q1 Predictions Min            -143.808
trainer/Q2 Predictions Mean            -47.673
trainer/Q2 Predictions Std              56.7002
trainer/Q2 Predictions Max              83.4086
trainer/Q2 Predictions Min            -143.991
trainer/Q Targets Mean                 -47.4127
trainer/Q Targets Std                   57.0858
trainer/Q Targets Max                   83.5507
trainer/Q Targets Min                 -142.748
trainer/Log Pis Mean                    -0.514825
trainer/Log Pis Std                      1.0192
trainer/Log Pis Max                      1.43787
trainer/Log Pis Min                     -4.81932
trainer/policy/mean Mean                -0.457165
trainer/policy/mean Std                  0.337554
trainer/policy/mean Max                  0.395351
trainer/policy/mean Min                 -0.85753
trainer/policy/normal/std Mean           0.770856
trainer/policy/normal/std Std            0.0795517
trainer/policy/normal/std Max            0.882965
trainer/policy/normal/std Min            0.632219
trainer/policy/normal/log_std Mean      -0.265666
trainer/policy/normal/log_std Std        0.104433
trainer/policy/normal/log_std Max       -0.124469
trainer/policy/normal/log_std Min       -0.45852
trainer/Alpha                            0.224896
trainer/Alpha Loss                      -3.75241
exploration/num steps total         104000
exploration/num paths total            520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.671228
exploration/Rewards Std                  1.40605
exploration/Rewards Max                 -1.10629e-96
exploration/Rewards Min                 -6.08398
exploration/Returns Mean              -134.246
exploration/Returns Std                 53.9304
exploration/Returns Max                -65.9988
exploration/Returns Min               -246.201
exploration/Actions Mean                -0.347926
exploration/Actions Std                  0.565808
exploration/Actions Max                  0.99042
exploration/Actions Min                 -0.997879
exploration/Num Paths                   10
exploration/Average Returns           -134.246
evaluation/num steps total          246024
evaluation/num paths total            1224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.3113
evaluation/Rewards Std                   0.913881
evaluation/Rewards Max                  -3.30002
evaluation/Rewards Min                  -6.11307
evaluation/Returns Mean              -1067.57
evaluation/Returns Std                 182.641
evaluation/Returns Max                -667.81
evaluation/Returns Min               -1179.78
evaluation/Actions Mean                 -0.490614
evaluation/Actions Std                   0.29209
evaluation/Actions Max                  -0.148822
evaluation/Actions Min                  -0.788435
evaluation/Num Paths                    24
evaluation/Average Returns           -1067.57
time/data storing (s)                    0.05714
time/evaluation sampling (s)            24.1904
time/exploration sampling (s)            9.58049
time/logging (s)                         0.164744
time/sac training (s)                   62.8201
time/saving (s)                          0.401109
time/training (s)                        0.000188312
time/epoch (s)                          97.2141
time/total (s)                        5223.51
Epoch                                   50
----------------------------------  ----------------
2020-11-09 16:35:51.845149 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 51 finished
----------------------------------  ----------------
replay_buffer/size                  106000
trainer/num train calls              52000
trainer/QF1 Loss                        58.1922
trainer/QF2 Loss                        56.6535
trainer/Policy Loss                     43.4428
trainer/Q1 Predictions Mean            -43.3993
trainer/Q1 Predictions Std              57.5269
trainer/Q1 Predictions Max             120.706
trainer/Q1 Predictions Min            -159.739
trainer/Q2 Predictions Mean            -43.6039
trainer/Q2 Predictions Std              57.659
trainer/Q2 Predictions Max             120.704
trainer/Q2 Predictions Min            -159.841
trainer/Q Targets Mean                 -43.687
trainer/Q Targets Std                   57.6648
trainer/Q Targets Max                  120.397
trainer/Q Targets Min                 -159.07
trainer/Log Pis Mean                    -0.535005
trainer/Log Pis Std                      1.11978
trainer/Log Pis Max                      1.58361
trainer/Log Pis Min                     -5.57314
trainer/policy/mean Mean                -0.450831
trainer/policy/mean Std                  0.365402
trainer/policy/mean Max                  0.409601
trainer/policy/mean Min                 -0.876502
trainer/policy/normal/std Mean           0.7644
trainer/policy/normal/std Std            0.0906704
trainer/policy/normal/std Max            0.888498
trainer/policy/normal/std Min            0.608167
trainer/policy/normal/log_std Mean      -0.275852
trainer/policy/normal/log_std Std        0.120499
trainer/policy/normal/log_std Max       -0.118223
trainer/policy/normal/log_std Min       -0.497306
trainer/Alpha                            0.218334
trainer/Alpha Loss                      -3.85759
exploration/num steps total         106000
exploration/num paths total            530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.480535
exploration/Rewards Std                  1.29591
exploration/Rewards Max                 -3.19252e-98
exploration/Rewards Min                 -6.12678
exploration/Returns Mean               -96.1069
exploration/Returns Std                 39.66
exploration/Returns Max                -53.239
exploration/Returns Min               -170.669
exploration/Actions Mean                -0.365575
exploration/Actions Std                  0.56984
exploration/Actions Max                  0.999038
exploration/Actions Min                 -0.99744
exploration/Num Paths                   10
exploration/Average Returns            -96.1069
evaluation/num steps total          250848
evaluation/num paths total            1248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.51299
evaluation/Rewards Std                   1.31605
evaluation/Rewards Max                  -0.00217631
evaluation/Rewards Min                  -6.13232
evaluation/Returns Mean              -1108.11
evaluation/Returns Std                 264.526
evaluation/Returns Max                  -0.437708
evaluation/Returns Min               -1207.47
evaluation/Actions Mean                 -0.489208
evaluation/Actions Std                   0.316051
evaluation/Actions Max                  -0.163535
evaluation/Actions Min                  -0.812537
evaluation/Num Paths                    24
evaluation/Average Returns           -1108.11
time/data storing (s)                    0.0498041
time/evaluation sampling (s)            22.2022
time/exploration sampling (s)            9.34899
time/logging (s)                         0.096814
time/sac training (s)                   54.66
time/saving (s)                          0.142516
time/training (s)                        0.000156176
time/epoch (s)                          86.5004
time/total (s)                        5321.27
Epoch                                   51
----------------------------------  ----------------
2020-11-09 16:37:22.503270 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 52 finished
----------------------------------  -----------------
replay_buffer/size                  108000
trainer/num train calls              53000
trainer/QF1 Loss                        15.1814
trainer/QF2 Loss                        15.7358
trainer/Policy Loss                     54.201
trainer/Q1 Predictions Mean            -54.2294
trainer/Q1 Predictions Std              58.0872
trainer/Q1 Predictions Max              83.2802
trainer/Q1 Predictions Min            -159.868
trainer/Q2 Predictions Mean            -54.2196
trainer/Q2 Predictions Std              58.0801
trainer/Q2 Predictions Max              83.5701
trainer/Q2 Predictions Min            -160.026
trainer/Q Targets Mean                 -54.7923
trainer/Q Targets Std                   58.6214
trainer/Q Targets Max                   82.8973
trainer/Q Targets Min                 -159.46
trainer/Log Pis Mean                    -0.651331
trainer/Log Pis Std                      1.00697
trainer/Log Pis Max                      1.32908
trainer/Log Pis Min                     -4.98524
trainer/policy/mean Mean                -0.408391
trainer/policy/mean Std                  0.369375
trainer/policy/mean Max                  0.451121
trainer/policy/mean Min                 -0.865304
trainer/policy/normal/std Mean           0.774087
trainer/policy/normal/std Std            0.0774664
trainer/policy/normal/std Max            0.890781
trainer/policy/normal/std Min            0.623989
trainer/policy/normal/log_std Mean      -0.261163
trainer/policy/normal/log_std Std        0.101308
trainer/policy/normal/log_std Max       -0.115657
trainer/policy/normal/log_std Min       -0.471623
trainer/Alpha                            0.211911
trainer/Alpha Loss                      -4.11378
exploration/num steps total         108000
exploration/num paths total            540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.670845
exploration/Rewards Std                  1.3252
exploration/Rewards Max                 -7.24045e-116
exploration/Rewards Min                 -6.13825
exploration/Returns Mean              -134.169
exploration/Returns Std                 56.8599
exploration/Returns Max                -45.1142
exploration/Returns Min               -212.188
exploration/Actions Mean                -0.350371
exploration/Actions Std                  0.559732
exploration/Actions Max                  0.992244
exploration/Actions Min                 -0.996993
exploration/Num Paths                   10
exploration/Average Returns           -134.169
evaluation/num steps total          255672
evaluation/num paths total            1272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.24845
evaluation/Rewards Std                   0.967472
evaluation/Rewards Max                  -2.61608
evaluation/Rewards Min                  -5.99781
evaluation/Returns Mean              -1054.94
evaluation/Returns Std                 194.439
evaluation/Returns Max                -526.275
evaluation/Returns Min               -1192.98
evaluation/Actions Mean                 -0.443046
evaluation/Actions Std                   0.331173
evaluation/Actions Max                  -0.100578
evaluation/Actions Min                  -0.783395
evaluation/Num Paths                    24
evaluation/Average Returns           -1054.94
time/data storing (s)                    0.0304236
time/evaluation sampling (s)            20.783
time/exploration sampling (s)            8.92279
time/logging (s)                         0.0604286
time/sac training (s)                   54.7939
time/saving (s)                          0.157677
time/training (s)                        0.000166177
time/epoch (s)                          84.7483
time/total (s)                        5411.85
Epoch                                   52
----------------------------------  -----------------
2020-11-09 16:39:02.325600 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 53 finished
----------------------------------  ----------------
replay_buffer/size                  110000
trainer/num train calls              54000
trainer/QF1 Loss                         9.61231
trainer/QF2 Loss                         9.49661
trainer/Policy Loss                     44.0798
trainer/Q1 Predictions Mean            -44.2195
trainer/Q1 Predictions Std              60.2801
trainer/Q1 Predictions Max              83.6135
trainer/Q1 Predictions Min            -145.149
trainer/Q2 Predictions Mean            -44.1874
trainer/Q2 Predictions Std              60.2359
trainer/Q2 Predictions Max              83.8331
trainer/Q2 Predictions Min            -145.98
trainer/Q Targets Mean                 -44.4214
trainer/Q Targets Std                   60.4301
trainer/Q Targets Max                   83.7104
trainer/Q Targets Min                 -145.225
trainer/Log Pis Mean                    -0.500945
trainer/Log Pis Std                      1.07574
trainer/Log Pis Max                      1.75029
trainer/Log Pis Min                     -5.00472
trainer/policy/mean Mean                -0.406329
trainer/policy/mean Std                  0.423633
trainer/policy/mean Max                  0.52162
trainer/policy/mean Min                 -0.895852
trainer/policy/normal/std Mean           0.757284
trainer/policy/normal/std Std            0.0936299
trainer/policy/normal/std Max            0.882359
trainer/policy/normal/std Min            0.590976
trainer/policy/normal/log_std Mean      -0.285826
trainer/policy/normal/log_std Std        0.125588
trainer/policy/normal/log_std Max       -0.125156
trainer/policy/normal/log_std Min       -0.52598
trainer/Alpha                            0.205786
trainer/Alpha Loss                      -3.95378
exploration/num steps total         110000
exploration/num paths total            550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.54112
exploration/Rewards Std                  1.24197
exploration/Rewards Max                 -2.01555e-68
exploration/Rewards Min                 -6.07656
exploration/Returns Mean              -108.224
exploration/Returns Std                 42.5754
exploration/Returns Max                -49.9777
exploration/Returns Min               -181.45
exploration/Actions Mean                -0.326859
exploration/Actions Std                  0.58986
exploration/Actions Max                  0.993552
exploration/Actions Min                 -0.998263
exploration/Num Paths                   10
exploration/Average Returns           -108.224
evaluation/num steps total          260496
evaluation/num paths total            1296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.22098
evaluation/Rewards Std                   1.22438
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.13895
evaluation/Returns Mean              -1049.42
evaluation/Returns Std                 246.03
evaluation/Returns Max                -663.301
evaluation/Returns Min               -1207.43
evaluation/Actions Mean                 -0.439629
evaluation/Actions Std                   0.381094
evaluation/Actions Max                   0.0285365
evaluation/Actions Min                  -0.824992
evaluation/Num Paths                    24
evaluation/Average Returns           -1049.42
time/data storing (s)                    0.0461785
time/evaluation sampling (s)            23.1211
time/exploration sampling (s)            9.19161
time/logging (s)                         0.0618919
time/sac training (s)                   57.9305
time/saving (s)                          0.115496
time/training (s)                        0.000143448
time/epoch (s)                          90.467
time/total (s)                        5511.63
Epoch                                   53
----------------------------------  ----------------
2020-11-09 16:40:33.981714 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 54 finished
----------------------------------  -----------------
replay_buffer/size                  112000
trainer/num train calls              55000
trainer/QF1 Loss                       174.879
trainer/QF2 Loss                       171.118
trainer/Policy Loss                     45.667
trainer/Q1 Predictions Mean            -45.6978
trainer/Q1 Predictions Std              58.9089
trainer/Q1 Predictions Max              91.1687
trainer/Q1 Predictions Min            -173.814
trainer/Q2 Predictions Mean            -45.7558
trainer/Q2 Predictions Std              58.8953
trainer/Q2 Predictions Max              91.8001
trainer/Q2 Predictions Min            -166.72
trainer/Q Targets Mean                 -45.3337
trainer/Q Targets Std                   58.649
trainer/Q Targets Max                   91.1472
trainer/Q Targets Min                 -172.249
trainer/Log Pis Mean                    -0.543506
trainer/Log Pis Std                      1.15891
trainer/Log Pis Max                      1.58106
trainer/Log Pis Min                     -5.18875
trainer/policy/mean Mean                -0.396993
trainer/policy/mean Std                  0.429775
trainer/policy/mean Max                  0.540542
trainer/policy/mean Min                 -0.902015
trainer/policy/normal/std Mean           0.759089
trainer/policy/normal/std Std            0.0886602
trainer/policy/normal/std Max            0.877465
trainer/policy/normal/std Min            0.591599
trainer/policy/normal/log_std Mean      -0.282589
trainer/policy/normal/log_std Std        0.118438
trainer/policy/normal/log_std Max       -0.130718
trainer/policy/normal/log_std Min       -0.524927
trainer/Alpha                            0.199787
trainer/Alpha Loss                      -4.09632
exploration/num steps total         112000
exploration/num paths total            560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.655863
exploration/Rewards Std                  1.35428
exploration/Rewards Max                 -1.19968e-144
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -131.173
exploration/Returns Std                 51.9933
exploration/Returns Max                -49.004
exploration/Returns Min               -223.691
exploration/Actions Mean                -0.417122
exploration/Actions Std                  0.555931
exploration/Actions Max                  0.993947
exploration/Actions Min                 -0.99764
exploration/Num Paths                   10
exploration/Average Returns           -131.173
evaluation/num steps total          265320
evaluation/num paths total            1320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.76312
evaluation/Rewards Std                   0.643537
evaluation/Rewards Max                  -4.06044
evaluation/Rewards Min                  -6.01371
evaluation/Returns Mean              -1158.39
evaluation/Returns Std                 129.351
evaluation/Returns Max                -816.149
evaluation/Returns Min               -1207.28
evaluation/Actions Mean                 -0.438734
evaluation/Actions Std                   0.378918
evaluation/Actions Max                  -0.0492184
evaluation/Actions Min                  -0.817889
evaluation/Num Paths                    24
evaluation/Average Returns           -1158.39
time/data storing (s)                    0.0463712
time/evaluation sampling (s)            22.2747
time/exploration sampling (s)            8.53608
time/logging (s)                         0.0856336
time/sac training (s)                   51.2182
time/saving (s)                          0.132752
time/training (s)                        0.000143687
time/epoch (s)                          82.2938
time/total (s)                        5603.28
Epoch                                   54
----------------------------------  -----------------
2020-11-09 16:42:12.807202 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 55 finished
----------------------------------  -----------------
replay_buffer/size                  114000
trainer/num train calls              56000
trainer/QF1 Loss                        12.4973
trainer/QF2 Loss                        14.2189
trainer/Policy Loss                     51.0448
trainer/Q1 Predictions Mean            -51.0905
trainer/Q1 Predictions Std              59.953
trainer/Q1 Predictions Max             121.301
trainer/Q1 Predictions Min            -160.705
trainer/Q2 Predictions Mean            -51.0518
trainer/Q2 Predictions Std              59.9192
trainer/Q2 Predictions Max             121.322
trainer/Q2 Predictions Min            -160.898
trainer/Q Targets Mean                 -51.4034
trainer/Q Targets Std                   60.3204
trainer/Q Targets Max                  121.197
trainer/Q Targets Min                 -159.942
trainer/Log Pis Mean                    -0.395296
trainer/Log Pis Std                      1.12128
trainer/Log Pis Max                      1.4252
trainer/Log Pis Min                     -5.59934
trainer/policy/mean Mean                -0.409762
trainer/policy/mean Std                  0.427771
trainer/policy/mean Max                  0.547892
trainer/policy/mean Min                 -0.898938
trainer/policy/normal/std Mean           0.751218
trainer/policy/normal/std Std            0.0924748
trainer/policy/normal/std Max            0.87332
trainer/policy/normal/std Min            0.58933
trainer/policy/normal/log_std Mean      -0.293809
trainer/policy/normal/log_std Std        0.125148
trainer/policy/normal/log_std Max       -0.135454
trainer/policy/normal/log_std Min       -0.528769
trainer/Alpha                            0.193943
trainer/Alpha Loss                      -3.92874
exploration/num steps total         114000
exploration/num paths total            570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.667909
exploration/Rewards Std                  1.40381
exploration/Rewards Max                 -9.84549e-128
exploration/Rewards Min                 -6.10928
exploration/Returns Mean              -133.582
exploration/Returns Std                 53.0119
exploration/Returns Max                -69.4265
exploration/Returns Min               -234.11
exploration/Actions Mean                -0.35947
exploration/Actions Std                  0.591919
exploration/Actions Max                  0.995595
exploration/Actions Min                 -0.998185
exploration/Num Paths                   10
exploration/Average Returns           -133.582
evaluation/num steps total          270144
evaluation/num paths total            1344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8442
evaluation/Rewards Std                   0.537806
evaluation/Rewards Max                  -4.06044
evaluation/Rewards Min                  -6.01885
evaluation/Returns Mean              -1174.68
evaluation/Returns Std                 108.099
evaluation/Returns Max                -816.149
evaluation/Returns Min               -1207.29
evaluation/Actions Mean                 -0.445962
evaluation/Actions Std                   0.384237
evaluation/Actions Max                  -0.0506962
evaluation/Actions Min                  -0.830453
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.68
time/data storing (s)                    0.076445
time/evaluation sampling (s)            22.5432
time/exploration sampling (s)            8.80483
time/logging (s)                         0.226019
time/sac training (s)                   56.8462
time/saving (s)                          0.824697
time/training (s)                        0.000171523
time/epoch (s)                          89.3216
time/total (s)                        5702.2
Epoch                                   55
----------------------------------  -----------------
2020-11-09 16:43:57.301189 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 56 finished
----------------------------------  -----------------
replay_buffer/size                  116000
trainer/num train calls              57000
trainer/QF1 Loss                        42.1215
trainer/QF2 Loss                        41.2407
trainer/Policy Loss                     50.77
trainer/Q1 Predictions Mean            -50.763
trainer/Q1 Predictions Std              61.4689
trainer/Q1 Predictions Max              82.7321
trainer/Q1 Predictions Min            -156.503
trainer/Q2 Predictions Mean            -50.6602
trainer/Q2 Predictions Std              61.4295
trainer/Q2 Predictions Max              82.63
trainer/Q2 Predictions Min            -152.95
trainer/Q Targets Mean                 -50.822
trainer/Q Targets Std                   61.8366
trainer/Q Targets Max                   82.5247
trainer/Q Targets Min                 -155.67
trainer/Log Pis Mean                    -0.325934
trainer/Log Pis Std                      1.10072
trainer/Log Pis Max                      1.65137
trainer/Log Pis Min                     -4.75686
trainer/policy/mean Mean                -0.419215
trainer/policy/mean Std                  0.420388
trainer/policy/mean Max                  0.557348
trainer/policy/mean Min                 -0.902423
trainer/policy/normal/std Mean           0.754517
trainer/policy/normal/std Std            0.09395
trainer/policy/normal/std Max            0.882256
trainer/policy/normal/std Min            0.589488
trainer/policy/normal/log_std Mean      -0.289631
trainer/policy/normal/log_std Std        0.12689
trainer/policy/normal/log_std Max       -0.125273
trainer/policy/normal/log_std Min       -0.5285
trainer/Alpha                            0.188231
trainer/Alpha Loss                      -3.88451
exploration/num steps total         116000
exploration/num paths total            580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.621084
exploration/Rewards Std                  1.37525
exploration/Rewards Max                 -5.36214e-123
exploration/Rewards Min                 -6.13185
exploration/Returns Mean              -124.217
exploration/Returns Std                 66.7039
exploration/Returns Max                -14.2074
exploration/Returns Min               -223.755
exploration/Actions Mean                -0.419111
exploration/Actions Std                  0.569124
exploration/Actions Max                  0.993412
exploration/Actions Min                 -0.999151
exploration/Num Paths                   10
exploration/Average Returns           -124.217
evaluation/num steps total          274968
evaluation/num paths total            1368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78674
evaluation/Rewards Std                   0.728501
evaluation/Rewards Max                  -3.36732
evaluation/Rewards Min                  -6.00804
evaluation/Returns Mean              -1163.14
evaluation/Returns Std                 146.401
evaluation/Returns Max                -677.525
evaluation/Returns Min               -1207.28
evaluation/Actions Mean                 -0.47268
evaluation/Actions Std                   0.359897
evaluation/Actions Max                  -0.012847
evaluation/Actions Min                  -0.833529
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.14
time/data storing (s)                    0.0996903
time/evaluation sampling (s)            22.1634
time/exploration sampling (s)            8.69859
time/logging (s)                         0.191654
time/sac training (s)                   60.2617
time/saving (s)                          0.162108
time/training (s)                        0.000160353
time/epoch (s)                          91.5773
time/total (s)                        5806.62
Epoch                                   56
----------------------------------  -----------------
2020-11-09 16:45:31.623276 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 57 finished
----------------------------------  ----------------
replay_buffer/size                  118000
trainer/num train calls              58000
trainer/QF1 Loss                        18.0859
trainer/QF2 Loss                        17.6175
trainer/Policy Loss                     56.0552
trainer/Q1 Predictions Mean            -55.9419
trainer/Q1 Predictions Std              55.9429
trainer/Q1 Predictions Max              83.2107
trainer/Q1 Predictions Min            -157.119
trainer/Q2 Predictions Mean            -56.0601
trainer/Q2 Predictions Std              55.9012
trainer/Q2 Predictions Max              83.4851
trainer/Q2 Predictions Min            -154.092
trainer/Q Targets Mean                 -55.9442
trainer/Q Targets Std                   56.3208
trainer/Q Targets Max                   83.451
trainer/Q Targets Min                 -155.932
trainer/Log Pis Mean                    -0.462234
trainer/Log Pis Std                      1.08552
trainer/Log Pis Max                      1.85691
trainer/Log Pis Min                     -5.14238
trainer/policy/mean Mean                -0.416831
trainer/policy/mean Std                  0.413178
trainer/policy/mean Max                  0.570247
trainer/policy/mean Min                 -0.937252
trainer/policy/normal/std Mean           0.753299
trainer/policy/normal/std Std            0.0967591
trainer/policy/normal/std Max            0.885325
trainer/policy/normal/std Min            0.542358
trainer/policy/normal/log_std Mean      -0.291777
trainer/policy/normal/log_std Std        0.131122
trainer/policy/normal/log_std Max       -0.1218
trainer/policy/normal/log_std Min       -0.611828
trainer/Alpha                            0.182679
trainer/Alpha Loss                      -4.18585
exploration/num steps total         118000
exploration/num paths total            590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.537226
exploration/Rewards Std                  1.25477
exploration/Rewards Max                 -2.16449e-92
exploration/Rewards Min                 -6.12563
exploration/Returns Mean              -107.445
exploration/Returns Std                 59.1301
exploration/Returns Max                -32.0925
exploration/Returns Min               -251.29
exploration/Actions Mean                -0.311256
exploration/Actions Std                  0.599034
exploration/Actions Max                  0.997051
exploration/Actions Min                 -0.997875
exploration/Num Paths                   10
exploration/Average Returns           -107.445
evaluation/num steps total          279792
evaluation/num paths total            1392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78262
evaluation/Rewards Std                   0.742279
evaluation/Rewards Max                  -3.3019
evaluation/Rewards Min                  -6.05713
evaluation/Returns Mean              -1162.31
evaluation/Returns Std                 149.164
evaluation/Returns Max                -664.515
evaluation/Returns Min               -1207.33
evaluation/Actions Mean                 -0.454506
evaluation/Actions Std                   0.376133
evaluation/Actions Max                   0.0476665
evaluation/Actions Min                  -0.831967
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.31
time/data storing (s)                    0.049618
time/evaluation sampling (s)            22.2434
time/exploration sampling (s)            9.08196
time/logging (s)                         0.039621
time/sac training (s)                   54.6009
time/saving (s)                          0.0999331
time/training (s)                        0.000160083
time/epoch (s)                          86.1156
time/total (s)                        5900.75
Epoch                                   57
----------------------------------  ----------------
2020-11-09 16:47:08.055836 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 58 finished
----------------------------------  -----------------
replay_buffer/size                  120000
trainer/num train calls              59000
trainer/QF1 Loss                        34.1653
trainer/QF2 Loss                        34.3005
trainer/Policy Loss                     46.4336
trainer/Q1 Predictions Mean            -46.4617
trainer/Q1 Predictions Std              60.9865
trainer/Q1 Predictions Max             119.319
trainer/Q1 Predictions Min            -173.445
trainer/Q2 Predictions Mean            -46.4441
trainer/Q2 Predictions Std              60.9656
trainer/Q2 Predictions Max             119.445
trainer/Q2 Predictions Min            -172.635
trainer/Q Targets Mean                 -46.1497
trainer/Q Targets Std                   61.3364
trainer/Q Targets Max                  119.468
trainer/Q Targets Min                 -172.613
trainer/Log Pis Mean                    -0.380247
trainer/Log Pis Std                      1.13708
trainer/Log Pis Max                      1.87397
trainer/Log Pis Min                     -5.49179
trainer/policy/mean Mean                -0.41962
trainer/policy/mean Std                  0.422538
trainer/policy/mean Max                  0.586114
trainer/policy/mean Min                 -0.896257
trainer/policy/normal/std Mean           0.755083
trainer/policy/normal/std Std            0.0930614
trainer/policy/normal/std Max            0.880453
trainer/policy/normal/std Min            0.593367
trainer/policy/normal/log_std Mean      -0.288733
trainer/policy/normal/log_std Std        0.125748
trainer/policy/normal/log_std Max       -0.127318
trainer/policy/normal/log_std Min       -0.521943
trainer/Alpha                            0.177367
trainer/Alpha Loss                      -4.11672
exploration/num steps total         120000
exploration/num paths total            600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.602909
exploration/Rewards Std                  1.32685
exploration/Rewards Max                 -3.05652e-131
exploration/Rewards Min                 -6.11541
exploration/Returns Mean              -120.582
exploration/Returns Std                 37.9335
exploration/Returns Max                -65.1385
exploration/Returns Min               -196.23
exploration/Actions Mean                -0.405387
exploration/Actions Std                  0.572851
exploration/Actions Max                  0.993208
exploration/Actions Min                 -0.996367
exploration/Num Paths                   10
exploration/Average Returns           -120.582
evaluation/num steps total          284616
evaluation/num paths total            1416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60096
evaluation/Rewards Std                   0.790264
evaluation/Rewards Max                  -4.06044
evaluation/Rewards Min                  -6.02082
evaluation/Returns Mean              -1125.79
evaluation/Returns Std                 158.843
evaluation/Returns Max                -816.149
evaluation/Returns Min               -1207.29
evaluation/Actions Mean                 -0.477526
evaluation/Actions Std                   0.357341
evaluation/Actions Max                  -0.0724974
evaluation/Actions Min                  -0.836115
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.79
time/data storing (s)                    0.0401011
time/evaluation sampling (s)            23.3746
time/exploration sampling (s)            8.95311
time/logging (s)                         0.0999802
time/sac training (s)                   56.1809
time/saving (s)                          0.153265
time/training (s)                        0.000211557
time/epoch (s)                          88.8022
time/total (s)                        5997.22
Epoch                                   58
----------------------------------  -----------------
2020-11-09 16:48:45.818972 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 59 finished
----------------------------------  ----------------
replay_buffer/size                  122000
trainer/num train calls              60000
trainer/QF1 Loss                        51.5169
trainer/QF2 Loss                        50.981
trainer/Policy Loss                     38.5255
trainer/Q1 Predictions Mean            -38.5756
trainer/Q1 Predictions Std              61.8186
trainer/Q1 Predictions Max             120.775
trainer/Q1 Predictions Min            -161.659
trainer/Q2 Predictions Mean            -38.6186
trainer/Q2 Predictions Std              61.8715
trainer/Q2 Predictions Max             121.175
trainer/Q2 Predictions Min            -161.906
trainer/Q Targets Mean                 -38.4301
trainer/Q Targets Std                   62.2267
trainer/Q Targets Max                  120.221
trainer/Q Targets Min                 -161.117
trainer/Log Pis Mean                    -0.143323
trainer/Log Pis Std                      0.973314
trainer/Log Pis Max                      2.45573
trainer/Log Pis Min                     -4.06231
trainer/policy/mean Mean                -0.39838
trainer/policy/mean Std                  0.460243
trainer/policy/mean Max                  0.64854
trainer/policy/mean Min                 -0.954847
trainer/policy/normal/std Mean           0.741119
trainer/policy/normal/std Std            0.0992865
trainer/policy/normal/std Max            0.876634
trainer/policy/normal/std Min            0.513631
trainer/policy/normal/log_std Mean      -0.308862
trainer/policy/normal/log_std Std        0.137207
trainer/policy/normal/log_std Max       -0.131666
trainer/policy/normal/log_std Min       -0.666249
trainer/Alpha                            0.172234
trainer/Alpha Loss                      -3.7699
exploration/num steps total         122000
exploration/num paths total            610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.56626
exploration/Rewards Std                  1.25809
exploration/Rewards Max                 -9.14953e-95
exploration/Rewards Min                 -6.11502
exploration/Returns Mean              -113.252
exploration/Returns Std                 42.332
exploration/Returns Max                -16.9725
exploration/Returns Min               -172.555
exploration/Actions Mean                -0.375684
exploration/Actions Std                  0.600737
exploration/Actions Max                  0.994323
exploration/Actions Min                 -0.998486
exploration/Num Paths                   10
exploration/Average Returns           -113.252
evaluation/num steps total          289440
evaluation/num paths total            1440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60102
evaluation/Rewards Std                   0.790201
evaluation/Rewards Max                  -4.06044
evaluation/Rewards Min                  -6.08449
evaluation/Returns Mean              -1125.8
evaluation/Returns Std                 158.829
evaluation/Returns Max                -816.149
evaluation/Returns Min               -1207.36
evaluation/Actions Mean                 -0.451041
evaluation/Actions Std                   0.407049
evaluation/Actions Max                  -0.0332052
evaluation/Actions Min                  -0.858542
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.8
time/data storing (s)                    0.0385312
time/evaluation sampling (s)            21.2696
time/exploration sampling (s)            9.06651
time/logging (s)                         0.073957
time/sac training (s)                   55.8451
time/saving (s)                          0.200922
time/training (s)                        0.000490468
time/epoch (s)                          86.495
time/total (s)                        6094.88
Epoch                                   59
----------------------------------  ----------------
2020-11-09 16:50:28.690886 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 60 finished
----------------------------------  ----------------
replay_buffer/size                  124000
trainer/num train calls              61000
trainer/QF1 Loss                        18.5605
trainer/QF2 Loss                        18.6567
trainer/Policy Loss                     49.2512
trainer/Q1 Predictions Mean            -49.2708
trainer/Q1 Predictions Std              59.6938
trainer/Q1 Predictions Max             105.507
trainer/Q1 Predictions Min            -191.956
trainer/Q2 Predictions Mean            -49.2311
trainer/Q2 Predictions Std              59.7585
trainer/Q2 Predictions Max             106.723
trainer/Q2 Predictions Min            -191.841
trainer/Q Targets Mean                 -49.2716
trainer/Q Targets Std                   59.8582
trainer/Q Targets Max                  105.924
trainer/Q Targets Min                 -191.293
trainer/Log Pis Mean                    -0.221631
trainer/Log Pis Std                      1.04729
trainer/Log Pis Max                      1.72591
trainer/Log Pis Min                     -4.05817
trainer/policy/mean Mean                -0.422819
trainer/policy/mean Std                  0.443244
trainer/policy/mean Max                  0.649155
trainer/policy/mean Min                 -0.927479
trainer/policy/normal/std Mean           0.740108
trainer/policy/normal/std Std            0.104412
trainer/policy/normal/std Max            0.872647
trainer/policy/normal/std Min            0.552652
trainer/policy/normal/log_std Mean      -0.311204
trainer/policy/normal/log_std Std        0.144108
trainer/policy/normal/log_std Max       -0.136225
trainer/policy/normal/log_std Min       -0.593027
trainer/Alpha                            0.167262
trainer/Alpha Loss                      -3.97271
exploration/num steps total         124000
exploration/num paths total            620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.688299
exploration/Rewards Std                  1.29086
exploration/Rewards Max                 -7.6304e-142
exploration/Rewards Min                 -6.10731
exploration/Returns Mean              -137.66
exploration/Returns Std                 65.2482
exploration/Returns Max                -40.9507
exploration/Returns Min               -300.849
exploration/Actions Mean                -0.381616
exploration/Actions Std                  0.599382
exploration/Actions Max                  0.995151
exploration/Actions Min                 -0.998645
exploration/Num Paths                   10
exploration/Average Returns           -137.66
evaluation/num steps total          294264
evaluation/num paths total            1464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56808
evaluation/Rewards Std                   0.980683
evaluation/Rewards Max                  -3.29643
evaluation/Rewards Min                  -6.01091
evaluation/Returns Mean              -1119.18
evaluation/Returns Std                 197.074
evaluation/Returns Max                -663.417
evaluation/Returns Min               -1207.28
evaluation/Actions Mean                 -0.462809
evaluation/Actions Std                   0.394577
evaluation/Actions Max                   0.0657809
evaluation/Actions Min                  -0.858519
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.18
time/data storing (s)                    0.0309338
time/evaluation sampling (s)            21.3679
time/exploration sampling (s)            7.95602
time/logging (s)                         0.115922
time/sac training (s)                   60.6897
time/saving (s)                          0.266498
time/training (s)                        0.000249677
time/epoch (s)                          90.4272
time/total (s)                        6197.76
Epoch                                   60
----------------------------------  ----------------
2020-11-09 16:52:08.581645 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 61 finished
----------------------------------  -----------------
replay_buffer/size                  126000
trainer/num train calls              62000
trainer/QF1 Loss                        10.3379
trainer/QF2 Loss                        10.4896
trainer/Policy Loss                     44.3958
trainer/Q1 Predictions Mean            -44.3408
trainer/Q1 Predictions Std              58.9485
trainer/Q1 Predictions Max              83.0418
trainer/Q1 Predictions Min            -146.645
trainer/Q2 Predictions Mean            -44.4485
trainer/Q2 Predictions Std              59.0181
trainer/Q2 Predictions Max              82.9995
trainer/Q2 Predictions Min            -147.291
trainer/Q Targets Mean                 -44.6837
trainer/Q Targets Std                   59.4089
trainer/Q Targets Max                   82.5203
trainer/Q Targets Min                 -146.114
trainer/Log Pis Mean                    -0.225824
trainer/Log Pis Std                      1.33873
trainer/Log Pis Max                      1.98323
trainer/Log Pis Min                     -6.21023
trainer/policy/mean Mean                -0.440475
trainer/policy/mean Std                  0.453613
trainer/policy/mean Max                  0.660461
trainer/policy/mean Min                 -0.926946
trainer/policy/normal/std Mean           0.735834
trainer/policy/normal/std Std            0.104163
trainer/policy/normal/std Max            0.87827
trainer/policy/normal/std Min            0.563907
trainer/policy/normal/log_std Mean      -0.317059
trainer/policy/normal/log_std Std        0.144534
trainer/policy/normal/log_std Max       -0.129801
trainer/policy/normal/log_std Min       -0.572866
trainer/Alpha                            0.162435
trainer/Alpha Loss                      -4.04538
exploration/num steps total         126000
exploration/num paths total            630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.566977
exploration/Rewards Std                  1.33333
exploration/Rewards Max                 -2.06082e-104
exploration/Rewards Min                 -6.12739
exploration/Returns Mean              -113.395
exploration/Returns Std                 30.7015
exploration/Returns Max                -62.7753
exploration/Returns Min               -160.319
exploration/Actions Mean                -0.387775
exploration/Actions Std                  0.592235
exploration/Actions Max                  0.994741
exploration/Actions Min                 -0.996773
exploration/Num Paths                   10
exploration/Average Returns           -113.395
evaluation/num steps total          299088
evaluation/num paths total            1488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.487241
evaluation/Actions Std                   0.387117
evaluation/Actions Max                  -0.0998196
evaluation/Actions Min                  -0.878657
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0492066
time/evaluation sampling (s)            21.9853
time/exploration sampling (s)           10.0537
time/logging (s)                         0.0711066
time/sac training (s)                   52.9892
time/saving (s)                          0.158872
time/training (s)                        0.000185092
time/epoch (s)                          85.3076
time/total (s)                        6297.56
Epoch                                   61
----------------------------------  -----------------
2020-11-09 16:53:37.163107 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 62 finished
----------------------------------  ----------------
replay_buffer/size                  128000
trainer/num train calls              63000
trainer/QF1 Loss                         9.49106
trainer/QF2 Loss                        10.2973
trainer/Policy Loss                     51.0289
trainer/Q1 Predictions Mean            -51.0105
trainer/Q1 Predictions Std              58.3045
trainer/Q1 Predictions Max              78.8947
trainer/Q1 Predictions Min            -174.374
trainer/Q2 Predictions Mean            -51.0205
trainer/Q2 Predictions Std              58.3087
trainer/Q2 Predictions Max              78.506
trainer/Q2 Predictions Min            -174.052
trainer/Q Targets Mean                 -51.0784
trainer/Q Targets Std                   58.537
trainer/Q Targets Max                   78.8144
trainer/Q Targets Min                 -173.439
trainer/Log Pis Mean                    -0.087812
trainer/Log Pis Std                      1.22856
trainer/Log Pis Max                      2.19254
trainer/Log Pis Min                     -4.95735
trainer/policy/mean Mean                -0.496458
trainer/policy/mean Std                  0.400905
trainer/policy/mean Max                  0.600401
trainer/policy/mean Min                 -0.919457
trainer/policy/normal/std Mean           0.726864
trainer/policy/normal/std Std            0.10496
trainer/policy/normal/std Max            0.865854
trainer/policy/normal/std Min            0.56596
trainer/policy/normal/log_std Mean      -0.329748
trainer/policy/normal/log_std Std        0.147491
trainer/policy/normal/log_std Max       -0.144039
trainer/policy/normal/log_std Min       -0.569232
trainer/Alpha                            0.157711
trainer/Alpha Loss                      -3.85618
exploration/num steps total         128000
exploration/num paths total            640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.47807
exploration/Rewards Std                  1.22976
exploration/Rewards Max                 -1.9906e-172
exploration/Rewards Min                 -6.07535
exploration/Returns Mean               -95.6141
exploration/Returns Std                 40.7942
exploration/Returns Max                -31.773
exploration/Returns Min               -164.945
exploration/Actions Mean                -0.329127
exploration/Actions Std                  0.618219
exploration/Actions Max                  0.993524
exploration/Actions Min                 -0.998517
exploration/Num Paths                   10
exploration/Average Returns            -95.6141
evaluation/num steps total          303912
evaluation/num paths total            1512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.93617e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.538183
evaluation/Actions Std                   0.338072
evaluation/Actions Max                  -0.200076
evaluation/Actions Min                  -0.876466
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.036436
time/evaluation sampling (s)            21.0676
time/exploration sampling (s)            8.66322
time/logging (s)                         0.0562012
time/sac training (s)                   50.7672
time/saving (s)                          0.0583928
time/training (s)                        0.000158158
time/epoch (s)                          80.6492
time/total (s)                        6386.09
Epoch                                   62
----------------------------------  ----------------
2020-11-09 16:55:12.805840 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 63 finished
----------------------------------  -----------------
replay_buffer/size                  130000
trainer/num train calls              64000
trainer/QF1 Loss                        63.9351
trainer/QF2 Loss                        64.6772
trainer/Policy Loss                     50.5134
trainer/Q1 Predictions Mean            -50.5686
trainer/Q1 Predictions Std              58.5532
trainer/Q1 Predictions Max              70.8519
trainer/Q1 Predictions Min            -134.912
trainer/Q2 Predictions Mean            -50.4822
trainer/Q2 Predictions Std              58.5224
trainer/Q2 Predictions Max              70.9179
trainer/Q2 Predictions Min            -133.781
trainer/Q Targets Mean                 -50.6312
trainer/Q Targets Std                   59.4042
trainer/Q Targets Max                   70.4433
trainer/Q Targets Min                 -134.143
trainer/Log Pis Mean                    -0.0935917
trainer/Log Pis Std                      1.24908
trainer/Log Pis Max                      2.52687
trainer/Log Pis Min                     -6.5904
trainer/policy/mean Mean                -0.476449
trainer/policy/mean Std                  0.427525
trainer/policy/mean Max                  0.646252
trainer/policy/mean Min                 -0.915041
trainer/policy/normal/std Mean           0.729066
trainer/policy/normal/std Std            0.10036
trainer/policy/normal/std Max            0.871822
trainer/policy/normal/std Min            0.575223
trainer/policy/normal/log_std Mean      -0.325732
trainer/policy/normal/log_std Std        0.14049
trainer/policy/normal/log_std Max       -0.13717
trainer/policy/normal/log_std Min       -0.552998
trainer/Alpha                            0.153118
trainer/Alpha Loss                      -3.92872
exploration/num steps total         130000
exploration/num paths total            650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.715494
exploration/Rewards Std                  1.35761
exploration/Rewards Max                 -5.21906e-186
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -143.099
exploration/Returns Std                 78.8746
exploration/Returns Max                -53.6001
exploration/Returns Min               -339.167
exploration/Actions Mean                -0.455335
exploration/Actions Std                  0.557474
exploration/Actions Max                  0.983654
exploration/Actions Min                 -0.998756
exploration/Num Paths                   10
exploration/Average Returns           -143.099
evaluation/num steps total          308736
evaluation/num paths total            1536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.555842
evaluation/Actions Std                   0.322798
evaluation/Actions Max                  -0.224825
evaluation/Actions Min                  -0.878278
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0396018
time/evaluation sampling (s)            21.1954
time/exploration sampling (s)            9.46277
time/logging (s)                         0.0422944
time/sac training (s)                   56.4132
time/saving (s)                          0.457417
time/training (s)                        0.000153405
time/epoch (s)                          87.6108
time/total (s)                        6481.69
Epoch                                   63
----------------------------------  -----------------
2020-11-09 16:56:50.391010 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 64 finished
----------------------------------  ----------------
replay_buffer/size                  132000
trainer/num train calls              65000
trainer/QF1 Loss                         7.88503
trainer/QF2 Loss                         7.94444
trainer/Policy Loss                     54.4653
trainer/Q1 Predictions Mean            -54.4768
trainer/Q1 Predictions Std              60.5883
trainer/Q1 Predictions Max              68.9556
trainer/Q1 Predictions Min            -196.69
trainer/Q2 Predictions Mean            -54.4209
trainer/Q2 Predictions Std              60.5378
trainer/Q2 Predictions Max              69.1796
trainer/Q2 Predictions Min            -192.682
trainer/Q Targets Mean                 -54.6694
trainer/Q Targets Std                   60.8633
trainer/Q Targets Max                   68.7666
trainer/Q Targets Min                 -195.617
trainer/Log Pis Mean                    -0.138886
trainer/Log Pis Std                      1.25392
trainer/Log Pis Max                      2.53233
trainer/Log Pis Min                     -5.00486
trainer/policy/mean Mean                -0.517153
trainer/policy/mean Std                  0.405414
trainer/policy/mean Max                  0.646922
trainer/policy/mean Min                 -0.954033
trainer/policy/normal/std Mean           0.72505
trainer/policy/normal/std Std            0.098079
trainer/policy/normal/std Max            0.853338
trainer/policy/normal/std Min            0.526448
trainer/policy/normal/log_std Mean      -0.330905
trainer/policy/normal/log_std Std        0.137872
trainer/policy/normal/log_std Max       -0.158599
trainer/policy/normal/log_std Min       -0.641603
trainer/Alpha                            0.148727
trainer/Alpha Loss                      -4.07595
exploration/num steps total         132000
exploration/num paths total            660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.73012
exploration/Rewards Std                  1.50116
exploration/Rewards Max                 -9.13698e-96
exploration/Rewards Min                 -6.10672
exploration/Returns Mean              -146.024
exploration/Returns Std                 33.8994
exploration/Returns Max                -70.1513
exploration/Returns Min               -194.549
exploration/Actions Mean                -0.47101
exploration/Actions Std                  0.539538
exploration/Actions Max                  0.99575
exploration/Actions Min                 -0.998324
exploration/Num Paths                   10
exploration/Average Returns           -146.024
evaluation/num steps total          313560
evaluation/num paths total            1560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.62965
evaluation/Rewards Std                   0.996596
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1131.56
evaluation/Returns Std                 200.316
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.585537
evaluation/Actions Std                   0.297695
evaluation/Actions Max                  -0.279523
evaluation/Actions Min                  -0.893241
evaluation/Num Paths                    24
evaluation/Average Returns           -1131.56
time/data storing (s)                    0.0324423
time/evaluation sampling (s)            22.1962
time/exploration sampling (s)            8.86417
time/logging (s)                         0.0673391
time/sac training (s)                   54.442
time/saving (s)                          0.0707983
time/training (s)                        0.000174978
time/epoch (s)                          85.6731
time/total (s)                        6579.25
Epoch                                   64
----------------------------------  ----------------
2020-11-09 16:58:21.314463 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 65 finished
----------------------------------  -----------------
replay_buffer/size                  134000
trainer/num train calls              66000
trainer/QF1 Loss                        82.8798
trainer/QF2 Loss                        83.8248
trainer/Policy Loss                     46.5207
trainer/Q1 Predictions Mean            -46.5348
trainer/Q1 Predictions Std              57.3167
trainer/Q1 Predictions Max             118.064
trainer/Q1 Predictions Min            -146.567
trainer/Q2 Predictions Mean            -46.4763
trainer/Q2 Predictions Std              57.2466
trainer/Q2 Predictions Max             118.262
trainer/Q2 Predictions Min            -147.003
trainer/Q Targets Mean                 -46.1671
trainer/Q Targets Std                   57.6356
trainer/Q Targets Max                  117.64
trainer/Q Targets Min                 -146.763
trainer/Log Pis Mean                    -0.27839
trainer/Log Pis Std                      1.3005
trainer/Log Pis Max                      1.8189
trainer/Log Pis Min                     -5.04585
trainer/policy/mean Mean                -0.380603
trainer/policy/mean Std                  0.504526
trainer/policy/mean Max                  0.751815
trainer/policy/mean Min                 -0.913253
trainer/policy/normal/std Mean           0.73008
trainer/policy/normal/std Std            0.101924
trainer/policy/normal/std Max            0.870859
trainer/policy/normal/std Min            0.571589
trainer/policy/normal/log_std Mean      -0.324639
trainer/policy/normal/log_std Std        0.142661
trainer/policy/normal/log_std Max       -0.138275
trainer/policy/normal/log_std Min       -0.559335
trainer/Alpha                            0.144444
trainer/Alpha Loss                      -4.40837
exploration/num steps total         134000
exploration/num paths total            670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.615111
exploration/Rewards Std                  1.42454
exploration/Rewards Max                 -2.51079e-132
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -123.022
exploration/Returns Std                 50.9127
exploration/Returns Max                -36.0753
exploration/Returns Min               -217.715
exploration/Actions Mean                -0.421147
exploration/Actions Std                  0.599253
exploration/Actions Max                  0.992257
exploration/Actions Min                 -0.997994
exploration/Num Paths                   10
exploration/Average Returns           -123.022
evaluation/num steps total          318384
evaluation/num paths total            1584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.456279
evaluation/Actions Std                   0.423784
evaluation/Actions Max                   0.0622399
evaluation/Actions Min                  -0.880538
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.043901
time/evaluation sampling (s)            20.849
time/exploration sampling (s)            8.58178
time/logging (s)                         0.0352243
time/sac training (s)                   51.5239
time/saving (s)                          0.0509748
time/training (s)                        0.000163229
time/epoch (s)                          81.085
time/total (s)                        6670.11
Epoch                                   65
----------------------------------  -----------------
2020-11-09 16:59:48.442444 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 66 finished
----------------------------------  -----------------
replay_buffer/size                  136000
trainer/num train calls              67000
trainer/QF1 Loss                        59.0979
trainer/QF2 Loss                        59.7407
trainer/Policy Loss                     48.3461
trainer/Q1 Predictions Mean            -48.3582
trainer/Q1 Predictions Std              59.7668
trainer/Q1 Predictions Max             116.885
trainer/Q1 Predictions Min            -165.482
trainer/Q2 Predictions Mean            -48.3135
trainer/Q2 Predictions Std              59.6719
trainer/Q2 Predictions Max             117.344
trainer/Q2 Predictions Min            -151.167
trainer/Q Targets Mean                 -48.3188
trainer/Q Targets Std                   60.1683
trainer/Q Targets Max                  116.606
trainer/Q Targets Min                 -164.497
trainer/Log Pis Mean                    -0.0699137
trainer/Log Pis Std                      1.35688
trainer/Log Pis Max                      7.66589
trainer/Log Pis Min                     -4.65209
trainer/policy/mean Mean                -0.503586
trainer/policy/mean Std                  0.421903
trainer/policy/mean Max                  0.671797
trainer/policy/mean Min                 -0.995505
trainer/policy/normal/std Mean           0.724939
trainer/policy/normal/std Std            0.107066
trainer/policy/normal/std Max            0.866906
trainer/policy/normal/std Min            0.35854
trainer/policy/normal/log_std Mean      -0.333042
trainer/policy/normal/log_std Std        0.152469
trainer/policy/normal/log_std Max       -0.142824
trainer/policy/normal/log_std Min       -1.02572
trainer/Alpha                            0.140204
trainer/Alpha Loss                      -4.06666
exploration/num steps total         136000
exploration/num paths total            680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.714031
exploration/Rewards Std                  1.45668
exploration/Rewards Max                 -5.89963e-176
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -142.806
exploration/Returns Std                 40.0268
exploration/Returns Max                -66.7129
exploration/Returns Min               -202.495
exploration/Actions Mean                -0.554465
exploration/Actions Std                  0.517661
exploration/Actions Max                  0.984708
exploration/Actions Min                 -0.999405
exploration/Num Paths                   10
exploration/Average Returns           -142.806
evaluation/num steps total          323208
evaluation/num paths total            1608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.17438e-12
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   3.01691e-11
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.586506
evaluation/Actions Std                   0.302803
evaluation/Actions Max                  -0.281962
evaluation/Actions Min                  -0.889867
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0418793
time/evaluation sampling (s)            21.0617
time/exploration sampling (s)            8.52774
time/logging (s)                         0.0811457
time/sac training (s)                   51.1354
time/saving (s)                          0.133449
time/training (s)                        0.000152148
time/epoch (s)                          80.9815
time/total (s)                        6757.24
Epoch                                   66
----------------------------------  -----------------
2020-11-09 17:01:25.064234 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 67 finished
----------------------------------  -----------------
replay_buffer/size                  138000
trainer/num train calls              68000
trainer/QF1 Loss                        13.9142
trainer/QF2 Loss                        14.6314
trainer/Policy Loss                     56.1121
trainer/Q1 Predictions Mean            -56.1572
trainer/Q1 Predictions Std              60.3882
trainer/Q1 Predictions Max              80.6564
trainer/Q1 Predictions Min            -195.076
trainer/Q2 Predictions Mean            -56.0797
trainer/Q2 Predictions Std              60.3584
trainer/Q2 Predictions Max              80.5643
trainer/Q2 Predictions Min            -195.368
trainer/Q Targets Mean                 -56.8764
trainer/Q Targets Std                   60.6269
trainer/Q Targets Max                   80.7536
trainer/Q Targets Min                 -194.382
trainer/Log Pis Mean                    -0.00510786
trainer/Log Pis Std                      1.32891
trainer/Log Pis Max                      3.07249
trainer/Log Pis Min                     -3.96586
trainer/policy/mean Mean                -0.53177
trainer/policy/mean Std                  0.391727
trainer/policy/mean Max                  0.678856
trainer/policy/mean Min                 -0.923558
trainer/policy/normal/std Mean           0.725216
trainer/policy/normal/std Std            0.109429
trainer/policy/normal/std Max            0.857525
trainer/policy/normal/std Min            0.558922
trainer/policy/normal/log_std Mean      -0.332965
trainer/policy/normal/log_std Std        0.153708
trainer/policy/normal/log_std Max       -0.153705
trainer/policy/normal/log_std Min       -0.581746
trainer/Alpha                            0.136051
trainer/Alpha Loss                      -3.99964
exploration/num steps total         138000
exploration/num paths total            690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.465312
exploration/Rewards Std                  1.28644
exploration/Rewards Max                 -2.91671e-236
exploration/Rewards Min                 -6.07535
exploration/Returns Mean               -93.0623
exploration/Returns Std                 36.0529
exploration/Returns Max                -51.2401
exploration/Returns Min               -157.526
exploration/Actions Mean                -0.403301
exploration/Actions Std                  0.600627
exploration/Actions Max                  0.997482
exploration/Actions Min                 -0.998263
exploration/Num Paths                   10
exploration/Average Returns            -93.0623
evaluation/num steps total          328032
evaluation/num paths total            1632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73252
evaluation/Rewards Std                   0.90704
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1152.24
evaluation/Returns Std                 182.315
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.569878
evaluation/Actions Std                   0.314077
evaluation/Actions Max                  -0.243042
evaluation/Actions Min                  -0.883112
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.24
time/data storing (s)                    0.0391249
time/evaluation sampling (s)            20.9661
time/exploration sampling (s)            8.69476
time/logging (s)                         0.0928526
time/sac training (s)                   52.7035
time/saving (s)                          0.134495
time/training (s)                        0.000141587
time/epoch (s)                          82.631
time/total (s)                        6853.83
Epoch                                   67
----------------------------------  -----------------
2020-11-09 17:02:47.498838 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 68 finished
----------------------------------  ----------------
replay_buffer/size                  140000
trainer/num train calls              69000
trainer/QF1 Loss                        14.2785
trainer/QF2 Loss                        15.6333
trainer/Policy Loss                     45.8146
trainer/Q1 Predictions Mean            -45.8669
trainer/Q1 Predictions Std              60.2974
trainer/Q1 Predictions Max              72.0565
trainer/Q1 Predictions Min            -165.939
trainer/Q2 Predictions Mean            -45.815
trainer/Q2 Predictions Std              60.239
trainer/Q2 Predictions Max              71.8755
trainer/Q2 Predictions Min            -159.814
trainer/Q Targets Mean                 -45.5679
trainer/Q Targets Std                   60.7344
trainer/Q Targets Max                   71.9794
trainer/Q Targets Min                 -165.186
trainer/Log Pis Mean                     0.0937954
trainer/Log Pis Std                      1.31608
trainer/Log Pis Max                      2.22451
trainer/Log Pis Min                     -5.96201
trainer/policy/mean Mean                -0.426942
trainer/policy/mean Std                  0.505444
trainer/policy/mean Max                  0.768978
trainer/policy/mean Min                 -0.939705
trainer/policy/normal/std Mean           0.709535
trainer/policy/normal/std Std            0.110709
trainer/policy/normal/std Max            0.851291
trainer/policy/normal/std Min            0.542965
trainer/policy/normal/log_std Mean      -0.355684
trainer/policy/normal/log_std Std        0.159432
trainer/policy/normal/log_std Max       -0.161001
trainer/policy/normal/log_std Min       -0.610711
trainer/Alpha                            0.132166
trainer/Alpha Loss                      -3.85758
exploration/num steps total         140000
exploration/num paths total            700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.645144
exploration/Rewards Std                  1.33736
exploration/Rewards Max                 -7.69026e-91
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -129.029
exploration/Returns Std                 50.4722
exploration/Returns Max                -61.1088
exploration/Returns Min               -208.727
exploration/Actions Mean                -0.379288
exploration/Actions Std                  0.622295
exploration/Actions Max                  0.999008
exploration/Actions Min                 -0.99764
exploration/Num Paths                   10
exploration/Average Returns           -129.029
evaluation/num steps total          332856
evaluation/num paths total            1656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.476843
evaluation/Actions Std                   0.432276
evaluation/Actions Max                   0.0434096
evaluation/Actions Min                  -0.909547
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0486228
time/evaluation sampling (s)            17.9524
time/exploration sampling (s)            6.94603
time/logging (s)                         0.0738051
time/sac training (s)                   39.0278
time/saving (s)                          0.134667
time/training (s)                        0.000128219
time/epoch (s)                          64.1834
time/total (s)                        6936.22
Epoch                                   68
----------------------------------  ----------------
2020-11-09 17:05:46.003894 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 69 finished
----------------------------------  ----------------
replay_buffer/size                  142000
trainer/num train calls              70000
trainer/QF1 Loss                        93.8885
trainer/QF2 Loss                        94.6342
trainer/Policy Loss                     53.6341
trainer/Q1 Predictions Mean            -53.572
trainer/Q1 Predictions Std              61.2026
trainer/Q1 Predictions Max              80.8502
trainer/Q1 Predictions Min            -195.691
trainer/Q2 Predictions Mean            -53.4961
trainer/Q2 Predictions Std              61.0967
trainer/Q2 Predictions Max              80.8252
trainer/Q2 Predictions Min            -195.922
trainer/Q Targets Mean                 -53.2034
trainer/Q Targets Std                   61.2411
trainer/Q Targets Max                   80.2436
trainer/Q Targets Min                 -194.903
trainer/Log Pis Mean                    -0.0213292
trainer/Log Pis Std                      1.25876
trainer/Log Pis Max                      4.87302
trainer/Log Pis Min                     -4.65758
trainer/policy/mean Mean                -0.506007
trainer/policy/mean Std                  0.405123
trainer/policy/mean Max                  0.6611
trainer/policy/mean Min                 -0.983562
trainer/policy/normal/std Mean           0.721141
trainer/policy/normal/std Std            0.101208
trainer/policy/normal/std Max            0.86184
trainer/policy/normal/std Min            0.439211
trainer/policy/normal/log_std Mean      -0.337063
trainer/policy/normal/log_std Std        0.143427
trainer/policy/normal/log_std Max       -0.148686
trainer/policy/normal/log_std Min       -0.822776
trainer/Alpha                            0.128238
trainer/Alpha Loss                      -4.15154
exploration/num steps total         142000
exploration/num paths total            710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.845745
exploration/Rewards Std                  1.5124
exploration/Rewards Max                 -1.9727e-142
exploration/Rewards Min                 -6.11062
exploration/Returns Mean              -169.149
exploration/Returns Std                 48.0284
exploration/Returns Max               -106.392
exploration/Returns Min               -253.947
exploration/Actions Mean                -0.490756
exploration/Actions Std                  0.538397
exploration/Actions Max                  0.980867
exploration/Actions Min                 -0.99803
exploration/Num Paths                   10
exploration/Average Returns           -169.149
evaluation/num steps total          337680
evaluation/num paths total            1680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.546826
evaluation/Actions Std                   0.333446
evaluation/Actions Max                  -0.203325
evaluation/Actions Min                  -0.879342
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0416304
time/evaluation sampling (s)            21.8194
time/exploration sampling (s)           14.3692
time/logging (s)                         0.135298
time/sac training (s)                   47.5867
time/saving (s)                          0.774639
time/training (s)                        0.000220791
time/epoch (s)                          84.7272
time/total (s)                        7114.75
Epoch                                   69
----------------------------------  ----------------
2020-11-09 17:08:56.189528 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 70 finished
----------------------------------  ----------------
replay_buffer/size                  144000
trainer/num train calls              71000
trainer/QF1 Loss                        27.773
trainer/QF2 Loss                        27.932
trainer/Policy Loss                     47.2555
trainer/Q1 Predictions Mean            -47.2939
trainer/Q1 Predictions Std              61.3959
trainer/Q1 Predictions Max             115.787
trainer/Q1 Predictions Min            -166.747
trainer/Q2 Predictions Mean            -47.19
trainer/Q2 Predictions Std              61.2865
trainer/Q2 Predictions Max             116.032
trainer/Q2 Predictions Min            -157.192
trainer/Q Targets Mean                 -47.5732
trainer/Q Targets Std                   61.6961
trainer/Q Targets Max                  115.331
trainer/Q Targets Min                 -165.966
trainer/Log Pis Mean                     0.199491
trainer/Log Pis Std                      1.29978
trainer/Log Pis Max                      3.9358
trainer/Log Pis Min                     -3.54198
trainer/policy/mean Mean                -0.553534
trainer/policy/mean Std                  0.412599
trainer/policy/mean Max                  0.715042
trainer/policy/mean Min                 -0.937181
trainer/policy/normal/std Mean           0.708413
trainer/policy/normal/std Std            0.101326
trainer/policy/normal/std Max            0.853222
trainer/policy/normal/std Min            0.552887
trainer/policy/normal/log_std Mean      -0.355225
trainer/policy/normal/log_std Std        0.145744
trainer/policy/normal/log_std Max       -0.158735
trainer/policy/normal/log_std Min       -0.592601
trainer/Alpha                            0.124629
trainer/Alpha Loss                      -3.74941
exploration/num steps total         144000
exploration/num paths total            720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.937446
exploration/Rewards Std                  1.42311
exploration/Rewards Max                 -1.82404e-86
exploration/Rewards Min                 -6.11025
exploration/Returns Mean              -187.489
exploration/Returns Std                113.306
exploration/Returns Max                -14.8678
exploration/Returns Min               -375.371
exploration/Actions Mean                -0.493974
exploration/Actions Std                  0.551836
exploration/Actions Max                  0.995375
exploration/Actions Min                 -0.999183
exploration/Num Paths                   10
exploration/Average Returns           -187.489
evaluation/num steps total          342504
evaluation/num paths total            1704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.627427
evaluation/Actions Std                   0.278945
evaluation/Actions Max                  -0.335948
evaluation/Actions Min                  -0.914757
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0270032
time/evaluation sampling (s)            19.8098
time/exploration sampling (s)            7.72562
time/logging (s)                         0.0888659
time/sac training (s)                   45.2522
time/saving (s)                          0.0782786
time/training (s)                        0.00016901
time/epoch (s)                          72.9819
time/total (s)                        7304.84
Epoch                                   70
----------------------------------  ----------------
2020-11-09 17:11:04.392257 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 71 finished
----------------------------------  -----------------
replay_buffer/size                  146000
trainer/num train calls              72000
trainer/QF1 Loss                        46.2995
trainer/QF2 Loss                        47.0257
trainer/Policy Loss                     47.0338
trainer/Q1 Predictions Mean            -46.9794
trainer/Q1 Predictions Std              63.5695
trainer/Q1 Predictions Max             115.771
trainer/Q1 Predictions Min            -196.124
trainer/Q2 Predictions Mean            -46.9566
trainer/Q2 Predictions Std              63.5594
trainer/Q2 Predictions Max             116.206
trainer/Q2 Predictions Min            -196.414
trainer/Q Targets Mean                 -47.5757
trainer/Q Targets Std                   63.8407
trainer/Q Targets Max                  115.108
trainer/Q Targets Min                 -195.5
trainer/Log Pis Mean                     0.162887
trainer/Log Pis Std                      1.39004
trainer/Log Pis Max                      3.19947
trainer/Log Pis Min                     -4.73241
trainer/policy/mean Mean                -0.579764
trainer/policy/mean Std                  0.389527
trainer/policy/mean Max                  0.700081
trainer/policy/mean Min                 -0.934243
trainer/policy/normal/std Mean           0.705885
trainer/policy/normal/std Std            0.0941445
trainer/policy/normal/std Max            0.84407
trainer/policy/normal/std Min            0.561981
trainer/policy/normal/log_std Mean      -0.357413
trainer/policy/normal/log_std Std        0.135731
trainer/policy/normal/log_std Max       -0.16952
trainer/policy/normal/log_std Min       -0.576287
trainer/Alpha                            0.121066
trainer/Alpha Loss                      -3.87892
exploration/num steps total         146000
exploration/num paths total            730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.624886
exploration/Rewards Std                  1.3931
exploration/Rewards Max                 -4.52765e-254
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -124.977
exploration/Returns Std                 51.7648
exploration/Returns Max                -52.4326
exploration/Returns Min               -216.445
exploration/Actions Mean                -0.522733
exploration/Actions Std                  0.526006
exploration/Actions Max                  0.986999
exploration/Actions Min                 -0.998972
exploration/Num Paths                   10
exploration/Average Returns           -124.977
evaluation/num steps total          347328
evaluation/num paths total            1728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.663209
evaluation/Actions Std                   0.243069
evaluation/Actions Max                  -0.417637
evaluation/Actions Min                  -0.914693
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0325422
time/evaluation sampling (s)            22.6226
time/exploration sampling (s)            8.9323
time/logging (s)                         0.19475
time/sac training (s)                   40.0199
time/saving (s)                          0.487893
time/training (s)                        0.000206728
time/epoch (s)                          72.2902
time/total (s)                        7433.12
Epoch                                   71
----------------------------------  -----------------
2020-11-09 17:12:42.361585 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 72 finished
----------------------------------  -----------------
replay_buffer/size                  148000
trainer/num train calls              73000
trainer/QF1 Loss                        59.9144
trainer/QF2 Loss                        59.4609
trainer/Policy Loss                     50.2091
trainer/Q1 Predictions Mean            -50.1712
trainer/Q1 Predictions Std              62.643
trainer/Q1 Predictions Max             120.006
trainer/Q1 Predictions Min            -167.119
trainer/Q2 Predictions Mean            -50.203
trainer/Q2 Predictions Std              62.579
trainer/Q2 Predictions Max             120.726
trainer/Q2 Predictions Min            -160.882
trainer/Q Targets Mean                 -50.022
trainer/Q Targets Std                   63.6485
trainer/Q Targets Max                  120.589
trainer/Q Targets Min                 -166.31
trainer/Log Pis Mean                     0.207769
trainer/Log Pis Std                      1.24435
trainer/Log Pis Max                      3.07641
trainer/Log Pis Min                     -4.68014
trainer/policy/mean Mean                -0.522146
trainer/policy/mean Std                  0.442934
trainer/policy/mean Max                  0.775168
trainer/policy/mean Min                 -0.93527
trainer/policy/normal/std Mean           0.706049
trainer/policy/normal/std Std            0.100611
trainer/policy/normal/std Max            0.835701
trainer/policy/normal/std Min            0.549118
trainer/policy/normal/log_std Mean      -0.358494
trainer/policy/normal/log_std Std        0.145261
trainer/policy/normal/log_std Max       -0.179485
trainer/policy/normal/log_std Min       -0.599442
trainer/Alpha                            0.117522
trainer/Alpha Loss                      -3.8374
exploration/num steps total         148000
exploration/num paths total            740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.577624
exploration/Rewards Std                  1.39106
exploration/Rewards Max                 -1.74291e-152
exploration/Rewards Min                 -6.11856
exploration/Returns Mean              -115.525
exploration/Returns Std                 50.6034
exploration/Returns Max                -30.9948
exploration/Returns Min               -194.042
exploration/Actions Mean                -0.570098
exploration/Actions Std                  0.501821
exploration/Actions Max                  0.989944
exploration/Actions Min                 -0.998804
exploration/Num Paths                   10
exploration/Average Returns           -115.525
evaluation/num steps total          352152
evaluation/num paths total            1752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.609087
evaluation/Actions Std                   0.291123
evaluation/Actions Max                  -0.287569
evaluation/Actions Min                  -0.908066
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0287435
time/evaluation sampling (s)            17.3247
time/exploration sampling (s)            7.17868
time/logging (s)                         0.106159
time/sac training (s)                   39.8976
time/saving (s)                          0.25171
time/training (s)                        0.000143714
time/epoch (s)                          64.7877
time/total (s)                        7530.97
Epoch                                   72
----------------------------------  -----------------
2020-11-09 17:14:09.734773 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 73 finished
----------------------------------  ----------------
replay_buffer/size                  150000
trainer/num train calls              74000
trainer/QF1 Loss                        26.9519
trainer/QF2 Loss                        27.936
trainer/Policy Loss                     54.3569
trainer/Q1 Predictions Mean            -54.416
trainer/Q1 Predictions Std              62.5028
trainer/Q1 Predictions Max              72.6285
trainer/Q1 Predictions Min            -175.747
trainer/Q2 Predictions Mean            -54.2925
trainer/Q2 Predictions Std              62.4401
trainer/Q2 Predictions Max              72.6885
trainer/Q2 Predictions Min            -175.467
trainer/Q Targets Mean                 -54.5906
trainer/Q Targets Std                   62.9277
trainer/Q Targets Max                   72.4464
trainer/Q Targets Min                 -174.835
trainer/Log Pis Mean                     0.267432
trainer/Log Pis Std                      1.20395
trainer/Log Pis Max                      3.03121
trainer/Log Pis Min                     -6.33854
trainer/policy/mean Mean                -0.440677
trainer/policy/mean Std                  0.509266
trainer/policy/mean Max                  0.744406
trainer/policy/mean Min                 -0.954162
trainer/policy/normal/std Mean           0.704286
trainer/policy/normal/std Std            0.106367
trainer/policy/normal/std Max            0.85448
trainer/policy/normal/std Min            0.526088
trainer/policy/normal/log_std Mean      -0.362312
trainer/policy/normal/log_std Std        0.15426
trainer/policy/normal/log_std Max       -0.157262
trainer/policy/normal/log_std Min       -0.642287
trainer/Alpha                            0.114106
trainer/Alpha Loss                      -3.76076
exploration/num steps total         150000
exploration/num paths total            750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.658619
exploration/Rewards Std                  1.42603
exploration/Rewards Max                 -1.00975e-90
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -131.724
exploration/Returns Std                 50.138
exploration/Returns Max                -37.9195
exploration/Returns Min               -226.33
exploration/Actions Mean                -0.504885
exploration/Actions Std                  0.548526
exploration/Actions Max                  0.997781
exploration/Actions Min                 -0.998349
exploration/Num Paths                   10
exploration/Average Returns           -131.724
evaluation/num steps total          356976
evaluation/num paths total            1776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.495679
evaluation/Actions Std                   0.413785
evaluation/Actions Max                  -0.0797935
evaluation/Actions Min                  -0.913947
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0370168
time/evaluation sampling (s)            17.9922
time/exploration sampling (s)            7.40258
time/logging (s)                         0.0892983
time/sac training (s)                   40.5045
time/saving (s)                          0.107422
time/training (s)                        0.00014011
time/epoch (s)                          66.1331
time/total (s)                        7618.29
Epoch                                   73
----------------------------------  ----------------
2020-11-09 17:15:39.211951 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 74 finished
----------------------------------  -----------------
replay_buffer/size                  152000
trainer/num train calls              75000
trainer/QF1 Loss                        69.092
trainer/QF2 Loss                        68.726
trainer/Policy Loss                     52.6049
trainer/Q1 Predictions Mean            -52.6744
trainer/Q1 Predictions Std              64.7823
trainer/Q1 Predictions Max             117.601
trainer/Q1 Predictions Min            -200.54
trainer/Q2 Predictions Mean            -52.5172
trainer/Q2 Predictions Std              64.743
trainer/Q2 Predictions Max             120.201
trainer/Q2 Predictions Min            -200.191
trainer/Q Targets Mean                 -52.4247
trainer/Q Targets Std                   65.0125
trainer/Q Targets Max                  118.527
trainer/Q Targets Min                 -199.609
trainer/Log Pis Mean                     0.250125
trainer/Log Pis Std                      1.12874
trainer/Log Pis Max                      2.68141
trainer/Log Pis Min                     -3.65898
trainer/policy/mean Mean                -0.523669
trainer/policy/mean Std                  0.434388
trainer/policy/mean Max                  0.796502
trainer/policy/mean Min                 -0.940118
trainer/policy/normal/std Mean           0.708819
trainer/policy/normal/std Std            0.107806
trainer/policy/normal/std Max            0.856933
trainer/policy/normal/std Min            0.544307
trainer/policy/normal/log_std Mean      -0.356069
trainer/policy/normal/log_std Std        0.155415
trainer/policy/normal/log_std Max       -0.154396
trainer/policy/normal/log_std Min       -0.608243
trainer/Alpha                            0.11075
trainer/Alpha Loss                      -3.85056
exploration/num steps total         152000
exploration/num paths total            760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.582461
exploration/Rewards Std                  1.21337
exploration/Rewards Max                 -1.27652e-157
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -116.492
exploration/Returns Std                 76.9214
exploration/Returns Max                -45.8251
exploration/Returns Min               -299.196
exploration/Actions Mean                -0.474039
exploration/Actions Std                  0.570875
exploration/Actions Max                  0.991908
exploration/Actions Min                 -0.997533
exploration/Num Paths                   10
exploration/Average Returns           -116.492
evaluation/num steps total          361800
evaluation/num paths total            1800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.579221
evaluation/Actions Std                   0.328233
evaluation/Actions Max                  -0.245666
evaluation/Actions Min                  -0.907058
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0298642
time/evaluation sampling (s)            18.5558
time/exploration sampling (s)            7.22769
time/logging (s)                         0.0523164
time/sac training (s)                   40.6819
time/saving (s)                          0.162494
time/training (s)                        0.000133718
time/epoch (s)                          66.7102
time/total (s)                        7707.7
Epoch                                   74
----------------------------------  -----------------
2020-11-09 17:17:08.351822 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 75 finished
----------------------------------  -----------------
replay_buffer/size                  154000
trainer/num train calls              76000
trainer/QF1 Loss                        13.5427
trainer/QF2 Loss                        14.6715
trainer/Policy Loss                     49.1547
trainer/Q1 Predictions Mean            -49.1044
trainer/Q1 Predictions Std              62.3168
trainer/Q1 Predictions Max             108.135
trainer/Q1 Predictions Min            -200.735
trainer/Q2 Predictions Mean            -49.0029
trainer/Q2 Predictions Std              62.3232
trainer/Q2 Predictions Max             110.243
trainer/Q2 Predictions Min            -200.467
trainer/Q Targets Mean                 -49.6515
trainer/Q Targets Std                   62.6822
trainer/Q Targets Max                  108.163
trainer/Q Targets Min                 -199.88
trainer/Log Pis Mean                     0.273508
trainer/Log Pis Std                      1.32464
trainer/Log Pis Max                      4.25955
trainer/Log Pis Min                     -4.58191
trainer/policy/mean Mean                -0.530242
trainer/policy/mean Std                  0.441787
trainer/policy/mean Max                  0.809068
trainer/policy/mean Min                 -0.970242
trainer/policy/normal/std Mean           0.703972
trainer/policy/normal/std Std            0.103192
trainer/policy/normal/std Max            0.841301
trainer/policy/normal/std Min            0.494491
trainer/policy/normal/log_std Mean      -0.362132
trainer/policy/normal/log_std Std        0.150307
trainer/policy/normal/log_std Max       -0.172805
trainer/policy/normal/log_std Min       -0.704227
trainer/Alpha                            0.107531
trainer/Alpha Loss                      -3.85003
exploration/num steps total         154000
exploration/num paths total            770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.527041
exploration/Rewards Std                  1.2496
exploration/Rewards Max                 -6.29729e-154
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -105.408
exploration/Returns Std                 43.5912
exploration/Returns Max                -33.1312
exploration/Returns Min               -200.87
exploration/Actions Mean                -0.54845
exploration/Actions Std                  0.53011
exploration/Actions Max                  0.995309
exploration/Actions Min                 -0.997882
exploration/Num Paths                   10
exploration/Average Returns           -105.408
evaluation/num steps total          366624
evaluation/num paths total            1824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.598428
evaluation/Actions Std                   0.310831
evaluation/Actions Max                  -0.254968
evaluation/Actions Min                  -0.919485
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0363316
time/evaluation sampling (s)            17.5379
time/exploration sampling (s)            7.25524
time/logging (s)                         0.126106
time/sac training (s)                   43.2342
time/saving (s)                          0.218999
time/training (s)                        0.000134315
time/epoch (s)                          68.4089
time/total (s)                        7796.87
Epoch                                   75
----------------------------------  -----------------
2020-11-09 17:19:30.541435 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 76 finished
----------------------------------  -----------------
replay_buffer/size                  156000
trainer/num train calls              77000
trainer/QF1 Loss                        34.4319
trainer/QF2 Loss                        34.4405
trainer/Policy Loss                     49.3192
trainer/Q1 Predictions Mean            -49.3273
trainer/Q1 Predictions Std              59.3642
trainer/Q1 Predictions Max              71.935
trainer/Q1 Predictions Min            -197.302
trainer/Q2 Predictions Mean            -49.2989
trainer/Q2 Predictions Std              59.3057
trainer/Q2 Predictions Max              71.7627
trainer/Q2 Predictions Min            -197.749
trainer/Q Targets Mean                 -49.3367
trainer/Q Targets Std                   59.7685
trainer/Q Targets Max                   71.1915
trainer/Q Targets Min                 -196.787
trainer/Log Pis Mean                     0.285525
trainer/Log Pis Std                      1.22457
trainer/Log Pis Max                      2.46682
trainer/Log Pis Min                     -4.04294
trainer/policy/mean Mean                -0.465673
trainer/policy/mean Std                  0.503025
trainer/policy/mean Max                  0.8216
trainer/policy/mean Min                 -0.961943
trainer/policy/normal/std Mean           0.70405
trainer/policy/normal/std Std            0.106171
trainer/policy/normal/std Max            0.851787
trainer/policy/normal/std Min            0.519856
trainer/policy/normal/log_std Mean      -0.362669
trainer/policy/normal/log_std Std        0.154612
trainer/policy/normal/log_std Max       -0.160418
trainer/policy/normal/log_std Min       -0.654203
trainer/Alpha                            0.104466
trainer/Alpha Loss                      -3.87282
exploration/num steps total         156000
exploration/num paths total            780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.753555
exploration/Rewards Std                  1.40424
exploration/Rewards Max                 -7.89552e-175
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -150.711
exploration/Returns Std                 55.4081
exploration/Returns Max                -87.5096
exploration/Returns Min               -259.466
exploration/Actions Mean                -0.505013
exploration/Actions Std                  0.558036
exploration/Actions Max                  0.992167
exploration/Actions Min                 -0.998421
exploration/Num Paths                   10
exploration/Average Returns           -150.711
evaluation/num steps total          371448
evaluation/num paths total            1848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96392
evaluation/Rewards Std                   0.534365
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.75
evaluation/Returns Std                 107.407
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.530285
evaluation/Actions Std                   0.384869
evaluation/Actions Max                  -0.143336
evaluation/Actions Min                  -0.922892
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.75
time/data storing (s)                    0.0275385
time/evaluation sampling (s)            17.2808
time/exploration sampling (s)            7.01267
time/logging (s)                         0.110362
time/sac training (s)                   49.8564
time/saving (s)                          0.321214
time/training (s)                        0.000188406
time/epoch (s)                          74.6092
time/total (s)                        7939.02
Epoch                                   76
----------------------------------  -----------------
2020-11-09 17:22:29.154289 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 77 finished
----------------------------------  -----------------
replay_buffer/size                  158000
trainer/num train calls              78000
trainer/QF1 Loss                        17.3823
trainer/QF2 Loss                        17.6725
trainer/Policy Loss                     47.6633
trainer/Q1 Predictions Mean            -47.7509
trainer/Q1 Predictions Std              64.4995
trainer/Q1 Predictions Max              77.5368
trainer/Q1 Predictions Min            -200.551
trainer/Q2 Predictions Mean            -47.7268
trainer/Q2 Predictions Std              64.4656
trainer/Q2 Predictions Max              77.3674
trainer/Q2 Predictions Min            -200.477
trainer/Q Targets Mean                 -48.1108
trainer/Q Targets Std                   65.0034
trainer/Q Targets Max                   77.323
trainer/Q Targets Min                 -199.832
trainer/Log Pis Mean                     0.505848
trainer/Log Pis Std                      1.28558
trainer/Log Pis Max                      2.97722
trainer/Log Pis Min                     -4.1352
trainer/policy/mean Mean                -0.467231
trainer/policy/mean Std                  0.518557
trainer/policy/mean Max                  0.831833
trainer/policy/mean Min                 -0.963637
trainer/policy/normal/std Mean           0.693235
trainer/policy/normal/std Std            0.107203
trainer/policy/normal/std Max            0.831297
trainer/policy/normal/std Min            0.520758
trainer/policy/normal/log_std Mean      -0.378681
trainer/policy/normal/log_std Std        0.157813
trainer/policy/normal/log_std Max       -0.184768
trainer/policy/normal/log_std Min       -0.652471
trainer/Alpha                            0.101536
trainer/Alpha Loss                      -3.41764
exploration/num steps total         158000
exploration/num paths total            790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.705206
exploration/Rewards Std                  1.47103
exploration/Rewards Max                 -2.62864e-144
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -141.041
exploration/Returns Std                 57.8703
exploration/Returns Max                -32.7892
exploration/Returns Min               -220.912
exploration/Actions Mean                -0.476686
exploration/Actions Std                  0.578788
exploration/Actions Max                  0.988943
exploration/Actions Min                 -0.998245
exploration/Num Paths                   10
exploration/Average Returns           -141.041
evaluation/num steps total          376272
evaluation/num paths total            1872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96392
evaluation/Rewards Std                   0.534365
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.75
evaluation/Returns Std                 107.407
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.542423
evaluation/Actions Std                   0.38302
evaluation/Actions Max                  -0.157752
evaluation/Actions Min                  -0.931543
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.75
time/data storing (s)                    0.0304221
time/evaluation sampling (s)            19.1989
time/exploration sampling (s)            7.98279
time/logging (s)                         0.104221
time/sac training (s)                   48.5868
time/saving (s)                          0.219901
time/training (s)                        0.000179513
time/epoch (s)                          76.1231
time/total (s)                        8117.59
Epoch                                   77
----------------------------------  -----------------
2020-11-09 17:24:44.918968 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 78 finished
----------------------------------  -----------------
replay_buffer/size                  160000
trainer/num train calls              79000
trainer/QF1 Loss                        17.0654
trainer/QF2 Loss                        15.0218
trainer/Policy Loss                     58.1043
trainer/Q1 Predictions Mean            -57.9798
trainer/Q1 Predictions Std              63.4263
trainer/Q1 Predictions Max              76.4081
trainer/Q1 Predictions Min            -200.789
trainer/Q2 Predictions Mean            -58.0358
trainer/Q2 Predictions Std              63.4643
trainer/Q2 Predictions Max              76.2012
trainer/Q2 Predictions Min            -200.65
trainer/Q Targets Mean                 -58.4455
trainer/Q Targets Std                   63.9033
trainer/Q Targets Max                   75.4109
trainer/Q Targets Min                 -199.847
trainer/Log Pis Mean                     0.554472
trainer/Log Pis Std                      1.16256
trainer/Log Pis Max                      2.94341
trainer/Log Pis Min                     -3.57659
trainer/policy/mean Mean                -0.472818
trainer/policy/mean Std                  0.510697
trainer/policy/mean Max                  0.847912
trainer/policy/mean Min                 -0.961494
trainer/policy/normal/std Mean           0.692148
trainer/policy/normal/std Std            0.113601
trainer/policy/normal/std Max            0.838964
trainer/policy/normal/std Min            0.519729
trainer/policy/normal/log_std Mean      -0.381847
trainer/policy/normal/log_std Std        0.167865
trainer/policy/normal/log_std Max       -0.175587
trainer/policy/normal/log_std Min       -0.654448
trainer/Alpha                            0.0986269
trainer/Alpha Loss                      -3.34844
exploration/num steps total         160000
exploration/num paths total            800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.507625
exploration/Rewards Std                  1.30708
exploration/Rewards Max                 -9.96107e-162
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -101.525
exploration/Returns Std                 57.9186
exploration/Returns Max                -19.0485
exploration/Returns Min               -200.724
exploration/Actions Mean                -0.45588
exploration/Actions Std                  0.614045
exploration/Actions Max                  0.992507
exploration/Actions Min                 -0.998947
exploration/Num Paths                   10
exploration/Average Returns           -101.525
evaluation/num steps total          381096
evaluation/num paths total            1896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.554565
evaluation/Actions Std                   0.374261
evaluation/Actions Max                  -0.175949
evaluation/Actions Min                  -0.933829
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0288849
time/evaluation sampling (s)            19.7393
time/exploration sampling (s)            8.13577
time/logging (s)                         0.181044
time/sac training (s)                   46.1388
time/saving (s)                          0.261485
time/training (s)                        0.000179191
time/epoch (s)                          74.4855
time/total (s)                        8253.38
Epoch                                   78
----------------------------------  -----------------
2020-11-09 17:26:55.816675 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 79 finished
----------------------------------  -----------------
replay_buffer/size                  162000
trainer/num train calls              80000
trainer/QF1 Loss                        47.7877
trainer/QF2 Loss                        48.2596
trainer/Policy Loss                     49.1872
trainer/Q1 Predictions Mean            -49.1687
trainer/Q1 Predictions Std              63.2029
trainer/Q1 Predictions Max              60.9509
trainer/Q1 Predictions Min            -176.838
trainer/Q2 Predictions Mean            -49.195
trainer/Q2 Predictions Std              63.2865
trainer/Q2 Predictions Max              60.9907
trainer/Q2 Predictions Min            -178.622
trainer/Q Targets Mean                 -49.1748
trainer/Q Targets Std                   63.8595
trainer/Q Targets Max                   60.42
trainer/Q Targets Min                 -179.225
trainer/Log Pis Mean                     0.521428
trainer/Log Pis Std                      1.29868
trainer/Log Pis Max                      3.26973
trainer/Log Pis Min                     -3.53393
trainer/policy/mean Mean                -0.434376
trainer/policy/mean Std                  0.551588
trainer/policy/mean Max                  0.86663
trainer/policy/mean Min                 -0.976503
trainer/policy/normal/std Mean           0.685588
trainer/policy/normal/std Std            0.114038
trainer/policy/normal/std Max            0.833201
trainer/policy/normal/std Min            0.479241
trainer/policy/normal/log_std Mean      -0.391752
trainer/policy/normal/log_std Std        0.170179
trainer/policy/normal/log_std Max       -0.18248
trainer/policy/normal/log_std Min       -0.735551
trainer/Alpha                            0.0957908
trainer/Alpha Loss                      -3.46812
exploration/num steps total         162000
exploration/num paths total            810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.762151
exploration/Rewards Std                  1.35199
exploration/Rewards Max                 -2.71237e-237
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -152.43
exploration/Returns Std                 85.7444
exploration/Returns Max                -57.4948
exploration/Returns Min               -339.68
exploration/Actions Mean                -0.422278
exploration/Actions Std                  0.652335
exploration/Actions Max                  0.99841
exploration/Actions Min                 -0.998885
exploration/Num Paths                   10
exploration/Average Returns           -152.43
evaluation/num steps total          385920
evaluation/num paths total            1920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.497031
evaluation/Actions Std                   0.436776
evaluation/Actions Max                  -0.0407427
evaluation/Actions Min                  -0.934149
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0321382
time/evaluation sampling (s)            19.5155
time/exploration sampling (s)            7.6909
time/logging (s)                         0.0662267
time/sac training (s)                   46.3031
time/saving (s)                          0.0580329
time/training (s)                        0.000123356
time/epoch (s)                          73.6661
time/total (s)                        8384.13
Epoch                                   79
----------------------------------  -----------------
2020-11-09 17:30:21.776688 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 80 finished
----------------------------------  ---------------
replay_buffer/size                  164000
trainer/num train calls              81000
trainer/QF1 Loss                        11.6314
trainer/QF2 Loss                        12.5732
trainer/Policy Loss                     54.6361
trainer/Q1 Predictions Mean            -54.5319
trainer/Q1 Predictions Std              62.2877
trainer/Q1 Predictions Max              69.3649
trainer/Q1 Predictions Min            -200.999
trainer/Q2 Predictions Mean            -54.5696
trainer/Q2 Predictions Std              62.3482
trainer/Q2 Predictions Max              69.3407
trainer/Q2 Predictions Min            -201.032
trainer/Q Targets Mean                 -54.8501
trainer/Q Targets Std                   62.6583
trainer/Q Targets Max                   68.7861
trainer/Q Targets Min                 -200.042
trainer/Log Pis Mean                     0.386782
trainer/Log Pis Std                      1.33024
trainer/Log Pis Max                      3.30394
trainer/Log Pis Min                     -4.05592
trainer/policy/mean Mean                -0.49343
trainer/policy/mean Std                  0.49655
trainer/policy/mean Max                  0.824404
trainer/policy/mean Min                 -0.948265
trainer/policy/normal/std Mean           0.701822
trainer/policy/normal/std Std            0.110616
trainer/policy/normal/std Max            0.853063
trainer/policy/normal/std Min            0.539833
trainer/policy/normal/log_std Mean      -0.366907
trainer/policy/normal/log_std Std        0.161411
trainer/policy/normal/log_std Max       -0.158921
trainer/policy/normal/log_std Min       -0.616495
trainer/Alpha                            0.0929676
trainer/Alpha Loss                      -3.83221
exploration/num steps total         164000
exploration/num paths total            820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.554058
exploration/Rewards Std                  1.33877
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -110.812
exploration/Returns Std                 64.0204
exploration/Returns Max                -28.5387
exploration/Returns Min               -211.821
exploration/Actions Mean                -0.439937
exploration/Actions Std                  0.623017
exploration/Actions Max                  0.993686
exploration/Actions Min                 -0.998213
exploration/Num Paths                   10
exploration/Average Returns           -110.812
evaluation/num steps total          390744
evaluation/num paths total            1944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.584894
evaluation/Actions Std                   0.340091
evaluation/Actions Max                  -0.239028
evaluation/Actions Min                  -0.924452
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.08798
time/evaluation sampling (s)            23.1682
time/exploration sampling (s)           11.3259
time/logging (s)                         0.218873
time/sac training (s)                   56.6106
time/saving (s)                          0.449419
time/training (s)                        0.00018949
time/epoch (s)                          91.8612
time/total (s)                        8590.2
Epoch                                   80
----------------------------------  ---------------
2020-11-09 17:35:37.469755 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 81 finished
----------------------------------  -----------------
replay_buffer/size                  166000
trainer/num train calls              82000
trainer/QF1 Loss                        63.5827
trainer/QF2 Loss                        66.5399
trainer/Policy Loss                     55.2915
trainer/Q1 Predictions Mean            -55.3089
trainer/Q1 Predictions Std              63.4373
trainer/Q1 Predictions Max             113.428
trainer/Q1 Predictions Min            -197.916
trainer/Q2 Predictions Mean            -55.2496
trainer/Q2 Predictions Std              63.3488
trainer/Q2 Predictions Max             113.99
trainer/Q2 Predictions Min            -198.197
trainer/Q Targets Mean                 -54.7665
trainer/Q Targets Std                   63.6322
trainer/Q Targets Max                  113.124
trainer/Q Targets Min                 -197.335
trainer/Log Pis Mean                     0.669159
trainer/Log Pis Std                      1.2462
trainer/Log Pis Max                      3.2825
trainer/Log Pis Min                     -4.35726
trainer/policy/mean Mean                -0.468049
trainer/policy/mean Std                  0.536513
trainer/policy/mean Max                  0.845784
trainer/policy/mean Min                 -0.985077
trainer/policy/normal/std Mean           0.682775
trainer/policy/normal/std Std            0.114944
trainer/policy/normal/std Max            0.837431
trainer/policy/normal/std Min            0.444216
trainer/policy/normal/log_std Mean      -0.39618
trainer/policy/normal/log_std Std        0.171957
trainer/policy/normal/log_std Max       -0.177416
trainer/policy/normal/log_std Min       -0.811444
trainer/Alpha                            0.0903747
trainer/Alpha Loss                      -3.19906
exploration/num steps total         166000
exploration/num paths total            830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.684667
exploration/Rewards Std                  1.42761
exploration/Rewards Max                 -3.02816e-127
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -136.933
exploration/Returns Std                 50.0963
exploration/Returns Max                -74.5296
exploration/Returns Min               -265.09
exploration/Actions Mean                -0.455954
exploration/Actions Std                  0.613314
exploration/Actions Max                  0.993642
exploration/Actions Min                 -0.998206
exploration/Num Paths                   10
exploration/Average Returns           -136.933
evaluation/num steps total          395568
evaluation/num paths total            1968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.62403
evaluation/Rewards Std                   1.00917
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1130.43
evaluation/Returns Std                 202.843
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.530161
evaluation/Actions Std                   0.410545
evaluation/Actions Max                  -0.0986648
evaluation/Actions Min                  -0.944477
evaluation/Num Paths                    24
evaluation/Average Returns           -1130.43
time/data storing (s)                    0.0680576
time/evaluation sampling (s)            20.0205
time/exploration sampling (s)            8.9299
time/logging (s)                         0.193901
time/sac training (s)                   47.2198
time/saving (s)                          0.229072
time/training (s)                        0.000139617
time/epoch (s)                          76.6613
time/total (s)                        8905.82
Epoch                                   81
----------------------------------  -----------------
2020-11-09 17:39:38.456325 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 82 finished
----------------------------------  -----------------
replay_buffer/size                  168000
trainer/num train calls              83000
trainer/QF1 Loss                        10.941
trainer/QF2 Loss                        11.8059
trainer/Policy Loss                     51.375
trainer/Q1 Predictions Mean            -51.3521
trainer/Q1 Predictions Std              59.6533
trainer/Q1 Predictions Max              74.8669
trainer/Q1 Predictions Min            -178.141
trainer/Q2 Predictions Mean            -51.321
trainer/Q2 Predictions Std              59.6127
trainer/Q2 Predictions Max              74.7199
trainer/Q2 Predictions Min            -179.867
trainer/Q Targets Mean                 -51.6141
trainer/Q Targets Std                   60.4098
trainer/Q Targets Max                   74.3945
trainer/Q Targets Min                 -182.934
trainer/Log Pis Mean                     0.536946
trainer/Log Pis Std                      1.45227
trainer/Log Pis Max                      3.46245
trainer/Log Pis Min                     -4.96853
trainer/policy/mean Mean                -0.446319
trainer/policy/mean Std                  0.559515
trainer/policy/mean Max                  0.854143
trainer/policy/mean Min                 -0.9636
trainer/policy/normal/std Mean           0.684644
trainer/policy/normal/std Std            0.115002
trainer/policy/normal/std Max            0.837843
trainer/policy/normal/std Min            0.510148
trainer/policy/normal/log_std Mean      -0.393359
trainer/policy/normal/log_std Std        0.17136
trainer/policy/normal/log_std Max       -0.176925
trainer/policy/normal/log_std Min       -0.673055
trainer/Alpha                            0.0876992
trainer/Alpha Loss                      -3.56084
exploration/num steps total         168000
exploration/num paths total            840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.688909
exploration/Rewards Std                  1.44192
exploration/Rewards Max                 -5.72745e-121
exploration/Rewards Min                 -6.12253
exploration/Returns Mean              -137.782
exploration/Returns Std                 73.2273
exploration/Returns Max                -10.8742
exploration/Returns Min               -270.143
exploration/Actions Mean                -0.43676
exploration/Actions Std                  0.623492
exploration/Actions Max                  0.999387
exploration/Actions Min                 -0.999085
exploration/Num Paths                   10
exploration/Average Returns           -137.782
evaluation/num steps total          400392
evaluation/num paths total            1992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.66536e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.506256
evaluation/Actions Std                   0.431222
evaluation/Actions Max                  -0.0749833
evaluation/Actions Min                  -0.93805
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0247502
time/evaluation sampling (s)            17.1592
time/exploration sampling (s)            7.01321
time/logging (s)                         0.193473
time/sac training (s)                   40.1782
time/saving (s)                          1.33169
time/training (s)                        0.000147927
time/epoch (s)                          65.9007
time/total (s)                        9146.75
Epoch                                   82
----------------------------------  -----------------
2020-11-09 17:45:04.906042 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 83 finished
----------------------------------  -----------------
replay_buffer/size                  170000
trainer/num train calls              84000
trainer/QF1 Loss                        51.2222
trainer/QF2 Loss                        50.1157
trainer/Policy Loss                     51.7708
trainer/Q1 Predictions Mean            -51.7222
trainer/Q1 Predictions Std              62.6365
trainer/Q1 Predictions Max              57.1392
trainer/Q1 Predictions Min            -198.191
trainer/Q2 Predictions Mean            -51.6441
trainer/Q2 Predictions Std              62.5444
trainer/Q2 Predictions Max              56.8607
trainer/Q2 Predictions Min            -198.445
trainer/Q Targets Mean                 -52.0771
trainer/Q Targets Std                   62.9658
trainer/Q Targets Max                   58.1063
trainer/Q Targets Min                 -197.681
trainer/Log Pis Mean                     0.376389
trainer/Log Pis Std                      1.51635
trainer/Log Pis Max                      3.93605
trainer/Log Pis Min                     -6.25922
trainer/policy/mean Mean                -0.440909
trainer/policy/mean Std                  0.561917
trainer/policy/mean Max                  0.876864
trainer/policy/mean Min                 -0.970253
trainer/policy/normal/std Mean           0.675628
trainer/policy/normal/std Std            0.101277
trainer/policy/normal/std Max            0.816472
trainer/policy/normal/std Min            0.496566
trainer/policy/normal/log_std Mean      -0.403652
trainer/policy/normal/log_std Std        0.152857
trainer/policy/normal/log_std Max       -0.202762
trainer/policy/normal/log_std Min       -0.700038
trainer/Alpha                            0.0851675
trainer/Alpha Loss                      -3.99917
exploration/num steps total         170000
exploration/num paths total            850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.655982
exploration/Rewards Std                  1.38349
exploration/Rewards Max                 -6.08094e-168
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -131.196
exploration/Returns Std                 79.5722
exploration/Returns Max                -52.2275
exploration/Returns Min               -312.633
exploration/Actions Mean                -0.428762
exploration/Actions Std                  0.648084
exploration/Actions Max                  0.997175
exploration/Actions Min                 -0.997171
exploration/Num Paths                   10
exploration/Average Returns           -131.196
evaluation/num steps total          405216
evaluation/num paths total            2016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.469961
evaluation/Actions Std                   0.466165
evaluation/Actions Max                   0.0252294
evaluation/Actions Min                  -0.936563
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0287699
time/evaluation sampling (s)            19.0076
time/exploration sampling (s)            7.9569
time/logging (s)                         0.194516
time/sac training (s)                   53.4788
time/saving (s)                          0.363888
time/training (s)                        0.000169779
time/epoch (s)                          81.0307
time/total (s)                        9473.15
Epoch                                   83
----------------------------------  -----------------
2020-11-09 17:49:52.647043 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 84 finished
----------------------------------  -----------------
replay_buffer/size                  172000
trainer/num train calls              85000
trainer/QF1 Loss                        28.2313
trainer/QF2 Loss                        29.9084
trainer/Policy Loss                     46.7937
trainer/Q1 Predictions Mean            -46.7693
trainer/Q1 Predictions Std              62.8584
trainer/Q1 Predictions Max             112.017
trainer/Q1 Predictions Min            -165.593
trainer/Q2 Predictions Mean            -46.7431
trainer/Q2 Predictions Std              62.7873
trainer/Q2 Predictions Max             111.884
trainer/Q2 Predictions Min            -165.952
trainer/Q Targets Mean                 -46.7166
trainer/Q Targets Std                   63.5466
trainer/Q Targets Max                  111.458
trainer/Q Targets Min                 -165.17
trainer/Log Pis Mean                     0.760381
trainer/Log Pis Std                      1.45281
trainer/Log Pis Max                      4.02768
trainer/Log Pis Min                     -5.51113
trainer/policy/mean Mean                -0.571079
trainer/policy/mean Std                  0.46437
trainer/policy/mean Max                  0.796805
trainer/policy/mean Min                 -0.967512
trainer/policy/normal/std Mean           0.670746
trainer/policy/normal/std Std            0.0979619
trainer/policy/normal/std Max            0.810849
trainer/policy/normal/std Min            0.511562
trainer/policy/normal/log_std Mean      -0.410297
trainer/policy/normal/log_std Std        0.148717
trainer/policy/normal/log_std Max       -0.209673
trainer/policy/normal/log_std Min       -0.670287
trainer/Alpha                            0.08276
trainer/Alpha Loss                      -3.0889
exploration/num steps total         172000
exploration/num paths total            860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.732135
exploration/Rewards Std                  1.46397
exploration/Rewards Max                 -9.39048e-148
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.427
exploration/Returns Std                 63.5853
exploration/Returns Max                -56.8401
exploration/Returns Min               -251.612
exploration/Actions Mean                -0.640089
exploration/Actions Std                  0.463847
exploration/Actions Max                  0.985384
exploration/Actions Min                 -0.999157
exploration/Num Paths                   10
exploration/Average Returns           -146.427
evaluation/num steps total          410040
evaluation/num paths total            2040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96392
evaluation/Rewards Std                   0.534365
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.75
evaluation/Returns Std                 107.407
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.680236
evaluation/Actions Std                   0.260335
evaluation/Actions Max                  -0.419218
evaluation/Actions Min                  -0.944529
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.75
time/data storing (s)                    0.0632018
time/evaluation sampling (s)            25.8706
time/exploration sampling (s)           12.4242
time/logging (s)                         0.228879
time/sac training (s)                   54.8218
time/saving (s)                          0.618023
time/training (s)                        0.000176191
time/epoch (s)                          94.0269
time/total (s)                        9760.88
Epoch                                   84
----------------------------------  -----------------
2020-11-09 17:53:33.882903 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 85 finished
----------------------------------  -----------------
replay_buffer/size                  174000
trainer/num train calls              86000
trainer/QF1 Loss                        39.1683
trainer/QF2 Loss                        38.8166
trainer/Policy Loss                     47.1583
trainer/Q1 Predictions Mean            -47.1361
trainer/Q1 Predictions Std              63.1221
trainer/Q1 Predictions Max              74.9932
trainer/Q1 Predictions Min            -198.362
trainer/Q2 Predictions Mean            -47.1162
trainer/Q2 Predictions Std              63.084
trainer/Q2 Predictions Max              74.7735
trainer/Q2 Predictions Min            -198.71
trainer/Q Targets Mean                 -47.1685
trainer/Q Targets Std                   63.4611
trainer/Q Targets Max                   74.4499
trainer/Q Targets Min                 -197.625
trainer/Log Pis Mean                     0.71592
trainer/Log Pis Std                      1.54315
trainer/Log Pis Max                      3.53741
trainer/Log Pis Min                     -5.45094
trainer/policy/mean Mean                -0.592806
trainer/policy/mean Std                  0.450364
trainer/policy/mean Max                  0.810725
trainer/policy/mean Min                 -0.987446
trainer/policy/normal/std Mean           0.669963
trainer/policy/normal/std Std            0.107855
trainer/policy/normal/std Max            0.824682
trainer/policy/normal/std Min            0.439088
trainer/policy/normal/log_std Mean      -0.413826
trainer/policy/normal/log_std Std        0.164006
trainer/policy/normal/log_std Max       -0.192758
trainer/policy/normal/log_std Min       -0.823056
trainer/Alpha                            0.0805227
trainer/Alpha Loss                      -3.23487
exploration/num steps total         174000
exploration/num paths total            870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.728227
exploration/Rewards Std                  1.37674
exploration/Rewards Max                 -1.00274e-177
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -145.645
exploration/Returns Std                 79.4719
exploration/Returns Max                -19.583
exploration/Returns Min               -298.879
exploration/Actions Mean                -0.561986
exploration/Actions Std                  0.548061
exploration/Actions Max                  0.996094
exploration/Actions Min                 -0.999208
exploration/Num Paths                   10
exploration/Average Returns           -145.645
evaluation/num steps total          414864
evaluation/num paths total            2064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.49761e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.673522
evaluation/Actions Std                   0.267854
evaluation/Actions Max                  -0.40565
evaluation/Actions Min                  -0.941792
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0300574
time/evaluation sampling (s)            17.5714
time/exploration sampling (s)            8.32583
time/logging (s)                         0.128183
time/sac training (s)                   43.8963
time/saving (s)                          0.500209
time/training (s)                        0.000174555
time/epoch (s)                          70.4521
time/total (s)                        9981.98
Epoch                                   85
----------------------------------  -----------------
2020-11-09 17:57:34.590805 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 86 finished
----------------------------------  -----------------
replay_buffer/size                  176000
trainer/num train calls              87000
trainer/QF1 Loss                        71.5736
trainer/QF2 Loss                        70.5246
trainer/Policy Loss                     44.6453
trainer/Q1 Predictions Mean            -44.6065
trainer/Q1 Predictions Std              58.4207
trainer/Q1 Predictions Max              65.2826
trainer/Q1 Predictions Min            -201.961
trainer/Q2 Predictions Mean            -44.567
trainer/Q2 Predictions Std              58.4212
trainer/Q2 Predictions Max              65.2511
trainer/Q2 Predictions Min            -201.975
trainer/Q Targets Mean                 -44.1523
trainer/Q Targets Std                   58.5961
trainer/Q Targets Max                   65.3152
trainer/Q Targets Min                 -201.241
trainer/Log Pis Mean                     0.789916
trainer/Log Pis Std                      1.37781
trainer/Log Pis Max                      3.47329
trainer/Log Pis Min                     -4.07618
trainer/policy/mean Mean                -0.370725
trainer/policy/mean Std                  0.63902
trainer/policy/mean Max                  0.892901
trainer/policy/mean Min                 -0.967663
trainer/policy/normal/std Mean           0.667342
trainer/policy/normal/std Std            0.100609
trainer/policy/normal/std Max            0.81649
trainer/policy/normal/std Min            0.499943
trainer/policy/normal/log_std Mean      -0.416068
trainer/policy/normal/log_std Std        0.153182
trainer/policy/normal/log_std Max       -0.20274
trainer/policy/normal/log_std Min       -0.693261
trainer/Alpha                            0.0781454
trainer/Alpha Loss                      -3.08472
exploration/num steps total         176000
exploration/num paths total            880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.727475
exploration/Rewards Std                  1.40047
exploration/Rewards Max                 -1.70176e-190
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -145.495
exploration/Returns Std                 56.9037
exploration/Returns Max                -78.6461
exploration/Returns Min               -268.844
exploration/Actions Mean                -0.369815
exploration/Actions Std                  0.701787
exploration/Actions Max                  0.993737
exploration/Actions Min                 -0.998984
exploration/Num Paths                   10
exploration/Average Returns           -145.495
evaluation/num steps total          419688
evaluation/num paths total            2088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.466115
evaluation/Actions Std                   0.477976
evaluation/Actions Max                   0.013899
evaluation/Actions Min                  -0.950316
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.028413
time/evaluation sampling (s)            18.1385
time/exploration sampling (s)            6.47369
time/logging (s)                         0.0904036
time/sac training (s)                   38.0346
time/saving (s)                          0.124558
time/training (s)                        0.000123494
time/epoch (s)                          62.8903
time/total (s)                       10222.6
Epoch                                   86
----------------------------------  -----------------
2020-11-09 18:00:55.793882 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 87 finished
----------------------------------  -----------------
replay_buffer/size                  178000
trainer/num train calls              88000
trainer/QF1 Loss                        11.4587
trainer/QF2 Loss                        11.8713
trainer/Policy Loss                     56.5359
trainer/Q1 Predictions Mean            -56.4912
trainer/Q1 Predictions Std              60.5329
trainer/Q1 Predictions Max             110.402
trainer/Q1 Predictions Min            -173.84
trainer/Q2 Predictions Mean            -56.5188
trainer/Q2 Predictions Std              60.621
trainer/Q2 Predictions Max             110.792
trainer/Q2 Predictions Min            -174.141
trainer/Q Targets Mean                 -56.5767
trainer/Q Targets Std                   61.0508
trainer/Q Targets Max                  110.212
trainer/Q Targets Min                 -173.332
trainer/Log Pis Mean                     0.829726
trainer/Log Pis Std                      1.37432
trainer/Log Pis Max                      3.39697
trainer/Log Pis Min                     -6.26087
trainer/policy/mean Mean                -0.536355
trainer/policy/mean Std                  0.508366
trainer/policy/mean Max                  0.850399
trainer/policy/mean Min                 -0.962096
trainer/policy/normal/std Mean           0.670563
trainer/policy/normal/std Std            0.10976
trainer/policy/normal/std Max            0.832654
trainer/policy/normal/std Min            0.516886
trainer/policy/normal/log_std Mean      -0.413397
trainer/policy/normal/log_std Std        0.166888
trainer/policy/normal/log_std Max       -0.183138
trainer/policy/normal/log_std Min       -0.659934
trainer/Alpha                            0.0758743
trainer/Alpha Loss                      -3.01776
exploration/num steps total         178000
exploration/num paths total            890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14999
exploration/Rewards Std                  1.50979
exploration/Rewards Max                 -2.97606e-100
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -229.997
exploration/Returns Std                100.313
exploration/Returns Max                -61.9341
exploration/Returns Min               -395.196
exploration/Actions Mean                -0.573736
exploration/Actions Std                  0.518291
exploration/Actions Max                  0.980474
exploration/Actions Min                 -0.999307
exploration/Num Paths                   10
exploration/Average Returns           -229.997
evaluation/num steps total          424512
evaluation/num paths total            2112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74108
evaluation/Rewards Std                   0.884392
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.96
evaluation/Returns Std                 177.763
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.627851
evaluation/Actions Std                   0.318051
evaluation/Actions Max                  -0.307027
evaluation/Actions Min                  -0.950118
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.96
time/data storing (s)                    0.0485335
time/evaluation sampling (s)            16.6533
time/exploration sampling (s)            7.70672
time/logging (s)                         0.211902
time/sac training (s)                   40.3648
time/saving (s)                          0.248233
time/training (s)                        0.000145295
time/epoch (s)                          65.2336
time/total (s)                       10423.9
Epoch                                   87
----------------------------------  -----------------
2020-11-09 18:05:22.709310 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 88 finished
----------------------------------  ----------------
replay_buffer/size                  180000
trainer/num train calls              89000
trainer/QF1 Loss                        51.0825
trainer/QF2 Loss                        50.556
trainer/Policy Loss                     52.8787
trainer/Q1 Predictions Mean            -52.7814
trainer/Q1 Predictions Std              60.4914
trainer/Q1 Predictions Max              77.015
trainer/Q1 Predictions Min            -174.154
trainer/Q2 Predictions Mean            -52.8384
trainer/Q2 Predictions Std              60.3974
trainer/Q2 Predictions Max              76.2354
trainer/Q2 Predictions Min            -174.542
trainer/Q Targets Mean                 -52.6554
trainer/Q Targets Std                   60.5784
trainer/Q Targets Max                   77.1784
trainer/Q Targets Min                 -173.697
trainer/Log Pis Mean                     0.99627
trainer/Log Pis Std                      1.44619
trainer/Log Pis Max                      4.95245
trainer/Log Pis Min                     -5.77256
trainer/policy/mean Mean                -0.527714
trainer/policy/mean Std                  0.527453
trainer/policy/mean Max                  0.860796
trainer/policy/mean Min                 -0.965851
trainer/policy/normal/std Mean           0.669502
trainer/policy/normal/std Std            0.112137
trainer/policy/normal/std Max            0.839043
trainer/policy/normal/std Min            0.514853
trainer/policy/normal/log_std Mean      -0.415596
trainer/policy/normal/log_std Std        0.170466
trainer/policy/normal/log_std Max       -0.175493
trainer/policy/normal/log_std Min       -0.663874
trainer/Alpha                            0.0737164
trainer/Alpha Loss                      -2.61726
exploration/num steps total         180000
exploration/num paths total            900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.678031
exploration/Rewards Std                  1.35294
exploration/Rewards Max                 -1.1294e-135
exploration/Rewards Min                 -6.11578
exploration/Returns Mean              -135.606
exploration/Returns Std                 99.8899
exploration/Returns Max                -12.5602
exploration/Returns Min               -336.624
exploration/Actions Mean                -0.476399
exploration/Actions Std                  0.615427
exploration/Actions Max                  0.994433
exploration/Actions Min                 -0.999127
exploration/Num Paths                   10
exploration/Average Returns           -135.606
evaluation/num steps total          429336
evaluation/num paths total            2136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.53967e-13
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   6.26843e-12
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.630842
evaluation/Actions Std                   0.319486
evaluation/Actions Max                  -0.311347
evaluation/Actions Min                  -0.950626
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0301306
time/evaluation sampling (s)            23.383
time/exploration sampling (s)            9.11942
time/logging (s)                         0.117368
time/sac training (s)                   39.2589
time/saving (s)                          0.6656
time/training (s)                        0.000163743
time/epoch (s)                          72.5745
time/total (s)                       10690.7
Epoch                                   88
----------------------------------  ----------------
2020-11-09 18:11:53.300345 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 89 finished
----------------------------------  -----------------
replay_buffer/size                  182000
trainer/num train calls              90000
trainer/QF1 Loss                        12.3629
trainer/QF2 Loss                        13.5296
trainer/Policy Loss                     48.9732
trainer/Q1 Predictions Mean            -48.8887
trainer/Q1 Predictions Std              62.9097
trainer/Q1 Predictions Max             109.473
trainer/Q1 Predictions Min            -173.01
trainer/Q2 Predictions Mean            -48.8432
trainer/Q2 Predictions Std              62.8317
trainer/Q2 Predictions Max             109.32
trainer/Q2 Predictions Min            -172.748
trainer/Q Targets Mean                 -49.3978
trainer/Q Targets Std                   63.4181
trainer/Q Targets Max                  108.988
trainer/Q Targets Min                 -172.349
trainer/Log Pis Mean                     0.757067
trainer/Log Pis Std                      1.17516
trainer/Log Pis Max                      3.58825
trainer/Log Pis Min                     -3.8623
trainer/policy/mean Mean                -0.438862
trainer/policy/mean Std                  0.58192
trainer/policy/mean Max                  0.888057
trainer/policy/mean Min                 -0.961498
trainer/policy/normal/std Mean           0.675844
trainer/policy/normal/std Std            0.104338
trainer/policy/normal/std Max            0.828244
trainer/policy/normal/std Min            0.52126
trainer/policy/normal/log_std Mean      -0.403942
trainer/policy/normal/log_std Std        0.15656
trainer/policy/normal/log_std Max       -0.188448
trainer/policy/normal/log_std Min       -0.651507
trainer/Alpha                            0.0715638
trainer/Alpha Loss                      -3.27782
exploration/num steps total         182000
exploration/num paths total            910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.770504
exploration/Rewards Std                  1.57774
exploration/Rewards Max                 -1.34151e-192
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -154.101
exploration/Returns Std                 72.971
exploration/Returns Max                -21.2006
exploration/Returns Min               -287.183
exploration/Actions Mean                -0.491858
exploration/Actions Std                  0.578659
exploration/Actions Max                  0.993168
exploration/Actions Min                 -0.998652
exploration/Num Paths                   10
exploration/Average Returns           -154.101
evaluation/num steps total          434160
evaluation/num paths total            2160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.515278
evaluation/Actions Std                   0.428259
evaluation/Actions Max                  -0.0806048
evaluation/Actions Min                  -0.950038
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0296385
time/evaluation sampling (s)            17.5397
time/exploration sampling (s)            7.73266
time/logging (s)                         0.225112
time/sac training (s)                   42.1678
time/saving (s)                          0.257221
time/training (s)                        0.000164886
time/epoch (s)                          67.9524
time/total (s)                       11081.3
Epoch                                   89
----------------------------------  -----------------
2020-11-09 18:17:25.543288 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 90 finished
----------------------------------  -----------------
replay_buffer/size                  184000
trainer/num train calls              91000
trainer/QF1 Loss                         9.94955
trainer/QF2 Loss                         9.87648
trainer/Policy Loss                     48.7512
trainer/Q1 Predictions Mean            -48.6416
trainer/Q1 Predictions Std              63.0846
trainer/Q1 Predictions Max             108.394
trainer/Q1 Predictions Min            -199.36
trainer/Q2 Predictions Mean            -48.7244
trainer/Q2 Predictions Std              63.1003
trainer/Q2 Predictions Max             108.428
trainer/Q2 Predictions Min            -199.633
trainer/Q Targets Mean                 -49.4344
trainer/Q Targets Std                   63.376
trainer/Q Targets Max                  107.859
trainer/Q Targets Min                 -198.427
trainer/Log Pis Mean                     0.904666
trainer/Log Pis Std                      1.68429
trainer/Log Pis Max                      5.18671
trainer/Log Pis Min                     -9.0772
trainer/policy/mean Mean                -0.599607
trainer/policy/mean Std                  0.468708
trainer/policy/mean Max                  0.85821
trainer/policy/mean Min                 -0.960886
trainer/policy/normal/std Mean           0.661808
trainer/policy/normal/std Std            0.0963173
trainer/policy/normal/std Max            0.816025
trainer/policy/normal/std Min            0.520113
trainer/policy/normal/log_std Mean      -0.423547
trainer/policy/normal/log_std Std        0.147285
trainer/policy/normal/log_std Max       -0.20331
trainer/policy/normal/log_std Min       -0.653709
trainer/Alpha                            0.0694898
trainer/Alpha Loss                      -2.92079
exploration/num steps total         184000
exploration/num paths total            920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.950856
exploration/Rewards Std                  1.42508
exploration/Rewards Max                 -2.50843e-188
exploration/Rewards Min                 -6.12573
exploration/Returns Mean              -190.171
exploration/Returns Std                125.876
exploration/Returns Max                -57.2828
exploration/Returns Min               -489.3
exploration/Actions Mean                -0.537858
exploration/Actions Std                  0.554766
exploration/Actions Max                  0.990597
exploration/Actions Min                 -0.999417
exploration/Num Paths                   10
exploration/Average Returns           -190.171
evaluation/num steps total          438984
evaluation/num paths total            2184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.698331
evaluation/Actions Std                   0.243509
evaluation/Actions Max                  -0.452253
evaluation/Actions Min                  -0.946294
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.031485
time/evaluation sampling (s)            17.8772
time/exploration sampling (s)            7.42011
time/logging (s)                         0.240144
time/sac training (s)                   45.4105
time/saving (s)                          0.545055
time/training (s)                        0.00017558
time/epoch (s)                          71.5247
time/total (s)                       11413.6
Epoch                                   90
----------------------------------  -----------------
2020-11-09 18:23:43.233266 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 91 finished
----------------------------------  -----------------
replay_buffer/size                  186000
trainer/num train calls              92000
trainer/QF1 Loss                        42.7826
trainer/QF2 Loss                        42.9922
trainer/Policy Loss                     56.866
trainer/Q1 Predictions Mean            -56.7894
trainer/Q1 Predictions Std              63.751
trainer/Q1 Predictions Max             107.653
trainer/Q1 Predictions Min            -203.617
trainer/Q2 Predictions Mean            -56.6506
trainer/Q2 Predictions Std              63.6123
trainer/Q2 Predictions Max             107.895
trainer/Q2 Predictions Min            -203.601
trainer/Q Targets Mean                 -56.4107
trainer/Q Targets Std                   64.368
trainer/Q Targets Max                  107.324
trainer/Q Targets Min                 -202.575
trainer/Log Pis Mean                     1.04368
trainer/Log Pis Std                      1.43772
trainer/Log Pis Max                      5.06152
trainer/Log Pis Min                     -4.59391
trainer/policy/mean Mean                -0.565636
trainer/policy/mean Std                  0.487852
trainer/policy/mean Max                  0.858267
trainer/policy/mean Min                 -0.972144
trainer/policy/normal/std Mean           0.661396
trainer/policy/normal/std Std            0.10242
trainer/policy/normal/std Max            0.819557
trainer/policy/normal/std Min            0.496603
trainer/policy/normal/log_std Mean      -0.425668
trainer/policy/normal/log_std Std        0.157438
trainer/policy/normal/log_std Max       -0.198991
trainer/policy/normal/log_std Min       -0.699964
trainer/Alpha                            0.0674842
trainer/Alpha Loss                      -2.57811
exploration/num steps total         186000
exploration/num paths total            930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.990413
exploration/Rewards Std                  1.48165
exploration/Rewards Max                 -6.98746e-138
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -198.083
exploration/Returns Std                 98.8787
exploration/Returns Max                -77.5783
exploration/Returns Min               -384.584
exploration/Actions Mean                -0.640692
exploration/Actions Std                  0.464979
exploration/Actions Max                  0.978055
exploration/Actions Min                 -0.998703
exploration/Num Paths                   10
exploration/Average Returns           -198.083
evaluation/num steps total          443808
evaluation/num paths total            2208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.660449
evaluation/Actions Std                   0.285426
evaluation/Actions Max                  -0.363235
evaluation/Actions Min                  -0.952118
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0541256
time/evaluation sampling (s)            24.5454
time/exploration sampling (s)            9.96197
time/logging (s)                         0.170923
time/sac training (s)                   42.1211
time/saving (s)                          0.30895
time/training (s)                        0.000136604
time/epoch (s)                          77.1626
time/total (s)                       11791.1
Epoch                                   91
----------------------------------  -----------------
2020-11-09 18:30:00.809473 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 92 finished
----------------------------------  ----------------
replay_buffer/size                  188000
trainer/num train calls              93000
trainer/QF1 Loss                       109.392
trainer/QF2 Loss                       109.838
trainer/Policy Loss                     52.9605
trainer/Q1 Predictions Mean            -52.7528
trainer/Q1 Predictions Std              61.4671
trainer/Q1 Predictions Max              61.1384
trainer/Q1 Predictions Min            -173.019
trainer/Q2 Predictions Mean            -52.8972
trainer/Q2 Predictions Std              61.5404
trainer/Q2 Predictions Max              61.1362
trainer/Q2 Predictions Min            -172.636
trainer/Q Targets Mean                 -52.4158
trainer/Q Targets Std                   62.3235
trainer/Q Targets Max                   61.2624
trainer/Q Targets Min                 -172.087
trainer/Log Pis Mean                     0.897758
trainer/Log Pis Std                      1.46874
trainer/Log Pis Max                      3.92895
trainer/Log Pis Min                     -8.89301
trainer/policy/mean Mean                -0.600493
trainer/policy/mean Std                  0.454035
trainer/policy/mean Max                  0.856607
trainer/policy/mean Min                 -0.967217
trainer/policy/normal/std Mean           0.659446
trainer/policy/normal/std Std            0.0998208
trainer/policy/normal/std Max            0.806776
trainer/policy/normal/std Min            0.510736
trainer/policy/normal/log_std Mean      -0.428085
trainer/policy/normal/log_std Std        0.153997
trainer/policy/normal/log_std Max       -0.214709
trainer/policy/normal/log_std Min       -0.671902
trainer/Alpha                            0.0656248
trainer/Alpha Loss                      -3.00229
exploration/num steps total         188000
exploration/num paths total            940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.794655
exploration/Rewards Std                  1.44357
exploration/Rewards Max                 -2.5672e-206
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -158.931
exploration/Returns Std                 66.6945
exploration/Returns Max                -72.6652
exploration/Returns Min               -273.156
exploration/Actions Mean                -0.535883
exploration/Actions Std                  0.569276
exploration/Actions Max                  0.988672
exploration/Actions Min                 -0.99902
exploration/Num Paths                   10
exploration/Average Returns           -158.931
evaluation/num steps total          448632
evaluation/num paths total            2232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.685503
evaluation/Actions Std                   0.264912
evaluation/Actions Max                  -0.417245
evaluation/Actions Min                  -0.952934
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.049995
time/evaluation sampling (s)            18.2462
time/exploration sampling (s)            9.18828
time/logging (s)                         0.301862
time/sac training (s)                   52.0461
time/saving (s)                          0.533843
time/training (s)                        0.00073359
time/epoch (s)                          80.3671
time/total (s)                       12168.8
Epoch                                   92
----------------------------------  ----------------
2020-11-09 18:35:04.075932 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 93 finished
----------------------------------  ----------------
replay_buffer/size                  190000
trainer/num train calls              94000
trainer/QF1 Loss                        18.4595
trainer/QF2 Loss                        17.8073
trainer/Policy Loss                     56.302
trainer/Q1 Predictions Mean            -56.2297
trainer/Q1 Predictions Std              62.8534
trainer/Q1 Predictions Max             107.418
trainer/Q1 Predictions Min            -174.471
trainer/Q2 Predictions Mean            -56.2178
trainer/Q2 Predictions Std              62.8046
trainer/Q2 Predictions Max             107.485
trainer/Q2 Predictions Min            -179.238
trainer/Q Targets Mean                 -56.6608
trainer/Q Targets Std                   63.3598
trainer/Q Targets Max                  106.927
trainer/Q Targets Min                 -178.708
trainer/Log Pis Mean                     1.16355
trainer/Log Pis Std                      1.47215
trainer/Log Pis Max                      6.06026
trainer/Log Pis Min                     -4.10608
trainer/policy/mean Mean                -0.572698
trainer/policy/mean Std                  0.490537
trainer/policy/mean Max                  0.776366
trainer/policy/mean Min                 -0.994328
trainer/policy/normal/std Mean           0.645802
trainer/policy/normal/std Std            0.0917393
trainer/policy/normal/std Max            0.787472
trainer/policy/normal/std Min            0.404922
trainer/policy/normal/log_std Mean      -0.447566
trainer/policy/normal/log_std Std        0.144279
trainer/policy/normal/log_std Max       -0.238927
trainer/policy/normal/log_std Min       -0.90406
trainer/Alpha                            0.0637671
trainer/Alpha Loss                      -2.30235
exploration/num steps total         190000
exploration/num paths total            950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.777871
exploration/Rewards Std                  1.58104
exploration/Rewards Max                 -2.78303e-88
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -155.574
exploration/Returns Std                 85.0237
exploration/Returns Max                -22.5869
exploration/Returns Min               -266.199
exploration/Actions Mean                -0.624034
exploration/Actions Std                  0.496163
exploration/Actions Max                  0.991344
exploration/Actions Min                 -0.999495
exploration/Num Paths                   10
exploration/Average Returns           -155.574
evaluation/num steps total          453456
evaluation/num paths total            2256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.49303e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   3.24887e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.660893
evaluation/Actions Std                   0.291023
evaluation/Actions Max                  -0.369816
evaluation/Actions Min                  -0.952438
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0588383
time/evaluation sampling (s)            23.9494
time/exploration sampling (s)            9.00892
time/logging (s)                         0.119786
time/sac training (s)                   39.0537
time/saving (s)                          0.970478
time/training (s)                        0.000130076
time/epoch (s)                          73.1613
time/total (s)                       12471.9
Epoch                                   93
----------------------------------  ----------------
2020-11-09 18:40:31.374781 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 94 finished
----------------------------------  ----------------
replay_buffer/size                  192000
trainer/num train calls              95000
trainer/QF1 Loss                        36.3169
trainer/QF2 Loss                        35.8074
trainer/Policy Loss                     55.4617
trainer/Q1 Predictions Mean            -55.2858
trainer/Q1 Predictions Std              63.91
trainer/Q1 Predictions Max             107.848
trainer/Q1 Predictions Min            -228.596
trainer/Q2 Predictions Mean            -55.2929
trainer/Q2 Predictions Std              63.9358
trainer/Q2 Predictions Max             107.946
trainer/Q2 Predictions Min            -228.811
trainer/Q Targets Mean                 -55.4401
trainer/Q Targets Std                   64.5218
trainer/Q Targets Max                  107.077
trainer/Q Targets Min                 -227.738
trainer/Log Pis Mean                     0.837249
trainer/Log Pis Std                      1.42987
trainer/Log Pis Max                      3.49558
trainer/Log Pis Min                     -4.27289
trainer/policy/mean Mean                -0.541621
trainer/policy/mean Std                  0.522213
trainer/policy/mean Max                  0.856574
trainer/policy/mean Min                 -0.966671
trainer/policy/normal/std Mean           0.659838
trainer/policy/normal/std Std            0.101596
trainer/policy/normal/std Max            0.80408
trainer/policy/normal/std Min            0.51254
trainer/policy/normal/log_std Mean      -0.4278
trainer/policy/normal/log_std Std        0.155694
trainer/policy/normal/log_std Max       -0.218057
trainer/policy/normal/log_std Min       -0.668376
trainer/Alpha                            0.0619433
trainer/Alpha Loss                      -3.23423
exploration/num steps total         192000
exploration/num paths total            960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.957801
exploration/Rewards Std                  1.60083
exploration/Rewards Max                 -6.72777e-87
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.56
exploration/Returns Std                 92.2198
exploration/Returns Max                -92.0737
exploration/Returns Min               -353.202
exploration/Actions Mean                -0.520665
exploration/Actions Std                  0.572988
exploration/Actions Max                  0.997216
exploration/Actions Min                 -0.998955
exploration/Num Paths                   10
exploration/Average Returns           -191.56
evaluation/num steps total          458280
evaluation/num paths total            2280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.602111
evaluation/Actions Std                   0.344954
evaluation/Actions Max                  -0.253821
evaluation/Actions Min                  -0.94703
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0374776
time/evaluation sampling (s)            24.9344
time/exploration sampling (s)           15.3106
time/logging (s)                         0.188256
time/sac training (s)                   36.0335
time/saving (s)                          0.170809
time/training (s)                        0.000139057
time/epoch (s)                          76.6752
time/total (s)                       12799.2
Epoch                                   94
----------------------------------  ----------------
2020-11-09 18:45:45.794554 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 95 finished
----------------------------------  ----------------
replay_buffer/size                  194000
trainer/num train calls              96000
trainer/QF1 Loss                        44.5782
trainer/QF2 Loss                        46.6914
trainer/Policy Loss                     49.6716
trainer/Q1 Predictions Mean            -49.5834
trainer/Q1 Predictions Std              62.9974
trainer/Q1 Predictions Max             108.681
trainer/Q1 Predictions Min            -205.119
trainer/Q2 Predictions Mean            -49.5954
trainer/Q2 Predictions Std              62.917
trainer/Q2 Predictions Max             108.72
trainer/Q2 Predictions Min            -205.163
trainer/Q Targets Mean                 -49.8582
trainer/Q Targets Std                   62.8212
trainer/Q Targets Max                  107.79
trainer/Q Targets Min                 -204.187
trainer/Log Pis Mean                     0.919671
trainer/Log Pis Std                      1.5825
trainer/Log Pis Max                      4.03802
trainer/Log Pis Min                     -5.7751
trainer/policy/mean Mean                -0.420909
trainer/policy/mean Std                  0.626885
trainer/policy/mean Max                  0.918292
trainer/policy/mean Min                 -0.974444
trainer/policy/normal/std Mean           0.646063
trainer/policy/normal/std Std            0.0959557
trainer/policy/normal/std Max            0.795781
trainer/policy/normal/std Min            0.49623
trainer/policy/normal/log_std Mean      -0.448019
trainer/policy/normal/log_std Std        0.149788
trainer/policy/normal/log_std Max       -0.228432
trainer/policy/normal/log_std Min       -0.700716
trainer/Alpha                            0.0601665
trainer/Alpha Loss                      -3.03642
exploration/num steps total         194000
exploration/num paths total            970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.709786
exploration/Rewards Std                  1.50023
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -141.957
exploration/Returns Std                 57.274
exploration/Returns Max                -68.4309
exploration/Returns Min               -256.168
exploration/Actions Mean                -0.501794
exploration/Actions Std                  0.59717
exploration/Actions Max                  0.996751
exploration/Actions Min                 -0.998854
exploration/Num Paths                   10
exploration/Average Returns           -141.957
evaluation/num steps total          463104
evaluation/num paths total            2304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.487366
evaluation/Actions Std                   0.466999
evaluation/Actions Max                  -0.0139314
evaluation/Actions Min                  -0.954746
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0389424
time/evaluation sampling (s)            21.1838
time/exploration sampling (s)           10.2371
time/logging (s)                         0.16366
time/sac training (s)                   38.4049
time/saving (s)                          0.340249
time/training (s)                        0.000135066
time/epoch (s)                          70.3687
time/total (s)                       13113.5
Epoch                                   95
----------------------------------  ----------------
2020-11-09 18:50:49.219100 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 96 finished
----------------------------------  ---------------
replay_buffer/size                  196000
trainer/num train calls              97000
trainer/QF1 Loss                        19.6779
trainer/QF2 Loss                        21.7329
trainer/Policy Loss                     53.6028
trainer/Q1 Predictions Mean            -53.5446
trainer/Q1 Predictions Std              63.2029
trainer/Q1 Predictions Max              70.8858
trainer/Q1 Predictions Min            -212.157
trainer/Q2 Predictions Mean            -53.3678
trainer/Q2 Predictions Std              63.126
trainer/Q2 Predictions Max              70.9287
trainer/Q2 Predictions Min            -212.666
trainer/Q Targets Mean                 -54.2475
trainer/Q Targets Std                   64.2699
trainer/Q Targets Max                   71.0615
trainer/Q Targets Min                 -211.598
trainer/Log Pis Mean                     1.11478
trainer/Log Pis Std                      1.26569
trainer/Log Pis Max                      4.38439
trainer/Log Pis Min                     -3.30766
trainer/policy/mean Mean                -0.476162
trainer/policy/mean Std                  0.576084
trainer/policy/mean Max                  0.864332
trainer/policy/mean Min                 -0.969146
trainer/policy/normal/std Mean           0.645116
trainer/policy/normal/std Std            0.0903088
trainer/policy/normal/std Max            0.789506
trainer/policy/normal/std Min            0.512641
trainer/policy/normal/log_std Mean      -0.448213
trainer/policy/normal/log_std Std        0.140893
trainer/policy/normal/log_std Max       -0.236347
trainer/policy/normal/log_std Min       -0.668179
trainer/Alpha                            0.0584724
trainer/Alpha Loss                      -2.51333
exploration/num steps total         196000
exploration/num paths total            980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.712266
exploration/Rewards Std                  1.49292
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -142.453
exploration/Returns Std                 60.4919
exploration/Returns Max                -45.3427
exploration/Returns Min               -238.426
exploration/Actions Mean                -0.380349
exploration/Actions Std                  0.692045
exploration/Actions Max                  0.994909
exploration/Actions Min                 -0.998491
exploration/Num Paths                   10
exploration/Average Returns           -142.453
evaluation/num steps total          467928
evaluation/num paths total            2328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.566791
evaluation/Actions Std                   0.386389
evaluation/Actions Max                  -0.144425
evaluation/Actions Min                  -0.953367
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0300414
time/evaluation sampling (s)            21.1648
time/exploration sampling (s)            8.68492
time/logging (s)                         0.110971
time/sac training (s)                   38.341
time/saving (s)                          0.368244
time/training (s)                        0.00014483
time/epoch (s)                          68.7001
time/total (s)                       13416.9
Epoch                                   96
----------------------------------  ---------------
2020-11-09 18:56:12.639383 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 97 finished
----------------------------------  ----------------
replay_buffer/size                  198000
trainer/num train calls              98000
trainer/QF1 Loss                         4.89686
trainer/QF2 Loss                         5.11224
trainer/Policy Loss                     55.0097
trainer/Q1 Predictions Mean            -54.8674
trainer/Q1 Predictions Std              64.4167
trainer/Q1 Predictions Max              90.5302
trainer/Q1 Predictions Min            -200.11
trainer/Q2 Predictions Mean            -55.0216
trainer/Q2 Predictions Std              64.5151
trainer/Q2 Predictions Max              91.3753
trainer/Q2 Predictions Min            -200.508
trainer/Q Targets Mean                 -55.2791
trainer/Q Targets Std                   64.9295
trainer/Q Targets Max                   91.393
trainer/Q Targets Min                 -199.423
trainer/Log Pis Mean                     1.24353
trainer/Log Pis Std                      1.46212
trainer/Log Pis Max                      4.54578
trainer/Log Pis Min                     -3.12416
trainer/policy/mean Mean                -0.580874
trainer/policy/mean Std                  0.528709
trainer/policy/mean Max                  0.910742
trainer/policy/mean Min                 -0.972983
trainer/policy/normal/std Mean           0.63259
trainer/policy/normal/std Std            0.0866798
trainer/policy/normal/std Max            0.778214
trainer/policy/normal/std Min            0.502335
trainer/policy/normal/log_std Mean      -0.467466
trainer/policy/normal/log_std Std        0.138582
trainer/policy/normal/log_std Max       -0.250753
trainer/policy/normal/log_std Min       -0.688487
trainer/Alpha                            0.0568581
trainer/Alpha Loss                      -2.16895
exploration/num steps total         198000
exploration/num paths total            990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.860224
exploration/Rewards Std                  1.56348
exploration/Rewards Max                 -3.58415e-93
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -172.045
exploration/Returns Std                131.501
exploration/Returns Max                -26.5817
exploration/Returns Min               -436.572
exploration/Actions Mean                -0.516778
exploration/Actions Std                  0.638883
exploration/Actions Max                  0.995836
exploration/Actions Min                 -0.999644
exploration/Num Paths                   10
exploration/Average Returns           -172.045
evaluation/num steps total          472752
evaluation/num paths total            2352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.712735
evaluation/Actions Std                   0.243987
evaluation/Actions Max                  -0.415017
evaluation/Actions Min                  -0.956853
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0353269
time/evaluation sampling (s)            17.9019
time/exploration sampling (s)            8.52289
time/logging (s)                         0.210155
time/sac training (s)                   35.715
time/saving (s)                          0.484964
time/training (s)                        0.000177606
time/epoch (s)                          62.8705
time/total (s)                       13740.4
Epoch                                   97
----------------------------------  ----------------
2020-11-09 19:00:46.436726 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 98 finished
----------------------------------  -----------------
replay_buffer/size                  200000
trainer/num train calls              99000
trainer/QF1 Loss                        14.3184
trainer/QF2 Loss                        16.8614
trainer/Policy Loss                     48.6587
trainer/Q1 Predictions Mean            -48.5387
trainer/Q1 Predictions Std              63.4319
trainer/Q1 Predictions Max              61.7721
trainer/Q1 Predictions Min            -229.467
trainer/Q2 Predictions Mean            -48.5632
trainer/Q2 Predictions Std              63.4052
trainer/Q2 Predictions Max              61.8211
trainer/Q2 Predictions Min            -230.178
trainer/Q Targets Mean                 -48.581
trainer/Q Targets Std                   63.8463
trainer/Q Targets Max                   62.0672
trainer/Q Targets Min                 -229.032
trainer/Log Pis Mean                     1.02908
trainer/Log Pis Std                      1.43131
trainer/Log Pis Max                      4.56279
trainer/Log Pis Min                     -4.38804
trainer/policy/mean Mean                -0.521429
trainer/policy/mean Std                  0.556937
trainer/policy/mean Max                  0.893677
trainer/policy/mean Min                 -0.972762
trainer/policy/normal/std Mean           0.650432
trainer/policy/normal/std Std            0.0973159
trainer/policy/normal/std Max            0.805588
trainer/policy/normal/std Min            0.509098
trainer/policy/normal/log_std Mean      -0.441458
trainer/policy/normal/log_std Std        0.151024
trainer/policy/normal/log_std Max       -0.216183
trainer/policy/normal/log_std Min       -0.675116
trainer/Alpha                            0.0553219
trainer/Alpha Loss                      -2.81041
exploration/num steps total         200000
exploration/num paths total           1000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.600714
exploration/Rewards Std                  1.39207
exploration/Rewards Max                 -1.30797e-138
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -120.143
exploration/Returns Std                 45.5953
exploration/Returns Max                -58.9583
exploration/Returns Min               -214.777
exploration/Actions Mean                -0.51566
exploration/Actions Std                  0.609208
exploration/Actions Max                  0.991639
exploration/Actions Min                 -0.998971
exploration/Num Paths                   10
exploration/Average Returns           -120.143
evaluation/num steps total          477576
evaluation/num paths total            2376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.615787
evaluation/Actions Std                   0.339746
evaluation/Actions Max                  -0.272272
evaluation/Actions Min                  -0.95905
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0335517
time/evaluation sampling (s)            18.3107
time/exploration sampling (s)            7.07866
time/logging (s)                         0.186409
time/sac training (s)                   38.0703
time/saving (s)                          1.41783
time/training (s)                        0.000144152
time/epoch (s)                          65.0976
time/total (s)                       14014.1
Epoch                                   98
----------------------------------  -----------------
2020-11-09 19:05:31.589890 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 99 finished
----------------------------------  ----------------
replay_buffer/size                  202000
trainer/num train calls             100000
trainer/QF1 Loss                        62.3015
trainer/QF2 Loss                        63.4552
trainer/Policy Loss                     50.0987
trainer/Q1 Predictions Mean            -49.8703
trainer/Q1 Predictions Std              63.8964
trainer/Q1 Predictions Max              86.4581
trainer/Q1 Predictions Min            -230.13
trainer/Q2 Predictions Mean            -49.9712
trainer/Q2 Predictions Std              63.9289
trainer/Q2 Predictions Max              85.8438
trainer/Q2 Predictions Min            -230.881
trainer/Q Targets Mean                 -49.413
trainer/Q Targets Std                   64.7371
trainer/Q Targets Max                  104.355
trainer/Q Targets Min                 -229.786
trainer/Log Pis Mean                     1.24973
trainer/Log Pis Std                      1.4973
trainer/Log Pis Max                      4.09874
trainer/Log Pis Min                     -5.59547
trainer/policy/mean Mean                -0.544599
trainer/policy/mean Std                  0.568779
trainer/policy/mean Max                  0.908564
trainer/policy/mean Min                 -0.974089
trainer/policy/normal/std Mean           0.632178
trainer/policy/normal/std Std            0.0860245
trainer/policy/normal/std Max            0.777069
trainer/policy/normal/std Min            0.499152
trainer/policy/normal/log_std Mean      -0.46793
trainer/policy/normal/log_std Std        0.136994
trainer/policy/normal/log_std Max       -0.252226
trainer/policy/normal/log_std Min       -0.694845
trainer/Alpha                            0.053846
trainer/Alpha Loss                      -2.19202
exploration/num steps total         202000
exploration/num paths total           1010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.06151
exploration/Rewards Std                  1.51255
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -212.301
exploration/Returns Std                157.478
exploration/Returns Max                -26.4072
exploration/Returns Min               -520.88
exploration/Actions Mean                -0.611395
exploration/Actions Std                  0.507496
exploration/Actions Max                  0.99251
exploration/Actions Min                 -0.998771
exploration/Num Paths                   10
exploration/Average Returns           -212.301
evaluation/num steps total          482400
evaluation/num paths total            2400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78727
evaluation/Rewards Std                   0.72887
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1163.24
evaluation/Returns Std                 146.286
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.673604
evaluation/Actions Std                   0.282693
evaluation/Actions Max                  -0.384309
evaluation/Actions Min                  -0.962239
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.24
time/data storing (s)                    0.0250729
time/evaluation sampling (s)            17.918
time/exploration sampling (s)            7.00884
time/logging (s)                         0.182085
time/sac training (s)                   34.5149
time/saving (s)                          0.203557
time/training (s)                        0.000127216
time/epoch (s)                          59.8525
time/total (s)                       14299.2
Epoch                                   99
----------------------------------  ----------------
2020-11-09 19:10:30.752949 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 100 finished
----------------------------------  -----------------
replay_buffer/size                  204000
trainer/num train calls             101000
trainer/QF1 Loss                        75.3763
trainer/QF2 Loss                        77.1046
trainer/Policy Loss                     50.4934
trainer/Q1 Predictions Mean            -50.3687
trainer/Q1 Predictions Std              61.9858
trainer/Q1 Predictions Max              73.7047
trainer/Q1 Predictions Min            -179.378
trainer/Q2 Predictions Mean            -50.2663
trainer/Q2 Predictions Std              61.9216
trainer/Q2 Predictions Max              73.3886
trainer/Q2 Predictions Min            -178.459
trainer/Q Targets Mean                 -50.0818
trainer/Q Targets Std                   62.9283
trainer/Q Targets Max                   73.3478
trainer/Q Targets Min                 -178.452
trainer/Log Pis Mean                     1.07384
trainer/Log Pis Std                      1.637
trainer/Log Pis Max                      4.43931
trainer/Log Pis Min                     -6.13
trainer/policy/mean Mean                -0.580518
trainer/policy/mean Std                  0.520168
trainer/policy/mean Max                  0.847024
trainer/policy/mean Min                 -0.9755
trainer/policy/normal/std Mean           0.65266
trainer/policy/normal/std Std            0.0912797
trainer/policy/normal/std Max            0.801393
trainer/policy/normal/std Min            0.516526
trainer/policy/normal/log_std Mean      -0.436578
trainer/policy/normal/log_std Std        0.140856
trainer/policy/normal/log_std Max       -0.221404
trainer/policy/normal/log_std Min       -0.66063
trainer/Alpha                            0.0523478
trainer/Alpha Loss                      -2.73203
exploration/num steps total         204000
exploration/num paths total           1020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.937371
exploration/Rewards Std                  1.67608
exploration/Rewards Max                 -4.95548e-241
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -187.474
exploration/Returns Std                 74.3886
exploration/Returns Max                -84.2483
exploration/Returns Min               -320.838
exploration/Actions Mean                -0.643695
exploration/Actions Std                  0.531893
exploration/Actions Max                  0.997598
exploration/Actions Min                 -0.998934
exploration/Num Paths                   10
exploration/Average Returns           -187.474
evaluation/num steps total          487224
evaluation/num paths total            2424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8525
evaluation/Rewards Std                   0.739096
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1176.35
evaluation/Returns Std                 148.558
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.70064
evaluation/Actions Std                   0.256227
evaluation/Actions Max                  -0.442435
evaluation/Actions Min                  -0.959555
evaluation/Num Paths                    24
evaluation/Average Returns           -1176.35
time/data storing (s)                    0.0276525
time/evaluation sampling (s)            18.944
time/exploration sampling (s)            7.83962
time/logging (s)                         0.130346
time/sac training (s)                   35.5995
time/saving (s)                          0.678277
time/training (s)                        0.000151925
time/epoch (s)                          63.2196
time/total (s)                       14598.3
Epoch                                  100
----------------------------------  -----------------
2020-11-09 19:16:48.435286 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 101 finished
----------------------------------  -----------------
replay_buffer/size                  206000
trainer/num train calls             102000
trainer/QF1 Loss                        57.0126
trainer/QF2 Loss                        58.8892
trainer/Policy Loss                     50.6057
trainer/Q1 Predictions Mean            -50.3846
trainer/Q1 Predictions Std              65.2734
trainer/Q1 Predictions Max             106.645
trainer/Q1 Predictions Min            -184.403
trainer/Q2 Predictions Mean            -50.5137
trainer/Q2 Predictions Std              65.2944
trainer/Q2 Predictions Max             107.031
trainer/Q2 Predictions Min            -184.377
trainer/Q Targets Mean                 -50.5287
trainer/Q Targets Std                   65.8901
trainer/Q Targets Max                  105.998
trainer/Q Targets Min                 -191.764
trainer/Log Pis Mean                     1.40296
trainer/Log Pis Std                      1.33036
trainer/Log Pis Max                      4.92081
trainer/Log Pis Min                     -3.46788
trainer/policy/mean Mean                -0.494245
trainer/policy/mean Std                  0.613009
trainer/policy/mean Max                  0.898171
trainer/policy/mean Min                 -0.983965
trainer/policy/normal/std Mean           0.64301
trainer/policy/normal/std Std            0.103875
trainer/policy/normal/std Max            0.823092
trainer/policy/normal/std Min            0.478041
trainer/policy/normal/log_std Mean      -0.454706
trainer/policy/normal/log_std Std        0.162034
trainer/policy/normal/log_std Max       -0.194688
trainer/policy/normal/log_std Min       -0.73806
trainer/Alpha                            0.0508029
trainer/Alpha Loss                      -1.77907
exploration/num steps total         206000
exploration/num paths total           1030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.762694
exploration/Rewards Std                  1.45566
exploration/Rewards Max                 -6.41521e-133
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -152.539
exploration/Returns Std                 94.804
exploration/Returns Max                -27.2421
exploration/Returns Min               -348.619
exploration/Actions Mean                -0.466114
exploration/Actions Std                  0.659467
exploration/Actions Max                  0.997545
exploration/Actions Min                 -0.998948
exploration/Num Paths                   10
exploration/Average Returns           -152.539
evaluation/num steps total          492048
evaluation/num paths total            2448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.61115e-13
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   2.22635e-12
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.570828
evaluation/Actions Std                   0.390599
evaluation/Actions Max                  -0.180221
evaluation/Actions Min                  -0.961605
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0348612
time/evaluation sampling (s)            21.5717
time/exploration sampling (s)            9.28606
time/logging (s)                         0.341481
time/sac training (s)                   43.7724
time/saving (s)                          0.203417
time/training (s)                        0.000425509
time/epoch (s)                          75.2104
time/total (s)                       14976.1
Epoch                                  101
----------------------------------  -----------------
2020-11-09 19:23:16.486744 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 102 finished
----------------------------------  -----------------
replay_buffer/size                  208000
trainer/num train calls             103000
trainer/QF1 Loss                        13.2382
trainer/QF2 Loss                        13.5042
trainer/Policy Loss                     56.898
trainer/Q1 Predictions Mean            -56.7792
trainer/Q1 Predictions Std              66.7339
trainer/Q1 Predictions Max              63.0942
trainer/Q1 Predictions Min            -231.136
trainer/Q2 Predictions Mean            -56.651
trainer/Q2 Predictions Std              66.7809
trainer/Q2 Predictions Max              62.8461
trainer/Q2 Predictions Min            -232
trainer/Q Targets Mean                 -57.4362
trainer/Q Targets Std                   67.4567
trainer/Q Targets Max                   62.6167
trainer/Q Targets Min                 -231.184
trainer/Log Pis Mean                     1.06737
trainer/Log Pis Std                      1.48643
trainer/Log Pis Max                      4.08072
trainer/Log Pis Min                     -4.43855
trainer/policy/mean Mean                -0.285435
trainer/policy/mean Std                  0.722036
trainer/policy/mean Max                  0.940794
trainer/policy/mean Min                 -0.972325
trainer/policy/normal/std Mean           0.634676
trainer/policy/normal/std Std            0.0909167
trainer/policy/normal/std Max            0.792457
trainer/policy/normal/std Min            0.514169
trainer/policy/normal/log_std Mean      -0.464831
trainer/policy/normal/log_std Std        0.142477
trainer/policy/normal/log_std Max       -0.232617
trainer/policy/normal/log_std Min       -0.665204
trainer/Alpha                            0.0492923
trainer/Alpha Loss                      -2.80721
exploration/num steps total         208000
exploration/num paths total           1040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.970634
exploration/Rewards Std                  1.37376
exploration/Rewards Max                 -4.90437e-171
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -194.127
exploration/Returns Std                123.974
exploration/Returns Max                -39.3869
exploration/Returns Min               -390.524
exploration/Actions Mean                -0.378621
exploration/Actions Std                  0.729626
exploration/Actions Max                  0.996822
exploration/Actions Min                 -0.999661
exploration/Num Paths                   10
exploration/Average Returns           -194.127
evaluation/num steps total          496872
evaluation/num paths total            2472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.62403
evaluation/Rewards Std                   1.00917
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1130.43
evaluation/Returns Std                 202.843
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.275741
evaluation/Actions Std                   0.683662
evaluation/Actions Max                   0.592439
evaluation/Actions Min                  -0.957598
evaluation/Num Paths                    24
evaluation/Average Returns           -1130.43
time/data storing (s)                    0.0357132
time/evaluation sampling (s)            23.4917
time/exploration sampling (s)            9.70591
time/logging (s)                         0.109321
time/sac training (s)                   38.9764
time/saving (s)                          0.112867
time/training (s)                        0.000225731
time/epoch (s)                          72.4321
time/total (s)                       15363.9
Epoch                                  102
----------------------------------  -----------------
2020-11-09 19:28:57.448413 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 103 finished
----------------------------------  -----------------
replay_buffer/size                  210000
trainer/num train calls             104000
trainer/QF1 Loss                        23.2571
trainer/QF2 Loss                        21.7994
trainer/Policy Loss                     50.7136
trainer/Q1 Predictions Mean            -50.5394
trainer/Q1 Predictions Std              64.3927
trainer/Q1 Predictions Max             106.256
trainer/Q1 Predictions Min            -181.209
trainer/Q2 Predictions Mean            -50.6328
trainer/Q2 Predictions Std              64.4592
trainer/Q2 Predictions Max             106.406
trainer/Q2 Predictions Min            -182.695
trainer/Q Targets Mean                 -50.7147
trainer/Q Targets Std                   64.954
trainer/Q Targets Max                  105.232
trainer/Q Targets Min                 -181.668
trainer/Log Pis Mean                     1.35798
trainer/Log Pis Std                      1.35414
trainer/Log Pis Max                      4.68236
trainer/Log Pis Min                     -3.39105
trainer/policy/mean Mean                -0.429038
trainer/policy/mean Std                  0.645434
trainer/policy/mean Max                  0.934144
trainer/policy/mean Min                 -0.975797
trainer/policy/normal/std Mean           0.635516
trainer/policy/normal/std Std            0.0898261
trainer/policy/normal/std Max            0.80852
trainer/policy/normal/std Min            0.496788
trainer/policy/normal/log_std Mean      -0.463301
trainer/policy/normal/log_std Std        0.141238
trainer/policy/normal/log_std Max       -0.21255
trainer/policy/normal/log_std Min       -0.699592
trainer/Alpha                            0.0479403
trainer/Alpha Loss                      -1.95033
exploration/num steps total         210000
exploration/num paths total           1050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.64841
exploration/Rewards Std                  1.21593
exploration/Rewards Max                 -1.88127e-144
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -129.682
exploration/Returns Std                108.457
exploration/Returns Max                -21.7041
exploration/Returns Min               -326.175
exploration/Actions Mean                -0.537971
exploration/Actions Std                  0.56662
exploration/Actions Max                  0.988873
exploration/Actions Min                 -0.999105
exploration/Num Paths                   10
exploration/Average Returns           -129.682
evaluation/num steps total          501696
evaluation/num paths total            2496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74108
evaluation/Rewards Std                   0.884392
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.96
evaluation/Returns Std                 177.763
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.480962
evaluation/Actions Std                   0.47622
evaluation/Actions Max                  -0.00365569
evaluation/Actions Min                  -0.957751
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.96
time/data storing (s)                    0.0345022
time/evaluation sampling (s)            17.862
time/exploration sampling (s)            7.32751
time/logging (s)                         0.185812
time/sac training (s)                   38.1689
time/saving (s)                          0.298723
time/training (s)                        0.000136439
time/epoch (s)                          63.8776
time/total (s)                       15704.9
Epoch                                  103
----------------------------------  -----------------
2020-11-09 19:34:22.657541 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 104 finished
----------------------------------  -----------------
replay_buffer/size                  212000
trainer/num train calls             105000
trainer/QF1 Loss                        34.5199
trainer/QF2 Loss                        34.5794
trainer/Policy Loss                     56.0756
trainer/Q1 Predictions Mean            -56.0339
trainer/Q1 Predictions Std              64.7244
trainer/Q1 Predictions Max             105.631
trainer/Q1 Predictions Min            -232.73
trainer/Q2 Predictions Mean            -55.9021
trainer/Q2 Predictions Std              64.6631
trainer/Q2 Predictions Max             105.907
trainer/Q2 Predictions Min            -233.562
trainer/Q Targets Mean                 -55.8702
trainer/Q Targets Std                   65.1919
trainer/Q Targets Max                  105.132
trainer/Q Targets Min                 -232.31
trainer/Log Pis Mean                     1.52356
trainer/Log Pis Std                      1.80356
trainer/Log Pis Max                      5.28759
trainer/Log Pis Min                     -4.57737
trainer/policy/mean Mean                -0.595034
trainer/policy/mean Std                  0.559589
trainer/policy/mean Max                  0.916761
trainer/policy/mean Min                 -0.97903
trainer/policy/normal/std Mean           0.628229
trainer/policy/normal/std Std            0.0944752
trainer/policy/normal/std Max            0.78319
trainer/policy/normal/std Min            0.481518
trainer/policy/normal/log_std Mean      -0.476251
trainer/policy/normal/log_std Std        0.151234
trainer/policy/normal/log_std Max       -0.244381
trainer/policy/normal/log_std Min       -0.730811
trainer/Alpha                            0.0466342
trainer/Alpha Loss                      -1.46049
exploration/num steps total         212000
exploration/num paths total           1060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.620215
exploration/Rewards Std                  1.2924
exploration/Rewards Max                 -1.43508e-171
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -124.043
exploration/Returns Std                 98.5485
exploration/Returns Max                -31.8431
exploration/Returns Min               -384.625
exploration/Actions Mean                -0.560663
exploration/Actions Std                  0.591265
exploration/Actions Max                  0.994646
exploration/Actions Min                 -0.999056
exploration/Num Paths                   10
exploration/Average Returns           -124.043
evaluation/num steps total          506520
evaluation/num paths total            2520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.724537
evaluation/Actions Std                   0.240361
evaluation/Actions Max                  -0.446244
evaluation/Actions Min                  -0.965092
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0238282
time/evaluation sampling (s)            15.6432
time/exploration sampling (s)            6.36078
time/logging (s)                         0.117005
time/sac training (s)                   41.944
time/saving (s)                          0.194528
time/training (s)                        0.00015839
time/epoch (s)                          64.2835
time/total (s)                       16030
Epoch                                  104
----------------------------------  -----------------
2020-11-09 19:41:16.958137 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 105 finished
----------------------------------  -----------------
replay_buffer/size                  214000
trainer/num train calls             106000
trainer/QF1 Loss                         4.33669
trainer/QF2 Loss                         5.04878
trainer/Policy Loss                     54.5614
trainer/Q1 Predictions Mean            -54.4179
trainer/Q1 Predictions Std              67.0179
trainer/Q1 Predictions Max              63.3028
trainer/Q1 Predictions Min            -210.102
trainer/Q2 Predictions Mean            -54.3804
trainer/Q2 Predictions Std              66.9109
trainer/Q2 Predictions Max              63.4604
trainer/Q2 Predictions Min            -210.174
trainer/Q Targets Mean                 -54.9767
trainer/Q Targets Std                   67.6521
trainer/Q Targets Max                   63.343
trainer/Q Targets Min                 -209.225
trainer/Log Pis Mean                     1.52677
trainer/Log Pis Std                      1.63133
trainer/Log Pis Max                      5.30564
trainer/Log Pis Min                     -4.30179
trainer/policy/mean Mean                -0.620519
trainer/policy/mean Std                  0.525627
trainer/policy/mean Max                  0.871769
trainer/policy/mean Min                 -0.975474
trainer/policy/normal/std Mean           0.613297
trainer/policy/normal/std Std            0.0778847
trainer/policy/normal/std Max            0.764543
trainer/policy/normal/std Min            0.488516
trainer/policy/normal/log_std Mean      -0.496997
trainer/policy/normal/log_std Std        0.127289
trainer/policy/normal/log_std Max       -0.268476
trainer/policy/normal/log_std Min       -0.716383
trainer/Alpha                            0.0456167
trainer/Alpha Loss                      -1.4611
exploration/num steps total         214000
exploration/num paths total           1070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.808099
exploration/Rewards Std                  1.40972
exploration/Rewards Max                 -5.66689e-238
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -161.62
exploration/Returns Std                126.093
exploration/Returns Max                -19.3665
exploration/Returns Min               -493.983
exploration/Actions Mean                -0.669755
exploration/Actions Std                  0.450816
exploration/Actions Max                  0.963927
exploration/Actions Min                 -0.999152
exploration/Num Paths                   10
exploration/Average Returns           -161.62
evaluation/num steps total          511344
evaluation/num paths total            2544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.761
evaluation/Actions Std                   0.20593
evaluation/Actions Max                  -0.547361
evaluation/Actions Min                  -0.967118
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0262213
time/evaluation sampling (s)            21.4015
time/exploration sampling (s)            8.52044
time/logging (s)                         0.236831
time/sac training (s)                   41.7316
time/saving (s)                          0.200858
time/training (s)                        0.000145094
time/epoch (s)                          72.1176
time/total (s)                       16444.4
Epoch                                  105
----------------------------------  -----------------
2020-11-09 19:49:09.183551 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 106 finished
----------------------------------  -----------------
replay_buffer/size                  216000
trainer/num train calls             107000
trainer/QF1 Loss                        29.7223
trainer/QF2 Loss                        28.9878
trainer/Policy Loss                     43.7756
trainer/Q1 Predictions Mean            -43.5754
trainer/Q1 Predictions Std              63.6953
trainer/Q1 Predictions Max              84.332
trainer/Q1 Predictions Min            -215.034
trainer/Q2 Predictions Mean            -43.6827
trainer/Q2 Predictions Std              63.8097
trainer/Q2 Predictions Max              84.4341
trainer/Q2 Predictions Min            -215.599
trainer/Q Targets Mean                 -43.9646
trainer/Q Targets Std                   64.3479
trainer/Q Targets Max                   83.6971
trainer/Q Targets Min                 -214.607
trainer/Log Pis Mean                     1.4416
trainer/Log Pis Std                      1.65911
trainer/Log Pis Max                      4.97493
trainer/Log Pis Min                     -5.75853
trainer/policy/mean Mean                -0.54774
trainer/policy/mean Std                  0.586744
trainer/policy/mean Max                  0.899017
trainer/policy/mean Min                 -0.974632
trainer/policy/normal/std Mean           0.615895
trainer/policy/normal/std Std            0.0759334
trainer/policy/normal/std Max            0.76492
trainer/policy/normal/std Min            0.491965
trainer/policy/normal/log_std Mean      -0.492266
trainer/policy/normal/log_std Std        0.123101
trainer/policy/normal/log_std Max       -0.267983
trainer/policy/normal/log_std Min       -0.709348
trainer/Alpha                            0.0443616
trainer/Alpha Loss                      -1.73964
exploration/num steps total         216000
exploration/num paths total           1080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.04283
exploration/Rewards Std                  1.67196
exploration/Rewards Max                 -5.99605e-104
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -208.566
exploration/Returns Std                100.134
exploration/Returns Max                -76.5292
exploration/Returns Min               -432.146
exploration/Actions Mean                -0.420501
exploration/Actions Std                  0.687388
exploration/Actions Max                  0.996218
exploration/Actions Min                 -0.999223
exploration/Num Paths                   10
exploration/Average Returns           -208.566
evaluation/num steps total          516168
evaluation/num paths total            2568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.70864
evaluation/Rewards Std                   1.30793
evaluation/Rewards Max                  -2.54314e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1147.44
evaluation/Returns Std                 262.71
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.659694
evaluation/Actions Std                   0.309476
evaluation/Actions Max                  -0.333523
evaluation/Actions Min                  -0.969779
evaluation/Num Paths                    24
evaluation/Average Returns           -1147.44
time/data storing (s)                    0.029791
time/evaluation sampling (s)            20.9888
time/exploration sampling (s)            8.69906
time/logging (s)                         0.332074
time/sac training (s)                   38.3602
time/saving (s)                          0.136215
time/training (s)                        0.000136132
time/epoch (s)                          68.5463
time/total (s)                       16916.7
Epoch                                  106
----------------------------------  -----------------
2020-11-09 21:46:56.021601 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 107 finished
----------------------------------  -----------------
replay_buffer/size                  218000
trainer/num train calls             108000
trainer/QF1 Loss                        38.3268
trainer/QF2 Loss                        39.4635
trainer/Policy Loss                     51.1537
trainer/Q1 Predictions Mean            -51.0915
trainer/Q1 Predictions Std              64.5573
trainer/Q1 Predictions Max              75.8371
trainer/Q1 Predictions Min            -201.416
trainer/Q2 Predictions Mean            -51.0398
trainer/Q2 Predictions Std              64.56
trainer/Q2 Predictions Max              76.474
trainer/Q2 Predictions Min            -201.851
trainer/Q Targets Mean                 -51.3478
trainer/Q Targets Std                   65.1113
trainer/Q Targets Max                   76.068
trainer/Q Targets Min                 -200.748
trainer/Log Pis Mean                     1.29074
trainer/Log Pis Std                      1.56025
trainer/Log Pis Max                      4.09729
trainer/Log Pis Min                     -8.06292
trainer/policy/mean Mean                -0.45846
trainer/policy/mean Std                  0.633818
trainer/policy/mean Max                  0.918784
trainer/policy/mean Min                 -0.975134
trainer/policy/normal/std Mean           0.629563
trainer/policy/normal/std Std            0.0859355
trainer/policy/normal/std Max            0.78938
trainer/policy/normal/std Min            0.496993
trainer/policy/normal/log_std Mean      -0.472054
trainer/policy/normal/log_std Std        0.13655
trainer/policy/normal/log_std Max       -0.236507
trainer/policy/normal/log_std Min       -0.69918
trainer/Alpha                            0.0432038
trainer/Alpha Loss                      -2.22838
exploration/num steps total         218000
exploration/num paths total           1090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.08964
exploration/Rewards Std                  1.46282
exploration/Rewards Max                 -8.71593e-106
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -217.928
exploration/Returns Std                127.334
exploration/Returns Max                -74.3042
exploration/Returns Min               -493.052
exploration/Actions Mean                -0.460517
exploration/Actions Std                  0.665066
exploration/Actions Max                  0.991935
exploration/Actions Min                 -0.99933
exploration/Num Paths                   10
exploration/Average Returns           -217.928
evaluation/num steps total          520992
evaluation/num paths total            2592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96392
evaluation/Rewards Std                   0.534365
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.75
evaluation/Returns Std                 107.407
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.567609
evaluation/Actions Std                   0.394509
evaluation/Actions Max                  -0.164928
evaluation/Actions Min                  -0.963669
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.75
time/data storing (s)                    0.0375413
time/evaluation sampling (s)            20.5738
time/exploration sampling (s)            7.60435
time/logging (s)                         0.0969638
time/sac training (s)                   45.1269
time/saving (s)                          0.167028
time/training (s)                        0.000158135
time/epoch (s)                          73.6068
time/total (s)                       23982.9
Epoch                                  107
----------------------------------  -----------------
2020-11-09 21:48:41.936979 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 108 finished
----------------------------------  -----------------
replay_buffer/size                  220000
trainer/num train calls             109000
trainer/QF1 Loss                       183.086
trainer/QF2 Loss                       181.45
trainer/Policy Loss                     54.5863
trainer/Q1 Predictions Mean            -54.4958
trainer/Q1 Predictions Std              66.8973
trainer/Q1 Predictions Max              66.786
trainer/Q1 Predictions Min            -203.954
trainer/Q2 Predictions Mean            -54.4307
trainer/Q2 Predictions Std              66.7639
trainer/Q2 Predictions Max              66.5661
trainer/Q2 Predictions Min            -202.463
trainer/Q Targets Mean                 -54.0163
trainer/Q Targets Std                   67.061
trainer/Q Targets Max                   66.3642
trainer/Q Targets Min                 -204.12
trainer/Log Pis Mean                     1.63927
trainer/Log Pis Std                      1.5315
trainer/Log Pis Max                      4.77786
trainer/Log Pis Min                     -7.43907
trainer/policy/mean Mean                -0.414487
trainer/policy/mean Std                  0.674755
trainer/policy/mean Max                  0.936679
trainer/policy/mean Min                 -0.978872
trainer/policy/normal/std Mean           0.606763
trainer/policy/normal/std Std            0.0792838
trainer/policy/normal/std Max            0.759307
trainer/policy/normal/std Min            0.476527
trainer/policy/normal/log_std Mean      -0.508109
trainer/policy/normal/log_std Std        0.130121
trainer/policy/normal/log_std Max       -0.275349
trainer/policy/normal/log_std Min       -0.741232
trainer/Alpha                            0.0419309
trainer/Alpha Loss                      -1.14415
exploration/num steps total         220000
exploration/num paths total           1100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.607115
exploration/Rewards Std                  1.40752
exploration/Rewards Max                 -8.01748e-243
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -121.423
exploration/Returns Std                 64.8118
exploration/Returns Max                -38.0542
exploration/Returns Min               -247.624
exploration/Actions Mean                -0.494813
exploration/Actions Std                  0.663418
exploration/Actions Max                  0.99747
exploration/Actions Min                 -0.999162
exploration/Num Paths                   10
exploration/Average Returns           -121.423
evaluation/num steps total          525816
evaluation/num paths total            2616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67501
evaluation/Rewards Std                   0.879357
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.68
evaluation/Returns Std                 176.393
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.452277
evaluation/Actions Std                   0.516868
evaluation/Actions Max                   0.387039
evaluation/Actions Min                  -0.968345
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.68
time/data storing (s)                    0.0463487
time/evaluation sampling (s)            20.1864
time/exploration sampling (s)            6.83713
time/logging (s)                         0.0460568
time/sac training (s)                   39.5129
time/saving (s)                          0.0765739
time/training (s)                        0.000101272
time/epoch (s)                          66.7055
time/total (s)                       24088.7
Epoch                                  108
----------------------------------  -----------------
2020-11-09 21:49:39.654044 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 109 finished
----------------------------------  -----------------
replay_buffer/size                  222000
trainer/num train calls             110000
trainer/QF1 Loss                        13.3397
trainer/QF2 Loss                        14.0322
trainer/Policy Loss                     53.0407
trainer/Q1 Predictions Mean            -52.9689
trainer/Q1 Predictions Std              70.6554
trainer/Q1 Predictions Max              72.0787
trainer/Q1 Predictions Min            -230.398
trainer/Q2 Predictions Mean            -52.9712
trainer/Q2 Predictions Std              70.7041
trainer/Q2 Predictions Max              72.1314
trainer/Q2 Predictions Min            -230.49
trainer/Q Targets Mean                 -53.5648
trainer/Q Targets Std                   71.3512
trainer/Q Targets Max                   72.1069
trainer/Q Targets Min                 -229.798
trainer/Log Pis Mean                     1.6139
trainer/Log Pis Std                      1.70199
trainer/Log Pis Max                      5.64817
trainer/Log Pis Min                     -4.48421
trainer/policy/mean Mean                -0.47588
trainer/policy/mean Std                  0.655101
trainer/policy/mean Max                  0.951857
trainer/policy/mean Min                 -0.987732
trainer/policy/normal/std Mean           0.615088
trainer/policy/normal/std Std            0.0859896
trainer/policy/normal/std Max            0.782633
trainer/policy/normal/std Min            0.460967
trainer/policy/normal/log_std Mean      -0.495747
trainer/policy/normal/log_std Std        0.13961
trainer/policy/normal/log_std Max       -0.245091
trainer/policy/normal/log_std Min       -0.774429
trainer/Alpha                            0.0408974
trainer/Alpha Loss                      -1.23423
exploration/num steps total         222000
exploration/num paths total           1110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.816757
exploration/Rewards Std                  1.55016
exploration/Rewards Max                 -1.70047e-140
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -163.351
exploration/Returns Std                102.934
exploration/Returns Max                -68.9514
exploration/Returns Min               -453.613
exploration/Actions Mean                -0.451599
exploration/Actions Std                  0.693678
exploration/Actions Max                  0.996187
exploration/Actions Min                 -0.999542
exploration/Num Paths                   10
exploration/Average Returns           -163.351
evaluation/num steps total          530640
evaluation/num paths total            2640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.55448
evaluation/Actions Std                   0.411588
evaluation/Actions Max                  -0.104611
evaluation/Actions Min                  -0.967917
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0196201
time/evaluation sampling (s)            13.6638
time/exploration sampling (s)            5.10757
time/logging (s)                         0.0191459
time/sac training (s)                   31.6552
time/saving (s)                          0.0181957
time/training (s)                        0.000117336
time/epoch (s)                          50.4836
time/total (s)                       24146.4
Epoch                                  109
----------------------------------  -----------------
2020-11-09 21:50:28.088441 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 110 finished
----------------------------------  ----------------
replay_buffer/size                  224000
trainer/num train calls             111000
trainer/QF1 Loss                        33.5363
trainer/QF2 Loss                        34.4272
trainer/Policy Loss                     58.2583
trainer/Q1 Predictions Mean            -58.0564
trainer/Q1 Predictions Std              68.3668
trainer/Q1 Predictions Max             104.26
trainer/Q1 Predictions Min            -229.102
trainer/Q2 Predictions Mean            -58.2089
trainer/Q2 Predictions Std              68.4712
trainer/Q2 Predictions Max             104.314
trainer/Q2 Predictions Min            -229.127
trainer/Q Targets Mean                 -57.8151
trainer/Q Targets Std                   68.8495
trainer/Q Targets Max                  104.324
trainer/Q Targets Min                 -228.466
trainer/Log Pis Mean                     1.62066
trainer/Log Pis Std                      1.60805
trainer/Log Pis Max                      5.26986
trainer/Log Pis Min                     -6.05463
trainer/policy/mean Mean                -0.456129
trainer/policy/mean Std                  0.665616
trainer/policy/mean Max                  0.955377
trainer/policy/mean Min                 -0.977263
trainer/policy/normal/std Mean           0.596285
trainer/policy/normal/std Std            0.0695833
trainer/policy/normal/std Max            0.726814
trainer/policy/normal/std Min            0.474829
trainer/policy/normal/log_std Mean      -0.523808
trainer/policy/normal/log_std Std        0.116218
trainer/policy/normal/log_std Max       -0.319085
trainer/policy/normal/log_std Min       -0.7448
trainer/Alpha                            0.0400243
trainer/Alpha Loss                      -1.22081
exploration/num steps total         224000
exploration/num paths total           1120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.998603
exploration/Rewards Std                  1.61038
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -199.721
exploration/Returns Std                119.505
exploration/Returns Max                -69.1886
exploration/Returns Min               -525.94
exploration/Actions Mean                -0.372262
exploration/Actions Std                  0.735033
exploration/Actions Max                  0.996148
exploration/Actions Min                 -0.998898
exploration/Num Paths                   10
exploration/Average Returns           -199.721
evaluation/num steps total          535464
evaluation/num paths total            2664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.525503
evaluation/Actions Std                   0.441438
evaluation/Actions Max                  -0.0696343
evaluation/Actions Min                  -0.965561
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0241072
time/evaluation sampling (s)            12.1865
time/exploration sampling (s)            4.83312
time/logging (s)                         0.0194852
time/sac training (s)                   29.5104
time/saving (s)                          0.0230817
time/training (s)                        0.000150475
time/epoch (s)                          46.5968
time/total (s)                       24194.8
Epoch                                  110
----------------------------------  ----------------
2020-11-09 21:51:17.321379 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 111 finished
----------------------------------  ----------------
replay_buffer/size                  226000
trainer/num train calls             112000
trainer/QF1 Loss                        11.0053
trainer/QF2 Loss                        10.9654
trainer/Policy Loss                     51.4755
trainer/Q1 Predictions Mean            -51.3351
trainer/Q1 Predictions Std              66.0127
trainer/Q1 Predictions Max             103.516
trainer/Q1 Predictions Min            -175.941
trainer/Q2 Predictions Mean            -51.4274
trainer/Q2 Predictions Std              66.0387
trainer/Q2 Predictions Max             103.647
trainer/Q2 Predictions Min            -174.005
trainer/Q Targets Mean                 -51.914
trainer/Q Targets Std                   66.8183
trainer/Q Targets Max                  103.229
trainer/Q Targets Min                 -176.271
trainer/Log Pis Mean                     1.97472
trainer/Log Pis Std                      1.81515
trainer/Log Pis Max                      6.11055
trainer/Log Pis Min                     -3.08823
trainer/policy/mean Mean                -0.648645
trainer/policy/mean Std                  0.527355
trainer/policy/mean Max                  0.900435
trainer/policy/mean Min                 -0.981208
trainer/policy/normal/std Mean           0.600813
trainer/policy/normal/std Std            0.0727104
trainer/policy/normal/std Max            0.749532
trainer/policy/normal/std Min            0.491973
trainer/policy/normal/log_std Mean      -0.516788
trainer/policy/normal/log_std Std        0.120923
trainer/policy/normal/log_std Max       -0.288307
trainer/policy/normal/log_std Min       -0.70933
trainer/Alpha                            0.0393671
trainer/Alpha Loss                      -0.081792
exploration/num steps total         226000
exploration/num paths total           1130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0703
exploration/Rewards Std                  1.57383
exploration/Rewards Max                 -4.50358e-63
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -214.06
exploration/Returns Std                169.081
exploration/Returns Max                -47.9911
exploration/Returns Min               -568.642
exploration/Actions Mean                -0.813839
exploration/Actions Std                  0.348273
exploration/Actions Max                  0.926881
exploration/Actions Min                 -0.999913
exploration/Num Paths                   10
exploration/Average Returns           -214.06
evaluation/num steps total          540288
evaluation/num paths total            2688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.53509e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.789735
evaluation/Actions Std                   0.179859
evaluation/Actions Max                  -0.609837
evaluation/Actions Min                  -0.969594
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0262239
time/evaluation sampling (s)            12.8762
time/exploration sampling (s)            5.15587
time/logging (s)                         0.023919
time/sac training (s)                   29.7197
time/saving (s)                          0.0222149
time/training (s)                        0.000118606
time/epoch (s)                          47.8242
time/total (s)                       24244
Epoch                                  111
----------------------------------  ----------------
2020-11-09 21:52:06.630468 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 112 finished
----------------------------------  -----------------
replay_buffer/size                  228000
trainer/num train calls             113000
trainer/QF1 Loss                        67.9138
trainer/QF2 Loss                        72.9002
trainer/Policy Loss                     51.9741
trainer/Q1 Predictions Mean            -51.815
trainer/Q1 Predictions Std              67.9853
trainer/Q1 Predictions Max             104.353
trainer/Q1 Predictions Min            -200.944
trainer/Q2 Predictions Mean            -51.7661
trainer/Q2 Predictions Std              67.9172
trainer/Q2 Predictions Max             104.331
trainer/Q2 Predictions Min            -201.31
trainer/Q Targets Mean                 -51.5697
trainer/Q Targets Std                   68.3718
trainer/Q Targets Max                  103.373
trainer/Q Targets Min                 -200.503
trainer/Log Pis Mean                     1.79055
trainer/Log Pis Std                      1.8427
trainer/Log Pis Max                      6.29246
trainer/Log Pis Min                     -7.31442
trainer/policy/mean Mean                -0.577698
trainer/policy/mean Std                  0.574817
trainer/policy/mean Max                  0.915749
trainer/policy/mean Min                 -0.981113
trainer/policy/normal/std Mean           0.608462
trainer/policy/normal/std Std            0.0767527
trainer/policy/normal/std Max            0.756006
trainer/policy/normal/std Min            0.494385
trainer/policy/normal/log_std Mean      -0.504787
trainer/policy/normal/log_std Std        0.126251
trainer/policy/normal/log_std Max       -0.279706
trainer/policy/normal/log_std Min       -0.704441
trainer/Alpha                            0.0383556
trainer/Alpha Loss                      -0.682993
exploration/num steps total         228000
exploration/num paths total           1140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12675
exploration/Rewards Std                  1.51339
exploration/Rewards Max                 -1.25421e-179
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -225.351
exploration/Returns Std                162.264
exploration/Returns Max                -21.3694
exploration/Returns Min               -544.86
exploration/Actions Mean                -0.644859
exploration/Actions Std                  0.541355
exploration/Actions Max                  0.993268
exploration/Actions Min                 -0.999958
exploration/Num Paths                   10
exploration/Average Returns           -225.351
evaluation/num steps total          545112
evaluation/num paths total            2712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56793
evaluation/Rewards Std                   0.982659
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1119.15
evaluation/Returns Std                 197.203
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.75572
evaluation/Actions Std                   0.21461
evaluation/Actions Max                  -0.516391
evaluation/Actions Min                  -0.969339
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.15
time/data storing (s)                    0.020226
time/evaluation sampling (s)            12.7199
time/exploration sampling (s)            4.87218
time/logging (s)                         0.019664
time/sac training (s)                   30.1969
time/saving (s)                          0.021833
time/training (s)                        0.000127411
time/epoch (s)                          47.8508
time/total (s)                       24293.3
Epoch                                  112
----------------------------------  -----------------
2020-11-09 21:52:54.951427 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 113 finished
----------------------------------  ----------------
replay_buffer/size                  230000
trainer/num train calls             114000
trainer/QF1 Loss                        39.4515
trainer/QF2 Loss                        38.6271
trainer/Policy Loss                     54.0802
trainer/Q1 Predictions Mean            -53.9749
trainer/Q1 Predictions Std              64.7447
trainer/Q1 Predictions Max              98.5768
trainer/Q1 Predictions Min            -184.514
trainer/Q2 Predictions Mean            -53.8736
trainer/Q2 Predictions Std              64.6501
trainer/Q2 Predictions Max              98.9104
trainer/Q2 Predictions Min            -184.622
trainer/Q Targets Mean                 -53.9809
trainer/Q Targets Std                   64.7401
trainer/Q Targets Max                   98.4954
trainer/Q Targets Min                 -183.968
trainer/Log Pis Mean                     1.78641
trainer/Log Pis Std                      1.57344
trainer/Log Pis Max                      5.81665
trainer/Log Pis Min                     -5.2659
trainer/policy/mean Mean                -0.534767
trainer/policy/mean Std                  0.618315
trainer/policy/mean Max                  0.930904
trainer/policy/mean Min                 -0.98112
trainer/policy/normal/std Mean           0.609373
trainer/policy/normal/std Std            0.0838301
trainer/policy/normal/std Max            0.764356
trainer/policy/normal/std Min            0.480595
trainer/policy/normal/log_std Mean      -0.504805
trainer/policy/normal/log_std Std        0.137728
trainer/policy/normal/log_std Max       -0.268722
trainer/policy/normal/log_std Min       -0.73273
trainer/Alpha                            0.0373551
trainer/Alpha Loss                      -0.702121
exploration/num steps total         230000
exploration/num paths total           1150
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.976168
exploration/Rewards Std                  1.63094
exploration/Rewards Max                 -1.09979e-97
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -195.234
exploration/Returns Std                131.728
exploration/Returns Max                -37.7694
exploration/Returns Min               -436.679
exploration/Actions Mean                -0.473327
exploration/Actions Std                  0.697265
exploration/Actions Max                  0.99797
exploration/Actions Min                 -0.999473
exploration/Num Paths                   10
exploration/Average Returns           -195.234
evaluation/num steps total          549936
evaluation/num paths total            2736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.46974e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.686888
evaluation/Actions Std                   0.282929
evaluation/Actions Max                  -0.403874
evaluation/Actions Min                  -0.970167
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0194718
time/evaluation sampling (s)            12.7902
time/exploration sampling (s)            5.03543
time/logging (s)                         0.0188259
time/sac training (s)                   29.2827
time/saving (s)                          0.0225636
time/training (s)                        0.000109688
time/epoch (s)                          47.1693
time/total (s)                       24341.6
Epoch                                  113
----------------------------------  ----------------
2020-11-09 21:53:43.605790 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 114 finished
----------------------------------  -----------------
replay_buffer/size                  232000
trainer/num train calls             115000
trainer/QF1 Loss                       128.225
trainer/QF2 Loss                       131.106
trainer/Policy Loss                     57.8121
trainer/Q1 Predictions Mean            -57.4586
trainer/Q1 Predictions Std              70.1248
trainer/Q1 Predictions Max             103.879
trainer/Q1 Predictions Min            -201.364
trainer/Q2 Predictions Mean            -57.6369
trainer/Q2 Predictions Std              70.2022
trainer/Q2 Predictions Max             103.883
trainer/Q2 Predictions Min            -201.802
trainer/Q Targets Mean                 -57.0076
trainer/Q Targets Std                   70.5462
trainer/Q Targets Max                  103.32
trainer/Q Targets Min                 -200.805
trainer/Log Pis Mean                     1.81403
trainer/Log Pis Std                      1.64486
trainer/Log Pis Max                      7.05527
trainer/Log Pis Min                     -4.22731
trainer/policy/mean Mean                -0.620386
trainer/policy/mean Std                  0.536824
trainer/policy/mean Max                  0.937142
trainer/policy/mean Min                 -0.9966
trainer/policy/normal/std Mean           0.614292
trainer/policy/normal/std Std            0.0895882
trainer/policy/normal/std Max            0.784472
trainer/policy/normal/std Min            0.476696
trainer/policy/normal/log_std Mean      -0.497903
trainer/policy/normal/log_std Std        0.145633
trainer/policy/normal/log_std Max       -0.242745
trainer/policy/normal/log_std Min       -0.740876
trainer/Alpha                            0.0364782
trainer/Alpha Loss                      -0.615768
exploration/num steps total         232000
exploration/num paths total           1160
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.791395
exploration/Rewards Std                  1.55221
exploration/Rewards Max                 -8.13123e-214
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -158.279
exploration/Returns Std                 74.2523
exploration/Returns Max                -56.0679
exploration/Returns Min               -304.138
exploration/Actions Mean                -0.518443
exploration/Actions Std                  0.65288
exploration/Actions Max                  0.994876
exploration/Actions Min                 -0.999304
exploration/Num Paths                   10
exploration/Average Returns           -158.279
evaluation/num steps total          554760
evaluation/num paths total            2760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.745383
evaluation/Actions Std                   0.227296
evaluation/Actions Max                  -0.516407
evaluation/Actions Min                  -0.972831
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0189599
time/evaluation sampling (s)            12.5927
time/exploration sampling (s)            5.13262
time/logging (s)                         0.0219469
time/sac training (s)                   29.7258
time/saving (s)                          0.0293151
time/training (s)                        0.000129913
time/epoch (s)                          47.5214
time/total (s)                       24390.2
Epoch                                  114
----------------------------------  -----------------
2020-11-09 21:54:31.611650 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 115 finished
----------------------------------  -----------------
replay_buffer/size                  234000
trainer/num train calls             116000
trainer/QF1 Loss                        23.2511
trainer/QF2 Loss                        21.528
trainer/Policy Loss                     57.9453
trainer/Q1 Predictions Mean            -57.8116
trainer/Q1 Predictions Std              64.2002
trainer/Q1 Predictions Max              60.9979
trainer/Q1 Predictions Min            -210.671
trainer/Q2 Predictions Mean            -57.709
trainer/Q2 Predictions Std              64.2611
trainer/Q2 Predictions Max              60.8095
trainer/Q2 Predictions Min            -210.427
trainer/Q Targets Mean                 -57.9128
trainer/Q Targets Std                   64.6121
trainer/Q Targets Max                   60.8003
trainer/Q Targets Min                 -209.514
trainer/Log Pis Mean                     1.68686
trainer/Log Pis Std                      1.81745
trainer/Log Pis Max                      5.35456
trainer/Log Pis Min                     -6.48934
trainer/policy/mean Mean                -0.365633
trainer/policy/mean Std                  0.723503
trainer/policy/mean Max                  0.960347
trainer/policy/mean Min                 -0.980473
trainer/policy/normal/std Mean           0.602589
trainer/policy/normal/std Std            0.0813125
trainer/policy/normal/std Max            0.754593
trainer/policy/normal/std Min            0.466213
trainer/policy/normal/log_std Mean      -0.515511
trainer/policy/normal/log_std Std        0.133663
trainer/policy/normal/log_std Max       -0.281577
trainer/policy/normal/log_std Min       -0.763113
trainer/Alpha                            0.035423
trainer/Alpha Loss                      -1.04599
exploration/num steps total         234000
exploration/num paths total           1170
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02198
exploration/Rewards Std                  1.4836
exploration/Rewards Max                 -3.39336e-174
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -204.395
exploration/Returns Std                102.999
exploration/Returns Max                -30.0971
exploration/Returns Min               -361.238
exploration/Actions Mean                -0.406657
exploration/Actions Std                  0.674189
exploration/Actions Max                  0.994244
exploration/Actions Min                 -0.998565
exploration/Num Paths                   10
exploration/Average Returns           -204.395
evaluation/num steps total          559584
evaluation/num paths total            2784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.391563
evaluation/Actions Std                   0.584568
evaluation/Actions Max                   0.561485
evaluation/Actions Min                  -0.97106
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0333007
time/evaluation sampling (s)            12.4782
time/exploration sampling (s)            4.99216
time/logging (s)                         0.0186656
time/sac training (s)                   29.3538
time/saving (s)                          0.0239448
time/training (s)                        0.000119412
time/epoch (s)                          46.9002
time/total (s)                       24438.2
Epoch                                  115
----------------------------------  -----------------
2020-11-09 21:55:19.606987 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 116 finished
----------------------------------  ----------------
replay_buffer/size                  236000
trainer/num train calls             117000
trainer/QF1 Loss                        80.4423
trainer/QF2 Loss                        80.4259
trainer/Policy Loss                     56.2813
trainer/Q1 Predictions Mean            -56.1128
trainer/Q1 Predictions Std              70.2906
trainer/Q1 Predictions Max             105.42
trainer/Q1 Predictions Min            -215.39
trainer/Q2 Predictions Mean            -56.1768
trainer/Q2 Predictions Std              70.3343
trainer/Q2 Predictions Max             105.473
trainer/Q2 Predictions Min            -215.953
trainer/Q Targets Mean                 -56.0605
trainer/Q Targets Std                   70.7278
trainer/Q Targets Max                  104.845
trainer/Q Targets Min                 -214.881
trainer/Log Pis Mean                     1.83599
trainer/Log Pis Std                      1.50176
trainer/Log Pis Max                      4.91433
trainer/Log Pis Min                     -3.85971
trainer/policy/mean Mean                -0.512831
trainer/policy/mean Std                  0.623603
trainer/policy/mean Max                  0.951495
trainer/policy/mean Min                 -0.981107
trainer/policy/normal/std Mean           0.612303
trainer/policy/normal/std Std            0.0852414
trainer/policy/normal/std Max            0.768125
trainer/policy/normal/std Min            0.4776
trainer/policy/normal/log_std Mean      -0.500182
trainer/policy/normal/log_std Std        0.13878
trainer/policy/normal/log_std Max       -0.263803
trainer/policy/normal/log_std Min       -0.738981
trainer/Alpha                            0.0346748
trainer/Alpha Loss                      -0.551353
exploration/num steps total         236000
exploration/num paths total           1180
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.717588
exploration/Rewards Std                  1.49628
exploration/Rewards Max                 -2.5438e-130
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -143.518
exploration/Returns Std                 94.4701
exploration/Returns Max                -58.6964
exploration/Returns Min               -406.346
exploration/Actions Mean                -0.397013
exploration/Actions Std                  0.709718
exploration/Actions Max                  0.998544
exploration/Actions Min                 -0.999029
exploration/Num Paths                   10
exploration/Average Returns           -143.518
evaluation/num steps total          564408
evaluation/num paths total            2808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.6579e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.571653
evaluation/Actions Std                   0.401298
evaluation/Actions Max                  -0.170339
evaluation/Actions Min                  -0.973298
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0195886
time/evaluation sampling (s)            12.9432
time/exploration sampling (s)            4.87736
time/logging (s)                         0.0192371
time/sac training (s)                   29.0037
time/saving (s)                          0.0198669
time/training (s)                        9.9786e-05
time/epoch (s)                          46.8831
time/total (s)                       24486.2
Epoch                                  116
----------------------------------  ----------------
2020-11-09 21:56:07.404533 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 117 finished
----------------------------------  ----------------
replay_buffer/size                  238000
trainer/num train calls             118000
trainer/QF1 Loss                        24.4545
trainer/QF2 Loss                        26.8823
trainer/Policy Loss                     56.2067
trainer/Q1 Predictions Mean            -56.0265
trainer/Q1 Predictions Std              68.3773
trainer/Q1 Predictions Max             105.152
trainer/Q1 Predictions Min            -235.399
trainer/Q2 Predictions Mean            -56.0124
trainer/Q2 Predictions Std              68.4035
trainer/Q2 Predictions Max             105.656
trainer/Q2 Predictions Min            -236.314
trainer/Q Targets Mean                 -56.3954
trainer/Q Targets Std                   69.0037
trainer/Q Targets Max                  104.729
trainer/Q Targets Min                 -235.116
trainer/Log Pis Mean                     1.84119
trainer/Log Pis Std                      1.67222
trainer/Log Pis Max                      5.31513
trainer/Log Pis Min                     -6.71927
trainer/policy/mean Mean                -0.632336
trainer/policy/mean Std                  0.531142
trainer/policy/mean Max                  0.93078
trainer/policy/mean Min                 -0.987179
trainer/policy/normal/std Mean           0.592017
trainer/policy/normal/std Std            0.0622147
trainer/policy/normal/std Max            0.7318
trainer/policy/normal/std Min            0.47869
trainer/policy/normal/log_std Mean      -0.529676
trainer/policy/normal/log_std Std        0.10417
trainer/policy/normal/log_std Max       -0.312248
trainer/policy/normal/log_std Min       -0.736701
trainer/Alpha                            0.0340931
trainer/Alpha Loss                      -0.536573
exploration/num steps total         238000
exploration/num paths total           1190
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.40692
exploration/Rewards Std                  1.7274
exploration/Rewards Max                 -7.16259e-52
exploration/Rewards Min                 -6.13959
exploration/Returns Mean              -281.383
exploration/Returns Std                155.345
exploration/Returns Max                -89.8117
exploration/Returns Min               -546.992
exploration/Actions Mean                -0.632962
exploration/Actions Std                  0.584816
exploration/Actions Max                  0.994742
exploration/Actions Min                 -0.998923
exploration/Num Paths                   10
exploration/Average Returns           -281.383
evaluation/num steps total          569232
evaluation/num paths total            2832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.772814
evaluation/Actions Std                   0.197909
evaluation/Actions Max                  -0.561696
evaluation/Actions Min                  -0.969597
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0193095
time/evaluation sampling (s)            12.2803
time/exploration sampling (s)            5.17899
time/logging (s)                         0.0191849
time/sac training (s)                   29.1146
time/saving (s)                          0.0234322
time/training (s)                        0.000116412
time/epoch (s)                          46.6359
time/total (s)                       24534
Epoch                                  117
----------------------------------  ----------------
2020-11-09 21:57:04.966462 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 118 finished
----------------------------------  -----------------
replay_buffer/size                  240000
trainer/num train calls             119000
trainer/QF1 Loss                        16.8215
trainer/QF2 Loss                        19.5849
trainer/Policy Loss                     47.9173
trainer/Q1 Predictions Mean            -47.8862
trainer/Q1 Predictions Std              62.8316
trainer/Q1 Predictions Max              56.8635
trainer/Q1 Predictions Min            -185.109
trainer/Q2 Predictions Mean            -47.7625
trainer/Q2 Predictions Std              62.7913
trainer/Q2 Predictions Max              57.0183
trainer/Q2 Predictions Min            -185.616
trainer/Q Targets Mean                 -48.2025
trainer/Q Targets Std                   63.0884
trainer/Q Targets Max                   56.5622
trainer/Q Targets Min                 -184.649
trainer/Log Pis Mean                     1.62089
trainer/Log Pis Std                      1.69947
trainer/Log Pis Max                      5.27592
trainer/Log Pis Min                     -4.86854
trainer/policy/mean Mean                -0.389577
trainer/policy/mean Std                  0.70771
trainer/policy/mean Max                  0.961077
trainer/policy/mean Min                 -0.976544
trainer/policy/normal/std Mean           0.589515
trainer/policy/normal/std Std            0.0634745
trainer/policy/normal/std Max            0.721119
trainer/policy/normal/std Min            0.482308
trainer/policy/normal/log_std Mean      -0.534176
trainer/policy/normal/log_std Std        0.106627
trainer/policy/normal/log_std Max       -0.326951
trainer/policy/normal/log_std Min       -0.729173
trainer/Alpha                            0.0337288
trainer/Alpha Loss                      -1.28495
exploration/num steps total         240000
exploration/num paths total           1200
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00392
exploration/Rewards Std                  1.47294
exploration/Rewards Max                 -2.97064e-109
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -200.785
exploration/Returns Std                127.785
exploration/Returns Max                -50.6852
exploration/Returns Min               -484.984
exploration/Actions Mean                -0.489928
exploration/Actions Std                  0.650236
exploration/Actions Max                  0.997689
exploration/Actions Min                 -0.998709
exploration/Num Paths                   10
exploration/Average Returns           -200.785
evaluation/num steps total          574056
evaluation/num paths total            2856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.474867
evaluation/Actions Std                   0.492988
evaluation/Actions Max                   0.0318949
evaluation/Actions Min                  -0.969675
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0245985
time/evaluation sampling (s)            13.5605
time/exploration sampling (s)            7.55716
time/logging (s)                         0.0248404
time/sac training (s)                   35.0849
time/saving (s)                          0.0296079
time/training (s)                        0.000149837
time/epoch (s)                          56.2817
time/total (s)                       24591.5
Epoch                                  118
----------------------------------  -----------------
2020-11-09 21:58:07.920560 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 119 finished
----------------------------------  -----------------
replay_buffer/size                  242000
trainer/num train calls             120000
trainer/QF1 Loss                        29.9847
trainer/QF2 Loss                        30.137
trainer/Policy Loss                     59.8048
trainer/Q1 Predictions Mean            -59.6597
trainer/Q1 Predictions Std              71.5406
trainer/Q1 Predictions Max              94.3073
trainer/Q1 Predictions Min            -236.691
trainer/Q2 Predictions Mean            -59.6539
trainer/Q2 Predictions Std              71.5635
trainer/Q2 Predictions Max              94.3104
trainer/Q2 Predictions Min            -237.484
trainer/Q Targets Mean                 -60.1103
trainer/Q Targets Std                   72.1251
trainer/Q Targets Max                   93.5861
trainer/Q Targets Min                 -236.422
trainer/Log Pis Mean                     2.11398
trainer/Log Pis Std                      1.68789
trainer/Log Pis Max                      5.93573
trainer/Log Pis Min                     -4.71174
trainer/policy/mean Mean                -0.648325
trainer/policy/mean Std                  0.522656
trainer/policy/mean Max                  0.912807
trainer/policy/mean Min                 -0.982479
trainer/policy/normal/std Mean           0.608894
trainer/policy/normal/std Std            0.0879113
trainer/policy/normal/std Max            0.769386
trainer/policy/normal/std Min            0.488737
trainer/policy/normal/log_std Mean      -0.506486
trainer/policy/normal/log_std Std        0.143843
trainer/policy/normal/log_std Max       -0.262162
trainer/policy/normal/log_std Min       -0.71593
trainer/Alpha                            0.0328903
trainer/Alpha Loss                       0.389209
exploration/num steps total         242000
exploration/num paths total           1210
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.25011
exploration/Rewards Std                  1.68758
exploration/Rewards Max                 -1.85396e-146
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -250.021
exploration/Returns Std                178.077
exploration/Returns Max                -69.3383
exploration/Returns Min               -581.083
exploration/Actions Mean                -0.709844
exploration/Actions Std                  0.512592
exploration/Actions Max                  0.994436
exploration/Actions Min                 -0.999839
exploration/Num Paths                   10
exploration/Average Returns           -250.021
evaluation/num steps total          578880
evaluation/num paths total            2880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   3.6337e-15
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   4.64125e-14
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.77161
evaluation/Actions Std                   0.200854
evaluation/Actions Max                  -0.570671
evaluation/Actions Min                  -0.972822
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.030137
time/evaluation sampling (s)            19.3361
time/exploration sampling (s)            6.83802
time/logging (s)                         0.0216273
time/sac training (s)                   35.4062
time/saving (s)                          0.0310549
time/training (s)                        0.000148383
time/epoch (s)                          61.6634
time/total (s)                       24654.4
Epoch                                  119
----------------------------------  -----------------
2020-11-09 21:59:04.756997 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 120 finished
----------------------------------  -----------------
replay_buffer/size                  244000
trainer/num train calls             121000
trainer/QF1 Loss                       102.75
trainer/QF2 Loss                       105.588
trainer/Policy Loss                     58.867
trainer/Q1 Predictions Mean            -58.7364
trainer/Q1 Predictions Std              65.6663
trainer/Q1 Predictions Max              77.5274
trainer/Q1 Predictions Min            -201.812
trainer/Q2 Predictions Mean            -58.6989
trainer/Q2 Predictions Std              65.6306
trainer/Q2 Predictions Max              77.3755
trainer/Q2 Predictions Min            -202.313
trainer/Q Targets Mean                 -58.7469
trainer/Q Targets Std                   66.2469
trainer/Q Targets Max                   73.8058
trainer/Q Targets Min                 -201.447
trainer/Log Pis Mean                     1.90125
trainer/Log Pis Std                      1.5539
trainer/Log Pis Max                      5.42775
trainer/Log Pis Min                     -4.36085
trainer/policy/mean Mean                -0.436266
trainer/policy/mean Std                  0.688771
trainer/policy/mean Max                  0.958488
trainer/policy/mean Min                 -0.98223
trainer/policy/normal/std Mean           0.585216
trainer/policy/normal/std Std            0.0740187
trainer/policy/normal/std Max            0.724248
trainer/policy/normal/std Min            0.459008
trainer/policy/normal/log_std Mean      -0.543675
trainer/policy/normal/log_std Std        0.125305
trainer/policy/normal/log_std Max       -0.322621
trainer/policy/normal/log_std Min       -0.778687
trainer/Alpha                            0.0323987
trainer/Alpha Loss                      -0.338692
exploration/num steps total         244000
exploration/num paths total           1220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.983763
exploration/Rewards Std                  1.65216
exploration/Rewards Max                 -1.98955e-272
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -196.753
exploration/Returns Std                110.146
exploration/Returns Max                -39.846
exploration/Returns Min               -475.496
exploration/Actions Mean                -0.363712
exploration/Actions Std                  0.72906
exploration/Actions Max                  0.997082
exploration/Actions Min                 -0.998961
exploration/Num Paths                   10
exploration/Average Returns           -196.753
evaluation/num steps total          583704
evaluation/num paths total            2904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59725
evaluation/Rewards Std                   1.38355
evaluation/Rewards Max                  -4.28103e-12
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1125.05
evaluation/Returns Std                 277.921
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.498209
evaluation/Actions Std                   0.4972
evaluation/Actions Max                   0.446215
evaluation/Actions Min                  -0.973896
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.05
time/data storing (s)                    0.0229022
time/evaluation sampling (s)            17.5217
time/exploration sampling (s)            7.00495
time/logging (s)                         0.0189574
time/sac training (s)                   31.0643
time/saving (s)                          0.0234888
time/training (s)                        0.000113208
time/epoch (s)                          55.6564
time/total (s)                       24711.2
Epoch                                  120
----------------------------------  -----------------
2020-11-09 21:59:56.220586 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 121 finished
----------------------------------  ----------------
replay_buffer/size                  246000
trainer/num train calls             122000
trainer/QF1 Loss                        46.2192
trainer/QF2 Loss                        47.5732
trainer/Policy Loss                     48.515
trainer/Q1 Predictions Mean            -48.387
trainer/Q1 Predictions Std              65.9719
trainer/Q1 Predictions Max              57.9709
trainer/Q1 Predictions Min            -237.229
trainer/Q2 Predictions Mean            -48.2288
trainer/Q2 Predictions Std              65.8777
trainer/Q2 Predictions Max              58.0888
trainer/Q2 Predictions Min            -238.003
trainer/Q Targets Mean                 -48.2658
trainer/Q Targets Std                   66.2838
trainer/Q Targets Max                   58.2295
trainer/Q Targets Min                 -236.799
trainer/Log Pis Mean                     1.8026
trainer/Log Pis Std                      1.72138
trainer/Log Pis Max                      7.17525
trainer/Log Pis Min                     -4.59108
trainer/policy/mean Mean                -0.559481
trainer/policy/mean Std                  0.60801
trainer/policy/mean Max                  0.925218
trainer/policy/mean Min                 -0.985558
trainer/policy/normal/std Mean           0.590558
trainer/policy/normal/std Std            0.0667513
trainer/policy/normal/std Max            0.729218
trainer/policy/normal/std Min            0.479356
trainer/policy/normal/log_std Mean      -0.533007
trainer/policy/normal/log_std Std        0.11212
trainer/policy/normal/log_std Max       -0.315782
trainer/policy/normal/log_std Min       -0.735311
trainer/Alpha                            0.031525
trainer/Alpha Loss                      -0.682417
exploration/num steps total         246000
exploration/num paths total           1230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.08037
exploration/Rewards Std                  1.64347
exploration/Rewards Max                 -2.99005e-92
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -216.074
exploration/Returns Std                136.21
exploration/Returns Max                -63.8258
exploration/Returns Min               -444.865
exploration/Actions Mean                -0.344077
exploration/Actions Std                  0.74083
exploration/Actions Max                  0.998628
exploration/Actions Min                 -0.999036
exploration/Num Paths                   10
exploration/Average Returns           -216.074
evaluation/num steps total          588528
evaluation/num paths total            2928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   2.2793e-08
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.668413
evaluation/Actions Std                   0.301699
evaluation/Actions Max                  -0.366288
evaluation/Actions Min                  -0.970905
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0192926
time/evaluation sampling (s)            14.4776
time/exploration sampling (s)            5.48588
time/logging (s)                         0.0212957
time/sac training (s)                   30.2501
time/saving (s)                          0.0213324
time/training (s)                        0.000126986
time/epoch (s)                          50.2756
time/total (s)                       24762.7
Epoch                                  121
----------------------------------  ----------------
2020-11-09 22:00:53.854685 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 122 finished
----------------------------------  -----------------
replay_buffer/size                  248000
trainer/num train calls             123000
trainer/QF1 Loss                       151.115
trainer/QF2 Loss                       153.623
trainer/Policy Loss                     66.7743
trainer/Q1 Predictions Mean            -66.6119
trainer/Q1 Predictions Std              62.4843
trainer/Q1 Predictions Max             105.065
trainer/Q1 Predictions Min            -217.389
trainer/Q2 Predictions Mean            -66.5117
trainer/Q2 Predictions Std              62.3272
trainer/Q2 Predictions Max             105.092
trainer/Q2 Predictions Min            -217.8
trainer/Q Targets Mean                 -66.0025
trainer/Q Targets Std                   62.9563
trainer/Q Targets Max                  104.817
trainer/Q Targets Min                 -216.641
trainer/Log Pis Mean                     1.66079
trainer/Log Pis Std                      1.61771
trainer/Log Pis Max                      4.81465
trainer/Log Pis Min                     -3.7417
trainer/policy/mean Mean                -0.540931
trainer/policy/mean Std                  0.602921
trainer/policy/mean Max                  0.930207
trainer/policy/mean Min                 -0.978204
trainer/policy/normal/std Mean           0.599019
trainer/policy/normal/std Std            0.0719872
trainer/policy/normal/std Max            0.754173
trainer/policy/normal/std Min            0.493981
trainer/policy/normal/log_std Mean      -0.519599
trainer/policy/normal/log_std Std        0.119126
trainer/policy/normal/log_std Max       -0.282134
trainer/policy/normal/log_std Min       -0.705258
trainer/Alpha                            0.0309409
trainer/Alpha Loss                      -1.17898
exploration/num steps total         248000
exploration/num paths total           1240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.731375
exploration/Rewards Std                  1.57069
exploration/Rewards Max                 -3.84759e-193
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.275
exploration/Returns Std                 68.151
exploration/Returns Max                -42.2838
exploration/Returns Min               -244.04
exploration/Actions Mean                -0.567184
exploration/Actions Std                  0.6021
exploration/Actions Max                  0.995251
exploration/Actions Min                 -0.999414
exploration/Num Paths                   10
exploration/Average Returns           -146.275
evaluation/num steps total          593352
evaluation/num paths total            2952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.45852
evaluation/Rewards Std                   1.07073
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1097.16
evaluation/Returns Std                 214.788
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.627354
evaluation/Actions Std                   0.35111
evaluation/Actions Max                  -0.246734
evaluation/Actions Min                  -0.971354
evaluation/Num Paths                    24
evaluation/Average Returns           -1097.16
time/data storing (s)                    0.0211949
time/evaluation sampling (s)            17.5467
time/exploration sampling (s)            6.56346
time/logging (s)                         0.0236047
time/sac training (s)                   31.6327
time/saving (s)                          0.0235782
time/training (s)                        0.000100738
time/epoch (s)                          55.8114
time/total (s)                       24820.3
Epoch                                  122
----------------------------------  -----------------
2020-11-09 22:01:43.968314 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 123 finished
----------------------------------  -----------------
replay_buffer/size                  250000
trainer/num train calls             124000
trainer/QF1 Loss                         7.78887
trainer/QF2 Loss                         7.70541
trainer/Policy Loss                     57.9665
trainer/Q1 Predictions Mean            -57.8901
trainer/Q1 Predictions Std              67.9324
trainer/Q1 Predictions Max             105.899
trainer/Q1 Predictions Min            -215.474
trainer/Q2 Predictions Mean            -57.8518
trainer/Q2 Predictions Std              67.8705
trainer/Q2 Predictions Max             105.806
trainer/Q2 Predictions Min            -215.646
trainer/Q Targets Mean                 -58.3279
trainer/Q Targets Std                   68.4574
trainer/Q Targets Max                  105.146
trainer/Q Targets Min                 -214.435
trainer/Log Pis Mean                     1.75571
trainer/Log Pis Std                      1.70376
trainer/Log Pis Max                      5.58372
trainer/Log Pis Min                     -5.14422
trainer/policy/mean Mean                -0.378999
trainer/policy/mean Std                  0.721372
trainer/policy/mean Max                  0.966437
trainer/policy/mean Min                 -0.981201
trainer/policy/normal/std Mean           0.599178
trainer/policy/normal/std Std            0.0721815
trainer/policy/normal/std Max            0.747847
trainer/policy/normal/std Min            0.492886
trainer/policy/normal/log_std Mean      -0.519344
trainer/policy/normal/log_std Std        0.119113
trainer/policy/normal/log_std Max       -0.290557
trainer/policy/normal/log_std Min       -0.707478
trainer/Alpha                            0.0306561
trainer/Alpha Loss                      -0.851318
exploration/num steps total         250000
exploration/num paths total           1250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0153
exploration/Rewards Std                  1.53427
exploration/Rewards Max                 -1.25084e-218
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -203.059
exploration/Returns Std                125.503
exploration/Returns Max                -62.6509
exploration/Returns Min               -443.416
exploration/Actions Mean                -0.418238
exploration/Actions Std                  0.707602
exploration/Actions Max                  0.99479
exploration/Actions Min                 -0.999087
exploration/Num Paths                   10
exploration/Average Returns           -203.059
evaluation/num steps total          598176
evaluation/num paths total            2976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95958
evaluation/Rewards Std                   0.55521
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.88
evaluation/Returns Std                 111.597
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.361358
evaluation/Actions Std                   0.611812
evaluation/Actions Max                   0.264548
evaluation/Actions Min                  -0.973066
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.88
time/data storing (s)                    0.0229105
time/evaluation sampling (s)            13.4575
time/exploration sampling (s)            5.7665
time/logging (s)                         0.0189969
time/sac training (s)                   29.2546
time/saving (s)                          0.0219574
time/training (s)                        0.000121811
time/epoch (s)                          48.5425
time/total (s)                       24870.4
Epoch                                  123
----------------------------------  -----------------
2020-11-09 22:02:33.746563 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 124 finished
----------------------------------  ----------------
replay_buffer/size                  252000
trainer/num train calls             125000
trainer/QF1 Loss                       127.979
trainer/QF2 Loss                       125.278
trainer/Policy Loss                     57.7594
trainer/Q1 Predictions Mean            -57.5996
trainer/Q1 Predictions Std              69.5302
trainer/Q1 Predictions Max              61.8342
trainer/Q1 Predictions Min            -223.741
trainer/Q2 Predictions Mean            -57.6031
trainer/Q2 Predictions Std              69.5791
trainer/Q2 Predictions Max              61.1858
trainer/Q2 Predictions Min            -223.866
trainer/Q Targets Mean                 -57.1338
trainer/Q Targets Std                   70.555
trainer/Q Targets Max                   61.1243
trainer/Q Targets Min                 -222.904
trainer/Log Pis Mean                     1.91807
trainer/Log Pis Std                      1.57309
trainer/Log Pis Max                      5.0687
trainer/Log Pis Min                     -3.88613
trainer/policy/mean Mean                -0.506994
trainer/policy/mean Std                  0.651494
trainer/policy/mean Max                  0.954499
trainer/policy/mean Min                 -0.980713
trainer/policy/normal/std Mean           0.61359
trainer/policy/normal/std Std            0.0839209
trainer/policy/normal/std Max            0.786753
trainer/policy/normal/std Min            0.481629
trainer/policy/normal/log_std Mean      -0.49766
trainer/policy/normal/log_std Std        0.135423
trainer/policy/normal/log_std Max       -0.239841
trainer/policy/normal/log_std Min       -0.730581
trainer/Alpha                            0.0307014
trainer/Alpha Loss                      -0.285393
exploration/num steps total         252000
exploration/num paths total           1260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15316
exploration/Rewards Std                  1.64187
exploration/Rewards Max                 -2.82903e-77
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -230.632
exploration/Returns Std                117.955
exploration/Returns Max               -100.662
exploration/Returns Min               -403.161
exploration/Actions Mean                -0.628583
exploration/Actions Std                  0.529628
exploration/Actions Max                  0.991785
exploration/Actions Min                 -0.9989
exploration/Num Paths                   10
exploration/Average Returns           -230.632
evaluation/num steps total          603000
evaluation/num paths total            3000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56738
evaluation/Rewards Std                   0.983127
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1119.04
evaluation/Returns Std                 197.452
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.632129
evaluation/Actions Std                   0.351974
evaluation/Actions Max                  -0.240413
evaluation/Actions Min                  -0.971551
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.04
time/data storing (s)                    0.0242374
time/evaluation sampling (s)            13.2838
time/exploration sampling (s)            5.60403
time/logging (s)                         0.0203788
time/sac training (s)                   29.6137
time/saving (s)                          0.0229412
time/training (s)                        0.00011956
time/epoch (s)                          48.5692
time/total (s)                       24920.1
Epoch                                  124
----------------------------------  ----------------
2020-11-09 22:03:22.995357 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 125 finished
----------------------------------  ----------------
replay_buffer/size                  254000
trainer/num train calls             126000
trainer/QF1 Loss                        51.3862
trainer/QF2 Loss                        55.445
trainer/Policy Loss                     57.9022
trainer/Q1 Predictions Mean            -57.6594
trainer/Q1 Predictions Std              67.671
trainer/Q1 Predictions Max              64.5276
trainer/Q1 Predictions Min            -203.772
trainer/Q2 Predictions Mean            -57.6406
trainer/Q2 Predictions Std              67.5971
trainer/Q2 Predictions Max              64.4424
trainer/Q2 Predictions Min            -204.179
trainer/Q Targets Mean                 -57.8146
trainer/Q Targets Std                   68.4039
trainer/Q Targets Max                   64.2795
trainer/Q Targets Min                 -202.906
trainer/Log Pis Mean                     1.88299
trainer/Log Pis Std                      1.65409
trainer/Log Pis Max                      5.82582
trainer/Log Pis Min                     -5.92654
trainer/policy/mean Mean                -0.38694
trainer/policy/mean Std                  0.720927
trainer/policy/mean Max                  0.957998
trainer/policy/mean Min                 -0.980987
trainer/policy/normal/std Mean           0.586682
trainer/policy/normal/std Std            0.0627734
trainer/policy/normal/std Max            0.760655
trainer/policy/normal/std Min            0.48911
trainer/policy/normal/log_std Mean      -0.538874
trainer/policy/normal/log_std Std        0.105269
trainer/policy/normal/log_std Max       -0.273575
trainer/policy/normal/log_std Min       -0.715168
trainer/Alpha                            0.0298276
trainer/Alpha Loss                      -0.410971
exploration/num steps total         254000
exploration/num paths total           1270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.970496
exploration/Rewards Std                  1.62099
exploration/Rewards Max                 -8.4112e-109
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -194.099
exploration/Returns Std                118.985
exploration/Returns Max                -33.4724
exploration/Returns Min               -410.063
exploration/Actions Mean                -0.361687
exploration/Actions Std                  0.732232
exploration/Actions Max                  0.99667
exploration/Actions Min                 -0.999435
exploration/Num Paths                   10
exploration/Average Returns           -194.099
evaluation/num steps total          607824
evaluation/num paths total            3024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.343237
evaluation/Actions Std                   0.626797
evaluation/Actions Max                   0.285585
evaluation/Actions Min                  -0.970359
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0198438
time/evaluation sampling (s)            12.4428
time/exploration sampling (s)            5.35768
time/logging (s)                         0.0224429
time/sac training (s)                   30.2105
time/saving (s)                          0.0256277
time/training (s)                        0.000124412
time/epoch (s)                          48.079
time/total (s)                       24969.3
Epoch                                  125
----------------------------------  ----------------
2020-11-09 22:04:30.431179 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 126 finished
----------------------------------  -----------------
replay_buffer/size                  256000
trainer/num train calls             127000
trainer/QF1 Loss                        18.8811
trainer/QF2 Loss                        20.07
trainer/Policy Loss                     53.737
trainer/Q1 Predictions Mean            -53.4592
trainer/Q1 Predictions Std              68.5605
trainer/Q1 Predictions Max             104.052
trainer/Q1 Predictions Min            -203.528
trainer/Q2 Predictions Mean            -53.4994
trainer/Q2 Predictions Std              68.6712
trainer/Q2 Predictions Max             103.984
trainer/Q2 Predictions Min            -203.85
trainer/Q Targets Mean                 -54.0435
trainer/Q Targets Std                   69.367
trainer/Q Targets Max                  103.665
trainer/Q Targets Min                 -202.945
trainer/Log Pis Mean                     2.00122
trainer/Log Pis Std                      1.5898
trainer/Log Pis Max                      5.40722
trainer/Log Pis Min                     -4.65749
trainer/policy/mean Mean                -0.500874
trainer/policy/mean Std                  0.663507
trainer/policy/mean Max                  0.957699
trainer/policy/mean Min                 -0.981229
trainer/policy/normal/std Mean           0.594649
trainer/policy/normal/std Std            0.074959
trainer/policy/normal/std Max            0.759693
trainer/policy/normal/std Min            0.479356
trainer/policy/normal/log_std Mean      -0.527608
trainer/policy/normal/log_std Std        0.12461
trainer/policy/normal/log_std Max       -0.27484
trainer/policy/normal/log_std Min       -0.735312
trainer/Alpha                            0.0294927
trainer/Alpha Loss                       0.00430448
exploration/num steps total         256000
exploration/num paths total           1280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.1366
exploration/Rewards Std                  1.65866
exploration/Rewards Max                 -1.16175e-212
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -227.32
exploration/Returns Std                162.917
exploration/Returns Max                -38.5555
exploration/Returns Min               -578.011
exploration/Actions Mean                -0.474356
exploration/Actions Std                  0.702337
exploration/Actions Max                  0.998158
exploration/Actions Min                 -0.998916
exploration/Num Paths                   10
exploration/Average Returns           -227.32
evaluation/num steps total          612648
evaluation/num paths total            3048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.58301e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.625933
evaluation/Actions Std                   0.34418
evaluation/Actions Max                  -0.281509
evaluation/Actions Min                  -0.970341
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0293088
time/evaluation sampling (s)            19.8459
time/exploration sampling (s)            8.14844
time/logging (s)                         0.0316741
time/sac training (s)                   38.0323
time/saving (s)                          0.0269702
time/training (s)                        0.000140053
time/epoch (s)                          66.1147
time/total (s)                       25036.8
Epoch                                  126
----------------------------------  -----------------
2020-11-09 22:05:32.189287 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 127 finished
----------------------------------  ----------------
replay_buffer/size                  258000
trainer/num train calls             128000
trainer/QF1 Loss                        37.8456
trainer/QF2 Loss                        38.3354
trainer/Policy Loss                     56.8849
trainer/Q1 Predictions Mean            -56.7023
trainer/Q1 Predictions Std              67.5053
trainer/Q1 Predictions Max              57.7445
trainer/Q1 Predictions Min            -218.923
trainer/Q2 Predictions Mean            -56.7389
trainer/Q2 Predictions Std              67.4399
trainer/Q2 Predictions Max              57.6516
trainer/Q2 Predictions Min            -219.327
trainer/Q Targets Mean                 -56.8624
trainer/Q Targets Std                   67.8439
trainer/Q Targets Max                   57.4542
trainer/Q Targets Min                 -218.162
trainer/Log Pis Mean                     1.93324
trainer/Log Pis Std                      1.59186
trainer/Log Pis Max                      6.1122
trainer/Log Pis Min                     -4.64467
trainer/policy/mean Mean                -0.572457
trainer/policy/mean Std                  0.603069
trainer/policy/mean Max                  0.931798
trainer/policy/mean Min                 -0.981752
trainer/policy/normal/std Mean           0.586655
trainer/policy/normal/std Std            0.0644206
trainer/policy/normal/std Max            0.730227
trainer/policy/normal/std Min            0.489644
trainer/policy/normal/log_std Mean      -0.539256
trainer/policy/normal/log_std Std        0.108559
trainer/policy/normal/log_std Max       -0.3144
trainer/policy/normal/log_std Min       -0.714077
trainer/Alpha                            0.0297178
trainer/Alpha Loss                      -0.23472
exploration/num steps total         258000
exploration/num paths total           1290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.835732
exploration/Rewards Std                  1.59009
exploration/Rewards Max                 -5.91747e-91
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -167.146
exploration/Returns Std                 95.2401
exploration/Returns Max                -19.3288
exploration/Returns Min               -424.665
exploration/Actions Mean                -0.654649
exploration/Actions Std                  0.524261
exploration/Actions Max                  0.994146
exploration/Actions Min                 -0.99923
exploration/Num Paths                   10
exploration/Average Returns           -167.146
evaluation/num steps total          617472
evaluation/num paths total            3072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67245
evaluation/Rewards Std                   0.884348
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.16
evaluation/Returns Std                 177.751
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.693924
evaluation/Actions Std                   0.282707
evaluation/Actions Max                  -0.38793
evaluation/Actions Min                  -0.975263
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.16
time/data storing (s)                    0.0264824
time/evaluation sampling (s)            18.3283
time/exploration sampling (s)            7.0581
time/logging (s)                         0.0296821
time/sac training (s)                   34.9461
time/saving (s)                          0.0251473
time/training (s)                        0.000141859
time/epoch (s)                          60.4139
time/total (s)                       25098.5
Epoch                                  127
----------------------------------  ----------------
2020-11-09 22:06:27.588249 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 128 finished
----------------------------------  -----------------
replay_buffer/size                  260000
trainer/num train calls             129000
trainer/QF1 Loss                        52.616
trainer/QF2 Loss                        52.5471
trainer/Policy Loss                     58.2313
trainer/Q1 Predictions Mean            -57.9431
trainer/Q1 Predictions Std              71.8459
trainer/Q1 Predictions Max              82.1824
trainer/Q1 Predictions Min            -240.864
trainer/Q2 Predictions Mean            -58.0084
trainer/Q2 Predictions Std              71.8476
trainer/Q2 Predictions Max              82.5018
trainer/Q2 Predictions Min            -241.544
trainer/Q Targets Mean                 -57.8754
trainer/Q Targets Std                   72.5601
trainer/Q Targets Max                   81.971
trainer/Q Targets Min                 -240.19
trainer/Log Pis Mean                     1.87594
trainer/Log Pis Std                      1.84407
trainer/Log Pis Max                      6.27433
trainer/Log Pis Min                     -4.52151
trainer/policy/mean Mean                -0.571657
trainer/policy/mean Std                  0.595553
trainer/policy/mean Max                  0.930266
trainer/policy/mean Min                 -0.983581
trainer/policy/normal/std Mean           0.590079
trainer/policy/normal/std Std            0.0687237
trainer/policy/normal/std Max            0.769403
trainer/policy/normal/std Min            0.474939
trainer/policy/normal/log_std Mean      -0.534192
trainer/policy/normal/log_std Std        0.115336
trainer/policy/normal/log_std Max       -0.26214
trainer/policy/normal/log_std Min       -0.744568
trainer/Alpha                            0.0292617
trainer/Alpha Loss                      -0.438132
exploration/num steps total         260000
exploration/num paths total           1300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.1112
exploration/Rewards Std                  1.63166
exploration/Rewards Max                 -1.37431e-137
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -222.24
exploration/Returns Std                168.938
exploration/Returns Max                -12.7748
exploration/Returns Min               -530.701
exploration/Actions Mean                -0.5485
exploration/Actions Std                  0.611531
exploration/Actions Max                  0.988124
exploration/Actions Min                 -0.998882
exploration/Num Paths                   10
exploration/Average Returns           -222.24
evaluation/num steps total          622296
evaluation/num paths total            3096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.32359
evaluation/Rewards Std                   1.18397
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1070.04
evaluation/Returns Std                 237.841
evaluation/Returns Max                -655.242
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.688328
evaluation/Actions Std                   0.292702
evaluation/Actions Max                  -0.349496
evaluation/Actions Min                  -0.975995
evaluation/Num Paths                    24
evaluation/Average Returns           -1070.04
time/data storing (s)                    0.0269679
time/evaluation sampling (s)            14.3276
time/exploration sampling (s)            5.96635
time/logging (s)                         0.022944
time/sac training (s)                   33.7142
time/saving (s)                          0.0269938
time/training (s)                        0.000150166
time/epoch (s)                          54.0851
time/total (s)                       25153.9
Epoch                                  128
----------------------------------  -----------------
2020-11-09 22:07:27.597928 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 129 finished
----------------------------------  ----------------
replay_buffer/size                  262000
trainer/num train calls             130000
trainer/QF1 Loss                        28.9031
trainer/QF2 Loss                        28.8002
trainer/Policy Loss                     57.7268
trainer/Q1 Predictions Mean            -57.4262
trainer/Q1 Predictions Std              72.5376
trainer/Q1 Predictions Max              82.5348
trainer/Q1 Predictions Min            -241.6
trainer/Q2 Predictions Mean            -57.581
trainer/Q2 Predictions Std              72.5603
trainer/Q2 Predictions Max              82.4881
trainer/Q2 Predictions Min            -242.242
trainer/Q Targets Mean                 -58.1886
trainer/Q Targets Std                   73.6181
trainer/Q Targets Max                   83.0943
trainer/Q Targets Min                 -240.991
trainer/Log Pis Mean                     2.07439
trainer/Log Pis Std                      1.79144
trainer/Log Pis Max                      6.77722
trainer/Log Pis Min                     -6.10241
trainer/policy/mean Mean                -0.597492
trainer/policy/mean Std                  0.586731
trainer/policy/mean Max                  0.943201
trainer/policy/mean Min                 -0.98338
trainer/policy/normal/std Mean           0.589608
trainer/policy/normal/std Std            0.0663036
trainer/policy/normal/std Max            0.751056
trainer/policy/normal/std Min            0.481553
trainer/policy/normal/log_std Mean      -0.534514
trainer/policy/normal/log_std Std        0.111063
trainer/policy/normal/log_std Max       -0.286274
trainer/policy/normal/log_std Min       -0.730739
trainer/Alpha                            0.0285959
trainer/Alpha Loss                       0.264419
exploration/num steps total         262000
exploration/num paths total           1310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.995129
exploration/Rewards Std                  1.52079
exploration/Rewards Max                 -3.32689e-91
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -199.026
exploration/Returns Std                119.794
exploration/Returns Max                -66.9222
exploration/Returns Min               -398.78
exploration/Actions Mean                -0.603677
exploration/Actions Std                  0.583741
exploration/Actions Max                  0.99416
exploration/Actions Min                 -0.998959
exploration/Num Paths                   10
exploration/Average Returns           -199.026
evaluation/num steps total          627120
evaluation/num paths total            3120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.64602
evaluation/Rewards Std                   1.29009
evaluation/Rewards Max                  -1.59682e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1134.85
evaluation/Returns Std                 258.408
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.716337
evaluation/Actions Std                   0.270689
evaluation/Actions Max                  -0.424463
evaluation/Actions Min                  -0.999944
evaluation/Num Paths                    24
evaluation/Average Returns           -1134.85
time/data storing (s)                    0.0271842
time/evaluation sampling (s)            17.3428
time/exploration sampling (s)            7.02318
time/logging (s)                         0.0254765
time/sac training (s)                   34.2185
time/saving (s)                          0.0266214
time/training (s)                        0.000141128
time/epoch (s)                          58.6638
time/total (s)                       25213.9
Epoch                                  129
----------------------------------  ----------------
2020-11-09 22:08:27.735959 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 130 finished
----------------------------------  ----------------
replay_buffer/size                  264000
trainer/num train calls             131000
trainer/QF1 Loss                        33.0588
trainer/QF2 Loss                        35.194
trainer/Policy Loss                     56.8528
trainer/Q1 Predictions Mean            -56.7645
trainer/Q1 Predictions Std              70.5691
trainer/Q1 Predictions Max              65.2293
trainer/Q1 Predictions Min            -222.182
trainer/Q2 Predictions Mean            -56.6382
trainer/Q2 Predictions Std              70.4457
trainer/Q2 Predictions Max              65.481
trainer/Q2 Predictions Min            -222.494
trainer/Q Targets Mean                 -56.7792
trainer/Q Targets Std                   71.4964
trainer/Q Targets Max                   66.3666
trainer/Q Targets Min                 -221.24
trainer/Log Pis Mean                     1.84754
trainer/Log Pis Std                      1.6599
trainer/Log Pis Max                      6.46395
trainer/Log Pis Min                     -4.23333
trainer/policy/mean Mean                -0.406272
trainer/policy/mean Std                  0.717011
trainer/policy/mean Max                  0.970174
trainer/policy/mean Min                 -0.980259
trainer/policy/normal/std Mean           0.572218
trainer/policy/normal/std Std            0.0543841
trainer/policy/normal/std Max            0.711287
trainer/policy/normal/std Min            0.475515
trainer/policy/normal/log_std Mean      -0.562655
trainer/policy/normal/log_std Std        0.0935383
trainer/policy/normal/log_std Max       -0.34068
trainer/policy/normal/log_std Min       -0.743358
trainer/Alpha                            0.0287569
trainer/Alpha Loss                      -0.541066
exploration/num steps total         264000
exploration/num paths total           1320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02627
exploration/Rewards Std                  1.51483
exploration/Rewards Max                 -1.61386e-54
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -205.254
exploration/Returns Std                100.991
exploration/Returns Max                -67.8582
exploration/Returns Min               -383.242
exploration/Actions Mean                -0.376534
exploration/Actions Std                  0.745434
exploration/Actions Max                  0.993687
exploration/Actions Min                 -0.998965
exploration/Num Paths                   10
exploration/Average Returns           -205.254
evaluation/num steps total          631944
evaluation/num paths total            3144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56504
evaluation/Rewards Std                   0.989169
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1118.57
evaluation/Returns Std                 198.505
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.453318
evaluation/Actions Std                   0.535185
evaluation/Actions Max                   0.655346
evaluation/Actions Min                  -0.971591
evaluation/Num Paths                    24
evaluation/Average Returns           -1118.57
time/data storing (s)                    0.0234956
time/evaluation sampling (s)            17.2186
time/exploration sampling (s)            7.14105
time/logging (s)                         0.0209917
time/sac training (s)                   34.2994
time/saving (s)                          0.0277472
time/training (s)                        0.000135384
time/epoch (s)                          58.7314
time/total (s)                       25274
Epoch                                  130
----------------------------------  ----------------
2020-11-09 22:09:27.486709 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 131 finished
----------------------------------  ----------------
replay_buffer/size                  266000
trainer/num train calls             132000
trainer/QF1 Loss                        80.2105
trainer/QF2 Loss                        77.4437
trainer/Policy Loss                     49.8099
trainer/Q1 Predictions Mean            -49.5635
trainer/Q1 Predictions Std              70.878
trainer/Q1 Predictions Max             124.808
trainer/Q1 Predictions Min            -220.152
trainer/Q2 Predictions Mean            -49.6937
trainer/Q2 Predictions Std              70.9576
trainer/Q2 Predictions Max             124.355
trainer/Q2 Predictions Min            -220.451
trainer/Q Targets Mean                 -49.6026
trainer/Q Targets Std                   71.1646
trainer/Q Targets Max                  124.729
trainer/Q Targets Min                 -219.418
trainer/Log Pis Mean                     2.01557
trainer/Log Pis Std                      1.6096
trainer/Log Pis Max                      5.55736
trainer/Log Pis Min                     -3.91398
trainer/policy/mean Mean                -0.40555
trainer/policy/mean Std                  0.723568
trainer/policy/mean Max                  0.959151
trainer/policy/mean Min                 -0.981854
trainer/policy/normal/std Mean           0.573102
trainer/policy/normal/std Std            0.0576667
trainer/policy/normal/std Max            0.708639
trainer/policy/normal/std Min            0.481021
trainer/policy/normal/log_std Mean      -0.561652
trainer/policy/normal/log_std Std        0.0991318
trainer/policy/normal/log_std Max       -0.34441
trainer/policy/normal/log_std Min       -0.731843
trainer/Alpha                            0.028884
trainer/Alpha Loss                       0.055181
exploration/num steps total         266000
exploration/num paths total           1330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.06322
exploration/Rewards Std                  1.60787
exploration/Rewards Max                 -1.18598e-71
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -212.643
exploration/Returns Std                151.175
exploration/Returns Max                -42.4125
exploration/Returns Min               -581.161
exploration/Actions Mean                -0.386402
exploration/Actions Std                  0.765355
exploration/Actions Max                  0.997938
exploration/Actions Min                 -0.998889
exploration/Num Paths                   10
exploration/Average Returns           -212.643
evaluation/num steps total          636768
evaluation/num paths total            3168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   3.23623e-11
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.44732
evaluation/Actions Std                   0.524078
evaluation/Actions Max                   0.166161
evaluation/Actions Min                  -0.971425
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0263509
time/evaluation sampling (s)            17.3451
time/exploration sampling (s)            7.3223
time/logging (s)                         0.0211705
time/sac training (s)                   33.6326
time/saving (s)                          0.0268085
time/training (s)                        0.000145024
time/epoch (s)                          58.3745
time/total (s)                       25333.7
Epoch                                  131
----------------------------------  ----------------
2020-11-09 22:10:27.009466 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 132 finished
----------------------------------  -----------------
replay_buffer/size                  268000
trainer/num train calls             133000
trainer/QF1 Loss                       142.86
trainer/QF2 Loss                       145.539
trainer/Policy Loss                     59.8464
trainer/Q1 Predictions Mean            -59.5806
trainer/Q1 Predictions Std              70.7708
trainer/Q1 Predictions Max             125.379
trainer/Q1 Predictions Min            -220.84
trainer/Q2 Predictions Mean            -59.5599
trainer/Q2 Predictions Std              70.7965
trainer/Q2 Predictions Max             125.295
trainer/Q2 Predictions Min            -221.032
trainer/Q Targets Mean                 -59.3544
trainer/Q Targets Std                   70.8098
trainer/Q Targets Max                  124.933
trainer/Q Targets Min                 -219.749
trainer/Log Pis Mean                     1.94191
trainer/Log Pis Std                      1.81954
trainer/Log Pis Max                      5.50219
trainer/Log Pis Min                     -4.89844
trainer/policy/mean Mean                -0.424339
trainer/policy/mean Std                  0.725555
trainer/policy/mean Max                  0.974184
trainer/policy/mean Min                 -0.982274
trainer/policy/normal/std Mean           0.578396
trainer/policy/normal/std Std            0.0599942
trainer/policy/normal/std Max            0.723325
trainer/policy/normal/std Min            0.473294
trainer/policy/normal/log_std Mean      -0.552736
trainer/policy/normal/log_std Std        0.101701
trainer/policy/normal/log_std Max       -0.323896
trainer/policy/normal/log_std Min       -0.748039
trainer/Alpha                            0.0289667
trainer/Alpha Loss                      -0.205729
exploration/num steps total         268000
exploration/num paths total           1340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.20432
exploration/Rewards Std                  1.6519
exploration/Rewards Max                 -6.77167e-225
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -240.863
exploration/Returns Std                131.661
exploration/Returns Max                -87.1751
exploration/Returns Min               -492.947
exploration/Actions Mean                -0.391646
exploration/Actions Std                  0.733117
exploration/Actions Max                  0.996381
exploration/Actions Min                 -0.999198
exploration/Num Paths                   10
exploration/Average Returns           -240.863
evaluation/num steps total          641592
evaluation/num paths total            3192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67679
evaluation/Rewards Std                   0.872856
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1141.04
evaluation/Returns Std                 175.442
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.48634
evaluation/Actions Std                   0.49422
evaluation/Actions Max                   0.0996068
evaluation/Actions Min                  -0.973525
evaluation/Num Paths                    24
evaluation/Average Returns           -1141.04
time/data storing (s)                    0.0251255
time/evaluation sampling (s)            17.1214
time/exploration sampling (s)            6.96993
time/logging (s)                         0.0295346
time/sac training (s)                   33.9909
time/saving (s)                          0.026508
time/training (s)                        0.000150433
time/epoch (s)                          58.1635
time/total (s)                       25393.2
Epoch                                  132
----------------------------------  -----------------
2020-11-09 22:11:26.231117 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 133 finished
----------------------------------  -----------------
replay_buffer/size                  270000
trainer/num train calls             134000
trainer/QF1 Loss                        12.7905
trainer/QF2 Loss                        11.8485
trainer/Policy Loss                     60.0134
trainer/Q1 Predictions Mean            -59.7117
trainer/Q1 Predictions Std              72.7479
trainer/Q1 Predictions Max             100.689
trainer/Q1 Predictions Min            -220.902
trainer/Q2 Predictions Mean            -59.8894
trainer/Q2 Predictions Std              72.8939
trainer/Q2 Predictions Max             100.706
trainer/Q2 Predictions Min            -221.103
trainer/Q Targets Mean                 -59.9236
trainer/Q Targets Std                   73.3941
trainer/Q Targets Max                  102.314
trainer/Q Targets Min                 -219.936
trainer/Log Pis Mean                     2.26949
trainer/Log Pis Std                      1.98416
trainer/Log Pis Max                      7.32431
trainer/Log Pis Min                     -4.5367
trainer/policy/mean Mean                -0.619257
trainer/policy/mean Std                  0.582258
trainer/policy/mean Max                  0.929331
trainer/policy/mean Min                 -0.99025
trainer/policy/normal/std Mean           0.582437
trainer/policy/normal/std Std            0.0630719
trainer/policy/normal/std Max            0.731247
trainer/policy/normal/std Min            0.485556
trainer/policy/normal/log_std Mean      -0.546267
trainer/policy/normal/log_std Std        0.106487
trainer/policy/normal/log_std Max       -0.313004
trainer/policy/normal/log_std Min       -0.722461
trainer/Alpha                            0.02932
trainer/Alpha Loss                       0.951164
exploration/num steps total         270000
exploration/num paths total           1350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.26179
exploration/Rewards Std                  1.70613
exploration/Rewards Max                 -1.04553e-180
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -252.359
exploration/Returns Std                171.409
exploration/Returns Max                -99.684
exploration/Returns Min               -587.346
exploration/Actions Mean                -0.692493
exploration/Actions Std                  0.533936
exploration/Actions Max                  0.998694
exploration/Actions Min                 -0.999991
exploration/Num Paths                   10
exploration/Average Returns           -252.359
evaluation/num steps total          646416
evaluation/num paths total            3216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.52215e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.756507
evaluation/Actions Std                   0.214737
evaluation/Actions Max                  -0.541689
evaluation/Actions Min                  -0.971467
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.029211
time/evaluation sampling (s)            17.3301
time/exploration sampling (s)            6.95163
time/logging (s)                         0.0262242
time/sac training (s)                   33.4716
time/saving (s)                          0.0256082
time/training (s)                        0.000146414
time/epoch (s)                          57.8345
time/total (s)                       25452.4
Epoch                                  133
----------------------------------  -----------------
2020-11-09 22:12:26.519921 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 134 finished
----------------------------------  -----------------
replay_buffer/size                  272000
trainer/num train calls             135000
trainer/QF1 Loss                        42.6121
trainer/QF2 Loss                        41.6943
trainer/Policy Loss                     59.9026
trainer/Q1 Predictions Mean            -59.7507
trainer/Q1 Predictions Std              69.4458
trainer/Q1 Predictions Max              57.9622
trainer/Q1 Predictions Min            -218.196
trainer/Q2 Predictions Mean            -59.7284
trainer/Q2 Predictions Std              69.4921
trainer/Q2 Predictions Max              58.299
trainer/Q2 Predictions Min            -216.306
trainer/Q Targets Mean                 -60.1388
trainer/Q Targets Std                   70.1387
trainer/Q Targets Max                   58.2571
trainer/Q Targets Min                 -217.274
trainer/Log Pis Mean                     2.35972
trainer/Log Pis Std                      1.69203
trainer/Log Pis Max                      9.08455
trainer/Log Pis Min                     -3.00599
trainer/policy/mean Mean                -0.545101
trainer/policy/mean Std                  0.650702
trainer/policy/mean Max                  0.957418
trainer/policy/mean Min                 -0.999343
trainer/policy/normal/std Mean           0.565315
trainer/policy/normal/std Std            0.0621933
trainer/policy/normal/std Max            0.706843
trainer/policy/normal/std Min            0.451829
trainer/policy/normal/log_std Mean      -0.576324
trainer/policy/normal/log_std Std        0.108671
trainer/policy/normal/log_std Max       -0.346947
trainer/policy/normal/log_std Min       -0.794451
trainer/Alpha                            0.0298107
trainer/Alpha Loss                       1.26364
exploration/num steps total         272000
exploration/num paths total           1360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00801
exploration/Rewards Std                  1.54377
exploration/Rewards Max                 -2.53089e-108
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -201.601
exploration/Returns Std                173.953
exploration/Returns Max                -27.7894
exploration/Returns Min               -517.198
exploration/Actions Mean                -0.743722
exploration/Actions Std                  0.390519
exploration/Actions Max                  0.974979
exploration/Actions Min                 -0.999402
exploration/Num Paths                   10
exploration/Average Returns           -201.601
evaluation/num steps total          651240
evaluation/num paths total            3240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.11162
evaluation/Rewards Std                   1.26837
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1027.44
evaluation/Returns Std                 254.436
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.720263
evaluation/Actions Std                   0.258127
evaluation/Actions Max                  -0.418746
evaluation/Actions Min                  -0.978644
evaluation/Num Paths                    24
evaluation/Average Returns           -1027.44
time/data storing (s)                    0.0270142
time/evaluation sampling (s)            17.8609
time/exploration sampling (s)            6.90483
time/logging (s)                         0.0223294
time/sac training (s)                   34.0153
time/saving (s)                          0.025824
time/training (s)                        0.000137964
time/epoch (s)                          58.8563
time/total (s)                       25512.6
Epoch                                  134
----------------------------------  -----------------
2020-11-09 22:13:28.204300 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 135 finished
----------------------------------  -----------------
replay_buffer/size                  274000
trainer/num train calls             136000
trainer/QF1 Loss                        96.4185
trainer/QF2 Loss                       100.215
trainer/Policy Loss                     53.0351
trainer/Q1 Predictions Mean            -52.7834
trainer/Q1 Predictions Std              69.3092
trainer/Q1 Predictions Max              71.0528
trainer/Q1 Predictions Min            -198.849
trainer/Q2 Predictions Mean            -52.8215
trainer/Q2 Predictions Std              69.3998
trainer/Q2 Predictions Max              70.9346
trainer/Q2 Predictions Min            -198.622
trainer/Q Targets Mean                 -52.6645
trainer/Q Targets Std                   69.9694
trainer/Q Targets Max                   71.4194
trainer/Q Targets Min                 -200.068
trainer/Log Pis Mean                     1.8474
trainer/Log Pis Std                      1.73228
trainer/Log Pis Max                      5.63162
trainer/Log Pis Min                     -3.87188
trainer/policy/mean Mean                -0.466726
trainer/policy/mean Std                  0.671382
trainer/policy/mean Max                  0.97026
trainer/policy/mean Min                 -0.983484
trainer/policy/normal/std Mean           0.569509
trainer/policy/normal/std Std            0.0576255
trainer/policy/normal/std Max            0.705612
trainer/policy/normal/std Min            0.466292
trainer/policy/normal/log_std Mean      -0.568009
trainer/policy/normal/log_std Std        0.0998695
trainer/policy/normal/log_std Max       -0.34869
trainer/policy/normal/log_std Min       -0.762944
trainer/Alpha                            0.0297609
trainer/Alpha Loss                      -0.536311
exploration/num steps total         274000
exploration/num paths total           1370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.731745
exploration/Rewards Std                  1.38313
exploration/Rewards Max                 -3.37029e-157
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.349
exploration/Returns Std                122.264
exploration/Returns Max                -16.6546
exploration/Returns Min               -417.266
exploration/Actions Mean                -0.493422
exploration/Actions Std                  0.682969
exploration/Actions Max                  0.99494
exploration/Actions Min                 -0.999939
exploration/Num Paths                   10
exploration/Average Returns           -146.349
evaluation/num steps total          656064
evaluation/num paths total            3264
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.70853
evaluation/Rewards Std                   1.30638
evaluation/Rewards Max                  -6.42087e-15
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1147.41
evaluation/Returns Std                 262.047
evaluation/Returns Max                 -10.1007
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.576982
evaluation/Actions Std                   0.401299
evaluation/Actions Max                   0.326935
evaluation/Actions Min                  -0.979643
evaluation/Num Paths                    24
evaluation/Average Returns           -1147.41
time/data storing (s)                    0.025829
time/evaluation sampling (s)            17.5814
time/exploration sampling (s)            7.29243
time/logging (s)                         0.0242186
time/sac training (s)                   35.3423
time/saving (s)                          0.03024
time/training (s)                        0.000123276
time/epoch (s)                          60.2965
time/total (s)                       25574.3
Epoch                                  135
----------------------------------  -----------------
2020-11-09 22:14:27.440494 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 136 finished
----------------------------------  ----------------
replay_buffer/size                  276000
trainer/num train calls             137000
trainer/QF1 Loss                        28.9917
trainer/QF2 Loss                        31.0197
trainer/Policy Loss                     60.8572
trainer/Q1 Predictions Mean            -60.5414
trainer/Q1 Predictions Std              71.7026
trainer/Q1 Predictions Max              56.3739
trainer/Q1 Predictions Min            -221.193
trainer/Q2 Predictions Mean            -60.5651
trainer/Q2 Predictions Std              71.6304
trainer/Q2 Predictions Max              55.8721
trainer/Q2 Predictions Min            -221.865
trainer/Q Targets Mean                 -61.0233
trainer/Q Targets Std                   72.2894
trainer/Q Targets Max                   55.1517
trainer/Q Targets Min                 -220.879
trainer/Log Pis Mean                     2.11787
trainer/Log Pis Std                      1.6371
trainer/Log Pis Max                      7.52882
trainer/Log Pis Min                     -3.36575
trainer/policy/mean Mean                -0.48199
trainer/policy/mean Std                  0.669309
trainer/policy/mean Max                  0.964413
trainer/policy/mean Min                 -0.999066
trainer/policy/normal/std Mean           0.581547
trainer/policy/normal/std Std            0.070576
trainer/policy/normal/std Max            0.734343
trainer/policy/normal/std Min            0.46578
trainer/policy/normal/log_std Mean      -0.549249
trainer/policy/normal/log_std Std        0.119173
trainer/policy/normal/log_std Max       -0.308779
trainer/policy/normal/log_std Min       -0.764042
trainer/Alpha                            0.0300042
trainer/Alpha Loss                       0.413299
exploration/num steps total         276000
exploration/num paths total           1380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.826787
exploration/Rewards Std                  1.48891
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -165.357
exploration/Returns Std                 91.9977
exploration/Returns Max                -41.0752
exploration/Returns Min               -280.767
exploration/Actions Mean                -0.58171
exploration/Actions Std                  0.576159
exploration/Actions Max                  0.989953
exploration/Actions Min                 -0.999234
exploration/Num Paths                   10
exploration/Average Returns           -165.357
evaluation/num steps total          660888
evaluation/num paths total            3288
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.591403
evaluation/Actions Std                   0.393875
evaluation/Actions Max                  -0.181171
evaluation/Actions Min                  -0.976301
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.0218685
time/evaluation sampling (s)            17.2136
time/exploration sampling (s)            7.38997
time/logging (s)                         0.0241254
time/sac training (s)                   33.1865
time/saving (s)                          0.0233866
time/training (s)                        0.000123016
time/epoch (s)                          57.8596
time/total (s)                       25633.5
Epoch                                  136
----------------------------------  ----------------
2020-11-09 22:15:20.636605 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 137 finished
----------------------------------  -----------------
replay_buffer/size                  278000
trainer/num train calls             138000
trainer/QF1 Loss                       199.484
trainer/QF2 Loss                       188.333
trainer/Policy Loss                     57.2383
trainer/Q1 Predictions Mean            -56.889
trainer/Q1 Predictions Std              73.785
trainer/Q1 Predictions Max              77.5021
trainer/Q1 Predictions Min            -219.638
trainer/Q2 Predictions Mean            -57.0689
trainer/Q2 Predictions Std              73.9568
trainer/Q2 Predictions Max              77.2862
trainer/Q2 Predictions Min            -219.572
trainer/Q Targets Mean                 -56.3699
trainer/Q Targets Std                   74.7157
trainer/Q Targets Max                   76.486
trainer/Q Targets Min                 -218.624
trainer/Log Pis Mean                     1.86661
trainer/Log Pis Std                      1.55526
trainer/Log Pis Max                      5.85311
trainer/Log Pis Min                     -3.06917
trainer/policy/mean Mean                -0.482022
trainer/policy/mean Std                  0.663968
trainer/policy/mean Max                  0.96453
trainer/policy/mean Min                 -0.995867
trainer/policy/normal/std Mean           0.581885
trainer/policy/normal/std Std            0.0592923
trainer/policy/normal/std Max            0.723669
trainer/policy/normal/std Min            0.479167
trainer/policy/normal/log_std Mean      -0.546576
trainer/policy/normal/log_std Std        0.100466
trainer/policy/normal/log_std Max       -0.323421
trainer/policy/normal/log_std Min       -0.735707
trainer/Alpha                            0.0304988
trainer/Alpha Loss                      -0.465538
exploration/num steps total         278000
exploration/num paths total           1390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.775511
exploration/Rewards Std                  1.48398
exploration/Rewards Max                 -3.66099e-215
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -155.102
exploration/Returns Std                156.136
exploration/Returns Max                -16.6924
exploration/Returns Min               -468.759
exploration/Actions Mean                -0.396962
exploration/Actions Std                  0.741239
exploration/Actions Max                  0.996623
exploration/Actions Min                 -0.999164
exploration/Num Paths                   10
exploration/Average Returns           -155.102
evaluation/num steps total          665712
evaluation/num paths total            3312
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56738
evaluation/Rewards Std                   0.983127
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1119.04
evaluation/Returns Std                 197.452
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.530603
evaluation/Actions Std                   0.443488
evaluation/Actions Max                   0.123583
evaluation/Actions Min                  -0.971851
evaluation/Num Paths                    24
evaluation/Average Returns           -1119.04
time/data storing (s)                    0.0211121
time/evaluation sampling (s)            15.729
time/exploration sampling (s)            6.33959
time/logging (s)                         0.0251265
time/sac training (s)                   29.8267
time/saving (s)                          0.0217717
time/training (s)                        0.000118389
time/epoch (s)                          51.9634
time/total (s)                       25686.7
Epoch                                  137
----------------------------------  -----------------
2020-11-09 22:16:10.658836 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 138 finished
----------------------------------  ---------------
replay_buffer/size                  280000
trainer/num train calls             139000
trainer/QF1 Loss                        50.7932
trainer/QF2 Loss                        54.3063
trainer/Policy Loss                     49.0774
trainer/Q1 Predictions Mean            -48.8985
trainer/Q1 Predictions Std              65.6531
trainer/Q1 Predictions Max             116.43
trainer/Q1 Predictions Min            -200.704
trainer/Q2 Predictions Mean            -48.8587
trainer/Q2 Predictions Std              65.5655
trainer/Q2 Predictions Max             115.944
trainer/Q2 Predictions Min            -201.096
trainer/Q Targets Mean                 -48.9601
trainer/Q Targets Std                   66.228
trainer/Q Targets Max                  114.899
trainer/Q Targets Min                 -200.368
trainer/Log Pis Mean                     2.0986
trainer/Log Pis Std                      1.97944
trainer/Log Pis Max                      7.03646
trainer/Log Pis Min                     -7.99955
trainer/policy/mean Mean                -0.34201
trainer/policy/mean Std                  0.756131
trainer/policy/mean Max                  0.982219
trainer/policy/mean Min                 -0.988972
trainer/policy/normal/std Mean           0.566082
trainer/policy/normal/std Std            0.0625459
trainer/policy/normal/std Max            0.725487
trainer/policy/normal/std Min            0.464552
trainer/policy/normal/log_std Mean      -0.574919
trainer/policy/normal/log_std Std        0.107762
trainer/policy/normal/log_std Max       -0.320912
trainer/policy/normal/log_std Min       -0.766681
trainer/Alpha                            0.0304717
trainer/Alpha Loss                       0.344196
exploration/num steps total         280000
exploration/num paths total           1400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.52416
exploration/Rewards Std                  1.55675
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -304.831
exploration/Returns Std                166.544
exploration/Returns Max                -46.9999
exploration/Returns Min               -535.094
exploration/Actions Mean                -0.20321
exploration/Actions Std                  0.808554
exploration/Actions Max                  0.997989
exploration/Actions Min                 -0.998926
exploration/Num Paths                   10
exploration/Average Returns           -304.831
evaluation/num steps total          670536
evaluation/num paths total            3336
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95958
evaluation/Rewards Std                   0.55521
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.88
evaluation/Returns Std                 111.597
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.336772
evaluation/Actions Std                   0.638003
evaluation/Actions Max                   0.505023
evaluation/Actions Min                  -0.974826
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.88
time/data storing (s)                    0.0232849
time/evaluation sampling (s)            14.1584
time/exploration sampling (s)            5.46857
time/logging (s)                         0.0166138
time/sac training (s)                   29.1314
time/saving (s)                          0.026687
time/training (s)                        0.00013055
time/epoch (s)                          48.8251
time/total (s)                       25736.7
Epoch                                  138
----------------------------------  ---------------
2020-11-09 22:16:59.716904 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 139 finished
----------------------------------  -----------------
replay_buffer/size                  282000
trainer/num train calls             140000
trainer/QF1 Loss                         7.31355
trainer/QF2 Loss                         6.76267
trainer/Policy Loss                     50.4739
trainer/Q1 Predictions Mean            -50.2158
trainer/Q1 Predictions Std              73.9874
trainer/Q1 Predictions Max             101.899
trainer/Q1 Predictions Min            -222.402
trainer/Q2 Predictions Mean            -50.3077
trainer/Q2 Predictions Std              74.0806
trainer/Q2 Predictions Max             101.875
trainer/Q2 Predictions Min            -222.836
trainer/Q Targets Mean                 -50.7859
trainer/Q Targets Std                   74.7543
trainer/Q Targets Max                  101.244
trainer/Q Targets Min                 -221.744
trainer/Log Pis Mean                     2.08043
trainer/Log Pis Std                      1.83015
trainer/Log Pis Max                      9.25323
trainer/Log Pis Min                     -4.3089
trainer/policy/mean Mean                -0.542485
trainer/policy/mean Std                  0.637016
trainer/policy/mean Max                  0.943363
trainer/policy/mean Min                 -0.998695
trainer/policy/normal/std Mean           0.585301
trainer/policy/normal/std Std            0.0646482
trainer/policy/normal/std Max            0.749969
trainer/policy/normal/std Min            0.487067
trainer/policy/normal/log_std Mean      -0.54155
trainer/policy/normal/log_std Std        0.108036
trainer/policy/normal/log_std Max       -0.287723
trainer/policy/normal/log_std Min       -0.719354
trainer/Alpha                            0.0308228
trainer/Alpha Loss                       0.27985
exploration/num steps total         282000
exploration/num paths total           1410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.582151
exploration/Rewards Std                  1.37367
exploration/Rewards Max                 -1.03052e-225
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -116.43
exploration/Returns Std                 58.2613
exploration/Returns Max                -50.6919
exploration/Returns Min               -249.553
exploration/Actions Mean                -0.598464
exploration/Actions Std                  0.569953
exploration/Actions Max                  0.996732
exploration/Actions Min                 -0.999286
exploration/Num Paths                   10
exploration/Average Returns           -116.43
evaluation/num steps total          675360
evaluation/num paths total            3360
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.4497
evaluation/Rewards Std                   1.08807
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1095.39
evaluation/Returns Std                 218.259
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.718496
evaluation/Actions Std                   0.259795
evaluation/Actions Max                  -0.416087
evaluation/Actions Min                  -0.971499
evaluation/Num Paths                    24
evaluation/Average Returns           -1095.39
time/data storing (s)                    0.0240566
time/evaluation sampling (s)            13.4762
time/exploration sampling (s)            5.39569
time/logging (s)                         0.0176436
time/sac training (s)                   28.9509
time/saving (s)                          0.0222662
time/training (s)                        0.000132841
time/epoch (s)                          47.8869
time/total (s)                       25785.7
Epoch                                  139
----------------------------------  -----------------
2020-11-09 22:17:49.414781 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 140 finished
----------------------------------  -----------------
replay_buffer/size                  284000
trainer/num train calls             141000
trainer/QF1 Loss                       273.595
trainer/QF2 Loss                       274.612
trainer/Policy Loss                     58.6661
trainer/Q1 Predictions Mean            -58.4034
trainer/Q1 Predictions Std              68.7113
trainer/Q1 Predictions Max              81.2868
trainer/Q1 Predictions Min            -223.213
trainer/Q2 Predictions Mean            -58.3309
trainer/Q2 Predictions Std              68.7576
trainer/Q2 Predictions Max              81.0005
trainer/Q2 Predictions Min            -223.454
trainer/Q Targets Mean                 -57.6739
trainer/Q Targets Std                   69.19
trainer/Q Targets Max                   81.0099
trainer/Q Targets Min                 -218.184
trainer/Log Pis Mean                     2.1217
trainer/Log Pis Std                      1.64111
trainer/Log Pis Max                      5.84487
trainer/Log Pis Min                     -4.3905
trainer/policy/mean Mean                -0.558833
trainer/policy/mean Std                  0.625594
trainer/policy/mean Max                  0.950548
trainer/policy/mean Min                 -0.983863
trainer/policy/normal/std Mean           0.581153
trainer/policy/normal/std Std            0.0692086
trainer/policy/normal/std Max            0.764863
trainer/policy/normal/std Min            0.47477
trainer/policy/normal/log_std Mean      -0.549612
trainer/policy/normal/log_std Std        0.11633
trainer/policy/normal/log_std Max       -0.268058
trainer/policy/normal/log_std Min       -0.744924
trainer/Alpha                            0.030859
trainer/Alpha Loss                       0.423306
exploration/num steps total         284000
exploration/num paths total           1420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.53528
exploration/Rewards Std                  1.71572
exploration/Rewards Max                 -2.84699e-150
exploration/Rewards Min                 -6.11413
exploration/Returns Mean              -307.057
exploration/Returns Std                142.377
exploration/Returns Max               -103.281
exploration/Returns Min               -584.741
exploration/Actions Mean                -0.562771
exploration/Actions Std                  0.603753
exploration/Actions Max                  0.996753
exploration/Actions Min                 -0.999028
exploration/Num Paths                   10
exploration/Average Returns           -307.057
evaluation/num steps total          680184
evaluation/num paths total            3384
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.72989
evaluation/Actions Std                   0.244493
evaluation/Actions Max                  -0.477908
evaluation/Actions Min                  -0.972731
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0198038
time/evaluation sampling (s)            13.4066
time/exploration sampling (s)            5.39437
time/logging (s)                         0.0205694
time/sac training (s)                   29.5816
time/saving (s)                          0.0227467
time/training (s)                        0.000143071
time/epoch (s)                          48.4458
time/total (s)                       25835.4
Epoch                                  140
----------------------------------  -----------------
2020-11-09 22:18:39.204663 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 141 finished
----------------------------------  ----------------
replay_buffer/size                  286000
trainer/num train calls             142000
trainer/QF1 Loss                        45.3739
trainer/QF2 Loss                        45.6274
trainer/Policy Loss                     58.4723
trainer/Q1 Predictions Mean            -58.3207
trainer/Q1 Predictions Std              72.1229
trainer/Q1 Predictions Max              78.1995
trainer/Q1 Predictions Min            -182.86
trainer/Q2 Predictions Mean            -58.2548
trainer/Q2 Predictions Std              72.0932
trainer/Q2 Predictions Max              78.5942
trainer/Q2 Predictions Min            -182.282
trainer/Q Targets Mean                 -58.5618
trainer/Q Targets Std                   73.0057
trainer/Q Targets Max                   79.7024
trainer/Q Targets Min                 -184.595
trainer/Log Pis Mean                     2.28868
trainer/Log Pis Std                      1.82534
trainer/Log Pis Max                      7.35733
trainer/Log Pis Min                     -5.86323
trainer/policy/mean Mean                -0.670061
trainer/policy/mean Std                  0.528239
trainer/policy/mean Max                  0.936356
trainer/policy/mean Min                 -0.989706
trainer/policy/normal/std Mean           0.589799
trainer/policy/normal/std Std            0.0697407
trainer/policy/normal/std Max            0.7515
trainer/policy/normal/std Min            0.486812
trainer/policy/normal/log_std Mean      -0.534789
trainer/policy/normal/log_std Std        0.116023
trainer/policy/normal/log_std Max       -0.285684
trainer/policy/normal/log_std Min       -0.719877
trainer/Alpha                            0.0302894
trainer/Alpha Loss                       1.00949
exploration/num steps total         286000
exploration/num paths total           1430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.29214
exploration/Rewards Std                  1.55016
exploration/Rewards Max                 -2.22576e-60
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -258.429
exploration/Returns Std                143.685
exploration/Returns Max                -46.1313
exploration/Returns Min               -488.107
exploration/Actions Mean                -0.612989
exploration/Actions Std                  0.565017
exploration/Actions Max                  0.991227
exploration/Actions Min                 -0.999516
exploration/Num Paths                   10
exploration/Average Returns           -258.429
evaluation/num steps total          685008
evaluation/num paths total            3408
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   6.76508e-12
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.856067
evaluation/Actions Std                   0.112511
evaluation/Actions Max                  -0.733132
evaluation/Actions Min                  -0.96923
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0242027
time/evaluation sampling (s)            13.83
time/exploration sampling (s)            5.58365
time/logging (s)                         0.0247565
time/sac training (s)                   29.1218
time/saving (s)                          0.0191028
time/training (s)                        9.378e-05
time/epoch (s)                          48.6036
time/total (s)                       25885.1
Epoch                                  141
----------------------------------  ----------------
2020-11-09 22:19:26.039941 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 142 finished
----------------------------------  -----------------
replay_buffer/size                  288000
trainer/num train calls             143000
trainer/QF1 Loss                        11.5658
trainer/QF2 Loss                        12.4035
trainer/Policy Loss                     55.3556
trainer/Q1 Predictions Mean            -55.1719
trainer/Q1 Predictions Std              72.279
trainer/Q1 Predictions Max             119.332
trainer/Q1 Predictions Min            -223.44
trainer/Q2 Predictions Mean            -55.1709
trainer/Q2 Predictions Std              72.1994
trainer/Q2 Predictions Max             119.126
trainer/Q2 Predictions Min            -223.924
trainer/Q Targets Mean                 -55.9018
trainer/Q Targets Std                   73.082
trainer/Q Targets Max                  118.406
trainer/Q Targets Min                 -223.005
trainer/Log Pis Mean                     2.26526
trainer/Log Pis Std                      1.60297
trainer/Log Pis Max                      6.63394
trainer/Log Pis Min                     -4.9097
trainer/policy/mean Mean                -0.663511
trainer/policy/mean Std                  0.544893
trainer/policy/mean Max                  0.934241
trainer/policy/mean Min                 -0.985205
trainer/policy/normal/std Mean           0.576129
trainer/policy/normal/std Std            0.0597711
trainer/policy/normal/std Max            0.778747
trainer/policy/normal/std Min            0.462853
trainer/policy/normal/log_std Mean      -0.556644
trainer/policy/normal/log_std Std        0.101436
trainer/policy/normal/log_std Max       -0.250069
trainer/policy/normal/log_std Min       -0.770346
trainer/Alpha                            0.0301008
trainer/Alpha Loss                       0.929251
exploration/num steps total         288000
exploration/num paths total           1440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.85233
exploration/Rewards Std                  1.63697
exploration/Rewards Max                 -1.76821e-106
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -370.467
exploration/Returns Std                187.426
exploration/Returns Max                -57.0944
exploration/Returns Min               -621.862
exploration/Actions Mean                -0.678165
exploration/Actions Std                  0.508586
exploration/Actions Max                  0.990945
exploration/Actions Min                 -0.998983
exploration/Num Paths                   10
exploration/Average Returns           -370.467
evaluation/num steps total          689832
evaluation/num paths total            3432
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.849796
evaluation/Actions Std                   0.124869
evaluation/Actions Max                  -0.599186
evaluation/Actions Min                  -0.973256
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0200834
time/evaluation sampling (s)            12.1004
time/exploration sampling (s)            4.90309
time/logging (s)                         0.0200526
time/sac training (s)                   28.5189
time/saving (s)                          0.0176256
time/training (s)                        0.000118638
time/epoch (s)                          45.5804
time/total (s)                       25931.9
Epoch                                  142
----------------------------------  -----------------
2020-11-09 22:20:11.881959 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 143 finished
----------------------------------  -----------------
replay_buffer/size                  290000
trainer/num train calls             144000
trainer/QF1 Loss                        45.6942
trainer/QF2 Loss                        40.5789
trainer/Policy Loss                     59.2812
trainer/Q1 Predictions Mean            -58.9194
trainer/Q1 Predictions Std              76.2114
trainer/Q1 Predictions Max              84.084
trainer/Q1 Predictions Min            -248.967
trainer/Q2 Predictions Mean            -58.9801
trainer/Q2 Predictions Std              76.2162
trainer/Q2 Predictions Max              83.592
trainer/Q2 Predictions Min            -249.636
trainer/Q Targets Mean                 -59.2765
trainer/Q Targets Std                   77.1115
trainer/Q Targets Max                   82.9697
trainer/Q Targets Min                 -248.312
trainer/Log Pis Mean                     1.98779
trainer/Log Pis Std                      1.66129
trainer/Log Pis Max                      6.51639
trainer/Log Pis Min                     -3.04507
trainer/policy/mean Mean                -0.476959
trainer/policy/mean Std                  0.677197
trainer/policy/mean Max                  0.972141
trainer/policy/mean Min                 -0.990901
trainer/policy/normal/std Mean           0.571585
trainer/policy/normal/std Std            0.0644754
trainer/policy/normal/std Max            0.725904
trainer/policy/normal/std Min            0.448215
trainer/policy/normal/log_std Mean      -0.565491
trainer/policy/normal/log_std Std        0.109979
trainer/policy/normal/log_std Max       -0.320337
trainer/policy/normal/log_std Min       -0.802483
trainer/Alpha                            0.0296674
trainer/Alpha Loss                      -0.0429509
exploration/num steps total         290000
exploration/num paths total           1450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.957594
exploration/Rewards Std                  1.52613
exploration/Rewards Max                 -7.53334e-242
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.519
exploration/Returns Std                117.407
exploration/Returns Max                -27.7179
exploration/Returns Min               -410.439
exploration/Actions Mean                -0.420802
exploration/Actions Std                  0.678051
exploration/Actions Max                  0.993681
exploration/Actions Min                 -0.998854
exploration/Num Paths                   10
exploration/Average Returns           -191.519
evaluation/num steps total          694656
evaluation/num paths total            3456
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.72804
evaluation/Rewards Std                   0.918891
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1151.34
evaluation/Returns Std                 184.696
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.593114
evaluation/Actions Std                   0.381671
evaluation/Actions Max                   0.173472
evaluation/Actions Min                  -0.971676
evaluation/Num Paths                    24
evaluation/Average Returns           -1151.34
time/data storing (s)                    0.0200839
time/evaluation sampling (s)            12.1093
time/exploration sampling (s)            4.84893
time/logging (s)                         0.0173826
time/sac training (s)                   27.6882
time/saving (s)                          0.0217816
time/training (s)                        0.000110195
time/epoch (s)                          44.7058
time/total (s)                       25977.8
Epoch                                  143
----------------------------------  -----------------
2020-11-09 22:20:58.861210 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 144 finished
----------------------------------  -----------------
replay_buffer/size                  292000
trainer/num train calls             145000
trainer/QF1 Loss                       137.875
trainer/QF2 Loss                       139.9
trainer/Policy Loss                     58.2113
trainer/Q1 Predictions Mean            -57.8823
trainer/Q1 Predictions Std              74.3904
trainer/Q1 Predictions Max              98.2712
trainer/Q1 Predictions Min            -225.364
trainer/Q2 Predictions Mean            -57.9218
trainer/Q2 Predictions Std              74.3201
trainer/Q2 Predictions Max              98.1203
trainer/Q2 Predictions Min            -225.71
trainer/Q Targets Mean                 -57.7933
trainer/Q Targets Std                   75.1276
trainer/Q Targets Max                   97.8741
trainer/Q Targets Min                 -224.475
trainer/Log Pis Mean                     1.9541
trainer/Log Pis Std                      1.70278
trainer/Log Pis Max                      5.24372
trainer/Log Pis Min                     -3.77774
trainer/policy/mean Mean                -0.433145
trainer/policy/mean Std                  0.70483
trainer/policy/mean Max                  0.957246
trainer/policy/mean Min                 -0.983951
trainer/policy/normal/std Mean           0.569432
trainer/policy/normal/std Std            0.0555195
trainer/policy/normal/std Max            0.737261
trainer/policy/normal/std Min            0.430902
trainer/policy/normal/log_std Mean      -0.567725
trainer/policy/normal/log_std Std        0.0953101
trainer/policy/normal/log_std Max       -0.304814
trainer/policy/normal/log_std Min       -0.841875
trainer/Alpha                            0.0297248
trainer/Alpha Loss                      -0.161376
exploration/num steps total         292000
exploration/num paths total           1460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02243
exploration/Rewards Std                  1.6069
exploration/Rewards Max                 -1.59861e-153
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -204.487
exploration/Returns Std                150.048
exploration/Returns Max                -25.1867
exploration/Returns Min               -557.036
exploration/Actions Mean                -0.469453
exploration/Actions Std                  0.714093
exploration/Actions Max                  0.996487
exploration/Actions Min                 -0.999738
exploration/Num Paths                   10
exploration/Average Returns           -204.487
evaluation/num steps total          699480
evaluation/num paths total            3480
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   7.29429e-13
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.581867
evaluation/Actions Std                   0.386862
evaluation/Actions Max                  -0.194955
evaluation/Actions Min                  -0.969736
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0207426
time/evaluation sampling (s)            12.6339
time/exploration sampling (s)            4.99314
time/logging (s)                         0.0235652
time/sac training (s)                   28.0583
time/saving (s)                          0.022095
time/training (s)                        0.00011366
time/epoch (s)                          45.7519
time/total (s)                       26024.7
Epoch                                  144
----------------------------------  -----------------
2020-11-09 22:21:45.406709 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 145 finished
----------------------------------  -----------------
replay_buffer/size                  294000
trainer/num train calls             146000
trainer/QF1 Loss                         8.9624
trainer/QF2 Loss                         9.3095
trainer/Policy Loss                     56.7922
trainer/Q1 Predictions Mean            -56.4913
trainer/Q1 Predictions Std              73.5361
trainer/Q1 Predictions Max              98.7839
trainer/Q1 Predictions Min            -220.484
trainer/Q2 Predictions Mean            -56.5064
trainer/Q2 Predictions Std              73.3304
trainer/Q2 Predictions Max              98.5423
trainer/Q2 Predictions Min            -218.238
trainer/Q Targets Mean                 -57.3612
trainer/Q Targets Std                   74.3064
trainer/Q Targets Max                   97.9347
trainer/Q Targets Min                 -219.83
trainer/Log Pis Mean                     2.10323
trainer/Log Pis Std                      1.8245
trainer/Log Pis Max                      6.55103
trainer/Log Pis Min                     -4.25304
trainer/policy/mean Mean                -0.566377
trainer/policy/mean Std                  0.626822
trainer/policy/mean Max                  0.954113
trainer/policy/mean Min                 -0.988061
trainer/policy/normal/std Mean           0.575629
trainer/policy/normal/std Std            0.0611668
trainer/policy/normal/std Max            0.743539
trainer/policy/normal/std Min            0.482669
trainer/policy/normal/log_std Mean      -0.55772
trainer/policy/normal/log_std Std        0.103215
trainer/policy/normal/log_std Max       -0.296333
trainer/policy/normal/log_std Min       -0.728424
trainer/Alpha                            0.0297857
trainer/Alpha Loss                       0.362706
exploration/num steps total         294000
exploration/num paths total           1470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.962644
exploration/Rewards Std                  1.56691
exploration/Rewards Max                 -4.03628e-107
exploration/Rewards Min                 -6.12042
exploration/Returns Mean              -192.529
exploration/Returns Std                122.031
exploration/Returns Max                -23.284
exploration/Returns Min               -465.647
exploration/Actions Mean                -0.457406
exploration/Actions Std                  0.709531
exploration/Actions Max                  0.997432
exploration/Actions Min                 -0.99941
exploration/Num Paths                   10
exploration/Average Returns           -192.529
evaluation/num steps total          704304
evaluation/num paths total            3504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56593
evaluation/Rewards Std                   0.986386
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1118.75
evaluation/Returns Std                 198.103
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.758468
evaluation/Actions Std                   0.216995
evaluation/Actions Max                  -0.512403
evaluation/Actions Min                  -0.968383
evaluation/Num Paths                    24
evaluation/Average Returns           -1118.75
time/data storing (s)                    0.020009
time/evaluation sampling (s)            12.0267
time/exploration sampling (s)            4.82531
time/logging (s)                         0.0173321
time/sac training (s)                   28.3682
time/saving (s)                          0.0230997
time/training (s)                        0.00011358
time/epoch (s)                          45.2808
time/total (s)                       26071.2
Epoch                                  145
----------------------------------  -----------------
2020-11-09 22:22:31.766071 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 146 finished
----------------------------------  ----------------
replay_buffer/size                  296000
trainer/num train calls             147000
trainer/QF1 Loss                        18.0489
trainer/QF2 Loss                        16.753
trainer/Policy Loss                     54.2132
trainer/Q1 Predictions Mean            -53.9099
trainer/Q1 Predictions Std              71.0231
trainer/Q1 Predictions Max              97.3253
trainer/Q1 Predictions Min            -222.126
trainer/Q2 Predictions Mean            -53.9001
trainer/Q2 Predictions Std              71.0515
trainer/Q2 Predictions Max              97.6415
trainer/Q2 Predictions Min            -215.757
trainer/Q Targets Mean                 -54.7099
trainer/Q Targets Std                   71.6137
trainer/Q Targets Max                   97.0055
trainer/Q Targets Min                 -220.972
trainer/Log Pis Mean                     2.0227
trainer/Log Pis Std                      1.66566
trainer/Log Pis Max                      7.74082
trainer/Log Pis Min                     -4.90915
trainer/policy/mean Mean                -0.527069
trainer/policy/mean Std                  0.665011
trainer/policy/mean Max                  0.960863
trainer/policy/mean Min                 -0.997569
trainer/policy/normal/std Mean           0.591619
trainer/policy/normal/std Std            0.070159
trainer/policy/normal/std Max            0.804479
trainer/policy/normal/std Min            0.4617
trainer/policy/normal/log_std Mean      -0.531663
trainer/policy/normal/log_std Std        0.115319
trainer/policy/normal/log_std Max       -0.217561
trainer/policy/normal/log_std Min       -0.772839
trainer/Alpha                            0.0299793
trainer/Alpha Loss                       0.0796032
exploration/num steps total         296000
exploration/num paths total           1480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.55499
exploration/Rewards Std                  1.60695
exploration/Rewards Max                 -5.15485e-82
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -310.997
exploration/Returns Std                124.166
exploration/Returns Max               -137.523
exploration/Returns Min               -512.454
exploration/Actions Mean                -0.56837
exploration/Actions Std                  0.601909
exploration/Actions Max                  0.994516
exploration/Actions Min                 -0.998822
exploration/Num Paths                   10
exploration/Average Returns           -310.997
evaluation/num steps total          709128
evaluation/num paths total            3528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.75837
evaluation/Rewards Std                   1.19507
evaluation/Rewards Max                  -1.57361e-15
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1157.43
evaluation/Returns Std                 239.373
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.730055
evaluation/Actions Std                   0.247227
evaluation/Actions Max                  -0.472033
evaluation/Actions Min                  -0.968788
evaluation/Num Paths                    24
evaluation/Average Returns           -1157.43
time/data storing (s)                    0.0201303
time/evaluation sampling (s)            12.1278
time/exploration sampling (s)            5.00462
time/logging (s)                         0.0173352
time/sac training (s)                   27.9924
time/saving (s)                          0.0233717
time/training (s)                        9.0783e-05
time/epoch (s)                          45.1857
time/total (s)                       26117.6
Epoch                                  146
----------------------------------  ----------------
2020-11-09 22:23:18.603745 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 147 finished
----------------------------------  ----------------
replay_buffer/size                  298000
trainer/num train calls             148000
trainer/QF1 Loss                       103.329
trainer/QF2 Loss                       108.695
trainer/Policy Loss                     60.0218
trainer/Q1 Predictions Mean            -59.6531
trainer/Q1 Predictions Std              74.4791
trainer/Q1 Predictions Max              66.1486
trainer/Q1 Predictions Min            -217.016
trainer/Q2 Predictions Mean            -59.7618
trainer/Q2 Predictions Std              74.4993
trainer/Q2 Predictions Max              66.4902
trainer/Q2 Predictions Min            -217.724
trainer/Q Targets Mean                 -59.1625
trainer/Q Targets Std                   74.718
trainer/Q Targets Max                   65.7757
trainer/Q Targets Min                 -216.656
trainer/Log Pis Mean                     2.05412
trainer/Log Pis Std                      1.82176
trainer/Log Pis Max                      6.11374
trainer/Log Pis Min                     -4.53228
trainer/policy/mean Mean                -0.454596
trainer/policy/mean Std                  0.693665
trainer/policy/mean Max                  0.969492
trainer/policy/mean Min                 -0.984031
trainer/policy/normal/std Mean           0.572808
trainer/policy/normal/std Std            0.0693811
trainer/policy/normal/std Max            0.769755
trainer/policy/normal/std Min            0.439324
trainer/policy/normal/log_std Mean      -0.56426
trainer/policy/normal/log_std Std        0.117675
trainer/policy/normal/log_std Max       -0.261683
trainer/policy/normal/log_std Min       -0.822519
trainer/Alpha                            0.0302472
trainer/Alpha Loss                       0.189324
exploration/num steps total         298000
exploration/num paths total           1490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.80188
exploration/Rewards Std                  1.4818
exploration/Rewards Max                 -2.8981e-180
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -160.376
exploration/Returns Std                 96.6115
exploration/Returns Max                -60.5117
exploration/Returns Min               -347.384
exploration/Actions Mean                -0.384895
exploration/Actions Std                  0.745205
exploration/Actions Max                  0.996256
exploration/Actions Min                 -0.999429
exploration/Num Paths                   10
exploration/Average Returns           -160.376
evaluation/num steps total          713952
evaluation/num paths total            3552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.62403
evaluation/Rewards Std                   1.00917
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1130.43
evaluation/Returns Std                 202.843
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.519986
evaluation/Actions Std                   0.455496
evaluation/Actions Max                   0.105056
evaluation/Actions Min                  -0.973247
evaluation/Num Paths                    24
evaluation/Average Returns           -1130.43
time/data storing (s)                    0.0251367
time/evaluation sampling (s)            12.1325
time/exploration sampling (s)            4.79872
time/logging (s)                         0.0183563
time/sac training (s)                   28.6082
time/saving (s)                          0.0213774
time/training (s)                        0.000115879
time/epoch (s)                          45.6044
time/total (s)                       26164.4
Epoch                                  147
----------------------------------  ----------------
2020-11-09 22:24:04.778462 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 148 finished
----------------------------------  ----------------
replay_buffer/size                  300000
trainer/num train calls             149000
trainer/QF1 Loss                       164.813
trainer/QF2 Loss                       173.74
trainer/Policy Loss                     61.2316
trainer/Q1 Predictions Mean            -60.7979
trainer/Q1 Predictions Std              72.8515
trainer/Q1 Predictions Max              84.8627
trainer/Q1 Predictions Min            -251.85
trainer/Q2 Predictions Mean            -60.9168
trainer/Q2 Predictions Std              72.8594
trainer/Q2 Predictions Max              84.68
trainer/Q2 Predictions Min            -252.559
trainer/Q Targets Mean                 -60.526
trainer/Q Targets Std                   72.9091
trainer/Q Targets Max                   52.1811
trainer/Q Targets Min                 -251.26
trainer/Log Pis Mean                     1.93023
trainer/Log Pis Std                      1.77623
trainer/Log Pis Max                      5.89336
trainer/Log Pis Min                     -4.9205
trainer/policy/mean Mean                -0.53068
trainer/policy/mean Std                  0.659788
trainer/policy/mean Max                  0.963544
trainer/policy/mean Min                 -0.984068
trainer/policy/normal/std Mean           0.592322
trainer/policy/normal/std Std            0.0752894
trainer/policy/normal/std Max            0.817345
trainer/policy/normal/std Min            0.471082
trainer/policy/normal/log_std Mean      -0.531503
trainer/policy/normal/log_std Std        0.123825
trainer/policy/normal/log_std Max       -0.201694
trainer/policy/normal/log_std Min       -0.752724
trainer/Alpha                            0.030083
trainer/Alpha Loss                      -0.244446
exploration/num steps total         300000
exploration/num paths total           1500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.67079
exploration/Rewards Std                  1.55914
exploration/Rewards Max                 -5.43219e-59
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -334.157
exploration/Returns Std                122.047
exploration/Returns Max                -94.9958
exploration/Returns Min               -516.275
exploration/Actions Mean                -0.461968
exploration/Actions Std                  0.693409
exploration/Actions Max                  0.996493
exploration/Actions Min                 -0.999067
exploration/Num Paths                   10
exploration/Average Returns           -334.157
evaluation/num steps total          718776
evaluation/num paths total            3576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.69603
evaluation/Actions Std                   0.274922
evaluation/Actions Max                  -0.41664
evaluation/Actions Min                  -0.974814
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0196453
time/evaluation sampling (s)            12.0796
time/exploration sampling (s)            4.95771
time/logging (s)                         0.0174633
time/sac training (s)                   27.8989
time/saving (s)                          0.0216308
time/training (s)                        0.000116348
time/epoch (s)                          44.995
time/total (s)                       26210.5
Epoch                                  148
----------------------------------  ----------------
2020-11-09 22:24:51.233316 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 149 finished
----------------------------------  ----------------
replay_buffer/size                  302000
trainer/num train calls             150000
trainer/QF1 Loss                        46.6849
trainer/QF2 Loss                        42.5344
trainer/Policy Loss                     64.8999
trainer/Q1 Predictions Mean            -64.5929
trainer/Q1 Predictions Std              72.6873
trainer/Q1 Predictions Max              67.8846
trainer/Q1 Predictions Min            -225.825
trainer/Q2 Predictions Mean            -64.61
trainer/Q2 Predictions Std              72.604
trainer/Q2 Predictions Max              67.7834
trainer/Q2 Predictions Min            -225.997
trainer/Q Targets Mean                 -65.1244
trainer/Q Targets Std                   73.6511
trainer/Q Targets Max                   67.7328
trainer/Q Targets Min                 -224.747
trainer/Log Pis Mean                     2.10606
trainer/Log Pis Std                      1.63833
trainer/Log Pis Max                      5.71302
trainer/Log Pis Min                     -4.8036
trainer/policy/mean Mean                -0.436874
trainer/policy/mean Std                  0.694633
trainer/policy/mean Max                  0.961618
trainer/policy/mean Min                 -0.993637
trainer/policy/normal/std Mean           0.575726
trainer/policy/normal/std Std            0.0680322
trainer/policy/normal/std Max            0.778112
trainer/policy/normal/std Min            0.43606
trainer/policy/normal/log_std Mean      -0.558868
trainer/policy/normal/log_std Std        0.115192
trainer/policy/normal/log_std Max       -0.250885
trainer/policy/normal/log_std Min       -0.829976
trainer/Alpha                            0.0298463
trainer/Alpha Loss                       0.372447
exploration/num steps total         302000
exploration/num paths total           1510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.944774
exploration/Rewards Std                  1.48877
exploration/Rewards Max                 -1.47142e-72
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.955
exploration/Returns Std                103.702
exploration/Returns Max                -80.4641
exploration/Returns Min               -477.98
exploration/Actions Mean                -0.326025
exploration/Actions Std                  0.784202
exploration/Actions Max                  0.997279
exploration/Actions Min                 -0.99934
exploration/Num Paths                   10
exploration/Average Returns           -188.955
evaluation/num steps total          723600
evaluation/num paths total            3600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.30547
evaluation/Rewards Std                   1.4949
evaluation/Rewards Max                  -7.24208e-18
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1066.4
evaluation/Returns Std                 299.982
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.524495
evaluation/Actions Std                   0.472586
evaluation/Actions Max                   0.921059
evaluation/Actions Min                  -0.978489
evaluation/Num Paths                    24
evaluation/Average Returns           -1066.4
time/data storing (s)                    0.0200608
time/evaluation sampling (s)            12.0692
time/exploration sampling (s)            4.90512
time/logging (s)                         0.0192593
time/sac training (s)                   28.1508
time/saving (s)                          0.0287214
time/training (s)                        9.5317e-05
time/epoch (s)                          45.1932
time/total (s)                       26257
Epoch                                  149
----------------------------------  ----------------
2020-11-09 22:25:37.132213 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 150 finished
----------------------------------  -----------------
replay_buffer/size                  304000
trainer/num train calls             151000
trainer/QF1 Loss                        64.1194
trainer/QF2 Loss                        66.2321
trainer/Policy Loss                     65.1732
trainer/Q1 Predictions Mean            -64.8425
trainer/Q1 Predictions Std              70.7672
trainer/Q1 Predictions Max              86.3649
trainer/Q1 Predictions Min            -208.971
trainer/Q2 Predictions Mean            -64.8615
trainer/Q2 Predictions Std              70.7704
trainer/Q2 Predictions Max              86.2585
trainer/Q2 Predictions Min            -209.533
trainer/Q Targets Mean                 -65.6927
trainer/Q Targets Std                   71.3727
trainer/Q Targets Max                   86.6114
trainer/Q Targets Min                 -208.393
trainer/Log Pis Mean                     1.79564
trainer/Log Pis Std                      1.68204
trainer/Log Pis Max                      5.71783
trainer/Log Pis Min                     -4.81478
trainer/policy/mean Mean                -0.368077
trainer/policy/mean Std                  0.750444
trainer/policy/mean Max                  0.975492
trainer/policy/mean Min                 -0.985052
trainer/policy/normal/std Mean           0.572372
trainer/policy/normal/std Std            0.0519355
trainer/policy/normal/std Max            0.744958
trainer/policy/normal/std Min            0.428451
trainer/policy/normal/log_std Mean      -0.561975
trainer/policy/normal/log_std Std        0.0890286
trainer/policy/normal/log_std Max       -0.294428
trainer/policy/normal/log_std Min       -0.847578
trainer/Alpha                            0.029792
trainer/Alpha Loss                      -0.718022
exploration/num steps total         304000
exploration/num paths total           1520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.40342
exploration/Rewards Std                  1.62138
exploration/Rewards Max                 -1.28444e-143
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -280.683
exploration/Returns Std                186.593
exploration/Returns Max                -86.1758
exploration/Returns Min               -636.975
exploration/Actions Mean                -0.26738
exploration/Actions Std                  0.813777
exploration/Actions Max                  0.997866
exploration/Actions Min                 -0.99875
exploration/Num Paths                   10
exploration/Average Returns           -280.683
evaluation/num steps total          728424
evaluation/num paths total            3624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.52645
evaluation/Rewards Std                   1.3793
evaluation/Rewards Max                  -5.38828e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1110.82
evaluation/Returns Std                 276.071
evaluation/Returns Max                 -16.0707
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.376646
evaluation/Actions Std                   0.601498
evaluation/Actions Max                   0.524005
evaluation/Actions Min                  -0.967047
evaluation/Num Paths                    24
evaluation/Average Returns           -1110.82
time/data storing (s)                    0.0197753
time/evaluation sampling (s)            12.0622
time/exploration sampling (s)            4.88073
time/logging (s)                         0.0190545
time/sac training (s)                   27.7511
time/saving (s)                          0.0217206
time/training (s)                        0.000116715
time/epoch (s)                          44.7547
time/total (s)                       26302.8
Epoch                                  150
----------------------------------  -----------------
2020-11-09 22:26:24.526285 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 151 finished
----------------------------------  ----------------
replay_buffer/size                  306000
trainer/num train calls             152000
trainer/QF1 Loss                        59.9524
trainer/QF2 Loss                        59.6261
trainer/Policy Loss                     56.4998
trainer/Q1 Predictions Mean            -56.233
trainer/Q1 Predictions Std              71.7779
trainer/Q1 Predictions Max             131.111
trainer/Q1 Predictions Min            -253.403
trainer/Q2 Predictions Mean            -56.3847
trainer/Q2 Predictions Std              71.9693
trainer/Q2 Predictions Max             131.241
trainer/Q2 Predictions Min            -254.215
trainer/Q Targets Mean                 -56.142
trainer/Q Targets Std                   71.8198
trainer/Q Targets Max                  131.145
trainer/Q Targets Min                 -252.925
trainer/Log Pis Mean                     2.11185
trainer/Log Pis Std                      1.71353
trainer/Log Pis Max                      5.90784
trainer/Log Pis Min                     -7.64367
trainer/policy/mean Mean                -0.407547
trainer/policy/mean Std                  0.727759
trainer/policy/mean Max                  0.969218
trainer/policy/mean Min                 -0.985291
trainer/policy/normal/std Mean           0.565361
trainer/policy/normal/std Std            0.0626942
trainer/policy/normal/std Max            0.780553
trainer/policy/normal/std Min            0.421779
trainer/policy/normal/log_std Mean      -0.576193
trainer/policy/normal/log_std Std        0.107606
trainer/policy/normal/log_std Max       -0.247752
trainer/policy/normal/log_std Min       -0.863274
trainer/Alpha                            0.0291927
trainer/Alpha Loss                       0.395269
exploration/num steps total         306000
exploration/num paths total           1530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.859837
exploration/Rewards Std                  1.53979
exploration/Rewards Max                 -5.28189e-37
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -171.967
exploration/Returns Std                 93.782
exploration/Returns Max                -64.4347
exploration/Returns Min               -401.3
exploration/Actions Mean                -0.431266
exploration/Actions Std                  0.738672
exploration/Actions Max                  0.996088
exploration/Actions Min                 -0.998713
exploration/Num Paths                   10
exploration/Average Returns           -171.967
evaluation/num steps total          733248
evaluation/num paths total            3648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.55116e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.55298
evaluation/Actions Std                   0.418066
evaluation/Actions Max                  -0.134791
evaluation/Actions Min                  -0.971719
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0242935
time/evaluation sampling (s)            12.1271
time/exploration sampling (s)            4.81514
time/logging (s)                         0.0191348
time/sac training (s)                   29.1336
time/saving (s)                          0.0230052
time/training (s)                        0.000111442
time/epoch (s)                          46.1423
time/total (s)                       26350.2
Epoch                                  151
----------------------------------  ----------------
2020-11-09 22:27:09.894240 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 152 finished
----------------------------------  -----------------
replay_buffer/size                  308000
trainer/num train calls             153000
trainer/QF1 Loss                        58.2571
trainer/QF2 Loss                        55.7283
trainer/Policy Loss                     46.9786
trainer/Q1 Predictions Mean            -46.667
trainer/Q1 Predictions Std              70.5177
trainer/Q1 Predictions Max              79.6842
trainer/Q1 Predictions Min            -254.13
trainer/Q2 Predictions Mean            -46.7988
trainer/Q2 Predictions Std              70.6853
trainer/Q2 Predictions Max              78.9666
trainer/Q2 Predictions Min            -254.992
trainer/Q Targets Mean                 -47.4963
trainer/Q Targets Std                   71.7879
trainer/Q Targets Max                   80.0374
trainer/Q Targets Min                 -253.598
trainer/Log Pis Mean                     1.95054
trainer/Log Pis Std                      1.8301
trainer/Log Pis Max                      6.61769
trainer/Log Pis Min                     -5.557
trainer/policy/mean Mean                -0.461802
trainer/policy/mean Std                  0.69616
trainer/policy/mean Max                  0.97332
trainer/policy/mean Min                 -0.984971
trainer/policy/normal/std Mean           0.563166
trainer/policy/normal/std Std            0.0649553
trainer/policy/normal/std Max            0.773279
trainer/policy/normal/std Min            0.402397
trainer/policy/normal/log_std Mean      -0.580613
trainer/policy/normal/log_std Std        0.11259
trainer/policy/normal/log_std Max       -0.257116
trainer/policy/normal/log_std Min       -0.910317
trainer/Alpha                            0.0288831
trainer/Alpha Loss                      -0.175309
exploration/num steps total         308000
exploration/num paths total           1540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.692864
exploration/Rewards Std                  1.48753
exploration/Rewards Max                 -4.09032e-295
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -138.573
exploration/Returns Std                112.546
exploration/Returns Max                -13.3965
exploration/Returns Min               -421.206
exploration/Actions Mean                -0.676489
exploration/Actions Std                  0.50425
exploration/Actions Max                  0.972007
exploration/Actions Min                 -0.999842
exploration/Num Paths                   10
exploration/Average Returns           -138.573
evaluation/num steps total          738072
evaluation/num paths total            3672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56159
evaluation/Rewards Std                   0.996086
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1117.88
evaluation/Returns Std                 200.054
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.667768
evaluation/Actions Std                   0.32683
evaluation/Actions Max                  -0.286498
evaluation/Actions Min                  -0.970912
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.88
time/data storing (s)                    0.0237968
time/evaluation sampling (s)            12.062
time/exploration sampling (s)            4.81817
time/logging (s)                         0.0189094
time/sac training (s)                   27.3421
time/saving (s)                          0.0233055
time/training (s)                        0.000110659
time/epoch (s)                          44.2883
time/total (s)                       26395.6
Epoch                                  152
----------------------------------  -----------------
2020-11-09 22:27:56.110193 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 153 finished
----------------------------------  -----------------
replay_buffer/size                  310000
trainer/num train calls             154000
trainer/QF1 Loss                         9.28504
trainer/QF2 Loss                        10.51
trainer/Policy Loss                     56.0045
trainer/Q1 Predictions Mean            -55.796
trainer/Q1 Predictions Std              77.5362
trainer/Q1 Predictions Max              98.6945
trainer/Q1 Predictions Min            -254.846
trainer/Q2 Predictions Mean            -55.6922
trainer/Q2 Predictions Std              77.4983
trainer/Q2 Predictions Max              98.6852
trainer/Q2 Predictions Min            -255.679
trainer/Q Targets Mean                 -56.2708
trainer/Q Targets Std                   78.1447
trainer/Q Targets Max                   97.7904
trainer/Q Targets Min                 -254.311
trainer/Log Pis Mean                     1.74593
trainer/Log Pis Std                      1.70807
trainer/Log Pis Max                      5.57734
trainer/Log Pis Min                     -4.18123
trainer/policy/mean Mean                -0.533678
trainer/policy/mean Std                  0.629459
trainer/policy/mean Max                  0.946718
trainer/policy/mean Min                 -0.984693
trainer/policy/normal/std Mean           0.590469
trainer/policy/normal/std Std            0.0744251
trainer/policy/normal/std Max            0.81104
trainer/policy/normal/std Min            0.46254
trainer/policy/normal/log_std Mean      -0.534461
trainer/policy/normal/log_std Std        0.12224
trainer/policy/normal/log_std Max       -0.209438
trainer/policy/normal/log_std Min       -0.771022
trainer/Alpha                            0.0287041
trainer/Alpha Loss                      -0.902136
exploration/num steps total         310000
exploration/num paths total           1550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.93205
exploration/Rewards Std                  1.48932
exploration/Rewards Max                 -5.08519e-188
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -186.41
exploration/Returns Std                120.001
exploration/Returns Max                -35.1669
exploration/Returns Min               -439.203
exploration/Actions Mean                -0.641138
exploration/Actions Std                  0.492059
exploration/Actions Max                  0.986938
exploration/Actions Min                 -0.999295
exploration/Num Paths                   10
exploration/Average Returns           -186.41
evaluation/num steps total          742896
evaluation/num paths total            3696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78199
evaluation/Rewards Std                   0.747422
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.18
evaluation/Returns Std                 149.8
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.762798
evaluation/Actions Std                   0.203597
evaluation/Actions Max                  -0.546125
evaluation/Actions Min                  -0.964453
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.18
time/data storing (s)                    0.0198062
time/evaluation sampling (s)            12.0755
time/exploration sampling (s)            4.84244
time/logging (s)                         0.0207117
time/sac training (s)                   28.0224
time/saving (s)                          0.0212897
time/training (s)                        9.0003e-05
time/epoch (s)                          45.0022
time/total (s)                       26441.7
Epoch                                  153
----------------------------------  -----------------
2020-11-09 22:28:41.469305 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 154 finished
----------------------------------  -----------------
replay_buffer/size                  312000
trainer/num train calls             155000
trainer/QF1 Loss                       168.177
trainer/QF2 Loss                       172.119
trainer/Policy Loss                     49.3044
trainer/Q1 Predictions Mean            -48.813
trainer/Q1 Predictions Std              72.9821
trainer/Q1 Predictions Max             128.571
trainer/Q1 Predictions Min            -226.955
trainer/Q2 Predictions Mean            -49.0748
trainer/Q2 Predictions Std              73.1263
trainer/Q2 Predictions Max             129.456
trainer/Q2 Predictions Min            -227.079
trainer/Q Targets Mean                 -48.1897
trainer/Q Targets Std                   73.0785
trainer/Q Targets Max                  129.396
trainer/Q Targets Min                 -225.82
trainer/Log Pis Mean                     1.63822
trainer/Log Pis Std                      1.76128
trainer/Log Pis Max                      5.59552
trainer/Log Pis Min                     -5.96619
trainer/policy/mean Mean                -0.478314
trainer/policy/mean Std                  0.656623
trainer/policy/mean Max                  0.956958
trainer/policy/mean Min                 -0.981309
trainer/policy/normal/std Mean           0.570316
trainer/policy/normal/std Std            0.0650022
trainer/policy/normal/std Max            0.763948
trainer/policy/normal/std Min            0.422072
trainer/policy/normal/log_std Mean      -0.567851
trainer/policy/normal/log_std Std        0.111295
trainer/policy/normal/log_std Max       -0.269256
trainer/policy/normal/log_std Min       -0.86258
trainer/Alpha                            0.0281318
trainer/Alpha Loss                      -1.29185
exploration/num steps total         312000
exploration/num paths total           1560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.788369
exploration/Rewards Std                  1.45309
exploration/Rewards Max                 -2.04888e-190
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -157.674
exploration/Returns Std                100.023
exploration/Returns Max                -41.4665
exploration/Returns Min               -340.943
exploration/Actions Mean                -0.485304
exploration/Actions Std                  0.672043
exploration/Actions Max                  0.995757
exploration/Actions Min                 -0.999992
exploration/Num Paths                   10
exploration/Average Returns           -157.674
evaluation/num steps total          747720
evaluation/num paths total            3720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.692874
evaluation/Actions Std                   0.275482
evaluation/Actions Max                  -0.413898
evaluation/Actions Min                  -0.974127
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0195304
time/evaluation sampling (s)            12.1473
time/exploration sampling (s)            4.64302
time/logging (s)                         0.0215398
time/sac training (s)                   27.4104
time/saving (s)                          0.0231642
time/training (s)                        0.000118169
time/epoch (s)                          44.265
time/total (s)                       26487.1
Epoch                                  154
----------------------------------  -----------------
2020-11-09 22:29:27.390131 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 155 finished
----------------------------------  -----------------
replay_buffer/size                  314000
trainer/num train calls             156000
trainer/QF1 Loss                        53.0837
trainer/QF2 Loss                        50.2908
trainer/Policy Loss                     69.3297
trainer/Q1 Predictions Mean            -69.022
trainer/Q1 Predictions Std              77.1877
trainer/Q1 Predictions Max              60.5571
trainer/Q1 Predictions Min            -225.502
trainer/Q2 Predictions Mean            -68.9873
trainer/Q2 Predictions Std              77.1177
trainer/Q2 Predictions Max              60.7388
trainer/Q2 Predictions Min            -224.357
trainer/Q Targets Mean                 -69.1091
trainer/Q Targets Std                   78.3834
trainer/Q Targets Max                   60.7678
trainer/Q Targets Min                 -225.681
trainer/Log Pis Mean                     1.90831
trainer/Log Pis Std                      1.50904
trainer/Log Pis Max                      5.99146
trainer/Log Pis Min                     -2.93432
trainer/policy/mean Mean                -0.466318
trainer/policy/mean Std                  0.663639
trainer/policy/mean Max                  0.967919
trainer/policy/mean Min                 -0.983943
trainer/policy/normal/std Mean           0.577317
trainer/policy/normal/std Std            0.0715859
trainer/policy/normal/std Max            0.793578
trainer/policy/normal/std Min            0.425391
trainer/policy/normal/log_std Mean      -0.556766
trainer/policy/normal/log_std Std        0.120605
trainer/policy/normal/log_std Max       -0.231203
trainer/policy/normal/log_std Min       -0.854747
trainer/Alpha                            0.027523
trainer/Alpha Loss                      -0.329411
exploration/num steps total         314000
exploration/num paths total           1570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.07072
exploration/Rewards Std                  1.3844
exploration/Rewards Max                 -4.84747e-132
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -214.143
exploration/Returns Std                144.807
exploration/Returns Max                -66.6439
exploration/Returns Min               -502.511
exploration/Actions Mean                -0.360163
exploration/Actions Std                  0.737929
exploration/Actions Max                  0.997584
exploration/Actions Min                 -0.999999
exploration/Num Paths                   10
exploration/Average Returns           -214.143
evaluation/num steps total          752544
evaluation/num paths total            3744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78199
evaluation/Rewards Std                   0.747422
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.18
evaluation/Returns Std                 149.8
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.541642
evaluation/Actions Std                   0.429472
evaluation/Actions Max                   0.109772
evaluation/Actions Min                  -0.969472
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.18
time/data storing (s)                    0.019418
time/evaluation sampling (s)            11.9735
time/exploration sampling (s)            4.84373
time/logging (s)                         0.0174763
time/sac training (s)                   27.8611
time/saving (s)                          0.0234368
time/training (s)                        0.000111744
time/epoch (s)                          44.7388
time/total (s)                       26533
Epoch                                  155
----------------------------------  -----------------
2020-11-09 22:30:13.981672 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 156 finished
----------------------------------  -----------------
replay_buffer/size                  316000
trainer/num train calls             157000
trainer/QF1 Loss                       210.309
trainer/QF2 Loss                       211.523
trainer/Policy Loss                     58.644
trainer/Q1 Predictions Mean            -58.3602
trainer/Q1 Predictions Std              76.8251
trainer/Q1 Predictions Max              58.3849
trainer/Q1 Predictions Min            -229.617
trainer/Q2 Predictions Mean            -58.2963
trainer/Q2 Predictions Std              76.9831
trainer/Q2 Predictions Max              58.2036
trainer/Q2 Predictions Min            -226.604
trainer/Q Targets Mean                 -57.7193
trainer/Q Targets Std                   77.1686
trainer/Q Targets Max                   58.1018
trainer/Q Targets Min                 -228.605
trainer/Log Pis Mean                     2.0424
trainer/Log Pis Std                      1.58844
trainer/Log Pis Max                      7.00095
trainer/Log Pis Min                     -4.73452
trainer/policy/mean Mean                -0.535843
trainer/policy/mean Std                  0.641127
trainer/policy/mean Max                  0.958659
trainer/policy/mean Min                 -0.989338
trainer/policy/normal/std Mean           0.586305
trainer/policy/normal/std Std            0.08215
trainer/policy/normal/std Max            0.786071
trainer/policy/normal/std Min            0.427488
trainer/policy/normal/log_std Mean      -0.543447
trainer/policy/normal/log_std Std        0.137124
trainer/policy/normal/log_std Max       -0.240708
trainer/policy/normal/log_std Min       -0.84983
trainer/Alpha                            0.0272819
trainer/Alpha Loss                       0.152688
exploration/num steps total         316000
exploration/num paths total           1580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13394
exploration/Rewards Std                  1.61541
exploration/Rewards Max                 -4.73331e-180
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -226.789
exploration/Returns Std                142.063
exploration/Returns Max                -65.729
exploration/Returns Min               -555.567
exploration/Actions Mean                -0.62473
exploration/Actions Std                  0.557107
exploration/Actions Max                  0.994477
exploration/Actions Min                 -0.999202
exploration/Num Paths                   10
exploration/Average Returns           -226.789
evaluation/num steps total          757368
evaluation/num paths total            3768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.45073
evaluation/Rewards Std                   1.08523
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1095.6
evaluation/Returns Std                 217.841
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.756047
evaluation/Actions Std                   0.221677
evaluation/Actions Max                  -0.507433
evaluation/Actions Min                  -0.973479
evaluation/Num Paths                    24
evaluation/Average Returns           -1095.6
time/data storing (s)                    0.0219867
time/evaluation sampling (s)            12.228
time/exploration sampling (s)            4.814
time/logging (s)                         0.0238022
time/sac training (s)                   28.2866
time/saving (s)                          0.0201628
time/training (s)                        0.000120398
time/epoch (s)                          45.3947
time/total (s)                       26579.5
Epoch                                  156
----------------------------------  -----------------
2020-11-09 22:31:00.707690 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 157 finished
----------------------------------  -----------------
replay_buffer/size                  318000
trainer/num train calls             158000
trainer/QF1 Loss                        19.3873
trainer/QF2 Loss                        19.8661
trainer/Policy Loss                     59.2506
trainer/Q1 Predictions Mean            -58.9588
trainer/Q1 Predictions Std              75.5936
trainer/Q1 Predictions Max             144.12
trainer/Q1 Predictions Min            -211.463
trainer/Q2 Predictions Mean            -58.9238
trainer/Q2 Predictions Std              75.6179
trainer/Q2 Predictions Max             143.782
trainer/Q2 Predictions Min            -212.036
trainer/Q Targets Mean                 -59.1695
trainer/Q Targets Std                   76.3335
trainer/Q Targets Max                  143.044
trainer/Q Targets Min                 -210.988
trainer/Log Pis Mean                     1.83367
trainer/Log Pis Std                      1.75379
trainer/Log Pis Max                      5.3908
trainer/Log Pis Min                     -4.25279
trainer/policy/mean Mean                -0.573624
trainer/policy/mean Std                  0.610109
trainer/policy/mean Max                  0.946419
trainer/policy/mean Min                 -0.984279
trainer/policy/normal/std Mean           0.581402
trainer/policy/normal/std Std            0.0698907
trainer/policy/normal/std Max            0.784699
trainer/policy/normal/std Min            0.401754
trainer/policy/normal/log_std Mean      -0.549332
trainer/policy/normal/log_std Std        0.117753
trainer/policy/normal/log_std Max       -0.242455
trainer/policy/normal/log_std Min       -0.911916
trainer/Alpha                            0.0270104
trainer/Alpha Loss                      -0.600699
exploration/num steps total         318000
exploration/num paths total           1590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.789389
exploration/Rewards Std                  1.51428
exploration/Rewards Max                 -3.12678e-166
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -157.878
exploration/Returns Std                120.964
exploration/Returns Max                 -6.76849
exploration/Returns Min               -468.017
exploration/Actions Mean                -0.480989
exploration/Actions Std                  0.669539
exploration/Actions Max                  0.996942
exploration/Actions Min                 -0.998961
exploration/Num Paths                   10
exploration/Average Returns           -157.878
evaluation/num steps total          762192
evaluation/num paths total            3792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.815873
evaluation/Actions Std                   0.182781
evaluation/Actions Max                   0.122241
evaluation/Actions Min                  -0.968887
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0221586
time/evaluation sampling (s)            12.3095
time/exploration sampling (s)            5.16491
time/logging (s)                         0.0233315
time/sac training (s)                   27.9457
time/saving (s)                          0.0228591
time/training (s)                        0.000114692
time/epoch (s)                          45.4885
time/total (s)                       26626.2
Epoch                                  157
----------------------------------  -----------------
2020-11-09 22:31:46.280360 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 158 finished
----------------------------------  -----------------
replay_buffer/size                  320000
trainer/num train calls             159000
trainer/QF1 Loss                       162.285
trainer/QF2 Loss                       159.597
trainer/Policy Loss                     54.8097
trainer/Q1 Predictions Mean            -54.4384
trainer/Q1 Predictions Std              74.7211
trainer/Q1 Predictions Max              87.4756
trainer/Q1 Predictions Min            -212.075
trainer/Q2 Predictions Mean            -54.5274
trainer/Q2 Predictions Std              74.858
trainer/Q2 Predictions Max              87.8526
trainer/Q2 Predictions Min            -212.62
trainer/Q Targets Mean                 -53.8541
trainer/Q Targets Std                   75.461
trainer/Q Targets Max                   88.9586
trainer/Q Targets Min                 -211.175
trainer/Log Pis Mean                     1.98098
trainer/Log Pis Std                      1.67901
trainer/Log Pis Max                      5.44231
trainer/Log Pis Min                     -5.27949
trainer/policy/mean Mean                -0.452589
trainer/policy/mean Std                  0.685269
trainer/policy/mean Max                  0.964954
trainer/policy/mean Min                 -0.987073
trainer/policy/normal/std Mean           0.560757
trainer/policy/normal/std Std            0.0675785
trainer/policy/normal/std Max            0.767861
trainer/policy/normal/std Min            0.381637
trainer/policy/normal/log_std Mean      -0.585476
trainer/policy/normal/log_std Std        0.117467
trainer/policy/normal/log_std Max       -0.264147
trainer/policy/normal/log_std Min       -0.963285
trainer/Alpha                            0.0266358
trainer/Alpha Loss                      -0.0689539
exploration/num steps total         320000
exploration/num paths total           1600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.779322
exploration/Rewards Std                  1.45507
exploration/Rewards Max                 -4.16991e-166
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -155.864
exploration/Returns Std                 90.4645
exploration/Returns Max                -43.9299
exploration/Returns Min               -339.634
exploration/Actions Mean                -0.534384
exploration/Actions Std                  0.647378
exploration/Actions Max                  0.998141
exploration/Actions Min                 -0.999117
exploration/Num Paths                   10
exploration/Average Returns           -155.864
evaluation/num steps total          767016
evaluation/num paths total            3816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82498
evaluation/Rewards Std                   1.20449
evaluation/Rewards Max                  -2.11974e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1170.82
evaluation/Returns Std                 241.34
evaluation/Returns Max                 -13.3965
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.610492
evaluation/Actions Std                   0.364612
evaluation/Actions Max                   0.424286
evaluation/Actions Min                  -0.982697
evaluation/Num Paths                    24
evaluation/Average Returns           -1170.82
time/data storing (s)                    0.0248193
time/evaluation sampling (s)            12.0976
time/exploration sampling (s)            4.82372
time/logging (s)                         0.0263661
time/sac training (s)                   27.4356
time/saving (s)                          0.0280543
time/training (s)                        0.000115037
time/epoch (s)                          44.4362
time/total (s)                       26671.8
Epoch                                  158
----------------------------------  -----------------
2020-11-09 22:32:32.290135 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 159 finished
----------------------------------  -----------------
replay_buffer/size                  322000
trainer/num train calls             160000
trainer/QF1 Loss                       190.108
trainer/QF2 Loss                       182.631
trainer/Policy Loss                     71.7124
trainer/Q1 Predictions Mean            -71.272
trainer/Q1 Predictions Std              79.8351
trainer/Q1 Predictions Max              96.8381
trainer/Q1 Predictions Min            -257.551
trainer/Q2 Predictions Mean            -71.2026
trainer/Q2 Predictions Std              79.7718
trainer/Q2 Predictions Max              96.7662
trainer/Q2 Predictions Min            -258.294
trainer/Q Targets Mean                 -70.0059
trainer/Q Targets Std                   80.3109
trainer/Q Targets Max                   97.6806
trainer/Q Targets Min                 -257.072
trainer/Log Pis Mean                     2.02006
trainer/Log Pis Std                      1.75956
trainer/Log Pis Max                     10.9161
trainer/Log Pis Min                     -2.79674
trainer/policy/mean Mean                -0.354022
trainer/policy/mean Std                  0.757817
trainer/policy/mean Max                  0.988166
trainer/policy/mean Min                 -0.999823
trainer/policy/normal/std Mean           0.568435
trainer/policy/normal/std Std            0.0575706
trainer/policy/normal/std Max            0.739484
trainer/policy/normal/std Min            0.377198
trainer/policy/normal/log_std Mean      -0.569905
trainer/policy/normal/log_std Std        0.100058
trainer/policy/normal/log_std Max       -0.301802
trainer/policy/normal/log_std Min       -0.974985
trainer/Alpha                            0.0266407
trainer/Alpha Loss                       0.0727225
exploration/num steps total         322000
exploration/num paths total           1610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13376
exploration/Rewards Std                  1.56051
exploration/Rewards Max                 -1.50385e-161
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -226.751
exploration/Returns Std                175.052
exploration/Returns Max                -54.8414
exploration/Returns Min               -508.613
exploration/Actions Mean                -0.268811
exploration/Actions Std                  0.777594
exploration/Actions Max                  0.998803
exploration/Actions Min                 -0.998855
exploration/Num Paths                   10
exploration/Average Returns           -226.751
evaluation/num steps total          771840
evaluation/num paths total            3840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60723
evaluation/Rewards Std                   0.874349
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1127.05
evaluation/Returns Std                 174.82
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.436762
evaluation/Actions Std                   0.554188
evaluation/Actions Max                   0.852396
evaluation/Actions Min                  -0.969704
evaluation/Num Paths                    24
evaluation/Average Returns           -1127.05
time/data storing (s)                    0.0198685
time/evaluation sampling (s)            12.1471
time/exploration sampling (s)            4.89986
time/logging (s)                         0.0191875
time/sac training (s)                   27.656
time/saving (s)                          0.0209486
time/training (s)                        9.2796e-05
time/epoch (s)                          44.7631
time/total (s)                       26717.8
Epoch                                  159
----------------------------------  -----------------
2020-11-09 22:33:18.144023 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 160 finished
----------------------------------  ----------------
replay_buffer/size                  324000
trainer/num train calls             161000
trainer/QF1 Loss                         9.79795
trainer/QF2 Loss                        12.5493
trainer/Policy Loss                     59.7156
trainer/Q1 Predictions Mean            -59.484
trainer/Q1 Predictions Std              74.7023
trainer/Q1 Predictions Max              96.7203
trainer/Q1 Predictions Min            -211.289
trainer/Q2 Predictions Mean            -59.2988
trainer/Q2 Predictions Std              74.554
trainer/Q2 Predictions Max              97.2155
trainer/Q2 Predictions Min            -210.705
trainer/Q Targets Mean                 -60.4029
trainer/Q Targets Std                   75.8728
trainer/Q Targets Max                   97.1528
trainer/Q Targets Min                 -211.743
trainer/Log Pis Mean                     2.02086
trainer/Log Pis Std                      1.70831
trainer/Log Pis Max                      5.93173
trainer/Log Pis Min                     -6.74052
trainer/policy/mean Mean                -0.5018
trainer/policy/mean Std                  0.655257
trainer/policy/mean Max                  0.98478
trainer/policy/mean Min                 -0.984372
trainer/policy/normal/std Mean           0.55732
trainer/policy/normal/std Std            0.0634159
trainer/policy/normal/std Max            0.73775
trainer/policy/normal/std Min            0.3635
trainer/policy/normal/log_std Mean      -0.591041
trainer/policy/normal/log_std Std        0.113371
trainer/policy/normal/log_std Max       -0.30415
trainer/policy/normal/log_std Min       -1.01198
trainer/Alpha                            0.0262234
trainer/Alpha Loss                       0.0759558
exploration/num steps total         324000
exploration/num paths total           1620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.761135
exploration/Rewards Std                  1.47877
exploration/Rewards Max                 -8.1102e-220
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -152.227
exploration/Returns Std                104.922
exploration/Returns Max                -32.4897
exploration/Returns Min               -374.549
exploration/Actions Mean                -0.523207
exploration/Actions Std                  0.610721
exploration/Actions Max                  0.997199
exploration/Actions Min                 -0.999195
exploration/Num Paths                   10
exploration/Average Returns           -152.227
evaluation/num steps total          776664
evaluation/num paths total            3864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.21403
evaluation/Rewards Std                   1.13165
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1048.02
evaluation/Returns Std                 225.989
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.66809
evaluation/Actions Std                   0.326185
evaluation/Actions Max                  -0.270111
evaluation/Actions Min                  -0.976036
evaluation/Num Paths                    24
evaluation/Average Returns           -1048.02
time/data storing (s)                    0.0200577
time/evaluation sampling (s)            12.1663
time/exploration sampling (s)            4.71902
time/logging (s)                         0.0250223
time/sac training (s)                   27.7562
time/saving (s)                          0.0246695
time/training (s)                        0.000106618
time/epoch (s)                          44.7113
time/total (s)                       26763.6
Epoch                                  160
----------------------------------  ----------------
2020-11-09 22:34:04.057241 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 161 finished
----------------------------------  -----------------
replay_buffer/size                  326000
trainer/num train calls             162000
trainer/QF1 Loss                        15.4198
trainer/QF2 Loss                        15.74
trainer/Policy Loss                     62.6833
trainer/Q1 Predictions Mean            -62.3913
trainer/Q1 Predictions Std              77.233
trainer/Q1 Predictions Max              56.5226
trainer/Q1 Predictions Min            -258.051
trainer/Q2 Predictions Mean            -62.5161
trainer/Q2 Predictions Std              77.2848
trainer/Q2 Predictions Max              56.3614
trainer/Q2 Predictions Min            -258.773
trainer/Q Targets Mean                 -62.7605
trainer/Q Targets Std                   77.7703
trainer/Q Targets Max                   57.4295
trainer/Q Targets Min                 -257.516
trainer/Log Pis Mean                     2.32467
trainer/Log Pis Std                      1.69019
trainer/Log Pis Max                      5.94785
trainer/Log Pis Min                     -2.60857
trainer/policy/mean Mean                -0.564119
trainer/policy/mean Std                  0.639643
trainer/policy/mean Max                  0.95252
trainer/policy/mean Min                 -0.989155
trainer/policy/normal/std Mean           0.567104
trainer/policy/normal/std Std            0.0706466
trainer/policy/normal/std Max            0.813088
trainer/policy/normal/std Min            0.395364
trainer/policy/normal/log_std Mean      -0.574701
trainer/policy/normal/log_std Std        0.121429
trainer/policy/normal/log_std Max       -0.206917
trainer/policy/normal/log_std Min       -0.927949
trainer/Alpha                            0.0266087
trainer/Alpha Loss                       1.17743
exploration/num steps total         326000
exploration/num paths total           1630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02125
exploration/Rewards Std                  1.80118
exploration/Rewards Max                 -4.36193e-108
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -204.251
exploration/Returns Std                 49.6806
exploration/Returns Max               -132.351
exploration/Returns Min               -277.204
exploration/Actions Mean                -0.453629
exploration/Actions Std                  0.683461
exploration/Actions Max                  0.996908
exploration/Actions Min                 -0.999268
exploration/Num Paths                   10
exploration/Average Returns           -204.251
evaluation/num steps total          781488
evaluation/num paths total            3888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.799334
evaluation/Actions Std                   0.175478
evaluation/Actions Max                  -0.614164
evaluation/Actions Min                  -0.973063
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0251822
time/evaluation sampling (s)            12.1835
time/exploration sampling (s)            5.01425
time/logging (s)                         0.0208414
time/sac training (s)                   27.4297
time/saving (s)                          0.0205075
time/training (s)                        0.000112084
time/epoch (s)                          44.6942
time/total (s)                       26809.5
Epoch                                  161
----------------------------------  -----------------
2020-11-09 22:34:53.150703 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 162 finished
----------------------------------  ----------------
replay_buffer/size                  328000
trainer/num train calls             163000
trainer/QF1 Loss                        65.9324
trainer/QF2 Loss                        69.8835
trainer/Policy Loss                     66.9108
trainer/Q1 Predictions Mean            -66.5565
trainer/Q1 Predictions Std              76.8591
trainer/Q1 Predictions Max              71.8188
trainer/Q1 Predictions Min            -258.595
trainer/Q2 Predictions Mean            -66.4281
trainer/Q2 Predictions Std              76.7766
trainer/Q2 Predictions Max              71.152
trainer/Q2 Predictions Min            -259.197
trainer/Q Targets Mean                 -66.5017
trainer/Q Targets Std                   77.4146
trainer/Q Targets Max                   71.3071
trainer/Q Targets Min                 -257.851
trainer/Log Pis Mean                     1.97337
trainer/Log Pis Std                      1.62324
trainer/Log Pis Max                      5.59845
trainer/Log Pis Min                     -4.77143
trainer/policy/mean Mean                -0.492322
trainer/policy/mean Std                  0.672968
trainer/policy/mean Max                  0.962972
trainer/policy/mean Min                 -0.986576
trainer/policy/normal/std Mean           0.576818
trainer/policy/normal/std Std            0.0703778
trainer/policy/normal/std Max            0.755812
trainer/policy/normal/std Min            0.364
trainer/policy/normal/log_std Mean      -0.557567
trainer/policy/normal/log_std Std        0.120909
trainer/policy/normal/log_std Max       -0.279963
trainer/policy/normal/log_std Min       -1.0106
trainer/Alpha                            0.027164
trainer/Alpha Loss                      -0.0960218
exploration/num steps total         328000
exploration/num paths total           1640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.84025
exploration/Rewards Std                  1.43272
exploration/Rewards Max                 -1.32173e-96
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -168.05
exploration/Returns Std                142.566
exploration/Returns Max                -38.8813
exploration/Returns Min               -508.881
exploration/Actions Mean                -0.280229
exploration/Actions Std                  0.80329
exploration/Actions Max                  0.998702
exploration/Actions Min                 -0.998899
exploration/Num Paths                   10
exploration/Average Returns           -168.05
evaluation/num steps total          786312
evaluation/num paths total            3912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67151
evaluation/Rewards Std                   0.887736
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1139.97
evaluation/Returns Std                 178.252
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.630302
evaluation/Actions Std                   0.359399
evaluation/Actions Max                   0.136215
evaluation/Actions Min                  -0.972531
evaluation/Num Paths                    24
evaluation/Average Returns           -1139.97
time/data storing (s)                    0.034087
time/evaluation sampling (s)            13.6151
time/exploration sampling (s)            6.30672
time/logging (s)                         0.0234882
time/sac training (s)                   27.3697
time/saving (s)                          0.0220053
time/training (s)                        0.000114379
time/epoch (s)                          47.3713
time/total (s)                       26858.6
Epoch                                  162
----------------------------------  ----------------
2020-11-09 22:35:43.396976 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 163 finished
----------------------------------  -----------------
replay_buffer/size                  330000
trainer/num train calls             164000
trainer/QF1 Loss                        82.15
trainer/QF2 Loss                        83.8997
trainer/Policy Loss                     57.0451
trainer/Q1 Predictions Mean            -56.704
trainer/Q1 Predictions Std              76.2654
trainer/Q1 Predictions Max              47.575
trainer/Q1 Predictions Min            -199.043
trainer/Q2 Predictions Mean            -56.7299
trainer/Q2 Predictions Std              76.3062
trainer/Q2 Predictions Max              46.7564
trainer/Q2 Predictions Min            -198.867
trainer/Q Targets Mean                 -56.5837
trainer/Q Targets Std                   76.598
trainer/Q Targets Max                   47.1207
trainer/Q Targets Min                 -200.935
trainer/Log Pis Mean                     2.02435
trainer/Log Pis Std                      1.62246
trainer/Log Pis Max                      5.4814
trainer/Log Pis Min                     -3.15923
trainer/policy/mean Mean                -0.414783
trainer/policy/mean Std                  0.709218
trainer/policy/mean Max                  0.965192
trainer/policy/mean Min                 -0.980981
trainer/policy/normal/std Mean           0.581368
trainer/policy/normal/std Std            0.0740091
trainer/policy/normal/std Max            0.832852
trainer/policy/normal/std Min            0.359711
trainer/policy/normal/log_std Mean      -0.550263
trainer/policy/normal/log_std Std        0.125032
trainer/policy/normal/log_std Max       -0.182899
trainer/policy/normal/log_std Min       -1.02245
trainer/Alpha                            0.026663
trainer/Alpha Loss                       0.0882504
exploration/num steps total         330000
exploration/num paths total           1650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.63618
exploration/Rewards Std                  1.45786
exploration/Rewards Max                 -1.41142e-213
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -127.236
exploration/Returns Std                 86.4649
exploration/Returns Max                -12.7133
exploration/Returns Min               -336.698
exploration/Actions Mean                -0.328048
exploration/Actions Std                  0.756247
exploration/Actions Max                  0.998025
exploration/Actions Min                 -0.999188
exploration/Num Paths                   10
exploration/Average Returns           -127.236
evaluation/num steps total          791136
evaluation/num paths total            3936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78387
evaluation/Rewards Std                   0.739064
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.56
evaluation/Returns Std                 148.549
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.53044
evaluation/Actions Std                   0.443831
evaluation/Actions Max                   0.315071
evaluation/Actions Min                  -0.967172
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.56
time/data storing (s)                    0.0260367
time/evaluation sampling (s)            15.4771
time/exploration sampling (s)            6.06506
time/logging (s)                         0.0164836
time/sac training (s)                   27.3608
time/saving (s)                          0.0191573
time/training (s)                        0.000101034
time/epoch (s)                          48.9647
time/total (s)                       26908.8
Epoch                                  163
----------------------------------  -----------------
2020-11-09 22:36:33.834012 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 164 finished
----------------------------------  -----------------
replay_buffer/size                  332000
trainer/num train calls             165000
trainer/QF1 Loss                        19.4178
trainer/QF2 Loss                        19.7599
trainer/Policy Loss                     54.7665
trainer/Q1 Predictions Mean            -54.4072
trainer/Q1 Predictions Std              75.5514
trainer/Q1 Predictions Max             140.99
trainer/Q1 Predictions Min            -206.162
trainer/Q2 Predictions Mean            -54.3532
trainer/Q2 Predictions Std              75.5419
trainer/Q2 Predictions Max             140.437
trainer/Q2 Predictions Min            -207.392
trainer/Q Targets Mean                 -55.0392
trainer/Q Targets Std                   76.0489
trainer/Q Targets Max                  140.188
trainer/Q Targets Min                 -206.22
trainer/Log Pis Mean                     2.17611
trainer/Log Pis Std                      1.84186
trainer/Log Pis Max                      6.7391
trainer/Log Pis Min                     -4.31491
trainer/policy/mean Mean                -0.628342
trainer/policy/mean Std                  0.575644
trainer/policy/mean Max                  0.976889
trainer/policy/mean Min                 -0.993193
trainer/policy/normal/std Mean           0.583505
trainer/policy/normal/std Std            0.0828178
trainer/policy/normal/std Max            0.866624
trainer/policy/normal/std Min            0.381871
trainer/policy/normal/log_std Mean      -0.548439
trainer/policy/normal/log_std Std        0.138524
trainer/policy/normal/log_std Max       -0.14315
trainer/policy/normal/log_std Min       -0.962672
trainer/Alpha                            0.0262933
trainer/Alpha Loss                       0.640768
exploration/num steps total         332000
exploration/num paths total           1660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.34774
exploration/Rewards Std                  1.64297
exploration/Rewards Max                 -2.87673e-162
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -269.547
exploration/Returns Std                184.558
exploration/Returns Max                -13.4
exploration/Returns Min               -540.471
exploration/Actions Mean                -0.630668
exploration/Actions Std                  0.561555
exploration/Actions Max                  0.992413
exploration/Actions Min                 -0.99958
exploration/Num Paths                   10
exploration/Average Returns           -269.547
evaluation/num steps total          795960
evaluation/num paths total            3960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.819973
evaluation/Actions Std                   0.195083
evaluation/Actions Max                   0.252233
evaluation/Actions Min                  -0.969768
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0321532
time/evaluation sampling (s)            15.6323
time/exploration sampling (s)            6.33265
time/logging (s)                         0.0189664
time/sac training (s)                   27.2413
time/saving (s)                          0.0204293
time/training (s)                        0.000107761
time/epoch (s)                          49.278
time/total (s)                       26959.2
Epoch                                  164
----------------------------------  -----------------
2020-11-09 22:37:24.226627 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 165 finished
----------------------------------  -----------------
replay_buffer/size                  334000
trainer/num train calls             166000
trainer/QF1 Loss                       209.147
trainer/QF2 Loss                       215.671
trainer/Policy Loss                     55.4594
trainer/Q1 Predictions Mean            -55.0554
trainer/Q1 Predictions Std              74.8409
trainer/Q1 Predictions Max             141.562
trainer/Q1 Predictions Min            -230.657
trainer/Q2 Predictions Mean            -55.153
trainer/Q2 Predictions Std              74.8665
trainer/Q2 Predictions Max             140.831
trainer/Q2 Predictions Min            -229.317
trainer/Q Targets Mean                 -53.8489
trainer/Q Targets Std                   75.0526
trainer/Q Targets Max                  140.107
trainer/Q Targets Min                 -230.917
trainer/Log Pis Mean                     2.02163
trainer/Log Pis Std                      1.68843
trainer/Log Pis Max                      6.12042
trainer/Log Pis Min                     -3.95163
trainer/policy/mean Mean                -0.602835
trainer/policy/mean Std                  0.594968
trainer/policy/mean Max                  0.932972
trainer/policy/mean Min                 -0.99099
trainer/policy/normal/std Mean           0.576987
trainer/policy/normal/std Std            0.0654928
trainer/policy/normal/std Max            0.783408
trainer/policy/normal/std Min            0.358666
trainer/policy/normal/log_std Mean      -0.556326
trainer/policy/normal/log_std Std        0.113099
trainer/policy/normal/log_std Max       -0.244101
trainer/policy/normal/log_std Min       -1.02536
trainer/Alpha                            0.0263711
trainer/Alpha Loss                       0.0786516
exploration/num steps total         334000
exploration/num paths total           1670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.327
exploration/Rewards Std                  1.56542
exploration/Rewards Max                 -4.29603e-171
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -265.399
exploration/Returns Std                146.642
exploration/Returns Max                -56.5159
exploration/Returns Min               -538.299
exploration/Actions Mean                -0.654903
exploration/Actions Std                  0.540766
exploration/Actions Max                  0.993202
exploration/Actions Min                 -0.998977
exploration/Num Paths                   10
exploration/Average Returns           -265.399
evaluation/num steps total          800784
evaluation/num paths total            3984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.815419
evaluation/Actions Std                   0.184448
evaluation/Actions Max                   0.100173
evaluation/Actions Min                  -0.971126
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0250619
time/evaluation sampling (s)            15.5192
time/exploration sampling (s)            6.16266
time/logging (s)                         0.0199279
time/sac training (s)                   27.4991
time/saving (s)                          0.021065
time/training (s)                        0.000113925
time/epoch (s)                          49.2471
time/total (s)                       27009.6
Epoch                                  165
----------------------------------  -----------------
2020-11-09 22:38:15.977236 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 166 finished
----------------------------------  -----------------
replay_buffer/size                  336000
trainer/num train calls             167000
trainer/QF1 Loss                        35.9286
trainer/QF2 Loss                        38.8919
trainer/Policy Loss                     56.4098
trainer/Q1 Predictions Mean            -55.9512
trainer/Q1 Predictions Std              76.7202
trainer/Q1 Predictions Max             141.956
trainer/Q1 Predictions Min            -214.46
trainer/Q2 Predictions Mean            -56.2809
trainer/Q2 Predictions Std              76.8451
trainer/Q2 Predictions Max             141.256
trainer/Q2 Predictions Min            -216.383
trainer/Q Targets Mean                 -56.8002
trainer/Q Targets Std                   78.3932
trainer/Q Targets Max                  140.716
trainer/Q Targets Min                 -259.096
trainer/Log Pis Mean                     1.98276
trainer/Log Pis Std                      1.57236
trainer/Log Pis Max                      5.65867
trainer/Log Pis Min                     -4.69758
trainer/policy/mean Mean                -0.436151
trainer/policy/mean Std                  0.695358
trainer/policy/mean Max                  0.963084
trainer/policy/mean Min                 -0.986526
trainer/policy/normal/std Mean           0.540211
trainer/policy/normal/std Std            0.065181
trainer/policy/normal/std Max            0.724109
trainer/policy/normal/std Min            0.315592
trainer/policy/normal/log_std Mean      -0.62309
trainer/policy/normal/log_std Std        0.121224
trainer/policy/normal/log_std Max       -0.322813
trainer/policy/normal/log_std Min       -1.1533
trainer/Alpha                            0.0262623
trainer/Alpha Loss                      -0.0627384
exploration/num steps total         336000
exploration/num paths total           1680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.32655
exploration/Rewards Std                  1.42252
exploration/Rewards Max                 -2.33468e-179
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -265.31
exploration/Returns Std                129.861
exploration/Returns Max                -39.4396
exploration/Returns Min               -463.124
exploration/Actions Mean                -0.462231
exploration/Actions Std                  0.648898
exploration/Actions Max                  0.997159
exploration/Actions Min                 -0.998856
exploration/Num Paths                   10
exploration/Average Returns           -265.31
evaluation/num steps total          805608
evaluation/num paths total            4008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95958
evaluation/Rewards Std                   0.55521
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.88
evaluation/Returns Std                 111.597
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.58688
evaluation/Actions Std                   0.396943
evaluation/Actions Max                   0.516531
evaluation/Actions Min                  -0.970179
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.88
time/data storing (s)                    0.0243802
time/evaluation sampling (s)            14.0031
time/exploration sampling (s)            5.84806
time/logging (s)                         0.0233201
time/sac training (s)                   30.5395
time/saving (s)                          0.0216507
time/training (s)                        0.000116684
time/epoch (s)                          50.4601
time/total (s)                       27061.3
Epoch                                  166
----------------------------------  -----------------
2020-11-09 22:39:11.813632 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 167 finished
----------------------------------  -----------------
replay_buffer/size                  338000
trainer/num train calls             168000
trainer/QF1 Loss                        42.5686
trainer/QF2 Loss                        44.4285
trainer/Policy Loss                     62.1411
trainer/Q1 Predictions Mean            -61.8294
trainer/Q1 Predictions Std              78.6573
trainer/Q1 Predictions Max             142.241
trainer/Q1 Predictions Min            -260.19
trainer/Q2 Predictions Mean            -61.8798
trainer/Q2 Predictions Std              78.7202
trainer/Q2 Predictions Max             141.758
trainer/Q2 Predictions Min            -260.857
trainer/Q Targets Mean                 -61.863
trainer/Q Targets Std                   79.3594
trainer/Q Targets Max                  140.844
trainer/Q Targets Min                 -259.631
trainer/Log Pis Mean                     1.91306
trainer/Log Pis Std                      1.60085
trainer/Log Pis Max                      5.81819
trainer/Log Pis Min                     -2.59457
trainer/policy/mean Mean                -0.450762
trainer/policy/mean Std                  0.696037
trainer/policy/mean Max                  0.966523
trainer/policy/mean Min                 -0.987678
trainer/policy/normal/std Mean           0.55491
trainer/policy/normal/std Std            0.0647565
trainer/policy/normal/std Max            0.750592
trainer/policy/normal/std Min            0.352798
trainer/policy/normal/log_std Mean      -0.595536
trainer/policy/normal/log_std Std        0.11404
trainer/policy/normal/log_std Max       -0.286893
trainer/policy/normal/log_std Min       -1.04186
trainer/Alpha                            0.0259974
trainer/Alpha Loss                      -0.317309
exploration/num steps total         338000
exploration/num paths total           1690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.784368
exploration/Rewards Std                  1.50627
exploration/Rewards Max                 -9.07337e-205
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -156.874
exploration/Returns Std                110.958
exploration/Returns Max                -15.4139
exploration/Returns Min               -395.862
exploration/Actions Mean                -0.375778
exploration/Actions Std                  0.750923
exploration/Actions Max                  0.995992
exploration/Actions Min                 -0.999148
exploration/Num Paths                   10
exploration/Average Returns           -156.874
evaluation/num steps total          810432
evaluation/num paths total            4032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73252
evaluation/Rewards Std                   0.90704
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1152.24
evaluation/Returns Std                 182.315
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.555445
evaluation/Actions Std                   0.423296
evaluation/Actions Max                   0.147845
evaluation/Actions Min                  -0.972743
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.24
time/data storing (s)                    0.0251032
time/evaluation sampling (s)            15.2028
time/exploration sampling (s)            6.52785
time/logging (s)                         0.0251123
time/sac training (s)                   32.5392
time/saving (s)                          0.0218932
time/training (s)                        0.000107823
time/epoch (s)                          54.342
time/total (s)                       27117.1
Epoch                                  167
----------------------------------  -----------------
2020-11-09 22:40:06.388206 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 168 finished
----------------------------------  -----------------
replay_buffer/size                  340000
trainer/num train calls             169000
trainer/QF1 Loss                        53.1348
trainer/QF2 Loss                        49.4691
trainer/Policy Loss                     60.134
trainer/Q1 Predictions Mean            -59.8006
trainer/Q1 Predictions Std              79.216
trainer/Q1 Predictions Max              99.7077
trainer/Q1 Predictions Min            -261.103
trainer/Q2 Predictions Mean            -59.7622
trainer/Q2 Predictions Std              79.1455
trainer/Q2 Predictions Max             100.201
trainer/Q2 Predictions Min            -261.697
trainer/Q Targets Mean                 -59.9059
trainer/Q Targets Std                   79.7176
trainer/Q Targets Max                   99.7495
trainer/Q Targets Min                 -260.241
trainer/Log Pis Mean                     1.86246
trainer/Log Pis Std                      1.66136
trainer/Log Pis Max                      6.04916
trainer/Log Pis Min                     -3.42425
trainer/policy/mean Mean                -0.401262
trainer/policy/mean Std                  0.716174
trainer/policy/mean Max                  0.971476
trainer/policy/mean Min                 -0.986524
trainer/policy/normal/std Mean           0.558356
trainer/policy/normal/std Std            0.0653808
trainer/policy/normal/std Max            0.762131
trainer/policy/normal/std Min            0.312054
trainer/policy/normal/log_std Mean      -0.589562
trainer/policy/normal/log_std Std        0.116753
trainer/policy/normal/log_std Max       -0.271636
trainer/policy/normal/log_std Min       -1.16458
trainer/Alpha                            0.0262549
trainer/Alpha Loss                      -0.500636
exploration/num steps total         340000
exploration/num paths total           1700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.7023
exploration/Rewards Std                  1.43637
exploration/Rewards Max                 -3.82449e-128
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -140.46
exploration/Returns Std                141.86
exploration/Returns Max                -10.1007
exploration/Returns Min               -518.162
exploration/Actions Mean                -0.603802
exploration/Actions Std                  0.547914
exploration/Actions Max                  0.985325
exploration/Actions Min                 -0.998255
exploration/Num Paths                   10
exploration/Average Returns           -140.46
evaluation/num steps total          815256
evaluation/num paths total            4056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.559275
evaluation/Actions Std                   0.412517
evaluation/Actions Max                   0.128692
evaluation/Actions Min                  -0.97034
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0194777
time/evaluation sampling (s)            14.6863
time/exploration sampling (s)            5.15326
time/logging (s)                         0.0251087
time/sac training (s)                   32.6948
time/saving (s)                          0.0211937
time/training (s)                        0.000132534
time/epoch (s)                          52.6002
time/total (s)                       27171.7
Epoch                                  168
----------------------------------  -----------------
2020-11-09 22:41:01.693132 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 169 finished
----------------------------------  -----------------
replay_buffer/size                  342000
trainer/num train calls             170000
trainer/QF1 Loss                         9.38925
trainer/QF2 Loss                        12.6317
trainer/Policy Loss                     48.3492
trainer/Q1 Predictions Mean            -48.0264
trainer/Q1 Predictions Std              75.0169
trainer/Q1 Predictions Max              96.7806
trainer/Q1 Predictions Min            -238.356
trainer/Q2 Predictions Mean            -47.9912
trainer/Q2 Predictions Std              74.9317
trainer/Q2 Predictions Max              96.7504
trainer/Q2 Predictions Min            -236.656
trainer/Q Targets Mean                 -48.8148
trainer/Q Targets Std                   75.6812
trainer/Q Targets Max                   96.1112
trainer/Q Targets Min                 -237.272
trainer/Log Pis Mean                     1.57272
trainer/Log Pis Std                      1.70857
trainer/Log Pis Max                      5.00963
trainer/Log Pis Min                     -3.38215
trainer/policy/mean Mean                -0.482323
trainer/policy/mean Std                  0.667846
trainer/policy/mean Max                  0.961028
trainer/policy/mean Min                 -0.977942
trainer/policy/normal/std Mean           0.568726
trainer/policy/normal/std Std            0.0670318
trainer/policy/normal/std Max            0.768753
trainer/policy/normal/std Min            0.304848
trainer/policy/normal/log_std Mean      -0.571678
trainer/policy/normal/log_std Std        0.12326
trainer/policy/normal/log_std Max       -0.262986
trainer/policy/normal/log_std Min       -1.18794
trainer/Alpha                            0.0258564
trainer/Alpha Loss                      -1.56181
exploration/num steps total         342000
exploration/num paths total           1710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.898164
exploration/Rewards Std                  1.41142
exploration/Rewards Max                 -9.14393e-142
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -179.633
exploration/Returns Std                106.81
exploration/Returns Max                -19.8735
exploration/Returns Min               -338.088
exploration/Actions Mean                -0.536091
exploration/Actions Std                  0.584175
exploration/Actions Max                  0.993335
exploration/Actions Min                 -0.998959
exploration/Num Paths                   10
exploration/Average Returns           -179.633
evaluation/num steps total          820080
evaluation/num paths total            4080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.703378
evaluation/Actions Std                   0.254744
evaluation/Actions Max                  -0.234119
evaluation/Actions Min                  -0.957424
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0193723
time/evaluation sampling (s)            15.7226
time/exploration sampling (s)            5.70846
time/logging (s)                         0.0183058
time/sac training (s)                   30.8611
time/saving (s)                          0.0189173
time/training (s)                        0.000110919
time/epoch (s)                          52.3489
time/total (s)                       27226.9
Epoch                                  169
----------------------------------  -----------------
2020-11-09 22:41:55.642273 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 170 finished
----------------------------------  -----------------
replay_buffer/size                  344000
trainer/num train calls             171000
trainer/QF1 Loss                       114.204
trainer/QF2 Loss                       114.276
trainer/Policy Loss                     62.0624
trainer/Q1 Predictions Mean            -61.7454
trainer/Q1 Predictions Std              75.1638
trainer/Q1 Predictions Max              94.4484
trainer/Q1 Predictions Min            -239.515
trainer/Q2 Predictions Mean            -61.7145
trainer/Q2 Predictions Std              75.151
trainer/Q2 Predictions Max              94.4983
trainer/Q2 Predictions Min            -237.889
trainer/Q Targets Mean                 -61.113
trainer/Q Targets Std                   76.0084
trainer/Q Targets Max                   94.6279
trainer/Q Targets Min                 -238.161
trainer/Log Pis Mean                     1.93125
trainer/Log Pis Std                      1.77285
trainer/Log Pis Max                      6.18528
trainer/Log Pis Min                     -3.70044
trainer/policy/mean Mean                -0.541776
trainer/policy/mean Std                  0.631333
trainer/policy/mean Max                  0.963476
trainer/policy/mean Min                 -0.98781
trainer/policy/normal/std Mean           0.567427
trainer/policy/normal/std Std            0.0791168
trainer/policy/normal/std Max            0.799709
trainer/policy/normal/std Min            0.335373
trainer/policy/normal/log_std Mean      -0.576083
trainer/policy/normal/log_std Std        0.13673
trainer/policy/normal/log_std Max       -0.223508
trainer/policy/normal/log_std Min       -1.09251
trainer/Alpha                            0.0252599
trainer/Alpha Loss                      -0.252907
exploration/num steps total         344000
exploration/num paths total           1720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15677
exploration/Rewards Std                  1.58181
exploration/Rewards Max                 -7.01255e-108
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -231.354
exploration/Returns Std                127.664
exploration/Returns Max               -102.407
exploration/Returns Min               -501.625
exploration/Actions Mean                -0.452144
exploration/Actions Std                  0.693938
exploration/Actions Max                  0.996963
exploration/Actions Min                 -0.998872
exploration/Num Paths                   10
exploration/Average Returns           -231.354
evaluation/num steps total          824904
evaluation/num paths total            4104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89434
evaluation/Rewards Std                   0.540329
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1184.76
evaluation/Returns Std                 108.305
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.750294
evaluation/Actions Std                   0.220204
evaluation/Actions Max                  -0.291044
evaluation/Actions Min                  -0.969233
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.76
time/data storing (s)                    0.0220448
time/evaluation sampling (s)            14.9731
time/exploration sampling (s)            5.73331
time/logging (s)                         0.0257131
time/sac training (s)                   31.2769
time/saving (s)                          0.0254416
time/training (s)                        0.000133417
time/epoch (s)                          52.0567
time/total (s)                       27280.9
Epoch                                  170
----------------------------------  -----------------
2020-11-09 22:42:47.268586 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 171 finished
----------------------------------  -----------------
replay_buffer/size                  346000
trainer/num train calls             172000
trainer/QF1 Loss                       186.862
trainer/QF2 Loss                       189.058
trainer/Policy Loss                     64.6448
trainer/Q1 Predictions Mean            -64.1279
trainer/Q1 Predictions Std              79.2983
trainer/Q1 Predictions Max              93.157
trainer/Q1 Predictions Min            -245.723
trainer/Q2 Predictions Mean            -64.3578
trainer/Q2 Predictions Std              79.5296
trainer/Q2 Predictions Max              93.2851
trainer/Q2 Predictions Min            -249.764
trainer/Q Targets Mean                 -63.4737
trainer/Q Targets Std                   79.9538
trainer/Q Targets Max                   93.7244
trainer/Q Targets Min                 -248.41
trainer/Log Pis Mean                     1.8704
trainer/Log Pis Std                      1.53282
trainer/Log Pis Max                      5.6795
trainer/Log Pis Min                     -3.56523
trainer/policy/mean Mean                -0.398916
trainer/policy/mean Std                  0.714234
trainer/policy/mean Max                  0.976808
trainer/policy/mean Min                 -0.98398
trainer/policy/normal/std Mean           0.570403
trainer/policy/normal/std Std            0.0749572
trainer/policy/normal/std Max            0.833097
trainer/policy/normal/std Min            0.343901
trainer/policy/normal/log_std Mean      -0.569795
trainer/policy/normal/log_std Std        0.128928
trainer/policy/normal/log_std Max       -0.182605
trainer/policy/normal/log_std Min       -1.0674
trainer/Alpha                            0.0247129
trainer/Alpha Loss                      -0.479579
exploration/num steps total         346000
exploration/num paths total           1730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12117
exploration/Rewards Std                  1.62674
exploration/Rewards Max                 -1.44289e-158
exploration/Rewards Min                 -6.12873
exploration/Returns Mean              -224.233
exploration/Returns Std                122.19
exploration/Returns Max                -61.3129
exploration/Returns Min               -529.568
exploration/Actions Mean                -0.401446
exploration/Actions Std                  0.706554
exploration/Actions Max                  0.998924
exploration/Actions Min                 -0.999016
exploration/Num Paths                   10
exploration/Average Returns           -224.233
evaluation/num steps total          829728
evaluation/num paths total            4128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.50543e-15
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   4.64125e-14
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.454325
evaluation/Actions Std                   0.512018
evaluation/Actions Max                   0.057945
evaluation/Actions Min                  -0.966665
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0244428
time/evaluation sampling (s)            15.0863
time/exploration sampling (s)            5.26932
time/logging (s)                         0.0237023
time/sac training (s)                   28.9657
time/saving (s)                          0.0213336
time/training (s)                        0.000108538
time/epoch (s)                          49.3909
time/total (s)                       27332.5
Epoch                                  171
----------------------------------  -----------------
2020-11-09 22:43:37.188102 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 172 finished
----------------------------------  -----------------
replay_buffer/size                  348000
trainer/num train calls             173000
trainer/QF1 Loss                       179.202
trainer/QF2 Loss                       166.608
trainer/Policy Loss                     63.0135
trainer/Q1 Predictions Mean            -62.6638
trainer/Q1 Predictions Std              76.5228
trainer/Q1 Predictions Max              52.329
trainer/Q1 Predictions Min            -261.606
trainer/Q2 Predictions Mean            -62.576
trainer/Q2 Predictions Std              76.6699
trainer/Q2 Predictions Max              53.4668
trainer/Q2 Predictions Min            -262.334
trainer/Q Targets Mean                 -61.4722
trainer/Q Targets Std                   76.8166
trainer/Q Targets Max                   52.7409
trainer/Q Targets Min                 -260.993
trainer/Log Pis Mean                     2.0246
trainer/Log Pis Std                      1.7876
trainer/Log Pis Max                      5.93499
trainer/Log Pis Min                     -6.71875
trainer/policy/mean Mean                -0.407879
trainer/policy/mean Std                  0.722937
trainer/policy/mean Max                  0.976502
trainer/policy/mean Min                 -0.986171
trainer/policy/normal/std Mean           0.556798
trainer/policy/normal/std Std            0.0724281
trainer/policy/normal/std Max            0.760367
trainer/policy/normal/std Min            0.280566
trainer/policy/normal/log_std Mean      -0.594425
trainer/policy/normal/log_std Std        0.135593
trainer/policy/normal/log_std Max       -0.273954
trainer/policy/normal/log_std Min       -1.27095
trainer/Alpha                            0.0244054
trainer/Alpha Loss                       0.0913527
exploration/num steps total         348000
exploration/num paths total           1740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.11266
exploration/Rewards Std                  1.45727
exploration/Rewards Max                 -1.71571e-296
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -222.531
exploration/Returns Std                147.771
exploration/Returns Max                -28.944
exploration/Returns Min               -444.76
exploration/Actions Mean                -0.389432
exploration/Actions Std                  0.744287
exploration/Actions Max                  0.996764
exploration/Actions Min                 -0.998937
exploration/Num Paths                   10
exploration/Average Returns           -222.531
evaluation/num steps total          834552
evaluation/num paths total            4152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.519369
evaluation/Actions Std                   0.461175
evaluation/Actions Max                   0.396835
evaluation/Actions Min                  -0.970451
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0203353
time/evaluation sampling (s)            13.1009
time/exploration sampling (s)            5.85367
time/logging (s)                         0.0199812
time/sac training (s)                   29.2064
time/saving (s)                          0.0226454
time/training (s)                        0.000126744
time/epoch (s)                          48.2241
time/total (s)                       27382.4
Epoch                                  172
----------------------------------  -----------------
2020-11-09 22:44:27.492006 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 173 finished
----------------------------------  ----------------
replay_buffer/size                  350000
trainer/num train calls             174000
trainer/QF1 Loss                         8.11566
trainer/QF2 Loss                         6.08091
trainer/Policy Loss                     65.0825
trainer/Q1 Predictions Mean            -64.7645
trainer/Q1 Predictions Std              78.2347
trainer/Q1 Predictions Max              53.2716
trainer/Q1 Predictions Min            -261.968
trainer/Q2 Predictions Mean            -64.7679
trainer/Q2 Predictions Std              78.2129
trainer/Q2 Predictions Max              53.5343
trainer/Q2 Predictions Min            -262.671
trainer/Q Targets Mean                 -65.3891
trainer/Q Targets Std                   78.7834
trainer/Q Targets Max                   53.9372
trainer/Q Targets Min                 -261.394
trainer/Log Pis Mean                     1.82928
trainer/Log Pis Std                      1.97535
trainer/Log Pis Max                      5.83457
trainer/Log Pis Min                     -5.50463
trainer/policy/mean Mean                -0.541982
trainer/policy/mean Std                  0.640885
trainer/policy/mean Max                  0.963641
trainer/policy/mean Min                 -0.985039
trainer/policy/normal/std Mean           0.568935
trainer/policy/normal/std Std            0.0831096
trainer/policy/normal/std Max            0.866952
trainer/policy/normal/std Min            0.280832
trainer/policy/normal/log_std Mean      -0.574823
trainer/policy/normal/log_std Std        0.148735
trainer/policy/normal/log_std Max       -0.142772
trainer/policy/normal/log_std Min       -1.27
trainer/Alpha                            0.0247656
trainer/Alpha Loss                      -0.631372
exploration/num steps total         350000
exploration/num paths total           1750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15102
exploration/Rewards Std                  1.72155
exploration/Rewards Max                 -5.3292e-43
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -230.203
exploration/Returns Std                115.958
exploration/Returns Max                -73.0031
exploration/Returns Min               -419.176
exploration/Actions Mean                -0.518422
exploration/Actions Std                  0.651352
exploration/Actions Max                  0.997163
exploration/Actions Min                 -0.999281
exploration/Num Paths                   10
exploration/Average Returns           -230.203
evaluation/num steps total          839376
evaluation/num paths total            4176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78676
evaluation/Rewards Std                   0.72946
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1163.14
evaluation/Returns Std                 146.618
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.752531
evaluation/Actions Std                   0.224522
evaluation/Actions Max                  -0.269448
evaluation/Actions Min                  -0.971581
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.14
time/data storing (s)                    0.0208848
time/evaluation sampling (s)            13.6487
time/exploration sampling (s)            6.53397
time/logging (s)                         0.0241736
time/sac training (s)                   28.6082
time/saving (s)                          0.0242882
time/training (s)                        0.000114194
time/epoch (s)                          48.8604
time/total (s)                       27432.6
Epoch                                  173
----------------------------------  ----------------
2020-11-09 22:45:27.813795 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 174 finished
----------------------------------  -----------------
replay_buffer/size                  352000
trainer/num train calls             175000
trainer/QF1 Loss                        28.743
trainer/QF2 Loss                        30.2832
trainer/Policy Loss                     65.2467
trainer/Q1 Predictions Mean            -64.7472
trainer/Q1 Predictions Std              78.6535
trainer/Q1 Predictions Max              57.4524
trainer/Q1 Predictions Min            -241.411
trainer/Q2 Predictions Mean            -64.9012
trainer/Q2 Predictions Std              78.711
trainer/Q2 Predictions Max              57.2368
trainer/Q2 Predictions Min            -240.007
trainer/Q Targets Mean                 -65.6145
trainer/Q Targets Std                   78.9322
trainer/Q Targets Max                   58.6057
trainer/Q Targets Min                 -240.255
trainer/Log Pis Mean                     2.12565
trainer/Log Pis Std                      1.90778
trainer/Log Pis Max                      6.03744
trainer/Log Pis Min                     -5.60103
trainer/policy/mean Mean                -0.625301
trainer/policy/mean Std                  0.583045
trainer/policy/mean Max                  0.955013
trainer/policy/mean Min                 -0.990493
trainer/policy/normal/std Mean           0.575162
trainer/policy/normal/std Std            0.0755839
trainer/policy/normal/std Max            0.827802
trainer/policy/normal/std Min            0.316322
trainer/policy/normal/log_std Mean      -0.562
trainer/policy/normal/log_std Std        0.135169
trainer/policy/normal/log_std Max       -0.188981
trainer/policy/normal/log_std Min       -1.151
trainer/Alpha                            0.0255464
trainer/Alpha Loss                       0.460783
exploration/num steps total         352000
exploration/num paths total           1760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.62803
exploration/Rewards Std                  1.51853
exploration/Rewards Max                 -4.02279e-107
exploration/Rewards Min                 -6.10909
exploration/Returns Mean              -325.605
exploration/Returns Std                196.657
exploration/Returns Max                -70.6354
exploration/Returns Min               -657.786
exploration/Actions Mean                -0.706036
exploration/Actions Std                  0.458442
exploration/Actions Max                  0.990338
exploration/Actions Min                 -0.999161
exploration/Num Paths                   10
exploration/Average Returns           -325.605
evaluation/num steps total          844200
evaluation/num paths total            4200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.54881
evaluation/Rewards Std                   1.02648
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1115.31
evaluation/Returns Std                 205.824
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.798415
evaluation/Actions Std                   0.236531
evaluation/Actions Max                   0.0100315
evaluation/Actions Min                  -0.969001
evaluation/Num Paths                    24
evaluation/Average Returns           -1115.31
time/data storing (s)                    0.0281276
time/evaluation sampling (s)            14.7371
time/exploration sampling (s)            8.30133
time/logging (s)                         0.026738
time/sac training (s)                   35.5228
time/saving (s)                          0.031359
time/training (s)                        0.000144614
time/epoch (s)                          58.6476
time/total (s)                       27492.9
Epoch                                  174
----------------------------------  -----------------
2020-11-09 22:46:22.052833 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 175 finished
----------------------------------  -----------------
replay_buffer/size                  354000
trainer/num train calls             176000
trainer/QF1 Loss                        94.1635
trainer/QF2 Loss                        95.0317
trainer/Policy Loss                     58.6875
trainer/Q1 Predictions Mean            -58.4142
trainer/Q1 Predictions Std              77.2184
trainer/Q1 Predictions Max             121.919
trainer/Q1 Predictions Min            -262.931
trainer/Q2 Predictions Mean            -58.3016
trainer/Q2 Predictions Std              77.0926
trainer/Q2 Predictions Max             121.522
trainer/Q2 Predictions Min            -263.554
trainer/Q Targets Mean                 -58.8092
trainer/Q Targets Std                   77.9021
trainer/Q Targets Max                  120.507
trainer/Q Targets Min                 -262.245
trainer/Log Pis Mean                     2.18072
trainer/Log Pis Std                      1.78182
trainer/Log Pis Max                      5.75863
trainer/Log Pis Min                     -4.28632
trainer/policy/mean Mean                -0.544863
trainer/policy/mean Std                  0.635682
trainer/policy/mean Max                  0.964393
trainer/policy/mean Min                 -0.989023
trainer/policy/normal/std Mean           0.568741
trainer/policy/normal/std Std            0.0821933
trainer/policy/normal/std Max            0.871685
trainer/policy/normal/std Min            0.278455
trainer/policy/normal/log_std Mean      -0.574637
trainer/policy/normal/log_std Std        0.143981
trainer/policy/normal/log_std Max       -0.137327
trainer/policy/normal/log_std Min       -1.2785
trainer/Alpha                            0.0258494
trainer/Alpha Loss                       0.660612
exploration/num steps total         354000
exploration/num paths total           1770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.802174
exploration/Rewards Std                  1.52125
exploration/Rewards Max                 -7.05421e-172
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -160.435
exploration/Returns Std                116.601
exploration/Returns Max                -49.5834
exploration/Returns Min               -439.873
exploration/Actions Mean                -0.579695
exploration/Actions Std                  0.635233
exploration/Actions Max                  0.996803
exploration/Actions Min                 -0.999303
exploration/Num Paths                   10
exploration/Average Returns           -160.435
evaluation/num steps total          849024
evaluation/num paths total            4224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   3.52305e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   4.64125e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.792799
evaluation/Actions Std                   0.180383
evaluation/Actions Max                  -0.608244
evaluation/Actions Min                  -0.97344
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0262759
time/evaluation sampling (s)            16.5345
time/exploration sampling (s)            5.68766
time/logging (s)                         0.0313144
time/sac training (s)                   30.4341
time/saving (s)                          0.0439215
time/training (s)                        0.000140858
time/epoch (s)                          52.7578
time/total (s)                       27547.1
Epoch                                  175
----------------------------------  -----------------
2020-11-09 22:47:18.870847 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 176 finished
----------------------------------  -----------------
replay_buffer/size                  356000
trainer/num train calls             177000
trainer/QF1 Loss                       248.597
trainer/QF2 Loss                       255.569
trainer/Policy Loss                     55.3793
trainer/Q1 Predictions Mean            -55.1376
trainer/Q1 Predictions Std              77.7175
trainer/Q1 Predictions Max             138.628
trainer/Q1 Predictions Min            -229.292
trainer/Q2 Predictions Mean            -54.9658
trainer/Q2 Predictions Std              77.5855
trainer/Q2 Predictions Max             137.993
trainer/Q2 Predictions Min            -228.076
trainer/Q Targets Mean                 -53.5523
trainer/Q Targets Std                   77.9523
trainer/Q Targets Max                  137.794
trainer/Q Targets Min                 -227.719
trainer/Log Pis Mean                     2.16006
trainer/Log Pis Std                      1.7875
trainer/Log Pis Max                      6.62156
trainer/Log Pis Min                     -3.0416
trainer/policy/mean Mean                -0.510122
trainer/policy/mean Std                  0.672367
trainer/policy/mean Max                  0.966219
trainer/policy/mean Min                 -0.98546
trainer/policy/normal/std Mean           0.565869
trainer/policy/normal/std Std            0.0772516
trainer/policy/normal/std Max            0.858046
trainer/policy/normal/std Min            0.272689
trainer/policy/normal/log_std Mean      -0.578703
trainer/policy/normal/log_std Std        0.137249
trainer/policy/normal/log_std Max       -0.153098
trainer/policy/normal/log_std Min       -1.29942
trainer/Alpha                            0.0262194
trainer/Alpha Loss                       0.582829
exploration/num steps total         356000
exploration/num paths total           1780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.39413
exploration/Rewards Std                  1.7365
exploration/Rewards Max                 -1.61999e-148
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -278.826
exploration/Returns Std                158.246
exploration/Returns Max                -91.1832
exploration/Returns Min               -573.484
exploration/Actions Mean                -0.588883
exploration/Actions Std                  0.644774
exploration/Actions Max                  0.998927
exploration/Actions Min                 -0.999125
exploration/Num Paths                   10
exploration/Average Returns           -278.826
evaluation/num steps total          853848
evaluation/num paths total            4248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.808761
evaluation/Actions Std                   0.19034
evaluation/Actions Max                   0.0175252
evaluation/Actions Min                  -0.974411
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0254397
time/evaluation sampling (s)            14.9975
time/exploration sampling (s)            5.61223
time/logging (s)                         0.027217
time/sac training (s)                   32.2831
time/saving (s)                          0.0287112
time/training (s)                        0.000165551
time/epoch (s)                          52.9744
time/total (s)                       27603.9
Epoch                                  176
----------------------------------  -----------------
2020-11-09 22:48:11.907264 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 177 finished
----------------------------------  -----------------
replay_buffer/size                  358000
trainer/num train calls             178000
trainer/QF1 Loss                        19.2341
trainer/QF2 Loss                        17.875
trainer/Policy Loss                     63.2857
trainer/Q1 Predictions Mean            -62.9383
trainer/Q1 Predictions Std              77.2822
trainer/Q1 Predictions Max              46.4789
trainer/Q1 Predictions Min            -219.566
trainer/Q2 Predictions Mean            -62.8099
trainer/Q2 Predictions Std              77.3021
trainer/Q2 Predictions Max              46.5654
trainer/Q2 Predictions Min            -223.472
trainer/Q Targets Mean                 -63.5506
trainer/Q Targets Std                   78.3085
trainer/Q Targets Max                   46.0224
trainer/Q Targets Min                 -223.941
trainer/Log Pis Mean                     2.19175
trainer/Log Pis Std                      1.71378
trainer/Log Pis Max                      5.52856
trainer/Log Pis Min                     -4.53331
trainer/policy/mean Mean                -0.532813
trainer/policy/mean Std                  0.647932
trainer/policy/mean Max                  0.968603
trainer/policy/mean Min                 -0.987362
trainer/policy/normal/std Mean           0.581363
trainer/policy/normal/std Std            0.0814585
trainer/policy/normal/std Max            0.868385
trainer/policy/normal/std Min            0.27842
trainer/policy/normal/log_std Mean      -0.552117
trainer/policy/normal/log_std Std        0.140125
trainer/policy/normal/log_std Max       -0.14112
trainer/policy/normal/log_std Min       -1.27862
trainer/Alpha                            0.026476
trainer/Alpha Loss                       0.696352
exploration/num steps total         358000
exploration/num paths total           1790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12312
exploration/Rewards Std                  1.57128
exploration/Rewards Max                 -3.51819e-270
exploration/Rewards Min                 -6.11027
exploration/Returns Mean              -224.624
exploration/Returns Std                124.45
exploration/Returns Max                -59.4223
exploration/Returns Min               -453.301
exploration/Actions Mean                -0.501561
exploration/Actions Std                  0.674399
exploration/Actions Max                  0.997412
exploration/Actions Min                 -0.998465
exploration/Num Paths                   10
exploration/Average Returns           -224.624
evaluation/num steps total          858672
evaluation/num paths total            4272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78731
evaluation/Rewards Std                   0.728663
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1163.25
evaluation/Returns Std                 146.249
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.732986
evaluation/Actions Std                   0.233213
evaluation/Actions Max                  -0.270951
evaluation/Actions Min                  -0.965532
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.25
time/data storing (s)                    0.0235295
time/evaluation sampling (s)            15.0894
time/exploration sampling (s)            5.50096
time/logging (s)                         0.0191474
time/sac training (s)                   29.3765
time/saving (s)                          0.0221839
time/training (s)                        9.7867e-05
time/epoch (s)                          50.0318
time/total (s)                       27656.9
Epoch                                  177
----------------------------------  -----------------
2020-11-09 22:49:02.175503 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 178 finished
----------------------------------  -----------------
replay_buffer/size                  360000
trainer/num train calls             179000
trainer/QF1 Loss                        37.5396
trainer/QF2 Loss                        37.2869
trainer/Policy Loss                     63.27
trainer/Q1 Predictions Mean            -62.872
trainer/Q1 Predictions Std              78.3068
trainer/Q1 Predictions Max              60.0445
trainer/Q1 Predictions Min            -263.631
trainer/Q2 Predictions Mean            -63.0151
trainer/Q2 Predictions Std              78.4708
trainer/Q2 Predictions Max              60.0475
trainer/Q2 Predictions Min            -264.355
trainer/Q Targets Mean                 -63.3556
trainer/Q Targets Std                   79.1339
trainer/Q Targets Max                   60.429
trainer/Q Targets Min                 -262.881
trainer/Log Pis Mean                     1.93693
trainer/Log Pis Std                      1.75846
trainer/Log Pis Max                      5.84963
trainer/Log Pis Min                     -3.97629
trainer/policy/mean Mean                -0.39896
trainer/policy/mean Std                  0.739266
trainer/policy/mean Max                  0.982045
trainer/policy/mean Min                 -0.984003
trainer/policy/normal/std Mean           0.566676
trainer/policy/normal/std Std            0.0734217
trainer/policy/normal/std Max            0.827329
trainer/policy/normal/std Min            0.283329
trainer/policy/normal/log_std Mean      -0.576235
trainer/policy/normal/log_std Std        0.128727
trainer/policy/normal/log_std Max       -0.189553
trainer/policy/normal/log_std Min       -1.26115
trainer/Alpha                            0.0263903
trainer/Alpha Loss                      -0.229229
exploration/num steps total         360000
exploration/num paths total           1800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.801815
exploration/Rewards Std                  1.428
exploration/Rewards Max                 -2.71639e-188
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -160.363
exploration/Returns Std                136.489
exploration/Returns Max                -19.9914
exploration/Returns Min               -473.002
exploration/Actions Mean                -0.410438
exploration/Actions Std                  0.708726
exploration/Actions Max                  0.997867
exploration/Actions Min                 -0.998706
exploration/Num Paths                   10
exploration/Average Returns           -160.363
evaluation/num steps total          863496
evaluation/num paths total            4296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.558025
evaluation/Actions Std                   0.422468
evaluation/Actions Max                   0.374733
evaluation/Actions Min                  -0.966309
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.020404
time/evaluation sampling (s)            13.1071
time/exploration sampling (s)            4.83343
time/logging (s)                         0.0315529
time/sac training (s)                   30.3572
time/saving (s)                          0.025797
time/training (s)                        0.00031825
time/epoch (s)                          48.3759
time/total (s)                       27707.2
Epoch                                  178
----------------------------------  -----------------
2020-11-09 22:49:56.578396 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 179 finished
----------------------------------  ----------------
replay_buffer/size                  362000
trainer/num train calls             180000
trainer/QF1 Loss                        56.2599
trainer/QF2 Loss                        51.3965
trainer/Policy Loss                     73.7176
trainer/Q1 Predictions Mean            -73.2079
trainer/Q1 Predictions Std              79.8753
trainer/Q1 Predictions Max              62.1448
trainer/Q1 Predictions Min            -215.046
trainer/Q2 Predictions Mean            -73.4229
trainer/Q2 Predictions Std              80.0616
trainer/Q2 Predictions Max              61.2488
trainer/Q2 Predictions Min            -215.791
trainer/Q Targets Mean                 -73.7578
trainer/Q Targets Std                   81.054
trainer/Q Targets Max                   61.5393
trainer/Q Targets Min                 -214.722
trainer/Log Pis Mean                     2.13266
trainer/Log Pis Std                      1.59844
trainer/Log Pis Max                      6.0818
trainer/Log Pis Min                     -3.11598
trainer/policy/mean Mean                -0.395033
trainer/policy/mean Std                  0.733973
trainer/policy/mean Max                  0.973229
trainer/policy/mean Min                 -0.984538
trainer/policy/normal/std Mean           0.569197
trainer/policy/normal/std Std            0.0782443
trainer/policy/normal/std Max            0.795374
trainer/policy/normal/std Min            0.267769
trainer/policy/normal/log_std Mean      -0.573335
trainer/policy/normal/log_std Std        0.142426
trainer/policy/normal/log_std Max       -0.228943
trainer/policy/normal/log_std Min       -1.31763
trainer/Alpha                            0.0265357
trainer/Alpha Loss                       0.481441
exploration/num steps total         362000
exploration/num paths total           1810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.44153
exploration/Rewards Std                  1.42437
exploration/Rewards Max                 -2.97205e-45
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -288.306
exploration/Returns Std                165.015
exploration/Returns Max                -26.8131
exploration/Returns Min               -479.499
exploration/Actions Mean                -0.454277
exploration/Actions Std                  0.692821
exploration/Actions Max                  0.998813
exploration/Actions Min                 -0.999161
exploration/Num Paths                   10
exploration/Average Returns           -288.306
evaluation/num steps total          868320
evaluation/num paths total            4320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.28101
evaluation/Rewards Std                   1.14077
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1061.48
evaluation/Returns Std                 228.032
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.42839
evaluation/Actions Std                   0.60064
evaluation/Actions Max                   0.827952
evaluation/Actions Min                  -0.967953
evaluation/Num Paths                    24
evaluation/Average Returns           -1061.48
time/data storing (s)                    0.0225341
time/evaluation sampling (s)            14.6207
time/exploration sampling (s)            7.35426
time/logging (s)                         0.0206404
time/sac training (s)                   29.508
time/saving (s)                          0.0199453
time/training (s)                        0.000110743
time/epoch (s)                          51.5462
time/total (s)                       27761.6
Epoch                                  179
----------------------------------  ----------------
2020-11-09 22:50:45.919772 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 180 finished
----------------------------------  -----------------
replay_buffer/size                  364000
trainer/num train calls             181000
trainer/QF1 Loss                        39.2595
trainer/QF2 Loss                        37.5605
trainer/Policy Loss                     58.8554
trainer/Q1 Predictions Mean            -58.63
trainer/Q1 Predictions Std              76.3265
trainer/Q1 Predictions Max              59.9737
trainer/Q1 Predictions Min            -228.514
trainer/Q2 Predictions Mean            -58.3896
trainer/Q2 Predictions Std              76.163
trainer/Q2 Predictions Max              60.5522
trainer/Q2 Predictions Min            -226.985
trainer/Q Targets Mean                 -58.8916
trainer/Q Targets Std                   76.7042
trainer/Q Targets Max                   61.7511
trainer/Q Targets Min                 -227.648
trainer/Log Pis Mean                     2.17934
trainer/Log Pis Std                      1.80001
trainer/Log Pis Max                      6.06537
trainer/Log Pis Min                     -4.98474
trainer/policy/mean Mean                -0.388591
trainer/policy/mean Std                  0.759319
trainer/policy/mean Max                  0.975598
trainer/policy/mean Min                 -0.986713
trainer/policy/normal/std Mean           0.545741
trainer/policy/normal/std Std            0.073308
trainer/policy/normal/std Max            0.83806
trainer/policy/normal/std Min            0.290734
trainer/policy/normal/log_std Mean      -0.614767
trainer/policy/normal/log_std Std        0.136723
trainer/policy/normal/log_std Max       -0.176666
trainer/policy/normal/log_std Min       -1.23535
trainer/Alpha                            0.0266663
trainer/Alpha Loss                       0.65
exploration/num steps total         364000
exploration/num paths total           1820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.757536
exploration/Rewards Std                  1.45744
exploration/Rewards Max                 -3.83639e-101
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -151.507
exploration/Returns Std                103.722
exploration/Returns Max                -60.3606
exploration/Returns Min               -423.068
exploration/Actions Mean                -0.468577
exploration/Actions Std                  0.684194
exploration/Actions Max                  0.997667
exploration/Actions Min                 -0.999304
exploration/Num Paths                   10
exploration/Average Returns           -151.507
evaluation/num steps total          873144
evaluation/num paths total            4344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39071
evaluation/Rewards Std                   1.06755
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.53
evaluation/Returns Std                 213.668
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.484586
evaluation/Actions Std                   0.530186
evaluation/Actions Max                   0.822434
evaluation/Actions Min                  -0.971977
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.53
time/data storing (s)                    0.0260937
time/evaluation sampling (s)            13.2304
time/exploration sampling (s)            5.54236
time/logging (s)                         0.0185731
time/sac training (s)                   28.4568
time/saving (s)                          0.0188415
time/training (s)                        0.000117963
time/epoch (s)                          47.2932
time/total (s)                       27810.9
Epoch                                  180
----------------------------------  -----------------
2020-11-09 22:51:33.178882 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 181 finished
----------------------------------  -----------------
replay_buffer/size                  366000
trainer/num train calls             182000
trainer/QF1 Loss                         9.46337
trainer/QF2 Loss                        10.7533
trainer/Policy Loss                     63.0503
trainer/Q1 Predictions Mean            -62.6906
trainer/Q1 Predictions Std              80.466
trainer/Q1 Predictions Max             101.154
trainer/Q1 Predictions Min            -264.827
trainer/Q2 Predictions Mean            -62.7051
trainer/Q2 Predictions Std              80.3706
trainer/Q2 Predictions Max             101.509
trainer/Q2 Predictions Min            -265.476
trainer/Q Targets Mean                 -63.1297
trainer/Q Targets Std                   81.4148
trainer/Q Targets Max                  101.61
trainer/Q Targets Min                 -264.058
trainer/Log Pis Mean                     2.1056
trainer/Log Pis Std                      1.59564
trainer/Log Pis Max                      5.6004
trainer/Log Pis Min                     -4.54006
trainer/policy/mean Mean                -0.396107
trainer/policy/mean Std                  0.732285
trainer/policy/mean Max                  0.974073
trainer/policy/mean Min                 -0.986144
trainer/policy/normal/std Mean           0.548784
trainer/policy/normal/std Std            0.0803349
trainer/policy/normal/std Max            0.810222
trainer/policy/normal/std Min            0.271053
trainer/policy/normal/log_std Mean      -0.611093
trainer/policy/normal/log_std Std        0.15076
trainer/policy/normal/log_std Max       -0.210447
trainer/policy/normal/log_std Min       -1.30544
trainer/Alpha                            0.026788
trainer/Alpha Loss                       0.382259
exploration/num steps total         366000
exploration/num paths total           1830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.658512
exploration/Rewards Std                  1.37927
exploration/Rewards Max                 -1.13701e-135
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -131.702
exploration/Returns Std                 87.2889
exploration/Returns Max                -15.4139
exploration/Returns Min               -269.602
exploration/Actions Mean                -0.2736
exploration/Actions Std                  0.7803
exploration/Actions Max                  0.996838
exploration/Actions Min                 -0.998457
exploration/Num Paths                   10
exploration/Average Returns           -131.702
evaluation/num steps total          877968
evaluation/num paths total            4368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.471805
evaluation/Actions Std                   0.505149
evaluation/Actions Max                   0.0622439
evaluation/Actions Min                  -0.970583
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.020197
time/evaluation sampling (s)            12.8544
time/exploration sampling (s)            5.03506
time/logging (s)                         0.0241404
time/sac training (s)                   27.9766
time/saving (s)                          0.0200601
time/training (s)                        0.000119131
time/epoch (s)                          45.9305
time/total (s)                       27858.1
Epoch                                  181
----------------------------------  -----------------
2020-11-09 22:52:21.642844 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 182 finished
----------------------------------  ----------------
replay_buffer/size                  368000
trainer/num train calls             183000
trainer/QF1 Loss                       106.162
trainer/QF2 Loss                       106.578
trainer/Policy Loss                     56.1351
trainer/Q1 Predictions Mean            -55.9504
trainer/Q1 Predictions Std              79.9196
trainer/Q1 Predictions Max             102.367
trainer/Q1 Predictions Min            -242.364
trainer/Q2 Predictions Mean            -55.7848
trainer/Q2 Predictions Std              79.8521
trainer/Q2 Predictions Max             102.852
trainer/Q2 Predictions Min            -242.992
trainer/Q Targets Mean                 -56.0137
trainer/Q Targets Std                   80.6389
trainer/Q Targets Max                  101.419
trainer/Q Targets Min                 -241.774
trainer/Log Pis Mean                     1.98431
trainer/Log Pis Std                      1.80008
trainer/Log Pis Max                      5.54782
trainer/Log Pis Min                     -6.57092
trainer/policy/mean Mean                -0.352648
trainer/policy/mean Std                  0.759792
trainer/policy/mean Max                  0.97828
trainer/policy/mean Min                 -0.983825
trainer/policy/normal/std Mean           0.552283
trainer/policy/normal/std Std            0.0803446
trainer/policy/normal/std Max            0.84911
trainer/policy/normal/std Min            0.249488
trainer/policy/normal/log_std Mean      -0.605005
trainer/policy/normal/log_std Std        0.154281
trainer/policy/normal/log_std Max       -0.163566
trainer/policy/normal/log_std Min       -1.38835
trainer/Alpha                            0.0268293
trainer/Alpha Loss                      -0.0567645
exploration/num steps total         368000
exploration/num paths total           1840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.976078
exploration/Rewards Std                  1.39358
exploration/Rewards Max                 -4.96192e-59
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -195.216
exploration/Returns Std                153.965
exploration/Returns Max                -51.2913
exploration/Returns Min               -477.947
exploration/Actions Mean                -0.361137
exploration/Actions Std                  0.718709
exploration/Actions Max                  0.998339
exploration/Actions Min                 -0.99935
exploration/Num Paths                   10
exploration/Average Returns           -195.216
evaluation/num steps total          882792
evaluation/num paths total            4392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.381915
evaluation/Actions Std                   0.58911
evaluation/Actions Max                   0.271789
evaluation/Actions Min                  -0.963519
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.032135
time/evaluation sampling (s)            12.8436
time/exploration sampling (s)            5.53352
time/logging (s)                         0.0237267
time/sac training (s)                   28.6178
time/saving (s)                          0.0223622
time/training (s)                        9.8775e-05
time/epoch (s)                          47.0732
time/total (s)                       27906.5
Epoch                                  182
----------------------------------  ----------------
2020-11-09 22:53:09.016556 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 183 finished
----------------------------------  -----------------
replay_buffer/size                  370000
trainer/num train calls             184000
trainer/QF1 Loss                       355.219
trainer/QF2 Loss                       346.871
trainer/Policy Loss                     65.2136
trainer/Q1 Predictions Mean            -64.805
trainer/Q1 Predictions Std              77.6582
trainer/Q1 Predictions Max              75.715
trainer/Q1 Predictions Min            -242.59
trainer/Q2 Predictions Mean            -64.871
trainer/Q2 Predictions Std              77.633
trainer/Q2 Predictions Max              75.528
trainer/Q2 Predictions Min            -243.316
trainer/Q Targets Mean                 -63.1414
trainer/Q Targets Std                   77.4494
trainer/Q Targets Max                   75.3546
trainer/Q Targets Min                 -242.213
trainer/Log Pis Mean                     1.98789
trainer/Log Pis Std                      1.74425
trainer/Log Pis Max                      5.69902
trainer/Log Pis Min                     -3.32667
trainer/policy/mean Mean                -0.444936
trainer/policy/mean Std                  0.719107
trainer/policy/mean Max                  0.973023
trainer/policy/mean Min                 -0.982336
trainer/policy/normal/std Mean           0.585424
trainer/policy/normal/std Std            0.0824513
trainer/policy/normal/std Max            0.861388
trainer/policy/normal/std Min            0.341723
trainer/policy/normal/log_std Mean      -0.544887
trainer/policy/normal/log_std Std        0.136347
trainer/policy/normal/log_std Max       -0.14921
trainer/policy/normal/log_std Min       -1.07375
trainer/Alpha                            0.0268567
trainer/Alpha Loss                      -0.0438033
exploration/num steps total         370000
exploration/num paths total           1850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.988911
exploration/Rewards Std                  1.39216
exploration/Rewards Max                 -1.09576e-139
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -197.782
exploration/Returns Std                155.096
exploration/Returns Max                 -9.44264
exploration/Returns Min               -473.211
exploration/Actions Mean                -0.478736
exploration/Actions Std                  0.707552
exploration/Actions Max                  0.997932
exploration/Actions Min                 -0.999561
exploration/Num Paths                   10
exploration/Average Returns           -197.782
evaluation/num steps total          887616
evaluation/num paths total            4416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.77461
evaluation/Rewards Std                   0.769776
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1160.7
evaluation/Returns Std                 154.718
evaluation/Returns Max                -647.554
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.57532
evaluation/Actions Std                   0.390134
evaluation/Actions Max                   0.203597
evaluation/Actions Min                  -0.964646
evaluation/Num Paths                    24
evaluation/Average Returns           -1160.7
time/data storing (s)                    0.0198585
time/evaluation sampling (s)            12.9006
time/exploration sampling (s)            4.90381
time/logging (s)                         0.0235164
time/sac training (s)                   28.2488
time/saving (s)                          0.0196045
time/training (s)                        9.2747e-05
time/epoch (s)                          46.1162
time/total (s)                       27953.9
Epoch                                  183
----------------------------------  -----------------
2020-11-09 22:53:56.628139 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 184 finished
----------------------------------  -----------------
replay_buffer/size                  372000
trainer/num train calls             185000
trainer/QF1 Loss                       133.088
trainer/QF2 Loss                       141.219
trainer/Policy Loss                     66.1128
trainer/Q1 Predictions Mean            -65.7455
trainer/Q1 Predictions Std              82.318
trainer/Q1 Predictions Max              49.6952
trainer/Q1 Predictions Min            -265.668
trainer/Q2 Predictions Mean            -65.6289
trainer/Q2 Predictions Std              82.1814
trainer/Q2 Predictions Max              49.5927
trainer/Q2 Predictions Min            -266.322
trainer/Q Targets Mean                 -65.6186
trainer/Q Targets Std                   83.2519
trainer/Q Targets Max                   49.2737
trainer/Q Targets Min                 -265.048
trainer/Log Pis Mean                     1.90722
trainer/Log Pis Std                      1.86941
trainer/Log Pis Max                      6.15821
trainer/Log Pis Min                     -3.46394
trainer/policy/mean Mean                -0.574972
trainer/policy/mean Std                  0.619959
trainer/policy/mean Max                  0.964138
trainer/policy/mean Min                 -0.988294
trainer/policy/normal/std Mean           0.58623
trainer/policy/normal/std Std            0.10333
trainer/policy/normal/std Max            0.904318
trainer/policy/normal/std Min            0.262089
trainer/policy/normal/log_std Mean      -0.549746
trainer/policy/normal/log_std Std        0.179234
trainer/policy/normal/log_std Max       -0.100574
trainer/policy/normal/log_std Min       -1.33907
trainer/Alpha                            0.026918
trainer/Alpha Loss                      -0.335408
exploration/num steps total         372000
exploration/num paths total           1860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.32452
exploration/Rewards Std                  1.60607
exploration/Rewards Max                 -3.21549e-124
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -264.903
exploration/Returns Std                150.302
exploration/Returns Max                -42.8072
exploration/Returns Min               -543.567
exploration/Actions Mean                -0.479833
exploration/Actions Std                  0.669516
exploration/Actions Max                  0.995636
exploration/Actions Min                 -0.998972
exploration/Num Paths                   10
exploration/Average Returns           -264.903
evaluation/num steps total          892440
evaluation/num paths total            4440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.744161
evaluation/Actions Std                   0.228472
evaluation/Actions Max                  -0.279492
evaluation/Actions Min                  -0.969463
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0208418
time/evaluation sampling (s)            12.8441
time/exploration sampling (s)            5.50564
time/logging (s)                         0.0202694
time/sac training (s)                   28.0063
time/saving (s)                          0.0215821
time/training (s)                        9.4162e-05
time/epoch (s)                          46.4189
time/total (s)                       28001.5
Epoch                                  184
----------------------------------  -----------------
2020-11-09 22:54:45.946241 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 185 finished
----------------------------------  -----------------
replay_buffer/size                  374000
trainer/num train calls             186000
trainer/QF1 Loss                       208.509
trainer/QF2 Loss                       211.308
trainer/Policy Loss                     71.4547
trainer/Q1 Predictions Mean            -70.7473
trainer/Q1 Predictions Std              80.7778
trainer/Q1 Predictions Max              75.979
trainer/Q1 Predictions Min            -292.575
trainer/Q2 Predictions Mean            -71.09
trainer/Q2 Predictions Std              81.0524
trainer/Q2 Predictions Max              75.2742
trainer/Q2 Predictions Min            -280.104
trainer/Q Targets Mean                 -70.2791
trainer/Q Targets Std                   81.8323
trainer/Q Targets Max                   74.8645
trainer/Q Targets Min                 -290.999
trainer/Log Pis Mean                     2.06383
trainer/Log Pis Std                      1.5408
trainer/Log Pis Max                      5.53677
trainer/Log Pis Min                     -3.06265
trainer/policy/mean Mean                -0.531096
trainer/policy/mean Std                  0.652458
trainer/policy/mean Max                  0.965648
trainer/policy/mean Min                 -0.985516
trainer/policy/normal/std Mean           0.573653
trainer/policy/normal/std Std            0.0828405
trainer/policy/normal/std Max            0.84881
trainer/policy/normal/std Min            0.270381
trainer/policy/normal/log_std Mean      -0.566059
trainer/policy/normal/log_std Std        0.14424
trainer/policy/normal/log_std Max       -0.16392
trainer/policy/normal/log_std Min       -1.30792
trainer/Alpha                            0.0271056
trainer/Alpha Loss                       0.230301
exploration/num steps total         374000
exploration/num paths total           1870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.09958
exploration/Rewards Std                  1.54954
exploration/Rewards Max                 -1.83482e-169
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -219.917
exploration/Returns Std                113.004
exploration/Returns Max                -94.0486
exploration/Returns Min               -453.679
exploration/Actions Mean                -0.456724
exploration/Actions Std                  0.662464
exploration/Actions Max                  0.998096
exploration/Actions Min                 -0.999523
exploration/Num Paths                   10
exploration/Average Returns           -219.917
evaluation/num steps total          897264
evaluation/num paths total            4464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.16746
evaluation/Rewards Std                   1.20336
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1038.66
evaluation/Returns Std                 240.896
evaluation/Returns Max                -636.651
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.64166
evaluation/Actions Std                   0.366078
evaluation/Actions Max                   0.151237
evaluation/Actions Min                  -0.9672
evaluation/Num Paths                    24
evaluation/Average Returns           -1038.66
time/data storing (s)                    0.0270689
time/evaluation sampling (s)            13.0501
time/exploration sampling (s)            4.99773
time/logging (s)                         0.0243339
time/sac training (s)                   29.5335
time/saving (s)                          0.0274407
time/training (s)                        0.000120049
time/epoch (s)                          47.6602
time/total (s)                       28050.8
Epoch                                  185
----------------------------------  -----------------
2020-11-09 22:55:40.981184 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 186 finished
----------------------------------  ----------------
replay_buffer/size                  376000
trainer/num train calls             187000
trainer/QF1 Loss                       316.455
trainer/QF2 Loss                       321.858
trainer/Policy Loss                     55.1147
trainer/Q1 Predictions Mean            -54.7918
trainer/Q1 Predictions Std              77.4675
trainer/Q1 Predictions Max              54.7865
trainer/Q1 Predictions Min            -266.484
trainer/Q2 Predictions Mean            -54.8579
trainer/Q2 Predictions Std              77.5504
trainer/Q2 Predictions Max              54.2159
trainer/Q2 Predictions Min            -267.054
trainer/Q Targets Mean                 -52.9717
trainer/Q Targets Std                   76.9644
trainer/Q Targets Max                   54.2824
trainer/Q Targets Min                 -265.645
trainer/Log Pis Mean                     1.88776
trainer/Log Pis Std                      1.76652
trainer/Log Pis Max                      5.48528
trainer/Log Pis Min                     -4.85591
trainer/policy/mean Mean                -0.356418
trainer/policy/mean Std                  0.762546
trainer/policy/mean Max                  0.971506
trainer/policy/mean Min                 -0.981986
trainer/policy/normal/std Mean           0.569428
trainer/policy/normal/std Std            0.0748532
trainer/policy/normal/std Max            0.804367
trainer/policy/normal/std Min            0.267479
trainer/policy/normal/log_std Mean      -0.572396
trainer/policy/normal/log_std Std        0.139889
trainer/policy/normal/log_std Max       -0.2177
trainer/policy/normal/log_std Min       -1.31872
trainer/Alpha                            0.0271692
trainer/Alpha Loss                      -0.404687
exploration/num steps total         376000
exploration/num paths total           1880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.771166
exploration/Rewards Std                  1.36897
exploration/Rewards Max                 -5.6794e-207
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -154.233
exploration/Returns Std                 91.9554
exploration/Returns Max                -66.029
exploration/Returns Min               -360.055
exploration/Actions Mean                -0.445093
exploration/Actions Std                  0.719629
exploration/Actions Max                  0.995422
exploration/Actions Min                 -0.998506
exploration/Num Paths                   10
exploration/Average Returns           -154.233
evaluation/num steps total          902088
evaluation/num paths total            4488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.85085e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.456839
evaluation/Actions Std                   0.506954
evaluation/Actions Max                   0.0502416
evaluation/Actions Min                  -0.963916
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.021076
time/evaluation sampling (s)            16.0985
time/exploration sampling (s)            6.75436
time/logging (s)                         0.0235873
time/sac training (s)                   29.4999
time/saving (s)                          0.0200674
time/training (s)                        0.000122093
time/epoch (s)                          52.4176
time/total (s)                       28105.8
Epoch                                  186
----------------------------------  ----------------
2020-11-09 22:56:38.510905 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 187 finished
----------------------------------  -----------------
replay_buffer/size                  378000
trainer/num train calls             188000
trainer/QF1 Loss                        91.3686
trainer/QF2 Loss                        90.6401
trainer/Policy Loss                     59.0281
trainer/Q1 Predictions Mean            -58.6423
trainer/Q1 Predictions Std              78.6121
trainer/Q1 Predictions Max              90.6928
trainer/Q1 Predictions Min            -214.588
trainer/Q2 Predictions Mean            -58.7046
trainer/Q2 Predictions Std              78.6766
trainer/Q2 Predictions Max              90.7374
trainer/Q2 Predictions Min            -216.752
trainer/Q Targets Mean                 -58.2945
trainer/Q Targets Std                   79.2916
trainer/Q Targets Max                   91.2115
trainer/Q Targets Min                 -217.48
trainer/Log Pis Mean                     2.10359
trainer/Log Pis Std                      1.79913
trainer/Log Pis Max                      5.68348
trainer/Log Pis Min                     -6.22078
trainer/policy/mean Mean                -0.422426
trainer/policy/mean Std                  0.731798
trainer/policy/mean Max                  0.984654
trainer/policy/mean Min                 -0.984014
trainer/policy/normal/std Mean           0.573951
trainer/policy/normal/std Std            0.0893074
trainer/policy/normal/std Max            0.921113
trainer/policy/normal/std Min            0.265085
trainer/policy/normal/log_std Mean      -0.567622
trainer/policy/normal/log_std Std        0.159986
trainer/policy/normal/log_std Max       -0.0821723
trainer/policy/normal/log_std Min       -1.3277
trainer/Alpha                            0.0268199
trainer/Alpha Loss                       0.374852
exploration/num steps total         378000
exploration/num paths total           1890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.857508
exploration/Rewards Std                  1.40676
exploration/Rewards Max                 -1.58757e-200
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -171.502
exploration/Returns Std                101.97
exploration/Returns Max                -27.3878
exploration/Returns Min               -346.814
exploration/Actions Mean                -0.284428
exploration/Actions Std                  0.770568
exploration/Actions Max                  0.996648
exploration/Actions Min                 -0.99901
exploration/Num Paths                   10
exploration/Average Returns           -171.502
evaluation/num steps total          906912
evaluation/num paths total            4512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.33973
evaluation/Rewards Std                   1.15738
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1073.29
evaluation/Returns Std                 232.217
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.473317
evaluation/Actions Std                   0.538107
evaluation/Actions Max                   0.59981
evaluation/Actions Min                  -0.964558
evaluation/Num Paths                    24
evaluation/Average Returns           -1073.29
time/data storing (s)                    0.0273204
time/evaluation sampling (s)            15.5862
time/exploration sampling (s)            6.45719
time/logging (s)                         0.0277819
time/sac training (s)                   32.0836
time/saving (s)                          0.034083
time/training (s)                        9.4259e-05
time/epoch (s)                          54.2162
time/total (s)                       28163.3
Epoch                                  187
----------------------------------  -----------------
2020-11-09 22:57:32.247065 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 188 finished
----------------------------------  ----------------
replay_buffer/size                  380000
trainer/num train calls             189000
trainer/QF1 Loss                        66.9701
trainer/QF2 Loss                        70.2128
trainer/Policy Loss                     55.91
trainer/Q1 Predictions Mean            -55.5984
trainer/Q1 Predictions Std              76.7383
trainer/Q1 Predictions Max             103.904
trainer/Q1 Predictions Min            -293.43
trainer/Q2 Predictions Mean            -55.5118
trainer/Q2 Predictions Std              76.6174
trainer/Q2 Predictions Max             104.362
trainer/Q2 Predictions Min            -285.56
trainer/Q Targets Mean                 -55.9994
trainer/Q Targets Std                   77.7274
trainer/Q Targets Max                  103.549
trainer/Q Targets Min                 -292.131
trainer/Log Pis Mean                     2.01508
trainer/Log Pis Std                      1.90227
trainer/Log Pis Max                      6.53588
trainer/Log Pis Min                     -4.82038
trainer/policy/mean Mean                -0.449258
trainer/policy/mean Std                  0.707381
trainer/policy/mean Max                  0.981607
trainer/policy/mean Min                 -0.987415
trainer/policy/normal/std Mean           0.567034
trainer/policy/normal/std Std            0.090206
trainer/policy/normal/std Max            0.94899
trainer/policy/normal/std Min            0.273286
trainer/policy/normal/log_std Mean      -0.579606
trainer/policy/normal/log_std Std        0.156468
trainer/policy/normal/log_std Max       -0.0523568
trainer/policy/normal/log_std Min       -1.29724
trainer/Alpha                            0.0266752
trainer/Alpha Loss                       0.0546557
exploration/num steps total         380000
exploration/num paths total           1900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.992219
exploration/Rewards Std                  1.52535
exploration/Rewards Max                 -5.76095e-87
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -198.444
exploration/Returns Std                120.171
exploration/Returns Max                -73.5006
exploration/Returns Min               -447.136
exploration/Actions Mean                -0.432003
exploration/Actions Std                  0.732219
exploration/Actions Max                  0.997881
exploration/Actions Min                 -0.999864
exploration/Num Paths                   10
exploration/Average Returns           -198.444
evaluation/num steps total          911736
evaluation/num paths total            4536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78387
evaluation/Rewards Std                   0.739064
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.56
evaluation/Returns Std                 148.549
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.568793
evaluation/Actions Std                   0.417303
evaluation/Actions Max                   0.421543
evaluation/Actions Min                  -0.96955
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.56
time/data storing (s)                    0.0224505
time/evaluation sampling (s)            15.9339
time/exploration sampling (s)            5.60928
time/logging (s)                         0.0201086
time/sac training (s)                   28.9118
time/saving (s)                          0.0488894
time/training (s)                        0.000132251
time/epoch (s)                          50.5466
time/total (s)                       28217
Epoch                                  188
----------------------------------  ----------------
2020-11-09 22:58:30.535179 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 189 finished
----------------------------------  -----------------
replay_buffer/size                  382000
trainer/num train calls             190000
trainer/QF1 Loss                        18.5441
trainer/QF2 Loss                        18.9005
trainer/Policy Loss                     63.0002
trainer/Q1 Predictions Mean            -62.7872
trainer/Q1 Predictions Std              84.9358
trainer/Q1 Predictions Max              90.557
trainer/Q1 Predictions Min            -293.308
trainer/Q2 Predictions Mean            -62.5184
trainer/Q2 Predictions Std              84.6448
trainer/Q2 Predictions Max              90.4854
trainer/Q2 Predictions Min            -286.471
trainer/Q Targets Mean                 -63.1428
trainer/Q Targets Std                   85.6011
trainer/Q Targets Max                   89.9268
trainer/Q Targets Min                 -291.878
trainer/Log Pis Mean                     2.05212
trainer/Log Pis Std                      1.77906
trainer/Log Pis Max                      5.48561
trainer/Log Pis Min                     -5.87505
trainer/policy/mean Mean                -0.440907
trainer/policy/mean Std                  0.710869
trainer/policy/mean Max                  0.975113
trainer/policy/mean Min                 -0.986171
trainer/policy/normal/std Mean           0.563488
trainer/policy/normal/std Std            0.0868222
trainer/policy/normal/std Max            0.936486
trainer/policy/normal/std Min            0.249231
trainer/policy/normal/log_std Mean      -0.586083
trainer/policy/normal/log_std Std        0.161417
trainer/policy/normal/log_std Max       -0.0656204
trainer/policy/normal/log_std Min       -1.38937
trainer/Alpha                            0.0273447
trainer/Alpha Loss                       0.187592
exploration/num steps total         382000
exploration/num paths total           1910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.765738
exploration/Rewards Std                  1.42796
exploration/Rewards Max                 -2.70792e-214
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -153.148
exploration/Returns Std                105.635
exploration/Returns Max                -23.1909
exploration/Returns Min               -319.703
exploration/Actions Mean                -0.31608
exploration/Actions Std                  0.747761
exploration/Actions Max                  0.995855
exploration/Actions Min                 -0.99913
exploration/Num Paths                   10
exploration/Average Returns           -153.148
evaluation/num steps total          916560
evaluation/num paths total            4560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.570719
evaluation/Actions Std                   0.404983
evaluation/Actions Max                   0.410411
evaluation/Actions Min                  -0.967962
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0235082
time/evaluation sampling (s)            15.8091
time/exploration sampling (s)            6.68299
time/logging (s)                         0.042552
time/sac training (s)                   31.1083
time/saving (s)                          0.026858
time/training (s)                        0.00012365
time/epoch (s)                          53.6934
time/total (s)                       28275.3
Epoch                                  189
----------------------------------  -----------------
2020-11-09 22:59:28.473466 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 190 finished
----------------------------------  ----------------
replay_buffer/size                  384000
trainer/num train calls             191000
trainer/QF1 Loss                       170.367
trainer/QF2 Loss                       171.077
trainer/Policy Loss                     68.0165
trainer/Q1 Predictions Mean            -67.7436
trainer/Q1 Predictions Std              83.1816
trainer/Q1 Predictions Max             130.467
trainer/Q1 Predictions Min            -229.331
trainer/Q2 Predictions Mean            -67.7113
trainer/Q2 Predictions Std              83.1246
trainer/Q2 Predictions Max             130.329
trainer/Q2 Predictions Min            -228.487
trainer/Q Targets Mean                 -67.1858
trainer/Q Targets Std                   83.3136
trainer/Q Targets Max                  129.798
trainer/Q Targets Min                 -228.146
trainer/Log Pis Mean                     2.21389
trainer/Log Pis Std                      1.75578
trainer/Log Pis Max                      7.83482
trainer/Log Pis Min                     -2.89263
trainer/policy/mean Mean                -0.414023
trainer/policy/mean Std                  0.742383
trainer/policy/mean Max                  0.975038
trainer/policy/mean Min                 -0.996363
trainer/policy/normal/std Mean           0.566463
trainer/policy/normal/std Std            0.0873544
trainer/policy/normal/std Max            0.901952
trainer/policy/normal/std Min            0.272933
trainer/policy/normal/log_std Mean      -0.580025
trainer/policy/normal/log_std Std        0.15318
trainer/policy/normal/log_std Max       -0.103193
trainer/policy/normal/log_std Min       -1.29853
trainer/Alpha                            0.0277191
trainer/Alpha Loss                       0.766942
exploration/num steps total         384000
exploration/num paths total           1920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.731376
exploration/Rewards Std                  1.30361
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.275
exploration/Returns Std                135.503
exploration/Returns Max                -23.1708
exploration/Returns Min               -444.514
exploration/Actions Mean                -0.561398
exploration/Actions Std                  0.653693
exploration/Actions Max                  0.999112
exploration/Actions Min                 -0.999688
exploration/Num Paths                   10
exploration/Average Returns           -146.275
evaluation/num steps total          921384
evaluation/num paths total            4584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.467746
evaluation/Actions Std                   0.505351
evaluation/Actions Max                   0.0546834
evaluation/Actions Min                  -0.970264
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0334618
time/evaluation sampling (s)            16.9663
time/exploration sampling (s)            6.42339
time/logging (s)                         0.0233038
time/sac training (s)                   30.2378
time/saving (s)                          0.0214248
time/training (s)                        0.000131872
time/epoch (s)                          53.7059
time/total (s)                       28333.2
Epoch                                  190
----------------------------------  ----------------
2020-11-09 23:00:40.309468 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 191 finished
----------------------------------  ----------------
replay_buffer/size                  386000
trainer/num train calls             192000
trainer/QF1 Loss                        30.5825
trainer/QF2 Loss                        31.61
trainer/Policy Loss                     55.6368
trainer/Q1 Predictions Mean            -55.3457
trainer/Q1 Predictions Std              78.2367
trainer/Q1 Predictions Max              64.4352
trainer/Q1 Predictions Min            -219.56
trainer/Q2 Predictions Mean            -55.3193
trainer/Q2 Predictions Std              78.1999
trainer/Q2 Predictions Max              64.3593
trainer/Q2 Predictions Min            -218.916
trainer/Q Targets Mean                 -55.4355
trainer/Q Targets Std                   78.4557
trainer/Q Targets Max                   64.2474
trainer/Q Targets Min                 -224.663
trainer/Log Pis Mean                     2.28169
trainer/Log Pis Std                      1.70356
trainer/Log Pis Max                      6.58927
trainer/Log Pis Min                     -4.44774
trainer/policy/mean Mean                -0.437814
trainer/policy/mean Std                  0.731782
trainer/policy/mean Max                  0.979256
trainer/policy/mean Min                 -0.983621
trainer/policy/normal/std Mean           0.575085
trainer/policy/normal/std Std            0.0896481
trainer/policy/normal/std Max            0.915333
trainer/policy/normal/std Min            0.270896
trainer/policy/normal/log_std Mean      -0.565508
trainer/policy/normal/log_std Std        0.158255
trainer/policy/normal/log_std Max       -0.0884674
trainer/policy/normal/log_std Min       -1.30602
trainer/Alpha                            0.0282334
trainer/Alpha Loss                       1.00485
exploration/num steps total         386000
exploration/num paths total           1930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.17086
exploration/Rewards Std                  1.51882
exploration/Rewards Max                 -1.5038e-228
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -234.173
exploration/Returns Std                174.441
exploration/Returns Max                -77.493
exploration/Returns Min               -544.791
exploration/Actions Mean                -0.371784
exploration/Actions Std                  0.754289
exploration/Actions Max                  0.998107
exploration/Actions Min                 -0.999281
exploration/Num Paths                   10
exploration/Average Returns           -234.173
evaluation/num steps total          926208
evaluation/num paths total            4608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.4556e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.564673
evaluation/Actions Std                   0.399893
evaluation/Actions Max                  -0.160708
evaluation/Actions Min                  -0.964992
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0215594
time/evaluation sampling (s)            22.2705
time/exploration sampling (s)            6.2991
time/logging (s)                         0.0236759
time/sac training (s)                   31.2482
time/saving (s)                          0.0267374
time/training (s)                        0.000116633
time/epoch (s)                          59.8899
time/total (s)                       28405
Epoch                                  191
----------------------------------  ----------------
2020-11-09 23:01:34.307920 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 192 finished
----------------------------------  -----------------
replay_buffer/size                  388000
trainer/num train calls             193000
trainer/QF1 Loss                        68.1915
trainer/QF2 Loss                        64.6361
trainer/Policy Loss                     58.7614
trainer/Q1 Predictions Mean            -58.4235
trainer/Q1 Predictions Std              79.2457
trainer/Q1 Predictions Max              88.1533
trainer/Q1 Predictions Min            -230.25
trainer/Q2 Predictions Mean            -58.4333
trainer/Q2 Predictions Std              79.1611
trainer/Q2 Predictions Max              88.1439
trainer/Q2 Predictions Min            -223.464
trainer/Q Targets Mean                 -58.2661
trainer/Q Targets Std                   79.4665
trainer/Q Targets Max                   87.6156
trainer/Q Targets Min                 -216.762
trainer/Log Pis Mean                     2.27335
trainer/Log Pis Std                      1.80359
trainer/Log Pis Max                      5.98224
trainer/Log Pis Min                     -2.99697
trainer/policy/mean Mean                -0.282775
trainer/policy/mean Std                  0.799163
trainer/policy/mean Max                  0.978329
trainer/policy/mean Min                 -0.987773
trainer/policy/normal/std Mean           0.551835
trainer/policy/normal/std Std            0.0895508
trainer/policy/normal/std Max            0.906605
trainer/policy/normal/std Min            0.245562
trainer/policy/normal/log_std Mean      -0.607778
trainer/policy/normal/log_std Std        0.164598
trainer/policy/normal/log_std Max       -0.0980488
trainer/policy/normal/log_std Min       -1.40421
trainer/Alpha                            0.0285237
trainer/Alpha Loss                       0.972321
exploration/num steps total         388000
exploration/num paths total           1940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.38399
exploration/Rewards Std                  1.59268
exploration/Rewards Max                 -1.47745e-190
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -276.799
exploration/Returns Std                170.804
exploration/Returns Max                -60.3881
exploration/Returns Min               -619.405
exploration/Actions Mean                -0.347526
exploration/Actions Std                  0.741032
exploration/Actions Max                  0.999123
exploration/Actions Min                 -0.999041
exploration/Num Paths                   10
exploration/Average Returns           -276.799
evaluation/num steps total          931032
evaluation/num paths total            4632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84381
evaluation/Rewards Std                   0.767927
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1174.61
evaluation/Returns Std                 154.352
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.2362
evaluation/Actions Std                   0.735703
evaluation/Actions Max                   0.720109
evaluation/Actions Min                  -0.97194
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.61
time/data storing (s)                    0.0197912
time/evaluation sampling (s)            15.7495
time/exploration sampling (s)            6.05991
time/logging (s)                         0.0189869
time/sac training (s)                   27.3429
time/saving (s)                          0.0217475
time/training (s)                        0.000121237
time/epoch (s)                          49.213
time/total (s)                       28458.9
Epoch                                  192
----------------------------------  -----------------
2020-11-09 23:02:27.773332 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 193 finished
----------------------------------  -----------------
replay_buffer/size                  390000
trainer/num train calls             194000
trainer/QF1 Loss                       116.86
trainer/QF2 Loss                       119.199
trainer/Policy Loss                     75.1073
trainer/Q1 Predictions Mean            -74.6646
trainer/Q1 Predictions Std              82.907
trainer/Q1 Predictions Max              74.0859
trainer/Q1 Predictions Min            -266.798
trainer/Q2 Predictions Mean            -74.6727
trainer/Q2 Predictions Std              82.9562
trainer/Q2 Predictions Max              73.6876
trainer/Q2 Predictions Min            -267.451
trainer/Q Targets Mean                 -74.2661
trainer/Q Targets Std                   83.7758
trainer/Q Targets Max                   73.7552
trainer/Q Targets Min                 -266.062
trainer/Log Pis Mean                     1.95168
trainer/Log Pis Std                      1.82226
trainer/Log Pis Max                      5.6873
trainer/Log Pis Min                     -4.60283
trainer/policy/mean Mean                -0.353426
trainer/policy/mean Std                  0.752766
trainer/policy/mean Max                  0.979332
trainer/policy/mean Min                 -0.986686
trainer/policy/normal/std Mean           0.575351
trainer/policy/normal/std Std            0.0918123
trainer/policy/normal/std Max            0.823188
trainer/policy/normal/std Min            0.243805
trainer/policy/normal/log_std Mean      -0.565156
trainer/policy/normal/log_std Std        0.15712
trainer/policy/normal/log_std Max       -0.194571
trainer/policy/normal/log_std Min       -1.41138
trainer/Alpha                            0.028778
trainer/Alpha Loss                      -0.171462
exploration/num steps total         390000
exploration/num paths total           1950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.844576
exploration/Rewards Std                  1.37195
exploration/Rewards Max                 -1.02362e-145
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -168.915
exploration/Returns Std                108.085
exploration/Returns Max                -28.4056
exploration/Returns Min               -398.905
exploration/Actions Mean                -0.320059
exploration/Actions Std                  0.792906
exploration/Actions Max                  0.998469
exploration/Actions Min                 -0.999506
exploration/Num Paths                   10
exploration/Average Returns           -168.915
evaluation/num steps total          935856
evaluation/num paths total            4656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89528
evaluation/Rewards Std                   0.534353
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1184.95
evaluation/Returns Std                 107.4
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.363898
evaluation/Actions Std                   0.608731
evaluation/Actions Max                   0.301391
evaluation/Actions Min                  -0.971801
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.95
time/data storing (s)                    0.0211483
time/evaluation sampling (s)            14.6803
time/exploration sampling (s)            7.16105
time/logging (s)                         0.0206745
time/sac training (s)                   29.2178
time/saving (s)                          0.0249835
time/training (s)                        0.000116299
time/epoch (s)                          51.1261
time/total (s)                       28512.4
Epoch                                  193
----------------------------------  -----------------
2020-11-09 23:03:23.923635 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 194 finished
----------------------------------  ----------------
replay_buffer/size                  392000
trainer/num train calls             195000
trainer/QF1 Loss                       107.927
trainer/QF2 Loss                       108.712
trainer/Policy Loss                     59.6308
trainer/Q1 Predictions Mean            -59.2914
trainer/Q1 Predictions Std              76.8811
trainer/Q1 Predictions Max              47.0604
trainer/Q1 Predictions Min            -224.282
trainer/Q2 Predictions Mean            -59.1738
trainer/Q2 Predictions Std              76.7176
trainer/Q2 Predictions Max              47.4813
trainer/Q2 Predictions Min            -221.978
trainer/Q Targets Mean                 -58.9269
trainer/Q Targets Std                   77.917
trainer/Q Targets Max                   47.319
trainer/Q Targets Min                 -225.756
trainer/Log Pis Mean                     2.13312
trainer/Log Pis Std                      1.69924
trainer/Log Pis Max                      6.26868
trainer/Log Pis Min                     -5.84149
trainer/policy/mean Mean                -0.351185
trainer/policy/mean Std                  0.760307
trainer/policy/mean Max                  0.976003
trainer/policy/mean Min                 -0.985636
trainer/policy/normal/std Mean           0.5481
trainer/policy/normal/std Std            0.0850503
trainer/policy/normal/std Max            0.841954
trainer/policy/normal/std Min            0.233118
trainer/policy/normal/log_std Mean      -0.613639
trainer/policy/normal/log_std Std        0.159552
trainer/policy/normal/log_std Max       -0.17203
trainer/policy/normal/log_std Min       -1.45621
trainer/Alpha                            0.028337
trainer/Alpha Loss                       0.474395
exploration/num steps total         392000
exploration/num paths total           1960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.41265
exploration/Rewards Std                  1.63904
exploration/Rewards Max                 -8.89869e-69
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -282.53
exploration/Returns Std                165.774
exploration/Returns Max                -71.2678
exploration/Returns Min               -672.227
exploration/Actions Mean                -0.441839
exploration/Actions Std                  0.689668
exploration/Actions Max                  0.996974
exploration/Actions Min                 -0.999424
exploration/Num Paths                   10
exploration/Average Returns           -282.53
evaluation/num steps total          940680
evaluation/num paths total            4680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67356
evaluation/Rewards Std                   0.883175
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.39
evaluation/Returns Std                 177.162
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.344732
evaluation/Actions Std                   0.636508
evaluation/Actions Max                   0.841457
evaluation/Actions Min                  -0.968903
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.39
time/data storing (s)                    0.0241737
time/evaluation sampling (s)            16.1022
time/exploration sampling (s)            7.61553
time/logging (s)                         0.03316
time/sac training (s)                   28.0609
time/saving (s)                          0.019823
time/training (s)                        0.000118913
time/epoch (s)                          51.8559
time/total (s)                       28568.5
Epoch                                  194
----------------------------------  ----------------
2020-11-09 23:04:13.943421 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 195 finished
----------------------------------  -----------------
replay_buffer/size                  394000
trainer/num train calls             196000
trainer/QF1 Loss                        22.6806
trainer/QF2 Loss                        19.8737
trainer/Policy Loss                     58.3966
trainer/Q1 Predictions Mean            -58.0163
trainer/Q1 Predictions Std              79.5887
trainer/Q1 Predictions Max             129.549
trainer/Q1 Predictions Min            -266.805
trainer/Q2 Predictions Mean            -58.0459
trainer/Q2 Predictions Std              79.4919
trainer/Q2 Predictions Max             129.112
trainer/Q2 Predictions Min            -267.625
trainer/Q Targets Mean                 -58.6913
trainer/Q Targets Std                   80.4782
trainer/Q Targets Max                  128.458
trainer/Q Targets Min                 -266.397
trainer/Log Pis Mean                     1.93781
trainer/Log Pis Std                      1.84691
trainer/Log Pis Max                      6.03426
trainer/Log Pis Min                     -5.25235
trainer/policy/mean Mean                -0.465349
trainer/policy/mean Std                  0.693201
trainer/policy/mean Max                  0.958402
trainer/policy/mean Min                 -0.985167
trainer/policy/normal/std Mean           0.583081
trainer/policy/normal/std Std            0.101154
trainer/policy/normal/std Max            1.005
trainer/policy/normal/std Min            0.245737
trainer/policy/normal/log_std Mean      -0.554791
trainer/policy/normal/log_std Std        0.178229
trainer/policy/normal/log_std Max        0.00498908
trainer/policy/normal/log_std Min       -1.40349
trainer/Alpha                            0.0284657
trainer/Alpha Loss                      -0.221335
exploration/num steps total         394000
exploration/num paths total           1970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.34353
exploration/Rewards Std                  1.48336
exploration/Rewards Max                 -9.13928e-103
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -268.705
exploration/Returns Std                144.333
exploration/Returns Max                -52.7009
exploration/Returns Min               -535.224
exploration/Actions Mean                -0.515015
exploration/Actions Std                  0.620707
exploration/Actions Max                  0.994949
exploration/Actions Min                 -0.999808
exploration/Num Paths                   10
exploration/Average Returns           -268.705
evaluation/num steps total          945504
evaluation/num paths total            4704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.49872
evaluation/Rewards Std                   0.981873
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1105.24
evaluation/Returns Std                 196.53
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.576702
evaluation/Actions Std                   0.430605
evaluation/Actions Max                   0.612669
evaluation/Actions Min                  -0.967965
evaluation/Num Paths                    24
evaluation/Average Returns           -1105.24
time/data storing (s)                    0.0214599
time/evaluation sampling (s)            14.5027
time/exploration sampling (s)            5.46732
time/logging (s)                         0.0227464
time/sac training (s)                   27.2104
time/saving (s)                          0.0275914
time/training (s)                        0.000147989
time/epoch (s)                          47.2525
time/total (s)                       28618.5
Epoch                                  195
----------------------------------  -----------------
2020-11-09 23:05:07.756449 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 196 finished
----------------------------------  -----------------
replay_buffer/size                  396000
trainer/num train calls             197000
trainer/QF1 Loss                        30.2592
trainer/QF2 Loss                        26.6523
trainer/Policy Loss                     56.7939
trainer/Q1 Predictions Mean            -56.2962
trainer/Q1 Predictions Std              78.9831
trainer/Q1 Predictions Max              51.4255
trainer/Q1 Predictions Min            -235.269
trainer/Q2 Predictions Mean            -56.6342
trainer/Q2 Predictions Std              79.2453
trainer/Q2 Predictions Max              51.5638
trainer/Q2 Predictions Min            -233.007
trainer/Q Targets Mean                 -56.9526
trainer/Q Targets Std                   79.947
trainer/Q Targets Max                   51.6201
trainer/Q Targets Min                 -235.233
trainer/Log Pis Mean                     1.94206
trainer/Log Pis Std                      1.72666
trainer/Log Pis Max                      6.2822
trainer/Log Pis Min                     -4.91594
trainer/policy/mean Mean                -0.492686
trainer/policy/mean Std                  0.662156
trainer/policy/mean Max                  0.958677
trainer/policy/mean Min                 -0.985564
trainer/policy/normal/std Mean           0.553811
trainer/policy/normal/std Std            0.0928233
trainer/policy/normal/std Max            0.904679
trainer/policy/normal/std Min            0.281083
trainer/policy/normal/log_std Mean      -0.6048
trainer/policy/normal/log_std Std        0.167165
trainer/policy/normal/log_std Max       -0.100175
trainer/policy/normal/log_std Min       -1.26911
trainer/Alpha                            0.0279219
trainer/Alpha Loss                      -0.207338
exploration/num steps total         396000
exploration/num paths total           1980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.83672
exploration/Rewards Std                  1.69569
exploration/Rewards Max                 -7.58217e-267
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -167.344
exploration/Returns Std                 57.7838
exploration/Returns Max                -53.0727
exploration/Returns Min               -285.336
exploration/Actions Mean                -0.367688
exploration/Actions Std                  0.756655
exploration/Actions Max                  0.998348
exploration/Actions Min                 -0.998968
exploration/Num Paths                   10
exploration/Average Returns           -167.344
evaluation/num steps total          950328
evaluation/num paths total            4728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95804
evaluation/Rewards Std                   0.562606
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.57
evaluation/Returns Std                 113.082
evaluation/Returns Max                -655.242
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.713245
evaluation/Actions Std                   0.270055
evaluation/Actions Max                   0.277494
evaluation/Actions Min                  -0.970594
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.57
time/data storing (s)                    0.0250896
time/evaluation sampling (s)            15.8617
time/exploration sampling (s)            6.81009
time/logging (s)                         0.0246054
time/sac training (s)                   28.6522
time/saving (s)                          0.0235735
time/training (s)                        0.000125462
time/epoch (s)                          51.3973
time/total (s)                       28672.3
Epoch                                  196
----------------------------------  -----------------
2020-11-09 23:05:58.687443 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 197 finished
----------------------------------  -----------------
replay_buffer/size                  398000
trainer/num train calls             198000
trainer/QF1 Loss                        91.9656
trainer/QF2 Loss                        89.0274
trainer/Policy Loss                     52.6649
trainer/Q1 Predictions Mean            -52.2262
trainer/Q1 Predictions Std              80.0303
trainer/Q1 Predictions Max             125.67
trainer/Q1 Predictions Min            -222.889
trainer/Q2 Predictions Mean            -52.2164
trainer/Q2 Predictions Std              79.8657
trainer/Q2 Predictions Max             125.357
trainer/Q2 Predictions Min            -220.298
trainer/Q Targets Mean                 -51.7397
trainer/Q Targets Std                   80.3331
trainer/Q Targets Max                  125.798
trainer/Q Targets Min                 -224.53
trainer/Log Pis Mean                     2.10512
trainer/Log Pis Std                      2.00923
trainer/Log Pis Max                      6.22959
trainer/Log Pis Min                     -9.13967
trainer/policy/mean Mean                -0.574985
trainer/policy/mean Std                  0.613828
trainer/policy/mean Max                  0.945899
trainer/policy/mean Min                 -0.994206
trainer/policy/normal/std Mean           0.560248
trainer/policy/normal/std Std            0.0913512
trainer/policy/normal/std Max            0.898574
trainer/policy/normal/std Min            0.228372
trainer/policy/normal/log_std Mean      -0.593231
trainer/policy/normal/log_std Std        0.169821
trainer/policy/normal/log_std Max       -0.106946
trainer/policy/normal/log_std Min       -1.47678
trainer/Alpha                            0.0277495
trainer/Alpha Loss                       0.376808
exploration/num steps total         398000
exploration/num paths total           1990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.904581
exploration/Rewards Std                  1.74439
exploration/Rewards Max                 -8.23948e-276
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -180.916
exploration/Returns Std                 94.9361
exploration/Returns Max                -38.3426
exploration/Returns Min               -335.894
exploration/Actions Mean                -0.502585
exploration/Actions Std                  0.636035
exploration/Actions Max                  0.996509
exploration/Actions Min                 -0.999516
exploration/Num Paths                   10
exploration/Average Returns           -180.916
evaluation/num steps total          955152
evaluation/num paths total            4752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.91173e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   2.36658e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.856729
evaluation/Actions Std                   0.113051
evaluation/Actions Max                  -0.743564
evaluation/Actions Min                  -0.969955
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0210344
time/evaluation sampling (s)            14.3859
time/exploration sampling (s)            5.373
time/logging (s)                         0.0215523
time/sac training (s)                   29.6815
time/saving (s)                          0.0213145
time/training (s)                        9.4098e-05
time/epoch (s)                          49.5044
time/total (s)                       28723.2
Epoch                                  197
----------------------------------  -----------------
2020-11-09 23:06:45.869923 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 198 finished
----------------------------------  ----------------
replay_buffer/size                  400000
trainer/num train calls             199000
trainer/QF1 Loss                        10.3824
trainer/QF2 Loss                        12.7454
trainer/Policy Loss                     67.9966
trainer/Q1 Predictions Mean            -67.5886
trainer/Q1 Predictions Std              81.5731
trainer/Q1 Predictions Max              84.9245
trainer/Q1 Predictions Min            -267.514
trainer/Q2 Predictions Mean            -67.5231
trainer/Q2 Predictions Std              81.5095
trainer/Q2 Predictions Max              84.8979
trainer/Q2 Predictions Min            -268.336
trainer/Q Targets Mean                 -68.2638
trainer/Q Targets Std                   82.4685
trainer/Q Targets Max                   84.6469
trainer/Q Targets Min                 -267.038
trainer/Log Pis Mean                     2.30411
trainer/Log Pis Std                      1.86541
trainer/Log Pis Max                      6.28784
trainer/Log Pis Min                     -8.7603
trainer/policy/mean Mean                -0.502695
trainer/policy/mean Std                  0.673108
trainer/policy/mean Max                  0.952661
trainer/policy/mean Min                 -0.987441
trainer/policy/normal/std Mean           0.568831
trainer/policy/normal/std Std            0.0922242
trainer/policy/normal/std Max            0.98308
trainer/policy/normal/std Min            0.248717
trainer/policy/normal/log_std Mean      -0.57674
trainer/policy/normal/log_std Std        0.157996
trainer/policy/normal/log_std Max       -0.0170647
trainer/policy/normal/log_std Min       -1.39144
trainer/Alpha                            0.0279384
trainer/Alpha Loss                       1.08805
exploration/num steps total         400000
exploration/num paths total           2000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15696
exploration/Rewards Std                  1.59372
exploration/Rewards Max                 -7.10062e-58
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -231.393
exploration/Returns Std                123.007
exploration/Returns Max                -90.5035
exploration/Returns Min               -468.655
exploration/Actions Mean                -0.40352
exploration/Actions Std                  0.748015
exploration/Actions Max                  0.998443
exploration/Actions Min                 -0.999756
exploration/Num Paths                   10
exploration/Average Returns           -231.393
evaluation/num steps total          959976
evaluation/num paths total            4776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44714
evaluation/Rewards Std                   1.09159
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1094.87
evaluation/Returns Std                 219.257
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.682163
evaluation/Actions Std                   0.340008
evaluation/Actions Max                   0.295083
evaluation/Actions Min                  -0.977194
evaluation/Num Paths                    24
evaluation/Average Returns           -1094.87
time/data storing (s)                    0.0258094
time/evaluation sampling (s)            13.0655
time/exploration sampling (s)            5.28996
time/logging (s)                         0.0170727
time/sac training (s)                   27.2413
time/saving (s)                          0.0214473
time/training (s)                        0.000114259
time/epoch (s)                          45.6612
time/total (s)                       28770.4
Epoch                                  198
----------------------------------  ----------------
2020-11-09 23:07:36.148993 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 199 finished
----------------------------------  -----------------
replay_buffer/size                  402000
trainer/num train calls             200000
trainer/QF1 Loss                       100.962
trainer/QF2 Loss                        99.7273
trainer/Policy Loss                     67.3839
trainer/Q1 Predictions Mean            -66.967
trainer/Q1 Predictions Std              82.6731
trainer/Q1 Predictions Max             111.821
trainer/Q1 Predictions Min            -294.896
trainer/Q2 Predictions Mean            -66.8421
trainer/Q2 Predictions Std              82.5488
trainer/Q2 Predictions Max             112.339
trainer/Q2 Predictions Min            -292.014
trainer/Q Targets Mean                 -66.8955
trainer/Q Targets Std                   83.34
trainer/Q Targets Max                  112.099
trainer/Q Targets Min                 -293.671
trainer/Log Pis Mean                     1.77786
trainer/Log Pis Std                      1.66665
trainer/Log Pis Max                      5.53872
trainer/Log Pis Min                     -3.78411
trainer/policy/mean Mean                -0.477311
trainer/policy/mean Std                  0.665173
trainer/policy/mean Max                  0.95546
trainer/policy/mean Min                 -0.996107
trainer/policy/normal/std Mean           0.558978
trainer/policy/normal/std Std            0.0847122
trainer/policy/normal/std Max            0.945009
trainer/policy/normal/std Min            0.234112
trainer/policy/normal/log_std Mean      -0.594708
trainer/policy/normal/log_std Std        0.168891
trainer/policy/normal/log_std Max       -0.0565606
trainer/policy/normal/log_std Min       -1.45196
trainer/Alpha                            0.0283262
trainer/Alpha Loss                      -0.79171
exploration/num steps total         402000
exploration/num paths total           2010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.808544
exploration/Rewards Std                  1.42198
exploration/Rewards Max                 -4.00845e-101
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -161.709
exploration/Returns Std                115.117
exploration/Returns Max                -28.4359
exploration/Returns Min               -417.299
exploration/Actions Mean                -0.376928
exploration/Actions Std                  0.756489
exploration/Actions Max                  0.998768
exploration/Actions Min                 -0.998958
exploration/Num Paths                   10
exploration/Average Returns           -161.709
evaluation/num steps total          964800
evaluation/num paths total            4800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.09036
evaluation/Rewards Std                   1.47858
evaluation/Rewards Max                  -2.77418e-22
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1023.16
evaluation/Returns Std                 295.036
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.548606
evaluation/Actions Std                   0.435742
evaluation/Actions Max                   0.635252
evaluation/Actions Min                  -0.970942
evaluation/Num Paths                    24
evaluation/Average Returns           -1023.16
time/data storing (s)                    0.0193757
time/evaluation sampling (s)            12.9279
time/exploration sampling (s)            5.57308
time/logging (s)                         0.0269768
time/sac training (s)                   30.241
time/saving (s)                          0.0220757
time/training (s)                        0.000115311
time/epoch (s)                          48.8106
time/total (s)                       28820.6
Epoch                                  199
----------------------------------  -----------------
2020-11-09 23:08:30.079378 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 200 finished
----------------------------------  ----------------
replay_buffer/size                  404000
trainer/num train calls             201000
trainer/QF1 Loss                        32.6453
trainer/QF2 Loss                        36.2803
trainer/Policy Loss                     77.7087
trainer/Q1 Predictions Mean            -77.3109
trainer/Q1 Predictions Std              83.6368
trainer/Q1 Predictions Max              43.8039
trainer/Q1 Predictions Min            -268.026
trainer/Q2 Predictions Mean            -77.2228
trainer/Q2 Predictions Std              83.5803
trainer/Q2 Predictions Max              44.3258
trainer/Q2 Predictions Min            -268.836
trainer/Q Targets Mean                 -77.2507
trainer/Q Targets Std                   84.4159
trainer/Q Targets Max                   44.4389
trainer/Q Targets Min                 -267.461
trainer/Log Pis Mean                     2.03941
trainer/Log Pis Std                      1.64883
trainer/Log Pis Max                      6.3084
trainer/Log Pis Min                     -2.71443
trainer/policy/mean Mean                -0.527599
trainer/policy/mean Std                  0.654944
trainer/policy/mean Max                  0.954121
trainer/policy/mean Min                 -0.982327
trainer/policy/normal/std Mean           0.583632
trainer/policy/normal/std Std            0.0945407
trainer/policy/normal/std Max            0.987603
trainer/policy/normal/std Min            0.302621
trainer/policy/normal/log_std Mean      -0.55111
trainer/policy/normal/log_std Std        0.158308
trainer/policy/normal/log_std Max       -0.0124748
trainer/policy/normal/log_std Min       -1.19527
trainer/Alpha                            0.0287554
trainer/Alpha Loss                       0.139863
exploration/num steps total         404000
exploration/num paths total           2020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.800479
exploration/Rewards Std                  1.35927
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -160.096
exploration/Returns Std                151.891
exploration/Returns Max                -15.3349
exploration/Returns Min               -497.111
exploration/Actions Mean                -0.580306
exploration/Actions Std                  0.578669
exploration/Actions Max                  0.992758
exploration/Actions Min                 -0.999466
exploration/Num Paths                   10
exploration/Average Returns           -160.096
evaluation/num steps total          969624
evaluation/num paths total            4824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.737355
evaluation/Actions Std                   0.243223
evaluation/Actions Max                  -0.0283101
evaluation/Actions Min                  -0.971239
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.0245961
time/evaluation sampling (s)            16.7554
time/exploration sampling (s)            5.43083
time/logging (s)                         0.0268564
time/sac training (s)                   28.8959
time/saving (s)                          0.021952
time/training (s)                        0.000123815
time/epoch (s)                          51.1556
time/total (s)                       28874.5
Epoch                                  200
----------------------------------  ----------------
2020-11-09 23:09:24.939632 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 201 finished
----------------------------------  ----------------
replay_buffer/size                  406000
trainer/num train calls             202000
trainer/QF1 Loss                       218.889
trainer/QF2 Loss                       233.677
trainer/Policy Loss                     62.2292
trainer/Q1 Predictions Mean            -61.9905
trainer/Q1 Predictions Std              78.7532
trainer/Q1 Predictions Max              84.396
trainer/Q1 Predictions Min            -205.648
trainer/Q2 Predictions Mean            -61.6247
trainer/Q2 Predictions Std              78.5889
trainer/Q2 Predictions Max              84.299
trainer/Q2 Predictions Min            -203.842
trainer/Q Targets Mean                 -60.8828
trainer/Q Targets Std                   79.0796
trainer/Q Targets Max                   83.9471
trainer/Q Targets Min                 -209.465
trainer/Log Pis Mean                     2.07046
trainer/Log Pis Std                      1.69946
trainer/Log Pis Max                      6.1137
trainer/Log Pis Min                     -3.89268
trainer/policy/mean Mean                -0.444672
trainer/policy/mean Std                  0.700793
trainer/policy/mean Max                  0.966705
trainer/policy/mean Min                 -0.986747
trainer/policy/normal/std Mean           0.575445
trainer/policy/normal/std Std            0.0966894
trainer/policy/normal/std Max            0.947828
trainer/policy/normal/std Min            0.241672
trainer/policy/normal/log_std Mean      -0.566496
trainer/policy/normal/log_std Std        0.16729
trainer/policy/normal/log_std Max       -0.0535817
trainer/policy/normal/log_std Min       -1.42017
trainer/Alpha                            0.0292426
trainer/Alpha Loss                       0.248864
exploration/num steps total         406000
exploration/num paths total           2030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00741
exploration/Rewards Std                  1.42018
exploration/Rewards Max                 -1.346e-90
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -201.483
exploration/Returns Std                160.275
exploration/Returns Max                -30.3544
exploration/Returns Min               -551.277
exploration/Actions Mean                -0.376487
exploration/Actions Std                  0.762587
exploration/Actions Max                  0.997646
exploration/Actions Min                 -0.999815
exploration/Num Paths                   10
exploration/Average Returns           -201.483
evaluation/num steps total          974448
evaluation/num paths total            4848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.84982e-10
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   2.56759e-09
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.737294
evaluation/Actions Std                   0.233582
evaluation/Actions Max                  -0.503633
evaluation/Actions Min                  -0.970876
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0214738
time/evaluation sampling (s)            17.3065
time/exploration sampling (s)            6.39118
time/logging (s)                         0.0214613
time/sac training (s)                   29.0765
time/saving (s)                          0.0259642
time/training (s)                        9.8956e-05
time/epoch (s)                          52.8432
time/total (s)                       28929.3
Epoch                                  201
----------------------------------  ----------------
2020-11-09 23:10:13.159150 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 202 finished
----------------------------------  -----------------
replay_buffer/size                  408000
trainer/num train calls             203000
trainer/QF1 Loss                       257.784
trainer/QF2 Loss                       257.559
trainer/Policy Loss                     65.9297
trainer/Q1 Predictions Mean            -65.4783
trainer/Q1 Predictions Std              79.7821
trainer/Q1 Predictions Max              83.4627
trainer/Q1 Predictions Min            -254.512
trainer/Q2 Predictions Mean            -65.4454
trainer/Q2 Predictions Std              79.7692
trainer/Q2 Predictions Max              83.3265
trainer/Q2 Predictions Min            -254.203
trainer/Q Targets Mean                 -64.5733
trainer/Q Targets Std                   80.1336
trainer/Q Targets Max                   83.4845
trainer/Q Targets Min                 -253.395
trainer/Log Pis Mean                     1.97817
trainer/Log Pis Std                      1.59947
trainer/Log Pis Max                      5.79989
trainer/Log Pis Min                     -4.13007
trainer/policy/mean Mean                -0.408554
trainer/policy/mean Std                  0.726438
trainer/policy/mean Max                  0.969772
trainer/policy/mean Min                 -0.986772
trainer/policy/normal/std Mean           0.579291
trainer/policy/normal/std Std            0.0934969
trainer/policy/normal/std Max            0.970734
trainer/policy/normal/std Min            0.25739
trainer/policy/normal/log_std Mean      -0.558638
trainer/policy/normal/log_std Std        0.159522
trainer/policy/normal/log_std Max       -0.0297027
trainer/policy/normal/log_std Min       -1.35716
trainer/Alpha                            0.0290515
trainer/Alpha Loss                      -0.0772336
exploration/num steps total         408000
exploration/num paths total           2040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.612129
exploration/Rewards Std                  1.31403
exploration/Rewards Max                 -8.82846e-105
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -122.426
exploration/Returns Std                 78.7094
exploration/Returns Max                -29.9176
exploration/Returns Min               -275.572
exploration/Actions Mean                -0.239863
exploration/Actions Std                  0.8215
exploration/Actions Max                  0.99875
exploration/Actions Min                 -0.999536
exploration/Num Paths                   10
exploration/Average Returns           -122.426
evaluation/num steps total          979272
evaluation/num paths total            4872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.50787
evaluation/Rewards Std                   0.957271
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1107.08
evaluation/Returns Std                 192.401
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.645798
evaluation/Actions Std                   0.373456
evaluation/Actions Max                  -0.183334
evaluation/Actions Min                  -0.969189
evaluation/Num Paths                    24
evaluation/Average Returns           -1107.08
time/data storing (s)                    0.0281835
time/evaluation sampling (s)            13.7495
time/exploration sampling (s)            4.96055
time/logging (s)                         0.0223128
time/sac training (s)                   27.924
time/saving (s)                          0.0205948
time/training (s)                        0.000103221
time/epoch (s)                          46.7052
time/total (s)                       28977.5
Epoch                                  202
----------------------------------  -----------------
2020-11-09 23:11:30.281156 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 203 finished
----------------------------------  ----------------
replay_buffer/size                  410000
trainer/num train calls             204000
trainer/QF1 Loss                       139.988
trainer/QF2 Loss                       139.617
trainer/Policy Loss                     60.4039
trainer/Q1 Predictions Mean            -60.1907
trainer/Q1 Predictions Std              81.1047
trainer/Q1 Predictions Max              81.9824
trainer/Q1 Predictions Min            -226.985
trainer/Q2 Predictions Mean            -59.8831
trainer/Q2 Predictions Std              80.8249
trainer/Q2 Predictions Max              81.7696
trainer/Q2 Predictions Min            -225.8
trainer/Q Targets Mean                 -59.604
trainer/Q Targets Std                   81.2939
trainer/Q Targets Max                   82.1719
trainer/Q Targets Min                 -226.011
trainer/Log Pis Mean                     1.79248
trainer/Log Pis Std                      1.79228
trainer/Log Pis Max                      6.26961
trainer/Log Pis Min                     -5.17226
trainer/policy/mean Mean                -0.387448
trainer/policy/mean Std                  0.731405
trainer/policy/mean Max                  0.967906
trainer/policy/mean Min                 -0.986419
trainer/policy/normal/std Mean           0.584857
trainer/policy/normal/std Std            0.0935486
trainer/policy/normal/std Max            0.913822
trainer/policy/normal/std Min            0.278786
trainer/policy/normal/log_std Mean      -0.549177
trainer/policy/normal/log_std Std        0.161023
trainer/policy/normal/log_std Max       -0.0901192
trainer/policy/normal/log_std Min       -1.27731
trainer/Alpha                            0.0287917
trainer/Alpha Loss                      -0.736224
exploration/num steps total         410000
exploration/num paths total           2050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.983501
exploration/Rewards Std                  1.49454
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -196.7
exploration/Returns Std                131.192
exploration/Returns Max                -45.8857
exploration/Returns Min               -507.372
exploration/Actions Mean                -0.508692
exploration/Actions Std                  0.611072
exploration/Actions Max                  0.994364
exploration/Actions Min                 -0.999085
exploration/Num Paths                   10
exploration/Average Returns           -196.7
evaluation/num steps total          984096
evaluation/num paths total            4896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.71957
evaluation/Rewards Std                   0.718817
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1149.63
evaluation/Returns Std                 144.249
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.537172
evaluation/Actions Std                   0.460246
evaluation/Actions Max                   0.808417
evaluation/Actions Min                  -0.970155
evaluation/Num Paths                    24
evaluation/Average Returns           -1149.63
time/data storing (s)                    0.0319406
time/evaluation sampling (s)            13.5704
time/exploration sampling (s)            8.77664
time/logging (s)                         0.0335389
time/sac training (s)                   38.2702
time/saving (s)                          0.0351838
time/training (s)                        0.000112749
time/epoch (s)                          60.7179
time/total (s)                       29054.6
Epoch                                  203
----------------------------------  ----------------
2020-11-09 23:12:24.521616 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 204 finished
----------------------------------  -----------------
replay_buffer/size                  412000
trainer/num train calls             205000
trainer/QF1 Loss                        38.0515
trainer/QF2 Loss                        33.6879
trainer/Policy Loss                     60.5921
trainer/Q1 Predictions Mean            -60.1533
trainer/Q1 Predictions Std              79.5773
trainer/Q1 Predictions Max              81.4304
trainer/Q1 Predictions Min            -227.311
trainer/Q2 Predictions Mean            -60.32
trainer/Q2 Predictions Std              79.6444
trainer/Q2 Predictions Max              81.5679
trainer/Q2 Predictions Min            -226.633
trainer/Q Targets Mean                 -61.0456
trainer/Q Targets Std                   80.1092
trainer/Q Targets Max                   81.2723
trainer/Q Targets Min                 -226.097
trainer/Log Pis Mean                     2.06658
trainer/Log Pis Std                      1.63468
trainer/Log Pis Max                      6.20652
trainer/Log Pis Min                     -5.20584
trainer/policy/mean Mean                -0.401775
trainer/policy/mean Std                  0.72261
trainer/policy/mean Max                  0.969678
trainer/policy/mean Min                 -0.986544
trainer/policy/normal/std Mean           0.586755
trainer/policy/normal/std Std            0.100091
trainer/policy/normal/std Max            0.939146
trainer/policy/normal/std Min            0.277049
trainer/policy/normal/log_std Mean      -0.547139
trainer/policy/normal/log_std Std        0.166384
trainer/policy/normal/log_std Max       -0.0627845
trainer/policy/normal/log_std Min       -1.28356
trainer/Alpha                            0.0283412
trainer/Alpha Loss                       0.237265
exploration/num steps total         412000
exploration/num paths total           2060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.966771
exploration/Rewards Std                  1.45988
exploration/Rewards Max                 -3.69301e-151
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -193.354
exploration/Returns Std                148.803
exploration/Returns Max                -59.7441
exploration/Returns Min               -542.301
exploration/Actions Mean                -0.400841
exploration/Actions Std                  0.708485
exploration/Actions Max                  0.998713
exploration/Actions Min                 -0.998466
exploration/Num Paths                   10
exploration/Average Returns           -193.354
evaluation/num steps total          988920
evaluation/num paths total            4920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.22121
evaluation/Rewards Std                   1.22703
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1049.46
evaluation/Returns Std                 246.094
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.556592
evaluation/Actions Std                   0.492776
evaluation/Actions Max                   0.637961
evaluation/Actions Min                  -0.972852
evaluation/Num Paths                    24
evaluation/Average Returns           -1049.46
time/data storing (s)                    0.0320509
time/evaluation sampling (s)            14.2324
time/exploration sampling (s)            5.13728
time/logging (s)                         0.0232443
time/sac training (s)                   28.0547
time/saving (s)                          0.0210323
time/training (s)                        0.000117614
time/epoch (s)                          47.5008
time/total (s)                       29108.8
Epoch                                  204
----------------------------------  -----------------
2020-11-09 23:13:14.874483 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 205 finished
----------------------------------  ----------------
replay_buffer/size                  414000
trainer/num train calls             206000
trainer/QF1 Loss                        41.2515
trainer/QF2 Loss                        37.5858
trainer/Policy Loss                     55.2288
trainer/Q1 Predictions Mean            -54.8172
trainer/Q1 Predictions Std              78.9304
trainer/Q1 Predictions Max              81.5998
trainer/Q1 Predictions Min            -221.669
trainer/Q2 Predictions Mean            -54.89
trainer/Q2 Predictions Std              79.0174
trainer/Q2 Predictions Max              81.531
trainer/Q2 Predictions Min            -222.639
trainer/Q Targets Mean                 -55.1057
trainer/Q Targets Std                   80.4151
trainer/Q Targets Max                   81.3116
trainer/Q Targets Min                 -222.406
trainer/Log Pis Mean                     1.85005
trainer/Log Pis Std                      1.8426
trainer/Log Pis Max                      6.07682
trainer/Log Pis Min                     -5.79357
trainer/policy/mean Mean                -0.367277
trainer/policy/mean Std                  0.751631
trainer/policy/mean Max                  0.964962
trainer/policy/mean Min                 -0.984392
trainer/policy/normal/std Mean           0.576563
trainer/policy/normal/std Std            0.0907129
trainer/policy/normal/std Max            0.960751
trainer/policy/normal/std Min            0.255994
trainer/policy/normal/log_std Mean      -0.563183
trainer/policy/normal/log_std Std        0.159995
trainer/policy/normal/log_std Max       -0.0400398
trainer/policy/normal/log_std Min       -1.3626
trainer/Alpha                            0.0289817
trainer/Alpha Loss                      -0.530989
exploration/num steps total         414000
exploration/num paths total           2070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14335
exploration/Rewards Std                  1.61497
exploration/Rewards Max                 -3.10796e-31
exploration/Rewards Min                 -6.12355
exploration/Returns Mean              -228.669
exploration/Returns Std                162.299
exploration/Returns Max                -53.0582
exploration/Returns Min               -582.755
exploration/Actions Mean                -0.531024
exploration/Actions Std                  0.688775
exploration/Actions Max                  0.997589
exploration/Actions Min                 -0.99904
exploration/Num Paths                   10
exploration/Average Returns           -228.669
evaluation/num steps total          993744
evaluation/num paths total            4944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6759
evaluation/Rewards Std                   0.876113
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.86
evaluation/Returns Std                 175.918
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.459593
evaluation/Actions Std                   0.549991
evaluation/Actions Max                   0.88618
evaluation/Actions Min                  -0.973911
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.86
time/data storing (s)                    0.0283621
time/evaluation sampling (s)            12.9506
time/exploration sampling (s)            5.44967
time/logging (s)                         0.0221213
time/sac training (s)                   28.4863
time/saving (s)                          0.0227425
time/training (s)                        0.000121294
time/epoch (s)                          46.9599
time/total (s)                       29159.2
Epoch                                  205
----------------------------------  ----------------
2020-11-09 23:14:10.823266 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 206 finished
----------------------------------  -----------------
replay_buffer/size                  416000
trainer/num train calls             207000
trainer/QF1 Loss                        24.7569
trainer/QF2 Loss                        25.6117
trainer/Policy Loss                     61.5435
trainer/Q1 Predictions Mean            -61.0895
trainer/Q1 Predictions Std              81.1448
trainer/Q1 Predictions Max              80.0946
trainer/Q1 Predictions Min            -268.637
trainer/Q2 Predictions Mean            -61.2363
trainer/Q2 Predictions Std              81.4053
trainer/Q2 Predictions Max              79.9585
trainer/Q2 Predictions Min            -269.182
trainer/Q Targets Mean                 -61.4231
trainer/Q Targets Std                   81.8753
trainer/Q Targets Max                   80.0855
trainer/Q Targets Min                 -267.903
trainer/Log Pis Mean                     2.00532
trainer/Log Pis Std                      1.60436
trainer/Log Pis Max                      5.8866
trainer/Log Pis Min                     -2.29285
trainer/policy/mean Mean                -0.490152
trainer/policy/mean Std                  0.673207
trainer/policy/mean Max                  0.946236
trainer/policy/mean Min                 -0.989428
trainer/policy/normal/std Mean           0.5974
trainer/policy/normal/std Std            0.11074
trainer/policy/normal/std Max            1.02141
trainer/policy/normal/std Min            0.25884
trainer/policy/normal/log_std Mean      -0.532207
trainer/policy/normal/log_std Std        0.185683
trainer/policy/normal/log_std Max        0.0211813
trainer/policy/normal/log_std Min       -1.35155
trainer/Alpha                            0.0289305
trainer/Alpha Loss                       0.0188407
exploration/num steps total         416000
exploration/num paths total           2080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.18567
exploration/Rewards Std                  1.57258
exploration/Rewards Max                 -2.38238e-142
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -237.134
exploration/Returns Std                167.298
exploration/Returns Max                -16.0707
exploration/Returns Min               -612.403
exploration/Actions Mean                -0.515279
exploration/Actions Std                  0.67184
exploration/Actions Max                  0.999863
exploration/Actions Min                 -0.999203
exploration/Num Paths                   10
exploration/Average Returns           -237.134
evaluation/num steps total          998568
evaluation/num paths total            4968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73252
evaluation/Rewards Std                   0.90704
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1152.24
evaluation/Returns Std                 182.315
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.68857
evaluation/Actions Std                   0.327421
evaluation/Actions Max                   0.234037
evaluation/Actions Min                  -0.970324
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.24
time/data storing (s)                    0.0244684
time/evaluation sampling (s)            15.1801
time/exploration sampling (s)            6.09414
time/logging (s)                         0.0374408
time/sac training (s)                   30.5771
time/saving (s)                          0.0380793
time/training (s)                        0.000133041
time/epoch (s)                          51.9514
time/total (s)                       29215.1
Epoch                                  206
----------------------------------  -----------------
2020-11-09 23:16:41.042980 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 207 finished
----------------------------------  -----------------
replay_buffer/size                  418000
trainer/num train calls             208000
trainer/QF1 Loss                        27.2855
trainer/QF2 Loss                        27.9195
trainer/Policy Loss                     74.0968
trainer/Q1 Predictions Mean            -73.7726
trainer/Q1 Predictions Std              86.1472
trainer/Q1 Predictions Max             114.288
trainer/Q1 Predictions Min            -255.319
trainer/Q2 Predictions Mean            -73.662
trainer/Q2 Predictions Std              86.0789
trainer/Q2 Predictions Max             113.181
trainer/Q2 Predictions Min            -255.206
trainer/Q Targets Mean                 -74.0294
trainer/Q Targets Std                   87.0407
trainer/Q Targets Max                  112.999
trainer/Q Targets Min                 -254.169
trainer/Log Pis Mean                     1.98505
trainer/Log Pis Std                      1.74765
trainer/Log Pis Max                      6.39348
trainer/Log Pis Min                     -4.1434
trainer/policy/mean Mean                -0.439646
trainer/policy/mean Std                  0.71473
trainer/policy/mean Max                  0.957083
trainer/policy/mean Min                 -0.985483
trainer/policy/normal/std Mean           0.593415
trainer/policy/normal/std Std            0.107595
trainer/policy/normal/std Max            1.03622
trainer/policy/normal/std Min            0.253052
trainer/policy/normal/log_std Mean      -0.538047
trainer/policy/normal/log_std Std        0.180588
trainer/policy/normal/log_std Max        0.0355758
trainer/policy/normal/log_std Min       -1.37416
trainer/Alpha                            0.0286016
trainer/Alpha Loss                      -0.0531462
exploration/num steps total         418000
exploration/num paths total           2090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.811463
exploration/Rewards Std                  1.37651
exploration/Rewards Max                 -6.01631e-271
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -162.293
exploration/Returns Std                 79.9037
exploration/Returns Max                -51.47
exploration/Returns Min               -291.492
exploration/Actions Mean                -0.438873
exploration/Actions Std                  0.68301
exploration/Actions Max                  0.995379
exploration/Actions Min                 -0.999084
exploration/Num Paths                   10
exploration/Average Returns           -162.293
evaluation/num steps total               1.00339e+06
evaluation/num paths total            4992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.72101
evaluation/Rewards Std                   0.714027
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1149.92
evaluation/Returns Std                 143.285
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.592092
evaluation/Actions Std                   0.389985
evaluation/Actions Max                  -0.0726476
evaluation/Actions Min                  -0.969168
evaluation/Num Paths                    24
evaluation/Average Returns           -1149.92
time/data storing (s)                    0.027706
time/evaluation sampling (s)            22.2482
time/exploration sampling (s)            8.30958
time/logging (s)                         0.0664255
time/sac training (s)                   54.9482
time/saving (s)                          0.156619
time/training (s)                        0.000200797
time/epoch (s)                          85.757
time/total (s)                       29365.3
Epoch                                  207
----------------------------------  -----------------
2020-11-09 23:19:00.876462 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 208 finished
----------------------------------  -----------------
replay_buffer/size                  420000
trainer/num train calls             209000
trainer/QF1 Loss                       198.328
trainer/QF2 Loss                       183.401
trainer/Policy Loss                     63.7078
trainer/Q1 Predictions Mean            -63.1266
trainer/Q1 Predictions Std              84.1418
trainer/Q1 Predictions Max              99.8953
trainer/Q1 Predictions Min            -225.164
trainer/Q2 Predictions Mean            -63.308
trainer/Q2 Predictions Std              84.3325
trainer/Q2 Predictions Max              99.6182
trainer/Q2 Predictions Min            -224.179
trainer/Q Targets Mean                 -62.3627
trainer/Q Targets Std                   84.4409
trainer/Q Targets Max                   99.4103
trainer/Q Targets Min                 -224.768
trainer/Log Pis Mean                     1.88768
trainer/Log Pis Std                      1.76266
trainer/Log Pis Max                      5.89547
trainer/Log Pis Min                     -5.42968
trainer/policy/mean Mean                -0.254224
trainer/policy/mean Std                  0.809691
trainer/policy/mean Max                  0.979291
trainer/policy/mean Min                 -0.987593
trainer/policy/normal/std Mean           0.559712
trainer/policy/normal/std Std            0.0783947
trainer/policy/normal/std Max            0.936215
trainer/policy/normal/std Min            0.22963
trainer/policy/normal/log_std Mean      -0.590901
trainer/policy/normal/log_std Std        0.149775
trainer/policy/normal/log_std Max       -0.0659106
trainer/policy/normal/log_std Min       -1.47128
trainer/Alpha                            0.0283167
trainer/Alpha Loss                      -0.400339
exploration/num steps total         420000
exploration/num paths total           2100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.772759
exploration/Rewards Std                  1.3768
exploration/Rewards Max                 -4.03947e-200
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -154.552
exploration/Returns Std                152.552
exploration/Returns Max                -16.0707
exploration/Returns Min               -550.725
exploration/Actions Mean                -0.352153
exploration/Actions Std                  0.757675
exploration/Actions Max                  0.99869
exploration/Actions Min                 -0.999088
exploration/Num Paths                   10
exploration/Average Returns           -154.552
evaluation/num steps total               1.00822e+06
evaluation/num paths total            5016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.28836
evaluation/Rewards Std                   1.12586
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1062.96
evaluation/Returns Std                 225.459
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.311363
evaluation/Actions Std                   0.676162
evaluation/Actions Max                   0.901784
evaluation/Actions Min                  -0.960827
evaluation/Num Paths                    24
evaluation/Average Returns           -1062.96
time/data storing (s)                    0.0240682
time/evaluation sampling (s)            19.3079
time/exploration sampling (s)            6.25797
time/logging (s)                         0.0376977
time/sac training (s)                   49.2988
time/saving (s)                          0.0743342
time/training (s)                        0.000193996
time/epoch (s)                          75.001
time/total (s)                       29505.1
Epoch                                  208
----------------------------------  -----------------
2020-11-09 23:21:43.379833 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 209 finished
----------------------------------  -----------------
replay_buffer/size                  422000
trainer/num train calls             210000
trainer/QF1 Loss                        86.5115
trainer/QF2 Loss                        77.8525
trainer/Policy Loss                     64.5857
trainer/Q1 Predictions Mean            -64.2428
trainer/Q1 Predictions Std              81.6402
trainer/Q1 Predictions Max              53.0931
trainer/Q1 Predictions Min            -268.03
trainer/Q2 Predictions Mean            -64.2157
trainer/Q2 Predictions Std              81.6051
trainer/Q2 Predictions Max              53.0417
trainer/Q2 Predictions Min            -268.708
trainer/Q Targets Mean                 -64.2513
trainer/Q Targets Std                   82.3597
trainer/Q Targets Max                   52.0895
trainer/Q Targets Min                 -267.69
trainer/Log Pis Mean                     1.95957
trainer/Log Pis Std                      1.69055
trainer/Log Pis Max                      6.28265
trainer/Log Pis Min                     -6.12334
trainer/policy/mean Mean                -0.438342
trainer/policy/mean Std                  0.707546
trainer/policy/mean Max                  0.961423
trainer/policy/mean Min                 -0.983925
trainer/policy/normal/std Mean           0.577656
trainer/policy/normal/std Std            0.0915349
trainer/policy/normal/std Max            0.843122
trainer/policy/normal/std Min            0.20068
trainer/policy/normal/log_std Mean      -0.562094
trainer/policy/normal/log_std Std        0.167697
trainer/policy/normal/log_std Max       -0.170644
trainer/policy/normal/log_std Min       -1.60604
trainer/Alpha                            0.0283584
trainer/Alpha Loss                      -0.144036
exploration/num steps total         422000
exploration/num paths total           2110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.944722
exploration/Rewards Std                  1.39756
exploration/Rewards Max                 -4.33497e-202
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.944
exploration/Returns Std                146.989
exploration/Returns Max                 -3.40126
exploration/Returns Min               -438.682
exploration/Actions Mean                -0.410258
exploration/Actions Std                  0.720295
exploration/Actions Max                  0.99904
exploration/Actions Min                 -0.998655
exploration/Num Paths                   10
exploration/Average Returns           -188.944
evaluation/num steps total               1.01304e+06
evaluation/num paths total            5040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78676
evaluation/Rewards Std                   0.72946
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1163.14
evaluation/Returns Std                 146.618
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.610916
evaluation/Actions Std                   0.37796
evaluation/Actions Max                  -0.200823
evaluation/Actions Min                  -0.969871
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.14
time/data storing (s)                    0.0236929
time/evaluation sampling (s)            17.6632
time/exploration sampling (s)            6.72976
time/logging (s)                         0.0759653
time/sac training (s)                   49.1297
time/saving (s)                          0.074111
time/training (s)                        0.000124782
time/epoch (s)                          73.6965
time/total (s)                       29667.6
Epoch                                  209
----------------------------------  -----------------
2020-11-09 23:23:47.185524 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 210 finished
----------------------------------  ----------------
replay_buffer/size                  424000
trainer/num train calls             211000
trainer/QF1 Loss                       200.824
trainer/QF2 Loss                       185.911
trainer/Policy Loss                     67.2113
trainer/Q1 Predictions Mean            -66.7109
trainer/Q1 Predictions Std              82.3006
trainer/Q1 Predictions Max              77.8981
trainer/Q1 Predictions Min            -222.481
trainer/Q2 Predictions Mean            -66.8392
trainer/Q2 Predictions Std              82.2944
trainer/Q2 Predictions Max              77.852
trainer/Q2 Predictions Min            -222.101
trainer/Q Targets Mean                 -65.5535
trainer/Q Targets Std                   82.7928
trainer/Q Targets Max                   78.7156
trainer/Q Targets Min                 -223.964
trainer/Log Pis Mean                     2.19855
trainer/Log Pis Std                      1.97401
trainer/Log Pis Max                      7.89908
trainer/Log Pis Min                     -5.54119
trainer/policy/mean Mean                -0.595228
trainer/policy/mean Std                  0.606622
trainer/policy/mean Max                  0.956813
trainer/policy/mean Min                 -0.996661
trainer/policy/normal/std Mean           0.578336
trainer/policy/normal/std Std            0.107131
trainer/policy/normal/std Max            1.1519
trainer/policy/normal/std Min            0.19514
trainer/policy/normal/log_std Mean      -0.565067
trainer/policy/normal/log_std Std        0.190415
trainer/policy/normal/log_std Max        0.141409
trainer/policy/normal/log_std Min       -1.63404
trainer/Alpha                            0.0281722
trainer/Alpha Loss                       0.70871
exploration/num steps total         424000
exploration/num paths total           2120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.37916
exploration/Rewards Std                  1.54967
exploration/Rewards Max                 -1.5142e-153
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -275.832
exploration/Returns Std                142.999
exploration/Returns Max               -150.31
exploration/Returns Min               -514.82
exploration/Actions Mean                -0.508114
exploration/Actions Std                  0.666602
exploration/Actions Max                  0.996135
exploration/Actions Min                 -0.999453
exploration/Num Paths                   10
exploration/Average Returns           -275.832
evaluation/num steps total               1.01786e+06
evaluation/num paths total            5064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.845363
evaluation/Actions Std                   0.13338
evaluation/Actions Max                  -0.497442
evaluation/Actions Min                  -0.970645
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0257419
time/evaluation sampling (s)            17.356
time/exploration sampling (s)            6.98479
time/logging (s)                         0.0993612
time/sac training (s)                   40.1227
time/saving (s)                          0.0945943
time/training (s)                        0.00031202
time/epoch (s)                          64.6835
time/total (s)                       29791.4
Epoch                                  210
----------------------------------  ----------------
2020-11-09 23:25:28.664707 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 211 finished
----------------------------------  -----------------
replay_buffer/size                  426000
trainer/num train calls             212000
trainer/QF1 Loss                       358.881
trainer/QF2 Loss                       341.297
trainer/Policy Loss                     63.7926
trainer/Q1 Predictions Mean            -63.4322
trainer/Q1 Predictions Std              81.4763
trainer/Q1 Predictions Max              98.4565
trainer/Q1 Predictions Min            -234.014
trainer/Q2 Predictions Mean            -63.3351
trainer/Q2 Predictions Std              81.4216
trainer/Q2 Predictions Max              98.7045
trainer/Q2 Predictions Min            -235.607
trainer/Q Targets Mean                 -61.8283
trainer/Q Targets Std                   81.7747
trainer/Q Targets Max                   98.3689
trainer/Q Targets Min                 -236.234
trainer/Log Pis Mean                     2.14171
trainer/Log Pis Std                      1.5689
trainer/Log Pis Max                      5.60572
trainer/Log Pis Min                     -3.26297
trainer/policy/mean Mean                -0.345188
trainer/policy/mean Std                  0.767506
trainer/policy/mean Max                  0.975907
trainer/policy/mean Min                 -0.981133
trainer/policy/normal/std Mean           0.552039
trainer/policy/normal/std Std            0.0858468
trainer/policy/normal/std Max            0.875567
trainer/policy/normal/std Min            0.225043
trainer/policy/normal/log_std Mean      -0.607071
trainer/policy/normal/log_std Std        0.165357
trainer/policy/normal/log_std Max       -0.132884
trainer/policy/normal/log_std Min       -1.49146
trainer/Alpha                            0.0287069
trainer/Alpha Loss                       0.503154
exploration/num steps total         426000
exploration/num paths total           2130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.672101
exploration/Rewards Std                  1.56579
exploration/Rewards Max                 -3.55145e-173
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -134.42
exploration/Returns Std                 79.738
exploration/Returns Max                -26.1886
exploration/Returns Min               -284.537
exploration/Actions Mean                -0.502477
exploration/Actions Std                  0.649003
exploration/Actions Max                  0.997203
exploration/Actions Min                 -0.999112
exploration/Num Paths                   10
exploration/Average Returns           -134.42
evaluation/num steps total               1.02269e+06
evaluation/num paths total            5088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.20207
evaluation/Rewards Std                   1.52662
evaluation/Rewards Max                  -9.2978e-26
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1045.62
evaluation/Returns Std                 305.733
evaluation/Returns Max                 -12.7748
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.444352
evaluation/Actions Std                   0.574916
evaluation/Actions Max                   0.896745
evaluation/Actions Min                  -0.970467
evaluation/Num Paths                    24
evaluation/Average Returns           -1045.62
time/data storing (s)                    0.0196509
time/evaluation sampling (s)            15.7569
time/exploration sampling (s)            5.68558
time/logging (s)                         0.0356069
time/sac training (s)                   37.7657
time/saving (s)                          0.0384362
time/training (s)                        0.000172725
time/epoch (s)                          59.3021
time/total (s)                       29892.8
Epoch                                  211
----------------------------------  -----------------
2020-11-09 23:26:53.285373 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 212 finished
----------------------------------  ----------------
replay_buffer/size                  428000
trainer/num train calls             213000
trainer/QF1 Loss                        43.3088
trainer/QF2 Loss                        42.3302
trainer/Policy Loss                     59.0134
trainer/Q1 Predictions Mean            -58.5764
trainer/Q1 Predictions Std              83.7877
trainer/Q1 Predictions Max              47.7335
trainer/Q1 Predictions Min            -268.326
trainer/Q2 Predictions Mean            -58.6105
trainer/Q2 Predictions Std              83.7999
trainer/Q2 Predictions Max              47.8784
trainer/Q2 Predictions Min            -269.016
trainer/Q Targets Mean                 -58.7195
trainer/Q Targets Std                   84.4652
trainer/Q Targets Max                   47.5292
trainer/Q Targets Min                 -267.624
trainer/Log Pis Mean                     2.08463
trainer/Log Pis Std                      1.68598
trainer/Log Pis Max                      7.18907
trainer/Log Pis Min                     -3.99636
trainer/policy/mean Mean                -0.490427
trainer/policy/mean Std                  0.682628
trainer/policy/mean Max                  0.964631
trainer/policy/mean Min                 -0.98829
trainer/policy/normal/std Mean           0.564643
trainer/policy/normal/std Std            0.0942985
trainer/policy/normal/std Max            0.938495
trainer/policy/normal/std Min            0.256836
trainer/policy/normal/log_std Mean      -0.586261
trainer/policy/normal/log_std Std        0.175669
trainer/policy/normal/log_std Max       -0.0634781
trainer/policy/normal/log_std Min       -1.35932
trainer/Alpha                            0.0290773
trainer/Alpha Loss                       0.299405
exploration/num steps total         428000
exploration/num paths total           2140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.05273
exploration/Rewards Std                  1.65255
exploration/Rewards Max                 -7.3422e-84
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -210.545
exploration/Returns Std                149.891
exploration/Returns Max                -43.8832
exploration/Returns Min               -578.737
exploration/Actions Mean                -0.553937
exploration/Actions Std                  0.639133
exploration/Actions Max                  0.997438
exploration/Actions Min                 -0.999943
exploration/Num Paths                   10
exploration/Average Returns           -210.545
evaluation/num steps total               1.02751e+06
evaluation/num paths total            5112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.703861
evaluation/Actions Std                   0.268552
evaluation/Actions Max                  -0.203075
evaluation/Actions Min                  -0.969881
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0213861
time/evaluation sampling (s)            13.6761
time/exploration sampling (s)            5.07501
time/logging (s)                         0.0307528
time/sac training (s)                   32.0931
time/saving (s)                          0.0318861
time/training (s)                        0.000122341
time/epoch (s)                          50.9284
time/total (s)                       29977.3
Epoch                                  212
----------------------------------  ----------------
2020-11-09 23:28:13.750955 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 213 finished
----------------------------------  -----------------
replay_buffer/size                  430000
trainer/num train calls             214000
trainer/QF1 Loss                       448.753
trainer/QF2 Loss                       441.251
trainer/Policy Loss                     62.1105
trainer/Q1 Predictions Mean            -61.7907
trainer/Q1 Predictions Std              80.6183
trainer/Q1 Predictions Max              78.1439
trainer/Q1 Predictions Min            -214.79
trainer/Q2 Predictions Mean            -61.7195
trainer/Q2 Predictions Std              80.6026
trainer/Q2 Predictions Max              78.1934
trainer/Q2 Predictions Min            -215.659
trainer/Q Targets Mean                 -59.5623
trainer/Q Targets Std                   80.8195
trainer/Q Targets Max                   77.4086
trainer/Q Targets Min                 -215.966
trainer/Log Pis Mean                     2.06078
trainer/Log Pis Std                      1.69686
trainer/Log Pis Max                      7.39744
trainer/Log Pis Min                     -3.18443
trainer/policy/mean Mean                -0.432656
trainer/policy/mean Std                  0.722362
trainer/policy/mean Max                  0.972056
trainer/policy/mean Min                 -0.992158
trainer/policy/normal/std Mean           0.572268
trainer/policy/normal/std Std            0.0922379
trainer/policy/normal/std Max            0.892322
trainer/policy/normal/std Min            0.193074
trainer/policy/normal/log_std Mean      -0.571979
trainer/policy/normal/log_std Std        0.171035
trainer/policy/normal/log_std Max       -0.113928
trainer/policy/normal/log_std Min       -1.64468
trainer/Alpha                            0.0296601
trainer/Alpha Loss                       0.213821
exploration/num steps total         430000
exploration/num paths total           2150
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.24215
exploration/Rewards Std                  1.64624
exploration/Rewards Max                 -4.93531e-112
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -248.43
exploration/Returns Std                122.437
exploration/Returns Max                -87.9362
exploration/Returns Min               -434.014
exploration/Actions Mean                -0.396999
exploration/Actions Std                  0.744894
exploration/Actions Max                  0.998198
exploration/Actions Min                 -0.999383
exploration/Num Paths                   10
exploration/Average Returns           -248.43
evaluation/num steps total               1.03234e+06
evaluation/num paths total            5136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.66575
evaluation/Rewards Std                   0.904209
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1138.82
evaluation/Returns Std                 181.368
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.548378
evaluation/Actions Std                   0.462477
evaluation/Actions Max                   0.68549
evaluation/Actions Min                  -0.972263
evaluation/Num Paths                    24
evaluation/Average Returns           -1138.82
time/data storing (s)                    0.021781
time/evaluation sampling (s)            15.1663
time/exploration sampling (s)            5.88639
time/logging (s)                         0.0311891
time/sac training (s)                   32.4701
time/saving (s)                          0.0347852
time/training (s)                        0.000163977
time/epoch (s)                          53.6107
time/total (s)                       30057.8
Epoch                                  213
----------------------------------  -----------------
2020-11-09 23:29:25.647167 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 214 finished
----------------------------------  -----------------
replay_buffer/size                  432000
trainer/num train calls             215000
trainer/QF1 Loss                       168.282
trainer/QF2 Loss                       165.404
trainer/Policy Loss                     65.2405
trainer/Q1 Predictions Mean            -64.8421
trainer/Q1 Predictions Std              85.0368
trainer/Q1 Predictions Max              78.1631
trainer/Q1 Predictions Min            -267.954
trainer/Q2 Predictions Mean            -64.9514
trainer/Q2 Predictions Std              85.1286
trainer/Q2 Predictions Max              77.9314
trainer/Q2 Predictions Min            -268.44
trainer/Q Targets Mean                 -63.9742
trainer/Q Targets Std                   85.4848
trainer/Q Targets Max                   77.5113
trainer/Q Targets Min                 -267.38
trainer/Log Pis Mean                     2.0547
trainer/Log Pis Std                      1.61392
trainer/Log Pis Max                      5.87153
trainer/Log Pis Min                     -4.59188
trainer/policy/mean Mean                -0.471902
trainer/policy/mean Std                  0.693239
trainer/policy/mean Max                  0.951217
trainer/policy/mean Min                 -0.982603
trainer/policy/normal/std Mean           0.567939
trainer/policy/normal/std Std            0.104663
trainer/policy/normal/std Max            0.931389
trainer/policy/normal/std Min            0.201793
trainer/policy/normal/log_std Mean      -0.583064
trainer/policy/normal/log_std Std        0.189388
trainer/policy/normal/log_std Max       -0.071078
trainer/policy/normal/log_std Min       -1.60051
trainer/Alpha                            0.0289962
trainer/Alpha Loss                       0.193672
exploration/num steps total         432000
exploration/num paths total           2160
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.964854
exploration/Rewards Std                  1.53634
exploration/Rewards Max                 -5.56171e-140
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -192.971
exploration/Returns Std                105.322
exploration/Returns Max                -21.7831
exploration/Returns Min               -405.056
exploration/Actions Mean                -0.529519
exploration/Actions Std                  0.638821
exploration/Actions Max                  0.997062
exploration/Actions Min                 -0.99875
exploration/Num Paths                   10
exploration/Average Returns           -192.971
evaluation/num steps total               1.03716e+06
evaluation/num paths total            5160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.11354
evaluation/Rewards Std                   1.17624
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1027.82
evaluation/Returns Std                 234.871
evaluation/Returns Max                -639.253
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.583778
evaluation/Actions Std                   0.416763
evaluation/Actions Max                   0.635599
evaluation/Actions Min                  -0.968755
evaluation/Num Paths                    24
evaluation/Average Returns           -1027.82
time/data storing (s)                    0.019766
time/evaluation sampling (s)            14.7866
time/exploration sampling (s)            5.34941
time/logging (s)                         0.0278747
time/sac training (s)                   30.3093
time/saving (s)                          0.0322727
time/training (s)                        0.000144247
time/epoch (s)                          50.5254
time/total (s)                       30129.6
Epoch                                  214
----------------------------------  -----------------
2020-11-09 23:30:29.411561 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 215 finished
----------------------------------  -----------------
replay_buffer/size                  434000
trainer/num train calls             216000
trainer/QF1 Loss                       313.863
trainer/QF2 Loss                       321.913
trainer/Policy Loss                     63.2982
trainer/Q1 Predictions Mean            -63.0205
trainer/Q1 Predictions Std              84.3015
trainer/Q1 Predictions Max             105.467
trainer/Q1 Predictions Min            -267.671
trainer/Q2 Predictions Mean            -62.9337
trainer/Q2 Predictions Std              84.1833
trainer/Q2 Predictions Max             105.636
trainer/Q2 Predictions Min            -268.331
trainer/Q Targets Mean                 -61.9526
trainer/Q Targets Std                   83.9027
trainer/Q Targets Max                  105.741
trainer/Q Targets Min                 -267.074
trainer/Log Pis Mean                     2.30794
trainer/Log Pis Std                      1.58512
trainer/Log Pis Max                      5.87018
trainer/Log Pis Min                     -3.53207
trainer/policy/mean Mean                -0.36776
trainer/policy/mean Std                  0.754368
trainer/policy/mean Max                  0.971294
trainer/policy/mean Min                 -0.986641
trainer/policy/normal/std Mean           0.554936
trainer/policy/normal/std Std            0.0914769
trainer/policy/normal/std Max            1.13024
trainer/policy/normal/std Min            0.221828
trainer/policy/normal/log_std Mean      -0.602468
trainer/policy/normal/log_std Std        0.166913
trainer/policy/normal/log_std Max        0.122427
trainer/policy/normal/log_std Min       -1.50585
trainer/Alpha                            0.0289964
trainer/Alpha Loss                       1.09029
exploration/num steps total         434000
exploration/num paths total           2170
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14778
exploration/Rewards Std                  1.63089
exploration/Rewards Max                 -8.99579e-197
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -229.555
exploration/Returns Std                173.901
exploration/Returns Max                -15.4139
exploration/Returns Min               -590.083
exploration/Actions Mean                -0.362625
exploration/Actions Std                  0.73354
exploration/Actions Max                  0.99725
exploration/Actions Min                 -0.99869
exploration/Num Paths                   10
exploration/Average Returns           -229.555
evaluation/num steps total               1.04198e+06
evaluation/num paths total            5184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.13567
evaluation/Rewards Std                   1.51689
evaluation/Rewards Max                  -1.50372e-21
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1032.27
evaluation/Returns Std                 303.693
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.459714
evaluation/Actions Std                   0.562133
evaluation/Actions Max                   0.94908
evaluation/Actions Min                  -0.977401
evaluation/Num Paths                    24
evaluation/Average Returns           -1032.27
time/data storing (s)                    0.0268205
time/evaluation sampling (s)            13.6084
time/exploration sampling (s)            5.05538
time/logging (s)                         0.0548866
time/sac training (s)                   30.5366
time/saving (s)                          0.0347826
time/training (s)                        0.000152665
time/epoch (s)                          49.317
time/total (s)                       30193.4
Epoch                                  215
----------------------------------  -----------------
2020-11-09 23:31:36.100115 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 216 finished
----------------------------------  -----------------
replay_buffer/size                  436000
trainer/num train calls             217000
trainer/QF1 Loss                        32.904
trainer/QF2 Loss                        30.5842
trainer/Policy Loss                     63.5139
trainer/Q1 Predictions Mean            -63.2218
trainer/Q1 Predictions Std              81.6918
trainer/Q1 Predictions Max              93.5135
trainer/Q1 Predictions Min            -239.482
trainer/Q2 Predictions Mean            -63.0181
trainer/Q2 Predictions Std              81.4779
trainer/Q2 Predictions Max              93.4971
trainer/Q2 Predictions Min            -237.536
trainer/Q Targets Mean                 -63.6596
trainer/Q Targets Std                   82.562
trainer/Q Targets Max                   92.8107
trainer/Q Targets Min                 -239.418
trainer/Log Pis Mean                     2.00971
trainer/Log Pis Std                      1.54378
trainer/Log Pis Max                      6.50649
trainer/Log Pis Min                     -2.73473
trainer/policy/mean Mean                -0.421957
trainer/policy/mean Std                  0.716478
trainer/policy/mean Max                  0.971886
trainer/policy/mean Min                 -0.985378
trainer/policy/normal/std Mean           0.568522
trainer/policy/normal/std Std            0.0939155
trainer/policy/normal/std Max            1.20171
trainer/policy/normal/std Min            0.271287
trainer/policy/normal/log_std Mean      -0.578331
trainer/policy/normal/log_std Std        0.166911
trainer/policy/normal/log_std Max        0.183741
trainer/policy/normal/log_std Min       -1.30458
trainer/Alpha                            0.0289743
trainer/Alpha Loss                       0.0343762
exploration/num steps total         436000
exploration/num paths total           2180
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.877375
exploration/Rewards Std                  1.54564
exploration/Rewards Max                 -2.37552e-102
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -175.475
exploration/Returns Std                 86.8272
exploration/Returns Max                -77.1817
exploration/Returns Min               -348.139
exploration/Actions Mean                -0.508613
exploration/Actions Std                  0.674762
exploration/Actions Max                  0.997781
exploration/Actions Min                 -0.998791
exploration/Num Paths                   10
exploration/Average Returns           -175.475
evaluation/num steps total               1.04681e+06
evaluation/num paths total            5208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   2.62549e-13
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.564353
evaluation/Actions Std                   0.403504
evaluation/Actions Max                  -0.135362
evaluation/Actions Min                  -0.968659
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0195866
time/evaluation sampling (s)            14.366
time/exploration sampling (s)            5.91193
time/logging (s)                         0.0201675
time/sac training (s)                   32.5747
time/saving (s)                          0.0202821
time/training (s)                        9.4954e-05
time/epoch (s)                          52.9127
time/total (s)                       30260
Epoch                                  216
----------------------------------  -----------------
2020-11-09 23:32:43.145871 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 217 finished
----------------------------------  -----------------
replay_buffer/size                  438000
trainer/num train calls             218000
trainer/QF1 Loss                         9.28794
trainer/QF2 Loss                         6.3184
trainer/Policy Loss                     63.0522
trainer/Q1 Predictions Mean            -62.5853
trainer/Q1 Predictions Std              83.2677
trainer/Q1 Predictions Max              42.4497
trainer/Q1 Predictions Min            -255.676
trainer/Q2 Predictions Mean            -62.7164
trainer/Q2 Predictions Std              83.2479
trainer/Q2 Predictions Max              42.8848
trainer/Q2 Predictions Min            -255.993
trainer/Q Targets Mean                 -63.5127
trainer/Q Targets Std                   84.2385
trainer/Q Targets Max                   41.9823
trainer/Q Targets Min                 -254.765
trainer/Log Pis Mean                     2.18838
trainer/Log Pis Std                      1.73658
trainer/Log Pis Max                      6.78636
trainer/Log Pis Min                     -3.46667
trainer/policy/mean Mean                -0.504822
trainer/policy/mean Std                  0.672187
trainer/policy/mean Max                  0.970871
trainer/policy/mean Min                 -0.983745
trainer/policy/normal/std Mean           0.561286
trainer/policy/normal/std Std            0.0976661
trainer/policy/normal/std Max            1.12945
trainer/policy/normal/std Min            0.264675
trainer/policy/normal/log_std Mean      -0.593025
trainer/policy/normal/log_std Std        0.179242
trainer/policy/normal/log_std Max        0.121727
trainer/policy/normal/log_std Min       -1.32925
trainer/Alpha                            0.0292689
trainer/Alpha Loss                       0.665224
exploration/num steps total         438000
exploration/num paths total           2190
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0383
exploration/Rewards Std                  1.48351
exploration/Rewards Max                 -3.32162e-271
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -207.661
exploration/Returns Std                161.485
exploration/Returns Max                -58.8248
exploration/Returns Min               -575.382
exploration/Actions Mean                -0.498906
exploration/Actions Std                  0.687757
exploration/Actions Max                  0.997305
exploration/Actions Min                 -0.99959
exploration/Num Paths                   10
exploration/Average Returns           -207.661
evaluation/num steps total               1.05163e+06
evaluation/num paths total            5232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59725
evaluation/Rewards Std                   1.38355
evaluation/Rewards Max                  -1.72714e-10
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1125.05
evaluation/Returns Std                 277.921
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.690791
evaluation/Actions Std                   0.315731
evaluation/Actions Max                   0.51745
evaluation/Actions Min                  -0.974383
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.05
time/data storing (s)                    0.0567079
time/evaluation sampling (s)            14.91
time/exploration sampling (s)            5.9353
time/logging (s)                         0.0249224
time/sac training (s)                   33.3724
time/saving (s)                          0.0220031
time/training (s)                        0.000122891
time/epoch (s)                          54.3215
time/total (s)                       30327
Epoch                                  217
----------------------------------  -----------------
2020-11-09 23:33:53.735529 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 218 finished
----------------------------------  -----------------
replay_buffer/size                  440000
trainer/num train calls             219000
trainer/QF1 Loss                        20.3442
trainer/QF2 Loss                        18.2063
trainer/Policy Loss                     62.7285
trainer/Q1 Predictions Mean            -62.3403
trainer/Q1 Predictions Std              80.7852
trainer/Q1 Predictions Max              49.1629
trainer/Q1 Predictions Min            -267.007
trainer/Q2 Predictions Mean            -62.3297
trainer/Q2 Predictions Std              80.6869
trainer/Q2 Predictions Max              49.4175
trainer/Q2 Predictions Min            -267.577
trainer/Q Targets Mean                 -62.812
trainer/Q Targets Std                   81.8945
trainer/Q Targets Max                   48.5654
trainer/Q Targets Min                 -266.433
trainer/Log Pis Mean                     1.967
trainer/Log Pis Std                      1.64541
trainer/Log Pis Max                      5.73688
trainer/Log Pis Min                     -2.52291
trainer/policy/mean Mean                -0.397894
trainer/policy/mean Std                  0.730033
trainer/policy/mean Max                  0.970528
trainer/policy/mean Min                 -0.984634
trainer/policy/normal/std Mean           0.566075
trainer/policy/normal/std Std            0.0890754
trainer/policy/normal/std Max            0.890583
trainer/policy/normal/std Min            0.270013
trainer/policy/normal/log_std Mean      -0.581139
trainer/policy/normal/log_std Std        0.155836
trainer/policy/normal/log_std Max       -0.115879
trainer/policy/normal/log_std Min       -1.30928
trainer/Alpha                            0.029227
trainer/Alpha Loss                      -0.116567
exploration/num steps total         440000
exploration/num paths total           2200
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.875768
exploration/Rewards Std                  1.47063
exploration/Rewards Max                 -1.15019e-119
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -175.154
exploration/Returns Std                145.952
exploration/Returns Max                -13.4329
exploration/Returns Min               -488.236
exploration/Actions Mean                -0.522672
exploration/Actions Std                  0.643062
exploration/Actions Max                  0.995858
exploration/Actions Min                 -0.999623
exploration/Num Paths                   10
exploration/Average Returns           -175.154
evaluation/num steps total               1.05646e+06
evaluation/num paths total            5256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.510403
evaluation/Actions Std                   0.52013
evaluation/Actions Max                   0.84934
evaluation/Actions Min                  -0.973214
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0227698
time/evaluation sampling (s)            15.4764
time/exploration sampling (s)            5.96975
time/logging (s)                         0.0374373
time/sac training (s)                   31.9646
time/saving (s)                          0.0385735
time/training (s)                        0.000114999
time/epoch (s)                          53.5097
time/total (s)                       30397.6
Epoch                                  218
----------------------------------  -----------------
2020-11-09 23:34:48.851102 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 219 finished
----------------------------------  ----------------
replay_buffer/size                  442000
trainer/num train calls             220000
trainer/QF1 Loss                        23.5613
trainer/QF2 Loss                        25.2376
trainer/Policy Loss                     60.2697
trainer/Q1 Predictions Mean            -60.0109
trainer/Q1 Predictions Std              83.6456
trainer/Q1 Predictions Max              74.2626
trainer/Q1 Predictions Min            -266.089
trainer/Q2 Predictions Mean            -59.717
trainer/Q2 Predictions Std              83.3815
trainer/Q2 Predictions Max              74.1602
trainer/Q2 Predictions Min            -266.741
trainer/Q Targets Mean                 -60.1331
trainer/Q Targets Std                   83.5905
trainer/Q Targets Max                   73.7227
trainer/Q Targets Min                 -265.508
trainer/Log Pis Mean                     1.88024
trainer/Log Pis Std                      1.74519
trainer/Log Pis Max                      6.01237
trainer/Log Pis Min                     -3.92842
trainer/policy/mean Mean                -0.437803
trainer/policy/mean Std                  0.718689
trainer/policy/mean Max                  0.972333
trainer/policy/mean Min                 -0.989164
trainer/policy/normal/std Mean           0.57745
trainer/policy/normal/std Std            0.0973528
trainer/policy/normal/std Max            1.14704
trainer/policy/normal/std Min            0.233572
trainer/policy/normal/log_std Mean      -0.563566
trainer/policy/normal/log_std Std        0.172756
trainer/policy/normal/log_std Max        0.137186
trainer/policy/normal/log_std Min       -1.45427
trainer/Alpha                            0.0297473
trainer/Alpha Loss                      -0.420956
exploration/num steps total         442000
exploration/num paths total           2210
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.20073
exploration/Rewards Std                  1.52101
exploration/Rewards Max                 -2.0747e-219
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -240.146
exploration/Returns Std                192.66
exploration/Returns Max                -27.7209
exploration/Returns Min               -545.23
exploration/Actions Mean                -0.443714
exploration/Actions Std                  0.690904
exploration/Actions Max                  0.997402
exploration/Actions Min                 -0.998733
exploration/Num Paths                   10
exploration/Average Returns           -240.146
evaluation/num steps total               1.06128e+06
evaluation/num paths total            5280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.22116
evaluation/Rewards Std                   1.11746
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1049.45
evaluation/Returns Std                 223.458
evaluation/Returns Max                -647.554
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.615538
evaluation/Actions Std                   0.368975
evaluation/Actions Max                  -0.163867
evaluation/Actions Min                  -0.970993
evaluation/Num Paths                    24
evaluation/Average Returns           -1049.45
time/data storing (s)                    0.0239396
time/evaluation sampling (s)            13.1318
time/exploration sampling (s)            5.16524
time/logging (s)                         0.0241697
time/sac training (s)                   28.9067
time/saving (s)                          0.0289298
time/training (s)                        0.000193574
time/epoch (s)                          47.2809
time/total (s)                       30452.7
Epoch                                  219
----------------------------------  ----------------
2020-11-09 23:36:42.907130 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 220 finished
----------------------------------  ----------------
replay_buffer/size                  444000
trainer/num train calls             221000
trainer/QF1 Loss                       111.633
trainer/QF2 Loss                       126.485
trainer/Policy Loss                     55.7043
trainer/Q1 Predictions Mean            -55.2224
trainer/Q1 Predictions Std              78.972
trainer/Q1 Predictions Max              72.5446
trainer/Q1 Predictions Min            -240.154
trainer/Q2 Predictions Mean            -55.2969
trainer/Q2 Predictions Std              79.0146
trainer/Q2 Predictions Max              72.2866
trainer/Q2 Predictions Min            -239.412
trainer/Q Targets Mean                 -54.549
trainer/Q Targets Std                   79.1912
trainer/Q Targets Max                   72.5523
trainer/Q Targets Min                 -239.95
trainer/Log Pis Mean                     2.01417
trainer/Log Pis Std                      1.67094
trainer/Log Pis Max                      6.76654
trainer/Log Pis Min                     -2.91421
trainer/policy/mean Mean                -0.487747
trainer/policy/mean Std                  0.686848
trainer/policy/mean Max                  0.964772
trainer/policy/mean Min                 -0.984752
trainer/policy/normal/std Mean           0.583736
trainer/policy/normal/std Std            0.106894
trainer/policy/normal/std Max            1.14984
trainer/policy/normal/std Min            0.273978
trainer/policy/normal/log_std Mean      -0.554498
trainer/policy/normal/log_std Std        0.180246
trainer/policy/normal/log_std Max        0.139621
trainer/policy/normal/log_std Min       -1.29471
trainer/Alpha                            0.0298731
trainer/Alpha Loss                       0.0497562
exploration/num steps total         444000
exploration/num paths total           2220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.06206
exploration/Rewards Std                  1.70185
exploration/Rewards Max                 -4.55776e-67
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -212.412
exploration/Returns Std                135.452
exploration/Returns Max                -88.9436
exploration/Returns Min               -528.628
exploration/Actions Mean                -0.445557
exploration/Actions Std                  0.745433
exploration/Actions Max                  0.996206
exploration/Actions Min                 -0.999998
exploration/Num Paths                   10
exploration/Average Returns           -212.412
evaluation/num steps total               1.0661e+06
evaluation/num paths total            5304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.06319
evaluation/Rewards Std                   1.14108
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1017.7
evaluation/Returns Std                 226.89
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.593872
evaluation/Actions Std                   0.419042
evaluation/Actions Max                   0.8263
evaluation/Actions Min                  -0.972209
evaluation/Num Paths                    24
evaluation/Average Returns           -1017.7
time/data storing (s)                    0.0450424
time/evaluation sampling (s)            13.3264
time/exploration sampling (s)           13.402
time/logging (s)                         0.033651
time/sac training (s)                   69.0768
time/saving (s)                          0.0433889
time/training (s)                        0.000117376
time/epoch (s)                          95.9274
time/total (s)                       30566.7
Epoch                                  220
----------------------------------  ----------------
2020-11-09 23:37:54.905277 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 221 finished
----------------------------------  -----------------
replay_buffer/size                  446000
trainer/num train calls             222000
trainer/QF1 Loss                        54.2535
trainer/QF2 Loss                        50.3135
trainer/Policy Loss                     61.8742
trainer/Q1 Predictions Mean            -61.4614
trainer/Q1 Predictions Std              83.4131
trainer/Q1 Predictions Max              71.4773
trainer/Q1 Predictions Min            -265.1
trainer/Q2 Predictions Mean            -61.448
trainer/Q2 Predictions Std              83.4594
trainer/Q2 Predictions Max              71.3418
trainer/Q2 Predictions Min            -265.747
trainer/Q Targets Mean                 -61.0917
trainer/Q Targets Std                   84.1165
trainer/Q Targets Max                   71.2539
trainer/Q Targets Min                 -264.432
trainer/Log Pis Mean                     1.92532
trainer/Log Pis Std                      1.73748
trainer/Log Pis Max                      5.89317
trainer/Log Pis Min                     -3.45807
trainer/policy/mean Mean                -0.340187
trainer/policy/mean Std                  0.765267
trainer/policy/mean Max                  0.977386
trainer/policy/mean Min                 -0.979436
trainer/policy/normal/std Mean           0.590816
trainer/policy/normal/std Std            0.102008
trainer/policy/normal/std Max            1.13834
trainer/policy/normal/std Min            0.247291
trainer/policy/normal/log_std Mean      -0.541442
trainer/policy/normal/log_std Std        0.177201
trainer/policy/normal/log_std Max        0.129573
trainer/policy/normal/log_std Min       -1.39719
trainer/Alpha                            0.0296744
trainer/Alpha Loss                      -0.262688
exploration/num steps total         446000
exploration/num paths total           2230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.846221
exploration/Rewards Std                  1.52159
exploration/Rewards Max                 -1.19751e-159
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -169.244
exploration/Returns Std                109.814
exploration/Returns Max                -28.3648
exploration/Returns Min               -456.116
exploration/Actions Mean                -0.539044
exploration/Actions Std                  0.653744
exploration/Actions Max                  0.997922
exploration/Actions Min                 -0.999311
exploration/Num Paths                   10
exploration/Average Returns           -169.244
evaluation/num steps total               1.07093e+06
evaluation/num paths total            5328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73252
evaluation/Rewards Std                   0.90704
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1152.24
evaluation/Returns Std                 182.315
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.490206
evaluation/Actions Std                   0.476887
evaluation/Actions Max                   0.170067
evaluation/Actions Min                  -0.967375
evaluation/Num Paths                    24
evaluation/Average Returns           -1152.24
time/data storing (s)                    0.0208116
time/evaluation sampling (s)            13.1096
time/exploration sampling (s)            5.2216
time/logging (s)                         0.0421771
time/sac training (s)                   36.6467
time/saving (s)                          0.0405768
time/training (s)                        0.000103784
time/epoch (s)                          55.0816
time/total (s)                       30638.7
Epoch                                  221
----------------------------------  -----------------
2020-11-09 23:38:59.812865 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 222 finished
----------------------------------  ----------------
replay_buffer/size                  448000
trainer/num train calls             223000
trainer/QF1 Loss                       144.111
trainer/QF2 Loss                       140.461
trainer/Policy Loss                     64.2023
trainer/Q1 Predictions Mean            -63.7577
trainer/Q1 Predictions Std              81.6576
trainer/Q1 Predictions Max             107.41
trainer/Q1 Predictions Min            -219.28
trainer/Q2 Predictions Mean            -63.7662
trainer/Q2 Predictions Std              81.5976
trainer/Q2 Predictions Max             107.646
trainer/Q2 Predictions Min            -224.509
trainer/Q Targets Mean                 -63.5413
trainer/Q Targets Std                   82.0034
trainer/Q Targets Max                  110.942
trainer/Q Targets Min                 -225.015
trainer/Log Pis Mean                     2.11319
trainer/Log Pis Std                      1.7334
trainer/Log Pis Max                      5.70355
trainer/Log Pis Min                     -6.00737
trainer/policy/mean Mean                -0.513854
trainer/policy/mean Std                  0.668481
trainer/policy/mean Max                  0.947643
trainer/policy/mean Min                 -0.993428
trainer/policy/normal/std Mean           0.590874
trainer/policy/normal/std Std            0.119687
trainer/policy/normal/std Max            1.21181
trainer/policy/normal/std Min            0.246746
trainer/policy/normal/log_std Mean      -0.545855
trainer/policy/normal/log_std Std        0.198803
trainer/policy/normal/log_std Max        0.192119
trainer/policy/normal/log_std Min       -1.3994
trainer/Alpha                            0.0295228
trainer/Alpha Loss                       0.398711
exploration/num steps total         448000
exploration/num paths total           2240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.03152
exploration/Rewards Std                  1.44335
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.09511
exploration/Returns Mean              -206.305
exploration/Returns Std                106.761
exploration/Returns Max                -73.7189
exploration/Returns Min               -393.311
exploration/Actions Mean                -0.552875
exploration/Actions Std                  0.620784
exploration/Actions Max                  0.998481
exploration/Actions Min                 -0.999623
exploration/Num Paths                   10
exploration/Average Returns           -206.305
evaluation/num steps total               1.07575e+06
evaluation/num paths total            5352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.51168
evaluation/Rewards Std                   1.53961
evaluation/Rewards Max                  -7.83913e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -906.848
evaluation/Returns Std                 307.028
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.537447
evaluation/Actions Std                   0.562833
evaluation/Actions Max                   0.834093
evaluation/Actions Min                  -0.96962
evaluation/Num Paths                    24
evaluation/Average Returns            -906.848
time/data storing (s)                    0.0200604
time/evaluation sampling (s)            15.3557
time/exploration sampling (s)            6.12453
time/logging (s)                         0.0285607
time/sac training (s)                   30.2763
time/saving (s)                          0.0283391
time/training (s)                        0.00014735
time/epoch (s)                          51.8337
time/total (s)                       30703.6
Epoch                                  222
----------------------------------  ----------------
2020-11-09 23:40:04.718406 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 223 finished
----------------------------------  -----------------
replay_buffer/size                  450000
trainer/num train calls             224000
trainer/QF1 Loss                       194.888
trainer/QF2 Loss                       193.835
trainer/Policy Loss                     68.7943
trainer/Q1 Predictions Mean            -68.3427
trainer/Q1 Predictions Std              84.2115
trainer/Q1 Predictions Max              88.5071
trainer/Q1 Predictions Min            -230.702
trainer/Q2 Predictions Mean            -68.4637
trainer/Q2 Predictions Std              84.2951
trainer/Q2 Predictions Max              88.7289
trainer/Q2 Predictions Min            -234.118
trainer/Q Targets Mean                 -68.4319
trainer/Q Targets Std                   85.1486
trainer/Q Targets Max                   88.6912
trainer/Q Targets Min                 -234.825
trainer/Log Pis Mean                     2.24175
trainer/Log Pis Std                      2.00679
trainer/Log Pis Max                      7.76579
trainer/Log Pis Min                     -7.86425
trainer/policy/mean Mean                -0.619928
trainer/policy/mean Std                  0.583286
trainer/policy/mean Max                  0.949436
trainer/policy/mean Min                 -0.994406
trainer/policy/normal/std Mean           0.587746
trainer/policy/normal/std Std            0.105024
trainer/policy/normal/std Max            1.17453
trainer/policy/normal/std Min            0.188008
trainer/policy/normal/log_std Mean      -0.547585
trainer/policy/normal/log_std Std        0.182796
trainer/policy/normal/log_std Max        0.160872
trainer/policy/normal/log_std Min       -1.67127
trainer/Alpha                            0.0299614
trainer/Alpha Loss                       0.848033
exploration/num steps total         450000
exploration/num paths total           2250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.24224
exploration/Rewards Std                  1.62402
exploration/Rewards Max                 -3.14745e-221
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -248.448
exploration/Returns Std                170.042
exploration/Returns Max                -26.4161
exploration/Returns Min               -565.961
exploration/Actions Mean                -0.475664
exploration/Actions Std                  0.70488
exploration/Actions Max                  0.997731
exploration/Actions Min                 -0.999716
exploration/Num Paths                   10
exploration/Average Returns           -248.448
evaluation/num steps total               1.08058e+06
evaluation/num paths total            5376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.51582
evaluation/Rewards Std                   1.21005
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -907.68
evaluation/Returns Std                 239.991
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.664411
evaluation/Actions Std                   0.405198
evaluation/Actions Max                   0.78779
evaluation/Actions Min                  -0.972844
evaluation/Num Paths                    24
evaluation/Average Returns            -907.68
time/data storing (s)                    0.020203
time/evaluation sampling (s)            12.5352
time/exploration sampling (s)            5.02312
time/logging (s)                         0.0299632
time/sac training (s)                   34.9411
time/saving (s)                          0.0399339
time/training (s)                        0.000122546
time/epoch (s)                          52.5897
time/total (s)                       30768.5
Epoch                                  223
----------------------------------  -----------------
2020-11-09 23:41:09.993290 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 224 finished
----------------------------------  -----------------
replay_buffer/size                  452000
trainer/num train calls             225000
trainer/QF1 Loss                       182.113
trainer/QF2 Loss                       181.514
trainer/Policy Loss                     73.3308
trainer/Q1 Predictions Mean            -72.8192
trainer/Q1 Predictions Std              86.4744
trainer/Q1 Predictions Max              68.8423
trainer/Q1 Predictions Min            -222.495
trainer/Q2 Predictions Mean            -72.8427
trainer/Q2 Predictions Std              86.4943
trainer/Q2 Predictions Max              68.6305
trainer/Q2 Predictions Min            -223.065
trainer/Q Targets Mean                 -72.5487
trainer/Q Targets Std                   87.2457
trainer/Q Targets Max                   68.6849
trainer/Q Targets Min                 -224.688
trainer/Log Pis Mean                     2.24611
trainer/Log Pis Std                      1.98583
trainer/Log Pis Max                      6.59673
trainer/Log Pis Min                     -6.23774
trainer/policy/mean Mean                -0.533246
trainer/policy/mean Std                  0.655625
trainer/policy/mean Max                  0.951108
trainer/policy/mean Min                 -0.98891
trainer/policy/normal/std Mean           0.589677
trainer/policy/normal/std Std            0.111851
trainer/policy/normal/std Max            1.05531
trainer/policy/normal/std Min            0.253592
trainer/policy/normal/log_std Mean      -0.545914
trainer/policy/normal/log_std Std        0.189243
trainer/policy/normal/log_std Max        0.053832
trainer/policy/normal/log_std Min       -1.37203
trainer/Alpha                            0.030365
trainer/Alpha Loss                       0.860029
exploration/num steps total         452000
exploration/num paths total           2260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.981743
exploration/Rewards Std                  1.68218
exploration/Rewards Max                 -5.63188e-208
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -196.349
exploration/Returns Std                 88.8045
exploration/Returns Max                -92.4015
exploration/Returns Min               -376.103
exploration/Actions Mean                -0.549778
exploration/Actions Std                  0.63175
exploration/Actions Max                  0.997081
exploration/Actions Min                 -0.99968
exploration/Num Paths                   10
exploration/Average Returns           -196.349
evaluation/num steps total               1.0854e+06
evaluation/num paths total            5400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78199
evaluation/Rewards Std                   0.747422
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.18
evaluation/Returns Std                 149.8
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.817887
evaluation/Actions Std                   0.160134
evaluation/Actions Max                  -0.648331
evaluation/Actions Min                  -0.976525
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.18
time/data storing (s)                    0.0261691
time/evaluation sampling (s)            14.0592
time/exploration sampling (s)            5.35504
time/logging (s)                         0.0266398
time/sac training (s)                   30.1079
time/saving (s)                          0.0330327
time/training (s)                        0.00013563
time/epoch (s)                          49.6081
time/total (s)                       30833.7
Epoch                                  224
----------------------------------  -----------------
2020-11-09 23:42:14.117284 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 225 finished
----------------------------------  -----------------
replay_buffer/size                  454000
trainer/num train calls             226000
trainer/QF1 Loss                       218.814
trainer/QF2 Loss                       209.92
trainer/Policy Loss                     63.8792
trainer/Q1 Predictions Mean            -63.4188
trainer/Q1 Predictions Std              81.8499
trainer/Q1 Predictions Max              57.1564
trainer/Q1 Predictions Min            -243.057
trainer/Q2 Predictions Mean            -63.4228
trainer/Q2 Predictions Std              81.7371
trainer/Q2 Predictions Max              57.3414
trainer/Q2 Predictions Min            -243.996
trainer/Q Targets Mean                 -62.5123
trainer/Q Targets Std                   82.6617
trainer/Q Targets Max                   57.4445
trainer/Q Targets Min                 -242.641
trainer/Log Pis Mean                     2.12784
trainer/Log Pis Std                      1.81175
trainer/Log Pis Max                      6.11514
trainer/Log Pis Min                     -2.79334
trainer/policy/mean Mean                -0.282158
trainer/policy/mean Std                  0.804904
trainer/policy/mean Max                  0.981353
trainer/policy/mean Min                 -0.980907
trainer/policy/normal/std Mean           0.558513
trainer/policy/normal/std Std            0.0833644
trainer/policy/normal/std Max            1.0448
trainer/policy/normal/std Min            0.238461
trainer/policy/normal/log_std Mean      -0.593545
trainer/policy/normal/log_std Std        0.150394
trainer/policy/normal/log_std Max        0.0438272
trainer/policy/normal/log_std Min       -1.43355
trainer/Alpha                            0.0301892
trainer/Alpha Loss                       0.447487
exploration/num steps total         454000
exploration/num paths total           2270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.04367
exploration/Rewards Std                  1.50908
exploration/Rewards Max                 -2.48914e-123
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -208.735
exploration/Returns Std                118.92
exploration/Returns Max                -35.3399
exploration/Returns Min               -474.037
exploration/Actions Mean                -0.342688
exploration/Actions Std                  0.766628
exploration/Actions Max                  0.995832
exploration/Actions Min                 -0.998957
exploration/Num Paths                   10
exploration/Average Returns           -208.735
evaluation/num steps total               1.09022e+06
evaluation/num paths total            5424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67245
evaluation/Rewards Std                   0.884348
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.16
evaluation/Returns Std                 177.751
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.315866
evaluation/Actions Std                   0.666885
evaluation/Actions Max                   0.887458
evaluation/Actions Min                  -0.968465
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.16
time/data storing (s)                    0.0198865
time/evaluation sampling (s)            12.7858
time/exploration sampling (s)            5.02428
time/logging (s)                         0.0433584
time/sac training (s)                   33.0696
time/saving (s)                          0.0381941
time/training (s)                        0.000201534
time/epoch (s)                          50.9813
time/total (s)                       30897.8
Epoch                                  225
----------------------------------  -----------------
2020-11-09 23:43:29.457253 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 226 finished
----------------------------------  ----------------
replay_buffer/size                  456000
trainer/num train calls             227000
trainer/QF1 Loss                        96.1933
trainer/QF2 Loss                        91.3344
trainer/Policy Loss                     57.8594
trainer/Q1 Predictions Mean            -57.3886
trainer/Q1 Predictions Std              79.7991
trainer/Q1 Predictions Max              56.4331
trainer/Q1 Predictions Min            -291.259
trainer/Q2 Predictions Mean            -57.4797
trainer/Q2 Predictions Std              79.8181
trainer/Q2 Predictions Max              56.3395
trainer/Q2 Predictions Min            -289.582
trainer/Q Targets Mean                 -57.4637
trainer/Q Targets Std                   80.591
trainer/Q Targets Max                   52.971
trainer/Q Targets Min                 -289.936
trainer/Log Pis Mean                     1.95257
trainer/Log Pis Std                      1.81704
trainer/Log Pis Max                      5.854
trainer/Log Pis Min                     -4.61772
trainer/policy/mean Mean                -0.417288
trainer/policy/mean Std                  0.733299
trainer/policy/mean Max                  0.969627
trainer/policy/mean Min                 -0.987294
trainer/policy/normal/std Mean           0.572028
trainer/policy/normal/std Std            0.0980182
trainer/policy/normal/std Max            1.10113
trainer/policy/normal/std Min            0.246508
trainer/policy/normal/log_std Mean      -0.572562
trainer/policy/normal/log_std Std        0.167156
trainer/policy/normal/log_std Max        0.0963385
trainer/policy/normal/log_std Min       -1.40036
trainer/Alpha                            0.0299557
trainer/Alpha Loss                      -0.166376
exploration/num steps total         456000
exploration/num paths total           2280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.958344
exploration/Rewards Std                  1.40727
exploration/Rewards Max                 -1.12391e-25
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.669
exploration/Returns Std                144.867
exploration/Returns Max                -52.7492
exploration/Returns Min               -574.224
exploration/Actions Mean                -0.229191
exploration/Actions Std                  0.82456
exploration/Actions Max                  0.999389
exploration/Actions Min                 -0.998402
exploration/Num Paths                   10
exploration/Average Returns           -191.669
evaluation/num steps total               1.09505e+06
evaluation/num paths total            5448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.534848
evaluation/Actions Std                   0.483561
evaluation/Actions Max                   0.896714
evaluation/Actions Min                  -0.970609
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0195381
time/evaluation sampling (s)            15.7665
time/exploration sampling (s)            5.85804
time/logging (s)                         0.0297729
time/sac training (s)                   32.1565
time/saving (s)                          0.0298356
time/training (s)                        0.000120279
time/epoch (s)                          53.8603
time/total (s)                       30973.1
Epoch                                  226
----------------------------------  ----------------
2020-11-09 23:44:30.118796 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 227 finished
----------------------------------  ----------------
replay_buffer/size                  458000
trainer/num train calls             228000
trainer/QF1 Loss                       236.972
trainer/QF2 Loss                       226.396
trainer/Policy Loss                     65.748
trainer/Q1 Predictions Mean            -65.3182
trainer/Q1 Predictions Std              85.4388
trainer/Q1 Predictions Max              64.1107
trainer/Q1 Predictions Min            -255.733
trainer/Q2 Predictions Mean            -65.343
trainer/Q2 Predictions Std              85.4308
trainer/Q2 Predictions Max              64.6924
trainer/Q2 Predictions Min            -256.216
trainer/Q Targets Mean                 -64.056
trainer/Q Targets Std                   86.1198
trainer/Q Targets Max                   66.693
trainer/Q Targets Min                 -255.001
trainer/Log Pis Mean                     2.01048
trainer/Log Pis Std                      1.7391
trainer/Log Pis Max                      6.69378
trainer/Log Pis Min                     -4.01076
trainer/policy/mean Mean                -0.479285
trainer/policy/mean Std                  0.702352
trainer/policy/mean Max                  0.985535
trainer/policy/mean Min                 -0.986401
trainer/policy/normal/std Mean           0.602327
trainer/policy/normal/std Std            0.11551
trainer/policy/normal/std Max            1.1885
trainer/policy/normal/std Min            0.30159
trainer/policy/normal/log_std Mean      -0.523909
trainer/policy/normal/log_std Std        0.18154
trainer/policy/normal/log_std Max        0.172692
trainer/policy/normal/log_std Min       -1.19869
trainer/Alpha                            0.0304895
trainer/Alpha Loss                       0.0365855
exploration/num steps total         458000
exploration/num paths total           2290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00053
exploration/Rewards Std                  1.51307
exploration/Rewards Max                 -2.66028e-82
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -200.106
exploration/Returns Std                126.967
exploration/Returns Max                -45.621
exploration/Returns Min               -491.161
exploration/Actions Mean                -0.511312
exploration/Actions Std                  0.689854
exploration/Actions Max                  0.997218
exploration/Actions Min                 -0.999859
exploration/Num Paths                   10
exploration/Average Returns           -200.106
evaluation/num steps total               1.09987e+06
evaluation/num paths total            5472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.01242
evaluation/Rewards Std                   1.20892
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1007.5
evaluation/Returns Std                 241.789
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.58078
evaluation/Actions Std                   0.500756
evaluation/Actions Max                   0.866823
evaluation/Actions Min                  -0.973711
evaluation/Num Paths                    24
evaluation/Average Returns           -1007.5
time/data storing (s)                    0.0199191
time/evaluation sampling (s)            12.4403
time/exploration sampling (s)            5.04321
time/logging (s)                         0.0190986
time/sac training (s)                   29.3797
time/saving (s)                          0.0213938
time/training (s)                        9.8708e-05
time/epoch (s)                          46.9236
time/total (s)                       31033.7
Epoch                                  227
----------------------------------  ----------------
2020-11-09 23:45:35.829990 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 228 finished
----------------------------------  -----------------
replay_buffer/size                  460000
trainer/num train calls             229000
trainer/QF1 Loss                       103.162
trainer/QF2 Loss                       105.619
trainer/Policy Loss                     66.1658
trainer/Q1 Predictions Mean            -65.7721
trainer/Q1 Predictions Std              82.4196
trainer/Q1 Predictions Max              68.7713
trainer/Q1 Predictions Min            -227.785
trainer/Q2 Predictions Mean            -65.6251
trainer/Q2 Predictions Std              82.2192
trainer/Q2 Predictions Max              68.0782
trainer/Q2 Predictions Min            -227.903
trainer/Q Targets Mean                 -65.3213
trainer/Q Targets Std                   83.1258
trainer/Q Targets Max                   68.0608
trainer/Q Targets Min                 -229.828
trainer/Log Pis Mean                     2.14962
trainer/Log Pis Std                      1.69638
trainer/Log Pis Max                      6.83549
trainer/Log Pis Min                     -4.256
trainer/policy/mean Mean                -0.52279
trainer/policy/mean Std                  0.670201
trainer/policy/mean Max                  0.957741
trainer/policy/mean Min                 -0.988899
trainer/policy/normal/std Mean           0.587348
trainer/policy/normal/std Std            0.113446
trainer/policy/normal/std Max            1.13284
trainer/policy/normal/std Min            0.252689
trainer/policy/normal/log_std Mean      -0.549502
trainer/policy/normal/log_std Std        0.184606
trainer/policy/normal/log_std Max        0.12473
trainer/policy/normal/log_std Min       -1.3756
trainer/Alpha                            0.030441
trainer/Alpha Loss                       0.522457
exploration/num steps total         460000
exploration/num paths total           2300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.814054
exploration/Rewards Std                  1.47663
exploration/Rewards Max                 -4.95481e-175
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -162.811
exploration/Returns Std                135.233
exploration/Returns Max                -16.6546
exploration/Returns Min               -526.819
exploration/Actions Mean                -0.727221
exploration/Actions Std                  0.41474
exploration/Actions Max                  0.985423
exploration/Actions Min                 -0.999361
exploration/Num Paths                   10
exploration/Average Returns           -162.811
evaluation/num steps total               1.1047e+06
evaluation/num paths total            5496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.24985
evaluation/Rewards Std                   1.46883
evaluation/Rewards Max                  -1.23642e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1055.22
evaluation/Returns Std                 294.616
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.58552
evaluation/Actions Std                   0.43603
evaluation/Actions Max                   0.539948
evaluation/Actions Min                  -0.973641
evaluation/Num Paths                    24
evaluation/Average Returns           -1055.22
time/data storing (s)                    0.0203529
time/evaluation sampling (s)            12.9941
time/exploration sampling (s)            4.95979
time/logging (s)                         0.0309327
time/sac training (s)                   32.2291
time/saving (s)                          0.0288296
time/training (s)                        0.000100425
time/epoch (s)                          50.2633
time/total (s)                       31099.4
Epoch                                  228
----------------------------------  -----------------
2020-11-09 23:47:06.235049 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 229 finished
----------------------------------  -----------------
replay_buffer/size                  462000
trainer/num train calls             230000
trainer/QF1 Loss                       272.018
trainer/QF2 Loss                       275.425
trainer/Policy Loss                     63.9351
trainer/Q1 Predictions Mean            -63.6062
trainer/Q1 Predictions Std              82.3054
trainer/Q1 Predictions Max              84.0722
trainer/Q1 Predictions Min            -240.964
trainer/Q2 Predictions Mean            -63.4148
trainer/Q2 Predictions Std              82.2797
trainer/Q2 Predictions Max              84.0606
trainer/Q2 Predictions Min            -241.143
trainer/Q Targets Mean                 -62.7535
trainer/Q Targets Std                   82.7872
trainer/Q Targets Max                   83.7796
trainer/Q Targets Min                 -240.107
trainer/Log Pis Mean                     1.88876
trainer/Log Pis Std                      1.6607
trainer/Log Pis Max                      5.35853
trainer/Log Pis Min                     -3.71136
trainer/policy/mean Mean                -0.408613
trainer/policy/mean Std                  0.724632
trainer/policy/mean Max                  0.964097
trainer/policy/mean Min                 -0.979386
trainer/policy/normal/std Mean           0.575865
trainer/policy/normal/std Std            0.0901974
trainer/policy/normal/std Max            0.884752
trainer/policy/normal/std Min            0.186882
trainer/policy/normal/log_std Mean      -0.565206
trainer/policy/normal/log_std Std        0.169115
trainer/policy/normal/log_std Max       -0.122448
trainer/policy/normal/log_std Min       -1.67728
trainer/Alpha                            0.0305847
trainer/Alpha Loss                      -0.387911
exploration/num steps total         462000
exploration/num paths total           2310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.09107
exploration/Rewards Std                  1.65384
exploration/Rewards Max                 -1.39156e-154
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -218.213
exploration/Returns Std                123.733
exploration/Returns Max                -77.9816
exploration/Returns Min               -487.148
exploration/Actions Mean                -0.395781
exploration/Actions Std                  0.73651
exploration/Actions Max                  0.997234
exploration/Actions Min                 -0.999254
exploration/Num Paths                   10
exploration/Average Returns           -218.213
evaluation/num steps total               1.10952e+06
evaluation/num paths total            5520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.53629
evaluation/Rewards Std                   1.36483
evaluation/Rewards Max                  -3.63341e-10
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1112.79
evaluation/Returns Std                 274.04
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.561082
evaluation/Actions Std                   0.449247
evaluation/Actions Max                   0.888668
evaluation/Actions Min                  -0.969552
evaluation/Num Paths                    24
evaluation/Average Returns           -1112.79
time/data storing (s)                    0.0209356
time/evaluation sampling (s)            16.5515
time/exploration sampling (s)            7.53978
time/logging (s)                         0.0482216
time/sac training (s)                   38.385
time/saving (s)                          0.0684
time/training (s)                        0.000129884
time/epoch (s)                          62.614
time/total (s)                       31189.8
Epoch                                  229
----------------------------------  -----------------
2020-11-09 23:48:26.278389 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 230 finished
----------------------------------  -----------------
replay_buffer/size                  464000
trainer/num train calls             231000
trainer/QF1 Loss                        21.4089
trainer/QF2 Loss                        24.0276
trainer/Policy Loss                     55.95
trainer/Q1 Predictions Mean            -55.708
trainer/Q1 Predictions Std              82.0236
trainer/Q1 Predictions Max              63.7789
trainer/Q1 Predictions Min            -263.766
trainer/Q2 Predictions Mean            -55.4969
trainer/Q2 Predictions Std              82.0151
trainer/Q2 Predictions Max              63.6528
trainer/Q2 Predictions Min            -264.024
trainer/Q Targets Mean                 -56.3127
trainer/Q Targets Std                   82.7507
trainer/Q Targets Max                   63.8955
trainer/Q Targets Min                 -262.938
trainer/Log Pis Mean                     2.08982
trainer/Log Pis Std                      1.91308
trainer/Log Pis Max                     10.078
trainer/Log Pis Min                     -3.8276
trainer/policy/mean Mean                -0.434606
trainer/policy/mean Std                  0.714472
trainer/policy/mean Max                  0.984532
trainer/policy/mean Min                 -0.999682
trainer/policy/normal/std Mean           0.587455
trainer/policy/normal/std Std            0.0995328
trainer/policy/normal/std Max            1.03114
trainer/policy/normal/std Min            0.187019
trainer/policy/normal/log_std Mean      -0.546978
trainer/policy/normal/log_std Std        0.17829
trainer/policy/normal/log_std Max        0.0306669
trainer/policy/normal/log_std Min       -1.67655
trainer/Alpha                            0.0307042
trainer/Alpha Loss                       0.312879
exploration/num steps total         464000
exploration/num paths total           2320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.926377
exploration/Rewards Std                  1.51887
exploration/Rewards Max                 -1.08613e-124
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -185.275
exploration/Returns Std                167.98
exploration/Returns Max                -27.9663
exploration/Returns Min               -585.203
exploration/Actions Mean                -0.398131
exploration/Actions Std                  0.757827
exploration/Actions Max                  0.998695
exploration/Actions Min                 -0.998864
exploration/Num Paths                   10
exploration/Average Returns           -185.275
evaluation/num steps total               1.11434e+06
evaluation/num paths total            5544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.597183
evaluation/Actions Std                   0.387606
evaluation/Actions Max                  -0.149484
evaluation/Actions Min                  -0.972791
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.0288675
time/evaluation sampling (s)            15.991
time/exploration sampling (s)            5.69516
time/logging (s)                         0.0328159
time/sac training (s)                   34.493
time/saving (s)                          0.0264619
time/training (s)                        0.000127257
time/epoch (s)                          56.2674
time/total (s)                       31269.8
Epoch                                  230
----------------------------------  -----------------
2020-11-09 23:49:51.961104 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 231 finished
----------------------------------  ----------------
replay_buffer/size                  466000
trainer/num train calls             232000
trainer/QF1 Loss                       199.443
trainer/QF2 Loss                       193.018
trainer/Policy Loss                     61.6105
trainer/Q1 Predictions Mean            -61.2255
trainer/Q1 Predictions Std              81.1162
trainer/Q1 Predictions Max              33.5542
trainer/Q1 Predictions Min            -232.637
trainer/Q2 Predictions Mean            -61.2771
trainer/Q2 Predictions Std              81.0572
trainer/Q2 Predictions Max              33.0489
trainer/Q2 Predictions Min            -234.172
trainer/Q Targets Mean                 -61.4664
trainer/Q Targets Std                   82.0132
trainer/Q Targets Max                   32.1364
trainer/Q Targets Min                 -235.347
trainer/Log Pis Mean                     2.0215
trainer/Log Pis Std                      1.75954
trainer/Log Pis Max                      5.85511
trainer/Log Pis Min                     -4.50944
trainer/policy/mean Mean                -0.351949
trainer/policy/mean Std                  0.757995
trainer/policy/mean Max                  0.964992
trainer/policy/mean Min                 -0.984912
trainer/policy/normal/std Mean           0.568683
trainer/policy/normal/std Std            0.0900959
trainer/policy/normal/std Max            0.901908
trainer/policy/normal/std Min            0.192295
trainer/policy/normal/log_std Mean      -0.577883
trainer/policy/normal/log_std Std        0.169023
trainer/policy/normal/log_std Max       -0.103243
trainer/policy/normal/log_std Min       -1.64873
trainer/Alpha                            0.0306566
trainer/Alpha Loss                       0.0749392
exploration/num steps total         466000
exploration/num paths total           2330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.11917
exploration/Rewards Std                  1.68418
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -223.834
exploration/Returns Std                191.028
exploration/Returns Max                -49.6098
exploration/Returns Min               -626.071
exploration/Actions Mean                -0.215378
exploration/Actions Std                  0.839541
exploration/Actions Max                  0.999252
exploration/Actions Min                 -0.99967
exploration/Num Paths                   10
exploration/Average Returns           -223.834
evaluation/num steps total               1.11917e+06
evaluation/num paths total            5568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.55711
evaluation/Rewards Std                   1.00613
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1116.98
evaluation/Returns Std                 202.074
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.492899
evaluation/Actions Std                   0.521225
evaluation/Actions Max                   0.711225
evaluation/Actions Min                  -0.977979
evaluation/Num Paths                    24
evaluation/Average Returns           -1116.98
time/data storing (s)                    0.0229155
time/evaluation sampling (s)            14.8494
time/exploration sampling (s)            8.18471
time/logging (s)                         0.0355183
time/sac training (s)                   34.4523
time/saving (s)                          0.0358232
time/training (s)                        0.000161131
time/epoch (s)                          57.5808
time/total (s)                       31355.5
Epoch                                  231
----------------------------------  ----------------
2020-11-09 23:51:13.392273 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 232 finished
----------------------------------  ----------------
replay_buffer/size                  468000
trainer/num train calls             233000
trainer/QF1 Loss                        31.3883
trainer/QF2 Loss                        31.1044
trainer/Policy Loss                     67.1699
trainer/Q1 Predictions Mean            -66.8324
trainer/Q1 Predictions Std              83.637
trainer/Q1 Predictions Max              62.0303
trainer/Q1 Predictions Min            -263.585
trainer/Q2 Predictions Mean            -66.6032
trainer/Q2 Predictions Std              83.3836
trainer/Q2 Predictions Max              62.0315
trainer/Q2 Predictions Min            -263.93
trainer/Q Targets Mean                 -67.1323
trainer/Q Targets Std                   84.3001
trainer/Q Targets Max                   61.943
trainer/Q Targets Min                 -262.567
trainer/Log Pis Mean                     2.10951
trainer/Log Pis Std                      1.77809
trainer/Log Pis Max                      5.80599
trainer/Log Pis Min                     -3.11352
trainer/policy/mean Mean                -0.337157
trainer/policy/mean Std                  0.773852
trainer/policy/mean Max                  0.966384
trainer/policy/mean Min                 -0.984935
trainer/policy/normal/std Mean           0.562793
trainer/policy/normal/std Std            0.0817457
trainer/policy/normal/std Max            0.899865
trainer/policy/normal/std Min            0.230774
trainer/policy/normal/log_std Mean      -0.585454
trainer/policy/normal/log_std Std        0.147193
trainer/policy/normal/log_std Max       -0.10551
trainer/policy/normal/log_std Min       -1.46632
trainer/Alpha                            0.0302208
trainer/Alpha Loss                       0.383215
exploration/num steps total         468000
exploration/num paths total           2340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12412
exploration/Rewards Std                  1.60271
exploration/Rewards Max                 -3.20666e-91
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -224.824
exploration/Returns Std                193.137
exploration/Returns Max                -57.4853
exploration/Returns Min               -583.78
exploration/Actions Mean                -0.304744
exploration/Actions Std                  0.764661
exploration/Actions Max                  0.99805
exploration/Actions Min                 -0.99905
exploration/Num Paths                   10
exploration/Average Returns           -224.824
evaluation/num steps total               1.12399e+06
evaluation/num paths total            5592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.71798
evaluation/Rewards Std                   0.724255
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1149.31
evaluation/Returns Std                 145.332
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.438414
evaluation/Actions Std                   0.560151
evaluation/Actions Max                   0.890841
evaluation/Actions Min                  -0.977418
evaluation/Num Paths                    24
evaluation/Average Returns           -1149.31
time/data storing (s)                    0.0281782
time/evaluation sampling (s)            14.8047
time/exploration sampling (s)            5.432
time/logging (s)                         0.0366481
time/sac training (s)                   33.5452
time/saving (s)                          0.12237
time/training (s)                        0.000108007
time/epoch (s)                          53.9693
time/total (s)                       31436.9
Epoch                                  232
----------------------------------  ----------------
2020-11-09 23:52:43.387068 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 233 finished
----------------------------------  ----------------
replay_buffer/size                  470000
trainer/num train calls             234000
trainer/QF1 Loss                       141.236
trainer/QF2 Loss                       144.59
trainer/Policy Loss                     67.4818
trainer/Q1 Predictions Mean            -67.0406
trainer/Q1 Predictions Std              87.9383
trainer/Q1 Predictions Max              82.7941
trainer/Q1 Predictions Min            -287.755
trainer/Q2 Predictions Mean            -66.7534
trainer/Q2 Predictions Std              87.8219
trainer/Q2 Predictions Max              82.0024
trainer/Q2 Predictions Min            -286.679
trainer/Q Targets Mean                 -66.3984
trainer/Q Targets Std                   88.1686
trainer/Q Targets Max                   82.0214
trainer/Q Targets Min                 -286.379
trainer/Log Pis Mean                     1.88901
trainer/Log Pis Std                      1.7355
trainer/Log Pis Max                      6.54912
trainer/Log Pis Min                     -3.28696
trainer/policy/mean Mean                -0.429883
trainer/policy/mean Std                  0.713785
trainer/policy/mean Max                  0.959586
trainer/policy/mean Min                 -0.999502
trainer/policy/normal/std Mean           0.581571
trainer/policy/normal/std Std            0.0979242
trainer/policy/normal/std Max            0.994521
trainer/policy/normal/std Min            0.264178
trainer/policy/normal/log_std Mean      -0.555965
trainer/policy/normal/log_std Std        0.167697
trainer/policy/normal/log_std Max       -0.00549446
trainer/policy/normal/log_std Min       -1.33113
trainer/Alpha                            0.0307603
trainer/Alpha Loss                      -0.386424
exploration/num steps total         470000
exploration/num paths total           2350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.903872
exploration/Rewards Std                  1.46016
exploration/Rewards Max                 -3.83111e-68
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -180.774
exploration/Returns Std                116.13
exploration/Returns Max                -43.3299
exploration/Returns Min               -420.724
exploration/Actions Mean                -0.360331
exploration/Actions Std                  0.780408
exploration/Actions Max                  0.99793
exploration/Actions Min                 -0.998839
exploration/Num Paths                   10
exploration/Average Returns           -180.774
evaluation/num steps total               1.12882e+06
evaluation/num paths total            5616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.50208
evaluation/Rewards Std                   0.97022
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1105.92
evaluation/Returns Std                 195.003
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.627081
evaluation/Actions Std                   0.367468
evaluation/Actions Max                  -0.170089
evaluation/Actions Min                  -0.973466
evaluation/Num Paths                    24
evaluation/Average Returns           -1105.92
time/data storing (s)                    0.0231921
time/evaluation sampling (s)            19.0346
time/exploration sampling (s)            5.5497
time/logging (s)                         0.035183
time/sac training (s)                   34.1209
time/saving (s)                          0.119556
time/training (s)                        0.000149066
time/epoch (s)                          58.8833
time/total (s)                       31526.8
Epoch                                  233
----------------------------------  ----------------
2020-11-09 23:54:33.376624 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 234 finished
----------------------------------  -----------------
replay_buffer/size                  472000
trainer/num train calls             235000
trainer/QF1 Loss                        29.732
trainer/QF2 Loss                        27.1041
trainer/Policy Loss                     64.4805
trainer/Q1 Predictions Mean            -64.0379
trainer/Q1 Predictions Std              85.5385
trainer/Q1 Predictions Max             117.185
trainer/Q1 Predictions Min            -228.604
trainer/Q2 Predictions Mean            -64.1864
trainer/Q2 Predictions Std              85.6242
trainer/Q2 Predictions Max             116.66
trainer/Q2 Predictions Min            -228.646
trainer/Q Targets Mean                 -65.3497
trainer/Q Targets Std                   86.4064
trainer/Q Targets Max                  115.908
trainer/Q Targets Min                 -230.901
trainer/Log Pis Mean                     2.08966
trainer/Log Pis Std                      1.88695
trainer/Log Pis Max                      7.48267
trainer/Log Pis Min                     -3.61865
trainer/policy/mean Mean                -0.569165
trainer/policy/mean Std                  0.625887
trainer/policy/mean Max                  0.936789
trainer/policy/mean Min                 -0.990568
trainer/policy/normal/std Mean           0.58098
trainer/policy/normal/std Std            0.104366
trainer/policy/normal/std Max            0.951317
trainer/policy/normal/std Min            0.175746
trainer/policy/normal/log_std Mean      -0.560084
trainer/policy/normal/log_std Std        0.189802
trainer/policy/normal/log_std Max       -0.0499077
trainer/policy/normal/log_std Min       -1.73872
trainer/Alpha                            0.0302154
trainer/Alpha Loss                       0.313751
exploration/num steps total         472000
exploration/num paths total           2360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.854892
exploration/Rewards Std                  1.51271
exploration/Rewards Max                 -1.41031e-183
exploration/Rewards Min                 -6.11544
exploration/Returns Mean              -170.978
exploration/Returns Std                 62.7747
exploration/Returns Max                -88.1675
exploration/Returns Min               -264.847
exploration/Actions Mean                -0.483676
exploration/Actions Std                  0.647657
exploration/Actions Max                  0.997089
exploration/Actions Min                 -0.99898
exploration/Num Paths                   10
exploration/Average Returns           -170.978
evaluation/num steps total               1.13364e+06
evaluation/num paths total            5640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.20274
evaluation/Rewards Std                   1.52494
evaluation/Rewards Max                  -1.37184e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1045.75
evaluation/Returns Std                 306.102
evaluation/Returns Max                  -6.76849
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.837113
evaluation/Actions Std                   0.139979
evaluation/Actions Max                  -0.668197
evaluation/Actions Min                  -0.984843
evaluation/Num Paths                    24
evaluation/Average Returns           -1045.75
time/data storing (s)                    0.020558
time/evaluation sampling (s)            22.4996
time/exploration sampling (s)            6.62459
time/logging (s)                         0.0570134
time/sac training (s)                   37.9685
time/saving (s)                          0.0901621
time/training (s)                        0.000157497
time/epoch (s)                          67.2606
time/total (s)                       31636.8
Epoch                                  234
----------------------------------  -----------------
2020-11-09 23:56:22.995878 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 235 finished
----------------------------------  ----------------
replay_buffer/size                  474000
trainer/num train calls             236000
trainer/QF1 Loss                        46.4195
trainer/QF2 Loss                        50.7902
trainer/Policy Loss                     80.5639
trainer/Q1 Predictions Mean            -80.038
trainer/Q1 Predictions Std              84.7856
trainer/Q1 Predictions Max              74.7404
trainer/Q1 Predictions Min            -241.396
trainer/Q2 Predictions Mean            -80.1046
trainer/Q2 Predictions Std              84.7123
trainer/Q2 Predictions Max              72.4453
trainer/Q2 Predictions Min            -242.118
trainer/Q Targets Mean                 -80.6896
trainer/Q Targets Std                   85.6141
trainer/Q Targets Max                   72.6543
trainer/Q Targets Min                 -241.042
trainer/Log Pis Mean                     2.16407
trainer/Log Pis Std                      1.84258
trainer/Log Pis Max                      8.73954
trainer/Log Pis Min                     -3.7302
trainer/policy/mean Mean                -0.566539
trainer/policy/mean Std                  0.634938
trainer/policy/mean Max                  0.973391
trainer/policy/mean Min                 -0.999503
trainer/policy/normal/std Mean           0.567761
trainer/policy/normal/std Std            0.0954406
trainer/policy/normal/std Max            0.814115
trainer/policy/normal/std Min            0.252427
trainer/policy/normal/log_std Mean      -0.580836
trainer/policy/normal/log_std Std        0.175661
trainer/policy/normal/log_std Max       -0.205653
trainer/policy/normal/log_std Min       -1.37663
trainer/Alpha                            0.0296762
trainer/Alpha Loss                       0.577118
exploration/num steps total         474000
exploration/num paths total           2370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.943778
exploration/Rewards Std                  1.60721
exploration/Rewards Max                 -7.1153e-125
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.756
exploration/Returns Std                111.836
exploration/Returns Max                -91.3056
exploration/Returns Min               -463.02
exploration/Actions Mean                -0.485999
exploration/Actions Std                  0.650663
exploration/Actions Max                  0.996957
exploration/Actions Min                 -0.999511
exploration/Num Paths                   10
exploration/Average Returns           -188.756
evaluation/num steps total               1.13846e+06
evaluation/num paths total            5664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.825889
evaluation/Actions Std                   0.146103
evaluation/Actions Max                  -0.675698
evaluation/Actions Min                  -0.972094
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0221288
time/evaluation sampling (s)            16.2982
time/exploration sampling (s)            6.61066
time/logging (s)                         0.0376974
time/sac training (s)                   39.25
time/saving (s)                          0.0749325
time/training (s)                        0.000154377
time/epoch (s)                          62.2938
time/total (s)                       31746.4
Epoch                                  235
----------------------------------  ----------------
2020-11-09 23:58:43.640462 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 236 finished
----------------------------------  -----------------
replay_buffer/size                  476000
trainer/num train calls             237000
trainer/QF1 Loss                        90.3463
trainer/QF2 Loss                        88.652
trainer/Policy Loss                     64.2127
trainer/Q1 Predictions Mean            -63.8443
trainer/Q1 Predictions Std              82.9664
trainer/Q1 Predictions Max              59.5856
trainer/Q1 Predictions Min            -222.475
trainer/Q2 Predictions Mean            -63.848
trainer/Q2 Predictions Std              82.8831
trainer/Q2 Predictions Max              59.5627
trainer/Q2 Predictions Min            -227.048
trainer/Q Targets Mean                 -64.3177
trainer/Q Targets Std                   84.2958
trainer/Q Targets Max                   59.2615
trainer/Q Targets Min                 -255.837
trainer/Log Pis Mean                     2.14252
trainer/Log Pis Std                      1.70197
trainer/Log Pis Max                      7.39905
trainer/Log Pis Min                     -4.65998
trainer/policy/mean Mean                -0.554543
trainer/policy/mean Std                  0.645535
trainer/policy/mean Max                  0.944437
trainer/policy/mean Min                 -0.993237
trainer/policy/normal/std Mean           0.571279
trainer/policy/normal/std Std            0.0971342
trainer/policy/normal/std Max            1.02581
trainer/policy/normal/std Min            0.229541
trainer/policy/normal/log_std Mean      -0.574712
trainer/policy/normal/log_std Std        0.175806
trainer/policy/normal/log_std Max        0.0254841
trainer/policy/normal/log_std Min       -1.47167
trainer/Alpha                            0.0301309
trainer/Alpha Loss                       0.499151
exploration/num steps total         476000
exploration/num paths total           2380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.819606
exploration/Rewards Std                  1.55359
exploration/Rewards Max                 -2.37538e-200
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -163.921
exploration/Returns Std                 67.7744
exploration/Returns Max                -50.4064
exploration/Returns Min               -260.94
exploration/Actions Mean                -0.559887
exploration/Actions Std                  0.597537
exploration/Actions Max                  0.99655
exploration/Actions Min                 -0.999316
exploration/Num Paths                   10
exploration/Average Returns           -163.921
evaluation/num steps total               1.14329e+06
evaluation/num paths total            5688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.5033
evaluation/Rewards Std                   0.971511
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1106.16
evaluation/Returns Std                 194.465
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.785995
evaluation/Actions Std                   0.289944
evaluation/Actions Max                   0.44918
evaluation/Actions Min                  -0.973253
evaluation/Num Paths                    24
evaluation/Average Returns           -1106.16
time/data storing (s)                    0.0485103
time/evaluation sampling (s)            20.0818
time/exploration sampling (s)            8.64693
time/logging (s)                         0.0881928
time/sac training (s)                   40.3217
time/saving (s)                          0.241806
time/training (s)                        0.000163587
time/epoch (s)                          69.4291
time/total (s)                       31887
Epoch                                  236
----------------------------------  -----------------
2020-11-10 00:01:42.745582 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 237 finished
----------------------------------  -----------------
replay_buffer/size                  478000
trainer/num train calls             238000
trainer/QF1 Loss                        69.2721
trainer/QF2 Loss                        67.696
trainer/Policy Loss                     55.8293
trainer/Q1 Predictions Mean            -55.5452
trainer/Q1 Predictions Std              83.0836
trainer/Q1 Predictions Max             108.264
trainer/Q1 Predictions Min            -284.062
trainer/Q2 Predictions Mean            -55.4351
trainer/Q2 Predictions Std              82.9851
trainer/Q2 Predictions Max             108.393
trainer/Q2 Predictions Min            -283.485
trainer/Q Targets Mean                 -55.6819
trainer/Q Targets Std                   83.7253
trainer/Q Targets Max                  107.698
trainer/Q Targets Min                 -283.091
trainer/Log Pis Mean                     1.90662
trainer/Log Pis Std                      1.54714
trainer/Log Pis Max                      5.49617
trainer/Log Pis Min                     -4.38296
trainer/policy/mean Mean                -0.51472
trainer/policy/mean Std                  0.649873
trainer/policy/mean Max                  0.962866
trainer/policy/mean Min                 -0.990733
trainer/policy/normal/std Mean           0.569804
trainer/policy/normal/std Std            0.0938895
trainer/policy/normal/std Max            1.0718
trainer/policy/normal/std Min            0.182901
trainer/policy/normal/log_std Mean      -0.576939
trainer/policy/normal/log_std Std        0.176032
trainer/policy/normal/log_std Max        0.0693358
trainer/policy/normal/log_std Min       -1.69881
trainer/Alpha                            0.0306293
trainer/Alpha Loss                      -0.325496
exploration/num steps total         478000
exploration/num paths total           2390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.33156
exploration/Rewards Std                  1.64678
exploration/Rewards Max                 -1.30249e-202
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -266.312
exploration/Returns Std                145.827
exploration/Returns Max                -24.5705
exploration/Returns Min               -548.232
exploration/Actions Mean                -0.593476
exploration/Actions Std                  0.603535
exploration/Actions Max                  0.995677
exploration/Actions Min                 -0.999038
exploration/Num Paths                   10
exploration/Average Returns           -266.312
evaluation/num steps total               1.14811e+06
evaluation/num paths total            5712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.45362
evaluation/Rewards Std                   1.07961
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1096.18
evaluation/Returns Std                 216.717
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.837559
evaluation/Actions Std                   0.133781
evaluation/Actions Max                  -0.683088
evaluation/Actions Min                  -0.968862
evaluation/Num Paths                    24
evaluation/Average Returns           -1096.18
time/data storing (s)                    0.0269615
time/evaluation sampling (s)            17.4305
time/exploration sampling (s)            7.84952
time/logging (s)                         0.0953162
time/sac training (s)                   45.5455
time/saving (s)                          0.192989
time/training (s)                        0.000150194
time/epoch (s)                          71.141
time/total (s)                       32066.1
Epoch                                  237
----------------------------------  -----------------
2020-11-10 00:04:10.496073 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 238 finished
----------------------------------  ----------------
replay_buffer/size                  480000
trainer/num train calls             239000
trainer/QF1 Loss                       219.381
trainer/QF2 Loss                       222.536
trainer/Policy Loss                     68.8704
trainer/Q1 Predictions Mean            -68.4662
trainer/Q1 Predictions Std              82.0287
trainer/Q1 Predictions Max              63.2431
trainer/Q1 Predictions Min            -283.523
trainer/Q2 Predictions Mean            -68.494
trainer/Q2 Predictions Std              82.0472
trainer/Q2 Predictions Max              62.6415
trainer/Q2 Predictions Min            -282.771
trainer/Q Targets Mean                 -67.6849
trainer/Q Targets Std                   82.574
trainer/Q Targets Max                   62.7033
trainer/Q Targets Min                 -282.313
trainer/Log Pis Mean                     2.13873
trainer/Log Pis Std                      1.70907
trainer/Log Pis Max                      5.79844
trainer/Log Pis Min                     -4.73538
trainer/policy/mean Mean                -0.539993
trainer/policy/mean Std                  0.639109
trainer/policy/mean Max                  0.937122
trainer/policy/mean Min                 -0.985504
trainer/policy/normal/std Mean           0.557113
trainer/policy/normal/std Std            0.089218
trainer/policy/normal/std Max            0.877582
trainer/policy/normal/std Min            0.228419
trainer/policy/normal/log_std Mean      -0.599322
trainer/policy/normal/log_std Std        0.176647
trainer/policy/normal/log_std Max       -0.130585
trainer/policy/normal/log_std Min       -1.47658
trainer/Alpha                            0.0307952
trainer/Alpha Loss                       0.482852
exploration/num steps total         480000
exploration/num paths total           2400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.04949
exploration/Rewards Std                  1.44253
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -209.898
exploration/Returns Std                161.781
exploration/Returns Max                 -3.4012
exploration/Returns Min               -518.003
exploration/Actions Mean                -0.546282
exploration/Actions Std                  0.648776
exploration/Actions Max                  0.997876
exploration/Actions Min                 -0.998837
exploration/Num Paths                   10
exploration/Average Returns           -209.898
evaluation/num steps total               1.15294e+06
evaluation/num paths total            5736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   5.41334e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.809558
evaluation/Actions Std                   0.164011
evaluation/Actions Max                  -0.634703
evaluation/Actions Min                  -0.974107
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0227896
time/evaluation sampling (s)            15.9081
time/exploration sampling (s)            6.09603
time/logging (s)                         0.0491993
time/sac training (s)                   40.5108
time/saving (s)                          0.106075
time/training (s)                        0.000164306
time/epoch (s)                          62.6931
time/total (s)                       32213.7
Epoch                                  238
----------------------------------  ----------------
2020-11-10 00:07:19.920496 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 239 finished
----------------------------------  -----------------
replay_buffer/size                  482000
trainer/num train calls             240000
trainer/QF1 Loss                        87.0844
trainer/QF2 Loss                        92.3533
trainer/Policy Loss                     57.96
trainer/Q1 Predictions Mean            -57.5245
trainer/Q1 Predictions Std              81.9912
trainer/Q1 Predictions Max              61.8322
trainer/Q1 Predictions Min            -223.204
trainer/Q2 Predictions Mean            -57.6335
trainer/Q2 Predictions Std              82.0754
trainer/Q2 Predictions Max              61.5874
trainer/Q2 Predictions Min            -224.389
trainer/Q Targets Mean                 -57.914
trainer/Q Targets Std                   82.58
trainer/Q Targets Max                   62.0045
trainer/Q Targets Min                 -229.483
trainer/Log Pis Mean                     2.00344
trainer/Log Pis Std                      1.8094
trainer/Log Pis Max                      6.44712
trainer/Log Pis Min                     -4.06772
trainer/policy/mean Mean                -0.5544
trainer/policy/mean Std                  0.647921
trainer/policy/mean Max                  0.927229
trainer/policy/mean Min                 -0.991721
trainer/policy/normal/std Mean           0.572769
trainer/policy/normal/std Std            0.0919992
trainer/policy/normal/std Max            1.06916
trainer/policy/normal/std Min            0.230305
trainer/policy/normal/log_std Mean      -0.570821
trainer/policy/normal/log_std Std        0.169043
trainer/policy/normal/log_std Max        0.0668758
trainer/policy/normal/log_std Min       -1.46835
trainer/Alpha                            0.0307854
trainer/Alpha Loss                       0.0119739
exploration/num steps total         482000
exploration/num paths total           2410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14106
exploration/Rewards Std                  1.53909
exploration/Rewards Max                 -4.01143e-267
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -228.212
exploration/Returns Std                158.247
exploration/Returns Max                -38.2847
exploration/Returns Min               -535.226
exploration/Actions Mean                -0.550303
exploration/Actions Std                  0.639452
exploration/Actions Max                  0.995841
exploration/Actions Min                 -0.999339
exploration/Num Paths                   10
exploration/Average Returns           -228.212
evaluation/num steps total               1.15776e+06
evaluation/num paths total            5760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.31065
evaluation/Rewards Std                   1.4872
evaluation/Rewards Max                  -5.46598e-14
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1067.44
evaluation/Returns Std                 298.034
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.73306
evaluation/Actions Std                   0.29577
evaluation/Actions Max                   0.275422
evaluation/Actions Min                  -0.968672
evaluation/Num Paths                    24
evaluation/Average Returns           -1067.44
time/data storing (s)                    0.0435791
time/evaluation sampling (s)            20.9403
time/exploration sampling (s)            8.09614
time/logging (s)                         0.0809989
time/sac training (s)                   40.2038
time/saving (s)                          0.233339
time/training (s)                        0.000129332
time/epoch (s)                          69.5982
time/total (s)                       32403.2
Epoch                                  239
----------------------------------  -----------------
2020-11-10 00:10:38.582854 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 240 finished
----------------------------------  -----------------
replay_buffer/size                  484000
trainer/num train calls             241000
trainer/QF1 Loss                        86.3011
trainer/QF2 Loss                        82.2288
trainer/Policy Loss                     63.9271
trainer/Q1 Predictions Mean            -63.6331
trainer/Q1 Predictions Std              84.6934
trainer/Q1 Predictions Max              83.1213
trainer/Q1 Predictions Min            -260.712
trainer/Q2 Predictions Mean            -63.6478
trainer/Q2 Predictions Std              84.5612
trainer/Q2 Predictions Max              83.2578
trainer/Q2 Predictions Min            -260.72
trainer/Q Targets Mean                 -63.3522
trainer/Q Targets Std                   84.7594
trainer/Q Targets Max                   83.144
trainer/Q Targets Min                 -259.936
trainer/Log Pis Mean                     2.03572
trainer/Log Pis Std                      1.70946
trainer/Log Pis Max                      6.41545
trainer/Log Pis Min                     -3.4124
trainer/policy/mean Mean                -0.483785
trainer/policy/mean Std                  0.691574
trainer/policy/mean Max                  0.947915
trainer/policy/mean Min                 -0.991201
trainer/policy/normal/std Mean           0.570025
trainer/policy/normal/std Std            0.0813911
trainer/policy/normal/std Max            0.799515
trainer/policy/normal/std Min            0.233879
trainer/policy/normal/log_std Mean      -0.572922
trainer/policy/normal/log_std Std        0.151221
trainer/policy/normal/log_std Max       -0.223749
trainer/policy/normal/log_std Min       -1.45295
trainer/Alpha                            0.0300119
trainer/Alpha Loss                       0.125236
exploration/num steps total         484000
exploration/num paths total           2420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.82966
exploration/Rewards Std                  1.44623
exploration/Rewards Max                 -6.02118e-146
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -165.932
exploration/Returns Std                 82.1186
exploration/Returns Max                -65.1512
exploration/Returns Min               -279.41
exploration/Actions Mean                -0.517186
exploration/Actions Std                  0.62471
exploration/Actions Max                  0.998803
exploration/Actions Min                 -0.999285
exploration/Num Paths                   10
exploration/Average Returns           -165.932
evaluation/num steps total               1.16258e+06
evaluation/num paths total            5784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6415
evaluation/Rewards Std                   1.29554
evaluation/Rewards Max                  -8.18948e-12
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1133.94
evaluation/Returns Std                 259.691
evaluation/Returns Max                 -13.3965
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.770515
evaluation/Actions Std                   0.313997
evaluation/Actions Max                   0.885958
evaluation/Actions Min                  -0.974629
evaluation/Num Paths                    24
evaluation/Average Returns           -1133.94
time/data storing (s)                    0.0472816
time/evaluation sampling (s)            18.1999
time/exploration sampling (s)            7.54906
time/logging (s)                         0.0546673
time/sac training (s)                   43.7343
time/saving (s)                          0.0667715
time/training (s)                        0.000156199
time/epoch (s)                          69.6522
time/total (s)                       32601.8
Epoch                                  240
----------------------------------  -----------------
2020-11-10 00:13:10.718153 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 241 finished
----------------------------------  -----------------
replay_buffer/size                  486000
trainer/num train calls             242000
trainer/QF1 Loss                        24.8586
trainer/QF2 Loss                        23.4624
trainer/Policy Loss                     57.2
trainer/Q1 Predictions Mean            -56.9366
trainer/Q1 Predictions Std              81.206
trainer/Q1 Predictions Max             116.007
trainer/Q1 Predictions Min            -260.862
trainer/Q2 Predictions Mean            -56.902
trainer/Q2 Predictions Std              81.2364
trainer/Q2 Predictions Max             115.201
trainer/Q2 Predictions Min            -260.919
trainer/Q Targets Mean                 -57.0692
trainer/Q Targets Std                   81.6722
trainer/Q Targets Max                  114.534
trainer/Q Targets Min                 -259.682
trainer/Log Pis Mean                     1.81874
trainer/Log Pis Std                      1.68398
trainer/Log Pis Max                      6.0584
trainer/Log Pis Min                     -5.58498
trainer/policy/mean Mean                -0.440394
trainer/policy/mean Std                  0.696533
trainer/policy/mean Max                  0.96116
trainer/policy/mean Min                 -0.981781
trainer/policy/normal/std Mean           0.572971
trainer/policy/normal/std Std            0.0912046
trainer/policy/normal/std Max            1.05101
trainer/policy/normal/std Min            0.247706
trainer/policy/normal/log_std Mean      -0.569144
trainer/policy/normal/log_std Std        0.156161
trainer/policy/normal/log_std Max        0.0497557
trainer/policy/normal/log_std Min       -1.39551
trainer/Alpha                            0.0299166
trainer/Alpha Loss                      -0.636086
exploration/num steps total         486000
exploration/num paths total           2430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.908272
exploration/Rewards Std                  1.54345
exploration/Rewards Max                 -3.20719e-148
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -181.654
exploration/Returns Std                122.655
exploration/Returns Max                 -6.76849
exploration/Returns Min               -421.353
exploration/Actions Mean                -0.307857
exploration/Actions Std                  0.776779
exploration/Actions Max                  0.99881
exploration/Actions Min                 -0.998969
exploration/Num Paths                   10
exploration/Average Returns           -181.654
evaluation/num steps total               1.16741e+06
evaluation/num paths total            5808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.38904e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.800466
evaluation/Actions Std                   0.168089
evaluation/Actions Max                  -0.623996
evaluation/Actions Min                  -0.969303
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0242444
time/evaluation sampling (s)            13.9814
time/exploration sampling (s)            5.56935
time/logging (s)                         0.0678697
time/sac training (s)                   39.9109
time/saving (s)                          0.131082
time/training (s)                        0.000143437
time/epoch (s)                          59.6849
time/total (s)                       32753.9
Epoch                                  241
----------------------------------  -----------------
2020-11-10 00:16:02.301595 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 242 finished
----------------------------------  -----------------
replay_buffer/size                  488000
trainer/num train calls             243000
trainer/QF1 Loss                        14.5044
trainer/QF2 Loss                        14.4913
trainer/Policy Loss                     67.26
trainer/Q1 Predictions Mean            -66.9621
trainer/Q1 Predictions Std              88.2263
trainer/Q1 Predictions Max              61.5279
trainer/Q1 Predictions Min            -281.616
trainer/Q2 Predictions Mean            -66.9949
trainer/Q2 Predictions Std              88.345
trainer/Q2 Predictions Max              61.7288
trainer/Q2 Predictions Min            -280.916
trainer/Q Targets Mean                 -67.695
trainer/Q Targets Std                   88.9105
trainer/Q Targets Max                   61.5922
trainer/Q Targets Min                 -280.684
trainer/Log Pis Mean                     1.75723
trainer/Log Pis Std                      1.68744
trainer/Log Pis Max                      5.91626
trainer/Log Pis Min                     -4.59207
trainer/policy/mean Mean                -0.370932
trainer/policy/mean Std                  0.75055
trainer/policy/mean Max                  0.96779
trainer/policy/mean Min                 -0.978546
trainer/policy/normal/std Mean           0.57678
trainer/policy/normal/std Std            0.0763397
trainer/policy/normal/std Max            0.962384
trainer/policy/normal/std Min            0.237028
trainer/policy/normal/log_std Mean      -0.559386
trainer/policy/normal/log_std Std        0.137599
trainer/policy/normal/log_std Max       -0.0383416
trainer/policy/normal/log_std Min       -1.43958
trainer/Alpha                            0.0298901
trainer/Alpha Loss                      -0.85219
exploration/num steps total         488000
exploration/num paths total           2440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00804
exploration/Rewards Std                  1.54908
exploration/Rewards Max                 -2.69199e-174
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -201.608
exploration/Returns Std                127.172
exploration/Returns Max                -22.509
exploration/Returns Min               -470.734
exploration/Actions Mean                -0.481265
exploration/Actions Std                  0.654562
exploration/Actions Max                  0.997583
exploration/Actions Min                 -0.998935
exploration/Num Paths                   10
exploration/Average Returns           -201.608
evaluation/num steps total               1.17223e+06
evaluation/num paths total            5832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.00951
evaluation/Rewards Std                   1.216
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1006.91
evaluation/Returns Std                 242.678
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.495358
evaluation/Actions Std                   0.569639
evaluation/Actions Max                   0.869098
evaluation/Actions Min                  -0.973572
evaluation/Num Paths                    24
evaluation/Average Returns           -1006.91
time/data storing (s)                    0.019956
time/evaluation sampling (s)            14.2542
time/exploration sampling (s)            7.07856
time/logging (s)                         0.0460672
time/sac training (s)                   41.0001
time/saving (s)                          0.0613003
time/training (s)                        0.000161422
time/epoch (s)                          62.4604
time/total (s)                       32925.4
Epoch                                  242
----------------------------------  -----------------
2020-11-10 00:18:30.714451 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 243 finished
----------------------------------  -----------------
replay_buffer/size                  490000
trainer/num train calls             244000
trainer/QF1 Loss                       236.207
trainer/QF2 Loss                       236.272
trainer/Policy Loss                     59.6881
trainer/Q1 Predictions Mean            -59.3861
trainer/Q1 Predictions Std              81.8325
trainer/Q1 Predictions Max              64.2469
trainer/Q1 Predictions Min            -260.019
trainer/Q2 Predictions Mean            -59.2728
trainer/Q2 Predictions Std              81.6638
trainer/Q2 Predictions Max              61.8207
trainer/Q2 Predictions Min            -260.229
trainer/Q Targets Mean                 -58.6279
trainer/Q Targets Std                   81.6889
trainer/Q Targets Max                   61.5108
trainer/Q Targets Min                 -258.893
trainer/Log Pis Mean                     2.06196
trainer/Log Pis Std                      1.71609
trainer/Log Pis Max                      5.87088
trainer/Log Pis Min                     -3.69177
trainer/policy/mean Mean                -0.424133
trainer/policy/mean Std                  0.720612
trainer/policy/mean Max                  0.967745
trainer/policy/mean Min                 -0.986615
trainer/policy/normal/std Mean           0.568285
trainer/policy/normal/std Std            0.089242
trainer/policy/normal/std Max            0.851786
trainer/policy/normal/std Min            0.306787
trainer/policy/normal/log_std Mean      -0.577485
trainer/policy/normal/log_std Std        0.158243
trainer/policy/normal/log_std Max       -0.16042
trainer/policy/normal/log_std Min       -1.1816
trainer/Alpha                            0.0299947
trainer/Alpha Loss                       0.217286
exploration/num steps total         490000
exploration/num paths total           2450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.10399
exploration/Rewards Std                  1.63658
exploration/Rewards Max                 -1.11215e-230
exploration/Rewards Min                 -6.10917
exploration/Returns Mean              -220.799
exploration/Returns Std                101.195
exploration/Returns Max                -78.5999
exploration/Returns Min               -419.537
exploration/Actions Mean                -0.388875
exploration/Actions Std                  0.758395
exploration/Actions Max                  0.997682
exploration/Actions Min                 -0.999727
exploration/Num Paths                   10
exploration/Average Returns           -220.799
evaluation/num steps total               1.17706e+06
evaluation/num paths total            5856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.06933
evaluation/Rewards Std                   1.12657
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1018.94
evaluation/Returns Std                 224.991
evaluation/Returns Max                -655.47
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.582297
evaluation/Actions Std                   0.477003
evaluation/Actions Max                   0.878951
evaluation/Actions Min                  -0.981846
evaluation/Num Paths                    24
evaluation/Average Returns           -1018.94
time/data storing (s)                    0.0286707
time/evaluation sampling (s)            15.5069
time/exploration sampling (s)            5.1038
time/logging (s)                         0.0455787
time/sac training (s)                   42.2178
time/saving (s)                          0.0901296
time/training (s)                        0.000161658
time/epoch (s)                          62.993
time/total (s)                       33073.8
Epoch                                  243
----------------------------------  -----------------
2020-11-10 00:20:59.962092 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 244 finished
----------------------------------  -----------------
replay_buffer/size                  492000
trainer/num train calls             245000
trainer/QF1 Loss                       122.508
trainer/QF2 Loss                       120.455
trainer/Policy Loss                     67.4636
trainer/Q1 Predictions Mean            -67.0684
trainer/Q1 Predictions Std              84.1979
trainer/Q1 Predictions Max              54.3926
trainer/Q1 Predictions Min            -279.002
trainer/Q2 Predictions Mean            -66.9733
trainer/Q2 Predictions Std              84.2591
trainer/Q2 Predictions Max              54.7098
trainer/Q2 Predictions Min            -278.299
trainer/Q Targets Mean                 -67.0248
trainer/Q Targets Std                   84.9822
trainer/Q Targets Max                   54.6005
trainer/Q Targets Min                 -277.821
trainer/Log Pis Mean                     2.17715
trainer/Log Pis Std                      1.79758
trainer/Log Pis Max                      6.66426
trainer/Log Pis Min                     -3.57729
trainer/policy/mean Mean                -0.58104
trainer/policy/mean Std                  0.603362
trainer/policy/mean Max                  0.947656
trainer/policy/mean Min                 -0.987932
trainer/policy/normal/std Mean           0.570713
trainer/policy/normal/std Std            0.0891278
trainer/policy/normal/std Max            0.838918
trainer/policy/normal/std Min            0.24911
trainer/policy/normal/log_std Mean      -0.573467
trainer/policy/normal/log_std Std        0.161431
trainer/policy/normal/log_std Max       -0.175643
trainer/policy/normal/log_std Min       -1.38986
trainer/Alpha                            0.0306093
trainer/Alpha Loss                       0.617622
exploration/num steps total         492000
exploration/num paths total           2460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.10405
exploration/Rewards Std                  1.59587
exploration/Rewards Max                 -2.06264e-129
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -220.809
exploration/Returns Std                202.913
exploration/Returns Max                -52.1396
exploration/Returns Min               -630.866
exploration/Actions Mean                -0.529779
exploration/Actions Std                  0.676262
exploration/Actions Max                  0.996496
exploration/Actions Min                 -0.999197
exploration/Num Paths                   10
exploration/Average Returns           -220.809
evaluation/num steps total               1.18188e+06
evaluation/num paths total            5880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.61482
evaluation/Rewards Std                   1.206
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -927.579
evaluation/Returns Std                 239.235
evaluation/Returns Max                -658.035
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.541604
evaluation/Actions Std                   0.56501
evaluation/Actions Max                   0.778028
evaluation/Actions Min                  -0.986127
evaluation/Num Paths                    24
evaluation/Average Returns            -927.579
time/data storing (s)                    0.0263846
time/evaluation sampling (s)            15.3427
time/exploration sampling (s)            5.43446
time/logging (s)                         0.0594005
time/sac training (s)                   39.4197
time/saving (s)                          0.0960509
time/training (s)                        0.000165553
time/epoch (s)                          60.3788
time/total (s)                       33223
Epoch                                  244
----------------------------------  -----------------
2020-11-10 00:24:00.172314 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 245 finished
----------------------------------  -----------------
replay_buffer/size                  494000
trainer/num train calls             246000
trainer/QF1 Loss                        14.6371
trainer/QF2 Loss                        17.9935
trainer/Policy Loss                     65.738
trainer/Q1 Predictions Mean            -65.2332
trainer/Q1 Predictions Std              84.9743
trainer/Q1 Predictions Max              53.9888
trainer/Q1 Predictions Min            -258.459
trainer/Q2 Predictions Mean            -65.2626
trainer/Q2 Predictions Std              85.1185
trainer/Q2 Predictions Max              54.2432
trainer/Q2 Predictions Min            -258.422
trainer/Q Targets Mean                 -65.8746
trainer/Q Targets Std                   85.8811
trainer/Q Targets Max                   54.0765
trainer/Q Targets Min                 -257.516
trainer/Log Pis Mean                     1.84998
trainer/Log Pis Std                      2.02506
trainer/Log Pis Max                      7.40709
trainer/Log Pis Min                     -4.32599
trainer/policy/mean Mean                -0.555272
trainer/policy/mean Std                  0.631816
trainer/policy/mean Max                  0.93553
trainer/policy/mean Min                 -0.996361
trainer/policy/normal/std Mean           0.58446
trainer/policy/normal/std Std            0.0865476
trainer/policy/normal/std Max            0.84697
trainer/policy/normal/std Min            0.250011
trainer/policy/normal/log_std Mean      -0.548843
trainer/policy/normal/log_std Std        0.1579
trainer/policy/normal/log_std Max       -0.16609
trainer/policy/normal/log_std Min       -1.38625
trainer/Alpha                            0.0309725
trainer/Alpha Loss                      -0.521259
exploration/num steps total         494000
exploration/num paths total           2470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.734169
exploration/Rewards Std                  1.44769
exploration/Rewards Max                 -1.00745e-129
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.834
exploration/Returns Std                 77.6365
exploration/Returns Max                -47.869
exploration/Returns Min               -302.65
exploration/Actions Mean                -0.489756
exploration/Actions Std                  0.645119
exploration/Actions Max                  0.996289
exploration/Actions Min                 -0.999123
exploration/Num Paths                   10
exploration/Average Returns           -146.834
evaluation/num steps total               1.1867e+06
evaluation/num paths total            5904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   5.80175e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   7.65454e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.92723
evaluation/Actions Std                   0.0455586
evaluation/Actions Max                  -0.881635
evaluation/Actions Min                  -0.972949
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.019681
time/evaluation sampling (s)            13.6476
time/exploration sampling (s)            5.29682
time/logging (s)                         0.0532311
time/sac training (s)                   49.9186
time/saving (s)                          0.0526891
time/training (s)                        0.000120406
time/epoch (s)                          68.9887
time/total (s)                       33403.2
Epoch                                  245
----------------------------------  -----------------
2020-11-10 00:26:38.231341 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 246 finished
----------------------------------  -----------------
replay_buffer/size                  496000
trainer/num train calls             247000
trainer/QF1 Loss                       161.011
trainer/QF2 Loss                       165.073
trainer/Policy Loss                     73.0189
trainer/Q1 Predictions Mean            -72.4874
trainer/Q1 Predictions Std              88.1602
trainer/Q1 Predictions Max             101.292
trainer/Q1 Predictions Min            -277.441
trainer/Q2 Predictions Mean            -72.7318
trainer/Q2 Predictions Std              88.398
trainer/Q2 Predictions Max             100.988
trainer/Q2 Predictions Min            -277
trainer/Q Targets Mean                 -72.2316
trainer/Q Targets Std                   89.0066
trainer/Q Targets Max                  100.92
trainer/Q Targets Min                 -276.461
trainer/Log Pis Mean                     2.27895
trainer/Log Pis Std                      1.65349
trainer/Log Pis Max                      5.97519
trainer/Log Pis Min                     -5.21957
trainer/policy/mean Mean                -0.377544
trainer/policy/mean Std                  0.761922
trainer/policy/mean Max                  0.96962
trainer/policy/mean Min                 -0.987814
trainer/policy/normal/std Mean           0.543172
trainer/policy/normal/std Std            0.0729023
trainer/policy/normal/std Max            0.842096
trainer/policy/normal/std Min            0.255225
trainer/policy/normal/log_std Mean      -0.619877
trainer/policy/normal/log_std Std        0.141433
trainer/policy/normal/log_std Max       -0.171861
trainer/policy/normal/log_std Min       -1.36561
trainer/Alpha                            0.030716
trainer/Alpha Loss                       0.971575
exploration/num steps total         496000
exploration/num paths total           2480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.47453
exploration/Rewards Std                  1.50918
exploration/Rewards Max                 -1.00393e-118
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -294.906
exploration/Returns Std                182.546
exploration/Returns Max                -51.4362
exploration/Returns Min               -519.503
exploration/Actions Mean                -0.401258
exploration/Actions Std                  0.725066
exploration/Actions Max                  0.994109
exploration/Actions Min                 -0.999379
exploration/Num Paths                   10
exploration/Average Returns           -294.906
evaluation/num steps total               1.19153e+06
evaluation/num paths total            5928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.01222e-13
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   1.41539e-12
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.73407
evaluation/Actions Std                   0.24146
evaluation/Actions Max                  -0.492423
evaluation/Actions Min                  -0.975525
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0197976
time/evaluation sampling (s)            16.1809
time/exploration sampling (s)            5.34671
time/logging (s)                         0.0540405
time/sac training (s)                   43.2982
time/saving (s)                          0.113407
time/training (s)                        0.000181364
time/epoch (s)                          65.0132
time/total (s)                       33561.2
Epoch                                  246
----------------------------------  -----------------
2020-11-10 00:30:12.874573 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 247 finished
----------------------------------  -----------------
replay_buffer/size                  498000
trainer/num train calls             248000
trainer/QF1 Loss                       147.676
trainer/QF2 Loss                       153.998
trainer/Policy Loss                     68.2368
trainer/Q1 Predictions Mean            -67.8296
trainer/Q1 Predictions Std              84.322
trainer/Q1 Predictions Max             115.446
trainer/Q1 Predictions Min            -254.912
trainer/Q2 Predictions Mean            -67.8185
trainer/Q2 Predictions Std              84.2923
trainer/Q2 Predictions Max             115.546
trainer/Q2 Predictions Min            -256.175
trainer/Q Targets Mean                 -67.5948
trainer/Q Targets Std                   84.8977
trainer/Q Targets Max                  115.271
trainer/Q Targets Min                 -255.02
trainer/Log Pis Mean                     2.0813
trainer/Log Pis Std                      1.78658
trainer/Log Pis Max                      7.51148
trainer/Log Pis Min                     -2.77789
trainer/policy/mean Mean                -0.621139
trainer/policy/mean Std                  0.583161
trainer/policy/mean Max                  0.946809
trainer/policy/mean Min                 -0.996697
trainer/policy/normal/std Mean           0.569044
trainer/policy/normal/std Std            0.0837942
trainer/policy/normal/std Max            0.84048
trainer/policy/normal/std Min            0.194781
trainer/policy/normal/log_std Mean      -0.575835
trainer/policy/normal/log_std Std        0.161233
trainer/policy/normal/log_std Max       -0.173783
trainer/policy/normal/log_std Min       -1.63588
trainer/Alpha                            0.0304423
trainer/Alpha Loss                       0.283881
exploration/num steps total         498000
exploration/num paths total           2490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.08628
exploration/Rewards Std                  1.62047
exploration/Rewards Max                 -2.03231e-124
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -217.256
exploration/Returns Std                 83.9354
exploration/Returns Max               -142.691
exploration/Returns Min               -403.441
exploration/Actions Mean                -0.51895
exploration/Actions Std                  0.649367
exploration/Actions Max                  0.995866
exploration/Actions Min                 -0.999226
exploration/Num Paths                   10
exploration/Average Returns           -217.256
evaluation/num steps total               1.19635e+06
evaluation/num paths total            5952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.74108
evaluation/Rewards Std                   0.884392
evaluation/Rewards Max                  -3.4012
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.96
evaluation/Returns Std                 177.763
evaluation/Returns Max                -683.641
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.944499
evaluation/Actions Std                   0.0264902
evaluation/Actions Max                  -0.86954
evaluation/Actions Min                  -0.967828
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.96
time/data storing (s)                    0.0248003
time/evaluation sampling (s)            18.0489
time/exploration sampling (s)            6.60193
time/logging (s)                         0.070715
time/sac training (s)                   50.0927
time/saving (s)                          0.120415
time/training (s)                        0.000168892
time/epoch (s)                          74.9597
time/total (s)                       33775.8
Epoch                                  247
----------------------------------  -----------------
2020-11-10 00:32:57.415468 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 248 finished
----------------------------------  -----------------
replay_buffer/size                  500000
trainer/num train calls             249000
trainer/QF1 Loss                        68.3268
trainer/QF2 Loss                        69.2136
trainer/Policy Loss                     61.0044
trainer/Q1 Predictions Mean            -60.5747
trainer/Q1 Predictions Std              83.3951
trainer/Q1 Predictions Max              46.3173
trainer/Q1 Predictions Min            -274.682
trainer/Q2 Predictions Mean            -60.6253
trainer/Q2 Predictions Std              83.3381
trainer/Q2 Predictions Max              45.3971
trainer/Q2 Predictions Min            -274.258
trainer/Q Targets Mean                 -60.595
trainer/Q Targets Std                   83.9508
trainer/Q Targets Max                   45.1018
trainer/Q Targets Min                 -273.621
trainer/Log Pis Mean                     1.87556
trainer/Log Pis Std                      1.83473
trainer/Log Pis Max                      5.62006
trainer/Log Pis Min                     -5.40009
trainer/policy/mean Mean                -0.367978
trainer/policy/mean Std                  0.745579
trainer/policy/mean Max                  0.981168
trainer/policy/mean Min                 -0.984434
trainer/policy/normal/std Mean           0.550805
trainer/policy/normal/std Std            0.0733663
trainer/policy/normal/std Max            0.853104
trainer/policy/normal/std Min            0.244906
trainer/policy/normal/log_std Mean      -0.605914
trainer/policy/normal/log_std Std        0.141994
trainer/policy/normal/log_std Max       -0.158874
trainer/policy/normal/log_std Min       -1.40688
trainer/Alpha                            0.0300856
trainer/Alpha Loss                      -0.435987
exploration/num steps total         500000
exploration/num paths total           2500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.53988
exploration/Rewards Std                  1.58581
exploration/Rewards Max                 -1.12667e-313
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -307.977
exploration/Returns Std                200.488
exploration/Returns Max                -53.4684
exploration/Returns Min               -585.807
exploration/Actions Mean                -0.414024
exploration/Actions Std                  0.734295
exploration/Actions Max                  0.997539
exploration/Actions Min                 -0.999664
exploration/Num Paths                   10
exploration/Average Returns           -307.977
evaluation/num steps total               1.20118e+06
evaluation/num paths total            5976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.84487
evaluation/Rewards Std                   1.78247
evaluation/Rewards Max                  -1.0745e-22
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -973.819
evaluation/Returns Std                 357.322
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.477666
evaluation/Actions Std                   0.55916
evaluation/Actions Max                   0.897408
evaluation/Actions Min                  -0.981237
evaluation/Num Paths                    24
evaluation/Average Returns            -973.819
time/data storing (s)                    0.0212195
time/evaluation sampling (s)            15.2869
time/exploration sampling (s)            5.73202
time/logging (s)                         0.0396725
time/sac training (s)                   44.9389
time/saving (s)                          0.138676
time/training (s)                        0.000170029
time/epoch (s)                          66.1575
time/total (s)                       33940.2
Epoch                                  248
----------------------------------  -----------------
2020-11-10 00:35:43.319157 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 249 finished
----------------------------------  -----------------
replay_buffer/size                  502000
trainer/num train calls             250000
trainer/QF1 Loss                       356.152
trainer/QF2 Loss                       346.663
trainer/Policy Loss                     60.3155
trainer/Q1 Predictions Mean            -59.8262
trainer/Q1 Predictions Std              78.6966
trainer/Q1 Predictions Max              50.9328
trainer/Q1 Predictions Min            -218.686
trainer/Q2 Predictions Mean            -59.9081
trainer/Q2 Predictions Std              78.6631
trainer/Q2 Predictions Max              51.064
trainer/Q2 Predictions Min            -220.056
trainer/Q Targets Mean                 -58.263
trainer/Q Targets Std                   79.3621
trainer/Q Targets Max                   50.9247
trainer/Q Targets Min                 -221.095
trainer/Log Pis Mean                     1.76978
trainer/Log Pis Std                      1.92109
trainer/Log Pis Max                      6.55382
trainer/Log Pis Min                     -4.38178
trainer/policy/mean Mean                -0.472855
trainer/policy/mean Std                  0.69071
trainer/policy/mean Max                  0.97361
trainer/policy/mean Min                 -0.982865
trainer/policy/normal/std Mean           0.580654
trainer/policy/normal/std Std            0.0793837
trainer/policy/normal/std Max            0.875243
trainer/policy/normal/std Min            0.280297
trainer/policy/normal/log_std Mean      -0.552961
trainer/policy/normal/log_std Std        0.137674
trainer/policy/normal/log_std Max       -0.133254
trainer/policy/normal/log_std Min       -1.27191
trainer/Alpha                            0.030872
trainer/Alpha Loss                      -0.800667
exploration/num steps total         502000
exploration/num paths total           2510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.19749
exploration/Rewards Std                  1.60591
exploration/Rewards Max                 -8.48801e-207
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -239.497
exploration/Returns Std                167.385
exploration/Returns Max                -45.427
exploration/Returns Min               -552.999
exploration/Actions Mean                -0.417133
exploration/Actions Std                  0.754596
exploration/Actions Max                  0.998324
exploration/Actions Min                 -0.999809
exploration/Num Paths                   10
exploration/Average Returns           -239.497
evaluation/num steps total               1.206e+06
evaluation/num paths total            6000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.90257
evaluation/Rewards Std                   1.1539
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -985.416
evaluation/Returns Std                 229.389
evaluation/Returns Max                -652.601
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.569165
evaluation/Actions Std                   0.462672
evaluation/Actions Max                   0.845201
evaluation/Actions Min                  -0.974836
evaluation/Num Paths                    24
evaluation/Average Returns            -985.416
time/data storing (s)                    0.0239325
time/evaluation sampling (s)            17.7685
time/exploration sampling (s)            8.82638
time/logging (s)                         0.0560393
time/sac training (s)                   39.8221
time/saving (s)                          0.414323
time/training (s)                        0.000188546
time/epoch (s)                          66.9114
time/total (s)                       34106.1
Epoch                                  249
----------------------------------  -----------------
2020-11-10 00:38:38.161391 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 250 finished
----------------------------------  ----------------
replay_buffer/size                  504000
trainer/num train calls             251000
trainer/QF1 Loss                        58.885
trainer/QF2 Loss                        65.9024
trainer/Policy Loss                     57.0339
trainer/Q1 Predictions Mean            -56.5709
trainer/Q1 Predictions Std              81.6474
trainer/Q1 Predictions Max              57.7772
trainer/Q1 Predictions Min            -273.888
trainer/Q2 Predictions Mean            -56.6316
trainer/Q2 Predictions Std              81.6111
trainer/Q2 Predictions Max              57.5643
trainer/Q2 Predictions Min            -274.863
trainer/Q Targets Mean                 -57.0209
trainer/Q Targets Std                   82.2764
trainer/Q Targets Max                   57.9191
trainer/Q Targets Min                 -273.465
trainer/Log Pis Mean                     1.8761
trainer/Log Pis Std                      1.77387
trainer/Log Pis Max                      7.03928
trainer/Log Pis Min                     -3.28347
trainer/policy/mean Mean                -0.559121
trainer/policy/mean Std                  0.636215
trainer/policy/mean Max                  0.959874
trainer/policy/mean Min                 -0.989112
trainer/policy/normal/std Mean           0.592237
trainer/policy/normal/std Std            0.0906097
trainer/policy/normal/std Max            1.01566
trainer/policy/normal/std Min            0.280712
trainer/policy/normal/log_std Mean      -0.535309
trainer/policy/normal/log_std Std        0.151481
trainer/policy/normal/log_std Max        0.0155403
trainer/policy/normal/log_std Min       -1.27043
trainer/Alpha                            0.0304822
trainer/Alpha Loss                      -0.432484
exploration/num steps total         504000
exploration/num paths total           2520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.864861
exploration/Rewards Std                  1.52476
exploration/Rewards Max                 -2.86877e-70
exploration/Rewards Min                 -6.10519
exploration/Returns Mean              -172.972
exploration/Returns Std                 83.5705
exploration/Returns Max                -53.2702
exploration/Returns Min               -287.004
exploration/Actions Mean                -0.611861
exploration/Actions Std                  0.559146
exploration/Actions Max                  0.998865
exploration/Actions Min                 -0.999419
exploration/Num Paths                   10
exploration/Average Returns           -172.972
evaluation/num steps total               1.21082e+06
evaluation/num paths total            6024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.98843
evaluation/Rewards Std                   1.14133
evaluation/Rewards Max                  -2.94444
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1002.67
evaluation/Returns Std                 226.338
evaluation/Returns Max                -607.768
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.516578
evaluation/Actions Std                   0.50349
evaluation/Actions Max                   0.799935
evaluation/Actions Min                  -0.978493
evaluation/Num Paths                    24
evaluation/Average Returns           -1002.67
time/data storing (s)                    0.0254106
time/evaluation sampling (s)            16.3892
time/exploration sampling (s)            6.02872
time/logging (s)                         0.0773469
time/sac training (s)                   45.1101
time/saving (s)                          0.181071
time/training (s)                        0.000219409
time/epoch (s)                          67.8121
time/total (s)                       34280.9
Epoch                                  250
----------------------------------  ----------------
2020-11-10 00:41:45.230574 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 251 finished
----------------------------------  ----------------
replay_buffer/size                  506000
trainer/num train calls             252000
trainer/QF1 Loss                       213.57
trainer/QF2 Loss                       211.841
trainer/Policy Loss                     63.5997
trainer/Q1 Predictions Mean            -63.1095
trainer/Q1 Predictions Std              85.2855
trainer/Q1 Predictions Max              32.0559
trainer/Q1 Predictions Min            -256.57
trainer/Q2 Predictions Mean            -63.1204
trainer/Q2 Predictions Std              85.1749
trainer/Q2 Predictions Max              33.5408
trainer/Q2 Predictions Min            -256.566
trainer/Q Targets Mean                 -62.6787
trainer/Q Targets Std                   85.8051
trainer/Q Targets Max                   41.9073
trainer/Q Targets Min                 -255.54
trainer/Log Pis Mean                     2.41918
trainer/Log Pis Std                      1.56703
trainer/Log Pis Max                      8.57439
trainer/Log Pis Min                     -2.74176
trainer/policy/mean Mean                -0.51636
trainer/policy/mean Std                  0.676611
trainer/policy/mean Max                  0.951105
trainer/policy/mean Min                 -0.997537
trainer/policy/normal/std Mean           0.583027
trainer/policy/normal/std Std            0.0962021
trainer/policy/normal/std Max            0.836796
trainer/policy/normal/std Min            0.21567
trainer/policy/normal/log_std Mean      -0.553037
trainer/policy/normal/log_std Std        0.165296
trainer/policy/normal/log_std Max       -0.178176
trainer/policy/normal/log_std Min       -1.53401
trainer/Alpha                            0.0304699
trainer/Alpha Loss                       1.46338
exploration/num steps total         506000
exploration/num paths total           2530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.99463
exploration/Rewards Std                  1.60312
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -198.926
exploration/Returns Std                146.314
exploration/Returns Max                -27.2473
exploration/Returns Min               -510.332
exploration/Actions Mean                -0.456748
exploration/Actions Std                  0.710452
exploration/Actions Max                  0.99717
exploration/Actions Min                 -0.999136
exploration/Num Paths                   10
exploration/Average Returns           -198.926
evaluation/num steps total               1.21565e+06
evaluation/num paths total            6048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61227
evaluation/Rewards Std                   1.03547
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1128.07
evaluation/Returns Std                 208.129
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.772059
evaluation/Actions Std                   0.262792
evaluation/Actions Max                  -0.045847
evaluation/Actions Min                  -0.979007
evaluation/Num Paths                    24
evaluation/Average Returns           -1128.07
time/data storing (s)                    0.0212071
time/evaluation sampling (s)            13.8412
time/exploration sampling (s)            6.25559
time/logging (s)                         0.0599472
time/sac training (s)                   44.0646
time/saving (s)                          0.0743351
time/training (s)                        0.000150794
time/epoch (s)                          64.3171
time/total (s)                       34467.9
Epoch                                  251
----------------------------------  ----------------
2020-11-10 00:45:25.933574 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 252 finished
----------------------------------  -----------------
replay_buffer/size                  508000
trainer/num train calls             253000
trainer/QF1 Loss                       147.67
trainer/QF2 Loss                       145.964
trainer/Policy Loss                     63.1107
trainer/Q1 Predictions Mean            -62.6787
trainer/Q1 Predictions Std              82.2249
trainer/Q1 Predictions Max              52.8333
trainer/Q1 Predictions Min            -270.671
trainer/Q2 Predictions Mean            -62.6959
trainer/Q2 Predictions Std              82.4931
trainer/Q2 Predictions Max              53.4449
trainer/Q2 Predictions Min            -270.333
trainer/Q Targets Mean                 -61.7412
trainer/Q Targets Std                   82.9465
trainer/Q Targets Max                   52.8546
trainer/Q Targets Min                 -269.545
trainer/Log Pis Mean                     1.9193
trainer/Log Pis Std                      1.77907
trainer/Log Pis Max                      6.06157
trainer/Log Pis Min                     -4.81196
trainer/policy/mean Mean                -0.534808
trainer/policy/mean Std                  0.654006
trainer/policy/mean Max                  0.944257
trainer/policy/mean Min                 -0.987712
trainer/policy/normal/std Mean           0.576043
trainer/policy/normal/std Std            0.0864963
trainer/policy/normal/std Max            0.909455
trainer/policy/normal/std Min            0.209827
trainer/policy/normal/log_std Mean      -0.563276
trainer/policy/normal/log_std Std        0.156117
trainer/policy/normal/log_std Max       -0.0949092
trainer/policy/normal/log_std Min       -1.56147
trainer/Alpha                            0.0303016
trainer/Alpha Loss                      -0.282167
exploration/num steps total         508000
exploration/num paths total           2540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02536
exploration/Rewards Std                  1.51247
exploration/Rewards Max                 -5.82722e-124
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -205.073
exploration/Returns Std                133.75
exploration/Returns Max                -42.1068
exploration/Returns Min               -429.689
exploration/Actions Mean                -0.411123
exploration/Actions Std                  0.696583
exploration/Actions Max                  0.99818
exploration/Actions Min                 -0.998861
exploration/Num Paths                   10
exploration/Average Returns           -205.073
evaluation/num steps total               1.22047e+06
evaluation/num paths total            6072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95958
evaluation/Rewards Std                   0.55521
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.88
evaluation/Returns Std                 111.597
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.816276
evaluation/Actions Std                   0.178299
evaluation/Actions Max                  -0.031959
evaluation/Actions Min                  -0.96955
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.88
time/data storing (s)                    0.0353082
time/evaluation sampling (s)            19.7156
time/exploration sampling (s)            9.07154
time/logging (s)                         0.417238
time/sac training (s)                   44.9997
time/saving (s)                          0.164502
time/training (s)                        0.000727399
time/epoch (s)                          74.4046
time/total (s)                       34688.9
Epoch                                  252
----------------------------------  -----------------
2020-11-10 00:50:38.918747 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 253 finished
----------------------------------  -----------------
replay_buffer/size                  510000
trainer/num train calls             254000
trainer/QF1 Loss                        66.9286
trainer/QF2 Loss                        63.8827
trainer/Policy Loss                     63.9289
trainer/Q1 Predictions Mean            -63.4086
trainer/Q1 Predictions Std              82.5914
trainer/Q1 Predictions Max              52.3908
trainer/Q1 Predictions Min            -254.38
trainer/Q2 Predictions Mean            -63.539
trainer/Q2 Predictions Std              82.6742
trainer/Q2 Predictions Max              53.2869
trainer/Q2 Predictions Min            -255.55
trainer/Q Targets Mean                 -63.6938
trainer/Q Targets Std                   83.7361
trainer/Q Targets Max                   53.0603
trainer/Q Targets Min                 -254.339
trainer/Log Pis Mean                     1.81148
trainer/Log Pis Std                      1.63422
trainer/Log Pis Max                      7.13698
trainer/Log Pis Min                     -3.05846
trainer/policy/mean Mean                -0.402561
trainer/policy/mean Std                  0.71649
trainer/policy/mean Max                  0.966099
trainer/policy/mean Min                 -0.98963
trainer/policy/normal/std Mean           0.556251
trainer/policy/normal/std Std            0.0726043
trainer/policy/normal/std Max            0.796668
trainer/policy/normal/std Min            0.238431
trainer/policy/normal/log_std Mean      -0.595313
trainer/policy/normal/log_std Std        0.134451
trainer/policy/normal/log_std Max       -0.227317
trainer/policy/normal/log_std Min       -1.43367
trainer/Alpha                            0.0296029
trainer/Alpha Loss                      -0.663577
exploration/num steps total         510000
exploration/num paths total           2550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.29501
exploration/Rewards Std                  1.47312
exploration/Rewards Max                 -9.38762e-224
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -259.002
exploration/Returns Std                197.348
exploration/Returns Max                -58.7297
exploration/Returns Min               -584.716
exploration/Actions Mean                -0.489846
exploration/Actions Std                  0.636622
exploration/Actions Max                  0.997954
exploration/Actions Min                 -0.998682
exploration/Num Paths                   10
exploration/Average Returns           -259.002
evaluation/num steps total               1.2253e+06
evaluation/num paths total            6096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84381
evaluation/Rewards Std                   0.767927
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1174.61
evaluation/Returns Std                 154.352
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.555785
evaluation/Actions Std                   0.437373
evaluation/Actions Max                   0.603267
evaluation/Actions Min                  -0.97037
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.61
time/data storing (s)                    0.0283814
time/evaluation sampling (s)            28.1492
time/exploration sampling (s)            8.13659
time/logging (s)                         0.309465
time/sac training (s)                   49.5528
time/saving (s)                          0.376242
time/training (s)                        0.000192591
time/epoch (s)                          86.5529
time/total (s)                       35001.8
Epoch                                  253
----------------------------------  -----------------
2020-11-10 00:55:16.524022 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 254 finished
----------------------------------  -----------------
replay_buffer/size                  512000
trainer/num train calls             255000
trainer/QF1 Loss                       149.914
trainer/QF2 Loss                       149.818
trainer/Policy Loss                     60.1792
trainer/Q1 Predictions Mean            -59.6907
trainer/Q1 Predictions Std              85.4757
trainer/Q1 Predictions Max             114.295
trainer/Q1 Predictions Min            -254.58
trainer/Q2 Predictions Mean            -59.7903
trainer/Q2 Predictions Std              85.71
trainer/Q2 Predictions Max             114.534
trainer/Q2 Predictions Min            -255.685
trainer/Q Targets Mean                 -59.3315
trainer/Q Targets Std                   85.8439
trainer/Q Targets Max                  114.152
trainer/Q Targets Min                 -254.61
trainer/Log Pis Mean                     1.70248
trainer/Log Pis Std                      1.66345
trainer/Log Pis Max                      5.44061
trainer/Log Pis Min                     -3.52108
trainer/policy/mean Mean                -0.470442
trainer/policy/mean Std                  0.682232
trainer/policy/mean Max                  0.9588
trainer/policy/mean Min                 -0.978629
trainer/policy/normal/std Mean           0.576757
trainer/policy/normal/std Std            0.0770678
trainer/policy/normal/std Max            0.812436
trainer/policy/normal/std Min            0.247216
trainer/policy/normal/log_std Mean      -0.55926
trainer/policy/normal/log_std Std        0.13458
trainer/policy/normal/log_std Max       -0.207718
trainer/policy/normal/log_std Min       -1.39749
trainer/Alpha                            0.0289526
trainer/Alpha Loss                      -1.05385
exploration/num steps total         512000
exploration/num paths total           2560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.665178
exploration/Rewards Std                  1.1592
exploration/Rewards Max                 -3.65963e-111
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -133.036
exploration/Returns Std                 86.0092
exploration/Returns Max                -33.1067
exploration/Returns Min               -334.617
exploration/Actions Mean                -0.419105
exploration/Actions Std                  0.710724
exploration/Actions Max                  0.999434
exploration/Actions Min                 -0.998712
exploration/Num Paths                   10
exploration/Average Returns           -133.036
evaluation/num steps total               1.23012e+06
evaluation/num paths total            6120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59506
evaluation/Rewards Std                   1.38628
evaluation/Rewards Max                  -2.46062e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1124.61
evaluation/Returns Std                 278.301
evaluation/Returns Max                  -6.76849
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.661109
evaluation/Actions Std                   0.381037
evaluation/Actions Max                   0.868125
evaluation/Actions Min                  -0.969322
evaluation/Num Paths                    24
evaluation/Average Returns           -1124.61
time/data storing (s)                    0.0280279
time/evaluation sampling (s)            19.4412
time/exploration sampling (s)            6.3968
time/logging (s)                         0.0639568
time/sac training (s)                   57.4301
time/saving (s)                          0.112691
time/training (s)                        0.000183187
time/epoch (s)                          83.473
time/total (s)                       35279.1
Epoch                                  254
----------------------------------  -----------------
2020-11-10 00:58:36.598558 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 255 finished
----------------------------------  -----------------
replay_buffer/size                  514000
trainer/num train calls             256000
trainer/QF1 Loss                        17.4431
trainer/QF2 Loss                        19.7732
trainer/Policy Loss                     60.3079
trainer/Q1 Predictions Mean            -60.0435
trainer/Q1 Predictions Std              86.4096
trainer/Q1 Predictions Max              58.6817
trainer/Q1 Predictions Min            -243.799
trainer/Q2 Predictions Mean            -59.7464
trainer/Q2 Predictions Std              86.032
trainer/Q2 Predictions Max              58.6164
trainer/Q2 Predictions Min            -243.335
trainer/Q Targets Mean                 -60.7818
trainer/Q Targets Std                   87.2864
trainer/Q Targets Max                   58.8011
trainer/Q Targets Min                 -244.007
trainer/Log Pis Mean                     2.24194
trainer/Log Pis Std                      1.74258
trainer/Log Pis Max                      8.41236
trainer/Log Pis Min                     -3.63972
trainer/policy/mean Mean                -0.547271
trainer/policy/mean Std                  0.640578
trainer/policy/mean Max                  0.940974
trainer/policy/mean Min                 -0.998379
trainer/policy/normal/std Mean           0.579458
trainer/policy/normal/std Std            0.0959726
trainer/policy/normal/std Max            0.952289
trainer/policy/normal/std Min            0.243759
trainer/policy/normal/log_std Mean      -0.559649
trainer/policy/normal/log_std Std        0.169778
trainer/policy/normal/log_std Max       -0.0488862
trainer/policy/normal/log_std Min       -1.41158
trainer/Alpha                            0.0291175
trainer/Alpha Loss                       0.855591
exploration/num steps total         514000
exploration/num paths total           2570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.89039
exploration/Rewards Std                  1.48759
exploration/Rewards Max                 -6.96627e-138
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -178.078
exploration/Returns Std                 90.4473
exploration/Returns Max                -56.1634
exploration/Returns Min               -347.591
exploration/Actions Mean                -0.39347
exploration/Actions Std                  0.719562
exploration/Actions Max                  0.996791
exploration/Actions Min                 -0.999849
exploration/Num Paths                   10
exploration/Average Returns           -178.078
evaluation/num steps total               1.23494e+06
evaluation/num paths total            6144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.50126
evaluation/Rewards Std                   0.975325
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1105.75
evaluation/Returns Std                 195.381
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.797264
evaluation/Actions Std                   0.224468
evaluation/Actions Max                   0.265645
evaluation/Actions Min                  -0.976219
evaluation/Num Paths                    24
evaluation/Average Returns           -1105.75
time/data storing (s)                    0.0312795
time/evaluation sampling (s)            16.989
time/exploration sampling (s)            6.26762
time/logging (s)                         0.0573727
time/sac training (s)                   43.4397
time/saving (s)                          0.128928
time/training (s)                        0.00015762
time/epoch (s)                          66.9141
time/total (s)                       35479.1
Epoch                                  255
----------------------------------  -----------------
2020-11-10 01:02:23.781582 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 256 finished
----------------------------------  ----------------
replay_buffer/size                  516000
trainer/num train calls             257000
trainer/QF1 Loss                       132.239
trainer/QF2 Loss                       139.115
trainer/Policy Loss                     68.9301
trainer/Q1 Predictions Mean            -68.5729
trainer/Q1 Predictions Std              88.7792
trainer/Q1 Predictions Max              80.3258
trainer/Q1 Predictions Min            -267.862
trainer/Q2 Predictions Mean            -68.449
trainer/Q2 Predictions Std              88.7026
trainer/Q2 Predictions Max              80.0158
trainer/Q2 Predictions Min            -267.582
trainer/Q Targets Mean                 -68.315
trainer/Q Targets Std                   89.4582
trainer/Q Targets Max                   81.3599
trainer/Q Targets Min                 -266.748
trainer/Log Pis Mean                     2.16248
trainer/Log Pis Std                      1.69652
trainer/Log Pis Max                      6.92929
trainer/Log Pis Min                     -5.08804
trainer/policy/mean Mean                -0.380913
trainer/policy/mean Std                  0.744213
trainer/policy/mean Max                  0.965544
trainer/policy/mean Min                 -0.990411
trainer/policy/normal/std Mean           0.558986
trainer/policy/normal/std Std            0.0792123
trainer/policy/normal/std Max            0.835942
trainer/policy/normal/std Min            0.196672
trainer/policy/normal/log_std Mean      -0.592179
trainer/policy/normal/log_std Std        0.148838
trainer/policy/normal/log_std Max       -0.179196
trainer/policy/normal/log_std Min       -1.62622
trainer/Alpha                            0.0294429
trainer/Alpha Loss                       0.572782
exploration/num steps total         516000
exploration/num paths total           2580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.798026
exploration/Rewards Std                  1.47968
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -159.605
exploration/Returns Std                142.312
exploration/Returns Max                -40.9782
exploration/Returns Min               -467.145
exploration/Actions Mean                -0.310029
exploration/Actions Std                  0.769645
exploration/Actions Max                  0.996669
exploration/Actions Min                 -0.999409
exploration/Num Paths                   10
exploration/Average Returns           -159.605
evaluation/num steps total               1.23977e+06
evaluation/num paths total            6168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.556893
evaluation/Actions Std                   0.444276
evaluation/Actions Max                   0.8585
evaluation/Actions Min                  -0.977023
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0215374
time/evaluation sampling (s)            13.4796
time/exploration sampling (s)            5.786
time/logging (s)                         0.0803888
time/sac training (s)                   40.9554
time/saving (s)                          0.0981479
time/training (s)                        0.000138768
time/epoch (s)                          60.4211
time/total (s)                       35706.3
Epoch                                  256
----------------------------------  ----------------
2020-11-10 01:05:05.938697 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 257 finished
----------------------------------  -----------------
replay_buffer/size                  518000
trainer/num train calls             258000
trainer/QF1 Loss                        16.1891
trainer/QF2 Loss                        18.2352
trainer/Policy Loss                     60.1508
trainer/Q1 Predictions Mean            -59.7334
trainer/Q1 Predictions Std              82.4042
trainer/Q1 Predictions Max              44.3897
trainer/Q1 Predictions Min            -232.989
trainer/Q2 Predictions Mean            -59.7423
trainer/Q2 Predictions Std              82.5122
trainer/Q2 Predictions Max              44.2748
trainer/Q2 Predictions Min            -232.158
trainer/Q Targets Mean                 -60.3916
trainer/Q Targets Std                   83.2652
trainer/Q Targets Max                   43.6765
trainer/Q Targets Min                 -234.882
trainer/Log Pis Mean                     1.86105
trainer/Log Pis Std                      1.81643
trainer/Log Pis Max                      6.6642
trainer/Log Pis Min                     -3.65501
trainer/policy/mean Mean                -0.516747
trainer/policy/mean Std                  0.66242
trainer/policy/mean Max                  0.963156
trainer/policy/mean Min                 -0.98958
trainer/policy/normal/std Mean           0.587377
trainer/policy/normal/std Std            0.108033
trainer/policy/normal/std Max            0.980094
trainer/policy/normal/std Min            0.245646
trainer/policy/normal/log_std Mean      -0.548846
trainer/policy/normal/log_std Std        0.184541
trainer/policy/normal/log_std Max       -0.0201069
trainer/policy/normal/log_std Min       -1.40386
trainer/Alpha                            0.0289221
trainer/Alpha Loss                      -0.492314
exploration/num steps total         518000
exploration/num paths total           2590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.894617
exploration/Rewards Std                  1.48074
exploration/Rewards Max                 -1.06246e-107
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -178.923
exploration/Returns Std                147.219
exploration/Returns Max                -15.4139
exploration/Returns Min               -450.768
exploration/Actions Mean                -0.565184
exploration/Actions Std                  0.648919
exploration/Actions Max                  0.999455
exploration/Actions Min                 -0.999104
exploration/Num Paths                   10
exploration/Average Returns           -178.923
evaluation/num steps total               1.24459e+06
evaluation/num paths total            6192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.8056
evaluation/Actions Std                   0.187897
evaluation/Actions Max                  -0.296115
evaluation/Actions Min                  -0.974289
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0207042
time/evaluation sampling (s)            12.7738
time/exploration sampling (s)            4.94491
time/logging (s)                         0.0477735
time/sac training (s)                   35.2043
time/saving (s)                          0.124406
time/training (s)                        0.00027331
time/epoch (s)                          53.1161
time/total (s)                       35868.4
Epoch                                  257
----------------------------------  -----------------
2020-11-10 01:07:19.986431 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 258 finished
----------------------------------  ----------------
replay_buffer/size                  520000
trainer/num train calls             259000
trainer/QF1 Loss                        74.9798
trainer/QF2 Loss                        75.4989
trainer/Policy Loss                     55.4089
trainer/Q1 Predictions Mean            -54.9591
trainer/Q1 Predictions Std              80.5349
trainer/Q1 Predictions Max              51.6743
trainer/Q1 Predictions Min            -235.778
trainer/Q2 Predictions Mean            -54.9932
trainer/Q2 Predictions Std              80.5125
trainer/Q2 Predictions Max              51.5146
trainer/Q2 Predictions Min            -230.273
trainer/Q Targets Mean                 -54.8379
trainer/Q Targets Std                   80.7906
trainer/Q Targets Max                   51.56
trainer/Q Targets Min                 -234.492
trainer/Log Pis Mean                     2.45642
trainer/Log Pis Std                      1.92821
trainer/Log Pis Max                      7.92956
trainer/Log Pis Min                     -3.54162
trainer/policy/mean Mean                -0.591769
trainer/policy/mean Std                  0.617236
trainer/policy/mean Max                  0.948388
trainer/policy/mean Min                 -0.993271
trainer/policy/normal/std Mean           0.583083
trainer/policy/normal/std Std            0.0954912
trainer/policy/normal/std Max            1.10591
trainer/policy/normal/std Min            0.234212
trainer/policy/normal/log_std Mean      -0.553171
trainer/policy/normal/log_std Std        0.169178
trainer/policy/normal/log_std Max        0.100666
trainer/policy/normal/log_std Min       -1.45153
trainer/Alpha                            0.0291214
trainer/Alpha Loss                       1.61402
exploration/num steps total         520000
exploration/num paths total           2600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.4931
exploration/Rewards Std                  1.54595
exploration/Rewards Max                 -3.50272e-78
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -298.62
exploration/Returns Std                138.767
exploration/Returns Max               -100.479
exploration/Returns Min               -539.429
exploration/Actions Mean                -0.633541
exploration/Actions Std                  0.566986
exploration/Actions Max                  0.997632
exploration/Actions Min                 -0.999361
exploration/Num Paths                   10
exploration/Average Returns           -298.62
evaluation/num steps total               1.24942e+06
evaluation/num paths total            6216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.70699
evaluation/Rewards Std                   1.30924
evaluation/Rewards Max                  -6.62183e-11
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1147.11
evaluation/Returns Std                 262.624
evaluation/Returns Max                 -10.1007
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.891343
evaluation/Actions Std                   0.260578
evaluation/Actions Max                   0.811119
evaluation/Actions Min                  -0.975139
evaluation/Num Paths                    24
evaluation/Average Returns           -1147.11
time/data storing (s)                    0.0202206
time/evaluation sampling (s)            12.9441
time/exploration sampling (s)            5.09056
time/logging (s)                         0.0441509
time/sac training (s)                   36.6381
time/saving (s)                          0.120852
time/training (s)                        0.000151837
time/epoch (s)                          54.8581
time/total (s)                       36002.4
Epoch                                  258
----------------------------------  ----------------
2020-11-10 01:09:36.316169 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 259 finished
----------------------------------  ----------------
replay_buffer/size                  522000
trainer/num train calls             260000
trainer/QF1 Loss                        51.91
trainer/QF2 Loss                        51.8359
trainer/Policy Loss                     66.4696
trainer/Q1 Predictions Mean            -65.933
trainer/Q1 Predictions Std              86.636
trainer/Q1 Predictions Max              37.4484
trainer/Q1 Predictions Min            -236.335
trainer/Q2 Predictions Mean            -65.9417
trainer/Q2 Predictions Std              86.6675
trainer/Q2 Predictions Max              35.1856
trainer/Q2 Predictions Min            -236.883
trainer/Q Targets Mean                 -66.596
trainer/Q Targets Std                   87.4352
trainer/Q Targets Max                   33.839
trainer/Q Targets Min                 -235.827
trainer/Log Pis Mean                     1.87182
trainer/Log Pis Std                      1.61921
trainer/Log Pis Max                      5.80094
trainer/Log Pis Min                     -3.79741
trainer/policy/mean Mean                -0.492457
trainer/policy/mean Std                  0.666072
trainer/policy/mean Max                  0.959846
trainer/policy/mean Min                 -0.986973
trainer/policy/normal/std Mean           0.563968
trainer/policy/normal/std Std            0.0948405
trainer/policy/normal/std Max            1.02633
trainer/policy/normal/std Min            0.2599
trainer/policy/normal/log_std Mean      -0.586627
trainer/policy/normal/log_std Std        0.167136
trainer/policy/normal/log_std Max        0.0259887
trainer/policy/normal/log_std Min       -1.34746
trainer/Alpha                            0.0285222
trainer/Alpha Loss                      -0.455939
exploration/num steps total         522000
exploration/num paths total           2610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0103
exploration/Rewards Std                  1.52726
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -202.06
exploration/Returns Std                102.886
exploration/Returns Max                -75.2781
exploration/Returns Min               -394.188
exploration/Actions Mean                -0.514155
exploration/Actions Std                  0.642973
exploration/Actions Max                  0.993881
exploration/Actions Min                 -0.999107
exploration/Num Paths                   10
exploration/Average Returns           -202.06
evaluation/num steps total               1.25424e+06
evaluation/num paths total            6240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.762065
evaluation/Actions Std                   0.275361
evaluation/Actions Max                   0.287914
evaluation/Actions Min                  -0.974996
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.02038
time/evaluation sampling (s)            15.4984
time/exploration sampling (s)            5.38472
time/logging (s)                         0.0623533
time/sac training (s)                   35.3344
time/saving (s)                          0.329746
time/training (s)                        0.000145474
time/epoch (s)                          56.6302
time/total (s)                       36138.7
Epoch                                  259
----------------------------------  ----------------
2020-11-10 01:12:01.373042 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 260 finished
----------------------------------  ----------------
replay_buffer/size                  524000
trainer/num train calls             261000
trainer/QF1 Loss                        86.5919
trainer/QF2 Loss                       100.09
trainer/Policy Loss                     77.4599
trainer/Q1 Predictions Mean            -76.7794
trainer/Q1 Predictions Std              89.0995
trainer/Q1 Predictions Max              52.4621
trainer/Q1 Predictions Min            -240.547
trainer/Q2 Predictions Mean            -77.0203
trainer/Q2 Predictions Std              89.1903
trainer/Q2 Predictions Max              52.4407
trainer/Q2 Predictions Min            -241.333
trainer/Q Targets Mean                 -77.1131
trainer/Q Targets Std                   90.4415
trainer/Q Targets Max                   52.3371
trainer/Q Targets Min                 -240.307
trainer/Log Pis Mean                     1.89332
trainer/Log Pis Std                      1.9589
trainer/Log Pis Max                      7.04991
trainer/Log Pis Min                     -5.24529
trainer/policy/mean Mean                -0.591447
trainer/policy/mean Std                  0.601283
trainer/policy/mean Max                  0.943519
trainer/policy/mean Min                 -0.987994
trainer/policy/normal/std Mean           0.595453
trainer/policy/normal/std Std            0.106327
trainer/policy/normal/std Max            1.05374
trainer/policy/normal/std Min            0.242305
trainer/policy/normal/log_std Mean      -0.534445
trainer/policy/normal/log_std Std        0.180911
trainer/policy/normal/log_std Max        0.0523496
trainer/policy/normal/log_std Min       -1.41756
trainer/Alpha                            0.0282837
trainer/Alpha Loss                      -0.38035
exploration/num steps total         524000
exploration/num paths total           2620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0213
exploration/Rewards Std                  1.66018
exploration/Rewards Max                 -3.07497e-33
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -204.259
exploration/Returns Std                139.907
exploration/Returns Max                -50.1076
exploration/Returns Min               -484.683
exploration/Actions Mean                -0.578986
exploration/Actions Std                  0.653564
exploration/Actions Max                  0.991353
exploration/Actions Min                 -0.999327
exploration/Num Paths                   10
exploration/Average Returns           -204.259
evaluation/num steps total               1.25906e+06
evaluation/num paths total            6264
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   4.64125e-14
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.735745
evaluation/Actions Std                   0.233863
evaluation/Actions Max                  -0.498857
evaluation/Actions Min                  -0.973261
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0208419
time/evaluation sampling (s)            13.6117
time/exploration sampling (s)            5.13396
time/logging (s)                         0.0513195
time/sac training (s)                   38.9068
time/saving (s)                          0.106431
time/training (s)                        0.000159813
time/epoch (s)                          57.8313
time/total (s)                       36283.7
Epoch                                  260
----------------------------------  ----------------
2020-11-10 01:14:34.430848 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 261 finished
----------------------------------  -----------------
replay_buffer/size                  526000
trainer/num train calls             262000
trainer/QF1 Loss                       182.142
trainer/QF2 Loss                       169.087
trainer/Policy Loss                     57.8376
trainer/Q1 Predictions Mean            -57.3684
trainer/Q1 Predictions Std              81.5404
trainer/Q1 Predictions Max              35.8799
trainer/Q1 Predictions Min            -226.67
trainer/Q2 Predictions Mean            -57.4761
trainer/Q2 Predictions Std              81.5306
trainer/Q2 Predictions Max              35.4667
trainer/Q2 Predictions Min            -225.463
trainer/Q Targets Mean                 -57.0578
trainer/Q Targets Std                   81.7436
trainer/Q Targets Max                   34.7371
trainer/Q Targets Min                 -230.65
trainer/Log Pis Mean                     1.8646
trainer/Log Pis Std                      1.71957
trainer/Log Pis Max                      5.82178
trainer/Log Pis Min                     -4.12847
trainer/policy/mean Mean                -0.424501
trainer/policy/mean Std                  0.709203
trainer/policy/mean Max                  0.96967
trainer/policy/mean Min                 -0.986585
trainer/policy/normal/std Mean           0.581616
trainer/policy/normal/std Std            0.0885948
trainer/policy/normal/std Max            0.91616
trainer/policy/normal/std Min            0.269402
trainer/policy/normal/log_std Mean      -0.553376
trainer/policy/normal/log_std Std        0.151837
trainer/policy/normal/log_std Max       -0.0875648
trainer/policy/normal/log_std Min       -1.31155
trainer/Alpha                            0.0284382
trainer/Alpha Loss                      -0.482044
exploration/num steps total         526000
exploration/num paths total           2630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.02109
exploration/Rewards Std                  1.4948
exploration/Rewards Max                 -4.08999e-247
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -204.219
exploration/Returns Std                163.388
exploration/Returns Max                -47.0849
exploration/Returns Min               -534.619
exploration/Actions Mean                -0.315175
exploration/Actions Std                  0.775209
exploration/Actions Max                  0.997948
exploration/Actions Min                 -0.999196
exploration/Num Paths                   10
exploration/Average Returns           -204.219
evaluation/num steps total               1.26389e+06
evaluation/num paths total            6288
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.95757
evaluation/Rewards Std                   1.54402
evaluation/Rewards Max                  -4.21942e-25
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -996.472
evaluation/Returns Std                 307.917
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.560839
evaluation/Actions Std                   0.461639
evaluation/Actions Max                   0.610905
evaluation/Actions Min                  -0.976044
evaluation/Num Paths                    24
evaluation/Average Returns            -996.472
time/data storing (s)                    0.0228881
time/evaluation sampling (s)            12.8721
time/exploration sampling (s)            5.22101
time/logging (s)                         0.078541
time/sac training (s)                   36.0326
time/saving (s)                          0.140899
time/training (s)                        0.000154904
time/epoch (s)                          54.3682
time/total (s)                       36436.7
Epoch                                  261
----------------------------------  -----------------
2020-11-10 01:16:50.380608 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 262 finished
----------------------------------  ----------------
replay_buffer/size                  528000
trainer/num train calls             263000
trainer/QF1 Loss                        20.1336
trainer/QF2 Loss                        21.8609
trainer/Policy Loss                     67.0674
trainer/Q1 Predictions Mean            -66.6602
trainer/Q1 Predictions Std              87.0998
trainer/Q1 Predictions Max              54.3046
trainer/Q1 Predictions Min            -254.101
trainer/Q2 Predictions Mean            -66.6255
trainer/Q2 Predictions Std              87.1174
trainer/Q2 Predictions Max              54.329
trainer/Q2 Predictions Min            -253.742
trainer/Q Targets Mean                 -67.438
trainer/Q Targets Std                   87.8882
trainer/Q Targets Max                   53.5791
trainer/Q Targets Min                 -253.158
trainer/Log Pis Mean                     1.97594
trainer/Log Pis Std                      1.66716
trainer/Log Pis Max                      5.88548
trainer/Log Pis Min                     -3.70089
trainer/policy/mean Mean                -0.431868
trainer/policy/mean Std                  0.720304
trainer/policy/mean Max                  0.969364
trainer/policy/mean Min                 -0.98538
trainer/policy/normal/std Mean           0.586135
trainer/policy/normal/std Std            0.0962485
trainer/policy/normal/std Max            0.894551
trainer/policy/normal/std Min            0.267102
trainer/policy/normal/log_std Mean      -0.547475
trainer/policy/normal/log_std Std        0.163341
trainer/policy/normal/log_std Max       -0.111433
trainer/policy/normal/log_std Min       -1.32012
trainer/Alpha                            0.0281698
trainer/Alpha Loss                      -0.0858915
exploration/num steps total         528000
exploration/num paths total           2640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.11118
exploration/Rewards Std                  1.57764
exploration/Rewards Max                 -3.01193e-92
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -222.235
exploration/Returns Std                126.375
exploration/Returns Max                -79.1348
exploration/Returns Min               -436.835
exploration/Actions Mean                -0.393045
exploration/Actions Std                  0.740631
exploration/Actions Max                  0.997954
exploration/Actions Min                 -0.99946
exploration/Num Paths                   10
exploration/Average Returns           -222.235
evaluation/num steps total               1.26871e+06
evaluation/num paths total            6312
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   6.92812e-10
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   9.61621e-09
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.723924
evaluation/Actions Std                   0.251106
evaluation/Actions Max                  -0.472593
evaluation/Actions Min                  -0.97502
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0200465
time/evaluation sampling (s)            15.0243
time/exploration sampling (s)            5.3794
time/logging (s)                         0.0465103
time/sac training (s)                   35.334
time/saving (s)                          0.146245
time/training (s)                        0.000152317
time/epoch (s)                          55.9507
time/total (s)                       36572.6
Epoch                                  262
----------------------------------  ----------------
2020-11-10 01:19:04.552554 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 263 finished
----------------------------------  ----------------
replay_buffer/size                  530000
trainer/num train calls             264000
trainer/QF1 Loss                        27.8162
trainer/QF2 Loss                        24.9054
trainer/Policy Loss                     62.2868
trainer/Q1 Predictions Mean            -61.8578
trainer/Q1 Predictions Std              86.8788
trainer/Q1 Predictions Max             102.648
trainer/Q1 Predictions Min            -253.838
trainer/Q2 Predictions Mean            -62.0024
trainer/Q2 Predictions Std              86.9518
trainer/Q2 Predictions Max             103.147
trainer/Q2 Predictions Min            -254.878
trainer/Q Targets Mean                 -62.555
trainer/Q Targets Std                   87.7037
trainer/Q Targets Max                  102.237
trainer/Q Targets Min                 -253.892
trainer/Log Pis Mean                     2.13169
trainer/Log Pis Std                      1.88132
trainer/Log Pis Max                      7.2986
trainer/Log Pis Min                     -5.21069
trainer/policy/mean Mean                -0.530115
trainer/policy/mean Std                  0.654078
trainer/policy/mean Max                  0.954789
trainer/policy/mean Min                 -0.992154
trainer/policy/normal/std Mean           0.590508
trainer/policy/normal/std Std            0.0976485
trainer/policy/normal/std Max            0.875866
trainer/policy/normal/std Min            0.253439
trainer/policy/normal/log_std Mean      -0.540149
trainer/policy/normal/log_std Std        0.163776
trainer/policy/normal/log_std Max       -0.132542
trainer/policy/normal/log_std Min       -1.37263
trainer/Alpha                            0.028386
trainer/Alpha Loss                       0.469054
exploration/num steps total         530000
exploration/num paths total           2650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.84753
exploration/Rewards Std                  1.46617
exploration/Rewards Max                 -5.09256e-98
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -169.506
exploration/Returns Std                136.17
exploration/Returns Max                -42.4142
exploration/Returns Min               -392.908
exploration/Actions Mean                -0.573871
exploration/Actions Std                  0.624193
exploration/Actions Max                  0.998382
exploration/Actions Min                 -0.999843
exploration/Num Paths                   10
exploration/Average Returns           -169.506
evaluation/num steps total               1.27354e+06
evaluation/num paths total            6336
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.90924e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   2.78475e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.801108
evaluation/Actions Std                   0.174083
evaluation/Actions Max                  -0.626915
evaluation/Actions Min                  -0.975692
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0249508
time/evaluation sampling (s)            13.31
time/exploration sampling (s)            6.54474
time/logging (s)                         0.0445336
time/sac training (s)                   35.1065
time/saving (s)                          0.118584
time/training (s)                        0.000151865
time/epoch (s)                          55.1495
time/total (s)                       36706.8
Epoch                                  263
----------------------------------  ----------------
2020-11-10 01:21:11.647237 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 264 finished
----------------------------------  -----------------
replay_buffer/size                  532000
trainer/num train calls             265000
trainer/QF1 Loss                         6.61903
trainer/QF2 Loss                         5.91462
trainer/Policy Loss                     64.1417
trainer/Q1 Predictions Mean            -63.6687
trainer/Q1 Predictions Std              82.0379
trainer/Q1 Predictions Max              53.9449
trainer/Q1 Predictions Min            -232.915
trainer/Q2 Predictions Mean            -63.7188
trainer/Q2 Predictions Std              82.0595
trainer/Q2 Predictions Max              54.2457
trainer/Q2 Predictions Min            -232.458
trainer/Q Targets Mean                 -64.5216
trainer/Q Targets Std                   83.1188
trainer/Q Targets Max                   53.8059
trainer/Q Targets Min                 -234.721
trainer/Log Pis Mean                     1.74847
trainer/Log Pis Std                      1.63717
trainer/Log Pis Max                      5.11477
trainer/Log Pis Min                     -4.83083
trainer/policy/mean Mean                -0.462537
trainer/policy/mean Std                  0.690738
trainer/policy/mean Max                  0.957719
trainer/policy/mean Min                 -0.981158
trainer/policy/normal/std Mean           0.576035
trainer/policy/normal/std Std            0.0947492
trainer/policy/normal/std Max            0.99279
trainer/policy/normal/std Min            0.241049
trainer/policy/normal/log_std Mean      -0.566155
trainer/policy/normal/log_std Std        0.176187
trainer/policy/normal/log_std Max       -0.00723649
trainer/policy/normal/log_std Min       -1.42275
trainer/Alpha                            0.0287646
trainer/Alpha Loss                      -0.892594
exploration/num steps total         532000
exploration/num paths total           2660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.6361
exploration/Rewards Std                  1.33768
exploration/Rewards Max                 -7.73411e-152
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -127.22
exploration/Returns Std                124.552
exploration/Returns Max                 -9.64863
exploration/Returns Min               -442.83
exploration/Actions Mean                -0.416956
exploration/Actions Std                  0.712734
exploration/Actions Max                  0.996546
exploration/Actions Min                 -0.999214
exploration/Num Paths                   10
exploration/Average Returns           -127.22
evaluation/num steps total               1.27836e+06
evaluation/num paths total            6360
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95644
evaluation/Rewards Std                   0.570254
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.24
evaluation/Returns Std                 114.618
evaluation/Returns Max                -647.554
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.721106
evaluation/Actions Std                   0.246743
evaluation/Actions Max                  -0.157855
evaluation/Actions Min                  -0.969095
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.24
time/data storing (s)                    0.0237555
time/evaluation sampling (s)            17.213
time/exploration sampling (s)            6.47036
time/logging (s)                         0.0386493
time/sac training (s)                   33.0517
time/saving (s)                          0.0577575
time/training (s)                        0.000202296
time/epoch (s)                          56.8553
time/total (s)                       36833.8
Epoch                                  264
----------------------------------  -----------------
2020-11-10 01:23:12.871572 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 265 finished
----------------------------------  ----------------
replay_buffer/size                  534000
trainer/num train calls             266000
trainer/QF1 Loss                        97.3137
trainer/QF2 Loss                        96.7354
trainer/Policy Loss                     64.992
trainer/Q1 Predictions Mean            -64.574
trainer/Q1 Predictions Std              85.0881
trainer/Q1 Predictions Max              82.6257
trainer/Q1 Predictions Min            -253.144
trainer/Q2 Predictions Mean            -64.6658
trainer/Q2 Predictions Std              85.2119
trainer/Q2 Predictions Max              82.8719
trainer/Q2 Predictions Min            -252.984
trainer/Q Targets Mean                 -64.3476
trainer/Q Targets Std                   85.8371
trainer/Q Targets Max                   82.6256
trainer/Q Targets Min                 -252.036
trainer/Log Pis Mean                     1.87994
trainer/Log Pis Std                      1.77276
trainer/Log Pis Max                      6.73657
trainer/Log Pis Min                     -4.99175
trainer/policy/mean Mean                -0.510286
trainer/policy/mean Std                  0.648372
trainer/policy/mean Max                  0.963116
trainer/policy/mean Min                 -0.990999
trainer/policy/normal/std Mean           0.575245
trainer/policy/normal/std Std            0.0905087
trainer/policy/normal/std Max            0.825391
trainer/policy/normal/std Min            0.232067
trainer/policy/normal/log_std Mean      -0.565372
trainer/policy/normal/log_std Std        0.158845
trainer/policy/normal/log_std Max       -0.191898
trainer/policy/normal/log_std Min       -1.46073
trainer/Alpha                            0.0279764
trainer/Alpha Loss                      -0.429369
exploration/num steps total         534000
exploration/num paths total           2670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.650599
exploration/Rewards Std                  1.35935
exploration/Rewards Max                 -7.8799e-304
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -130.12
exploration/Returns Std                 88.5725
exploration/Returns Max                -32.3278
exploration/Returns Min               -362.122
exploration/Actions Mean                -0.40759
exploration/Actions Std                  0.717023
exploration/Actions Max                  0.996102
exploration/Actions Min                 -0.999151
exploration/Num Paths                   10
exploration/Average Returns           -130.12
evaluation/num steps total               1.28318e+06
evaluation/num paths total            6384
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.772012
evaluation/Actions Std                   0.225185
evaluation/Actions Max                   0.215542
evaluation/Actions Min                  -0.97176
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.021776
time/evaluation sampling (s)            13.4028
time/exploration sampling (s)            5.79381
time/logging (s)                         0.0477295
time/sac training (s)                   34.5769
time/saving (s)                          0.114481
time/training (s)                        0.000141662
time/epoch (s)                          53.9576
time/total (s)                       36955
Epoch                                  265
----------------------------------  ----------------
2020-11-10 01:25:06.398164 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 266 finished
----------------------------------  ----------------
replay_buffer/size                  536000
trainer/num train calls             267000
trainer/QF1 Loss                         7.69477
trainer/QF2 Loss                         7.41422
trainer/Policy Loss                     56.8175
trainer/Q1 Predictions Mean            -56.3563
trainer/Q1 Predictions Std              81.4623
trainer/Q1 Predictions Max              53.6449
trainer/Q1 Predictions Min            -231.292
trainer/Q2 Predictions Mean            -56.4129
trainer/Q2 Predictions Std              81.707
trainer/Q2 Predictions Max              53.7396
trainer/Q2 Predictions Min            -232.654
trainer/Q Targets Mean                 -57.2364
trainer/Q Targets Std                   82.5881
trainer/Q Targets Max                   53.6794
trainer/Q Targets Min                 -234.529
trainer/Log Pis Mean                     2.07753
trainer/Log Pis Std                      1.72628
trainer/Log Pis Max                      6.60714
trainer/Log Pis Min                     -6.62416
trainer/policy/mean Mean                -0.406399
trainer/policy/mean Std                  0.737025
trainer/policy/mean Max                  0.974098
trainer/policy/mean Min                 -0.988339
trainer/policy/normal/std Mean           0.559034
trainer/policy/normal/std Std            0.0835824
trainer/policy/normal/std Max            0.912782
trainer/policy/normal/std Min            0.252138
trainer/policy/normal/log_std Mean      -0.593037
trainer/policy/normal/log_std Std        0.154305
trainer/policy/normal/log_std Max       -0.0912584
trainer/policy/normal/log_std Min       -1.37778
trainer/Alpha                            0.0280453
trainer/Alpha Loss                       0.277089
exploration/num steps total         536000
exploration/num paths total           2680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.93
exploration/Rewards Std                  1.45953
exploration/Rewards Max                 -2.33117e-80
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -186
exploration/Returns Std                120.653
exploration/Returns Max                -30.3544
exploration/Returns Min               -397.25
exploration/Actions Mean                -0.402937
exploration/Actions Std                  0.705691
exploration/Actions Max                  0.995419
exploration/Actions Min                 -0.999492
exploration/Num Paths                   10
exploration/Average Returns           -186
evaluation/num steps total               1.28801e+06
evaluation/num paths total            6408
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8928
evaluation/Rewards Std                   0.547742
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1184.45
evaluation/Returns Std                 109.791
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.588857
evaluation/Actions Std                   0.40348
evaluation/Actions Max                   0.581123
evaluation/Actions Min                  -0.976383
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.45
time/data storing (s)                    0.023637
time/evaluation sampling (s)            13.6504
time/exploration sampling (s)            5.33545
time/logging (s)                         0.0392714
time/sac training (s)                   32.4274
time/saving (s)                          0.0699031
time/training (s)                        0.000159342
time/epoch (s)                          51.5463
time/total (s)                       37068.5
Epoch                                  266
----------------------------------  ----------------
2020-11-10 01:26:59.355164 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 267 finished
----------------------------------  -----------------
replay_buffer/size                  538000
trainer/num train calls             268000
trainer/QF1 Loss                       113.719
trainer/QF2 Loss                       112.335
trainer/Policy Loss                     66.6168
trainer/Q1 Predictions Mean            -66.2283
trainer/Q1 Predictions Std              84.0811
trainer/Q1 Predictions Max              40.4152
trainer/Q1 Predictions Min            -252.521
trainer/Q2 Predictions Mean            -66.0936
trainer/Q2 Predictions Std              83.943
trainer/Q2 Predictions Max              39.8796
trainer/Q2 Predictions Min            -253.914
trainer/Q Targets Mean                 -66.1097
trainer/Q Targets Std                   85.1225
trainer/Q Targets Max                   39.9053
trainer/Q Targets Min                 -252.688
trainer/Log Pis Mean                     2.18104
trainer/Log Pis Std                      1.81804
trainer/Log Pis Max                      5.77622
trainer/Log Pis Min                     -7.58749
trainer/policy/mean Mean                -0.351701
trainer/policy/mean Std                  0.762029
trainer/policy/mean Max                  0.980117
trainer/policy/mean Min                 -0.986163
trainer/policy/normal/std Mean           0.561265
trainer/policy/normal/std Std            0.0802232
trainer/policy/normal/std Max            0.912175
trainer/policy/normal/std Min            0.262814
trainer/policy/normal/log_std Mean      -0.587623
trainer/policy/normal/log_std Std        0.142367
trainer/policy/normal/log_std Max       -0.0919233
trainer/policy/normal/log_std Min       -1.33631
trainer/Alpha                            0.0282774
trainer/Alpha Loss                       0.645541
exploration/num steps total         538000
exploration/num paths total           2690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.89296
exploration/Rewards Std                  1.57798
exploration/Rewards Max                 -1.32736e-119
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -378.592
exploration/Returns Std                162.991
exploration/Returns Max                -23.0516
exploration/Returns Min               -561.164
exploration/Actions Mean                -0.26678
exploration/Actions Std                  0.82477
exploration/Actions Max                  0.998508
exploration/Actions Min                 -0.999449
exploration/Num Paths                   10
exploration/Average Returns           -378.592
evaluation/num steps total               1.29283e+06
evaluation/num paths total            6432
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44731
evaluation/Rewards Std                   1.09342
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1094.91
evaluation/Returns Std                 219.188
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.408703
evaluation/Actions Std                   0.565889
evaluation/Actions Max                   0.797247
evaluation/Actions Min                  -0.979479
evaluation/Num Paths                    24
evaluation/Average Returns           -1094.91
time/data storing (s)                    0.022216
time/evaluation sampling (s)            15.1498
time/exploration sampling (s)            5.72318
time/logging (s)                         0.036662
time/sac training (s)                   31.3747
time/saving (s)                          0.151952
time/training (s)                        0.000122151
time/epoch (s)                          52.4587
time/total (s)                       37181.4
Epoch                                  267
----------------------------------  -----------------
2020-11-10 01:28:43.492676 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 268 finished
----------------------------------  ----------------
replay_buffer/size                  540000
trainer/num train calls             269000
trainer/QF1 Loss                       229.343
trainer/QF2 Loss                       226.107
trainer/Policy Loss                     59.1571
trainer/Q1 Predictions Mean            -58.7013
trainer/Q1 Predictions Std              81.3753
trainer/Q1 Predictions Max              29.2537
trainer/Q1 Predictions Min            -237.292
trainer/Q2 Predictions Mean            -58.6287
trainer/Q2 Predictions Std              81.1546
trainer/Q2 Predictions Max              28.8848
trainer/Q2 Predictions Min            -239.432
trainer/Q Targets Mean                 -57.7682
trainer/Q Targets Std                   81.976
trainer/Q Targets Max                   29.2503
trainer/Q Targets Min                 -239.773
trainer/Log Pis Mean                     1.79568
trainer/Log Pis Std                      1.68787
trainer/Log Pis Max                      6.20195
trainer/Log Pis Min                     -4.36625
trainer/policy/mean Mean                -0.394942
trainer/policy/mean Std                  0.73634
trainer/policy/mean Max                  0.964081
trainer/policy/mean Min                 -0.984727
trainer/policy/normal/std Mean           0.573648
trainer/policy/normal/std Std            0.0887412
trainer/policy/normal/std Max            0.892982
trainer/policy/normal/std Min            0.239548
trainer/policy/normal/log_std Mean      -0.567644
trainer/policy/normal/log_std Std        0.155314
trainer/policy/normal/log_std Max       -0.113188
trainer/policy/normal/log_std Min       -1.429
trainer/Alpha                            0.0276303
trainer/Alpha Loss                      -0.733283
exploration/num steps total         540000
exploration/num paths total           2700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.699981
exploration/Rewards Std                  1.41295
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -139.996
exploration/Returns Std                 93.1662
exploration/Returns Max                -18.4953
exploration/Returns Min               -363.557
exploration/Actions Mean                -0.528207
exploration/Actions Std                  0.641482
exploration/Actions Max                  0.994791
exploration/Actions Min                 -0.99927
exploration/Num Paths                   10
exploration/Average Returns           -139.996
evaluation/num steps total               1.29766e+06
evaluation/num paths total            6456
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.43246
evaluation/Rewards Std                   0.970162
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1091.92
evaluation/Returns Std                 193.485
evaluation/Returns Max                -655.47
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.530757
evaluation/Actions Std                   0.474709
evaluation/Actions Max                   0.656777
evaluation/Actions Min                  -0.970101
evaluation/Num Paths                    24
evaluation/Average Returns           -1091.92
time/data storing (s)                    0.0206294
time/evaluation sampling (s)            12.4684
time/exploration sampling (s)            4.90861
time/logging (s)                         0.0828544
time/sac training (s)                   34.1436
time/saving (s)                          0.0628337
time/training (s)                        0.000166339
time/epoch (s)                          51.6871
time/total (s)                       37285.6
Epoch                                  268
----------------------------------  ----------------
2020-11-10 01:30:43.200031 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 269 finished
----------------------------------  ----------------
replay_buffer/size                  542000
trainer/num train calls             270000
trainer/QF1 Loss                        30.4683
trainer/QF2 Loss                        26.1221
trainer/Policy Loss                     72.8952
trainer/Q1 Predictions Mean            -72.4605
trainer/Q1 Predictions Std              87.102
trainer/Q1 Predictions Max              39.2493
trainer/Q1 Predictions Min            -256.699
trainer/Q2 Predictions Mean            -72.3481
trainer/Q2 Predictions Std              87.0644
trainer/Q2 Predictions Max              38.8636
trainer/Q2 Predictions Min            -256.649
trainer/Q Targets Mean                 -72.889
trainer/Q Targets Std                   87.6736
trainer/Q Targets Max                   38.3821
trainer/Q Targets Min                 -255.633
trainer/Log Pis Mean                     2.08844
trainer/Log Pis Std                      1.54468
trainer/Log Pis Max                      5.54046
trainer/Log Pis Min                     -2.63666
trainer/policy/mean Mean                -0.460961
trainer/policy/mean Std                  0.697374
trainer/policy/mean Max                  0.9528
trainer/policy/mean Min                 -0.985637
trainer/policy/normal/std Mean           0.585878
trainer/policy/normal/std Std            0.101923
trainer/policy/normal/std Max            0.954767
trainer/policy/normal/std Min            0.25038
trainer/policy/normal/log_std Mean      -0.549103
trainer/policy/normal/log_std Std        0.16924
trainer/policy/normal/log_std Max       -0.0462881
trainer/policy/normal/log_std Min       -1.38478
trainer/Alpha                            0.0272066
trainer/Alpha Loss                       0.318777
exploration/num steps total         542000
exploration/num paths total           2710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.33869
exploration/Rewards Std                  1.59851
exploration/Rewards Max                 -3.6324e-164
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -267.738
exploration/Returns Std                139.558
exploration/Returns Max                -63.6615
exploration/Returns Min               -444.661
exploration/Actions Mean                -0.357148
exploration/Actions Std                  0.76968
exploration/Actions Max                  0.999202
exploration/Actions Min                 -0.999271
exploration/Num Paths                   10
exploration/Average Returns           -267.738
evaluation/num steps total               1.30248e+06
evaluation/num paths total            6480
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.573879
evaluation/Actions Std                   0.413299
evaluation/Actions Max                   0.592469
evaluation/Actions Min                  -0.972009
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0324084
time/evaluation sampling (s)            13.5135
time/exploration sampling (s)            7.66541
time/logging (s)                         0.038001
time/sac training (s)                   36.524
time/saving (s)                          0.0687983
time/training (s)                        0.000129415
time/epoch (s)                          57.8423
time/total (s)                       37405.2
Epoch                                  269
----------------------------------  ----------------
2020-11-10 01:32:52.818091 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 270 finished
----------------------------------  -----------------
replay_buffer/size                  544000
trainer/num train calls             271000
trainer/QF1 Loss                        73.3783
trainer/QF2 Loss                        72.2822
trainer/Policy Loss                     67.9559
trainer/Q1 Predictions Mean            -67.5395
trainer/Q1 Predictions Std              85.4341
trainer/Q1 Predictions Max              41.8331
trainer/Q1 Predictions Min            -231.109
trainer/Q2 Predictions Mean            -67.5572
trainer/Q2 Predictions Std              85.5667
trainer/Q2 Predictions Max              41.6797
trainer/Q2 Predictions Min            -229.327
trainer/Q Targets Mean                 -67.625
trainer/Q Targets Std                   86.5137
trainer/Q Targets Max                   41.8783
trainer/Q Targets Min                 -232.726
trainer/Log Pis Mean                     1.90727
trainer/Log Pis Std                      1.80803
trainer/Log Pis Max                      5.12337
trainer/Log Pis Min                     -6.00734
trainer/policy/mean Mean                -0.530545
trainer/policy/mean Std                  0.647458
trainer/policy/mean Max                  0.946012
trainer/policy/mean Min                 -0.987809
trainer/policy/normal/std Mean           0.586102
trainer/policy/normal/std Std            0.0975167
trainer/policy/normal/std Max            0.91916
trainer/policy/normal/std Min            0.251236
trainer/policy/normal/log_std Mean      -0.547948
trainer/policy/normal/log_std Std        0.166198
trainer/policy/normal/log_std Max       -0.084295
trainer/policy/normal/log_std Min       -1.38136
trainer/Alpha                            0.0274402
trainer/Alpha Loss                      -0.33343
exploration/num steps total         544000
exploration/num paths total           2720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.751013
exploration/Rewards Std                  1.38684
exploration/Rewards Max                 -8.50626e-288
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -150.203
exploration/Returns Std                 91.3949
exploration/Returns Max                -52.8532
exploration/Returns Min               -299.564
exploration/Actions Mean                -0.442607
exploration/Actions Std                  0.657054
exploration/Actions Max                  0.995389
exploration/Actions Min                 -0.998955
exploration/Num Paths                   10
exploration/Average Returns           -150.203
evaluation/num steps total               1.3073e+06
evaluation/num paths total            6504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.94275
evaluation/Rewards Std                   1.46378
evaluation/Rewards Max                  -3.39781e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -993.493
evaluation/Returns Std                 291.984
evaluation/Returns Max                 -21.3124
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.543729
evaluation/Actions Std                   0.539737
evaluation/Actions Max                   0.90415
evaluation/Actions Min                  -0.985151
evaluation/Num Paths                    24
evaluation/Average Returns            -993.493
time/data storing (s)                    0.021824
time/evaluation sampling (s)            13.6832
time/exploration sampling (s)            5.36971
time/logging (s)                         0.060373
time/sac training (s)                   37.6785
time/saving (s)                          0.449898
time/training (s)                        0.000166879
time/epoch (s)                          57.2636
time/total (s)                       37534.8
Epoch                                  270
----------------------------------  -----------------
2020-11-10 01:35:07.647007 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 271 finished
----------------------------------  -----------------
replay_buffer/size                  546000
trainer/num train calls             272000
trainer/QF1 Loss                       131.445
trainer/QF2 Loss                       133.564
trainer/Policy Loss                     74.0615
trainer/Q1 Predictions Mean            -73.4089
trainer/Q1 Predictions Std              87.5085
trainer/Q1 Predictions Max              37.3302
trainer/Q1 Predictions Min            -252.322
trainer/Q2 Predictions Mean            -73.5704
trainer/Q2 Predictions Std              87.578
trainer/Q2 Predictions Max              37.4666
trainer/Q2 Predictions Min            -253.678
trainer/Q Targets Mean                 -73.7043
trainer/Q Targets Std                   88.5698
trainer/Q Targets Max                   37.152
trainer/Q Targets Min                 -252.622
trainer/Log Pis Mean                     1.93563
trainer/Log Pis Std                      1.72158
trainer/Log Pis Max                      6.57316
trainer/Log Pis Min                     -4.20958
trainer/policy/mean Mean                -0.410522
trainer/policy/mean Std                  0.708227
trainer/policy/mean Max                  0.96668
trainer/policy/mean Min                 -0.986943
trainer/policy/normal/std Mean           0.585221
trainer/policy/normal/std Std            0.10197
trainer/policy/normal/std Max            0.918303
trainer/policy/normal/std Min            0.269664
trainer/policy/normal/log_std Mean      -0.550104
trainer/policy/normal/log_std Std        0.167524
trainer/policy/normal/log_std Max       -0.0852281
trainer/policy/normal/log_std Min       -1.31058
trainer/Alpha                            0.0269021
trainer/Alpha Loss                      -0.23274
exploration/num steps total         546000
exploration/num paths total           2730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.21521
exploration/Rewards Std                  1.63735
exploration/Rewards Max                 -2.19743e-191
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -243.042
exploration/Returns Std                183.188
exploration/Returns Max                -40.027
exploration/Returns Min               -603.88
exploration/Actions Mean                -0.249659
exploration/Actions Std                  0.789502
exploration/Actions Max                  0.998589
exploration/Actions Min                 -0.999699
exploration/Num Paths                   10
exploration/Average Returns           -243.042
evaluation/num steps total               1.31213e+06
evaluation/num paths total            6528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.23072
evaluation/Rewards Std                   1.10159
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1051.37
evaluation/Returns Std                 220.122
evaluation/Returns Max                -663.157
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.479902
evaluation/Actions Std                   0.568368
evaluation/Actions Max                   0.838597
evaluation/Actions Min                  -0.976983
evaluation/Num Paths                    24
evaluation/Average Returns           -1051.37
time/data storing (s)                    0.0196265
time/evaluation sampling (s)            15.2198
time/exploration sampling (s)            5.3413
time/logging (s)                         0.0701786
time/sac training (s)                   36.7958
time/saving (s)                          0.188796
time/training (s)                        0.000217063
time/epoch (s)                          57.6357
time/total (s)                       37669.6
Epoch                                  271
----------------------------------  -----------------
2020-11-10 01:37:17.589502 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 272 finished
----------------------------------  -----------------
replay_buffer/size                  548000
trainer/num train calls             273000
trainer/QF1 Loss                        53.4013
trainer/QF2 Loss                        57.0475
trainer/Policy Loss                     70.7889
trainer/Q1 Predictions Mean            -70.3303
trainer/Q1 Predictions Std              85.5454
trainer/Q1 Predictions Max              39.8929
trainer/Q1 Predictions Min            -250.724
trainer/Q2 Predictions Mean            -70.1383
trainer/Q2 Predictions Std              85.3168
trainer/Q2 Predictions Max              40.1502
trainer/Q2 Predictions Min            -249.635
trainer/Q Targets Mean                 -70.6562
trainer/Q Targets Std                   86.2889
trainer/Q Targets Max                   39.7124
trainer/Q Targets Min                 -250.702
trainer/Log Pis Mean                     2.03066
trainer/Log Pis Std                      1.84168
trainer/Log Pis Max                      6.79564
trainer/Log Pis Min                     -4.14632
trainer/policy/mean Mean                -0.377498
trainer/policy/mean Std                  0.74911
trainer/policy/mean Max                  0.98295
trainer/policy/mean Min                 -0.987174
trainer/policy/normal/std Mean           0.571226
trainer/policy/normal/std Std            0.0859779
trainer/policy/normal/std Max            0.821126
trainer/policy/normal/std Min            0.278536
trainer/policy/normal/log_std Mean      -0.571019
trainer/policy/normal/log_std Std        0.148499
trainer/policy/normal/log_std Max       -0.197079
trainer/policy/normal/log_std Min       -1.27821
trainer/Alpha                            0.0271153
trainer/Alpha Loss                       0.110616
exploration/num steps total         548000
exploration/num paths total           2740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.726288
exploration/Rewards Std                  1.39859
exploration/Rewards Max                 -4.67092e-289
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -145.258
exploration/Returns Std                116.463
exploration/Returns Max                -30.9675
exploration/Returns Min               -428.46
exploration/Actions Mean                -0.207908
exploration/Actions Std                  0.800164
exploration/Actions Max                  0.996361
exploration/Actions Min                 -0.999174
exploration/Num Paths                   10
exploration/Average Returns           -145.258
evaluation/num steps total               1.31695e+06
evaluation/num paths total            6552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6389
evaluation/Rewards Std                   1.30277
evaluation/Rewards Max                  -6.26042e-08
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1133.42
evaluation/Returns Std                 261.352
evaluation/Returns Max                  -6.76851
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.454201
evaluation/Actions Std                   0.538225
evaluation/Actions Max                   0.337646
evaluation/Actions Min                  -0.978053
evaluation/Num Paths                    24
evaluation/Average Returns           -1133.42
time/data storing (s)                    0.0193672
time/evaluation sampling (s)            14.2556
time/exploration sampling (s)            5.16616
time/logging (s)                         0.0644274
time/sac training (s)                   34.1052
time/saving (s)                          0.0766545
time/training (s)                        0.000158583
time/epoch (s)                          53.6876
time/total (s)                       37799.5
Epoch                                  272
----------------------------------  -----------------
2020-11-10 01:39:25.876739 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 273 finished
----------------------------------  -----------------
replay_buffer/size                  550000
trainer/num train calls             274000
trainer/QF1 Loss                       123.668
trainer/QF2 Loss                       123.688
trainer/Policy Loss                     61.0651
trainer/Q1 Predictions Mean            -60.6586
trainer/Q1 Predictions Std              85.0041
trainer/Q1 Predictions Max              30.1406
trainer/Q1 Predictions Min            -252.092
trainer/Q2 Predictions Mean            -60.6626
trainer/Q2 Predictions Std              84.8765
trainer/Q2 Predictions Max              32.1159
trainer/Q2 Predictions Min            -251.998
trainer/Q Targets Mean                 -60.9495
trainer/Q Targets Std                   85.5204
trainer/Q Targets Max                   31.2485
trainer/Q Targets Min                 -251.562
trainer/Log Pis Mean                     2.11108
trainer/Log Pis Std                      1.54634
trainer/Log Pis Max                      6.61396
trainer/Log Pis Min                     -3.74659
trainer/policy/mean Mean                -0.477539
trainer/policy/mean Std                  0.676876
trainer/policy/mean Max                  0.967466
trainer/policy/mean Min                 -0.987473
trainer/policy/normal/std Mean           0.569497
trainer/policy/normal/std Std            0.0986056
trainer/policy/normal/std Max            0.899831
trainer/policy/normal/std Min            0.282494
trainer/policy/normal/log_std Mean      -0.577216
trainer/policy/normal/log_std Std        0.167223
trainer/policy/normal/log_std Max       -0.105549
trainer/policy/normal/log_std Min       -1.2641
trainer/Alpha                            0.0267088
trainer/Alpha Loss                       0.402417
exploration/num steps total         550000
exploration/num paths total           2750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.1467
exploration/Rewards Std                  1.58098
exploration/Rewards Max                 -5.96112e-136
exploration/Rewards Min                 -6.12352
exploration/Returns Mean              -229.339
exploration/Returns Std                136.157
exploration/Returns Max                -32.1878
exploration/Returns Min               -508.071
exploration/Actions Mean                -0.531159
exploration/Actions Std                  0.647609
exploration/Actions Max                  0.997816
exploration/Actions Min                 -0.999581
exploration/Num Paths                   10
exploration/Average Returns           -229.339
evaluation/num steps total               1.32178e+06
evaluation/num paths total            6576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.2227
evaluation/Rewards Std                   1.11701
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1049.76
evaluation/Returns Std                 222.926
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.562598
evaluation/Actions Std                   0.419732
evaluation/Actions Max                   0.694564
evaluation/Actions Min                  -0.974649
evaluation/Num Paths                    24
evaluation/Average Returns           -1049.76
time/data storing (s)                    0.0235728
time/evaluation sampling (s)            16.9951
time/exploration sampling (s)            5.56025
time/logging (s)                         0.0459001
time/sac training (s)                   37.3248
time/saving (s)                          0.11021
time/training (s)                        0.000161667
time/epoch (s)                          60.06
time/total (s)                       37927.7
Epoch                                  273
----------------------------------  -----------------
2020-11-10 01:41:54.773024 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 274 finished
----------------------------------  -----------------
replay_buffer/size                  552000
trainer/num train calls             275000
trainer/QF1 Loss                        97.4481
trainer/QF2 Loss                        92.101
trainer/Policy Loss                     58.6644
trainer/Q1 Predictions Mean            -58.088
trainer/Q1 Predictions Std              82.871
trainer/Q1 Predictions Max              44.6544
trainer/Q1 Predictions Min            -241.135
trainer/Q2 Predictions Mean            -58.2549
trainer/Q2 Predictions Std              82.8865
trainer/Q2 Predictions Max              44.4224
trainer/Q2 Predictions Min            -236.981
trainer/Q Targets Mean                 -58.2794
trainer/Q Targets Std                   83.9385
trainer/Q Targets Max                   44.2397
trainer/Q Targets Min                 -241.142
trainer/Log Pis Mean                     2.25022
trainer/Log Pis Std                      1.99964
trainer/Log Pis Max                      7.09908
trainer/Log Pis Min                     -6.90459
trainer/policy/mean Mean                -0.596521
trainer/policy/mean Std                  0.599477
trainer/policy/mean Max                  0.976596
trainer/policy/mean Min                 -0.994705
trainer/policy/normal/std Mean           0.578843
trainer/policy/normal/std Std            0.0984714
trainer/policy/normal/std Max            0.937179
trainer/policy/normal/std Min            0.284
trainer/policy/normal/log_std Mean      -0.560469
trainer/policy/normal/log_std Std        0.164439
trainer/policy/normal/log_std Max       -0.0648814
trainer/policy/normal/log_std Min       -1.25878
trainer/Alpha                            0.0262631
trainer/Alpha Loss                       0.910698
exploration/num steps total         552000
exploration/num paths total           2760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.969912
exploration/Rewards Std                  1.44364
exploration/Rewards Max                 -9.67974e-310
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -193.982
exploration/Returns Std                 86.0615
exploration/Returns Max                -77.569
exploration/Returns Min               -345.989
exploration/Actions Mean                -0.672627
exploration/Actions Std                  0.553167
exploration/Actions Max                  0.998693
exploration/Actions Min                 -0.999482
exploration/Num Paths                   10
exploration/Average Returns           -193.982
evaluation/num steps total               1.3266e+06
evaluation/num paths total            6600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.5024
evaluation/Rewards Std                   0.974279
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1105.98
evaluation/Returns Std                 194.859
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.56578
evaluation/Actions Std                   0.457356
evaluation/Actions Max                   0.505525
evaluation/Actions Min                  -0.979548
evaluation/Num Paths                    24
evaluation/Average Returns           -1105.98
time/data storing (s)                    0.0214745
time/evaluation sampling (s)            15.7702
time/exploration sampling (s)            5.15856
time/logging (s)                         0.0649324
time/sac training (s)                   42.81
time/saving (s)                          0.150166
time/training (s)                        0.000176259
time/epoch (s)                          63.9755
time/total (s)                       38076.6
Epoch                                  274
----------------------------------  -----------------
2020-11-10 01:44:47.718451 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 275 finished
----------------------------------  -----------------
replay_buffer/size                  554000
trainer/num train calls             276000
trainer/QF1 Loss                       250.54
trainer/QF2 Loss                       256.864
trainer/Policy Loss                     57.3158
trainer/Q1 Predictions Mean            -56.912
trainer/Q1 Predictions Std              84.0702
trainer/Q1 Predictions Max             104.149
trainer/Q1 Predictions Min            -233.985
trainer/Q2 Predictions Mean            -56.8878
trainer/Q2 Predictions Std              84.1146
trainer/Q2 Predictions Max             104.136
trainer/Q2 Predictions Min            -240.591
trainer/Q Targets Mean                 -55.86
trainer/Q Targets Std                   84.5192
trainer/Q Targets Max                  104.55
trainer/Q Targets Min                 -232.72
trainer/Log Pis Mean                     2.17535
trainer/Log Pis Std                      2.16529
trainer/Log Pis Max                      7.65692
trainer/Log Pis Min                     -4.81939
trainer/policy/mean Mean                -0.658475
trainer/policy/mean Std                  0.556231
trainer/policy/mean Max                  0.945364
trainer/policy/mean Min                 -0.99617
trainer/policy/normal/std Mean           0.572025
trainer/policy/normal/std Std            0.101719
trainer/policy/normal/std Max            0.884394
trainer/policy/normal/std Min            0.237797
trainer/policy/normal/log_std Mean      -0.574412
trainer/policy/normal/log_std Std        0.179548
trainer/policy/normal/log_std Max       -0.122852
trainer/policy/normal/log_std Min       -1.43634
trainer/Alpha                            0.0264252
trainer/Alpha Loss                       0.63713
exploration/num steps total         554000
exploration/num paths total           2770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15972
exploration/Rewards Std                  1.54831
exploration/Rewards Max                 -3.29755e-143
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -231.945
exploration/Returns Std                132.738
exploration/Returns Max                -10.1007
exploration/Returns Min               -439.195
exploration/Actions Mean                -0.595093
exploration/Actions Std                  0.613603
exploration/Actions Max                  0.993451
exploration/Actions Min                 -0.999621
exploration/Num Paths                   10
exploration/Average Returns           -231.945
evaluation/num steps total               1.33142e+06
evaluation/num paths total            6624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.82361
evaluation/Rewards Std                   1.20923
evaluation/Rewards Max                  -8.02054e-15
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1170.55
evaluation/Returns Std                 242.664
evaluation/Returns Max                  -6.76849
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.93817
evaluation/Actions Std                   0.0411535
evaluation/Actions Max                  -0.128311
evaluation/Actions Min                  -0.978711
evaluation/Num Paths                    24
evaluation/Average Returns           -1170.55
time/data storing (s)                    0.0207216
time/evaluation sampling (s)            21.0204
time/exploration sampling (s)            5.54121
time/logging (s)                         0.0739168
time/sac training (s)                   42.2776
time/saving (s)                          0.470014
time/training (s)                        0.000142552
time/epoch (s)                          69.404
time/total (s)                       38249.5
Epoch                                  275
----------------------------------  -----------------
2020-11-10 01:47:50.399129 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 276 finished
----------------------------------  ----------------
replay_buffer/size                  556000
trainer/num train calls             277000
trainer/QF1 Loss                       148.51
trainer/QF2 Loss                       155.276
trainer/Policy Loss                     57.7887
trainer/Q1 Predictions Mean            -57.3916
trainer/Q1 Predictions Std              84.7708
trainer/Q1 Predictions Max             103.883
trainer/Q1 Predictions Min            -252.358
trainer/Q2 Predictions Mean            -57.3217
trainer/Q2 Predictions Std              84.6018
trainer/Q2 Predictions Max             104.064
trainer/Q2 Predictions Min            -253.559
trainer/Q Targets Mean                 -57.2309
trainer/Q Targets Std                   85.7066
trainer/Q Targets Max                  103.916
trainer/Q Targets Min                 -252.2
trainer/Log Pis Mean                     2.30691
trainer/Log Pis Std                      1.83728
trainer/Log Pis Max                      7.46467
trainer/Log Pis Min                     -4.12794
trainer/policy/mean Mean                -0.576035
trainer/policy/mean Std                  0.619882
trainer/policy/mean Max                  0.950699
trainer/policy/mean Min                 -0.990052
trainer/policy/normal/std Mean           0.5706
trainer/policy/normal/std Std            0.100382
trainer/policy/normal/std Max            0.89541
trainer/policy/normal/std Min            0.244555
trainer/policy/normal/log_std Mean      -0.576637
trainer/policy/normal/log_std Std        0.178325
trainer/policy/normal/log_std Max       -0.110473
trainer/policy/normal/log_std Min       -1.40831
trainer/Alpha                            0.0265802
trainer/Alpha Loss                       1.11334
exploration/num steps total         556000
exploration/num paths total           2780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.27347
exploration/Rewards Std                  1.732
exploration/Rewards Max                 -3.80135e-57
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -254.695
exploration/Returns Std                169.647
exploration/Returns Max                -55.3617
exploration/Returns Min               -611.374
exploration/Actions Mean                -0.555914
exploration/Actions Std                  0.653863
exploration/Actions Max                  0.996334
exploration/Actions Min                 -0.999887
exploration/Num Paths                   10
exploration/Average Returns           -254.695
evaluation/num steps total               1.33625e+06
evaluation/num paths total            6648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.06909
evaluation/Rewards Std                   1.23039
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1018.89
evaluation/Returns Std                 246.414
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.635645
evaluation/Actions Std                   0.447207
evaluation/Actions Max                   0.518582
evaluation/Actions Min                  -0.982421
evaluation/Num Paths                    24
evaluation/Average Returns           -1018.89
time/data storing (s)                    0.0207114
time/evaluation sampling (s)            13.6188
time/exploration sampling (s)            6.62744
time/logging (s)                         0.0738752
time/sac training (s)                   34.5446
time/saving (s)                          0.115974
time/training (s)                        0.000166983
time/epoch (s)                          55.0016
time/total (s)                       38432.2
Epoch                                  276
----------------------------------  ----------------
2020-11-10 01:50:11.470254 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 277 finished
----------------------------------  -----------------
replay_buffer/size                  558000
trainer/num train calls             278000
trainer/QF1 Loss                        49.0006
trainer/QF2 Loss                        55.4119
trainer/Policy Loss                     59.0657
trainer/Q1 Predictions Mean            -58.749
trainer/Q1 Predictions Std              81.9974
trainer/Q1 Predictions Max              43.6169
trainer/Q1 Predictions Min            -247.841
trainer/Q2 Predictions Mean            -58.5024
trainer/Q2 Predictions Std              81.7746
trainer/Q2 Predictions Max              43.8077
trainer/Q2 Predictions Min            -247.512
trainer/Q Targets Mean                 -58.5064
trainer/Q Targets Std                   82.5653
trainer/Q Targets Max                   44.3253
trainer/Q Targets Min                 -246.915
trainer/Log Pis Mean                     2.14826
trainer/Log Pis Std                      1.75815
trainer/Log Pis Max                      6.11898
trainer/Log Pis Min                     -3.17591
trainer/policy/mean Mean                -0.474022
trainer/policy/mean Std                  0.686565
trainer/policy/mean Max                  0.982438
trainer/policy/mean Min                 -0.989421
trainer/policy/normal/std Mean           0.571894
trainer/policy/normal/std Std            0.092462
trainer/policy/normal/std Max            0.855153
trainer/policy/normal/std Min            0.278227
trainer/policy/normal/log_std Mean      -0.57163
trainer/policy/normal/log_std Std        0.160393
trainer/policy/normal/log_std Max       -0.156475
trainer/policy/normal/log_std Min       -1.27932
trainer/Alpha                            0.026642
trainer/Alpha Loss                       0.537489
exploration/num steps total         558000
exploration/num paths total           2790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.38167
exploration/Rewards Std                  1.39375
exploration/Rewards Max                 -1.27969e-198
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -276.334
exploration/Returns Std                129.528
exploration/Returns Max               -104.433
exploration/Returns Min               -444.864
exploration/Actions Mean                -0.352074
exploration/Actions Std                  0.748084
exploration/Actions Max                  0.99762
exploration/Actions Min                 -0.999286
exploration/Num Paths                   10
exploration/Average Returns           -276.334
evaluation/num steps total               1.34107e+06
evaluation/num paths total            6672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.26168
evaluation/Rewards Std                   1.03223
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1057.6
evaluation/Returns Std                 206.126
evaluation/Returns Max                -644.907
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.607912
evaluation/Actions Std                   0.419029
evaluation/Actions Max                   0.669822
evaluation/Actions Min                  -0.983845
evaluation/Num Paths                    24
evaluation/Average Returns           -1057.6
time/data storing (s)                    0.0210335
time/evaluation sampling (s)            13.2734
time/exploration sampling (s)            5.01471
time/logging (s)                         0.0570773
time/sac training (s)                   34.2742
time/saving (s)                          0.127791
time/training (s)                        0.000145681
time/epoch (s)                          52.7684
time/total (s)                       38573.2
Epoch                                  277
----------------------------------  -----------------
2020-11-10 01:52:21.613735 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 278 finished
----------------------------------  -----------------
replay_buffer/size                  560000
trainer/num train calls             279000
trainer/QF1 Loss                       130.27
trainer/QF2 Loss                       127.001
trainer/Policy Loss                     59.6756
trainer/Q1 Predictions Mean            -59.103
trainer/Q1 Predictions Std              82.289
trainer/Q1 Predictions Max              55.7952
trainer/Q1 Predictions Min            -249.062
trainer/Q2 Predictions Mean            -59.196
trainer/Q2 Predictions Std              82.4083
trainer/Q2 Predictions Max              55.6642
trainer/Q2 Predictions Min            -248.57
trainer/Q Targets Mean                 -59.1523
trainer/Q Targets Std                   83.1612
trainer/Q Targets Max                   55.6261
trainer/Q Targets Min                 -247.747
trainer/Log Pis Mean                     2.03407
trainer/Log Pis Std                      1.85496
trainer/Log Pis Max                      6.63598
trainer/Log Pis Min                     -5.45125
trainer/policy/mean Mean                -0.48931
trainer/policy/mean Std                  0.692312
trainer/policy/mean Max                  0.980673
trainer/policy/mean Min                 -0.98824
trainer/policy/normal/std Mean           0.575897
trainer/policy/normal/std Std            0.0862993
trainer/policy/normal/std Max            0.876475
trainer/policy/normal/std Min            0.288409
trainer/policy/normal/log_std Mean      -0.563007
trainer/policy/normal/log_std Std        0.150234
trainer/policy/normal/log_std Max       -0.131847
trainer/policy/normal/log_std Min       -1.24337
trainer/Alpha                            0.0267122
trainer/Alpha Loss                       0.123409
exploration/num steps total         560000
exploration/num paths total           2800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.17193
exploration/Rewards Std                  1.44833
exploration/Rewards Max                 -4.17573e-106
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -234.387
exploration/Returns Std                135.681
exploration/Returns Max                -45.3292
exploration/Returns Min               -462.929
exploration/Actions Mean                -0.448577
exploration/Actions Std                  0.715205
exploration/Actions Max                  0.998033
exploration/Actions Min                 -0.998667
exploration/Num Paths                   10
exploration/Average Returns           -234.387
evaluation/num steps total               1.3459e+06
evaluation/num paths total            6696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.66201
evaluation/Rewards Std                   1.23496
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -937.064
evaluation/Returns Std                 246.038
evaluation/Returns Max                -641.818
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.604238
evaluation/Actions Std                   0.393432
evaluation/Actions Max                   0.72889
evaluation/Actions Min                  -0.975592
evaluation/Num Paths                    24
evaluation/Average Returns            -937.064
time/data storing (s)                    0.0216482
time/evaluation sampling (s)            12.3279
time/exploration sampling (s)            4.95582
time/logging (s)                         0.0374516
time/sac training (s)                   34.258
time/saving (s)                          0.272726
time/training (s)                        0.0001602
time/epoch (s)                          51.8737
time/total (s)                       38703.3
Epoch                                  278
----------------------------------  -----------------
2020-11-10 01:54:29.248789 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 279 finished
----------------------------------  -----------------
replay_buffer/size                  562000
trainer/num train calls             280000
trainer/QF1 Loss                        99.0075
trainer/QF2 Loss                       102.466
trainer/Policy Loss                     57.7587
trainer/Q1 Predictions Mean            -57.2574
trainer/Q1 Predictions Std              85.9178
trainer/Q1 Predictions Max             101.225
trainer/Q1 Predictions Min            -239.862
trainer/Q2 Predictions Mean            -57.3987
trainer/Q2 Predictions Std              86.0679
trainer/Q2 Predictions Max             101.199
trainer/Q2 Predictions Min            -240.915
trainer/Q Targets Mean                 -57.1656
trainer/Q Targets Std                   85.5572
trainer/Q Targets Max                  100.532
trainer/Q Targets Min                 -239.742
trainer/Log Pis Mean                     1.95502
trainer/Log Pis Std                      1.82098
trainer/Log Pis Max                      6.58034
trainer/Log Pis Min                     -3.28798
trainer/policy/mean Mean                -0.454326
trainer/policy/mean Std                  0.692285
trainer/policy/mean Max                  0.972309
trainer/policy/mean Min                 -0.987346
trainer/policy/normal/std Mean           0.581145
trainer/policy/normal/std Std            0.0853194
trainer/policy/normal/std Max            0.841286
trainer/policy/normal/std Min            0.256765
trainer/policy/normal/log_std Mean      -0.553395
trainer/policy/normal/log_std Std        0.14632
trainer/policy/normal/log_std Max       -0.172823
trainer/policy/normal/log_std Min       -1.3596
trainer/Alpha                            0.0264158
trainer/Alpha Loss                      -0.163455
exploration/num steps total         562000
exploration/num paths total           2810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00949
exploration/Rewards Std                  1.54289
exploration/Rewards Max                 -3.11459e-215
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -201.898
exploration/Returns Std                135.975
exploration/Returns Max                -64.338
exploration/Returns Min               -467.081
exploration/Actions Mean                -0.410046
exploration/Actions Std                  0.713433
exploration/Actions Max                  0.998223
exploration/Actions Min                 -0.99858
exploration/Num Paths                   10
exploration/Average Returns           -201.898
evaluation/num steps total               1.35072e+06
evaluation/num paths total            6720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.97159
evaluation/Rewards Std                   1.4207
evaluation/Rewards Max                  -1.09041e-21
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -999.289
evaluation/Returns Std                 284.324
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.490841
evaluation/Actions Std                   0.51361
evaluation/Actions Max                   0.884726
evaluation/Actions Min                  -0.971535
evaluation/Num Paths                    24
evaluation/Average Returns            -999.289
time/data storing (s)                    0.0209393
time/evaluation sampling (s)            14.3349
time/exploration sampling (s)            5.04253
time/logging (s)                         0.0595518
time/sac training (s)                   33.3421
time/saving (s)                          0.966483
time/training (s)                        0.000205171
time/epoch (s)                          53.7667
time/total (s)                       38830.9
Epoch                                  279
----------------------------------  -----------------
2020-11-10 01:56:33.842118 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 280 finished
----------------------------------  ----------------
replay_buffer/size                  564000
trainer/num train calls             281000
trainer/QF1 Loss                       127.95
trainer/QF2 Loss                       125.648
trainer/Policy Loss                     69.0472
trainer/Q1 Predictions Mean            -68.3853
trainer/Q1 Predictions Std              89.5722
trainer/Q1 Predictions Max              84.4356
trainer/Q1 Predictions Min            -275.88
trainer/Q2 Predictions Mean            -68.7361
trainer/Q2 Predictions Std              89.8008
trainer/Q2 Predictions Max              83.9072
trainer/Q2 Predictions Min            -276.223
trainer/Q Targets Mean                 -68.7066
trainer/Q Targets Std                   90.7283
trainer/Q Targets Max                   85.9839
trainer/Q Targets Min                 -274.756
trainer/Log Pis Mean                     1.96845
trainer/Log Pis Std                      1.90116
trainer/Log Pis Max                      6.66291
trainer/Log Pis Min                     -4.20809
trainer/policy/mean Mean                -0.5956
trainer/policy/mean Std                  0.597624
trainer/policy/mean Max                  0.953286
trainer/policy/mean Min                 -0.987527
trainer/policy/normal/std Mean           0.589784
trainer/policy/normal/std Std            0.0999444
trainer/policy/normal/std Max            0.903406
trainer/policy/normal/std Min            0.315177
trainer/policy/normal/log_std Mean      -0.541592
trainer/policy/normal/log_std Std        0.163136
trainer/policy/normal/log_std Max       -0.101583
trainer/policy/normal/log_std Min       -1.15462
trainer/Alpha                            0.0263104
trainer/Alpha Loss                      -0.114777
exploration/num steps total         564000
exploration/num paths total           2820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.21394
exploration/Rewards Std                  1.61066
exploration/Rewards Max                 -5.2113e-151
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -242.787
exploration/Returns Std                145.598
exploration/Returns Max                -89.8811
exploration/Returns Min               -520.267
exploration/Actions Mean                -0.509718
exploration/Actions Std                  0.674407
exploration/Actions Max                  0.996929
exploration/Actions Min                 -0.99953
exploration/Num Paths                   10
exploration/Average Returns           -242.787
evaluation/num steps total               1.35554e+06
evaluation/num paths total            6744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.73686
evaluation/Rewards Std                   0.895548
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1153.11
evaluation/Returns Std                 180.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.865915
evaluation/Actions Std                   0.109574
evaluation/Actions Max                  -0.719119
evaluation/Actions Min                  -0.976681
evaluation/Num Paths                    24
evaluation/Average Returns           -1153.11
time/data storing (s)                    0.0279956
time/evaluation sampling (s)            13.1511
time/exploration sampling (s)            5.98494
time/logging (s)                         0.0422256
time/sac training (s)                   33.9831
time/saving (s)                          0.437551
time/training (s)                        0.000166726
time/epoch (s)                          53.6271
time/total (s)                       38955.4
Epoch                                  280
----------------------------------  ----------------
2020-11-10 01:58:32.234303 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 281 finished
----------------------------------  -----------------
replay_buffer/size                  566000
trainer/num train calls             282000
trainer/QF1 Loss                         5.74999
trainer/QF2 Loss                        10.6397
trainer/Policy Loss                     63.9455
trainer/Q1 Predictions Mean            -63.5718
trainer/Q1 Predictions Std              83.4352
trainer/Q1 Predictions Max              96.3836
trainer/Q1 Predictions Min            -252.296
trainer/Q2 Predictions Mean            -63.3384
trainer/Q2 Predictions Std              83.205
trainer/Q2 Predictions Max              96.3767
trainer/Q2 Predictions Min            -253.517
trainer/Q Targets Mean                 -64.2246
trainer/Q Targets Std                   84.4113
trainer/Q Targets Max                   96.5224
trainer/Q Targets Min                 -252.261
trainer/Log Pis Mean                     1.72163
trainer/Log Pis Std                      1.885
trainer/Log Pis Max                      6.55059
trainer/Log Pis Min                     -5.16003
trainer/policy/mean Mean                -0.563393
trainer/policy/mean Std                  0.607225
trainer/policy/mean Max                  0.950974
trainer/policy/mean Min                 -0.992012
trainer/policy/normal/std Mean           0.595239
trainer/policy/normal/std Std            0.102979
trainer/policy/normal/std Max            0.96895
trainer/policy/normal/std Min            0.267087
trainer/policy/normal/log_std Mean      -0.533321
trainer/policy/normal/log_std Std        0.17028
trainer/policy/normal/log_std Max       -0.0315427
trainer/policy/normal/log_std Min       -1.32018
trainer/Alpha                            0.0259188
trainer/Alpha Loss                      -1.01683
exploration/num steps total         566000
exploration/num paths total           2830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13092
exploration/Rewards Std                  1.44227
exploration/Rewards Max                 -3.04517e-141
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -226.185
exploration/Returns Std                120.57
exploration/Returns Max                -75.4765
exploration/Returns Min               -499.188
exploration/Actions Mean                -0.493172
exploration/Actions Std                  0.664225
exploration/Actions Max                  0.995767
exploration/Actions Min                 -0.999894
exploration/Num Paths                   10
exploration/Average Returns           -226.185
evaluation/num steps total               1.36037e+06
evaluation/num paths total            6768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.8257
evaluation/Actions Std                   0.146076
evaluation/Actions Max                  -0.671917
evaluation/Actions Min                  -0.972876
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.0300671
time/evaluation sampling (s)            12.609
time/exploration sampling (s)            5.10717
time/logging (s)                         0.0639133
time/sac training (s)                   33.4046
time/saving (s)                          0.601089
time/training (s)                        0.000144923
time/epoch (s)                          51.816
time/total (s)                       39073.8
Epoch                                  281
----------------------------------  -----------------
2020-11-10 02:00:36.799249 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 282 finished
----------------------------------  ----------------
replay_buffer/size                  568000
trainer/num train calls             283000
trainer/QF1 Loss                        36.1387
trainer/QF2 Loss                        33.0099
trainer/Policy Loss                     70.965
trainer/Q1 Predictions Mean            -70.3312
trainer/Q1 Predictions Std              88.071
trainer/Q1 Predictions Max              93.6814
trainer/Q1 Predictions Min            -236.312
trainer/Q2 Predictions Mean            -70.6138
trainer/Q2 Predictions Std              88.2345
trainer/Q2 Predictions Max              94.2545
trainer/Q2 Predictions Min            -233.837
trainer/Q Targets Mean                 -70.6821
trainer/Q Targets Std                   89.0711
trainer/Q Targets Max                   93.636
trainer/Q Targets Min                 -237.565
trainer/Log Pis Mean                     2.03835
trainer/Log Pis Std                      1.85629
trainer/Log Pis Max                      6.92052
trainer/Log Pis Min                     -3.90767
trainer/policy/mean Mean                -0.559238
trainer/policy/mean Std                  0.611477
trainer/policy/mean Max                  0.963929
trainer/policy/mean Min                 -0.988602
trainer/policy/normal/std Mean           0.573226
trainer/policy/normal/std Std            0.10243
trainer/policy/normal/std Max            0.85862
trainer/policy/normal/std Min            0.245086
trainer/policy/normal/log_std Mean      -0.572085
trainer/policy/normal/log_std Std        0.176814
trainer/policy/normal/log_std Max       -0.152428
trainer/policy/normal/log_std Min       -1.40615
trainer/Alpha                            0.0256486
trainer/Alpha Loss                       0.140501
exploration/num steps total         568000
exploration/num paths total           2840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.867752
exploration/Rewards Std                  1.61206
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -173.55
exploration/Returns Std                128.554
exploration/Returns Max                -36.099
exploration/Returns Min               -460.856
exploration/Actions Mean                -0.536373
exploration/Actions Std                  0.618296
exploration/Actions Max                  0.990946
exploration/Actions Min                 -0.999451
exploration/Num Paths                   10
exploration/Average Returns           -173.55
evaluation/num steps total               1.36519e+06
evaluation/num paths total            6792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.862835
evaluation/Actions Std                   0.11371
evaluation/Actions Max                  -0.646869
evaluation/Actions Min                  -0.977271
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0200757
time/evaluation sampling (s)            15.7756
time/exploration sampling (s)            5.14314
time/logging (s)                         0.0389093
time/sac training (s)                   32.6006
time/saving (s)                          0.066787
time/training (s)                        0.000162839
time/epoch (s)                          53.6453
time/total (s)                       39198.3
Epoch                                  282
----------------------------------  ----------------
2020-11-10 02:02:47.647762 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 283 finished
----------------------------------  ----------------
replay_buffer/size                  570000
trainer/num train calls             284000
trainer/QF1 Loss                        31.7326
trainer/QF2 Loss                        28.8163
trainer/Policy Loss                     69.3858
trainer/Q1 Predictions Mean            -68.8442
trainer/Q1 Predictions Std              89.0348
trainer/Q1 Predictions Max              55.2218
trainer/Q1 Predictions Min            -251.764
trainer/Q2 Predictions Mean            -68.8903
trainer/Q2 Predictions Std              89.0147
trainer/Q2 Predictions Max              54.9751
trainer/Q2 Predictions Min            -252.942
trainer/Q Targets Mean                 -69.463
trainer/Q Targets Std                   90.0861
trainer/Q Targets Max                   54.7394
trainer/Q Targets Min                 -251.847
trainer/Log Pis Mean                     2.05678
trainer/Log Pis Std                      1.63995
trainer/Log Pis Max                      5.94262
trainer/Log Pis Min                     -3.43023
trainer/policy/mean Mean                -0.536078
trainer/policy/mean Std                  0.626864
trainer/policy/mean Max                  0.969368
trainer/policy/mean Min                 -0.988007
trainer/policy/normal/std Mean           0.574605
trainer/policy/normal/std Std            0.0875656
trainer/policy/normal/std Max            0.89594
trainer/policy/normal/std Min            0.266357
trainer/policy/normal/log_std Mean      -0.56597
trainer/policy/normal/log_std Std        0.156576
trainer/policy/normal/log_std Max       -0.109882
trainer/policy/normal/log_std Min       -1.32292
trainer/Alpha                            0.0257775
trainer/Alpha Loss                       0.207706
exploration/num steps total         570000
exploration/num paths total           2850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.08988
exploration/Rewards Std                  1.59481
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -217.976
exploration/Returns Std                113.823
exploration/Returns Max                -81.73
exploration/Returns Min               -403.254
exploration/Actions Mean                -0.542104
exploration/Actions Std                  0.610451
exploration/Actions Max                  0.995945
exploration/Actions Min                 -0.99904
exploration/Num Paths                   10
exploration/Average Returns           -217.976
evaluation/num steps total               1.37002e+06
evaluation/num paths total            6816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.779659
evaluation/Actions Std                   0.227592
evaluation/Actions Max                   0.251996
evaluation/Actions Min                  -0.977724
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0254699
time/evaluation sampling (s)            16.1539
time/exploration sampling (s)            5.54553
time/logging (s)                         0.0361042
time/sac training (s)                   33.8215
time/saving (s)                          0.158855
time/training (s)                        0.000158762
time/epoch (s)                          55.7415
time/total (s)                       39329.1
Epoch                                  283
----------------------------------  ----------------
2020-11-10 02:04:47.323097 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 284 finished
----------------------------------  ----------------
replay_buffer/size                  572000
trainer/num train calls             285000
trainer/QF1 Loss                        63.3485
trainer/QF2 Loss                        70.3573
trainer/Policy Loss                     67.2569
trainer/Q1 Predictions Mean            -66.7958
trainer/Q1 Predictions Std              86.6413
trainer/Q1 Predictions Max              45.0955
trainer/Q1 Predictions Min            -251.294
trainer/Q2 Predictions Mean            -66.8032
trainer/Q2 Predictions Std              86.6158
trainer/Q2 Predictions Max              45.1296
trainer/Q2 Predictions Min            -252.536
trainer/Q Targets Mean                 -67.0141
trainer/Q Targets Std                   87.2685
trainer/Q Targets Max                   44.9201
trainer/Q Targets Min                 -251.378
trainer/Log Pis Mean                     1.74156
trainer/Log Pis Std                      1.8994
trainer/Log Pis Max                      6.87728
trainer/Log Pis Min                     -6.98562
trainer/policy/mean Mean                -0.552148
trainer/policy/mean Std                  0.61722
trainer/policy/mean Max                  0.951288
trainer/policy/mean Min                 -0.988585
trainer/policy/normal/std Mean           0.558655
trainer/policy/normal/std Std            0.0816126
trainer/policy/normal/std Max            0.83928
trainer/policy/normal/std Min            0.241717
trainer/policy/normal/log_std Mean      -0.59295
trainer/policy/normal/log_std Std        0.147912
trainer/policy/normal/log_std Max       -0.175211
trainer/policy/normal/log_std Min       -1.41999
trainer/Alpha                            0.025462
trainer/Alpha Loss                      -0.948606
exploration/num steps total         572000
exploration/num paths total           2860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.600071
exploration/Rewards Std                  1.34553
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -120.014
exploration/Returns Std                 96.8143
exploration/Returns Max                 -6.76849
exploration/Returns Min               -311.758
exploration/Actions Mean                -0.613904
exploration/Actions Std                  0.57968
exploration/Actions Max                  0.99937
exploration/Actions Min                 -0.998554
exploration/Num Paths                   10
exploration/Average Returns           -120.014
evaluation/num steps total               1.37484e+06
evaluation/num paths total            6840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.50169
evaluation/Rewards Std                   0.972687
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1105.84
evaluation/Returns Std                 195.179
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.810374
evaluation/Actions Std                   0.181475
evaluation/Actions Max                  -0.111432
evaluation/Actions Min                  -0.975904
evaluation/Num Paths                    24
evaluation/Average Returns           -1105.84
time/data storing (s)                    0.0238133
time/evaluation sampling (s)            13.11
time/exploration sampling (s)            4.99546
time/logging (s)                         0.0462939
time/sac training (s)                   33.9191
time/saving (s)                          0.12743
time/training (s)                        0.000128639
time/epoch (s)                          52.2223
time/total (s)                       39448.8
Epoch                                  284
----------------------------------  ----------------
2020-11-10 02:06:41.931208 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 285 finished
----------------------------------  -----------------
replay_buffer/size                  574000
trainer/num train calls             286000
trainer/QF1 Loss                       130.979
trainer/QF2 Loss                       139.942
trainer/Policy Loss                     62.3747
trainer/Q1 Predictions Mean            -61.9162
trainer/Q1 Predictions Std              84.3118
trainer/Q1 Predictions Max              98.5922
trainer/Q1 Predictions Min            -251.458
trainer/Q2 Predictions Mean            -61.8737
trainer/Q2 Predictions Std              84.1182
trainer/Q2 Predictions Max              98.5689
trainer/Q2 Predictions Min            -252.663
trainer/Q Targets Mean                 -61.8953
trainer/Q Targets Std                   84.841
trainer/Q Targets Max                   98.0423
trainer/Q Targets Min                 -251.338
trainer/Log Pis Mean                     2.06263
trainer/Log Pis Std                      1.84396
trainer/Log Pis Max                      6.34378
trainer/Log Pis Min                     -5.12877
trainer/policy/mean Mean                -0.410335
trainer/policy/mean Std                  0.720975
trainer/policy/mean Max                  0.975295
trainer/policy/mean Min                 -0.986946
trainer/policy/normal/std Mean           0.563176
trainer/policy/normal/std Std            0.0845414
trainer/policy/normal/std Max            0.86092
trainer/policy/normal/std Min            0.268151
trainer/policy/normal/log_std Mean      -0.585273
trainer/policy/normal/log_std Std        0.149456
trainer/policy/normal/log_std Max       -0.149754
trainer/policy/normal/log_std Min       -1.3162
trainer/Alpha                            0.0252667
trainer/Alpha Loss                       0.230362
exploration/num steps total         574000
exploration/num paths total           2870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13414
exploration/Rewards Std                  1.62417
exploration/Rewards Max                 -1.63504e-265
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -226.828
exploration/Returns Std                164.074
exploration/Returns Max                -19.9505
exploration/Returns Min               -564.045
exploration/Actions Mean                -0.325105
exploration/Actions Std                  0.73637
exploration/Actions Max                  0.996439
exploration/Actions Min                 -0.999246
exploration/Num Paths                   10
exploration/Average Returns           -226.828
evaluation/num steps total               1.37966e+06
evaluation/num paths total            6864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.61365
evaluation/Rewards Std                   1.22699
evaluation/Rewards Max                  -2.99573
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -927.344
evaluation/Returns Std                 241.677
evaluation/Returns Max                -617.514
evaluation/Returns Min               -1131.34
evaluation/Actions Mean                 -0.550333
evaluation/Actions Std                   0.463278
evaluation/Actions Max                   0.860581
evaluation/Actions Min                  -0.978322
evaluation/Num Paths                    24
evaluation/Average Returns            -927.344
time/data storing (s)                    0.0242443
time/evaluation sampling (s)            13.1793
time/exploration sampling (s)            5.04584
time/logging (s)                         0.0454086
time/sac training (s)                   32.1248
time/saving (s)                          0.155403
time/training (s)                        0.000154282
time/epoch (s)                          50.5752
time/total (s)                       39563.4
Epoch                                  285
----------------------------------  -----------------
2020-11-10 02:08:54.902190 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 286 finished
----------------------------------  -----------------
replay_buffer/size                  576000
trainer/num train calls             287000
trainer/QF1 Loss                       240.065
trainer/QF2 Loss                       237.686
trainer/Policy Loss                     73.9459
trainer/Q1 Predictions Mean            -73.3653
trainer/Q1 Predictions Std              89.1593
trainer/Q1 Predictions Max              40.0261
trainer/Q1 Predictions Min            -275.669
trainer/Q2 Predictions Mean            -73.375
trainer/Q2 Predictions Std              89.0308
trainer/Q2 Predictions Max              41.4184
trainer/Q2 Predictions Min            -276.213
trainer/Q Targets Mean                 -72.3741
trainer/Q Targets Std                   90.394
trainer/Q Targets Max                   38.8301
trainer/Q Targets Min                 -274.991
trainer/Log Pis Mean                     2.18071
trainer/Log Pis Std                      1.72262
trainer/Log Pis Max                      6.50838
trainer/Log Pis Min                     -3.21066
trainer/policy/mean Mean                -0.486812
trainer/policy/mean Std                  0.676728
trainer/policy/mean Max                  0.965797
trainer/policy/mean Min                 -0.987028
trainer/policy/normal/std Mean           0.567796
trainer/policy/normal/std Std            0.0873952
trainer/policy/normal/std Max            0.829042
trainer/policy/normal/std Min            0.342919
trainer/policy/normal/log_std Mean      -0.577387
trainer/policy/normal/log_std Std        0.150032
trainer/policy/normal/log_std Max       -0.187485
trainer/policy/normal/log_std Min       -1.07026
trainer/Alpha                            0.025371
trainer/Alpha Loss                       0.663958
exploration/num steps total         576000
exploration/num paths total           2880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.06001
exploration/Rewards Std                  1.46574
exploration/Rewards Max                 -4.29465e-185
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -212.002
exploration/Returns Std                134.233
exploration/Returns Max                -80.8244
exploration/Returns Min               -477.388
exploration/Actions Mean                -0.621907
exploration/Actions Std                  0.591467
exploration/Actions Max                  0.994287
exploration/Actions Min                 -0.999691
exploration/Num Paths                   10
exploration/Average Returns           -212.002
evaluation/num steps total               1.38449e+06
evaluation/num paths total            6888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   4.71292e-15
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   4.64125e-14
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.834355
evaluation/Actions Std                   0.144978
evaluation/Actions Max                  -0.689185
evaluation/Actions Min                  -0.979674
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0267563
time/evaluation sampling (s)            12.6102
time/exploration sampling (s)            6.41862
time/logging (s)                         0.0492761
time/sac training (s)                   34.41
time/saving (s)                          0.414642
time/training (s)                        0.000163502
time/epoch (s)                          53.9297
time/total (s)                       39696.3
Epoch                                  286
----------------------------------  -----------------
2020-11-10 02:11:01.471482 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 287 finished
----------------------------------  -----------------
replay_buffer/size                  578000
trainer/num train calls             288000
trainer/QF1 Loss                        77.4677
trainer/QF2 Loss                        80.5273
trainer/Policy Loss                     58.957
trainer/Q1 Predictions Mean            -58.6335
trainer/Q1 Predictions Std              85.8984
trainer/Q1 Predictions Max              96.4075
trainer/Q1 Predictions Min            -251.226
trainer/Q2 Predictions Mean            -58.5798
trainer/Q2 Predictions Std              85.8228
trainer/Q2 Predictions Max              96.7026
trainer/Q2 Predictions Min            -252.372
trainer/Q Targets Mean                 -58.8489
trainer/Q Targets Std                   86.5992
trainer/Q Targets Max                   96.3157
trainer/Q Targets Min                 -251.244
trainer/Log Pis Mean                     2.15807
trainer/Log Pis Std                      1.88497
trainer/Log Pis Max                      6.42537
trainer/Log Pis Min                     -6.94775
trainer/policy/mean Mean                -0.439691
trainer/policy/mean Std                  0.709783
trainer/policy/mean Max                  0.980234
trainer/policy/mean Min                 -0.988903
trainer/policy/normal/std Mean           0.573914
trainer/policy/normal/std Std            0.0861247
trainer/policy/normal/std Max            0.816528
trainer/policy/normal/std Min            0.271997
trainer/policy/normal/log_std Mean      -0.566389
trainer/policy/normal/log_std Std        0.149412
trainer/policy/normal/log_std Max       -0.202694
trainer/policy/normal/log_std Min       -1.30196
trainer/Alpha                            0.0260586
trainer/Alpha Loss                       0.576533
exploration/num steps total         578000
exploration/num paths total           2890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0356
exploration/Rewards Std                  1.60344
exploration/Rewards Max                 -4.18511e-217
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -207.12
exploration/Returns Std                147.182
exploration/Returns Max                -44.4784
exploration/Returns Min               -536.488
exploration/Actions Mean                -0.174904
exploration/Actions Std                  0.824534
exploration/Actions Max                  0.998883
exploration/Actions Min                 -0.998933
exploration/Num Paths                   10
exploration/Average Returns           -207.12
evaluation/num steps total               1.38931e+06
evaluation/num paths total            6912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6042
evaluation/Rewards Std                   0.88233
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1126.44
evaluation/Returns Std                 176.423
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.574085
evaluation/Actions Std                   0.431121
evaluation/Actions Max                   0.544086
evaluation/Actions Min                  -0.98014
evaluation/Num Paths                    24
evaluation/Average Returns           -1126.44
time/data storing (s)                    0.0224393
time/evaluation sampling (s)            13.2158
time/exploration sampling (s)            5.03006
time/logging (s)                         0.0357925
time/sac training (s)                   34.301
time/saving (s)                          0.0752712
time/training (s)                        0.00015465
time/epoch (s)                          52.6805
time/total (s)                       39822.8
Epoch                                  287
----------------------------------  -----------------
2020-11-10 02:13:21.580418 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 288 finished
----------------------------------  ----------------
replay_buffer/size                  580000
trainer/num train calls             289000
trainer/QF1 Loss                       103.242
trainer/QF2 Loss                       106.118
trainer/Policy Loss                     65.3349
trainer/Q1 Predictions Mean            -64.8999
trainer/Q1 Predictions Std              86.6752
trainer/Q1 Predictions Max              32.4587
trainer/Q1 Predictions Min            -242.955
trainer/Q2 Predictions Mean            -64.8014
trainer/Q2 Predictions Std              86.6933
trainer/Q2 Predictions Max              32.6392
trainer/Q2 Predictions Min            -242.185
trainer/Q Targets Mean                 -64.9838
trainer/Q Targets Std                   86.9998
trainer/Q Targets Max                   32.6785
trainer/Q Targets Min                 -241.97
trainer/Log Pis Mean                     2.07965
trainer/Log Pis Std                      1.58372
trainer/Log Pis Max                      6.39682
trainer/Log Pis Min                     -3.09377
trainer/policy/mean Mean                -0.482523
trainer/policy/mean Std                  0.692303
trainer/policy/mean Max                  0.962536
trainer/policy/mean Min                 -0.994959
trainer/policy/normal/std Mean           0.582072
trainer/policy/normal/std Std            0.0995882
trainer/policy/normal/std Max            0.895666
trainer/policy/normal/std Min            0.297946
trainer/policy/normal/log_std Mean      -0.555476
trainer/policy/normal/log_std Std        0.169141
trainer/policy/normal/log_std Max       -0.110188
trainer/policy/normal/log_std Min       -1.21084
trainer/Alpha                            0.0263233
trainer/Alpha Loss                       0.289694
exploration/num steps total         580000
exploration/num paths total           2900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.748118
exploration/Rewards Std                  1.23554
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -149.624
exploration/Returns Std                137.614
exploration/Returns Max                -15.4251
exploration/Returns Min               -517.954
exploration/Actions Mean                -0.273055
exploration/Actions Std                  0.781439
exploration/Actions Max                  0.998573
exploration/Actions Min                 -0.998858
exploration/Num Paths                   10
exploration/Average Returns           -149.624
evaluation/num steps total               1.39414e+06
evaluation/num paths total            6936
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.95686
evaluation/Rewards Std                   1.18656
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -996.329
evaluation/Returns Std                 236.201
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.533723
evaluation/Actions Std                   0.471436
evaluation/Actions Max                   0.562228
evaluation/Actions Min                  -0.977816
evaluation/Num Paths                    24
evaluation/Average Returns            -996.329
time/data storing (s)                    0.0197866
time/evaluation sampling (s)            16.3982
time/exploration sampling (s)            4.91351
time/logging (s)                         0.061126
time/sac training (s)                   33.9616
time/saving (s)                          0.212451
time/training (s)                        0.000149723
time/epoch (s)                          55.5669
time/total (s)                       39962.9
Epoch                                  288
----------------------------------  ----------------
2020-11-10 02:15:30.123841 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 289 finished
----------------------------------  ----------------
replay_buffer/size                  582000
trainer/num train calls             290000
trainer/QF1 Loss                       145.545
trainer/QF2 Loss                       140.688
trainer/Policy Loss                     62.4601
trainer/Q1 Predictions Mean            -61.8575
trainer/Q1 Predictions Std              83.8678
trainer/Q1 Predictions Max              35.125
trainer/Q1 Predictions Min            -241.926
trainer/Q2 Predictions Mean            -62.038
trainer/Q2 Predictions Std              84.1172
trainer/Q2 Predictions Max              36.0182
trainer/Q2 Predictions Min            -241.301
trainer/Q Targets Mean                 -62.0175
trainer/Q Targets Std                   84.6456
trainer/Q Targets Max                   35.9324
trainer/Q Targets Min                 -243.575
trainer/Log Pis Mean                     1.58512
trainer/Log Pis Std                      1.49729
trainer/Log Pis Max                      5.21643
trainer/Log Pis Min                     -4.0872
trainer/policy/mean Mean                -0.497279
trainer/policy/mean Std                  0.638084
trainer/policy/mean Max                  0.966729
trainer/policy/mean Min                 -0.981683
trainer/policy/normal/std Mean           0.575178
trainer/policy/normal/std Std            0.0910768
trainer/policy/normal/std Max            0.874141
trainer/policy/normal/std Min            0.235863
trainer/policy/normal/log_std Mean      -0.565875
trainer/policy/normal/log_std Std        0.162158
trainer/policy/normal/log_std Max       -0.134513
trainer/policy/normal/log_std Min       -1.4445
trainer/Alpha                            0.026437
trainer/Alpha Loss                      -1.50727
exploration/num steps total         582000
exploration/num paths total           2910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.36918
exploration/Rewards Std                  1.45237
exploration/Rewards Max                 -4.74046e-86
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -273.836
exploration/Returns Std                175.703
exploration/Returns Max                -38.3922
exploration/Returns Min               -591.795
exploration/Actions Mean                -0.407638
exploration/Actions Std                  0.718962
exploration/Actions Max                  0.998112
exploration/Actions Min                 -0.999263
exploration/Num Paths                   10
exploration/Average Returns           -273.836
evaluation/num steps total               1.39896e+06
evaluation/num paths total            6960
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.89234
evaluation/Rewards Std                   1.16977
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -983.361
evaluation/Returns Std                 232.31
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.528261
evaluation/Actions Std                   0.509937
evaluation/Actions Max                   0.901698
evaluation/Actions Min                  -0.971007
evaluation/Num Paths                    24
evaluation/Average Returns            -983.361
time/data storing (s)                    0.0230303
time/evaluation sampling (s)            13.0399
time/exploration sampling (s)            5.00742
time/logging (s)                         0.0438985
time/sac training (s)                   33.8585
time/saving (s)                          0.132985
time/training (s)                        0.000139592
time/epoch (s)                          52.1059
time/total (s)                       40091.4
Epoch                                  289
----------------------------------  ----------------
2020-11-10 02:17:41.060225 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 290 finished
----------------------------------  -----------------
replay_buffer/size                  584000
trainer/num train calls             291000
trainer/QF1 Loss                        64.1717
trainer/QF2 Loss                        65.7645
trainer/Policy Loss                     63.7241
trainer/Q1 Predictions Mean            -63.3327
trainer/Q1 Predictions Std              86.4031
trainer/Q1 Predictions Max              93.1402
trainer/Q1 Predictions Min            -233.53
trainer/Q2 Predictions Mean            -63.2151
trainer/Q2 Predictions Std              86.2736
trainer/Q2 Predictions Max              93.1627
trainer/Q2 Predictions Min            -232.803
trainer/Q Targets Mean                 -63.1018
trainer/Q Targets Std                   86.9806
trainer/Q Targets Max                   92.7968
trainer/Q Targets Min                 -234.704
trainer/Log Pis Mean                     1.84882
trainer/Log Pis Std                      1.82207
trainer/Log Pis Max                      6.46221
trainer/Log Pis Min                     -3.9473
trainer/policy/mean Mean                -0.444232
trainer/policy/mean Std                  0.702408
trainer/policy/mean Max                  0.976279
trainer/policy/mean Min                 -0.988103
trainer/policy/normal/std Mean           0.573447
trainer/policy/normal/std Std            0.0905587
trainer/policy/normal/std Max            0.836227
trainer/policy/normal/std Min            0.272057
trainer/policy/normal/log_std Mean      -0.568425
trainer/policy/normal/log_std Std        0.157575
trainer/policy/normal/log_std Max       -0.178855
trainer/policy/normal/log_std Min       -1.30174
trainer/Alpha                            0.0263261
trainer/Alpha Loss                      -0.549873
exploration/num steps total         584000
exploration/num paths total           2920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.65623
exploration/Rewards Std                  1.31866
exploration/Rewards Max                 -2.34285e-212
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -131.246
exploration/Returns Std                 87.3912
exploration/Returns Max                -13.3965
exploration/Returns Min               -324.247
exploration/Actions Mean                -0.343575
exploration/Actions Std                  0.74735
exploration/Actions Max                  0.998465
exploration/Actions Min                 -0.999612
exploration/Num Paths                   10
exploration/Average Returns           -131.246
evaluation/num steps total               1.40378e+06
evaluation/num paths total            6984
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.05513
evaluation/Rewards Std                   1.74029
evaluation/Rewards Max                  -3.83117e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1016.08
evaluation/Returns Std                 346.676
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.510615
evaluation/Actions Std                   0.50842
evaluation/Actions Max                   0.969655
evaluation/Actions Min                  -0.98148
evaluation/Num Paths                    24
evaluation/Average Returns           -1016.08
time/data storing (s)                    0.0201851
time/evaluation sampling (s)            12.7165
time/exploration sampling (s)            5.85268
time/logging (s)                         0.0591106
time/sac training (s)                   32.8493
time/saving (s)                          0.075643
time/training (s)                        0.000169734
time/epoch (s)                          51.5735
time/total (s)                       40222.3
Epoch                                  290
----------------------------------  -----------------
2020-11-10 02:20:01.111081 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 291 finished
----------------------------------  -----------------
replay_buffer/size                  586000
trainer/num train calls             292000
trainer/QF1 Loss                        21.3953
trainer/QF2 Loss                        28.2308
trainer/Policy Loss                     63.2751
trainer/Q1 Predictions Mean            -62.9788
trainer/Q1 Predictions Std              84.7465
trainer/Q1 Predictions Max              92.1111
trainer/Q1 Predictions Min            -238.819
trainer/Q2 Predictions Mean            -62.8031
trainer/Q2 Predictions Std              84.5022
trainer/Q2 Predictions Max              91.992
trainer/Q2 Predictions Min            -239.665
trainer/Q Targets Mean                 -63.3721
trainer/Q Targets Std                   85.2731
trainer/Q Targets Max                   91.5364
trainer/Q Targets Min                 -238.702
trainer/Log Pis Mean                     2.26636
trainer/Log Pis Std                      1.94218
trainer/Log Pis Max                      7.29035
trainer/Log Pis Min                     -3.33117
trainer/policy/mean Mean                -0.665407
trainer/policy/mean Std                  0.5431
trainer/policy/mean Max                  0.948363
trainer/policy/mean Min                 -0.995848
trainer/policy/normal/std Mean           0.588422
trainer/policy/normal/std Std            0.0995983
trainer/policy/normal/std Max            0.912825
trainer/policy/normal/std Min            0.233504
trainer/policy/normal/log_std Mean      -0.544121
trainer/policy/normal/log_std Std        0.165633
trainer/policy/normal/log_std Max       -0.0912106
trainer/policy/normal/log_std Min       -1.45456
trainer/Alpha                            0.0264365
trainer/Alpha Loss                       0.967687
exploration/num steps total         586000
exploration/num paths total           2930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.32477
exploration/Rewards Std                  1.79109
exploration/Rewards Max                 -1.63004e-133
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -264.954
exploration/Returns Std                170.643
exploration/Returns Max                -50.2493
exploration/Returns Min               -569.246
exploration/Actions Mean                -0.635968
exploration/Actions Std                  0.512366
exploration/Actions Max                  0.998449
exploration/Actions Min                 -0.999609
exploration/Num Paths                   10
exploration/Average Returns           -264.954
evaluation/num steps total               1.40861e+06
evaluation/num paths total            7008
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67931
evaluation/Rewards Std                   0.867955
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1141.54
evaluation/Returns Std                 174.106
evaluation/Returns Max                -679.535
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.742404
evaluation/Actions Std                   0.241073
evaluation/Actions Max                  -0.470616
evaluation/Actions Min                  -0.975086
evaluation/Num Paths                    24
evaluation/Average Returns           -1141.54
time/data storing (s)                    0.0318939
time/evaluation sampling (s)            13.6247
time/exploration sampling (s)            4.98241
time/logging (s)                         0.0370443
time/sac training (s)                   32.5462
time/saving (s)                          0.0689654
time/training (s)                        0.000141711
time/epoch (s)                          51.2913
time/total (s)                       40362.3
Epoch                                  291
----------------------------------  -----------------
2020-11-10 02:22:08.061778 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 292 finished
----------------------------------  -----------------
replay_buffer/size                  588000
trainer/num train calls             293000
trainer/QF1 Loss                       281.082
trainer/QF2 Loss                       277.737
trainer/Policy Loss                     68.7434
trainer/Q1 Predictions Mean            -68.0371
trainer/Q1 Predictions Std              88.0934
trainer/Q1 Predictions Max              91.7074
trainer/Q1 Predictions Min            -247.344
trainer/Q2 Predictions Mean            -68.2543
trainer/Q2 Predictions Std              88.2019
trainer/Q2 Predictions Max              91.706
trainer/Q2 Predictions Min            -247.573
trainer/Q Targets Mean                 -67.2087
trainer/Q Targets Std                   88.3547
trainer/Q Targets Max                   91.2784
trainer/Q Targets Min                 -247.55
trainer/Log Pis Mean                     1.61888
trainer/Log Pis Std                      1.62018
trainer/Log Pis Max                      5.22239
trainer/Log Pis Min                     -3.39692
trainer/policy/mean Mean                -0.503994
trainer/policy/mean Std                  0.647164
trainer/policy/mean Max                  0.952027
trainer/policy/mean Min                 -0.979693
trainer/policy/normal/std Mean           0.589291
trainer/policy/normal/std Std            0.096764
trainer/policy/normal/std Max            0.899053
trainer/policy/normal/std Min            0.229703
trainer/policy/normal/log_std Mean      -0.541901
trainer/policy/normal/log_std Std        0.161439
trainer/policy/normal/log_std Max       -0.106414
trainer/policy/normal/log_std Min       -1.47097
trainer/Alpha                            0.0259543
trainer/Alpha Loss                      -1.39163
exploration/num steps total         588000
exploration/num paths total           2940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.751808
exploration/Rewards Std                  1.35929
exploration/Rewards Max                 -1.05816e-178
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -150.362
exploration/Returns Std                 70.8201
exploration/Returns Max                -59.9783
exploration/Returns Min               -262.621
exploration/Actions Mean                -0.475467
exploration/Actions Std                  0.652365
exploration/Actions Max                  0.997576
exploration/Actions Min                 -0.999665
exploration/Num Paths                   10
exploration/Average Returns           -150.362
evaluation/num steps total               1.41343e+06
evaluation/num paths total            7032
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.46391
evaluation/Rewards Std                   1.78389
evaluation/Rewards Max                  -7.11042e-23
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -897.247
evaluation/Returns Std                 354.717
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.557162
evaluation/Actions Std                   0.43739
evaluation/Actions Max                   0.91363
evaluation/Actions Min                  -0.96988
evaluation/Num Paths                    24
evaluation/Average Returns            -897.247
time/data storing (s)                    0.0230348
time/evaluation sampling (s)            12.2015
time/exploration sampling (s)            4.91649
time/logging (s)                         0.0389917
time/sac training (s)                   32.8676
time/saving (s)                          1.26919
time/training (s)                        0.000156165
time/epoch (s)                          51.317
time/total (s)                       40489.2
Epoch                                  292
----------------------------------  -----------------
2020-11-10 02:24:19.181128 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 293 finished
----------------------------------  ----------------
replay_buffer/size                  590000
trainer/num train calls             294000
trainer/QF1 Loss                         7.41892
trainer/QF2 Loss                         8.45662
trainer/Policy Loss                     55.3589
trainer/Q1 Predictions Mean            -54.8909
trainer/Q1 Predictions Std              83.386
trainer/Q1 Predictions Max              69.5647
trainer/Q1 Predictions Min            -235.023
trainer/Q2 Predictions Mean            -54.9291
trainer/Q2 Predictions Std              83.3608
trainer/Q2 Predictions Max              69.5188
trainer/Q2 Predictions Min            -233.329
trainer/Q Targets Mean                 -55.6381
trainer/Q Targets Std                   84.514
trainer/Q Targets Max                   69.1512
trainer/Q Targets Min                 -235.635
trainer/Log Pis Mean                     1.55337
trainer/Log Pis Std                      1.7399
trainer/Log Pis Max                      5.42231
trainer/Log Pis Min                     -4.18279
trainer/policy/mean Mean                -0.466593
trainer/policy/mean Std                  0.682046
trainer/policy/mean Max                  0.967962
trainer/policy/mean Min                 -0.978618
trainer/policy/normal/std Mean           0.578371
trainer/policy/normal/std Std            0.0880892
trainer/policy/normal/std Max            0.869032
trainer/policy/normal/std Min            0.28383
trainer/policy/normal/log_std Mean      -0.559147
trainer/policy/normal/log_std Std        0.153564
trainer/policy/normal/log_std Max       -0.140376
trainer/policy/normal/log_std Min       -1.25938
trainer/Alpha                            0.0258472
trainer/Alpha Loss                      -1.63269
exploration/num steps total         590000
exploration/num paths total           2950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.850825
exploration/Rewards Std                  1.52106
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -170.165
exploration/Returns Std                 91.7002
exploration/Returns Max                -63.4451
exploration/Returns Min               -375.63
exploration/Actions Mean                -0.410501
exploration/Actions Std                  0.694994
exploration/Actions Max                  0.998574
exploration/Actions Min                 -0.999348
exploration/Num Paths                   10
exploration/Average Returns           -170.165
evaluation/num steps total               1.41826e+06
evaluation/num paths total            7056
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.86901
evaluation/Rewards Std                   1.20246
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -978.672
evaluation/Returns Std                 239.035
evaluation/Returns Max                -633.239
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.53983
evaluation/Actions Std                   0.435165
evaluation/Actions Max                   0.640643
evaluation/Actions Min                  -0.967623
evaluation/Num Paths                    24
evaluation/Average Returns            -978.672
time/data storing (s)                    0.0203259
time/evaluation sampling (s)            13.7842
time/exploration sampling (s)            5.1259
time/logging (s)                         0.0412045
time/sac training (s)                   33.8465
time/saving (s)                          0.604187
time/training (s)                        0.000205268
time/epoch (s)                          53.4225
time/total (s)                       40620.3
Epoch                                  293
----------------------------------  ----------------
2020-11-10 02:26:32.436693 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 294 finished
----------------------------------  -----------------
replay_buffer/size                  592000
trainer/num train calls             295000
trainer/QF1 Loss                        41.9756
trainer/QF2 Loss                        40.9716
trainer/Policy Loss                     67.6438
trainer/Q1 Predictions Mean            -67.242
trainer/Q1 Predictions Std              87.7879
trainer/Q1 Predictions Max              90.4435
trainer/Q1 Predictions Min            -238.517
trainer/Q2 Predictions Mean            -67.2061
trainer/Q2 Predictions Std              87.626
trainer/Q2 Predictions Max              90.2011
trainer/Q2 Predictions Min            -239.68
trainer/Q Targets Mean                 -67.3798
trainer/Q Targets Std                   88.1888
trainer/Q Targets Max                   89.6204
trainer/Q Targets Min                 -239.968
trainer/Log Pis Mean                     2.26303
trainer/Log Pis Std                      1.80561
trainer/Log Pis Max                      6.82216
trainer/Log Pis Min                     -4.66623
trainer/policy/mean Mean                -0.334294
trainer/policy/mean Std                  0.764984
trainer/policy/mean Max                  0.976644
trainer/policy/mean Min                 -0.988755
trainer/policy/normal/std Mean           0.567946
trainer/policy/normal/std Std            0.0892907
trainer/policy/normal/std Max            0.827221
trainer/policy/normal/std Min            0.229595
trainer/policy/normal/log_std Mean      -0.578244
trainer/policy/normal/log_std Std        0.159948
trainer/policy/normal/log_std Max       -0.189683
trainer/policy/normal/log_std Min       -1.47144
trainer/Alpha                            0.0253622
trainer/Alpha Loss                       0.966514
exploration/num steps total         592000
exploration/num paths total           2960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.761547
exploration/Rewards Std                  1.49881
exploration/Rewards Max                 -1.41892e-137
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -152.309
exploration/Returns Std                 95.4255
exploration/Returns Max                -39.7339
exploration/Returns Min               -387.407
exploration/Actions Mean                -0.243199
exploration/Actions Std                  0.759365
exploration/Actions Max                  0.997873
exploration/Actions Min                 -0.998937
exploration/Num Paths                   10
exploration/Average Returns           -152.309
evaluation/num steps total               1.42308e+06
evaluation/num paths total            7080
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.11579
evaluation/Rewards Std                   1.26213
evaluation/Rewards Max                  -3.25812
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1028.27
evaluation/Returns Std                 253.297
evaluation/Returns Max                -657.846
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.341855
evaluation/Actions Std                   0.657295
evaluation/Actions Max                   0.89847
evaluation/Actions Min                  -0.981249
evaluation/Num Paths                    24
evaluation/Average Returns           -1028.27
time/data storing (s)                    0.0252974
time/evaluation sampling (s)            12.5503
time/exploration sampling (s)            5.51947
time/logging (s)                         0.0462267
time/sac training (s)                   33.2256
time/saving (s)                          0.187283
time/training (s)                        0.000148757
time/epoch (s)                          51.5544
time/total (s)                       40753.6
Epoch                                  294
----------------------------------  -----------------
2020-11-10 02:28:33.718072 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 295 finished
----------------------------------  -----------------
replay_buffer/size                  594000
trainer/num train calls             296000
trainer/QF1 Loss                       242.242
trainer/QF2 Loss                       255.257
trainer/Policy Loss                     61.6699
trainer/Q1 Predictions Mean            -61.0403
trainer/Q1 Predictions Std              84.6118
trainer/Q1 Predictions Max              33.2502
trainer/Q1 Predictions Min            -233.286
trainer/Q2 Predictions Mean            -61.2752
trainer/Q2 Predictions Std              84.9486
trainer/Q2 Predictions Max              33.2267
trainer/Q2 Predictions Min            -227.681
trainer/Q Targets Mean                 -60.1247
trainer/Q Targets Std                   84.5179
trainer/Q Targets Max                   32.9204
trainer/Q Targets Min                 -234.626
trainer/Log Pis Mean                     2.1322
trainer/Log Pis Std                      1.81053
trainer/Log Pis Max                      6.48044
trainer/Log Pis Min                     -3.96026
trainer/policy/mean Mean                -0.390967
trainer/policy/mean Std                  0.72406
trainer/policy/mean Max                  0.981018
trainer/policy/mean Min                 -0.987978
trainer/policy/normal/std Mean           0.574902
trainer/policy/normal/std Std            0.0909105
trainer/policy/normal/std Max            0.906324
trainer/policy/normal/std Min            0.227941
trainer/policy/normal/log_std Mean      -0.565854
trainer/policy/normal/log_std Std        0.157314
trainer/policy/normal/log_std Max       -0.0983585
trainer/policy/normal/log_std Min       -1.47867
trainer/Alpha                            0.0251606
trainer/Alpha Loss                       0.486813
exploration/num steps total         594000
exploration/num paths total           2970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.03966
exploration/Rewards Std                  1.63245
exploration/Rewards Max                 -1.70096e-145
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -207.932
exploration/Returns Std                134.478
exploration/Returns Max                -74.4301
exploration/Returns Min               -505.256
exploration/Actions Mean                -0.428947
exploration/Actions Std                  0.733621
exploration/Actions Max                  0.999366
exploration/Actions Min                 -0.999251
exploration/Num Paths                   10
exploration/Average Returns           -207.932
evaluation/num steps total               1.4279e+06
evaluation/num paths total            7104
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.59822
evaluation/Rewards Std                   0.898113
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1125.24
evaluation/Returns Std                 179.729
evaluation/Returns Max                -636.651
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.544679
evaluation/Actions Std                   0.461554
evaluation/Actions Max                   0.91916
evaluation/Actions Min                  -0.980091
evaluation/Num Paths                    24
evaluation/Average Returns           -1125.24
time/data storing (s)                    0.0196281
time/evaluation sampling (s)            12.8798
time/exploration sampling (s)            4.88814
time/logging (s)                         0.0332049
time/sac training (s)                   32.8276
time/saving (s)                          0.121065
time/training (s)                        0.000149606
time/epoch (s)                          50.7696
time/total (s)                       40874.8
Epoch                                  295
----------------------------------  -----------------
2020-11-10 02:30:46.343953 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 296 finished
----------------------------------  ----------------
replay_buffer/size                  596000
trainer/num train calls             297000
trainer/QF1 Loss                        48.006
trainer/QF2 Loss                        48.9008
trainer/Policy Loss                     69.5532
trainer/Q1 Predictions Mean            -69.1583
trainer/Q1 Predictions Std              89.4161
trainer/Q1 Predictions Max              31.0249
trainer/Q1 Predictions Min            -249.666
trainer/Q2 Predictions Mean            -69.1113
trainer/Q2 Predictions Std              89.1708
trainer/Q2 Predictions Max              30.632
trainer/Q2 Predictions Min            -250.86
trainer/Q Targets Mean                 -69.5818
trainer/Q Targets Std                   90.0212
trainer/Q Targets Max                   31.0537
trainer/Q Targets Min                 -249.702
trainer/Log Pis Mean                     2.38617
trainer/Log Pis Std                      1.64222
trainer/Log Pis Max                      6.23818
trainer/Log Pis Min                     -3.79084
trainer/policy/mean Mean                -0.365143
trainer/policy/mean Std                  0.755668
trainer/policy/mean Max                  0.976799
trainer/policy/mean Min                 -0.99339
trainer/policy/normal/std Mean           0.569134
trainer/policy/normal/std Std            0.0951951
trainer/policy/normal/std Max            0.857904
trainer/policy/normal/std Min            0.236484
trainer/policy/normal/log_std Mean      -0.577483
trainer/policy/normal/log_std Std        0.167163
trainer/policy/normal/log_std Max       -0.153263
trainer/policy/normal/log_std Min       -1.44187
trainer/Alpha                            0.0252885
trainer/Alpha Loss                       1.4201
exploration/num steps total         596000
exploration/num paths total           2980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13829
exploration/Rewards Std                  1.62958
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -227.658
exploration/Returns Std                125.674
exploration/Returns Max                -38.8347
exploration/Returns Min               -462.691
exploration/Actions Mean                -0.283381
exploration/Actions Std                  0.767803
exploration/Actions Max                  0.998164
exploration/Actions Min                 -0.999788
exploration/Num Paths                   10
exploration/Average Returns           -227.658
evaluation/num steps total               1.43273e+06
evaluation/num paths total            7128
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6759
evaluation/Rewards Std                   0.876113
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.86
evaluation/Returns Std                 175.918
evaluation/Returns Max                -672.552
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.396527
evaluation/Actions Std                   0.600235
evaluation/Actions Max                   0.890749
evaluation/Actions Min                  -0.984002
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.86
time/data storing (s)                    0.0197743
time/evaluation sampling (s)            13.5839
time/exploration sampling (s)            4.79517
time/logging (s)                         0.0809824
time/sac training (s)                   32.8916
time/saving (s)                          0.0863286
time/training (s)                        0.00015294
time/epoch (s)                          51.4579
time/total (s)                       41007.4
Epoch                                  296
----------------------------------  ----------------
2020-11-10 02:32:53.070574 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 297 finished
----------------------------------  -----------------
replay_buffer/size                  598000
trainer/num train calls             298000
trainer/QF1 Loss                       145.374
trainer/QF2 Loss                       149.76
trainer/Policy Loss                     74.6923
trainer/Q1 Predictions Mean            -74.3478
trainer/Q1 Predictions Std              89.0656
trainer/Q1 Predictions Max              88.5448
trainer/Q1 Predictions Min            -231.014
trainer/Q2 Predictions Mean            -74.4093
trainer/Q2 Predictions Std              89.0903
trainer/Q2 Predictions Max              88.5974
trainer/Q2 Predictions Min            -230.391
trainer/Q Targets Mean                 -74.331
trainer/Q Targets Std                   90.017
trainer/Q Targets Max                   87.8105
trainer/Q Targets Min                 -232.27
trainer/Log Pis Mean                     1.91254
trainer/Log Pis Std                      1.82099
trainer/Log Pis Max                      6.25936
trainer/Log Pis Min                     -4.15707
trainer/policy/mean Mean                -0.286734
trainer/policy/mean Std                  0.789095
trainer/policy/mean Max                  0.978809
trainer/policy/mean Min                 -0.983735
trainer/policy/normal/std Mean           0.568926
trainer/policy/normal/std Std            0.0761764
trainer/policy/normal/std Max            0.809208
trainer/policy/normal/std Min            0.287826
trainer/policy/normal/log_std Mean      -0.573072
trainer/policy/normal/log_std Std        0.135925
trainer/policy/normal/log_std Max       -0.211699
trainer/policy/normal/log_std Min       -1.2454
trainer/Alpha                            0.0258461
trainer/Alpha Loss                      -0.319705
exploration/num steps total         598000
exploration/num paths total           2990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00449
exploration/Rewards Std                  1.59214
exploration/Rewards Max                 -2.23367e-106
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -200.898
exploration/Returns Std                 87.5068
exploration/Returns Max                -47.4249
exploration/Returns Min               -338.875
exploration/Actions Mean                -0.311241
exploration/Actions Std                  0.747066
exploration/Actions Max                  0.997176
exploration/Actions Min                 -0.999463
exploration/Num Paths                   10
exploration/Average Returns           -200.898
evaluation/num steps total               1.43755e+06
evaluation/num paths total            7152
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.50419
evaluation/Rewards Std                   0.968735
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1106.34
evaluation/Returns Std                 194.062
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.270269
evaluation/Actions Std                   0.715527
evaluation/Actions Max                   0.909173
evaluation/Actions Min                  -0.977173
evaluation/Num Paths                    24
evaluation/Average Returns           -1106.34
time/data storing (s)                    0.024731
time/evaluation sampling (s)            12.4797
time/exploration sampling (s)            5.30353
time/logging (s)                         0.0742282
time/sac training (s)                   33.3938
time/saving (s)                          0.318073
time/training (s)                        0.000127657
time/epoch (s)                          51.5943
time/total (s)                       41134.1
Epoch                                  297
----------------------------------  -----------------
2020-11-10 02:34:59.290298 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 298 finished
----------------------------------  -----------------
replay_buffer/size                  600000
trainer/num train calls             299000
trainer/QF1 Loss                       143.953
trainer/QF2 Loss                       131.997
trainer/Policy Loss                     63.0508
trainer/Q1 Predictions Mean            -62.6362
trainer/Q1 Predictions Std              83.5563
trainer/Q1 Predictions Max              32.7895
trainer/Q1 Predictions Min            -236.907
trainer/Q2 Predictions Mean            -62.6637
trainer/Q2 Predictions Std              83.5398
trainer/Q2 Predictions Max              33.3135
trainer/Q2 Predictions Min            -237.959
trainer/Q Targets Mean                 -62.1772
trainer/Q Targets Std                   84.3799
trainer/Q Targets Max                   32.785
trainer/Q Targets Min                 -237.186
trainer/Log Pis Mean                     2.31463
trainer/Log Pis Std                      1.67971
trainer/Log Pis Max                      6.05935
trainer/Log Pis Min                     -3.398
trainer/policy/mean Mean                -0.487657
trainer/policy/mean Std                  0.687666
trainer/policy/mean Max                  0.967847
trainer/policy/mean Min                 -0.990651
trainer/policy/normal/std Mean           0.586336
trainer/policy/normal/std Std            0.0974705
trainer/policy/normal/std Max            0.891458
trainer/policy/normal/std Min            0.299735
trainer/policy/normal/log_std Mean      -0.547123
trainer/policy/normal/log_std Std        0.16189
trainer/policy/normal/log_std Max       -0.114897
trainer/policy/normal/log_std Min       -1.20486
trainer/Alpha                            0.0263285
trainer/Alpha Loss                       1.14433
exploration/num steps total         600000
exploration/num paths total           3000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.995498
exploration/Rewards Std                  1.53175
exploration/Rewards Max                 -2.07514e-144
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -199.1
exploration/Returns Std                133.872
exploration/Returns Max                -60.0317
exploration/Returns Min               -460.222
exploration/Actions Mean                -0.458174
exploration/Actions Std                  0.69782
exploration/Actions Max                  0.997542
exploration/Actions Min                 -0.99915
exploration/Num Paths                   10
exploration/Average Returns           -199.1
evaluation/num steps total               1.44238e+06
evaluation/num paths total            7176
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44117
evaluation/Rewards Std                   1.10318
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1093.67
evaluation/Returns Std                 221.588
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.591466
evaluation/Actions Std                   0.39182
evaluation/Actions Max                   0.619361
evaluation/Actions Min                  -0.9834
evaluation/Num Paths                    24
evaluation/Average Returns           -1093.67
time/data storing (s)                    0.0206439
time/evaluation sampling (s)            13.2503
time/exploration sampling (s)            5.07154
time/logging (s)                         0.033301
time/sac training (s)                   32.986
time/saving (s)                          0.0426633
time/training (s)                        0.000153795
time/epoch (s)                          51.4045
time/total (s)                       41260.3
Epoch                                  298
----------------------------------  -----------------
2020-11-10 02:37:09.410356 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 299 finished
----------------------------------  -----------------
replay_buffer/size                  602000
trainer/num train calls             300000
trainer/QF1 Loss                        89.9498
trainer/QF2 Loss                        89.446
trainer/Policy Loss                     63.057
trainer/Q1 Predictions Mean            -62.6566
trainer/Q1 Predictions Std              84.9003
trainer/Q1 Predictions Max              56.063
trainer/Q1 Predictions Min            -235.563
trainer/Q2 Predictions Mean            -62.6562
trainer/Q2 Predictions Std              84.7433
trainer/Q2 Predictions Max              56.1056
trainer/Q2 Predictions Min            -235.007
trainer/Q Targets Mean                 -62.4993
trainer/Q Targets Std                   84.7064
trainer/Q Targets Max                   55.5909
trainer/Q Targets Min                 -234.61
trainer/Log Pis Mean                     2.2012
trainer/Log Pis Std                      1.78282
trainer/Log Pis Max                      6.78271
trainer/Log Pis Min                     -4.13485
trainer/policy/mean Mean                -0.504262
trainer/policy/mean Std                  0.664167
trainer/policy/mean Max                  0.958591
trainer/policy/mean Min                 -0.986773
trainer/policy/normal/std Mean           0.57389
trainer/policy/normal/std Std            0.0900041
trainer/policy/normal/std Max            0.838043
trainer/policy/normal/std Min            0.290327
trainer/policy/normal/log_std Mean      -0.56735
trainer/policy/normal/log_std Std        0.155049
trainer/policy/normal/log_std Max       -0.176686
trainer/policy/normal/log_std Min       -1.23675
trainer/Alpha                            0.026625
trainer/Alpha Loss                       0.729524
exploration/num steps total         602000
exploration/num paths total           3010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.940725
exploration/Rewards Std                  1.56909
exploration/Rewards Max                 -2.31761e-203
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.145
exploration/Returns Std                111.086
exploration/Returns Max                -92.8261
exploration/Returns Min               -397.559
exploration/Actions Mean                -0.358598
exploration/Actions Std                  0.72703
exploration/Actions Max                  0.9979
exploration/Actions Min                 -0.999584
exploration/Num Paths                   10
exploration/Average Returns           -188.145
evaluation/num steps total               1.4472e+06
evaluation/num paths total            7200
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.97596
evaluation/Rewards Std                   1.52001
evaluation/Rewards Max                  -1.10145e-12
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1000.17
evaluation/Returns Std                 303.879
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.458686
evaluation/Actions Std                   0.575904
evaluation/Actions Max                   0.920603
evaluation/Actions Min                  -0.978015
evaluation/Num Paths                    24
evaluation/Average Returns           -1000.17
time/data storing (s)                    0.0225759
time/evaluation sampling (s)            13.1482
time/exploration sampling (s)            5.85628
time/logging (s)                         0.0407833
time/sac training (s)                   32.802
time/saving (s)                          0.290837
time/training (s)                        0.000154466
time/epoch (s)                          52.1608
time/total (s)                       41390.4
Epoch                                  299
----------------------------------  -----------------
2020-11-10 02:39:21.193720 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 300 finished
----------------------------------  -----------------
replay_buffer/size                  604000
trainer/num train calls             301000
trainer/QF1 Loss                        23.9859
trainer/QF2 Loss                        25.8644
trainer/Policy Loss                     66.5825
trainer/Q1 Predictions Mean            -66.145
trainer/Q1 Predictions Std              88.9889
trainer/Q1 Predictions Max              55.9804
trainer/Q1 Predictions Min            -236.336
trainer/Q2 Predictions Mean            -66.1847
trainer/Q2 Predictions Std              89.1142
trainer/Q2 Predictions Max              56.3465
trainer/Q2 Predictions Min            -237.365
trainer/Q Targets Mean                 -66.3443
trainer/Q Targets Std                   89.642
trainer/Q Targets Max                   55.7964
trainer/Q Targets Min                 -236.31
trainer/Log Pis Mean                     2.336
trainer/Log Pis Std                      1.66368
trainer/Log Pis Max                      6.27989
trainer/Log Pis Min                     -4.11445
trainer/policy/mean Mean                -0.559997
trainer/policy/mean Std                  0.637805
trainer/policy/mean Max                  0.953543
trainer/policy/mean Min                 -0.989146
trainer/policy/normal/std Mean           0.585934
trainer/policy/normal/std Std            0.101938
trainer/policy/normal/std Max            0.944971
trainer/policy/normal/std Min            0.267948
trainer/policy/normal/log_std Mean      -0.549681
trainer/policy/normal/log_std Std        0.175412
trainer/policy/normal/log_std Max       -0.0566009
trainer/policy/normal/log_std Min       -1.31696
trainer/Alpha                            0.0274363
trainer/Alpha Loss                       1.20821
exploration/num steps total         604000
exploration/num paths total           3020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.962603
exploration/Rewards Std                  1.569
exploration/Rewards Max                 -5.75001e-115
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -192.521
exploration/Returns Std                117.265
exploration/Returns Max                -73.602
exploration/Returns Min               -415.3
exploration/Actions Mean                -0.360207
exploration/Actions Std                  0.784741
exploration/Actions Max                  0.998423
exploration/Actions Min                 -0.999729
exploration/Num Paths                   10
exploration/Average Returns           -192.521
evaluation/num steps total               1.45202e+06
evaluation/num paths total            7224
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78442
evaluation/Rewards Std                   0.738279
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.67
evaluation/Returns Std                 148.179
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.577647
evaluation/Actions Std                   0.417995
evaluation/Actions Max                   0.583032
evaluation/Actions Min                  -0.981963
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.67
time/data storing (s)                    0.0197956
time/evaluation sampling (s)            14.8811
time/exploration sampling (s)            5.29525
time/logging (s)                         0.0363915
time/sac training (s)                   32.322
time/saving (s)                          0.0503763
time/training (s)                        0.000178439
time/epoch (s)                          52.605
time/total (s)                       41522.1
Epoch                                  300
----------------------------------  -----------------
2020-11-10 02:41:33.280518 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 301 finished
----------------------------------  -----------------
replay_buffer/size                  606000
trainer/num train calls             302000
trainer/QF1 Loss                       195.412
trainer/QF2 Loss                       197.944
trainer/Policy Loss                     62.7563
trainer/Q1 Predictions Mean            -62.2458
trainer/Q1 Predictions Std              88.3078
trainer/Q1 Predictions Max              64.46
trainer/Q1 Predictions Min            -247.665
trainer/Q2 Predictions Mean            -62.3988
trainer/Q2 Predictions Std              88.478
trainer/Q2 Predictions Max              64.3655
trainer/Q2 Predictions Min            -248.922
trainer/Q Targets Mean                 -62.0482
trainer/Q Targets Std                   88.7666
trainer/Q Targets Max                   63.6819
trainer/Q Targets Min                 -247.947
trainer/Log Pis Mean                     2.28196
trainer/Log Pis Std                      1.62204
trainer/Log Pis Max                      6.37267
trainer/Log Pis Min                     -5.56181
trainer/policy/mean Mean                -0.399419
trainer/policy/mean Std                  0.74048
trainer/policy/mean Max                  0.955952
trainer/policy/mean Min                 -0.989378
trainer/policy/normal/std Mean           0.56777
trainer/policy/normal/std Std            0.0803692
trainer/policy/normal/std Max            0.818469
trainer/policy/normal/std Min            0.24991
trainer/policy/normal/log_std Mean      -0.576101
trainer/policy/normal/log_std Std        0.143229
trainer/policy/normal/log_std Max       -0.20032
trainer/policy/normal/log_std Min       -1.38665
trainer/Alpha                            0.0276639
trainer/Alpha Loss                       1.01157
exploration/num steps total         606000
exploration/num paths total           3030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.828999
exploration/Rewards Std                  1.45841
exploration/Rewards Max                 -1.13451e-167
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -165.8
exploration/Returns Std                170.398
exploration/Returns Max                -23.1693
exploration/Returns Min               -619.339
exploration/Actions Mean                -0.41013
exploration/Actions Std                  0.719481
exploration/Actions Max                  0.998033
exploration/Actions Min                 -0.998774
exploration/Num Paths                   10
exploration/Average Returns           -165.8
evaluation/num steps total               1.45685e+06
evaluation/num paths total            7248
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.23196
evaluation/Rewards Std                   1.09747
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1051.62
evaluation/Returns Std                 219.702
evaluation/Returns Max                -655.47
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.303976
evaluation/Actions Std                   0.702595
evaluation/Actions Max                   0.908825
evaluation/Actions Min                  -0.979121
evaluation/Num Paths                    24
evaluation/Average Returns           -1051.62
time/data storing (s)                    0.0198324
time/evaluation sampling (s)            14.2127
time/exploration sampling (s)            4.98072
time/logging (s)                         0.0487602
time/sac training (s)                   32.8487
time/saving (s)                          0.262369
time/training (s)                        0.000252483
time/epoch (s)                          52.3733
time/total (s)                       41654.2
Epoch                                  301
----------------------------------  -----------------
2020-11-10 02:44:14.176968 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 302 finished
----------------------------------  ----------------
replay_buffer/size                  608000
trainer/num train calls             303000
trainer/QF1 Loss                        44.5713
trainer/QF2 Loss                        38.5012
trainer/Policy Loss                     60.7304
trainer/Q1 Predictions Mean            -60.28
trainer/Q1 Predictions Std              87.1019
trainer/Q1 Predictions Max              55.3847
trainer/Q1 Predictions Min            -240.21
trainer/Q2 Predictions Mean            -60.363
trainer/Q2 Predictions Std              87.1975
trainer/Q2 Predictions Max              55.5602
trainer/Q2 Predictions Min            -241.43
trainer/Q Targets Mean                 -60.9371
trainer/Q Targets Std                   88.2201
trainer/Q Targets Max                   56.0841
trainer/Q Targets Min                 -243.112
trainer/Log Pis Mean                     2.06095
trainer/Log Pis Std                      1.56862
trainer/Log Pis Max                      6.06855
trainer/Log Pis Min                     -4.02611
trainer/policy/mean Mean                -0.440931
trainer/policy/mean Std                  0.71724
trainer/policy/mean Max                  0.972463
trainer/policy/mean Min                 -0.985471
trainer/policy/normal/std Mean           0.579236
trainer/policy/normal/std Std            0.092859
trainer/policy/normal/std Max            0.902721
trainer/policy/normal/std Min            0.253456
trainer/policy/normal/log_std Mean      -0.558441
trainer/policy/normal/log_std Std        0.156868
trainer/policy/normal/log_std Max       -0.102341
trainer/policy/normal/log_std Min       -1.37257
trainer/Alpha                            0.027424
trainer/Alpha Loss                       0.219182
exploration/num steps total         608000
exploration/num paths total           3040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.771512
exploration/Rewards Std                  1.3611
exploration/Rewards Max                 -2.34291e-89
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -154.302
exploration/Returns Std                156.77
exploration/Returns Max                 -9.44264
exploration/Returns Min               -475.536
exploration/Actions Mean                -0.50005
exploration/Actions Std                  0.690028
exploration/Actions Max                  0.997661
exploration/Actions Min                 -0.999389
exploration/Num Paths                   10
exploration/Average Returns           -154.302
evaluation/num steps total               1.46167e+06
evaluation/num paths total            7272
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84969
evaluation/Rewards Std                   0.748419
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.79
evaluation/Returns Std                 150.432
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.409466
evaluation/Actions Std                   0.565754
evaluation/Actions Max                   0.381792
evaluation/Actions Min                  -0.974254
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.79
time/data storing (s)                    0.0207591
time/evaluation sampling (s)            12.6422
time/exploration sampling (s)            4.8043
time/logging (s)                         0.0549306
time/sac training (s)                   33.0617
time/saving (s)                          0.282837
time/training (s)                        0.000172487
time/epoch (s)                          50.8669
time/total (s)                       41815
Epoch                                  302
----------------------------------  ----------------
2020-11-10 02:46:54.471160 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 303 finished
----------------------------------  -----------------
replay_buffer/size                  610000
trainer/num train calls             304000
trainer/QF1 Loss                         6.52556
trainer/QF2 Loss                         7.60402
trainer/Policy Loss                     64.4242
trainer/Q1 Predictions Mean            -64.0151
trainer/Q1 Predictions Std              86.5267
trainer/Q1 Predictions Max              54.7811
trainer/Q1 Predictions Min            -247.13
trainer/Q2 Predictions Mean            -63.976
trainer/Q2 Predictions Std              86.4883
trainer/Q2 Predictions Max              54.6876
trainer/Q2 Predictions Min            -246.82
trainer/Q Targets Mean                 -64.6758
trainer/Q Targets Std                   87.6689
trainer/Q Targets Max                   55.2702
trainer/Q Targets Min                 -246.923
trainer/Log Pis Mean                     2.124
trainer/Log Pis Std                      1.53111
trainer/Log Pis Max                      5.97599
trainer/Log Pis Min                     -2.65945
trainer/policy/mean Mean                -0.328137
trainer/policy/mean Std                  0.775434
trainer/policy/mean Max                  0.968167
trainer/policy/mean Min                 -0.987488
trainer/policy/normal/std Mean           0.573793
trainer/policy/normal/std Std            0.0734667
trainer/policy/normal/std Max            0.837157
trainer/policy/normal/std Min            0.25729
trainer/policy/normal/log_std Mean      -0.563575
trainer/policy/normal/log_std Std        0.127506
trainer/policy/normal/log_std Max       -0.177743
trainer/policy/normal/log_std Min       -1.35755
trainer/Alpha                            0.0279703
trainer/Alpha Loss                       0.44351
exploration/num steps total         610000
exploration/num paths total           3050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.903361
exploration/Rewards Std                  1.48267
exploration/Rewards Max                 -2.13096e-255
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -180.672
exploration/Returns Std                 72.7331
exploration/Returns Max                -50.9922
exploration/Returns Min               -296.041
exploration/Actions Mean                -0.427697
exploration/Actions Std                  0.70761
exploration/Actions Max                  0.997925
exploration/Actions Min                 -0.999926
exploration/Num Paths                   10
exploration/Average Returns           -180.672
evaluation/num steps total               1.4665e+06
evaluation/num paths total            7296
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.193799
evaluation/Actions Std                   0.780116
evaluation/Actions Max                   0.597578
evaluation/Actions Min                  -0.975552
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0240417
time/evaluation sampling (s)            16.7805
time/exploration sampling (s)            4.99834
time/logging (s)                         0.0418001
time/sac training (s)                   32.3032
time/saving (s)                          0.0883253
time/training (s)                        0.000150225
time/epoch (s)                          54.2363
time/total (s)                       41975.3
Epoch                                  303
----------------------------------  -----------------
2020-11-10 02:49:40.249360 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 304 finished
----------------------------------  ----------------
replay_buffer/size                  612000
trainer/num train calls             305000
trainer/QF1 Loss                       151.451
trainer/QF2 Loss                       153.958
trainer/Policy Loss                     67.8608
trainer/Q1 Predictions Mean            -67.596
trainer/Q1 Predictions Std              88.0798
trainer/Q1 Predictions Max              55.3297
trainer/Q1 Predictions Min            -235.355
trainer/Q2 Predictions Mean            -67.4181
trainer/Q2 Predictions Std              87.905
trainer/Q2 Predictions Max              55.5316
trainer/Q2 Predictions Min            -235.744
trainer/Q Targets Mean                 -68.2707
trainer/Q Targets Std                   89.2221
trainer/Q Targets Max                   55.1331
trainer/Q Targets Min                 -237.31
trainer/Log Pis Mean                     1.96966
trainer/Log Pis Std                      1.72927
trainer/Log Pis Max                      5.97141
trainer/Log Pis Min                     -5.03567
trainer/policy/mean Mean                -0.392668
trainer/policy/mean Std                  0.75195
trainer/policy/mean Max                  0.969673
trainer/policy/mean Min                 -0.994183
trainer/policy/normal/std Mean           0.582622
trainer/policy/normal/std Std            0.0908821
trainer/policy/normal/std Max            0.838519
trainer/policy/normal/std Min            0.253384
trainer/policy/normal/log_std Mean      -0.552164
trainer/policy/normal/log_std Std        0.154619
trainer/policy/normal/log_std Max       -0.176118
trainer/policy/normal/log_std Min       -1.37285
trainer/Alpha                            0.0274252
trainer/Alpha Loss                      -0.109129
exploration/num steps total         612000
exploration/num paths total           3060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.93622
exploration/Rewards Std                  1.51578
exploration/Rewards Max                 -2.72214e-89
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -187.244
exploration/Returns Std                118.92
exploration/Returns Max                -74.8689
exploration/Returns Min               -439.77
exploration/Actions Mean                -0.412464
exploration/Actions Std                  0.717737
exploration/Actions Max                  0.998669
exploration/Actions Min                 -0.99894
exploration/Num Paths                   10
exploration/Average Returns           -187.244
evaluation/num steps total               1.47132e+06
evaluation/num paths total            7320
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89673
evaluation/Rewards Std                   0.52741
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1185.24
evaluation/Returns Std                 106.005
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.377817
evaluation/Actions Std                   0.601803
evaluation/Actions Max                   0.910847
evaluation/Actions Min                  -0.971058
evaluation/Num Paths                    24
evaluation/Average Returns           -1185.24
time/data storing (s)                    0.0201221
time/evaluation sampling (s)            12.4774
time/exploration sampling (s)            5.00216
time/logging (s)                         0.0924834
time/sac training (s)                   32.9506
time/saving (s)                          0.343814
time/training (s)                        0.000143286
time/epoch (s)                          50.8867
time/total (s)                       42141.1
Epoch                                  304
----------------------------------  ----------------
2020-11-10 02:51:58.031282 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 305 finished
----------------------------------  ----------------
replay_buffer/size                  614000
trainer/num train calls             306000
trainer/QF1 Loss                        79.0907
trainer/QF2 Loss                        77.5589
trainer/Policy Loss                     61.1857
trainer/Q1 Predictions Mean            -60.6339
trainer/Q1 Predictions Std              84.8472
trainer/Q1 Predictions Max              60.5442
trainer/Q1 Predictions Min            -230.797
trainer/Q2 Predictions Mean            -60.8931
trainer/Q2 Predictions Std              85.0706
trainer/Q2 Predictions Max              60.5481
trainer/Q2 Predictions Min            -230.562
trainer/Q Targets Mean                 -60.5674
trainer/Q Targets Std                   84.8614
trainer/Q Targets Max                   60.1686
trainer/Q Targets Min                 -235.294
trainer/Log Pis Mean                     2.2255
trainer/Log Pis Std                      1.72945
trainer/Log Pis Max                      7.24707
trainer/Log Pis Min                     -3.69048
trainer/policy/mean Mean                -0.533238
trainer/policy/mean Std                  0.654577
trainer/policy/mean Max                  0.952168
trainer/policy/mean Min                 -0.991869
trainer/policy/normal/std Mean           0.594107
trainer/policy/normal/std Std            0.0999361
trainer/policy/normal/std Max            0.884765
trainer/policy/normal/std Min            0.330622
trainer/policy/normal/log_std Mean      -0.534076
trainer/policy/normal/log_std Std        0.161639
trainer/policy/normal/log_std Max       -0.122433
trainer/policy/normal/log_std Min       -1.10678
trainer/Alpha                            0.0276645
trainer/Alpha Loss                       0.809023
exploration/num steps total         614000
exploration/num paths total           3070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.25715
exploration/Rewards Std                  1.66815
exploration/Rewards Max                 -2.22287e-80
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -251.43
exploration/Returns Std                 94.5933
exploration/Returns Max               -108.314
exploration/Returns Min               -464.329
exploration/Actions Mean                -0.561954
exploration/Actions Std                  0.65407
exploration/Actions Max                  0.99635
exploration/Actions Min                 -0.999833
exploration/Num Paths                   10
exploration/Average Returns           -251.43
evaluation/num steps total               1.47614e+06
evaluation/num paths total            7344
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.11428
evaluation/Rewards Std                   1.17426
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1027.97
evaluation/Returns Std                 234.554
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.589632
evaluation/Actions Std                   0.394688
evaluation/Actions Max                   0.749987
evaluation/Actions Min                  -0.979044
evaluation/Num Paths                    24
evaluation/Average Returns           -1027.97
time/data storing (s)                    0.0278112
time/evaluation sampling (s)            12.6529
time/exploration sampling (s)            5.88064
time/logging (s)                         0.055334
time/sac training (s)                   32.5305
time/saving (s)                          0.159961
time/training (s)                        0.000181518
time/epoch (s)                          51.3074
time/total (s)                       42278.8
Epoch                                  305
----------------------------------  ----------------
2020-11-10 02:54:18.575237 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 306 finished
----------------------------------  -----------------
replay_buffer/size                  616000
trainer/num train calls             307000
trainer/QF1 Loss                        58.445
trainer/QF2 Loss                        55.0093
trainer/Policy Loss                     63.6332
trainer/Q1 Predictions Mean            -63.2868
trainer/Q1 Predictions Std              86.6093
trainer/Q1 Predictions Max              58.7901
trainer/Q1 Predictions Min            -234.313
trainer/Q2 Predictions Mean            -63.146
trainer/Q2 Predictions Std              86.4501
trainer/Q2 Predictions Max              58.6755
trainer/Q2 Predictions Min            -235.331
trainer/Q Targets Mean                 -63.6454
trainer/Q Targets Std                   87.7246
trainer/Q Targets Max                   58.7313
trainer/Q Targets Min                 -235.014
trainer/Log Pis Mean                     1.89218
trainer/Log Pis Std                      1.66025
trainer/Log Pis Max                      5.37546
trainer/Log Pis Min                     -3.61798
trainer/policy/mean Mean                -0.372879
trainer/policy/mean Std                  0.737243
trainer/policy/mean Max                  0.969869
trainer/policy/mean Min                 -0.993055
trainer/policy/normal/std Mean           0.561742
trainer/policy/normal/std Std            0.0787052
trainer/policy/normal/std Max            0.819015
trainer/policy/normal/std Min            0.26177
trainer/policy/normal/log_std Mean      -0.586403
trainer/policy/normal/log_std Std        0.139622
trainer/policy/normal/log_std Max       -0.199653
trainer/policy/normal/log_std Min       -1.34029
trainer/Alpha                            0.0273878
trainer/Alpha Loss                      -0.387904
exploration/num steps total         616000
exploration/num paths total           3080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.25274
exploration/Rewards Std                  1.63687
exploration/Rewards Max                 -4.91063e-205
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -250.547
exploration/Returns Std                162.58
exploration/Returns Max                -77.5575
exploration/Returns Min               -534.863
exploration/Actions Mean                -0.276354
exploration/Actions Std                  0.772835
exploration/Actions Max                  0.996882
exploration/Actions Min                 -0.999368
exploration/Num Paths                   10
exploration/Average Returns           -250.547
evaluation/num steps total               1.48097e+06
evaluation/num paths total            7368
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95804
evaluation/Rewards Std                   0.562606
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.57
evaluation/Returns Std                 113.082
evaluation/Returns Max                -655.242
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.218748
evaluation/Actions Std                   0.759611
evaluation/Actions Max                   0.554281
evaluation/Actions Min                  -0.979572
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.57
time/data storing (s)                    0.0245663
time/evaluation sampling (s)            12.4532
time/exploration sampling (s)            5.86055
time/logging (s)                         0.0785808
time/sac training (s)                   32.5718
time/saving (s)                          0.100682
time/training (s)                        0.000147294
time/epoch (s)                          51.0896
time/total (s)                       42419.3
Epoch                                  306
----------------------------------  -----------------
2020-11-10 02:56:24.855070 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 307 finished
----------------------------------  -----------------
replay_buffer/size                  618000
trainer/num train calls             308000
trainer/QF1 Loss                        86.8489
trainer/QF2 Loss                       110.49
trainer/Policy Loss                     60.3911
trainer/Q1 Predictions Mean            -59.9001
trainer/Q1 Predictions Std              80.6216
trainer/Q1 Predictions Max              32.4989
trainer/Q1 Predictions Min            -232.371
trainer/Q2 Predictions Mean            -59.7953
trainer/Q2 Predictions Std              80.4718
trainer/Q2 Predictions Max              32.7454
trainer/Q2 Predictions Min            -234.033
trainer/Q Targets Mean                 -59.8386
trainer/Q Targets Std                   81.5642
trainer/Q Targets Max                   32.2968
trainer/Q Targets Min                 -235.053
trainer/Log Pis Mean                     2.03726
trainer/Log Pis Std                      1.7964
trainer/Log Pis Max                      6.05714
trainer/Log Pis Min                     -5.21979
trainer/policy/mean Mean                -0.246308
trainer/policy/mean Std                  0.80177
trainer/policy/mean Max                  0.974244
trainer/policy/mean Min                 -0.984035
trainer/policy/normal/std Mean           0.5574
trainer/policy/normal/std Std            0.0721472
trainer/policy/normal/std Max            0.788401
trainer/policy/normal/std Min            0.245757
trainer/policy/normal/log_std Mean      -0.593404
trainer/policy/normal/log_std Std        0.137119
trainer/policy/normal/log_std Max       -0.237748
trainer/policy/normal/log_std Min       -1.40341
trainer/Alpha                            0.0275574
trainer/Alpha Loss                       0.133813
exploration/num steps total         618000
exploration/num paths total           3090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.18693
exploration/Rewards Std                  1.6008
exploration/Rewards Max                 -1.00779e-179
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -237.385
exploration/Returns Std                182.62
exploration/Returns Max                -10.1358
exploration/Returns Min               -609.417
exploration/Actions Mean                -0.175984
exploration/Actions Std                  0.791814
exploration/Actions Max                  0.999088
exploration/Actions Min                 -0.999581
exploration/Num Paths                   10
exploration/Average Returns           -237.385
evaluation/num steps total               1.48579e+06
evaluation/num paths total            7392
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   1.27275e-12
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.116582
evaluation/Actions Std                   0.856891
evaluation/Actions Max                   0.805446
evaluation/Actions Min                  -0.973473
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0200897
time/evaluation sampling (s)            12.4466
time/exploration sampling (s)            4.78942
time/logging (s)                         0.0252814
time/sac training (s)                   32.7986
time/saving (s)                          0.139202
time/training (s)                        0.000139237
time/epoch (s)                          50.2193
time/total (s)                       42545.5
Epoch                                  307
----------------------------------  -----------------
2020-11-10 02:58:42.936639 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 308 finished
----------------------------------  ----------------
replay_buffer/size                  620000
trainer/num train calls             309000
trainer/QF1 Loss                        34.9991
trainer/QF2 Loss                        33.7948
trainer/Policy Loss                     66.82
trainer/Q1 Predictions Mean            -66.2772
trainer/Q1 Predictions Std              83.5468
trainer/Q1 Predictions Max              47.4409
trainer/Q1 Predictions Min            -226.826
trainer/Q2 Predictions Mean            -66.3363
trainer/Q2 Predictions Std              83.695
trainer/Q2 Predictions Max              47.4724
trainer/Q2 Predictions Min            -226.412
trainer/Q Targets Mean                 -67.1246
trainer/Q Targets Std                   85.1434
trainer/Q Targets Max                   47.5516
trainer/Q Targets Min                 -231.53
trainer/Log Pis Mean                     1.7691
trainer/Log Pis Std                      1.79483
trainer/Log Pis Max                      5.83089
trainer/Log Pis Min                     -4.0668
trainer/policy/mean Mean                -0.486269
trainer/policy/mean Std                  0.670898
trainer/policy/mean Max                  0.950857
trainer/policy/mean Min                 -0.989248
trainer/policy/normal/std Mean           0.578677
trainer/policy/normal/std Std            0.0962823
trainer/policy/normal/std Max            0.88989
trainer/policy/normal/std Min            0.267766
trainer/policy/normal/log_std Mean      -0.560337
trainer/policy/normal/log_std Std        0.162546
trainer/policy/normal/log_std Max       -0.116658
trainer/policy/normal/log_std Min       -1.31764
trainer/Alpha                            0.0269537
trainer/Alpha Loss                      -0.834388
exploration/num steps total         620000
exploration/num paths total           3100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14905
exploration/Rewards Std                  1.46569
exploration/Rewards Max                 -3.60619e-75
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -229.809
exploration/Returns Std                170.775
exploration/Returns Max                -29.1016
exploration/Returns Min               -586.815
exploration/Actions Mean                -0.395208
exploration/Actions Std                  0.74831
exploration/Actions Max                  0.996651
exploration/Actions Min                 -0.999854
exploration/Num Paths                   10
exploration/Average Returns           -229.809
evaluation/num steps total               1.49062e+06
evaluation/num paths total            7416
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6759
evaluation/Rewards Std                   0.876113
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.86
evaluation/Returns Std                 175.918
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.49613
evaluation/Actions Std                   0.512259
evaluation/Actions Max                   0.893121
evaluation/Actions Min                  -0.973017
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.86
time/data storing (s)                    0.0199421
time/evaluation sampling (s)            14.8981
time/exploration sampling (s)            5.30509
time/logging (s)                         0.04154
time/sac training (s)                   32.2078
time/saving (s)                          0.0782215
time/training (s)                        0.000158994
time/epoch (s)                          52.5508
time/total (s)                       42683.6
Epoch                                  308
----------------------------------  ----------------
2020-11-10 03:00:58.369287 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 309 finished
----------------------------------  ----------------
replay_buffer/size                  622000
trainer/num train calls             310000
trainer/QF1 Loss                       246.294
trainer/QF2 Loss                       244.905
trainer/Policy Loss                     60.9454
trainer/Q1 Predictions Mean            -60.4827
trainer/Q1 Predictions Std              83.4841
trainer/Q1 Predictions Max              54.175
trainer/Q1 Predictions Min            -236.098
trainer/Q2 Predictions Mean            -60.3732
trainer/Q2 Predictions Std              83.2594
trainer/Q2 Predictions Max              54.1517
trainer/Q2 Predictions Min            -233.723
trainer/Q Targets Mean                 -59.847
trainer/Q Targets Std                   83.3465
trainer/Q Targets Max                   53.8764
trainer/Q Targets Min                 -236.598
trainer/Log Pis Mean                     1.89739
trainer/Log Pis Std                      1.73638
trainer/Log Pis Max                      5.94042
trainer/Log Pis Min                     -3.997
trainer/policy/mean Mean                -0.377065
trainer/policy/mean Std                  0.744856
trainer/policy/mean Max                  0.966867
trainer/policy/mean Min                 -0.987902
trainer/policy/normal/std Mean           0.569329
trainer/policy/normal/std Std            0.085218
trainer/policy/normal/std Max            0.8157
trainer/policy/normal/std Min            0.237642
trainer/policy/normal/log_std Mean      -0.574842
trainer/policy/normal/log_std Std        0.154542
trainer/policy/normal/log_std Max       -0.203709
trainer/policy/normal/log_std Min       -1.43699
trainer/Alpha                            0.0265743
trainer/Alpha Loss                      -0.372233
exploration/num steps total         622000
exploration/num paths total           3110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.60177
exploration/Rewards Std                  1.45136
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -320.354
exploration/Returns Std                189.805
exploration/Returns Max                -32.3974
exploration/Returns Min               -552.347
exploration/Actions Mean                -0.212805
exploration/Actions Std                  0.79986
exploration/Actions Max                  0.999324
exploration/Actions Min                 -0.998906
exploration/Num Paths                   10
exploration/Average Returns           -320.354
evaluation/num steps total               1.49544e+06
evaluation/num paths total            7440
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39628
evaluation/Rewards Std                   1.05577
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1084.65
evaluation/Returns Std                 211.463
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.326393
evaluation/Actions Std                   0.665265
evaluation/Actions Max                   0.904725
evaluation/Actions Min                  -0.976332
evaluation/Num Paths                    24
evaluation/Average Returns           -1084.65
time/data storing (s)                    0.0249629
time/evaluation sampling (s)            12.7057
time/exploration sampling (s)            4.86111
time/logging (s)                         0.051327
time/sac training (s)                   33.0351
time/saving (s)                          0.332603
time/training (s)                        0.000146764
time/epoch (s)                          51.011
time/total (s)                       42819
Epoch                                  309
----------------------------------  ----------------
2020-11-10 03:03:07.255787 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 310 finished
----------------------------------  ----------------
replay_buffer/size                  624000
trainer/num train calls             311000
trainer/QF1 Loss                        92.8464
trainer/QF2 Loss                        94.4119
trainer/Policy Loss                     70.3966
trainer/Q1 Predictions Mean            -69.7926
trainer/Q1 Predictions Std              86.7425
trainer/Q1 Predictions Max              31.3934
trainer/Q1 Predictions Min            -231.085
trainer/Q2 Predictions Mean            -69.9202
trainer/Q2 Predictions Std              86.8439
trainer/Q2 Predictions Max              31.3841
trainer/Q2 Predictions Min            -230.716
trainer/Q Targets Mean                 -70.1963
trainer/Q Targets Std                   87.674
trainer/Q Targets Max                   31.0582
trainer/Q Targets Min                 -234.916
trainer/Log Pis Mean                     2.02043
trainer/Log Pis Std                      1.71181
trainer/Log Pis Max                      6.69535
trainer/Log Pis Min                     -4.1355
trainer/policy/mean Mean                -0.47613
trainer/policy/mean Std                  0.693386
trainer/policy/mean Max                  0.965588
trainer/policy/mean Min                 -0.992132
trainer/policy/normal/std Mean           0.582903
trainer/policy/normal/std Std            0.0979209
trainer/policy/normal/std Max            0.889498
trainer/policy/normal/std Min            0.23876
trainer/policy/normal/log_std Mean      -0.553319
trainer/policy/normal/log_std Std        0.164265
trainer/policy/normal/log_std Max       -0.117098
trainer/policy/normal/log_std Min       -1.4323
trainer/Alpha                            0.0264977
trainer/Alpha Loss                       0.0741783
exploration/num steps total         624000
exploration/num paths total           3120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0107
exploration/Rewards Std                  1.54325
exploration/Rewards Max                 -2.1025e-133
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -202.139
exploration/Returns Std                206.827
exploration/Returns Max                 -3.4012
exploration/Returns Min               -536.85
exploration/Actions Mean                -0.512693
exploration/Actions Std                  0.684003
exploration/Actions Max                  0.996468
exploration/Actions Min                 -0.999564
exploration/Num Paths                   10
exploration/Average Returns           -202.139
evaluation/num steps total               1.50026e+06
evaluation/num paths total            7464
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.42543
evaluation/Rewards Std                   1.42923
evaluation/Rewards Max                  -1.50495e-13
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1090.51
evaluation/Returns Std                 286.887
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.534816
evaluation/Actions Std                   0.475938
evaluation/Actions Max                   0.89609
evaluation/Actions Min                  -0.979949
evaluation/Num Paths                    24
evaluation/Average Returns           -1090.51
time/data storing (s)                    0.019455
time/evaluation sampling (s)            12.4828
time/exploration sampling (s)            5.02887
time/logging (s)                         0.0543157
time/sac training (s)                   33.2481
time/saving (s)                          0.399181
time/training (s)                        0.00013466
time/epoch (s)                          51.2328
time/total (s)                       42947.8
Epoch                                  310
----------------------------------  ----------------
2020-11-10 03:05:14.081060 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 311 finished
----------------------------------  -----------------
replay_buffer/size                  626000
trainer/num train calls             312000
trainer/QF1 Loss                        86.5009
trainer/QF2 Loss                        88.8084
trainer/Policy Loss                     58.549
trainer/Q1 Predictions Mean            -58.1789
trainer/Q1 Predictions Std              85.071
trainer/Q1 Predictions Max              32.2895
trainer/Q1 Predictions Min            -232.785
trainer/Q2 Predictions Mean            -58.0469
trainer/Q2 Predictions Std              85.0359
trainer/Q2 Predictions Max              31.9649
trainer/Q2 Predictions Min            -233.119
trainer/Q Targets Mean                 -58.4881
trainer/Q Targets Std                   86.3236
trainer/Q Targets Max                   31.8512
trainer/Q Targets Min                 -235.187
trainer/Log Pis Mean                     1.88826
trainer/Log Pis Std                      1.77691
trainer/Log Pis Max                      7.02643
trainer/Log Pis Min                     -5.37149
trainer/policy/mean Mean                -0.387293
trainer/policy/mean Std                  0.725184
trainer/policy/mean Max                  0.961773
trainer/policy/mean Min                 -0.988239
trainer/policy/normal/std Mean           0.554943
trainer/policy/normal/std Std            0.0954482
trainer/policy/normal/std Max            0.875857
trainer/policy/normal/std Min            0.287419
trainer/policy/normal/log_std Mean      -0.603014
trainer/policy/normal/log_std Std        0.167136
trainer/policy/normal/log_std Max       -0.132553
trainer/policy/normal/log_std Min       -1.24681
trainer/Alpha                            0.0260185
trainer/Alpha Loss                      -0.407726
exploration/num steps total         626000
exploration/num paths total           3130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.903282
exploration/Rewards Std                  1.38553
exploration/Rewards Max                 -1.09063e-128
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -180.656
exploration/Returns Std                137.551
exploration/Returns Max                -41.6873
exploration/Returns Min               -487.503
exploration/Actions Mean                -0.570259
exploration/Actions Std                  0.616932
exploration/Actions Max                  0.997116
exploration/Actions Min                 -0.999049
exploration/Num Paths                   10
exploration/Average Returns           -180.656
evaluation/num steps total               1.50509e+06
evaluation/num paths total            7488
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39295
evaluation/Rewards Std                   1.06372
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.98
evaluation/Returns Std                 212.768
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.341628
evaluation/Actions Std                   0.659858
evaluation/Actions Max                   0.909565
evaluation/Actions Min                  -0.977378
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.98
time/data storing (s)                    0.0199459
time/evaluation sampling (s)            12.9277
time/exploration sampling (s)            4.95535
time/logging (s)                         0.055202
time/sac training (s)                   32.3687
time/saving (s)                          0.362838
time/training (s)                        0.000193356
time/epoch (s)                          50.6899
time/total (s)                       43074.6
Epoch                                  311
----------------------------------  -----------------
2020-11-10 03:07:31.021391 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 312 finished
----------------------------------  -----------------
replay_buffer/size                  628000
trainer/num train calls             313000
trainer/QF1 Loss                        25.0436
trainer/QF2 Loss                        25.744
trainer/Policy Loss                     66.275
trainer/Q1 Predictions Mean            -65.8581
trainer/Q1 Predictions Std              89.2913
trainer/Q1 Predictions Max              47.3987
trainer/Q1 Predictions Min            -237.071
trainer/Q2 Predictions Mean            -65.8206
trainer/Q2 Predictions Std              89.211
trainer/Q2 Predictions Max              47.6625
trainer/Q2 Predictions Min            -238.214
trainer/Q Targets Mean                 -66.4311
trainer/Q Targets Std                   89.746
trainer/Q Targets Max                   46.932
trainer/Q Targets Min                 -238.934
trainer/Log Pis Mean                     2.00192
trainer/Log Pis Std                      1.906
trainer/Log Pis Max                      6.8948
trainer/Log Pis Min                     -5.93354
trainer/policy/mean Mean                -0.448788
trainer/policy/mean Std                  0.699808
trainer/policy/mean Max                  0.946651
trainer/policy/mean Min                 -0.99103
trainer/policy/normal/std Mean           0.580024
trainer/policy/normal/std Std            0.0975365
trainer/policy/normal/std Max            1.07679
trainer/policy/normal/std Min            0.282725
trainer/policy/normal/log_std Mean      -0.557869
trainer/policy/normal/log_std Std        0.160238
trainer/policy/normal/log_std Max        0.0739879
trainer/policy/normal/log_std Min       -1.26328
trainer/Alpha                            0.0260918
trainer/Alpha Loss                       0.00699571
exploration/num steps total         628000
exploration/num paths total           3140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.854087
exploration/Rewards Std                  1.41327
exploration/Rewards Max                 -1.04379e-199
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -170.817
exploration/Returns Std                130.809
exploration/Returns Max                -35.6325
exploration/Returns Min               -419.183
exploration/Actions Mean                -0.421518
exploration/Actions Std                  0.718205
exploration/Actions Max                  0.997652
exploration/Actions Min                 -0.999547
exploration/Num Paths                   10
exploration/Average Returns           -170.817
evaluation/num steps total               1.50991e+06
evaluation/num paths total            7512
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.57394
evaluation/Rewards Std                   1.66781
evaluation/Rewards Max                  -3.79144e-18
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1120.36
evaluation/Returns Std                 334.26
evaluation/Returns Max                 -10.1007
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.550669
evaluation/Actions Std                   0.427707
evaluation/Actions Max                   0.642837
evaluation/Actions Min                  -0.98816
evaluation/Num Paths                    24
evaluation/Average Returns           -1120.36
time/data storing (s)                    0.0242329
time/evaluation sampling (s)            13.8657
time/exploration sampling (s)            5.06897
time/logging (s)                         0.0293077
time/sac training (s)                   32.373
time/saving (s)                          0.0341068
time/training (s)                        0.000168838
time/epoch (s)                          51.3955
time/total (s)                       43211.5
Epoch                                  312
----------------------------------  -----------------
2020-11-10 03:09:48.079652 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 313 finished
----------------------------------  ----------------
replay_buffer/size                  630000
trainer/num train calls             314000
trainer/QF1 Loss                        29.9234
trainer/QF2 Loss                        36.9051
trainer/Policy Loss                     59.6254
trainer/Q1 Predictions Mean            -59.2891
trainer/Q1 Predictions Std              83.3561
trainer/Q1 Predictions Max              52.7515
trainer/Q1 Predictions Min            -230.081
trainer/Q2 Predictions Mean            -59.1898
trainer/Q2 Predictions Std              83.1299
trainer/Q2 Predictions Max              52.9716
trainer/Q2 Predictions Min            -229.957
trainer/Q Targets Mean                 -59.7608
trainer/Q Targets Std                   84.1661
trainer/Q Targets Max                   53.6869
trainer/Q Targets Min                 -234.972
trainer/Log Pis Mean                     2.14724
trainer/Log Pis Std                      1.83172
trainer/Log Pis Max                      7.98538
trainer/Log Pis Min                     -6.41992
trainer/policy/mean Mean                -0.502735
trainer/policy/mean Std                  0.66524
trainer/policy/mean Max                  0.946369
trainer/policy/mean Min                 -0.998443
trainer/policy/normal/std Mean           0.578639
trainer/policy/normal/std Std            0.0926593
trainer/policy/normal/std Max            0.85845
trainer/policy/normal/std Min            0.226547
trainer/policy/normal/log_std Mean      -0.559293
trainer/policy/normal/log_std Std        0.155432
trainer/policy/normal/log_std Max       -0.152627
trainer/policy/normal/log_std Min       -1.4848
trainer/Alpha                            0.0260688
trainer/Alpha Loss                       0.536972
exploration/num steps total         630000
exploration/num paths total           3150
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.887826
exploration/Rewards Std                  1.40908
exploration/Rewards Max                 -2.09601e-85
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -177.565
exploration/Returns Std                128.628
exploration/Returns Max                -28.5201
exploration/Returns Min               -391.022
exploration/Actions Mean                -0.522483
exploration/Actions Std                  0.663532
exploration/Actions Max                  0.996939
exploration/Actions Min                 -0.999728
exploration/Num Paths                   10
exploration/Average Returns           -177.565
evaluation/num steps total               1.51474e+06
evaluation/num paths total            7536
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.23055
evaluation/Rewards Std                   1.10191
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1051.34
evaluation/Returns Std                 220.189
evaluation/Returns Max                -663.157
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.552475
evaluation/Actions Std                   0.495914
evaluation/Actions Max                   0.841021
evaluation/Actions Min                  -0.979603
evaluation/Num Paths                    24
evaluation/Average Returns           -1051.34
time/data storing (s)                    0.0213456
time/evaluation sampling (s)            12.2913
time/exploration sampling (s)            5.01945
time/logging (s)                         0.0613176
time/sac training (s)                   33.5121
time/saving (s)                          0.231778
time/training (s)                        0.000172754
time/epoch (s)                          51.1374
time/total (s)                       43348.5
Epoch                                  313
----------------------------------  ----------------
2020-11-10 03:12:00.538039 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 314 finished
----------------------------------  -----------------
replay_buffer/size                  632000
trainer/num train calls             315000
trainer/QF1 Loss                        57.4417
trainer/QF2 Loss                        59.9141
trainer/Policy Loss                     62.759
trainer/Q1 Predictions Mean            -62.3507
trainer/Q1 Predictions Std              84.6035
trainer/Q1 Predictions Max              64.6069
trainer/Q1 Predictions Min            -235.595
trainer/Q2 Predictions Mean            -62.2913
trainer/Q2 Predictions Std              84.4409
trainer/Q2 Predictions Max              64.5693
trainer/Q2 Predictions Min            -235.519
trainer/Q Targets Mean                 -62.2611
trainer/Q Targets Std                   84.7882
trainer/Q Targets Max                   64.423
trainer/Q Targets Min                 -236.731
trainer/Log Pis Mean                     1.97079
trainer/Log Pis Std                      1.77217
trainer/Log Pis Max                      6.04879
trainer/Log Pis Min                     -7.67524
trainer/policy/mean Mean                -0.434122
trainer/policy/mean Std                  0.697972
trainer/policy/mean Max                  0.9643
trainer/policy/mean Min                 -0.987543
trainer/policy/normal/std Mean           0.558487
trainer/policy/normal/std Std            0.0834579
trainer/policy/normal/std Max            1.03361
trainer/policy/normal/std Min            0.293617
trainer/policy/normal/log_std Mean      -0.593248
trainer/policy/normal/log_std Std        0.145997
trainer/policy/normal/log_std Max        0.0330602
trainer/policy/normal/log_std Min       -1.22548
trainer/Alpha                            0.0262225
trainer/Alpha Loss                      -0.106345
exploration/num steps total         632000
exploration/num paths total           3160
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14158
exploration/Rewards Std                  1.57854
exploration/Rewards Max                 -7.20895e-188
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -228.316
exploration/Returns Std                134.658
exploration/Returns Max                -26.4345
exploration/Returns Min               -516.345
exploration/Actions Mean                -0.365483
exploration/Actions Std                  0.748399
exploration/Actions Max                  0.99831
exploration/Actions Min                 -0.999393
exploration/Num Paths                   10
exploration/Average Returns           -228.316
evaluation/num steps total               1.51956e+06
evaluation/num paths total            7560
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.77435
evaluation/Rewards Std                   1.70762
evaluation/Rewards Max                  -1.36562e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -959.645
evaluation/Returns Std                 341.234
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.393093
evaluation/Actions Std                   0.631318
evaluation/Actions Max                   0.906797
evaluation/Actions Min                  -0.983285
evaluation/Num Paths                    24
evaluation/Average Returns            -959.645
time/data storing (s)                    0.0195433
time/evaluation sampling (s)            12.8089
time/exploration sampling (s)            4.89904
time/logging (s)                         0.0514821
time/sac training (s)                   33.0779
time/saving (s)                          0.194758
time/training (s)                        0.000156724
time/epoch (s)                          51.0517
time/total (s)                       43481
Epoch                                  314
----------------------------------  -----------------
2020-11-10 03:14:22.232474 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 315 finished
----------------------------------  -----------------
replay_buffer/size                  634000
trainer/num train calls             316000
trainer/QF1 Loss                        25.5484
trainer/QF2 Loss                        26.9981
trainer/Policy Loss                     69.7768
trainer/Q1 Predictions Mean            -69.2518
trainer/Q1 Predictions Std              86.0392
trainer/Q1 Predictions Max              51.7627
trainer/Q1 Predictions Min            -242.769
trainer/Q2 Predictions Mean            -69.1213
trainer/Q2 Predictions Std              85.9068
trainer/Q2 Predictions Max              52.0095
trainer/Q2 Predictions Min            -244.072
trainer/Q Targets Mean                 -69.8803
trainer/Q Targets Std                   87.2163
trainer/Q Targets Max                   52.1489
trainer/Q Targets Min                 -242.906
trainer/Log Pis Mean                     2.26018
trainer/Log Pis Std                      1.77209
trainer/Log Pis Max                      6.0385
trainer/Log Pis Min                     -2.97269
trainer/policy/mean Mean                -0.520055
trainer/policy/mean Std                  0.660839
trainer/policy/mean Max                  0.960139
trainer/policy/mean Min                 -0.989636
trainer/policy/normal/std Mean           0.568369
trainer/policy/normal/std Std            0.103487
trainer/policy/normal/std Max            0.922128
trainer/policy/normal/std Min            0.255099
trainer/policy/normal/log_std Mean      -0.58096
trainer/policy/normal/log_std Std        0.178323
trainer/policy/normal/log_std Max       -0.0810707
trainer/policy/normal/log_std Min       -1.3661
trainer/Alpha                            0.0259024
trainer/Alpha Loss                       0.950533
exploration/num steps total         634000
exploration/num paths total           3170
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.910159
exploration/Rewards Std                  1.45933
exploration/Rewards Max                 -1.17192e-179
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -182.032
exploration/Returns Std                141.299
exploration/Returns Max                -46.6594
exploration/Returns Min               -489.867
exploration/Actions Mean                -0.516933
exploration/Actions Std                  0.636857
exploration/Actions Max                  0.993801
exploration/Actions Min                 -0.999325
exploration/Num Paths                   10
exploration/Average Returns           -182.032
evaluation/num steps total               1.52438e+06
evaluation/num paths total            7584
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.38851
evaluation/Rewards Std                   1.07127
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.09
evaluation/Returns Std                 214.552
evaluation/Returns Max                -652.867
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.595624
evaluation/Actions Std                   0.405186
evaluation/Actions Max                   0.410688
evaluation/Actions Min                  -0.986607
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.09
time/data storing (s)                    0.0262703
time/evaluation sampling (s)            12.6165
time/exploration sampling (s)            5.12331
time/logging (s)                         0.0449627
time/sac training (s)                   33.2
time/saving (s)                          0.237485
time/training (s)                        0.000160505
time/epoch (s)                          51.2487
time/total (s)                       43622.6
Epoch                                  315
----------------------------------  -----------------
2020-11-10 03:16:50.673638 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 316 finished
----------------------------------  ----------------
replay_buffer/size                  636000
trainer/num train calls             317000
trainer/QF1 Loss                        46.2246
trainer/QF2 Loss                        40.4193
trainer/Policy Loss                     60.9151
trainer/Q1 Predictions Mean            -60.4429
trainer/Q1 Predictions Std              83.5903
trainer/Q1 Predictions Max              29.8231
trainer/Q1 Predictions Min            -242.646
trainer/Q2 Predictions Mean            -60.4633
trainer/Q2 Predictions Std              83.6409
trainer/Q2 Predictions Max              30.5204
trainer/Q2 Predictions Min            -243.948
trainer/Q Targets Mean                 -60.8123
trainer/Q Targets Std                   83.8324
trainer/Q Targets Max                   30.1755
trainer/Q Targets Min                 -242.823
trainer/Log Pis Mean                     2.08047
trainer/Log Pis Std                      1.88471
trainer/Log Pis Max                      6.68726
trainer/Log Pis Min                     -5.21984
trainer/policy/mean Mean                -0.630595
trainer/policy/mean Std                  0.568865
trainer/policy/mean Max                  0.929462
trainer/policy/mean Min                 -0.998756
trainer/policy/normal/std Mean           0.572796
trainer/policy/normal/std Std            0.101852
trainer/policy/normal/std Max            0.874499
trainer/policy/normal/std Min            0.214818
trainer/policy/normal/log_std Mean      -0.573431
trainer/policy/normal/log_std Std        0.183377
trainer/policy/normal/log_std Max       -0.134105
trainer/policy/normal/log_std Min       -1.53797
trainer/Alpha                            0.0261565
trainer/Alpha Loss                       0.293202
exploration/num steps total         636000
exploration/num paths total           3180
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.20384
exploration/Rewards Std                  1.59162
exploration/Rewards Max                 -1.29916e-42
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -240.768
exploration/Returns Std                152.207
exploration/Returns Max                -69.3784
exploration/Returns Min               -501.351
exploration/Actions Mean                -0.565687
exploration/Actions Std                  0.640024
exploration/Actions Max                  0.989595
exploration/Actions Min                 -0.999453
exploration/Num Paths                   10
exploration/Average Returns           -240.768
evaluation/num steps total               1.52921e+06
evaluation/num paths total            7608
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -3.88496
evaluation/Rewards Std                   1.30734
evaluation/Rewards Max                  -4.38768e-12
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -780.878
evaluation/Returns Std                 251.809
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1039.47
evaluation/Actions Mean                 -0.53281
evaluation/Actions Std                   0.550995
evaluation/Actions Max                   0.737419
evaluation/Actions Min                  -0.981747
evaluation/Num Paths                    24
evaluation/Average Returns            -780.878
time/data storing (s)                    0.0202523
time/evaluation sampling (s)            13.0214
time/exploration sampling (s)            5.48483
time/logging (s)                         0.0493822
time/sac training (s)                   33.2288
time/saving (s)                          0.0891648
time/training (s)                        0.000146349
time/epoch (s)                          51.8939
time/total (s)                       43771
Epoch                                  316
----------------------------------  ----------------
2020-11-10 03:19:19.334515 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 317 finished
----------------------------------  ----------------
replay_buffer/size                  638000
trainer/num train calls             318000
trainer/QF1 Loss                        78.4142
trainer/QF2 Loss                        84.3128
trainer/Policy Loss                     52.9713
trainer/Q1 Predictions Mean            -52.5948
trainer/Q1 Predictions Std              81.0564
trainer/Q1 Predictions Max              53.9568
trainer/Q1 Predictions Min            -242.361
trainer/Q2 Predictions Mean            -52.6122
trainer/Q2 Predictions Std              81.1481
trainer/Q2 Predictions Max              54.02
trainer/Q2 Predictions Min            -243.626
trainer/Q Targets Mean                 -52.5334
trainer/Q Targets Std                   81.3196
trainer/Q Targets Max                   53.5058
trainer/Q Targets Min                 -242.627
trainer/Log Pis Mean                     1.83383
trainer/Log Pis Std                      1.87829
trainer/Log Pis Max                      6.19862
trainer/Log Pis Min                     -5.76814
trainer/policy/mean Mean                -0.579235
trainer/policy/mean Std                  0.611803
trainer/policy/mean Max                  0.950115
trainer/policy/mean Min                 -0.98838
trainer/policy/normal/std Mean           0.573174
trainer/policy/normal/std Std            0.0912405
trainer/policy/normal/std Max            0.867245
trainer/policy/normal/std Min            0.294246
trainer/policy/normal/log_std Mean      -0.568488
trainer/policy/normal/log_std Std        0.152939
trainer/policy/normal/log_std Max       -0.142434
trainer/policy/normal/log_std Min       -1.22334
trainer/Alpha                            0.0260537
trainer/Alpha Loss                      -0.606107
exploration/num steps total         638000
exploration/num paths total           3190
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.05267
exploration/Rewards Std                  1.64829
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -210.535
exploration/Returns Std                132.442
exploration/Returns Max                -37.6583
exploration/Returns Min               -482.078
exploration/Actions Mean                -0.547766
exploration/Actions Std                  0.632482
exploration/Actions Max                  0.99561
exploration/Actions Min                 -0.998908
exploration/Num Paths                   10
exploration/Average Returns           -210.535
evaluation/num steps total               1.53403e+06
evaluation/num paths total            7632
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84381
evaluation/Rewards Std                   0.767927
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1174.61
evaluation/Returns Std                 154.352
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.755933
evaluation/Actions Std                   0.300812
evaluation/Actions Max                   0.514719
evaluation/Actions Min                  -0.973368
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.61
time/data storing (s)                    0.020917
time/evaluation sampling (s)            12.9632
time/exploration sampling (s)            4.92524
time/logging (s)                         0.0581488
time/sac training (s)                   32.8962
time/saving (s)                          0.536535
time/training (s)                        0.000115848
time/epoch (s)                          51.4003
time/total (s)                       43919.6
Epoch                                  317
----------------------------------  ----------------
2020-11-10 03:21:39.209138 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 318 finished
----------------------------------  -----------------
replay_buffer/size                  640000
trainer/num train calls             319000
trainer/QF1 Loss                        18.8831
trainer/QF2 Loss                        21.3981
trainer/Policy Loss                     54.3647
trainer/Q1 Predictions Mean            -54.0585
trainer/Q1 Predictions Std              82.9052
trainer/Q1 Predictions Max              52.3266
trainer/Q1 Predictions Min            -241.412
trainer/Q2 Predictions Mean            -53.9114
trainer/Q2 Predictions Std              82.9068
trainer/Q2 Predictions Max              52.3907
trainer/Q2 Predictions Min            -242.954
trainer/Q Targets Mean                 -54.8853
trainer/Q Targets Std                   83.5702
trainer/Q Targets Max                   52.0887
trainer/Q Targets Min                 -242.478
trainer/Log Pis Mean                     2.35996
trainer/Log Pis Std                      1.80811
trainer/Log Pis Max                      6.53406
trainer/Log Pis Min                     -4.95631
trainer/policy/mean Mean                -0.528692
trainer/policy/mean Std                  0.650133
trainer/policy/mean Max                  0.954082
trainer/policy/mean Min                 -0.990203
trainer/policy/normal/std Mean           0.564296
trainer/policy/normal/std Std            0.0946109
trainer/policy/normal/std Max            0.851903
trainer/policy/normal/std Min            0.211516
trainer/policy/normal/log_std Mean      -0.586567
trainer/policy/normal/log_std Std        0.172694
trainer/policy/normal/log_std Max       -0.160283
trainer/policy/normal/log_std Min       -1.55345
trainer/Alpha                            0.0264903
trainer/Alpha Loss                       1.307
exploration/num steps total         640000
exploration/num paths total           3200
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.941967
exploration/Rewards Std                  1.53168
exploration/Rewards Max                 -9.48994e-121
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.393
exploration/Returns Std                 98.3894
exploration/Returns Max                -35.9663
exploration/Returns Min               -334.337
exploration/Actions Mean                -0.490471
exploration/Actions Std                  0.603938
exploration/Actions Max                  0.994665
exploration/Actions Min                 -0.998724
exploration/Num Paths                   10
exploration/Average Returns           -188.393
evaluation/num steps total               1.53886e+06
evaluation/num paths total            7656
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.26628
evaluation/Rewards Std                   1.02848
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1058.52
evaluation/Returns Std                 204.242
evaluation/Returns Max                -658.035
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.595558
evaluation/Actions Std                   0.395252
evaluation/Actions Max                   0.481482
evaluation/Actions Min                  -0.979758
evaluation/Num Paths                    24
evaluation/Average Returns           -1058.52
time/data storing (s)                    0.0206441
time/evaluation sampling (s)            13.1753
time/exploration sampling (s)            4.96337
time/logging (s)                         0.0717661
time/sac training (s)                   32.7467
time/saving (s)                          0.458875
time/training (s)                        0.000164199
time/epoch (s)                          51.4368
time/total (s)                       44059.5
Epoch                                  318
----------------------------------  -----------------
2020-11-10 03:23:53.596058 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 319 finished
----------------------------------  ----------------
replay_buffer/size                  642000
trainer/num train calls             320000
trainer/QF1 Loss                        27.3808
trainer/QF2 Loss                        35.4892
trainer/Policy Loss                     74.3499
trainer/Q1 Predictions Mean            -73.7703
trainer/Q1 Predictions Std              88.6627
trainer/Q1 Predictions Max              34.7357
trainer/Q1 Predictions Min            -235.526
trainer/Q2 Predictions Mean            -73.9938
trainer/Q2 Predictions Std              88.9454
trainer/Q2 Predictions Max              35.0187
trainer/Q2 Predictions Min            -237.765
trainer/Q Targets Mean                 -74.4309
trainer/Q Targets Std                   89.3488
trainer/Q Targets Max                   34.9603
trainer/Q Targets Min                 -239.086
trainer/Log Pis Mean                     1.93521
trainer/Log Pis Std                      1.74851
trainer/Log Pis Max                      6.32697
trainer/Log Pis Min                     -2.85925
trainer/policy/mean Mean                -0.381286
trainer/policy/mean Std                  0.728101
trainer/policy/mean Max                  0.968671
trainer/policy/mean Min                 -0.990011
trainer/policy/normal/std Mean           0.569971
trainer/policy/normal/std Std            0.0900426
trainer/policy/normal/std Max            0.823581
trainer/policy/normal/std Min            0.254598
trainer/policy/normal/log_std Mean      -0.57453
trainer/policy/normal/log_std Std        0.157997
trainer/policy/normal/log_std Max       -0.194094
trainer/policy/normal/log_std Min       -1.36807
trainer/Alpha                            0.0262949
trainer/Alpha Loss                      -0.235733
exploration/num steps total         642000
exploration/num paths total           3210
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.3422
exploration/Rewards Std                  1.35064
exploration/Rewards Max                 -2.37735e-70
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -268.441
exploration/Returns Std                109.378
exploration/Returns Max               -111.631
exploration/Returns Min               -451.357
exploration/Actions Mean                -0.372984
exploration/Actions Std                  0.773705
exploration/Actions Max                  0.997682
exploration/Actions Min                 -0.999791
exploration/Num Paths                   10
exploration/Average Returns           -268.441
evaluation/num steps total               1.54368e+06
evaluation/num paths total            7680
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.34042
evaluation/Rewards Std                   1.15672
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1073.42
evaluation/Returns Std                 231.96
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.436751
evaluation/Actions Std                   0.593033
evaluation/Actions Max                   0.807477
evaluation/Actions Min                  -0.976159
evaluation/Num Paths                    24
evaluation/Average Returns           -1073.42
time/data storing (s)                    0.0201263
time/evaluation sampling (s)            12.5824
time/exploration sampling (s)            5.01673
time/logging (s)                         0.0871225
time/sac training (s)                   32.3716
time/saving (s)                          0.26932
time/training (s)                        0.000124833
time/epoch (s)                          50.3474
time/total (s)                       44193.9
Epoch                                  319
----------------------------------  ----------------
2020-11-10 03:26:12.410196 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 320 finished
----------------------------------  -----------------
replay_buffer/size                  644000
trainer/num train calls             321000
trainer/QF1 Loss                        99.9597
trainer/QF2 Loss                        96.9226
trainer/Policy Loss                     64.7055
trainer/Q1 Predictions Mean            -64.2937
trainer/Q1 Predictions Std              82.6853
trainer/Q1 Predictions Max              46.5392
trainer/Q1 Predictions Min            -237.486
trainer/Q2 Predictions Mean            -64.2765
trainer/Q2 Predictions Std              82.87
trainer/Q2 Predictions Max              46.6971
trainer/Q2 Predictions Min            -237.903
trainer/Q Targets Mean                 -64.6001
trainer/Q Targets Std                   83.75
trainer/Q Targets Max                   46.3435
trainer/Q Targets Min                 -239.697
trainer/Log Pis Mean                     2.17779
trainer/Log Pis Std                      1.73534
trainer/Log Pis Max                      6.55646
trainer/Log Pis Min                     -3.5804
trainer/policy/mean Mean                -0.539083
trainer/policy/mean Std                  0.64111
trainer/policy/mean Max                  0.956629
trainer/policy/mean Min                 -0.998243
trainer/policy/normal/std Mean           0.57338
trainer/policy/normal/std Std            0.0969125
trainer/policy/normal/std Max            0.856036
trainer/policy/normal/std Min            0.210145
trainer/policy/normal/log_std Mean      -0.570465
trainer/policy/normal/log_std Std        0.170509
trainer/policy/normal/log_std Max       -0.155443
trainer/policy/normal/log_std Min       -1.55996
trainer/Alpha                            0.0264127
trainer/Alpha Loss                       0.646069
exploration/num steps total         644000
exploration/num paths total           3220
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.00608
exploration/Rewards Std                  1.4961
exploration/Rewards Max                 -2.16611e-100
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -201.215
exploration/Returns Std                159.412
exploration/Returns Max                -37.194
exploration/Returns Min               -480.527
exploration/Actions Mean                -0.404805
exploration/Actions Std                  0.69925
exploration/Actions Max                  0.995934
exploration/Actions Min                 -0.999321
exploration/Num Paths                   10
exploration/Average Returns           -201.215
evaluation/num steps total               1.5485e+06
evaluation/num paths total            7704
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95804
evaluation/Rewards Std                   0.562606
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.57
evaluation/Returns Std                 113.082
evaluation/Returns Max                -655.242
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.785124
evaluation/Actions Std                   0.23811
evaluation/Actions Max                   0.759856
evaluation/Actions Min                  -0.978428
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.57
time/data storing (s)                    0.0202264
time/evaluation sampling (s)            14.5959
time/exploration sampling (s)            5.13847
time/logging (s)                         0.0449595
time/sac training (s)                   32.7211
time/saving (s)                          0.0874371
time/training (s)                        0.000165143
time/epoch (s)                          52.6083
time/total (s)                       44332.6
Epoch                                  320
----------------------------------  -----------------
2020-11-10 03:28:36.190509 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 321 finished
----------------------------------  ----------------
replay_buffer/size                  646000
trainer/num train calls             322000
trainer/QF1 Loss                        12.3132
trainer/QF2 Loss                        11.9286
trainer/Policy Loss                     70.3375
trainer/Q1 Predictions Mean            -69.9172
trainer/Q1 Predictions Std              90.7019
trainer/Q1 Predictions Max              47.9423
trainer/Q1 Predictions Min            -267.493
trainer/Q2 Predictions Mean            -69.883
trainer/Q2 Predictions Std              90.7665
trainer/Q2 Predictions Max              47.7274
trainer/Q2 Predictions Min            -266.209
trainer/Q Targets Mean                 -70.9001
trainer/Q Targets Std                   91.9456
trainer/Q Targets Max                   47.7466
trainer/Q Targets Min                 -266.274
trainer/Log Pis Mean                     2.21171
trainer/Log Pis Std                      1.6606
trainer/Log Pis Max                      6.12437
trainer/Log Pis Min                     -3.30409
trainer/policy/mean Mean                -0.478876
trainer/policy/mean Std                  0.678541
trainer/policy/mean Max                  0.961356
trainer/policy/mean Min                 -0.992778
trainer/policy/normal/std Mean           0.56744
trainer/policy/normal/std Std            0.0979292
trainer/policy/normal/std Max            0.866639
trainer/policy/normal/std Min            0.255281
trainer/policy/normal/log_std Mean      -0.581248
trainer/policy/normal/log_std Std        0.171591
trainer/policy/normal/log_std Max       -0.143132
trainer/policy/normal/log_std Min       -1.36539
trainer/Alpha                            0.0267803
trainer/Alpha Loss                       0.766421
exploration/num steps total         646000
exploration/num paths total           3230
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.24453
exploration/Rewards Std                  1.56176
exploration/Rewards Max                 -2.87346e-66
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -248.907
exploration/Returns Std                157.297
exploration/Returns Max                -18.7097
exploration/Returns Min               -466.792
exploration/Actions Mean                -0.580894
exploration/Actions Std                  0.60088
exploration/Actions Max                  0.98683
exploration/Actions Min                 -0.999635
exploration/Num Paths                   10
exploration/Average Returns           -248.907
evaluation/num steps total               1.55333e+06
evaluation/num paths total            7728
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.64715
evaluation/Rewards Std                   1.28773
evaluation/Rewards Max                  -5.34776e-22
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1135.08
evaluation/Returns Std                 258.647
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.588258
evaluation/Actions Std                   0.410278
evaluation/Actions Max                  -0.143686
evaluation/Actions Min                  -0.985806
evaluation/Num Paths                    24
evaluation/Average Returns           -1135.08
time/data storing (s)                    0.0193803
time/evaluation sampling (s)            12.7647
time/exploration sampling (s)            4.9773
time/logging (s)                         0.0838901
time/sac training (s)                   33.068
time/saving (s)                          0.322447
time/training (s)                        0.00016002
time/epoch (s)                          51.2358
time/total (s)                       44476.4
Epoch                                  321
----------------------------------  ----------------
2020-11-10 03:31:05.084334 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 322 finished
----------------------------------  -----------------
replay_buffer/size                  648000
trainer/num train calls             323000
trainer/QF1 Loss                       188.345
trainer/QF2 Loss                       191.388
trainer/Policy Loss                     65.4129
trainer/Q1 Predictions Mean            -64.8785
trainer/Q1 Predictions Std              86.3951
trainer/Q1 Predictions Max              28.9269
trainer/Q1 Predictions Min            -227.147
trainer/Q2 Predictions Mean            -64.9767
trainer/Q2 Predictions Std              86.4921
trainer/Q2 Predictions Max              29.0724
trainer/Q2 Predictions Min            -226.663
trainer/Q Targets Mean                 -63.8972
trainer/Q Targets Std                   85.873
trainer/Q Targets Max                   28.6975
trainer/Q Targets Min                 -230.295
trainer/Log Pis Mean                     1.82032
trainer/Log Pis Std                      1.65963
trainer/Log Pis Max                      5.3029
trainer/Log Pis Min                     -4.58026
trainer/policy/mean Mean                -0.458329
trainer/policy/mean Std                  0.676602
trainer/policy/mean Max                  0.966522
trainer/policy/mean Min                 -0.985849
trainer/policy/normal/std Mean           0.589908
trainer/policy/normal/std Std            0.0991034
trainer/policy/normal/std Max            0.931108
trainer/policy/normal/std Min            0.292325
trainer/policy/normal/log_std Mean      -0.540935
trainer/policy/normal/log_std Std        0.16005
trainer/policy/normal/log_std Max       -0.0713802
trainer/policy/normal/log_std Min       -1.22989
trainer/Alpha                            0.0268083
trainer/Alpha Loss                      -0.650259
exploration/num steps total         648000
exploration/num paths total           3240
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.555058
exploration/Rewards Std                  1.32677
exploration/Rewards Max                 -1.16685e-202
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -111.012
exploration/Returns Std                 63.459
exploration/Returns Max                -48.9304
exploration/Returns Min               -256.195
exploration/Actions Mean                -0.515961
exploration/Actions Std                  0.634918
exploration/Actions Max                  0.995596
exploration/Actions Min                 -0.99925
exploration/Num Paths                   10
exploration/Average Returns           -111.012
evaluation/num steps total               1.55815e+06
evaluation/num paths total            7752
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   6.18702e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   8.64568e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.635255
evaluation/Actions Std                   0.335639
evaluation/Actions Max                  -0.299514
evaluation/Actions Min                  -0.971326
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0210859
time/evaluation sampling (s)            12.7165
time/exploration sampling (s)            4.8591
time/logging (s)                         0.0772671
time/sac training (s)                   33.3123
time/saving (s)                          0.332439
time/training (s)                        0.000139641
time/epoch (s)                          51.3189
time/total (s)                       44625.2
Epoch                                  322
----------------------------------  -----------------
2020-11-10 03:33:29.350549 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 323 finished
----------------------------------  -----------------
replay_buffer/size                  650000
trainer/num train calls             324000
trainer/QF1 Loss                        34.042
trainer/QF2 Loss                        32.337
trainer/Policy Loss                     65.33
trainer/Q1 Predictions Mean            -64.8567
trainer/Q1 Predictions Std              83.7493
trainer/Q1 Predictions Max              41.3622
trainer/Q1 Predictions Min            -241.844
trainer/Q2 Predictions Mean            -64.8187
trainer/Q2 Predictions Std              83.9519
trainer/Q2 Predictions Max              41.6995
trainer/Q2 Predictions Min            -243.05
trainer/Q Targets Mean                 -65.1129
trainer/Q Targets Std                   84.49
trainer/Q Targets Max                   49.682
trainer/Q Targets Min                 -241.848
trainer/Log Pis Mean                     1.81933
trainer/Log Pis Std                      1.61265
trainer/Log Pis Max                      6.8757
trainer/Log Pis Min                     -4.32597
trainer/policy/mean Mean                -0.395099
trainer/policy/mean Std                  0.720313
trainer/policy/mean Max                  0.967441
trainer/policy/mean Min                 -0.986542
trainer/policy/normal/std Mean           0.568874
trainer/policy/normal/std Std            0.0851527
trainer/policy/normal/std Max            0.848762
trainer/policy/normal/std Min            0.30021
trainer/policy/normal/log_std Mean      -0.574495
trainer/policy/normal/log_std Std        0.141988
trainer/policy/normal/log_std Max       -0.163976
trainer/policy/normal/log_std Min       -1.20327
trainer/Alpha                            0.0260919
trainer/Alpha Loss                      -0.658734
exploration/num steps total         650000
exploration/num paths total           3250
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.732872
exploration/Rewards Std                  1.33717
exploration/Rewards Max                 -9.77198e-106
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -146.574
exploration/Returns Std                 92.0415
exploration/Returns Max                -29.2781
exploration/Returns Min               -362.921
exploration/Actions Mean                -0.511538
exploration/Actions Std                  0.64944
exploration/Actions Max                  0.998608
exploration/Actions Min                 -0.999096
exploration/Num Paths                   10
exploration/Average Returns           -146.574
evaluation/num steps total               1.56298e+06
evaluation/num paths total            7776
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.38892
evaluation/Rewards Std                   1.07239
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.17
evaluation/Returns Std                 214.354
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.35509
evaluation/Actions Std                   0.639394
evaluation/Actions Max                   0.698454
evaluation/Actions Min                  -0.978299
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.17
time/data storing (s)                    0.0199723
time/evaluation sampling (s)            12.7326
time/exploration sampling (s)            5.00834
time/logging (s)                         0.0408447
time/sac training (s)                   32.905
time/saving (s)                          0.138568
time/training (s)                        0.000152664
time/epoch (s)                          50.8455
time/total (s)                       44769.4
Epoch                                  323
----------------------------------  -----------------
2020-11-10 03:35:47.552311 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 324 finished
----------------------------------  ----------------
replay_buffer/size                  652000
trainer/num train calls             325000
trainer/QF1 Loss                       196.132
trainer/QF2 Loss                       187.109
trainer/Policy Loss                     57.2546
trainer/Q1 Predictions Mean            -56.8651
trainer/Q1 Predictions Std              83.3473
trainer/Q1 Predictions Max              45.194
trainer/Q1 Predictions Min            -266.12
trainer/Q2 Predictions Mean            -56.8643
trainer/Q2 Predictions Std              83.2906
trainer/Q2 Predictions Max              45.0149
trainer/Q2 Predictions Min            -265.094
trainer/Q Targets Mean                 -56.5311
trainer/Q Targets Std                   84.1996
trainer/Q Targets Max                   44.725
trainer/Q Targets Min                 -265.173
trainer/Log Pis Mean                     2.02566
trainer/Log Pis Std                      1.53021
trainer/Log Pis Max                      5.22205
trainer/Log Pis Min                     -3.24896
trainer/policy/mean Mean                -0.424109
trainer/policy/mean Std                  0.702516
trainer/policy/mean Max                  0.958956
trainer/policy/mean Min                 -0.986288
trainer/policy/normal/std Mean           0.585911
trainer/policy/normal/std Std            0.108396
trainer/policy/normal/std Max            1.1208
trainer/policy/normal/std Min            0.22023
trainer/policy/normal/log_std Mean      -0.551073
trainer/policy/normal/log_std Std        0.181671
trainer/policy/normal/log_std Max        0.114044
trainer/policy/normal/log_std Min       -1.51308
trainer/Alpha                            0.0260363
trainer/Alpha Loss                       0.0936238
exploration/num steps total         652000
exploration/num paths total           3260
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.48519
exploration/Rewards Std                  1.49491
exploration/Rewards Max                 -6.15786e-92
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -297.038
exploration/Returns Std                107.951
exploration/Returns Max               -117.568
exploration/Returns Min               -496.199
exploration/Actions Mean                -0.392861
exploration/Actions Std                  0.726511
exploration/Actions Max                  0.998244
exploration/Actions Min                 -0.999941
exploration/Num Paths                   10
exploration/Average Returns           -297.038
evaluation/num steps total               1.5678e+06
evaluation/num paths total            7800
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.55437e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.561583
evaluation/Actions Std                   0.413597
evaluation/Actions Max                  -0.147747
evaluation/Actions Min                  -0.975746
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0210973
time/evaluation sampling (s)            12.4692
time/exploration sampling (s)            5.11098
time/logging (s)                         0.0530671
time/sac training (s)                   32.9453
time/saving (s)                          0.169142
time/training (s)                        0.000163453
time/epoch (s)                          50.7689
time/total (s)                       44907.6
Epoch                                  324
----------------------------------  ----------------
2020-11-10 03:38:13.736631 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 325 finished
----------------------------------  -----------------
replay_buffer/size                  654000
trainer/num train calls             326000
trainer/QF1 Loss                        60.1484
trainer/QF2 Loss                        62.1752
trainer/Policy Loss                     54.961
trainer/Q1 Predictions Mean            -54.4921
trainer/Q1 Predictions Std              80.8845
trainer/Q1 Predictions Max              42.4259
trainer/Q1 Predictions Min            -234.917
trainer/Q2 Predictions Mean            -54.4817
trainer/Q2 Predictions Std              80.9788
trainer/Q2 Predictions Max              42.8589
trainer/Q2 Predictions Min            -233.979
trainer/Q Targets Mean                 -54.7818
trainer/Q Targets Std                   81.4161
trainer/Q Targets Max                   41.9287
trainer/Q Targets Min                 -235.687
trainer/Log Pis Mean                     1.46967
trainer/Log Pis Std                      1.67785
trainer/Log Pis Max                      5.67349
trainer/Log Pis Min                     -7.63881
trainer/policy/mean Mean                -0.41106
trainer/policy/mean Std                  0.705399
trainer/policy/mean Max                  0.958391
trainer/policy/mean Min                 -0.982491
trainer/policy/normal/std Mean           0.581115
trainer/policy/normal/std Std            0.088525
trainer/policy/normal/std Max            0.883665
trainer/policy/normal/std Min            0.265662
trainer/policy/normal/log_std Mean      -0.553973
trainer/policy/normal/log_std Std        0.149137
trainer/policy/normal/log_std Max       -0.123677
trainer/policy/normal/log_std Min       -1.32553
trainer/Alpha                            0.0255998
trainer/Alpha Loss                      -1.94376
exploration/num steps total         654000
exploration/num paths total           3270
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.06599
exploration/Rewards Std                  1.39665
exploration/Rewards Max                 -5.72826e-208
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -213.197
exploration/Returns Std                169.76
exploration/Returns Max                -44.3269
exploration/Returns Min               -497.47
exploration/Actions Mean                -0.362894
exploration/Actions Std                  0.749789
exploration/Actions Max                  0.997645
exploration/Actions Min                 -0.999798
exploration/Num Paths                   10
exploration/Average Returns           -213.197
evaluation/num steps total               1.57262e+06
evaluation/num paths total            7824
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.64462
evaluation/Rewards Std                   1.29118
evaluation/Rewards Max                  -4.1963e-15
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1134.57
evaluation/Returns Std                 258.856
evaluation/Returns Max                 -10.1007
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.5377
evaluation/Actions Std                   0.429507
evaluation/Actions Max                   0.496643
evaluation/Actions Min                  -0.968423
evaluation/Num Paths                    24
evaluation/Average Returns           -1134.57
time/data storing (s)                    0.0242072
time/evaluation sampling (s)            13.1285
time/exploration sampling (s)            5.53839
time/logging (s)                         0.0822277
time/sac training (s)                   32.255
time/saving (s)                          0.204778
time/training (s)                        0.000173874
time/epoch (s)                          51.2333
time/total (s)                       45053.8
Epoch                                  325
----------------------------------  -----------------
2020-11-10 03:40:48.819856 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 326 finished
----------------------------------  -----------------
replay_buffer/size                  656000
trainer/num train calls             327000
trainer/QF1 Loss                         9.20963
trainer/QF2 Loss                         8.5448
trainer/Policy Loss                     71.3615
trainer/Q1 Predictions Mean            -70.8649
trainer/Q1 Predictions Std              89.7126
trainer/Q1 Predictions Max              50.0471
trainer/Q1 Predictions Min            -231.638
trainer/Q2 Predictions Mean            -70.8279
trainer/Q2 Predictions Std              89.8025
trainer/Q2 Predictions Max              50.4459
trainer/Q2 Predictions Min            -230.591
trainer/Q Targets Mean                 -72.0339
trainer/Q Targets Std                   91.1002
trainer/Q Targets Max                   50.0425
trainer/Q Targets Min                 -234.539
trainer/Log Pis Mean                     1.66394
trainer/Log Pis Std                      1.76751
trainer/Log Pis Max                      6.8529
trainer/Log Pis Min                     -2.72372
trainer/policy/mean Mean                -0.546404
trainer/policy/mean Std                  0.61351
trainer/policy/mean Max                  0.946961
trainer/policy/mean Min                 -0.991248
trainer/policy/normal/std Mean           0.579076
trainer/policy/normal/std Std            0.101449
trainer/policy/normal/std Max            0.907136
trainer/policy/normal/std Min            0.351906
trainer/policy/normal/log_std Mean      -0.56039
trainer/policy/normal/log_std Std        0.164745
trainer/policy/normal/log_std Max       -0.0974625
trainer/policy/normal/log_std Min       -1.04439
trainer/Alpha                            0.0246794
trainer/Alpha Loss                      -1.24404
exploration/num steps total         656000
exploration/num paths total           3280
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.628158
exploration/Rewards Std                  1.44945
exploration/Rewards Max                 -6.67034e-194
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -125.632
exploration/Returns Std                 62.3733
exploration/Returns Max                -52.0793
exploration/Returns Min               -244.128
exploration/Actions Mean                -0.467381
exploration/Actions Std                  0.648538
exploration/Actions Max                  0.996787
exploration/Actions Min                 -0.998547
exploration/Num Paths                   10
exploration/Average Returns           -125.632
evaluation/num steps total               1.57745e+06
evaluation/num paths total            7848
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.19918
evaluation/Rewards Std                   1.43022
evaluation/Rewards Max                  -9.22771e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1045.03
evaluation/Returns Std                 285.507
evaluation/Returns Max                 -21.9678
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.603301
evaluation/Actions Std                   0.419566
evaluation/Actions Max                   0.585931
evaluation/Actions Min                  -0.974841
evaluation/Num Paths                    24
evaluation/Average Returns           -1045.03
time/data storing (s)                    0.0201579
time/evaluation sampling (s)            14.4834
time/exploration sampling (s)            6.46224
time/logging (s)                         0.0366621
time/sac training (s)                   32.5143
time/saving (s)                          0.153675
time/training (s)                        0.000176568
time/epoch (s)                          53.6706
time/total (s)                       45208.8
Epoch                                  326
----------------------------------  -----------------
2020-11-10 03:44:09.394295 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 327 finished
----------------------------------  -----------------
replay_buffer/size                  658000
trainer/num train calls             328000
trainer/QF1 Loss                        63.9615
trainer/QF2 Loss                        66.5365
trainer/Policy Loss                     70.4918
trainer/Q1 Predictions Mean            -70.0303
trainer/Q1 Predictions Std              88.4744
trainer/Q1 Predictions Max              41.1425
trainer/Q1 Predictions Min            -240.311
trainer/Q2 Predictions Mean            -70.0471
trainer/Q2 Predictions Std              88.5036
trainer/Q2 Predictions Max              40.8044
trainer/Q2 Predictions Min            -241.559
trainer/Q Targets Mean                 -70.2272
trainer/Q Targets Std                   89.2212
trainer/Q Targets Max                   41.1344
trainer/Q Targets Min                 -240.581
trainer/Log Pis Mean                     1.94848
trainer/Log Pis Std                      1.82278
trainer/Log Pis Max                      6.77882
trainer/Log Pis Min                     -3.06056
trainer/policy/mean Mean                -0.625054
trainer/policy/mean Std                  0.563407
trainer/policy/mean Max                  0.924041
trainer/policy/mean Min                 -0.993031
trainer/policy/normal/std Mean           0.581135
trainer/policy/normal/std Std            0.108369
trainer/policy/normal/std Max            0.926093
trainer/policy/normal/std Min            0.26747
trainer/policy/normal/log_std Mean      -0.559229
trainer/policy/normal/log_std Std        0.179929
trainer/policy/normal/log_std Max       -0.076781
trainer/policy/normal/log_std Min       -1.31875
trainer/Alpha                            0.0246665
trainer/Alpha Loss                      -0.190737
exploration/num steps total         658000
exploration/num paths total           3290
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.77916
exploration/Rewards Std                  1.48233
exploration/Rewards Max                 -5.61727e-163
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -155.832
exploration/Returns Std                 97.9495
exploration/Returns Max                -30.3544
exploration/Returns Min               -367.46
exploration/Actions Mean                -0.478394
exploration/Actions Std                  0.67185
exploration/Actions Max                  0.997113
exploration/Actions Min                 -0.999221
exploration/Num Paths                   10
exploration/Average Returns           -155.832
evaluation/num steps total               1.58227e+06
evaluation/num paths total            7872
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.45239
evaluation/Rewards Std                   1.08414
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1095.93
evaluation/Returns Std                 217.189
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.719239
evaluation/Actions Std                   0.379766
evaluation/Actions Max                   0.315166
evaluation/Actions Min                  -0.978915
evaluation/Num Paths                    24
evaluation/Average Returns           -1095.93
time/data storing (s)                    0.0200633
time/evaluation sampling (s)            12.5866
time/exploration sampling (s)            5.00318
time/logging (s)                         0.0731804
time/sac training (s)                   33.6493
time/saving (s)                          0.31941
time/training (s)                        0.000130569
time/epoch (s)                          51.6518
time/total (s)                       45409.3
Epoch                                  327
----------------------------------  -----------------
2020-11-10 03:47:08.892713 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 328 finished
----------------------------------  -----------------
replay_buffer/size                  660000
trainer/num train calls             329000
trainer/QF1 Loss                       117.214
trainer/QF2 Loss                       119.888
trainer/Policy Loss                     68.5034
trainer/Q1 Predictions Mean            -68.0654
trainer/Q1 Predictions Std              85.7381
trainer/Q1 Predictions Max              49.9637
trainer/Q1 Predictions Min            -231.475
trainer/Q2 Predictions Mean            -68.0086
trainer/Q2 Predictions Std              85.7113
trainer/Q2 Predictions Max              50.2662
trainer/Q2 Predictions Min            -229.441
trainer/Q Targets Mean                 -67.7823
trainer/Q Targets Std                   85.6396
trainer/Q Targets Max                   50.0245
trainer/Q Targets Min                 -233.891
trainer/Log Pis Mean                     1.98018
trainer/Log Pis Std                      1.70927
trainer/Log Pis Max                      5.83754
trainer/Log Pis Min                     -4.57856
trainer/policy/mean Mean                -0.435764
trainer/policy/mean Std                  0.696952
trainer/policy/mean Max                  0.967217
trainer/policy/mean Min                 -0.989599
trainer/policy/normal/std Mean           0.562233
trainer/policy/normal/std Std            0.0914696
trainer/policy/normal/std Max            0.82932
trainer/policy/normal/std Min            0.187646
trainer/policy/normal/log_std Mean      -0.589691
trainer/policy/normal/log_std Std        0.170584
trainer/policy/normal/log_std Max       -0.187149
trainer/policy/normal/log_std Min       -1.6732
trainer/Alpha                            0.0247951
trainer/Alpha Loss                      -0.0732793
exploration/num steps total         660000
exploration/num paths total           3300
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.27525
exploration/Rewards Std                  1.553
exploration/Rewards Max                 -1.24833e-222
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -255.051
exploration/Returns Std                187.603
exploration/Returns Max                -41.0126
exploration/Returns Min               -570.351
exploration/Actions Mean                -0.263576
exploration/Actions Std                  0.775997
exploration/Actions Max                  0.998842
exploration/Actions Min                 -0.999211
exploration/Num Paths                   10
exploration/Average Returns           -255.051
evaluation/num steps total               1.5871e+06
evaluation/num paths total            7896
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.07769
evaluation/Rewards Std                   1.57508
evaluation/Rewards Max                  -2.96284e-26
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1020.62
evaluation/Returns Std                 315.598
evaluation/Returns Max                 -13.3965
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.475361
evaluation/Actions Std                   0.527202
evaluation/Actions Max                   0.628755
evaluation/Actions Min                  -0.980033
evaluation/Num Paths                    24
evaluation/Average Returns           -1020.62
time/data storing (s)                    0.0246205
time/evaluation sampling (s)            12.8707
time/exploration sampling (s)            5.10076
time/logging (s)                         0.0607355
time/sac training (s)                   33.013
time/saving (s)                          0.196105
time/training (s)                        0.000149274
time/epoch (s)                          51.2661
time/total (s)                       45588.8
Epoch                                  328
----------------------------------  -----------------
2020-11-10 03:49:58.025493 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 329 finished
----------------------------------  ----------------
replay_buffer/size                  662000
trainer/num train calls             330000
trainer/QF1 Loss                       211.215
trainer/QF2 Loss                       211.635
trainer/Policy Loss                     75.0441
trainer/Q1 Predictions Mean            -74.4831
trainer/Q1 Predictions Std              89.8439
trainer/Q1 Predictions Max              73.7707
trainer/Q1 Predictions Min            -238.689
trainer/Q2 Predictions Mean            -74.6105
trainer/Q2 Predictions Std              89.9056
trainer/Q2 Predictions Max              74.0106
trainer/Q2 Predictions Min            -237.481
trainer/Q Targets Mean                 -73.9314
trainer/Q Targets Std                   90.9219
trainer/Q Targets Max                   73.773
trainer/Q Targets Min                 -239.462
trainer/Log Pis Mean                     1.88954
trainer/Log Pis Std                      1.46591
trainer/Log Pis Max                      5.70073
trainer/Log Pis Min                     -4.04014
trainer/policy/mean Mean                -0.331548
trainer/policy/mean Std                  0.751481
trainer/policy/mean Max                  0.971261
trainer/policy/mean Min                 -0.989242
trainer/policy/normal/std Mean           0.577273
trainer/policy/normal/std Std            0.0945005
trainer/policy/normal/std Max            0.868642
trainer/policy/normal/std Min            0.238793
trainer/policy/normal/log_std Mean      -0.562661
trainer/policy/normal/log_std Std        0.163361
trainer/policy/normal/log_std Max       -0.140824
trainer/policy/normal/log_std Min       -1.43216
trainer/Alpha                            0.0244264
trainer/Alpha Loss                      -0.410042
exploration/num steps total         662000
exploration/num paths total           3310
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.783347
exploration/Rewards Std                  1.53099
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -156.669
exploration/Returns Std                 77.698
exploration/Returns Max                -65.1887
exploration/Returns Min               -280.357
exploration/Actions Mean                -0.492409
exploration/Actions Std                  0.615488
exploration/Actions Max                  0.998936
exploration/Actions Min                 -0.999601
exploration/Num Paths                   10
exploration/Average Returns           -156.669
evaluation/num steps total               1.59192e+06
evaluation/num paths total            7920
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.3904
evaluation/Rewards Std                   1.06719
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.47
evaluation/Returns Std                 213.766
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.408594
evaluation/Actions Std                   0.592172
evaluation/Actions Max                   0.651241
evaluation/Actions Min                  -0.981115
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.47
time/data storing (s)                    0.0206568
time/evaluation sampling (s)            12.6923
time/exploration sampling (s)            4.83418
time/logging (s)                         0.0465982
time/sac training (s)                   32.0824
time/saving (s)                          0.280236
time/training (s)                        0.00014101
time/epoch (s)                          49.9565
time/total (s)                       45757.9
Epoch                                  329
----------------------------------  ----------------
2020-11-10 03:52:42.786080 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 330 finished
----------------------------------  ----------------
replay_buffer/size                  664000
trainer/num train calls             331000
trainer/QF1 Loss                       130.017
trainer/QF2 Loss                       118.803
trainer/Policy Loss                     72.8649
trainer/Q1 Predictions Mean            -72.4114
trainer/Q1 Predictions Std              89.6446
trainer/Q1 Predictions Max              46.8254
trainer/Q1 Predictions Min            -239.726
trainer/Q2 Predictions Mean            -72.2514
trainer/Q2 Predictions Std              89.5051
trainer/Q2 Predictions Max              46.867
trainer/Q2 Predictions Min            -241.015
trainer/Q Targets Mean                 -71.8437
trainer/Q Targets Std                   89.5588
trainer/Q Targets Max                   47.0371
trainer/Q Targets Min                 -239.735
trainer/Log Pis Mean                     2.15576
trainer/Log Pis Std                      1.88546
trainer/Log Pis Max                      7.7877
trainer/Log Pis Min                     -5.35499
trainer/policy/mean Mean                -0.603923
trainer/policy/mean Std                  0.568866
trainer/policy/mean Max                  0.956828
trainer/policy/mean Min                 -0.994804
trainer/policy/normal/std Mean           0.575458
trainer/policy/normal/std Std            0.0977539
trainer/policy/normal/std Max            0.893331
trainer/policy/normal/std Min            0.25601
trainer/policy/normal/log_std Mean      -0.566661
trainer/policy/normal/log_std Std        0.167901
trainer/policy/normal/log_std Max       -0.112798
trainer/policy/normal/log_std Min       -1.36254
trainer/Alpha                            0.0244357
trainer/Alpha Loss                       0.578134
exploration/num steps total         664000
exploration/num paths total           3320
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.10307
exploration/Rewards Std                  1.52981
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -220.614
exploration/Returns Std                164.782
exploration/Returns Max                -38.9554
exploration/Returns Min               -613.876
exploration/Actions Mean                -0.530157
exploration/Actions Std                  0.652822
exploration/Actions Max                  0.997616
exploration/Actions Min                 -0.999418
exploration/Num Paths                   10
exploration/Average Returns           -220.614
evaluation/num steps total               1.59674e+06
evaluation/num paths total            7944
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.17143
evaluation/Rewards Std                   1.19617
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1039.46
evaluation/Returns Std                 239.49
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.761624
evaluation/Actions Std                   0.289528
evaluation/Actions Max                   0.164747
evaluation/Actions Min                  -0.98144
evaluation/Num Paths                    24
evaluation/Average Returns           -1039.46
time/data storing (s)                    0.0289651
time/evaluation sampling (s)            12.3301
time/exploration sampling (s)            5.6998
time/logging (s)                         0.0437537
time/sac training (s)                   32.4675
time/saving (s)                          0.277809
time/training (s)                        0.000158155
time/epoch (s)                          50.848
time/total (s)                       45922.6
Epoch                                  330
----------------------------------  ----------------
2020-11-10 03:55:20.744445 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 331 finished
----------------------------------  -----------------
replay_buffer/size                  666000
trainer/num train calls             332000
trainer/QF1 Loss                       110.613
trainer/QF2 Loss                       114.044
trainer/Policy Loss                     67.1233
trainer/Q1 Predictions Mean            -66.5287
trainer/Q1 Predictions Std              83.842
trainer/Q1 Predictions Max              28.8543
trainer/Q1 Predictions Min            -234.984
trainer/Q2 Predictions Mean            -66.5714
trainer/Q2 Predictions Std              83.9081
trainer/Q2 Predictions Max              28.9632
trainer/Q2 Predictions Min            -238.165
trainer/Q Targets Mean                 -66.9776
trainer/Q Targets Std                   85.2208
trainer/Q Targets Max                   29.171
trainer/Q Targets Min                 -239.622
trainer/Log Pis Mean                     1.70048
trainer/Log Pis Std                      1.7069
trainer/Log Pis Max                      5.31419
trainer/Log Pis Min                     -6.07394
trainer/policy/mean Mean                -0.427236
trainer/policy/mean Std                  0.697936
trainer/policy/mean Max                  0.964641
trainer/policy/mean Min                 -0.986175
trainer/policy/normal/std Mean           0.579733
trainer/policy/normal/std Std            0.0918523
trainer/policy/normal/std Max            0.868228
trainer/policy/normal/std Min            0.278025
trainer/policy/normal/log_std Mean      -0.557304
trainer/policy/normal/log_std Std        0.155316
trainer/policy/normal/log_std Max       -0.141301
trainer/policy/normal/log_std Min       -1.28004
trainer/Alpha                            0.0247034
trainer/Alpha Loss                      -1.10849
exploration/num steps total         666000
exploration/num paths total           3330
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.795044
exploration/Rewards Std                  1.43475
exploration/Rewards Max                 -1.30492e-207
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -159.009
exploration/Returns Std                123.046
exploration/Returns Max                -13.3588
exploration/Returns Min               -459.017
exploration/Actions Mean                -0.486007
exploration/Actions Std                  0.636468
exploration/Actions Max                  0.996666
exploration/Actions Min                 -0.999658
exploration/Num Paths                   10
exploration/Average Returns           -159.009
evaluation/num steps total               1.60157e+06
evaluation/num paths total            7968
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.31382
evaluation/Rewards Std                   1.48279
evaluation/Rewards Max                  -1.18947e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1068.08
evaluation/Returns Std                 297.156
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.467851
evaluation/Actions Std                   0.560074
evaluation/Actions Max                   0.879714
evaluation/Actions Min                  -0.975163
evaluation/Num Paths                    24
evaluation/Average Returns           -1068.08
time/data storing (s)                    0.0308653
time/evaluation sampling (s)            13.1034
time/exploration sampling (s)            5.00005
time/logging (s)                         0.053696
time/sac training (s)                   32.8626
time/saving (s)                          0.204044
time/training (s)                        0.000193244
time/epoch (s)                          51.2548
time/total (s)                       46080.5
Epoch                                  331
----------------------------------  -----------------
2020-11-10 03:58:00.331403 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 332 finished
----------------------------------  ----------------
replay_buffer/size                  668000
trainer/num train calls             333000
trainer/QF1 Loss                        36.2051
trainer/QF2 Loss                        42.7088
trainer/Policy Loss                     64.7953
trainer/Q1 Predictions Mean            -64.2484
trainer/Q1 Predictions Std              87.4711
trainer/Q1 Predictions Max              56.9579
trainer/Q1 Predictions Min            -262.726
trainer/Q2 Predictions Mean            -64.5036
trainer/Q2 Predictions Std              87.7355
trainer/Q2 Predictions Max              56.9723
trainer/Q2 Predictions Min            -261.295
trainer/Q Targets Mean                 -64.7041
trainer/Q Targets Std                   88.2899
trainer/Q Targets Max                   57.2037
trainer/Q Targets Min                 -261.369
trainer/Log Pis Mean                     2.27154
trainer/Log Pis Std                      1.53974
trainer/Log Pis Max                      6.33118
trainer/Log Pis Min                     -3.38988
trainer/policy/mean Mean                -0.607239
trainer/policy/mean Std                  0.571184
trainer/policy/mean Max                  0.942227
trainer/policy/mean Min                 -0.987754
trainer/policy/normal/std Mean           0.586733
trainer/policy/normal/std Std            0.115448
trainer/policy/normal/std Max            0.936743
trainer/policy/normal/std Min            0.214173
trainer/policy/normal/log_std Mean      -0.551836
trainer/policy/normal/log_std Std        0.193569
trainer/policy/normal/log_std Max       -0.0653464
trainer/policy/normal/log_std Min       -1.54097
trainer/Alpha                            0.0250415
trainer/Alpha Loss                       1.00123
exploration/num steps total         668000
exploration/num paths total           3340
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.5855
exploration/Rewards Std                  1.50218
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -117.1
exploration/Returns Std                 55.7653
exploration/Returns Max                -58.6458
exploration/Returns Min               -260.214
exploration/Actions Mean                -0.499069
exploration/Actions Std                  0.670082
exploration/Actions Max                  0.997385
exploration/Actions Min                 -0.999465
exploration/Num Paths                   10
exploration/Average Returns           -117.1
evaluation/num steps total               1.60639e+06
evaluation/num paths total            7992
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.67097
evaluation/Rewards Std                   1.25172
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -938.865
evaluation/Returns Std                 247.081
evaluation/Returns Max                -635.765
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.513848
evaluation/Actions Std                   0.518495
evaluation/Actions Max                   0.732518
evaluation/Actions Min                  -0.979207
evaluation/Num Paths                    24
evaluation/Average Returns            -938.865
time/data storing (s)                    0.0218513
time/evaluation sampling (s)            12.8002
time/exploration sampling (s)            4.85966
time/logging (s)                         0.0433225
time/sac training (s)                   32.7426
time/saving (s)                          0.135895
time/training (s)                        0.000117816
time/epoch (s)                          50.6037
time/total (s)                       46240.1
Epoch                                  332
----------------------------------  ----------------
2020-11-10 04:00:37.294876 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 333 finished
----------------------------------  -----------------
replay_buffer/size                  670000
trainer/num train calls             334000
trainer/QF1 Loss                       206.394
trainer/QF2 Loss                       215.447
trainer/Policy Loss                     57.9203
trainer/Q1 Predictions Mean            -57.3541
trainer/Q1 Predictions Std              82.8521
trainer/Q1 Predictions Max              56.8664
trainer/Q1 Predictions Min            -228.493
trainer/Q2 Predictions Mean            -57.5246
trainer/Q2 Predictions Std              82.9015
trainer/Q2 Predictions Max              56.5857
trainer/Q2 Predictions Min            -229.182
trainer/Q Targets Mean                 -56.6433
trainer/Q Targets Std                   82.6512
trainer/Q Targets Max                   56.5326
trainer/Q Targets Min                 -231.826
trainer/Log Pis Mean                     2.02991
trainer/Log Pis Std                      1.66973
trainer/Log Pis Max                      5.44851
trainer/Log Pis Min                     -4.21212
trainer/policy/mean Mean                -0.441885
trainer/policy/mean Std                  0.696477
trainer/policy/mean Max                  0.961094
trainer/policy/mean Min                 -0.987831
trainer/policy/normal/std Mean           0.573024
trainer/policy/normal/std Std            0.0961253
trainer/policy/normal/std Max            0.889597
trainer/policy/normal/std Min            0.210391
trainer/policy/normal/log_std Mean      -0.570871
trainer/policy/normal/log_std Std        0.169501
trainer/policy/normal/log_std Max       -0.116987
trainer/policy/normal/log_std Min       -1.55879
trainer/Alpha                            0.024873
trainer/Alpha Loss                       0.11049
exploration/num steps total         670000
exploration/num paths total           3350
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.17701
exploration/Rewards Std                  1.62839
exploration/Rewards Max                 -4.95918e-103
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -235.402
exploration/Returns Std                158.026
exploration/Returns Max                -65.7382
exploration/Returns Min               -521.839
exploration/Actions Mean                -0.350011
exploration/Actions Std                  0.71637
exploration/Actions Max                  0.997277
exploration/Actions Min                 -0.999204
exploration/Num Paths                   10
exploration/Average Returns           -235.402
evaluation/num steps total               1.61122e+06
evaluation/num paths total            8016
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.53913
evaluation/Rewards Std                   1.35857
evaluation/Rewards Max                  -2.79663e-18
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1113.37
evaluation/Returns Std                 272.171
evaluation/Returns Max                 -12.7748
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.544239
evaluation/Actions Std                   0.458105
evaluation/Actions Max                   0.958167
evaluation/Actions Min                  -0.977321
evaluation/Num Paths                    24
evaluation/Average Returns           -1113.37
time/data storing (s)                    0.020958
time/evaluation sampling (s)            12.4551
time/exploration sampling (s)            4.99305
time/logging (s)                         0.0404759
time/sac training (s)                   32.5127
time/saving (s)                          0.354993
time/training (s)                        0.000186649
time/epoch (s)                          50.3775
time/total (s)                       46397
Epoch                                  333
----------------------------------  -----------------
2020-11-10 04:03:25.415755 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 334 finished
----------------------------------  -----------------
replay_buffer/size                  672000
trainer/num train calls             335000
trainer/QF1 Loss                       127.626
trainer/QF2 Loss                       126.159
trainer/Policy Loss                     70.1027
trainer/Q1 Predictions Mean            -69.6581
trainer/Q1 Predictions Std              85.8071
trainer/Q1 Predictions Max              40.6226
trainer/Q1 Predictions Min            -228.992
trainer/Q2 Predictions Mean            -69.636
trainer/Q2 Predictions Std              85.5815
trainer/Q2 Predictions Max              40.2837
trainer/Q2 Predictions Min            -228.74
trainer/Q Targets Mean                 -69.6021
trainer/Q Targets Std                   86.4221
trainer/Q Targets Max                   39.819
trainer/Q Targets Min                 -232.132
trainer/Log Pis Mean                     1.64776
trainer/Log Pis Std                      1.78726
trainer/Log Pis Max                     10.0731
trainer/Log Pis Min                     -4.95953
trainer/policy/mean Mean                -0.420562
trainer/policy/mean Std                  0.682557
trainer/policy/mean Max                  0.962378
trainer/policy/mean Min                 -0.998809
trainer/policy/normal/std Mean           0.574065
trainer/policy/normal/std Std            0.0895257
trainer/policy/normal/std Max            0.948906
trainer/policy/normal/std Min            0.204335
trainer/policy/normal/log_std Mean      -0.567349
trainer/policy/normal/log_std Std        0.159339
trainer/policy/normal/log_std Max       -0.0524455
trainer/policy/normal/log_std Min       -1.58799
trainer/Alpha                            0.0247788
trainer/Alpha Loss                      -1.30251
exploration/num steps total         672000
exploration/num paths total           3360
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.851167
exploration/Rewards Std                  1.54414
exploration/Rewards Max                 -6.91858e-134
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -170.233
exploration/Returns Std                 93.6916
exploration/Returns Max                -45.0056
exploration/Returns Min               -290.224
exploration/Actions Mean                -0.401781
exploration/Actions Std                  0.714834
exploration/Actions Max                  0.997983
exploration/Actions Min                 -0.998493
exploration/Num Paths                   10
exploration/Average Returns           -170.233
evaluation/num steps total               1.61604e+06
evaluation/num paths total            8040
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   1.21717e-11
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.572932
evaluation/Actions Std                   0.398957
evaluation/Actions Max                  -0.173532
evaluation/Actions Min                  -0.973354
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0200057
time/evaluation sampling (s)            13.1579
time/exploration sampling (s)            5.05868
time/logging (s)                         0.064126
time/sac training (s)                   32.375
time/saving (s)                          0.344522
time/training (s)                        0.000137048
time/epoch (s)                          51.0204
time/total (s)                       46565.1
Epoch                                  334
----------------------------------  -----------------
2020-11-10 04:06:10.277647 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 335 finished
----------------------------------  ----------------
replay_buffer/size                  674000
trainer/num train calls             336000
trainer/QF1 Loss                       267.089
trainer/QF2 Loss                       278.461
trainer/Policy Loss                     68.8575
trainer/Q1 Predictions Mean            -68.1685
trainer/Q1 Predictions Std              84.2731
trainer/Q1 Predictions Max              69.5172
trainer/Q1 Predictions Min            -240.664
trainer/Q2 Predictions Mean            -68.3181
trainer/Q2 Predictions Std              84.5094
trainer/Q2 Predictions Max              69.4723
trainer/Q2 Predictions Min            -241.51
trainer/Q Targets Mean                 -67.3739
trainer/Q Targets Std                   85.0045
trainer/Q Targets Max                   68.9336
trainer/Q Targets Min                 -243.101
trainer/Log Pis Mean                     1.76847
trainer/Log Pis Std                      1.55122
trainer/Log Pis Max                      6.17742
trainer/Log Pis Min                     -2.48208
trainer/policy/mean Mean                -0.415455
trainer/policy/mean Std                  0.703795
trainer/policy/mean Max                  0.95773
trainer/policy/mean Min                 -0.985705
trainer/policy/normal/std Mean           0.580095
trainer/policy/normal/std Std            0.0967976
trainer/policy/normal/std Max            0.889361
trainer/policy/normal/std Min            0.242167
trainer/policy/normal/log_std Mean      -0.558495
trainer/policy/normal/log_std Std        0.168373
trainer/policy/normal/log_std Max       -0.117252
trainer/policy/normal/log_std Min       -1.41813
trainer/Alpha                            0.024697
trainer/Alpha Loss                      -0.856908
exploration/num steps total         674000
exploration/num paths total           3370
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.22459
exploration/Rewards Std                  1.55212
exploration/Rewards Max                 -3.65716e-81
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -244.917
exploration/Returns Std                159.478
exploration/Returns Max                -61.4123
exploration/Returns Min               -540.102
exploration/Actions Mean                -0.343218
exploration/Actions Std                  0.776437
exploration/Actions Max                  0.999069
exploration/Actions Min                 -0.999394
exploration/Num Paths                   10
exploration/Average Returns           -244.917
evaluation/num steps total               1.62086e+06
evaluation/num paths total            8064
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.559322
evaluation/Actions Std                   0.43568
evaluation/Actions Max                   0.813358
evaluation/Actions Min                  -0.972802
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.0276326
time/evaluation sampling (s)            12.4467
time/exploration sampling (s)            6.50372
time/logging (s)                         0.0433709
time/sac training (s)                   32.4188
time/saving (s)                          0.243411
time/training (s)                        0.00014975
time/epoch (s)                          51.6838
time/total (s)                       46729.9
Epoch                                  335
----------------------------------  ----------------
2020-11-10 04:09:22.822203 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 336 finished
----------------------------------  -----------------
replay_buffer/size                  676000
trainer/num train calls             337000
trainer/QF1 Loss                        38.4082
trainer/QF2 Loss                        41.824
trainer/Policy Loss                     61.701
trainer/Q1 Predictions Mean            -61.2827
trainer/Q1 Predictions Std              85.6157
trainer/Q1 Predictions Max              47.4956
trainer/Q1 Predictions Min            -241.078
trainer/Q2 Predictions Mean            -61.222
trainer/Q2 Predictions Std              85.5799
trainer/Q2 Predictions Max              47.6165
trainer/Q2 Predictions Min            -240.133
trainer/Q Targets Mean                 -61.3149
trainer/Q Targets Std                   85.8944
trainer/Q Targets Max                   47.5746
trainer/Q Targets Min                 -242.818
trainer/Log Pis Mean                     2.24519
trainer/Log Pis Std                      1.65751
trainer/Log Pis Max                      6.77846
trainer/Log Pis Min                     -3.7686
trainer/policy/mean Mean                -0.557797
trainer/policy/mean Std                  0.629381
trainer/policy/mean Max                  0.96738
trainer/policy/mean Min                 -0.991377
trainer/policy/normal/std Mean           0.582355
trainer/policy/normal/std Std            0.106091
trainer/policy/normal/std Max            0.895717
trainer/policy/normal/std Min            0.242865
trainer/policy/normal/log_std Mean      -0.556665
trainer/policy/normal/log_std Std        0.178626
trainer/policy/normal/log_std Max       -0.110131
trainer/policy/normal/log_std Min       -1.41525
trainer/Alpha                            0.0246297
trainer/Alpha Loss                       0.908148
exploration/num steps total         676000
exploration/num paths total           3380
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.833517
exploration/Rewards Std                  1.5089
exploration/Rewards Max                 -5.12165e-258
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -166.703
exploration/Returns Std                 99.5986
exploration/Returns Max                -30.3544
exploration/Returns Min               -352.602
exploration/Actions Mean                -0.619202
exploration/Actions Std                  0.548807
exploration/Actions Max                  0.997155
exploration/Actions Min                 -0.999181
exploration/Num Paths                   10
exploration/Average Returns           -166.703
evaluation/num steps total               1.62569e+06
evaluation/num paths total            8088
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.64452
evaluation/Rewards Std                   0.729931
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1134.55
evaluation/Returns Std                 145.736
evaluation/Returns Max                -630.674
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.582342
evaluation/Actions Std                   0.399984
evaluation/Actions Max                   0.744194
evaluation/Actions Min                  -0.979091
evaluation/Num Paths                    24
evaluation/Average Returns           -1134.55
time/data storing (s)                    0.019769
time/evaluation sampling (s)            12.6397
time/exploration sampling (s)            5.2825
time/logging (s)                         0.100267
time/sac training (s)                   33.3087
time/saving (s)                          0.29811
time/training (s)                        0.000121865
time/epoch (s)                          51.6492
time/total (s)                       46922.5
Epoch                                  336
----------------------------------  -----------------
2020-11-10 04:12:25.531813 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 337 finished
----------------------------------  -----------------
replay_buffer/size                  678000
trainer/num train calls             338000
trainer/QF1 Loss                        55.0523
trainer/QF2 Loss                        51.8427
trainer/Policy Loss                     67.4034
trainer/Q1 Predictions Mean            -66.7246
trainer/Q1 Predictions Std              87.4617
trainer/Q1 Predictions Max              64.632
trainer/Q1 Predictions Min            -238.578
trainer/Q2 Predictions Mean            -67.0075
trainer/Q2 Predictions Std              87.7743
trainer/Q2 Predictions Max              64.7917
trainer/Q2 Predictions Min            -239.642
trainer/Q Targets Mean                 -67.6985
trainer/Q Targets Std                   88.8564
trainer/Q Targets Max                   64.6535
trainer/Q Targets Min                 -238.528
trainer/Log Pis Mean                     2.22259
trainer/Log Pis Std                      1.72008
trainer/Log Pis Max                      7.10666
trainer/Log Pis Min                     -4.31865
trainer/policy/mean Mean                -0.532206
trainer/policy/mean Std                  0.633148
trainer/policy/mean Max                  0.956587
trainer/policy/mean Min                 -0.992739
trainer/policy/normal/std Mean           0.588236
trainer/policy/normal/std Std            0.121237
trainer/policy/normal/std Max            0.963333
trainer/policy/normal/std Min            0.217013
trainer/policy/normal/log_std Mean      -0.551161
trainer/policy/normal/log_std Std        0.202665
trainer/policy/normal/log_std Max       -0.0373566
trainer/policy/normal/log_std Min       -1.5278
trainer/Alpha                            0.0244486
trainer/Alpha Loss                       0.826068
exploration/num steps total         678000
exploration/num paths total           3390
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.958355
exploration/Rewards Std                  1.56656
exploration/Rewards Max                 -1.80005e-101
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.671
exploration/Returns Std                125.376
exploration/Returns Max                -58.5011
exploration/Returns Min               -523.438
exploration/Actions Mean                -0.430135
exploration/Actions Std                  0.692822
exploration/Actions Max                  0.999076
exploration/Actions Min                 -0.99942
exploration/Num Paths                   10
exploration/Average Returns           -191.671
evaluation/num steps total               1.63051e+06
evaluation/num paths total            8112
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.54713
evaluation/Rewards Std                   0.839712
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1114.97
evaluation/Returns Std                 167.992
evaluation/Returns Max                -655.47
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.557806
evaluation/Actions Std                   0.441309
evaluation/Actions Max                   0.666962
evaluation/Actions Min                  -0.979203
evaluation/Num Paths                    24
evaluation/Average Returns           -1114.97
time/data storing (s)                    0.0212856
time/evaluation sampling (s)            12.9695
time/exploration sampling (s)            5.03376
time/logging (s)                         0.0533091
time/sac training (s)                   31.8896
time/saving (s)                          0.225671
time/training (s)                        0.000136299
time/epoch (s)                          50.1933
time/total (s)                       47105.1
Epoch                                  337
----------------------------------  -----------------
2020-11-10 04:15:24.942163 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 338 finished
----------------------------------  ----------------
replay_buffer/size                  680000
trainer/num train calls             339000
trainer/QF1 Loss                       119.807
trainer/QF2 Loss                       118.92
trainer/Policy Loss                     70.1348
trainer/Q1 Predictions Mean            -69.4316
trainer/Q1 Predictions Std              86.8871
trainer/Q1 Predictions Max              46.3382
trainer/Q1 Predictions Min            -237.015
trainer/Q2 Predictions Mean            -69.4758
trainer/Q2 Predictions Std              86.8557
trainer/Q2 Predictions Max              46.4981
trainer/Q2 Predictions Min            -234.826
trainer/Q Targets Mean                 -69.3196
trainer/Q Targets Std                   87.5067
trainer/Q Targets Max                   46.4791
trainer/Q Targets Min                 -238.069
trainer/Log Pis Mean                     1.76091
trainer/Log Pis Std                      1.49211
trainer/Log Pis Max                      5.87321
trainer/Log Pis Min                     -2.69006
trainer/policy/mean Mean                -0.489648
trainer/policy/mean Std                  0.653611
trainer/policy/mean Max                  0.95399
trainer/policy/mean Min                 -0.985464
trainer/policy/normal/std Mean           0.591165
trainer/policy/normal/std Std            0.109084
trainer/policy/normal/std Max            0.889646
trainer/policy/normal/std Min            0.214619
trainer/policy/normal/log_std Mean      -0.542264
trainer/policy/normal/log_std Std        0.182761
trainer/policy/normal/log_std Max       -0.116932
trainer/policy/normal/log_std Min       -1.53889
trainer/Alpha                            0.0244702
trainer/Alpha Loss                      -0.887091
exploration/num steps total         680000
exploration/num paths total           3400
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.29685
exploration/Rewards Std                  1.5307
exploration/Rewards Max                 -3.69338e-82
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -259.369
exploration/Returns Std                124.934
exploration/Returns Max               -103.529
exploration/Returns Min               -514.14
exploration/Actions Mean                -0.609162
exploration/Actions Std                  0.580261
exploration/Actions Max                  0.998295
exploration/Actions Min                 -0.999462
exploration/Num Paths                   10
exploration/Average Returns           -259.369
evaluation/num steps total               1.63534e+06
evaluation/num paths total            8136
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.39361
evaluation/Rewards Std                   1.05726
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1084.12
evaluation/Returns Std                 212.5
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.529357
evaluation/Actions Std                   0.450568
evaluation/Actions Max                   0.156181
evaluation/Actions Min                  -0.974025
evaluation/Num Paths                    24
evaluation/Average Returns           -1084.12
time/data storing (s)                    0.0207943
time/evaluation sampling (s)            12.5984
time/exploration sampling (s)            5.06342
time/logging (s)                         0.0597129
time/sac training (s)                   32.6303
time/saving (s)                          0.449366
time/training (s)                        0.000125149
time/epoch (s)                          50.8221
time/total (s)                       47284.5
Epoch                                  338
----------------------------------  ----------------
2020-11-10 04:18:24.667017 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 339 finished
----------------------------------  ----------------
replay_buffer/size                  682000
trainer/num train calls             340000
trainer/QF1 Loss                       115.833
trainer/QF2 Loss                        94.0876
trainer/Policy Loss                     69.1056
trainer/Q1 Predictions Mean            -68.5835
trainer/Q1 Predictions Std              88.1978
trainer/Q1 Predictions Max              46.4739
trainer/Q1 Predictions Min            -232.865
trainer/Q2 Predictions Mean            -68.6366
trainer/Q2 Predictions Std              88.451
trainer/Q2 Predictions Max              46.7419
trainer/Q2 Predictions Min            -234.681
trainer/Q Targets Mean                 -68.7655
trainer/Q Targets Std                   88.9618
trainer/Q Targets Max                   46.4095
trainer/Q Targets Min                 -236.053
trainer/Log Pis Mean                     1.87314
trainer/Log Pis Std                      1.48705
trainer/Log Pis Max                      5.90468
trainer/Log Pis Min                     -3.11963
trainer/policy/mean Mean                -0.405307
trainer/policy/mean Std                  0.705309
trainer/policy/mean Max                  0.973848
trainer/policy/mean Min                 -0.986333
trainer/policy/normal/std Mean           0.579327
trainer/policy/normal/std Std            0.105449
trainer/policy/normal/std Max            0.916652
trainer/policy/normal/std Min            0.243324
trainer/policy/normal/log_std Mean      -0.562195
trainer/policy/normal/log_std Std        0.181583
trainer/policy/normal/log_std Max       -0.0870277
trainer/policy/normal/log_std Min       -1.41336
trainer/Alpha                            0.024293
trainer/Alpha Loss                      -0.471592
exploration/num steps total         682000
exploration/num paths total           3410
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.17526
exploration/Rewards Std                  1.77828
exploration/Rewards Max                 -1.28828e-90
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -235.053
exploration/Returns Std                164.352
exploration/Returns Max                -45.02
exploration/Returns Min               -654.784
exploration/Actions Mean                -0.458027
exploration/Actions Std                  0.62833
exploration/Actions Max                  0.99708
exploration/Actions Min                 -0.999533
exploration/Num Paths                   10
exploration/Average Returns           -235.053
evaluation/num steps total               1.64016e+06
evaluation/num paths total            8160
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.53831e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.47408
evaluation/Actions Std                   0.500125
evaluation/Actions Max                   0.0261294
evaluation/Actions Min                  -0.974567
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0215801
time/evaluation sampling (s)            12.6134
time/exploration sampling (s)            4.99636
time/logging (s)                         0.0629467
time/sac training (s)                   32.7862
time/saving (s)                          0.111315
time/training (s)                        0.000144051
time/epoch (s)                          50.5919
time/total (s)                       47464.2
Epoch                                  339
----------------------------------  ----------------
2020-11-10 04:21:17.275628 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 340 finished
----------------------------------  -----------------
replay_buffer/size                  684000
trainer/num train calls             341000
trainer/QF1 Loss                        31.0917
trainer/QF2 Loss                        20.8237
trainer/Policy Loss                     68.4468
trainer/Q1 Predictions Mean            -67.834
trainer/Q1 Predictions Std              87.9297
trainer/Q1 Predictions Max              66.0676
trainer/Q1 Predictions Min            -238.369
trainer/Q2 Predictions Mean            -68.0463
trainer/Q2 Predictions Std              88.2365
trainer/Q2 Predictions Max              66.1934
trainer/Q2 Predictions Min            -238.855
trainer/Q Targets Mean                 -68.5072
trainer/Q Targets Std                   89.2505
trainer/Q Targets Max                   66.2401
trainer/Q Targets Min                 -239.247
trainer/Log Pis Mean                     1.99785
trainer/Log Pis Std                      1.66058
trainer/Log Pis Max                      5.9819
trainer/Log Pis Min                     -3.69757
trainer/policy/mean Mean                -0.447122
trainer/policy/mean Std                  0.681912
trainer/policy/mean Max                  0.967033
trainer/policy/mean Min                 -0.989431
trainer/policy/normal/std Mean           0.581594
trainer/policy/normal/std Std            0.111034
trainer/policy/normal/std Max            0.913202
trainer/policy/normal/std Min            0.214548
trainer/policy/normal/log_std Mean      -0.559633
trainer/policy/normal/log_std Std        0.188154
trainer/policy/normal/log_std Max       -0.090798
trainer/policy/normal/log_std Min       -1.53922
trainer/Alpha                            0.0243209
trainer/Alpha Loss                      -0.00797617
exploration/num steps total         684000
exploration/num paths total           3420
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.73644
exploration/Rewards Std                  1.61099
exploration/Rewards Max                 -1.38434e-206
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -147.288
exploration/Returns Std                 68.3327
exploration/Returns Max                -48.0685
exploration/Returns Min               -305.387
exploration/Actions Mean                -0.348372
exploration/Actions Std                  0.749299
exploration/Actions Max                  0.998414
exploration/Actions Min                 -0.998981
exploration/Num Paths                   10
exploration/Average Returns           -147.288
evaluation/num steps total               1.64498e+06
evaluation/num paths total            8184
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.38969
evaluation/Rewards Std                   1.18759
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1083.33
evaluation/Returns Std                 238.706
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.482318
evaluation/Actions Std                   0.515381
evaluation/Actions Max                   0.373356
evaluation/Actions Min                  -0.978289
evaluation/Num Paths                    24
evaluation/Average Returns           -1083.33
time/data storing (s)                    0.0201177
time/evaluation sampling (s)            12.617
time/exploration sampling (s)            5.06924
time/logging (s)                         0.0598967
time/sac training (s)                   32.5079
time/saving (s)                          0.416419
time/training (s)                        0.000151856
time/epoch (s)                          50.6907
time/total (s)                       47636.7
Epoch                                  340
----------------------------------  -----------------
2020-11-10 04:24:21.494697 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 341 finished
----------------------------------  ----------------
replay_buffer/size                  686000
trainer/num train calls             342000
trainer/QF1 Loss                       259.76
trainer/QF2 Loss                       262.099
trainer/Policy Loss                     50.2298
trainer/Q1 Predictions Mean            -49.791
trainer/Q1 Predictions Std              76.8987
trainer/Q1 Predictions Max              65.3768
trainer/Q1 Predictions Min            -231.367
trainer/Q2 Predictions Mean            -49.7132
trainer/Q2 Predictions Std              76.8708
trainer/Q2 Predictions Max              65.4291
trainer/Q2 Predictions Min            -229.903
trainer/Q Targets Mean                 -49.0073
trainer/Q Targets Std                   77.0792
trainer/Q Targets Max                   65.3483
trainer/Q Targets Min                 -234.831
trainer/Log Pis Mean                     2.2204
trainer/Log Pis Std                      1.74275
trainer/Log Pis Max                      7.1174
trainer/Log Pis Min                     -4.17032
trainer/policy/mean Mean                -0.571328
trainer/policy/mean Std                  0.607963
trainer/policy/mean Max                  0.950228
trainer/policy/mean Min                 -0.989415
trainer/policy/normal/std Mean           0.560063
trainer/policy/normal/std Std            0.103472
trainer/policy/normal/std Max            0.96541
trainer/policy/normal/std Min            0.198602
trainer/policy/normal/log_std Mean      -0.597094
trainer/policy/normal/log_std Std        0.190165
trainer/policy/normal/log_std Max       -0.0352022
trainer/policy/normal/log_std Min       -1.61645
trainer/Alpha                            0.0245935
trainer/Alpha Loss                       0.816645
exploration/num steps total         686000
exploration/num paths total           3430
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.872757
exploration/Rewards Std                  1.56151
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -174.551
exploration/Returns Std                 81.9382
exploration/Returns Max                -63.6395
exploration/Returns Min               -342.412
exploration/Actions Mean                -0.67075
exploration/Actions Std                  0.516283
exploration/Actions Max                  0.994037
exploration/Actions Min                 -0.999178
exploration/Num Paths                   10
exploration/Average Returns           -174.551
evaluation/num steps total               1.64981e+06
evaluation/num paths total            8208
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.793817
evaluation/Actions Std                   0.213257
evaluation/Actions Max                   0.146168
evaluation/Actions Min                  -0.979135
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0205206
time/evaluation sampling (s)            12.6604
time/exploration sampling (s)            4.76046
time/logging (s)                         0.0635392
time/sac training (s)                   32.7474
time/saving (s)                          0.278271
time/training (s)                        0.000114111
time/epoch (s)                          50.5307
time/total (s)                       47820.9
Epoch                                  341
----------------------------------  ----------------
2020-11-10 04:27:23.365577 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 342 finished
----------------------------------  -----------------
replay_buffer/size                  688000
trainer/num train calls             343000
trainer/QF1 Loss                        19.8019
trainer/QF2 Loss                        19.6151
trainer/Policy Loss                     65.4383
trainer/Q1 Predictions Mean            -64.9344
trainer/Q1 Predictions Std              86.1766
trainer/Q1 Predictions Max              43.7603
trainer/Q1 Predictions Min            -236.264
trainer/Q2 Predictions Mean            -65.0616
trainer/Q2 Predictions Std              86.314
trainer/Q2 Predictions Max              43.7467
trainer/Q2 Predictions Min            -231.803
trainer/Q Targets Mean                 -65.832
trainer/Q Targets Std                   87.0003
trainer/Q Targets Max                   43.6916
trainer/Q Targets Min                 -237.3
trainer/Log Pis Mean                     1.89228
trainer/Log Pis Std                      1.64174
trainer/Log Pis Max                      6.20869
trainer/Log Pis Min                     -6.1149
trainer/policy/mean Mean                -0.458782
trainer/policy/mean Std                  0.680095
trainer/policy/mean Max                  0.972024
trainer/policy/mean Min                 -0.988332
trainer/policy/normal/std Mean           0.578507
trainer/policy/normal/std Std            0.108145
trainer/policy/normal/std Max            0.912712
trainer/policy/normal/std Min            0.204509
trainer/policy/normal/log_std Mean      -0.564673
trainer/policy/normal/log_std Std        0.188051
trainer/policy/normal/log_std Max       -0.0913347
trainer/policy/normal/log_std Min       -1.58714
trainer/Alpha                            0.0246859
trainer/Alpha Loss                      -0.39871
exploration/num steps total         688000
exploration/num paths total           3440
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.826705
exploration/Rewards Std                  1.39832
exploration/Rewards Max                 -3.23262e-159
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -165.341
exploration/Returns Std                113.383
exploration/Returns Max                -46.6162
exploration/Returns Min               -365.073
exploration/Actions Mean                -0.359926
exploration/Actions Std                  0.759767
exploration/Actions Max                  0.996705
exploration/Actions Min                 -0.999513
exploration/Num Paths                   10
exploration/Average Returns           -165.341
evaluation/num steps total               1.65463e+06
evaluation/num paths total            8232
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.71714
evaluation/Rewards Std                   0.727989
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1149.14
evaluation/Returns Std                 145.869
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.570321
evaluation/Actions Std                   0.422126
evaluation/Actions Max                  -0.112395
evaluation/Actions Min                  -0.98368
evaluation/Num Paths                    24
evaluation/Average Returns           -1149.14
time/data storing (s)                    0.020268
time/evaluation sampling (s)            12.6474
time/exploration sampling (s)            5.0204
time/logging (s)                         0.100742
time/sac training (s)                   32.6052
time/saving (s)                          0.358283
time/training (s)                        0.000168247
time/epoch (s)                          50.7525
time/total (s)                       48002.8
Epoch                                  342
----------------------------------  -----------------
2020-11-10 04:30:25.506140 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 343 finished
----------------------------------  ----------------
replay_buffer/size                  690000
trainer/num train calls             344000
trainer/QF1 Loss                         9.28183
trainer/QF2 Loss                        10.9804
trainer/Policy Loss                     70.8242
trainer/Q1 Predictions Mean            -70.352
trainer/Q1 Predictions Std              88.2979
trainer/Q1 Predictions Max              40.4978
trainer/Q1 Predictions Min            -256.939
trainer/Q2 Predictions Mean            -70.3266
trainer/Q2 Predictions Std              88.262
trainer/Q2 Predictions Max              40.3439
trainer/Q2 Predictions Min            -256.075
trainer/Q Targets Mean                 -71.1615
trainer/Q Targets Std                   89.5699
trainer/Q Targets Max                   40.8656
trainer/Q Targets Min                 -255.738
trainer/Log Pis Mean                     2.3603
trainer/Log Pis Std                      1.89863
trainer/Log Pis Max                      7.67425
trainer/Log Pis Min                     -5.77527
trainer/policy/mean Mean                -0.680776
trainer/policy/mean Std                  0.499982
trainer/policy/mean Max                  0.936086
trainer/policy/mean Min                 -0.994251
trainer/policy/normal/std Mean           0.591913
trainer/policy/normal/std Std            0.119851
trainer/policy/normal/std Max            1.00476
trainer/policy/normal/std Min            0.25106
trainer/policy/normal/log_std Mean      -0.544328
trainer/policy/normal/log_std Std        0.200218
trainer/policy/normal/log_std Max        0.00474814
trainer/policy/normal/log_std Min       -1.38206
trainer/Alpha                            0.0249056
trainer/Alpha Loss                       1.33046
exploration/num steps total         690000
exploration/num paths total           3450
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.26676
exploration/Rewards Std                  1.66571
exploration/Rewards Max                 -5.58485e-96
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -253.351
exploration/Returns Std                113.625
exploration/Returns Max               -105.249
exploration/Returns Min               -431.312
exploration/Actions Mean                -0.623691
exploration/Actions Std                  0.565373
exploration/Actions Max                  0.998708
exploration/Actions Min                 -0.99955
exploration/Num Paths                   10
exploration/Average Returns           -253.351
evaluation/num steps total               1.65946e+06
evaluation/num paths total            8256
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.95307
evaluation/Rewards Std                   1.06682
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -995.568
evaluation/Returns Std                 211.657
evaluation/Returns Max                -644.344
evaluation/Returns Min               -1131.34
evaluation/Actions Mean                 -0.630265
evaluation/Actions Std                   0.388943
evaluation/Actions Max                   0.333083
evaluation/Actions Min                  -0.975931
evaluation/Num Paths                    24
evaluation/Average Returns            -995.568
time/data storing (s)                    0.019881
time/evaluation sampling (s)            12.6272
time/exploration sampling (s)            4.99034
time/logging (s)                         0.072917
time/sac training (s)                   32.7
time/saving (s)                          0.207245
time/training (s)                        0.000154075
time/epoch (s)                          50.6177
time/total (s)                       48184.9
Epoch                                  343
----------------------------------  ----------------
2020-11-10 04:33:23.010287 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 344 finished
----------------------------------  -----------------
replay_buffer/size                  692000
trainer/num train calls             345000
trainer/QF1 Loss                        68.9691
trainer/QF2 Loss                        71.2588
trainer/Policy Loss                     59.9739
trainer/Q1 Predictions Mean            -59.5927
trainer/Q1 Predictions Std              83.0203
trainer/Q1 Predictions Max              49.9528
trainer/Q1 Predictions Min            -229.728
trainer/Q2 Predictions Mean            -59.3878
trainer/Q2 Predictions Std              82.9769
trainer/Q2 Predictions Max              49.8231
trainer/Q2 Predictions Min            -235.04
trainer/Q Targets Mean                 -59.6423
trainer/Q Targets Std                   83.2176
trainer/Q Targets Max                   49.75
trainer/Q Targets Min                 -239.986
trainer/Log Pis Mean                     1.89424
trainer/Log Pis Std                      1.65151
trainer/Log Pis Max                      5.71496
trainer/Log Pis Min                     -5.15346
trainer/policy/mean Mean                -0.522377
trainer/policy/mean Std                  0.631214
trainer/policy/mean Max                  0.959915
trainer/policy/mean Min                 -0.990135
trainer/policy/normal/std Mean           0.569417
trainer/policy/normal/std Std            0.103325
trainer/policy/normal/std Max            0.885766
trainer/policy/normal/std Min            0.228863
trainer/policy/normal/log_std Mean      -0.579532
trainer/policy/normal/log_std Std        0.182881
trainer/policy/normal/log_std Max       -0.121303
trainer/policy/normal/log_std Min       -1.47463
trainer/Alpha                            0.0245287
trainer/Alpha Loss                      -0.392132
exploration/num steps total         692000
exploration/num paths total           3460
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.752497
exploration/Rewards Std                  1.34455
exploration/Rewards Max                 -1.22522e-114
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -150.499
exploration/Returns Std                 91.1294
exploration/Returns Max                -70.8247
exploration/Returns Min               -336.058
exploration/Actions Mean                -0.746088
exploration/Actions Std                  0.41001
exploration/Actions Max                  0.974162
exploration/Actions Min                 -0.999747
exploration/Num Paths                   10
exploration/Average Returns           -150.499
evaluation/num steps total               1.66428e+06
evaluation/num paths total            8280
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.97036
evaluation/Rewards Std                   1.92836
evaluation/Rewards Max                  -4.55527e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -999.042
evaluation/Returns Std                 385.039
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.519453
evaluation/Actions Std                   0.491628
evaluation/Actions Max                   0.896227
evaluation/Actions Min                  -0.97567
evaluation/Num Paths                    24
evaluation/Average Returns            -999.042
time/data storing (s)                    0.0202332
time/evaluation sampling (s)            12.6058
time/exploration sampling (s)            4.97078
time/logging (s)                         0.0649964
time/sac training (s)                   32.3651
time/saving (s)                          0.1857
time/training (s)                        0.000156498
time/epoch (s)                          50.2128
time/total (s)                       48362.3
Epoch                                  344
----------------------------------  -----------------
2020-11-10 04:36:29.337780 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 345 finished
----------------------------------  -----------------
replay_buffer/size                  694000
trainer/num train calls             346000
trainer/QF1 Loss                       104.731
trainer/QF2 Loss                        95.1451
trainer/Policy Loss                     65.135
trainer/Q1 Predictions Mean            -64.5386
trainer/Q1 Predictions Std              84.6704
trainer/Q1 Predictions Max              42.9857
trainer/Q1 Predictions Min            -230.88
trainer/Q2 Predictions Mean            -64.4764
trainer/Q2 Predictions Std              84.7703
trainer/Q2 Predictions Max              43.1684
trainer/Q2 Predictions Min            -230.227
trainer/Q Targets Mean                 -64.5468
trainer/Q Targets Std                   86.2917
trainer/Q Targets Max                   43.07
trainer/Q Targets Min                 -235.568
trainer/Log Pis Mean                     1.99949
trainer/Log Pis Std                      1.65542
trainer/Log Pis Max                      6.96183
trainer/Log Pis Min                     -5.24808
trainer/policy/mean Mean                -0.460202
trainer/policy/mean Std                  0.681319
trainer/policy/mean Max                  0.968542
trainer/policy/mean Min                 -0.98914
trainer/policy/normal/std Mean           0.581292
trainer/policy/normal/std Std            0.103322
trainer/policy/normal/std Max            0.960423
trainer/policy/normal/std Min            0.30304
trainer/policy/normal/log_std Mean      -0.557179
trainer/policy/normal/log_std Std        0.168986
trainer/policy/normal/log_std Max       -0.0403814
trainer/policy/normal/log_std Min       -1.19389
trainer/Alpha                            0.0243888
trainer/Alpha Loss                      -0.00189591
exploration/num steps total         694000
exploration/num paths total           3470
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.522263
exploration/Rewards Std                  1.2593
exploration/Rewards Max                 -1.95534e-183
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -104.453
exploration/Returns Std                101.066
exploration/Returns Max                 -0.00157079
exploration/Returns Min               -305.099
exploration/Actions Mean                -0.469684
exploration/Actions Std                  0.671967
exploration/Actions Max                  0.999033
exploration/Actions Min                 -0.99901
exploration/Num Paths                   10
exploration/Average Returns           -104.453
evaluation/num steps total               1.6691e+06
evaluation/num paths total            8304
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.14416
evaluation/Rewards Std                   1.23887
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1033.98
evaluation/Returns Std                 248.396
evaluation/Returns Max                -625.432
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.50459
evaluation/Actions Std                   0.502494
evaluation/Actions Max                   0.565639
evaluation/Actions Min                  -0.983298
evaluation/Num Paths                    24
evaluation/Average Returns           -1033.98
time/data storing (s)                    0.0196517
time/evaluation sampling (s)            12.7046
time/exploration sampling (s)            4.90726
time/logging (s)                         0.0828457
time/sac training (s)                   32.5992
time/saving (s)                          0.314573
time/training (s)                        0.000175639
time/epoch (s)                          50.6282
time/total (s)                       48548.6
Epoch                                  345
----------------------------------  -----------------
2020-11-10 04:39:45.136223 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 346 finished
----------------------------------  -----------------
replay_buffer/size                  696000
trainer/num train calls             347000
trainer/QF1 Loss                        75.8208
trainer/QF2 Loss                        84.1639
trainer/Policy Loss                     70.786
trainer/Q1 Predictions Mean            -70.3581
trainer/Q1 Predictions Std              89.7463
trainer/Q1 Predictions Max              31.2246
trainer/Q1 Predictions Min            -233.324
trainer/Q2 Predictions Mean            -70.119
trainer/Q2 Predictions Std              89.2518
trainer/Q2 Predictions Max              30.7283
trainer/Q2 Predictions Min            -232.864
trainer/Q Targets Mean                 -71.0563
trainer/Q Targets Std                   90.77
trainer/Q Targets Max                   30.8806
trainer/Q Targets Min                 -237.923
trainer/Log Pis Mean                     1.84489
trainer/Log Pis Std                      1.61152
trainer/Log Pis Max                      6.12965
trainer/Log Pis Min                     -4.16206
trainer/policy/mean Mean                -0.472106
trainer/policy/mean Std                  0.66556
trainer/policy/mean Max                  0.974628
trainer/policy/mean Min                 -0.986606
trainer/policy/normal/std Mean           0.59068
trainer/policy/normal/std Std            0.123365
trainer/policy/normal/std Max            1.0682
trainer/policy/normal/std Min            0.259751
trainer/policy/normal/log_std Mean      -0.546646
trainer/policy/normal/log_std Std        0.198466
trainer/policy/normal/log_std Max        0.0659783
trainer/policy/normal/log_std Min       -1.34803
trainer/Alpha                            0.0240097
trainer/Alpha Loss                      -0.578461
exploration/num steps total         696000
exploration/num paths total           3480
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.718445
exploration/Rewards Std                  1.31068
exploration/Rewards Max                 -6.49803e-234
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -143.689
exploration/Returns Std                 96.9294
exploration/Returns Max                -34.6726
exploration/Returns Min               -333.361
exploration/Actions Mean                -0.412622
exploration/Actions Std                  0.68042
exploration/Actions Max                  0.989786
exploration/Actions Min                 -0.99864
exploration/Num Paths                   10
exploration/Average Returns           -143.689
evaluation/num steps total               1.67393e+06
evaluation/num paths total            8328
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.1928
evaluation/Rewards Std                   1.01891
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1043.75
evaluation/Returns Std                 202.593
evaluation/Returns Max                -628.071
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.461606
evaluation/Actions Std                   0.546511
evaluation/Actions Max                   0.837516
evaluation/Actions Min                  -0.980131
evaluation/Num Paths                    24
evaluation/Average Returns           -1043.75
time/data storing (s)                    0.0198355
time/evaluation sampling (s)            12.5799
time/exploration sampling (s)            5.03358
time/logging (s)                         0.0772999
time/sac training (s)                   32.5973
time/saving (s)                          0.292759
time/training (s)                        0.000168587
time/epoch (s)                          50.6009
time/total (s)                       48744.4
Epoch                                  346
----------------------------------  -----------------
2020-11-10 04:43:15.479991 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 347 finished
----------------------------------  -----------------
replay_buffer/size                  698000
trainer/num train calls             348000
trainer/QF1 Loss                       246.809
trainer/QF2 Loss                       238.313
trainer/Policy Loss                     61.3149
trainer/Q1 Predictions Mean            -60.7486
trainer/Q1 Predictions Std              86.7338
trainer/Q1 Predictions Max              43.4525
trainer/Q1 Predictions Min            -236.394
trainer/Q2 Predictions Mean            -60.7231
trainer/Q2 Predictions Std              86.9251
trainer/Q2 Predictions Max              43.6073
trainer/Q2 Predictions Min            -237.146
trainer/Q Targets Mean                 -60.257
trainer/Q Targets Std                   88.0422
trainer/Q Targets Max                   43.0596
trainer/Q Targets Min                 -238.731
trainer/Log Pis Mean                     1.6521
trainer/Log Pis Std                      1.70316
trainer/Log Pis Max                      7.797
trainer/Log Pis Min                     -5.71798
trainer/policy/mean Mean                -0.419865
trainer/policy/mean Std                  0.707627
trainer/policy/mean Max                  0.973284
trainer/policy/mean Min                 -0.994416
trainer/policy/normal/std Mean           0.586277
trainer/policy/normal/std Std            0.104086
trainer/policy/normal/std Max            0.972573
trainer/policy/normal/std Min            0.34619
trainer/policy/normal/log_std Mean      -0.548213
trainer/policy/normal/log_std Std        0.165128
trainer/policy/normal/log_std Max       -0.02781
trainer/policy/normal/log_std Min       -1.06077
trainer/Alpha                            0.0239324
trainer/Alpha Loss                      -1.29853
exploration/num steps total         698000
exploration/num paths total           3490
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.829163
exploration/Rewards Std                  1.49268
exploration/Rewards Max                 -2.75851e-152
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -165.833
exploration/Returns Std                109.002
exploration/Returns Max                -27.7894
exploration/Returns Min               -347.92
exploration/Actions Mean                -0.31721
exploration/Actions Std                  0.718752
exploration/Actions Max                  0.997176
exploration/Actions Min                 -0.999239
exploration/Num Paths                   10
exploration/Average Returns           -165.833
evaluation/num steps total               1.67875e+06
evaluation/num paths total            8352
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.28514
evaluation/Rewards Std                   1.12727
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1062.31
evaluation/Returns Std                 226.573
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.470764
evaluation/Actions Std                   0.502361
evaluation/Actions Max                   0.155145
evaluation/Actions Min                  -0.972883
evaluation/Num Paths                    24
evaluation/Average Returns           -1062.31
time/data storing (s)                    0.0200862
time/evaluation sampling (s)            12.7869
time/exploration sampling (s)            5.06985
time/logging (s)                         0.0533402
time/sac training (s)                   32.98
time/saving (s)                          0.209876
time/training (s)                        0.000158471
time/epoch (s)                          51.1202
time/total (s)                       48954.7
Epoch                                  347
----------------------------------  -----------------
2020-11-10 04:46:44.036548 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 348 finished
----------------------------------  -----------------
replay_buffer/size                  700000
trainer/num train calls             349000
trainer/QF1 Loss                       133.32
trainer/QF2 Loss                       131.546
trainer/Policy Loss                     63.5165
trainer/Q1 Predictions Mean            -62.94
trainer/Q1 Predictions Std              87.5839
trainer/Q1 Predictions Max              61.2506
trainer/Q1 Predictions Min            -230.056
trainer/Q2 Predictions Mean            -63.1223
trainer/Q2 Predictions Std              87.8747
trainer/Q2 Predictions Max              61.246
trainer/Q2 Predictions Min            -229.572
trainer/Q Targets Mean                 -62.9271
trainer/Q Targets Std                   88.6181
trainer/Q Targets Max                   60.9192
trainer/Q Targets Min                 -235.435
trainer/Log Pis Mean                     2.00984
trainer/Log Pis Std                      1.59513
trainer/Log Pis Max                      5.95179
trainer/Log Pis Min                     -3.78431
trainer/policy/mean Mean                -0.447891
trainer/policy/mean Std                  0.685726
trainer/policy/mean Max                  0.976951
trainer/policy/mean Min                 -0.987384
trainer/policy/normal/std Mean           0.56655
trainer/policy/normal/std Std            0.105063
trainer/policy/normal/std Max            0.994391
trainer/policy/normal/std Min            0.206338
trainer/policy/normal/log_std Mean      -0.584679
trainer/policy/normal/log_std Std        0.181697
trainer/policy/normal/log_std Max       -0.00562518
trainer/policy/normal/log_std Min       -1.57824
trainer/Alpha                            0.0236564
trainer/Alpha Loss                       0.0368353
exploration/num steps total         700000
exploration/num paths total           3500
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.14412
exploration/Rewards Std                  1.61563
exploration/Rewards Max                 -1.56493e-257
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -228.824
exploration/Returns Std                151.196
exploration/Returns Max                -47.2564
exploration/Returns Min               -552.674
exploration/Actions Mean                -0.349103
exploration/Actions Std                  0.722037
exploration/Actions Max                  0.998585
exploration/Actions Min                 -0.999203
exploration/Num Paths                   10
exploration/Average Returns           -228.824
evaluation/num steps total               1.68358e+06
evaluation/num paths total            8376
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.02257
evaluation/Rewards Std                   1.19568
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1009.54
evaluation/Returns Std                 238.888
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.549048
evaluation/Actions Std                   0.51154
evaluation/Actions Max                   0.841963
evaluation/Actions Min                  -0.983219
evaluation/Num Paths                    24
evaluation/Average Returns           -1009.54
time/data storing (s)                    0.0196219
time/evaluation sampling (s)            12.8663
time/exploration sampling (s)            5.04833
time/logging (s)                         0.0736693
time/sac training (s)                   31.8739
time/saving (s)                          0.269843
time/training (s)                        0.000129371
time/epoch (s)                          50.1517
time/total (s)                       49163.2
Epoch                                  348
----------------------------------  -----------------
2020-11-10 04:50:11.598101 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 349 finished
----------------------------------  -----------------
replay_buffer/size                  702000
trainer/num train calls             350000
trainer/QF1 Loss                        56.7173
trainer/QF2 Loss                        57.6053
trainer/Policy Loss                     68.6239
trainer/Q1 Predictions Mean            -68.0605
trainer/Q1 Predictions Std              88.7152
trainer/Q1 Predictions Max              40.6895
trainer/Q1 Predictions Min            -242.318
trainer/Q2 Predictions Mean            -68.1593
trainer/Q2 Predictions Std              88.824
trainer/Q2 Predictions Max              40.3343
trainer/Q2 Predictions Min            -243.698
trainer/Q Targets Mean                 -68.6423
trainer/Q Targets Std                   89.7309
trainer/Q Targets Max                   40.8331
trainer/Q Targets Min                 -245.722
trainer/Log Pis Mean                     2.36745
trainer/Log Pis Std                      1.61907
trainer/Log Pis Max                      7.75191
trainer/Log Pis Min                     -3.16203
trainer/policy/mean Mean                -0.58118
trainer/policy/mean Std                  0.602733
trainer/policy/mean Max                  0.973078
trainer/policy/mean Min                 -0.991193
trainer/policy/normal/std Mean           0.574111
trainer/policy/normal/std Std            0.114892
trainer/policy/normal/std Max            0.883507
trainer/policy/normal/std Min            0.202943
trainer/policy/normal/log_std Mean      -0.57414
trainer/policy/normal/log_std Std        0.195677
trainer/policy/normal/log_std Max       -0.123856
trainer/policy/normal/log_std Min       -1.59483
trainer/Alpha                            0.0233382
trainer/Alpha Loss                       1.38077
exploration/num steps total         702000
exploration/num paths total           3510
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.29851
exploration/Rewards Std                  1.53944
exploration/Rewards Max                 -2.25013e-155
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -259.703
exploration/Returns Std                133.609
exploration/Returns Max                -73.3903
exploration/Returns Min               -481.705
exploration/Actions Mean                -0.577683
exploration/Actions Std                  0.541998
exploration/Actions Max                  0.986208
exploration/Actions Min                 -0.999247
exploration/Num Paths                   10
exploration/Average Returns           -259.703
evaluation/num steps total               1.6884e+06
evaluation/num paths total            8400
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.19752
evaluation/Rewards Std                   1.43371
evaluation/Rewards Max                  -3.06427e-25
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1044.7
evaluation/Returns Std                 287.135
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.568464
evaluation/Actions Std                   0.48048
evaluation/Actions Max                   0.679843
evaluation/Actions Min                  -0.982324
evaluation/Num Paths                    24
evaluation/Average Returns           -1044.7
time/data storing (s)                    0.0215365
time/evaluation sampling (s)            12.8706
time/exploration sampling (s)            4.96763
time/logging (s)                         0.0841951
time/sac training (s)                   33.1032
time/saving (s)                          0.212786
time/training (s)                        0.000147078
time/epoch (s)                          51.2601
time/total (s)                       49370.7
Epoch                                  349
----------------------------------  -----------------
2020-11-10 04:53:30.088160 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 350 finished
----------------------------------  -----------------
replay_buffer/size                  704000
trainer/num train calls             351000
trainer/QF1 Loss                        27.1489
trainer/QF2 Loss                        28.0449
trainer/Policy Loss                     61.5597
trainer/Q1 Predictions Mean            -60.9697
trainer/Q1 Predictions Std              85.1222
trainer/Q1 Predictions Max              44.6938
trainer/Q1 Predictions Min            -229.987
trainer/Q2 Predictions Mean            -61.1591
trainer/Q2 Predictions Std              85.3848
trainer/Q2 Predictions Max              44.682
trainer/Q2 Predictions Min            -235.831
trainer/Q Targets Mean                 -61.9444
trainer/Q Targets Std                   86.5341
trainer/Q Targets Max                   44.8229
trainer/Q Targets Min                 -237.972
trainer/Log Pis Mean                     2.40224
trainer/Log Pis Std                      1.69392
trainer/Log Pis Max                      6.88923
trainer/Log Pis Min                     -5.16126
trainer/policy/mean Mean                -0.654707
trainer/policy/mean Std                  0.535901
trainer/policy/mean Max                  0.966764
trainer/policy/mean Min                 -0.993641
trainer/policy/normal/std Mean           0.572127
trainer/policy/normal/std Std            0.113164
trainer/policy/normal/std Max            0.946213
trainer/policy/normal/std Min            0.20129
trainer/policy/normal/log_std Mean      -0.577633
trainer/policy/normal/log_std Std        0.197587
trainer/policy/normal/log_std Max       -0.0552873
trainer/policy/normal/log_std Min       -1.60301
trainer/Alpha                            0.023737
trainer/Alpha Loss                       1.50468
exploration/num steps total         704000
exploration/num paths total           3520
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.29892
exploration/Rewards Std                  1.5556
exploration/Rewards Max                 -1.38425e-118
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -259.783
exploration/Returns Std                147.777
exploration/Returns Max                -53.1662
exploration/Returns Min               -498.939
exploration/Actions Mean                -0.571771
exploration/Actions Std                  0.607939
exploration/Actions Max                  0.993649
exploration/Actions Min                 -0.999036
exploration/Num Paths                   10
exploration/Average Returns           -259.783
evaluation/num steps total               1.69322e+06
evaluation/num paths total            8424
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.00238
evaluation/Rewards Std                   1.11879
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1005.48
evaluation/Returns Std                 221.542
evaluation/Returns Max                -644.344
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.558185
evaluation/Actions Std                   0.465871
evaluation/Actions Max                   0.456224
evaluation/Actions Min                  -0.980293
evaluation/Num Paths                    24
evaluation/Average Returns           -1005.48
time/data storing (s)                    0.0206642
time/evaluation sampling (s)            12.7402
time/exploration sampling (s)            4.83101
time/logging (s)                         0.0494317
time/sac training (s)                   31.9097
time/saving (s)                          0.18348
time/training (s)                        0.000140848
time/epoch (s)                          49.7347
time/total (s)                       49569.2
Epoch                                  350
----------------------------------  -----------------
2020-11-10 04:56:44.659047 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 351 finished
----------------------------------  -----------------
replay_buffer/size                  706000
trainer/num train calls             352000
trainer/QF1 Loss                       254.499
trainer/QF2 Loss                       248.524
trainer/Policy Loss                     63.819
trainer/Q1 Predictions Mean            -63.2112
trainer/Q1 Predictions Std              85.0592
trainer/Q1 Predictions Max              31.1561
trainer/Q1 Predictions Min            -238.245
trainer/Q2 Predictions Mean            -63.2521
trainer/Q2 Predictions Std              85.297
trainer/Q2 Predictions Max              31.3867
trainer/Q2 Predictions Min            -236.125
trainer/Q Targets Mean                 -61.641
trainer/Q Targets Std                   85.215
trainer/Q Targets Max                   31.1831
trainer/Q Targets Min                 -239.064
trainer/Log Pis Mean                     2.03285
trainer/Log Pis Std                      1.63445
trainer/Log Pis Max                      6.08658
trainer/Log Pis Min                     -3.60908
trainer/policy/mean Mean                -0.425876
trainer/policy/mean Std                  0.70461
trainer/policy/mean Max                  0.982822
trainer/policy/mean Min                 -0.988825
trainer/policy/normal/std Mean           0.568756
trainer/policy/normal/std Std            0.107743
trainer/policy/normal/std Max            1.00605
trainer/policy/normal/std Min            0.206164
trainer/policy/normal/log_std Mean      -0.582241
trainer/policy/normal/log_std Std        0.191974
trainer/policy/normal/log_std Max        0.00603401
trainer/policy/normal/log_std Min       -1.57908
trainer/Alpha                            0.0235362
trainer/Alpha Loss                       0.123153
exploration/num steps total         706000
exploration/num paths total           3530
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.914577
exploration/Rewards Std                  1.50741
exploration/Rewards Max                 -1.13977e-181
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -182.915
exploration/Returns Std                110.827
exploration/Returns Max                -25.0732
exploration/Returns Min               -383.965
exploration/Actions Mean                -0.488686
exploration/Actions Std                  0.656543
exploration/Actions Max                  0.996991
exploration/Actions Min                 -0.998831
exploration/Num Paths                   10
exploration/Average Returns           -182.915
evaluation/num steps total               1.69805e+06
evaluation/num paths total            8448
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   7.63318e-11
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   1.0595e-09
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.587172
evaluation/Actions Std                   0.390835
evaluation/Actions Max                  -0.196327
evaluation/Actions Min                  -0.97856
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0200019
time/evaluation sampling (s)            12.4196
time/exploration sampling (s)            4.95899
time/logging (s)                         0.0552844
time/sac training (s)                   32.6801
time/saving (s)                          0.299091
time/training (s)                        0.00014912
time/epoch (s)                          50.4332
time/total (s)                       49763.7
Epoch                                  351
----------------------------------  -----------------
2020-11-10 05:00:02.482999 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 352 finished
----------------------------------  ----------------
replay_buffer/size                  708000
trainer/num train calls             353000
trainer/QF1 Loss                       107.616
trainer/QF2 Loss                       101.448
trainer/Policy Loss                     60.7929
trainer/Q1 Predictions Mean            -60.3056
trainer/Q1 Predictions Std              86.8422
trainer/Q1 Predictions Max              57.9336
trainer/Q1 Predictions Min            -237.382
trainer/Q2 Predictions Mean            -60.2746
trainer/Q2 Predictions Std              86.8044
trainer/Q2 Predictions Max              58.3726
trainer/Q2 Predictions Min            -235.986
trainer/Q Targets Mean                 -59.8689
trainer/Q Targets Std                   87.2253
trainer/Q Targets Max                   58.8726
trainer/Q Targets Min                 -239.171
trainer/Log Pis Mean                     1.83548
trainer/Log Pis Std                      2.05331
trainer/Log Pis Max                      7.39655
trainer/Log Pis Min                     -7.94434
trainer/policy/mean Mean                -0.633856
trainer/policy/mean Std                  0.54674
trainer/policy/mean Max                  0.918036
trainer/policy/mean Min                 -0.99033
trainer/policy/normal/std Mean           0.605935
trainer/policy/normal/std Std            0.114949
trainer/policy/normal/std Max            0.984555
trainer/policy/normal/std Min            0.217741
trainer/policy/normal/log_std Mean      -0.517856
trainer/policy/normal/log_std Std        0.181892
trainer/policy/normal/log_std Max       -0.0155658
trainer/policy/normal/log_std Min       -1.52445
trainer/Alpha                            0.0240768
trainer/Alpha Loss                      -0.613075
exploration/num steps total         708000
exploration/num paths total           3540
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.0129
exploration/Rewards Std                  1.49215
exploration/Rewards Max                 -3.21023e-94
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -202.58
exploration/Returns Std                133.581
exploration/Returns Max                -29.6805
exploration/Returns Min               -497.028
exploration/Actions Mean                -0.655276
exploration/Actions Std                  0.506078
exploration/Actions Max                  0.986695
exploration/Actions Min                 -0.999601
exploration/Num Paths                   10
exploration/Average Returns           -202.58
evaluation/num steps total               1.70287e+06
evaluation/num paths total            8472
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.52672
evaluation/Rewards Std                   1.80138
evaluation/Rewards Max                  -5.4081e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -909.871
evaluation/Returns Std                 358.466
evaluation/Returns Max                 -18.7097
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.555338
evaluation/Actions Std                   0.468125
evaluation/Actions Max                   0.618082
evaluation/Actions Min                  -0.974306
evaluation/Num Paths                    24
evaluation/Average Returns            -909.871
time/data storing (s)                    0.0204791
time/evaluation sampling (s)            12.7599
time/exploration sampling (s)            4.99662
time/logging (s)                         0.0690241
time/sac training (s)                   32.6566
time/saving (s)                          0.484971
time/training (s)                        0.000137909
time/epoch (s)                          50.9877
time/total (s)                       49961.5
Epoch                                  352
----------------------------------  ----------------
2020-11-10 05:03:24.404920 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 353 finished
----------------------------------  -----------------
replay_buffer/size                  710000
trainer/num train calls             354000
trainer/QF1 Loss                       234.83
trainer/QF2 Loss                       219.656
trainer/Policy Loss                     64.9894
trainer/Q1 Predictions Mean            -64.4929
trainer/Q1 Predictions Std              83.2701
trainer/Q1 Predictions Max              59.0926
trainer/Q1 Predictions Min            -232.242
trainer/Q2 Predictions Mean            -64.4703
trainer/Q2 Predictions Std              83.1449
trainer/Q2 Predictions Max              59.0406
trainer/Q2 Predictions Min            -233.733
trainer/Q Targets Mean                 -64.0728
trainer/Q Targets Std                   83.7579
trainer/Q Targets Max                   58.857
trainer/Q Targets Min                 -237.071
trainer/Log Pis Mean                     2.15671
trainer/Log Pis Std                      1.85966
trainer/Log Pis Max                      8.09425
trainer/Log Pis Min                     -4.98246
trainer/policy/mean Mean                -0.555897
trainer/policy/mean Std                  0.629403
trainer/policy/mean Max                  0.974044
trainer/policy/mean Min                 -0.998651
trainer/policy/normal/std Mean           0.602861
trainer/policy/normal/std Std            0.106647
trainer/policy/normal/std Max            0.929089
trainer/policy/normal/std Min            0.290013
trainer/policy/normal/log_std Mean      -0.520558
trainer/policy/normal/log_std Std        0.167618
trainer/policy/normal/log_std Max       -0.0735506
trainer/policy/normal/log_std Min       -1.23783
trainer/Alpha                            0.0242802
trainer/Alpha Loss                       0.582678
exploration/num steps total         710000
exploration/num paths total           3550
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.87043
exploration/Rewards Std                  1.65073
exploration/Rewards Max                 -3.79564e-245
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -174.086
exploration/Returns Std                 56.8285
exploration/Returns Max                -92.5817
exploration/Returns Min               -254.554
exploration/Actions Mean                -0.496536
exploration/Actions Std                  0.70443
exploration/Actions Max                  0.997872
exploration/Actions Min                 -0.999433
exploration/Num Paths                   10
exploration/Average Returns           -174.086
evaluation/num steps total               1.7077e+06
evaluation/num paths total            8496
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   1.78366e-14
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   2.36658e-13
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.799735
evaluation/Actions Std                   0.180546
evaluation/Actions Max                  -0.61906
evaluation/Actions Min                  -0.980285
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0200791
time/evaluation sampling (s)            12.6516
time/exploration sampling (s)            4.90741
time/logging (s)                         0.0446467
time/sac training (s)                   32.8879
time/saving (s)                          0.110169
time/training (s)                        0.000176408
time/epoch (s)                          50.622
time/total (s)                       50163.4
Epoch                                  353
----------------------------------  -----------------
2020-11-10 05:06:53.109427 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 354 finished
----------------------------------  ----------------
replay_buffer/size                  712000
trainer/num train calls             355000
trainer/QF1 Loss                        75.84
trainer/QF2 Loss                        78.5687
trainer/Policy Loss                     71.3792
trainer/Q1 Predictions Mean            -70.7239
trainer/Q1 Predictions Std              91.7816
trainer/Q1 Predictions Max              58.334
trainer/Q1 Predictions Min            -244.373
trainer/Q2 Predictions Mean            -70.7349
trainer/Q2 Predictions Std              91.7434
trainer/Q2 Predictions Max              58.5673
trainer/Q2 Predictions Min            -243.553
trainer/Q Targets Mean                 -70.5902
trainer/Q Targets Std                   92.478
trainer/Q Targets Max                   58.5826
trainer/Q Targets Min                 -243.765
trainer/Log Pis Mean                     1.98007
trainer/Log Pis Std                      1.53068
trainer/Log Pis Max                      6.1619
trainer/Log Pis Min                     -3.48667
trainer/policy/mean Mean                -0.440093
trainer/policy/mean Std                  0.68164
trainer/policy/mean Max                  0.972325
trainer/policy/mean Min                 -0.990005
trainer/policy/normal/std Mean           0.575493
trainer/policy/normal/std Std            0.103562
trainer/policy/normal/std Max            0.867552
trainer/policy/normal/std Min            0.241464
trainer/policy/normal/log_std Mean      -0.568139
trainer/policy/normal/log_std Std        0.176403
trainer/policy/normal/log_std Max       -0.142079
trainer/policy/normal/log_std Min       -1.42104
trainer/Alpha                            0.0239652
trainer/Alpha Loss                      -0.0743512
exploration/num steps total         712000
exploration/num paths total           3560
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.695713
exploration/Rewards Std                  1.47288
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -139.143
exploration/Returns Std                100.032
exploration/Returns Max                -32.0135
exploration/Returns Min               -384.556
exploration/Actions Mean                -0.479954
exploration/Actions Std                  0.660267
exploration/Actions Max                  0.99493
exploration/Actions Min                 -0.999009
exploration/Num Paths                   10
exploration/Average Returns           -139.143
evaluation/num steps total               1.71252e+06
evaluation/num paths total            8520
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.14423
evaluation/Rewards Std                   1.50713
evaluation/Rewards Max                  -5.781e-15
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1033.99
evaluation/Returns Std                 301.052
evaluation/Returns Max                 -15.4139
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.492668
evaluation/Actions Std                   0.495594
evaluation/Actions Max                   0.624737
evaluation/Actions Min                  -0.978363
evaluation/Num Paths                    24
evaluation/Average Returns           -1033.99
time/data storing (s)                    0.0205591
time/evaluation sampling (s)            12.6091
time/exploration sampling (s)            4.71881
time/logging (s)                         0.0716665
time/sac training (s)                   32.5779
time/saving (s)                          0.27833
time/training (s)                        0.000149846
time/epoch (s)                          50.2765
time/total (s)                       50372.1
Epoch                                  354
----------------------------------  ----------------
2020-11-10 05:10:32.781934 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 355 finished
----------------------------------  -----------------
replay_buffer/size                  714000
trainer/num train calls             356000
trainer/QF1 Loss                        10.937
trainer/QF2 Loss                         9.5441
trainer/Policy Loss                     63.0104
trainer/Q1 Predictions Mean            -62.4109
trainer/Q1 Predictions Std              85.839
trainer/Q1 Predictions Max              37.8747
trainer/Q1 Predictions Min            -244.043
trainer/Q2 Predictions Mean            -62.6719
trainer/Q2 Predictions Std              86.0133
trainer/Q2 Predictions Max              37.7233
trainer/Q2 Predictions Min            -243.175
trainer/Q Targets Mean                 -63.1083
trainer/Q Targets Std                   86.7024
trainer/Q Targets Max                   37.7571
trainer/Q Targets Min                 -243.826
trainer/Log Pis Mean                     2.0611
trainer/Log Pis Std                      1.60593
trainer/Log Pis Max                      5.70249
trainer/Log Pis Min                     -3.43666
trainer/policy/mean Mean                -0.477503
trainer/policy/mean Std                  0.680401
trainer/policy/mean Max                  0.969079
trainer/policy/mean Min                 -0.990451
trainer/policy/normal/std Mean           0.578349
trainer/policy/normal/std Std            0.099181
trainer/policy/normal/std Max            0.896026
trainer/policy/normal/std Min            0.210836
trainer/policy/normal/log_std Mean      -0.561934
trainer/policy/normal/log_std Std        0.169913
trainer/policy/normal/log_std Max       -0.109785
trainer/policy/normal/log_std Min       -1.55668
trainer/Alpha                            0.0237292
trainer/Alpha Loss                       0.228585
exploration/num steps total         714000
exploration/num paths total           3570
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.948975
exploration/Rewards Std                  1.68449
exploration/Rewards Max                 -3.04439e-127
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -189.795
exploration/Returns Std                 89.8434
exploration/Returns Max                -56.392
exploration/Returns Min               -378.225
exploration/Actions Mean                -0.603176
exploration/Actions Std                  0.579503
exploration/Actions Max                  0.992704
exploration/Actions Min                 -0.999094
exploration/Num Paths                   10
exploration/Average Returns           -189.795
evaluation/num steps total               1.71734e+06
evaluation/num paths total            8544
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.7056
evaluation/Rewards Std                   1.31351
evaluation/Rewards Max                  -2.34715e-13
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1146.83
evaluation/Returns Std                 263.833
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.642497
evaluation/Actions Std                   0.355867
evaluation/Actions Max                   0.619369
evaluation/Actions Min                  -0.98568
evaluation/Num Paths                    24
evaluation/Average Returns           -1146.83
time/data storing (s)                    0.0271492
time/evaluation sampling (s)            12.7502
time/exploration sampling (s)            5.03023
time/logging (s)                         0.0670329
time/sac training (s)                   32.5992
time/saving (s)                          0.400313
time/training (s)                        0.000170623
time/epoch (s)                          50.8742
time/total (s)                       50591.7
Epoch                                  355
----------------------------------  -----------------
2020-11-10 05:13:59.251577 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 356 finished
----------------------------------  -----------------
replay_buffer/size                  716000
trainer/num train calls             357000
trainer/QF1 Loss                        80.7423
trainer/QF2 Loss                        80.4865
trainer/Policy Loss                     65.5087
trainer/Q1 Predictions Mean            -65.1144
trainer/Q1 Predictions Std              87.8027
trainer/Q1 Predictions Max              29.0532
trainer/Q1 Predictions Min            -236.221
trainer/Q2 Predictions Mean            -65.0523
trainer/Q2 Predictions Std              87.7685
trainer/Q2 Predictions Max              29.1645
trainer/Q2 Predictions Min            -236.155
trainer/Q Targets Mean                 -65.5553
trainer/Q Targets Std                   88.6417
trainer/Q Targets Max                   28.5562
trainer/Q Targets Min                 -240.778
trainer/Log Pis Mean                     1.77665
trainer/Log Pis Std                      1.70388
trainer/Log Pis Max                      5.20225
trainer/Log Pis Min                     -5.12916
trainer/policy/mean Mean                -0.503394
trainer/policy/mean Std                  0.658895
trainer/policy/mean Max                  0.949819
trainer/policy/mean Min                 -0.994794
trainer/policy/normal/std Mean           0.581905
trainer/policy/normal/std Std            0.103949
trainer/policy/normal/std Max            0.948922
trainer/policy/normal/std Min            0.226053
trainer/policy/normal/log_std Mean      -0.55736
trainer/policy/normal/log_std Std        0.180346
trainer/policy/normal/log_std Max       -0.0524284
trainer/policy/normal/log_std Min       -1.48699
trainer/Alpha                            0.0237579
trainer/Alpha Loss                      -0.835298
exploration/num steps total         716000
exploration/num paths total           3580
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.952838
exploration/Rewards Std                  1.47446
exploration/Rewards Max                 -1.72052e-166
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -190.568
exploration/Returns Std                106.977
exploration/Returns Max                -35.1213
exploration/Returns Min               -355.155
exploration/Actions Mean                -0.412676
exploration/Actions Std                  0.710711
exploration/Actions Max                  0.998284
exploration/Actions Min                 -0.999062
exploration/Num Paths                   10
exploration/Average Returns           -190.568
evaluation/num steps total               1.72217e+06
evaluation/num paths total            8568
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.58274
evaluation/Rewards Std                   1.77269
evaluation/Rewards Max                  -2.19993e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -921.13
evaluation/Returns Std                 354.594
evaluation/Returns Max                  -3.4012
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.578976
evaluation/Actions Std                   0.44668
evaluation/Actions Max                   0.367745
evaluation/Actions Min                  -0.981793
evaluation/Num Paths                    24
evaluation/Average Returns            -921.13
time/data storing (s)                    0.0206003
time/evaluation sampling (s)            12.5755
time/exploration sampling (s)            4.98043
time/logging (s)                         0.0415454
time/sac training (s)                   32.6014
time/saving (s)                          0.22519
time/training (s)                        0.000108063
time/epoch (s)                          50.4448
time/total (s)                       50798.1
Epoch                                  356
----------------------------------  -----------------
2020-11-10 05:17:31.148114 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 357 finished
----------------------------------  -----------------
replay_buffer/size                  718000
trainer/num train calls             358000
trainer/QF1 Loss                       163.749
trainer/QF2 Loss                       173.297
trainer/Policy Loss                     57.1216
trainer/Q1 Predictions Mean            -56.7172
trainer/Q1 Predictions Std              81.2119
trainer/Q1 Predictions Max              34.2808
trainer/Q1 Predictions Min            -232.623
trainer/Q2 Predictions Mean            -56.6069
trainer/Q2 Predictions Std              81.2082
trainer/Q2 Predictions Max              34.3445
trainer/Q2 Predictions Min            -233.837
trainer/Q Targets Mean                 -56.0897
trainer/Q Targets Std                   81.7047
trainer/Q Targets Max                   34.6602
trainer/Q Targets Min                 -236.462
trainer/Log Pis Mean                     2.20706
trainer/Log Pis Std                      1.87267
trainer/Log Pis Max                      6.66285
trainer/Log Pis Min                     -5.57326
trainer/policy/mean Mean                -0.541588
trainer/policy/mean Std                  0.629516
trainer/policy/mean Max                  0.947734
trainer/policy/mean Min                 -0.992377
trainer/policy/normal/std Mean           0.572811
trainer/policy/normal/std Std            0.102793
trainer/policy/normal/std Max            0.947189
trainer/policy/normal/std Min            0.206637
trainer/policy/normal/log_std Mean      -0.572698
trainer/policy/normal/log_std Std        0.175803
trainer/policy/normal/log_std Max       -0.0542564
trainer/policy/normal/log_std Min       -1.57679
trainer/Alpha                            0.0240817
trainer/Alpha Loss                       0.771577
exploration/num steps total         718000
exploration/num paths total           3590
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.944015
exploration/Rewards Std                  1.59303
exploration/Rewards Max                 -3.36437e-196
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -188.803
exploration/Returns Std                123.829
exploration/Returns Max                -62.3287
exploration/Returns Min               -467.387
exploration/Actions Mean                -0.398839
exploration/Actions Std                  0.718133
exploration/Actions Max                  0.997691
exploration/Actions Min                 -0.999214
exploration/Num Paths                   10
exploration/Average Returns           -188.803
evaluation/num steps total               1.72699e+06
evaluation/num paths total            8592
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.09843
evaluation/Rewards Std                   1.20322
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1024.78
evaluation/Returns Std                 239.497
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.545156
evaluation/Actions Std                   0.497239
evaluation/Actions Max                   0.574369
evaluation/Actions Min                  -0.982078
evaluation/Num Paths                    24
evaluation/Average Returns           -1024.78
time/data storing (s)                    0.0194145
time/evaluation sampling (s)            12.5886
time/exploration sampling (s)            5.04621
time/logging (s)                         0.0427298
time/sac training (s)                   32.5823
time/saving (s)                          0.200666
time/training (s)                        0.000147582
time/epoch (s)                          50.4801
time/total (s)                       51010
Epoch                                  357
----------------------------------  -----------------
2020-11-10 05:20:56.253796 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 358 finished
----------------------------------  ----------------
replay_buffer/size                  720000
trainer/num train calls             359000
trainer/QF1 Loss                        57.6916
trainer/QF2 Loss                        52.2065
trainer/Policy Loss                     64.7244
trainer/Q1 Predictions Mean            -64.0806
trainer/Q1 Predictions Std              84.8672
trainer/Q1 Predictions Max              41.6442
trainer/Q1 Predictions Min            -240.547
trainer/Q2 Predictions Mean            -64.2306
trainer/Q2 Predictions Std              85.0758
trainer/Q2 Predictions Max              41.4099
trainer/Q2 Predictions Min            -240.996
trainer/Q Targets Mean                 -64.1087
trainer/Q Targets Std                   85.6946
trainer/Q Targets Max                   41.4741
trainer/Q Targets Min                 -242.419
trainer/Log Pis Mean                     1.8232
trainer/Log Pis Std                      1.72504
trainer/Log Pis Max                      5.45943
trainer/Log Pis Min                     -4.63372
trainer/policy/mean Mean                -0.343211
trainer/policy/mean Std                  0.757804
trainer/policy/mean Max                  0.976212
trainer/policy/mean Min                 -0.990532
trainer/policy/normal/std Mean           0.576053
trainer/policy/normal/std Std            0.0862292
trainer/policy/normal/std Max            0.852939
trainer/policy/normal/std Min            0.204918
trainer/policy/normal/log_std Mean      -0.562908
trainer/policy/normal/log_std Std        0.152838
trainer/policy/normal/log_std Max       -0.159068
trainer/policy/normal/log_std Min       -1.58515
trainer/Alpha                            0.0242145
trainer/Alpha Loss                      -0.657844
exploration/num steps total         720000
exploration/num paths total           3600
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.957896
exploration/Rewards Std                  1.60702
exploration/Rewards Max                 -1.2355e-203
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.579
exploration/Returns Std                111.514
exploration/Returns Max                -47.0369
exploration/Returns Min               -479.172
exploration/Actions Mean                -0.324615
exploration/Actions Std                  0.746626
exploration/Actions Max                  0.996911
exploration/Actions Min                 -0.998909
exploration/Num Paths                   10
exploration/Average Returns           -191.579
evaluation/num steps total               1.73182e+06
evaluation/num paths total            8616
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67501
evaluation/Rewards Std                   0.879357
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.68
evaluation/Returns Std                 176.393
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.389492
evaluation/Actions Std                   0.597458
evaluation/Actions Max                   0.784769
evaluation/Actions Min                  -0.973332
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.68
time/data storing (s)                    0.0257682
time/evaluation sampling (s)            13.248
time/exploration sampling (s)            5.20364
time/logging (s)                         0.0545031
time/sac training (s)                   32.0699
time/saving (s)                          0.32217
time/training (s)                        0.000152228
time/epoch (s)                          50.9242
time/total (s)                       51215
Epoch                                  358
----------------------------------  ----------------
2020-11-10 05:24:21.636353 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 359 finished
----------------------------------  -----------------
replay_buffer/size                  722000
trainer/num train calls             360000
trainer/QF1 Loss                        27.1975
trainer/QF2 Loss                        36.2539
trainer/Policy Loss                     73.9095
trainer/Q1 Predictions Mean            -73.3459
trainer/Q1 Predictions Std              88.6593
trainer/Q1 Predictions Max              43.1089
trainer/Q1 Predictions Min            -236.498
trainer/Q2 Predictions Mean            -73.3953
trainer/Q2 Predictions Std              88.6991
trainer/Q2 Predictions Max              42.8932
trainer/Q2 Predictions Min            -233.417
trainer/Q Targets Mean                 -73.9852
trainer/Q Targets Std                   89.7767
trainer/Q Targets Max                   42.4925
trainer/Q Targets Min                 -238.972
trainer/Log Pis Mean                     1.93874
trainer/Log Pis Std                      1.78909
trainer/Log Pis Max                      5.86038
trainer/Log Pis Min                     -4.31298
trainer/policy/mean Mean                -0.304772
trainer/policy/mean Std                  0.778978
trainer/policy/mean Max                  0.980379
trainer/policy/mean Min                 -0.985206
trainer/policy/normal/std Mean           0.570821
trainer/policy/normal/std Std            0.0903822
trainer/policy/normal/std Max            0.851153
trainer/policy/normal/std Min            0.214106
trainer/policy/normal/log_std Mean      -0.573462
trainer/policy/normal/log_std Std        0.162392
trainer/policy/normal/log_std Max       -0.161163
trainer/policy/normal/log_std Min       -1.54128
trainer/Alpha                            0.0241201
trainer/Alpha Loss                      -0.228181
exploration/num steps total         722000
exploration/num paths total           3610
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.38213
exploration/Rewards Std                  1.53303
exploration/Rewards Max                 -1.60346e-234
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -276.426
exploration/Returns Std                152.956
exploration/Returns Max                -73.2044
exploration/Returns Min               -521.164
exploration/Actions Mean                -0.278816
exploration/Actions Std                  0.756664
exploration/Actions Max                  0.998812
exploration/Actions Min                 -0.999203
exploration/Num Paths                   10
exploration/Average Returns           -276.426
evaluation/num steps total               1.73664e+06
evaluation/num paths total            8640
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.210962
evaluation/Actions Std                   0.763626
evaluation/Actions Max                   0.564938
evaluation/Actions Min                  -0.976988
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.019588
time/evaluation sampling (s)            12.6866
time/exploration sampling (s)            5.03081
time/logging (s)                         0.0510375
time/sac training (s)                   32.439
time/saving (s)                          0.213044
time/training (s)                        0.000155587
time/epoch (s)                          50.4402
time/total (s)                       51420.4
Epoch                                  359
----------------------------------  -----------------
2020-11-10 05:27:48.780778 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 360 finished
----------------------------------  -----------------
replay_buffer/size                  724000
trainer/num train calls             361000
trainer/QF1 Loss                        31.0417
trainer/QF2 Loss                        35.5725
trainer/Policy Loss                     62.2425
trainer/Q1 Predictions Mean            -61.753
trainer/Q1 Predictions Std              84.6214
trainer/Q1 Predictions Max              51.02
trainer/Q1 Predictions Min            -248.144
trainer/Q2 Predictions Mean            -61.89
trainer/Q2 Predictions Std              84.6488
trainer/Q2 Predictions Max              51.3575
trainer/Q2 Predictions Min            -247.698
trainer/Q Targets Mean                 -61.9685
trainer/Q Targets Std                   84.9504
trainer/Q Targets Max                   51.9457
trainer/Q Targets Min                 -247.218
trainer/Log Pis Mean                     1.97781
trainer/Log Pis Std                      1.82181
trainer/Log Pis Max                      6.69894
trainer/Log Pis Min                     -3.85303
trainer/policy/mean Mean                -0.331213
trainer/policy/mean Std                  0.773744
trainer/policy/mean Max                  0.980936
trainer/policy/mean Min                 -0.990735
trainer/policy/normal/std Mean           0.572632
trainer/policy/normal/std Std            0.0850027
trainer/policy/normal/std Max            0.853806
trainer/policy/normal/std Min            0.235694
trainer/policy/normal/log_std Mean      -0.568704
trainer/policy/normal/log_std Std        0.151662
trainer/policy/normal/log_std Max       -0.158052
trainer/policy/normal/log_std Min       -1.44522
trainer/Alpha                            0.0243952
trainer/Alpha Loss                      -0.0823885
exploration/num steps total         724000
exploration/num paths total           3620
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.545063
exploration/Rewards Std                  1.39151
exploration/Rewards Max                 -1.16902e-115
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -109.013
exploration/Returns Std                 66.3399
exploration/Returns Max                -53.8288
exploration/Returns Min               -293.904
exploration/Actions Mean                -0.209325
exploration/Actions Std                  0.826031
exploration/Actions Max                  0.999277
exploration/Actions Min                 -0.999101
exploration/Num Paths                   10
exploration/Average Returns           -109.013
evaluation/num steps total               1.74146e+06
evaluation/num paths total            8664
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61151
evaluation/Rewards Std                   0.860408
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1127.91
evaluation/Returns Std                 172.558
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.278741
evaluation/Actions Std                   0.704846
evaluation/Actions Max                   0.896429
evaluation/Actions Min                  -0.979002
evaluation/Num Paths                    24
evaluation/Average Returns           -1127.91
time/data storing (s)                    0.0215701
time/evaluation sampling (s)            12.6373
time/exploration sampling (s)            5.00299
time/logging (s)                         0.0850993
time/sac training (s)                   32.3081
time/saving (s)                          0.485038
time/training (s)                        0.00015532
time/epoch (s)                          50.5402
time/total (s)                       51627.5
Epoch                                  360
----------------------------------  -----------------
2020-11-10 05:31:13.232629 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 361 finished
----------------------------------  ----------------
replay_buffer/size                  726000
trainer/num train calls             362000
trainer/QF1 Loss                        10.6712
trainer/QF2 Loss                        14.6612
trainer/Policy Loss                     55.4715
trainer/Q1 Predictions Mean            -54.952
trainer/Q1 Predictions Std              80.8102
trainer/Q1 Predictions Max              40.4209
trainer/Q1 Predictions Min            -229.826
trainer/Q2 Predictions Mean            -54.978
trainer/Q2 Predictions Std              80.5998
trainer/Q2 Predictions Max              40.2935
trainer/Q2 Predictions Min            -229.566
trainer/Q Targets Mean                 -55.3755
trainer/Q Targets Std                   81.4266
trainer/Q Targets Max                   40.4421
trainer/Q Targets Min                 -234.652
trainer/Log Pis Mean                     2.18506
trainer/Log Pis Std                      1.84351
trainer/Log Pis Max                      6.91294
trainer/Log Pis Min                     -5.05356
trainer/policy/mean Mean                -0.653523
trainer/policy/mean Std                  0.535309
trainer/policy/mean Max                  0.935807
trainer/policy/mean Min                 -0.991751
trainer/policy/normal/std Mean           0.609187
trainer/policy/normal/std Std            0.119222
trainer/policy/normal/std Max            0.970801
trainer/policy/normal/std Min            0.306875
trainer/policy/normal/log_std Mean      -0.513499
trainer/policy/normal/log_std Std        0.186397
trainer/policy/normal/log_std Max       -0.0296337
trainer/policy/normal/log_std Min       -1.18132
trainer/Alpha                            0.0250132
trainer/Alpha Loss                       0.682571
exploration/num steps total         726000
exploration/num paths total           3630
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.905747
exploration/Rewards Std                  1.69496
exploration/Rewards Max                 -5.3718e-188
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -181.149
exploration/Returns Std                151.882
exploration/Returns Max                -52.9301
exploration/Returns Min               -593.463
exploration/Actions Mean                -0.672559
exploration/Actions Std                  0.439041
exploration/Actions Max                  0.968268
exploration/Actions Min                 -0.999222
exploration/Num Paths                   10
exploration/Average Returns           -181.149
evaluation/num steps total               1.74629e+06
evaluation/num paths total            8688
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.20317
evaluation/Rewards Std                   1.42578
evaluation/Rewards Max                  -2.21562e-12
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1045.84
evaluation/Returns Std                 283.992
evaluation/Returns Max                 -27.7894
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.614175
evaluation/Actions Std                   0.413781
evaluation/Actions Max                   0.911211
evaluation/Actions Min                  -0.977272
evaluation/Num Paths                    24
evaluation/Average Returns           -1045.84
time/data storing (s)                    0.0218949
time/evaluation sampling (s)            12.6927
time/exploration sampling (s)            4.99525
time/logging (s)                         0.0605614
time/sac training (s)                   32.6996
time/saving (s)                          0.406158
time/training (s)                        0.000222414
time/epoch (s)                          50.8764
time/total (s)                       51831.9
Epoch                                  361
----------------------------------  ----------------
2020-11-10 05:34:58.981821 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 362 finished
----------------------------------  -----------------
replay_buffer/size                  728000
trainer/num train calls             363000
trainer/QF1 Loss                        78.0661
trainer/QF2 Loss                        78.078
trainer/Policy Loss                     63.3331
trainer/Q1 Predictions Mean            -62.9234
trainer/Q1 Predictions Std              86.3135
trainer/Q1 Predictions Max              36.618
trainer/Q1 Predictions Min            -232.748
trainer/Q2 Predictions Mean            -62.9002
trainer/Q2 Predictions Std              86.2325
trainer/Q2 Predictions Max              36.513
trainer/Q2 Predictions Min            -232.122
trainer/Q Targets Mean                 -62.8765
trainer/Q Targets Std                   87.0588
trainer/Q Targets Max                   36.2001
trainer/Q Targets Min                 -237.35
trainer/Log Pis Mean                     1.85591
trainer/Log Pis Std                      1.66321
trainer/Log Pis Max                      6.70732
trainer/Log Pis Min                     -3.10799
trainer/policy/mean Mean                -0.502987
trainer/policy/mean Std                  0.642345
trainer/policy/mean Max                  0.956486
trainer/policy/mean Min                 -0.98751
trainer/policy/normal/std Mean           0.576352
trainer/policy/normal/std Std            0.107066
trainer/policy/normal/std Max            0.863136
trainer/policy/normal/std Min            0.210669
trainer/policy/normal/log_std Mean      -0.568163
trainer/policy/normal/log_std Std        0.186485
trainer/policy/normal/log_std Max       -0.147184
trainer/policy/normal/log_std Min       -1.55747
trainer/Alpha                            0.0250688
trainer/Alpha Loss                      -0.531147
exploration/num steps total         728000
exploration/num paths total           3640
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.874943
exploration/Rewards Std                  1.61886
exploration/Rewards Max                 -9.00528e-142
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -174.989
exploration/Returns Std                117.693
exploration/Returns Max                -65.8946
exploration/Returns Min               -496.764
exploration/Actions Mean                -0.507697
exploration/Actions Std                  0.659278
exploration/Actions Max                  0.995514
exploration/Actions Min                 -0.999609
exploration/Num Paths                   10
exploration/Average Returns           -174.989
evaluation/num steps total               1.75111e+06
evaluation/num paths total            8712
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.55248
evaluation/Rewards Std                   1.01656
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1116.05
evaluation/Returns Std                 204.158
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.659087
evaluation/Actions Std                   0.341483
evaluation/Actions Max                   0.306381
evaluation/Actions Min                  -0.976878
evaluation/Num Paths                    24
evaluation/Average Returns           -1116.05
time/data storing (s)                    0.0292064
time/evaluation sampling (s)            12.7334
time/exploration sampling (s)            5.16762
time/logging (s)                         0.0439817
time/sac training (s)                   32.7564
time/saving (s)                          0.172422
time/training (s)                        0.000140735
time/epoch (s)                          50.9031
time/total (s)                       52057.6
Epoch                                  362
----------------------------------  -----------------
2020-11-10 05:38:40.957168 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 363 finished
----------------------------------  ----------------
replay_buffer/size                  730000
trainer/num train calls             364000
trainer/QF1 Loss                       165.073
trainer/QF2 Loss                       151.698
trainer/Policy Loss                     63.2593
trainer/Q1 Predictions Mean            -62.6645
trainer/Q1 Predictions Std              85.8239
trainer/Q1 Predictions Max              36.1942
trainer/Q1 Predictions Min            -231.075
trainer/Q2 Predictions Mean            -62.7203
trainer/Q2 Predictions Std              85.981
trainer/Q2 Predictions Max              36.2041
trainer/Q2 Predictions Min            -235.466
trainer/Q Targets Mean                 -62.1196
trainer/Q Targets Std                   86.1924
trainer/Q Targets Max                   36.3408
trainer/Q Targets Min                 -238.844
trainer/Log Pis Mean                     1.67933
trainer/Log Pis Std                      1.76435
trainer/Log Pis Max                      6.71035
trainer/Log Pis Min                     -6.85397
trainer/policy/mean Mean                -0.56687
trainer/policy/mean Std                  0.582765
trainer/policy/mean Max                  0.927761
trainer/policy/mean Min                 -0.996045
trainer/policy/normal/std Mean           0.581123
trainer/policy/normal/std Std            0.096242
trainer/policy/normal/std Max            0.93542
trainer/policy/normal/std Min            0.271493
trainer/policy/normal/log_std Mean      -0.556392
trainer/policy/normal/log_std Std        0.166081
trainer/policy/normal/log_std Max       -0.0667592
trainer/policy/normal/log_std Min       -1.30382
trainer/Alpha                            0.0255333
trainer/Alpha Loss                      -1.17616
exploration/num steps total         730000
exploration/num paths total           3650
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.919538
exploration/Rewards Std                  1.50975
exploration/Rewards Max                 -3.09911e-92
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -183.908
exploration/Returns Std                120.439
exploration/Returns Max                 -3.4012
exploration/Returns Min               -460.607
exploration/Actions Mean                -0.540158
exploration/Actions Std                  0.613496
exploration/Actions Max                  0.988813
exploration/Actions Min                 -0.998843
exploration/Num Paths                   10
exploration/Average Returns           -183.908
evaluation/num steps total               1.75594e+06
evaluation/num paths total            8736
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.71646
evaluation/Rewards Std                   1.52835
evaluation/Rewards Max                  -3.11211e-17
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -948.009
evaluation/Returns Std                 303.51
evaluation/Returns Max                 -27.1355
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.606565
evaluation/Actions Std                   0.39021
evaluation/Actions Max                   0.464424
evaluation/Actions Min                  -0.972545
evaluation/Num Paths                    24
evaluation/Average Returns            -948.009
time/data storing (s)                    0.0245887
time/evaluation sampling (s)            12.62
time/exploration sampling (s)            5.11041
time/logging (s)                         0.0930948
time/sac training (s)                   32.4003
time/saving (s)                          0.335895
time/training (s)                        0.000136221
time/epoch (s)                          50.5844
time/total (s)                       52279.6
Epoch                                  363
----------------------------------  ----------------
2020-11-10 05:43:04.808196 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 364 finished
----------------------------------  ----------------
replay_buffer/size                  732000
trainer/num train calls             365000
trainer/QF1 Loss                        58.8688
trainer/QF2 Loss                        50.233
trainer/Policy Loss                     57.2106
trainer/Q1 Predictions Mean            -56.6515
trainer/Q1 Predictions Std              82.1452
trainer/Q1 Predictions Max              34.7495
trainer/Q1 Predictions Min            -237.284
trainer/Q2 Predictions Mean            -56.9018
trainer/Q2 Predictions Std              82.3854
trainer/Q2 Predictions Max              34.9269
trainer/Q2 Predictions Min            -238.128
trainer/Q Targets Mean                 -57.2241
trainer/Q Targets Std                   82.8592
trainer/Q Targets Max                   33.9566
trainer/Q Targets Min                 -240.088
trainer/Log Pis Mean                     2.00471
trainer/Log Pis Std                      1.75062
trainer/Log Pis Max                      7.77999
trainer/Log Pis Min                     -4.89813
trainer/policy/mean Mean                -0.594941
trainer/policy/mean Std                  0.576575
trainer/policy/mean Max                  0.925509
trainer/policy/mean Min                 -0.996531
trainer/policy/normal/std Mean           0.578823
trainer/policy/normal/std Std            0.0976533
trainer/policy/normal/std Max            0.880737
trainer/policy/normal/std Min            0.230485
trainer/policy/normal/log_std Mean      -0.560073
trainer/policy/normal/log_std Std        0.161344
trainer/policy/normal/log_std Max       -0.126997
trainer/policy/normal/log_std Min       -1.46757
trainer/Alpha                            0.025648
trainer/Alpha Loss                       0.0172647
exploration/num steps total         732000
exploration/num paths total           3660
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.572303
exploration/Rewards Std                  1.45925
exploration/Rewards Max                 -1.10049e-68
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -114.461
exploration/Returns Std                 51.9285
exploration/Returns Max                -29.2781
exploration/Returns Min               -209.923
exploration/Actions Mean                -0.536824
exploration/Actions Std                  0.63291
exploration/Actions Max                  0.994548
exploration/Actions Min                 -0.999238
exploration/Num Paths                   10
exploration/Average Returns           -114.461
evaluation/num steps total               1.76076e+06
evaluation/num paths total            8760
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.47501
evaluation/Rewards Std                   1.33997
evaluation/Rewards Max                  -1.44889e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1100.48
evaluation/Returns Std                 268.253
evaluation/Returns Max                 -16.0707
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.818891
evaluation/Actions Std                   0.161613
evaluation/Actions Max                  -0.396802
evaluation/Actions Min                  -0.979308
evaluation/Num Paths                    24
evaluation/Average Returns           -1100.48
time/data storing (s)                    0.0219594
time/evaluation sampling (s)            12.7009
time/exploration sampling (s)            6.52982
time/logging (s)                         0.0478023
time/sac training (s)                   32.4745
time/saving (s)                          0.0848939
time/training (s)                        0.000207191
time/epoch (s)                          51.8601
time/total (s)                       52543.4
Epoch                                  364
----------------------------------  ----------------
2020-11-10 05:47:00.657873 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 365 finished
----------------------------------  -----------------
replay_buffer/size                  734000
trainer/num train calls             366000
trainer/QF1 Loss                       115.711
trainer/QF2 Loss                       116.154
trainer/Policy Loss                     45.7789
trainer/Q1 Predictions Mean            -45.4422
trainer/Q1 Predictions Std              78.6019
trainer/Q1 Predictions Max              53.0473
trainer/Q1 Predictions Min            -232.687
trainer/Q2 Predictions Mean            -45.3707
trainer/Q2 Predictions Std              78.595
trainer/Q2 Predictions Max              53.1615
trainer/Q2 Predictions Min            -233.539
trainer/Q Targets Mean                 -44.9822
trainer/Q Targets Std                   78.5376
trainer/Q Targets Max                   53.5877
trainer/Q Targets Min                 -235.295
trainer/Log Pis Mean                     1.95275
trainer/Log Pis Std                      1.75784
trainer/Log Pis Max                      6.04131
trainer/Log Pis Min                     -5.94391
trainer/policy/mean Mean                -0.572237
trainer/policy/mean Std                  0.60036
trainer/policy/mean Max                  0.948403
trainer/policy/mean Min                 -0.990659
trainer/policy/normal/std Mean           0.573523
trainer/policy/normal/std Std            0.1003
trainer/policy/normal/std Max            0.88618
trainer/policy/normal/std Min            0.223874
trainer/policy/normal/log_std Mean      -0.570917
trainer/policy/normal/log_std Std        0.173466
trainer/policy/normal/log_std Max       -0.120836
trainer/policy/normal/log_std Min       -1.49667
trainer/Alpha                            0.0254926
trainer/Alpha Loss                      -0.173372
exploration/num steps total         734000
exploration/num paths total           3670
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.925118
exploration/Rewards Std                  1.58743
exploration/Rewards Max                 -4.42602e-178
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -185.024
exploration/Returns Std                 85.7091
exploration/Returns Max                -72.1738
exploration/Returns Min               -386.017
exploration/Actions Mean                -0.540641
exploration/Actions Std                  0.635255
exploration/Actions Max                  0.996691
exploration/Actions Min                 -0.998752
exploration/Num Paths                   10
exploration/Average Returns           -185.024
evaluation/num steps total               1.76558e+06
evaluation/num paths total            8784
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60365
evaluation/Rewards Std                   0.882899
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1126.33
evaluation/Returns Std                 176.714
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.784095
evaluation/Actions Std                   0.211943
evaluation/Actions Max                  -0.0905915
evaluation/Actions Min                  -0.97886
evaluation/Num Paths                    24
evaluation/Average Returns           -1126.33
time/data storing (s)                    0.0281034
time/evaluation sampling (s)            12.8948
time/exploration sampling (s)            4.9681
time/logging (s)                         0.0716889
time/sac training (s)                   32.357
time/saving (s)                          0.291893
time/training (s)                        0.000172964
time/epoch (s)                          50.6118
time/total (s)                       52779.2
Epoch                                  365
----------------------------------  -----------------
2020-11-10 05:50:48.712198 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 366 finished
----------------------------------  ----------------
replay_buffer/size                  736000
trainer/num train calls             367000
trainer/QF1 Loss                       139.876
trainer/QF2 Loss                       153.021
trainer/Policy Loss                     64.319
trainer/Q1 Predictions Mean            -63.7874
trainer/Q1 Predictions Std              82.1539
trainer/Q1 Predictions Max              34.1917
trainer/Q1 Predictions Min            -232.515
trainer/Q2 Predictions Mean            -63.6914
trainer/Q2 Predictions Std              82.1568
trainer/Q2 Predictions Max              34.2127
trainer/Q2 Predictions Min            -231.145
trainer/Q Targets Mean                 -62.8122
trainer/Q Targets Std                   82.6762
trainer/Q Targets Max                   34.1204
trainer/Q Targets Min                 -236.514
trainer/Log Pis Mean                     2.18849
trainer/Log Pis Std                      1.79723
trainer/Log Pis Max                      5.74733
trainer/Log Pis Min                     -7.26304
trainer/policy/mean Mean                -0.310458
trainer/policy/mean Std                  0.775979
trainer/policy/mean Max                  0.968099
trainer/policy/mean Min                 -0.991298
trainer/policy/normal/std Mean           0.562163
trainer/policy/normal/std Std            0.0854003
trainer/policy/normal/std Max            0.842525
trainer/policy/normal/std Min            0.277453
trainer/policy/normal/log_std Mean      -0.587111
trainer/policy/normal/log_std Std        0.148752
trainer/policy/normal/log_std Max       -0.171352
trainer/policy/normal/log_std Min       -1.2821
trainer/Alpha                            0.0253651
trainer/Alpha Loss                       0.692577
exploration/num steps total         736000
exploration/num paths total           3680
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.993006
exploration/Rewards Std                  1.50376
exploration/Rewards Max                 -2.26305e-98
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -198.601
exploration/Returns Std                124.69
exploration/Returns Max                -66.6643
exploration/Returns Min               -499.343
exploration/Actions Mean                -0.273311
exploration/Actions Std                  0.797617
exploration/Actions Max                  0.996233
exploration/Actions Min                 -0.999507
exploration/Num Paths                   10
exploration/Average Returns           -198.601
evaluation/num steps total               1.77041e+06
evaluation/num paths total            8808
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78497
evaluation/Rewards Std                   0.737493
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.78
evaluation/Returns Std                 147.809
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.381096
evaluation/Actions Std                   0.601335
evaluation/Actions Max                   0.512606
evaluation/Actions Min                  -0.979548
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.78
time/data storing (s)                    0.0209215
time/evaluation sampling (s)            12.8808
time/exploration sampling (s)            5.01806
time/logging (s)                         0.0779568
time/sac training (s)                   32.1825
time/saving (s)                          0.408724
time/training (s)                        0.000136921
time/epoch (s)                          50.5891
time/total (s)                       53007.2
Epoch                                  366
----------------------------------  ----------------
2020-11-10 05:54:34.272107 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 367 finished
----------------------------------  -----------------
replay_buffer/size                  738000
trainer/num train calls             368000
trainer/QF1 Loss                       188.995
trainer/QF2 Loss                       171.106
trainer/Policy Loss                     72.5134
trainer/Q1 Predictions Mean            -71.9703
trainer/Q1 Predictions Std              88.627
trainer/Q1 Predictions Max              52.8394
trainer/Q1 Predictions Min            -233.393
trainer/Q2 Predictions Mean            -71.9143
trainer/Q2 Predictions Std              88.5377
trainer/Q2 Predictions Max              52.9269
trainer/Q2 Predictions Min            -232.76
trainer/Q Targets Mean                 -71.4244
trainer/Q Targets Std                   89.566
trainer/Q Targets Max                   53.1295
trainer/Q Targets Min                 -237.667
trainer/Log Pis Mean                     2.05842
trainer/Log Pis Std                      1.79135
trainer/Log Pis Max                      6.55859
trainer/Log Pis Min                     -4.8324
trainer/policy/mean Mean                -0.438736
trainer/policy/mean Std                  0.703927
trainer/policy/mean Max                  0.973361
trainer/policy/mean Min                 -0.991246
trainer/policy/normal/std Mean           0.586972
trainer/policy/normal/std Std            0.101822
trainer/policy/normal/std Max            0.88038
trainer/policy/normal/std Min            0.219526
trainer/policy/normal/log_std Mean      -0.548135
trainer/policy/normal/log_std Std        0.178135
trainer/policy/normal/log_std Max       -0.127401
trainer/policy/normal/log_std Min       -1.51629
trainer/Alpha                            0.0258925
trainer/Alpha Loss                       0.213445
exploration/num steps total         738000
exploration/num paths total           3690
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.907003
exploration/Rewards Std                  1.40401
exploration/Rewards Max                 -6.32977e-193
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -181.401
exploration/Returns Std                106.913
exploration/Returns Max                -49.3208
exploration/Returns Min               -365.073
exploration/Actions Mean                -0.415343
exploration/Actions Std                  0.733646
exploration/Actions Max                  0.996087
exploration/Actions Min                 -0.999571
exploration/Num Paths                   10
exploration/Average Returns           -181.401
evaluation/num steps total               1.77523e+06
evaluation/num paths total            8832
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61824
evaluation/Rewards Std                   1.02212
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1129.27
evaluation/Returns Std                 205.445
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.578417
evaluation/Actions Std                   0.423971
evaluation/Actions Max                   0.309859
evaluation/Actions Min                  -0.977667
evaluation/Num Paths                    24
evaluation/Average Returns           -1129.27
time/data storing (s)                    0.0196136
time/evaluation sampling (s)            12.6411
time/exploration sampling (s)            4.95976
time/logging (s)                         0.0547251
time/sac training (s)                   33.5374
time/saving (s)                          0.201714
time/training (s)                        0.000128739
time/epoch (s)                          51.4144
time/total (s)                       53232.7
Epoch                                  367
----------------------------------  -----------------
2020-11-10 05:58:33.383535 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 368 finished
----------------------------------  -----------------
replay_buffer/size                  740000
trainer/num train calls             369000
trainer/QF1 Loss                       226.428
trainer/QF2 Loss                       229.626
trainer/Policy Loss                     69.453
trainer/Q1 Predictions Mean            -68.8374
trainer/Q1 Predictions Std              86.8515
trainer/Q1 Predictions Max              35.1785
trainer/Q1 Predictions Min            -234.406
trainer/Q2 Predictions Mean            -69.0584
trainer/Q2 Predictions Std              87.1392
trainer/Q2 Predictions Max              35.2435
trainer/Q2 Predictions Min            -235.156
trainer/Q Targets Mean                 -68.3911
trainer/Q Targets Std                   87.8702
trainer/Q Targets Max                   35.3142
trainer/Q Targets Min                 -236.602
trainer/Log Pis Mean                     2.61586
trainer/Log Pis Std                      1.88226
trainer/Log Pis Max                      7.27221
trainer/Log Pis Min                     -2.72823
trainer/policy/mean Mean                -0.714231
trainer/policy/mean Std                  0.503514
trainer/policy/mean Max                  0.938303
trainer/policy/mean Min                 -0.995134
trainer/policy/normal/std Mean           0.581738
trainer/policy/normal/std Std            0.101733
trainer/policy/normal/std Max            0.851965
trainer/policy/normal/std Min            0.219004
trainer/policy/normal/log_std Mean      -0.556193
trainer/policy/normal/log_std Std        0.168522
trainer/policy/normal/log_std Max       -0.160209
trainer/policy/normal/log_std Min       -1.51867
trainer/Alpha                            0.0258886
trainer/Alpha Loss                       2.25033
exploration/num steps total         740000
exploration/num paths total           3700
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.782443
exploration/Rewards Std                  1.58661
exploration/Rewards Max                 -1.16729e-189
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -156.489
exploration/Returns Std                100.168
exploration/Returns Max                -17.006
exploration/Returns Min               -270.815
exploration/Actions Mean                -0.66158
exploration/Actions Std                  0.526954
exploration/Actions Max                  0.982111
exploration/Actions Min                 -0.999738
exploration/Num Paths                   10
exploration/Average Returns           -156.489
evaluation/num steps total               1.78006e+06
evaluation/num paths total            8856
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84381
evaluation/Rewards Std                   0.767927
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1174.61
evaluation/Returns Std                 154.352
evaluation/Returns Max                -662.676
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.931074
evaluation/Actions Std                   0.0917301
evaluation/Actions Max                  -0.422625
evaluation/Actions Min                  -0.977551
evaluation/Num Paths                    24
evaluation/Average Returns           -1174.61
time/data storing (s)                    0.0224877
time/evaluation sampling (s)            12.5953
time/exploration sampling (s)            4.91673
time/logging (s)                         0.0473951
time/sac training (s)                   36.2488
time/saving (s)                          0.676596
time/training (s)                        0.000125835
time/epoch (s)                          54.5074
time/total (s)                       53471.8
Epoch                                  368
----------------------------------  -----------------
2020-11-10 06:02:22.758171 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 369 finished
----------------------------------  ----------------
replay_buffer/size                  742000
trainer/num train calls             370000
trainer/QF1 Loss                        91.9297
trainer/QF2 Loss                        90.992
trainer/Policy Loss                     64.4926
trainer/Q1 Predictions Mean            -64.0498
trainer/Q1 Predictions Std              87.1888
trainer/Q1 Predictions Max              52.5907
trainer/Q1 Predictions Min            -234.102
trainer/Q2 Predictions Mean            -63.9154
trainer/Q2 Predictions Std              87.1366
trainer/Q2 Predictions Max              52.5152
trainer/Q2 Predictions Min            -231.387
trainer/Q Targets Mean                 -64.4177
trainer/Q Targets Std                   88.233
trainer/Q Targets Max                   52.456
trainer/Q Targets Min                 -238.373
trainer/Log Pis Mean                     1.83539
trainer/Log Pis Std                      1.62443
trainer/Log Pis Max                      5.33456
trainer/Log Pis Min                     -3.05999
trainer/policy/mean Mean                -0.314544
trainer/policy/mean Std                  0.755862
trainer/policy/mean Max                  0.969094
trainer/policy/mean Min                 -0.989703
trainer/policy/normal/std Mean           0.576972
trainer/policy/normal/std Std            0.0939953
trainer/policy/normal/std Max            0.864709
trainer/policy/normal/std Min            0.274714
trainer/policy/normal/log_std Mean      -0.562819
trainer/policy/normal/log_std Std        0.16025
trainer/policy/normal/log_std Max       -0.145363
trainer/policy/normal/log_std Min       -1.29202
trainer/Alpha                            0.0255744
trainer/Alpha Loss                      -0.603481
exploration/num steps total         742000
exploration/num paths total           3710
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.925144
exploration/Rewards Std                  1.52375
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -185.029
exploration/Returns Std                109.176
exploration/Returns Max                -33.7243
exploration/Returns Min               -410.003
exploration/Actions Mean                -0.277842
exploration/Actions Std                  0.787283
exploration/Actions Max                  0.998679
exploration/Actions Min                 -0.998891
exploration/Num Paths                   10
exploration/Average Returns           -185.029
evaluation/num steps total               1.78488e+06
evaluation/num paths total            8880
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   3.77114e-12
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.463112
evaluation/Actions Std                   0.509927
evaluation/Actions Max                   0.0472945
evaluation/Actions Min                  -0.973575
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0225791
time/evaluation sampling (s)            12.7295
time/exploration sampling (s)            4.89913
time/logging (s)                         0.0905394
time/sac training (s)                   32.1319
time/saving (s)                          0.31488
time/training (s)                        0.000151975
time/epoch (s)                          50.1887
time/total (s)                       53701.2
Epoch                                  369
----------------------------------  ----------------
2020-11-10 06:06:11.932485 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 370 finished
----------------------------------  -----------------
replay_buffer/size                  744000
trainer/num train calls             371000
trainer/QF1 Loss                        70.4514
trainer/QF2 Loss                        64.6989
trainer/Policy Loss                     72.8277
trainer/Q1 Predictions Mean            -72.2084
trainer/Q1 Predictions Std              89.4721
trainer/Q1 Predictions Max              52.9237
trainer/Q1 Predictions Min            -232.063
trainer/Q2 Predictions Mean            -72.305
trainer/Q2 Predictions Std              89.6025
trainer/Q2 Predictions Max              52.8678
trainer/Q2 Predictions Min            -234.549
trainer/Q Targets Mean                 -72.5771
trainer/Q Targets Std                   90.4376
trainer/Q Targets Max                   52.2679
trainer/Q Targets Min                 -236.849
trainer/Log Pis Mean                     1.8522
trainer/Log Pis Std                      1.71898
trainer/Log Pis Max                      7.28206
trainer/Log Pis Min                     -4.81285
trainer/policy/mean Mean                -0.441237
trainer/policy/mean Std                  0.699145
trainer/policy/mean Max                  0.96644
trainer/policy/mean Min                 -0.991773
trainer/policy/normal/std Mean           0.585508
trainer/policy/normal/std Std            0.107156
trainer/policy/normal/std Max            0.893976
trainer/policy/normal/std Min            0.315421
trainer/policy/normal/log_std Mean      -0.550881
trainer/policy/normal/log_std Std        0.174213
trainer/policy/normal/log_std Max       -0.112077
trainer/policy/normal/log_std Min       -1.15385
trainer/Alpha                            0.0253585
trainer/Alpha Loss                      -0.543094
exploration/num steps total         744000
exploration/num paths total           3720
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.886895
exploration/Rewards Std                  1.42654
exploration/Rewards Max                 -1.28894e-163
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -177.379
exploration/Returns Std                123.261
exploration/Returns Max                -36.6679
exploration/Returns Min               -435.747
exploration/Actions Mean                -0.435597
exploration/Actions Std                  0.714929
exploration/Actions Max                  0.997666
exploration/Actions Min                 -0.99931
exploration/Num Paths                   10
exploration/Average Returns           -177.379
evaluation/num steps total               1.7897e+06
evaluation/num paths total            8904
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61216
evaluation/Rewards Std                   0.859468
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1128.04
evaluation/Returns Std                 172.196
evaluation/Returns Max                -667.99
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.531223
evaluation/Actions Std                   0.453455
evaluation/Actions Max                   0.345194
evaluation/Actions Min                  -0.979032
evaluation/Num Paths                    24
evaluation/Average Returns           -1128.04
time/data storing (s)                    0.0234966
time/evaluation sampling (s)            12.6928
time/exploration sampling (s)            4.90277
time/logging (s)                         0.0552583
time/sac training (s)                   32.2711
time/saving (s)                          0.158583
time/training (s)                        0.000128818
time/epoch (s)                          50.1042
time/total (s)                       53930.3
Epoch                                  370
----------------------------------  -----------------
2020-11-10 06:10:09.737035 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 371 finished
----------------------------------  ----------------
replay_buffer/size                  746000
trainer/num train calls             372000
trainer/QF1 Loss                       135.8
trainer/QF2 Loss                       119.249
trainer/Policy Loss                     62.1543
trainer/Q1 Predictions Mean            -61.7156
trainer/Q1 Predictions Std              83.296
trainer/Q1 Predictions Max              35.7069
trainer/Q1 Predictions Min            -238.004
trainer/Q2 Predictions Mean            -61.6476
trainer/Q2 Predictions Std              83.1549
trainer/Q2 Predictions Max              36.0372
trainer/Q2 Predictions Min            -236.786
trainer/Q Targets Mean                 -61.1663
trainer/Q Targets Std                   83.3691
trainer/Q Targets Max                   35.9107
trainer/Q Targets Min                 -239.452
trainer/Log Pis Mean                     1.69335
trainer/Log Pis Std                      1.68984
trainer/Log Pis Max                      6.53271
trainer/Log Pis Min                     -7.64676
trainer/policy/mean Mean                -0.502997
trainer/policy/mean Std                  0.640133
trainer/policy/mean Max                  0.973238
trainer/policy/mean Min                 -0.984951
trainer/policy/normal/std Mean           0.576642
trainer/policy/normal/std Std            0.0972908
trainer/policy/normal/std Max            0.889888
trainer/policy/normal/std Min            0.202982
trainer/policy/normal/log_std Mean      -0.564611
trainer/policy/normal/log_std Std        0.169132
trainer/policy/normal/log_std Max       -0.11666
trainer/policy/normal/log_std Min       -1.59464
trainer/Alpha                            0.0250593
trainer/Alpha Loss                      -1.13048
exploration/num steps total         746000
exploration/num paths total           3730
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.615407
exploration/Rewards Std                  1.44338
exploration/Rewards Max                 -1.40774e-45
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -123.081
exploration/Returns Std                 62.6679
exploration/Returns Max                -16.6546
exploration/Returns Min               -237.654
exploration/Actions Mean                -0.641275
exploration/Actions Std                  0.52956
exploration/Actions Max                  0.9969
exploration/Actions Min                 -0.999355
exploration/Num Paths                   10
exploration/Average Returns           -123.081
evaluation/num steps total               1.79453e+06
evaluation/num paths total            8928
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.23424
evaluation/Rewards Std                   1.20574
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1052.08
evaluation/Returns Std                 241.964
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.650182
evaluation/Actions Std                   0.38233
evaluation/Actions Max                   0.246616
evaluation/Actions Min                  -0.972018
evaluation/Num Paths                    24
evaluation/Average Returns           -1052.08
time/data storing (s)                    0.0203964
time/evaluation sampling (s)            12.5799
time/exploration sampling (s)            5.05891
time/logging (s)                         0.0544511
time/sac training (s)                   32.4713
time/saving (s)                          0.43849
time/training (s)                        0.000140225
time/epoch (s)                          50.6236
time/total (s)                       54168
Epoch                                  371
----------------------------------  ----------------
2020-11-10 06:13:52.167472 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 372 finished
----------------------------------  -----------------
replay_buffer/size                  748000
trainer/num train calls             373000
trainer/QF1 Loss                       274.463
trainer/QF2 Loss                       303.992
trainer/Policy Loss                     60.6865
trainer/Q1 Predictions Mean            -59.926
trainer/Q1 Predictions Std              82.2896
trainer/Q1 Predictions Max              30.9603
trainer/Q1 Predictions Min            -239.179
trainer/Q2 Predictions Mean            -60.1528
trainer/Q2 Predictions Std              82.6648
trainer/Q2 Predictions Max              31.2587
trainer/Q2 Predictions Min            -239.217
trainer/Q Targets Mean                 -58.9113
trainer/Q Targets Std                   83.3344
trainer/Q Targets Max                   31.1761
trainer/Q Targets Min                 -240.396
trainer/Log Pis Mean                     1.95817
trainer/Log Pis Std                      1.79509
trainer/Log Pis Max                      7.22087
trainer/Log Pis Min                     -5.11882
trainer/policy/mean Mean                -0.547962
trainer/policy/mean Std                  0.627978
trainer/policy/mean Max                  0.955182
trainer/policy/mean Min                 -0.990054
trainer/policy/normal/std Mean           0.585537
trainer/policy/normal/std Std            0.105469
trainer/policy/normal/std Max            0.995488
trainer/policy/normal/std Min            0.213285
trainer/policy/normal/log_std Mean      -0.551468
trainer/policy/normal/log_std Std        0.182396
trainer/policy/normal/log_std Max       -0.0045224
trainer/policy/normal/log_std Min       -1.54513
trainer/Alpha                            0.0250929
trainer/Alpha Loss                      -0.154153
exploration/num steps total         748000
exploration/num paths total           3740
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.924301
exploration/Rewards Std                  1.41474
exploration/Rewards Max                 -2.04989e-239
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -184.86
exploration/Returns Std                 94.826
exploration/Returns Max                -58.468
exploration/Returns Min               -396.606
exploration/Actions Mean                -0.48451
exploration/Actions Std                  0.692144
exploration/Actions Max                  0.99786
exploration/Actions Min                 -0.999072
exploration/Num Paths                   10
exploration/Average Returns           -184.86
evaluation/num steps total               1.79935e+06
evaluation/num paths total            8952
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56682
evaluation/Rewards Std                   0.983594
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1118.93
evaluation/Returns Std                 197.7
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.69906
evaluation/Actions Std                   0.311473
evaluation/Actions Max                  -0.317028
evaluation/Actions Min                  -0.975845
evaluation/Num Paths                    24
evaluation/Average Returns           -1118.93
time/data storing (s)                    0.0202118
time/evaluation sampling (s)            12.5001
time/exploration sampling (s)            4.97438
time/logging (s)                         0.0746786
time/sac training (s)                   32.0132
time/saving (s)                          0.395761
time/training (s)                        0.000136472
time/epoch (s)                          49.9784
time/total (s)                       54390.5
Epoch                                  372
----------------------------------  -----------------
2020-11-10 06:17:38.250764 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 373 finished
----------------------------------  -----------------
replay_buffer/size                  750000
trainer/num train calls             374000
trainer/QF1 Loss                       251.474
trainer/QF2 Loss                       247.435
trainer/Policy Loss                     65.2994
trainer/Q1 Predictions Mean            -64.8061
trainer/Q1 Predictions Std              85.3939
trainer/Q1 Predictions Max              41.9182
trainer/Q1 Predictions Min            -237.246
trainer/Q2 Predictions Mean            -64.7829
trainer/Q2 Predictions Std              85.257
trainer/Q2 Predictions Max              41.9521
trainer/Q2 Predictions Min            -240.11
trainer/Q Targets Mean                 -63.5523
trainer/Q Targets Std                   85.6117
trainer/Q Targets Max                   41.651
trainer/Q Targets Min                 -236.712
trainer/Log Pis Mean                     1.97423
trainer/Log Pis Std                      1.62834
trainer/Log Pis Max                      5.78111
trainer/Log Pis Min                     -3.26719
trainer/policy/mean Mean                -0.446905
trainer/policy/mean Std                  0.688083
trainer/policy/mean Max                  0.964253
trainer/policy/mean Min                 -0.989342
trainer/policy/normal/std Mean           0.567809
trainer/policy/normal/std Std            0.0986662
trainer/policy/normal/std Max            0.848012
trainer/policy/normal/std Min            0.205697
trainer/policy/normal/log_std Mean      -0.58234
trainer/policy/normal/log_std Std        0.18737
trainer/policy/normal/log_std Max       -0.16486
trainer/policy/normal/log_std Min       -1.58135
trainer/Alpha                            0.025253
trainer/Alpha Loss                      -0.0947912
exploration/num steps total         750000
exploration/num paths total           3750
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.13315
exploration/Rewards Std                  1.42602
exploration/Rewards Max                 -1.11941e-105
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -226.629
exploration/Returns Std                154.957
exploration/Returns Max                -37.4432
exploration/Returns Min               -507.101
exploration/Actions Mean                -0.371939
exploration/Actions Std                  0.775362
exploration/Actions Max                  0.99915
exploration/Actions Min                 -0.999281
exploration/Num Paths                   10
exploration/Average Returns           -226.629
evaluation/num steps total               1.80418e+06
evaluation/num paths total            8976
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.55897
evaluation/Rewards Std                   1.00298
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1117.35
evaluation/Returns Std                 201.268
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.520171
evaluation/Actions Std                   0.486708
evaluation/Actions Max                   0.584214
evaluation/Actions Min                  -0.977307
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.35
time/data storing (s)                    0.0208143
time/evaluation sampling (s)            12.7121
time/exploration sampling (s)            4.93571
time/logging (s)                         0.051006
time/sac training (s)                   32.4992
time/saving (s)                          0.386406
time/training (s)                        0.000152327
time/epoch (s)                          50.6054
time/total (s)                       54616.5
Epoch                                  373
----------------------------------  -----------------
2020-11-10 06:21:28.351143 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 374 finished
----------------------------------  -----------------
replay_buffer/size                  752000
trainer/num train calls             375000
trainer/QF1 Loss                       101.226
trainer/QF2 Loss                       100.829
trainer/Policy Loss                     60.8939
trainer/Q1 Predictions Mean            -60.4381
trainer/Q1 Predictions Std              84.036
trainer/Q1 Predictions Max              34.7769
trainer/Q1 Predictions Min            -241.608
trainer/Q2 Predictions Mean            -60.4048
trainer/Q2 Predictions Std              84.1305
trainer/Q2 Predictions Max              34.8662
trainer/Q2 Predictions Min            -242.412
trainer/Q Targets Mean                 -60.4007
trainer/Q Targets Std                   84.6046
trainer/Q Targets Max                   34.7762
trainer/Q Targets Min                 -242.037
trainer/Log Pis Mean                     2.13986
trainer/Log Pis Std                      1.79988
trainer/Log Pis Max                      8.99851
trainer/Log Pis Min                     -4.15943
trainer/policy/mean Mean                -0.573376
trainer/policy/mean Std                  0.609867
trainer/policy/mean Max                  0.956547
trainer/policy/mean Min                 -0.997939
trainer/policy/normal/std Mean           0.581024
trainer/policy/normal/std Std            0.111308
trainer/policy/normal/std Max            0.877603
trainer/policy/normal/std Min            0.205434
trainer/policy/normal/log_std Mean      -0.562066
trainer/policy/normal/log_std Std        0.200227
trainer/policy/normal/log_std Max       -0.130561
trainer/policy/normal/log_std Min       -1.58263
trainer/Alpha                            0.0258153
trainer/Alpha Loss                       0.51145
exploration/num steps total         752000
exploration/num paths total           3760
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.17233
exploration/Rewards Std                  1.60854
exploration/Rewards Max                 -1.32301e-132
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -234.467
exploration/Returns Std                128.339
exploration/Returns Max                -62.0243
exploration/Returns Min               -525.82
exploration/Actions Mean                -0.636652
exploration/Actions Std                  0.545841
exploration/Actions Max                  0.986387
exploration/Actions Min                 -0.999503
exploration/Num Paths                   10
exploration/Average Returns           -234.467
evaluation/num steps total               1.809e+06
evaluation/num paths total            9000
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.33152
evaluation/Rewards Std                   1.04076
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1071.64
evaluation/Returns Std                 208.241
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.58611
evaluation/Actions Std                   0.408854
evaluation/Actions Max                  -0.0265992
evaluation/Actions Min                  -0.977194
evaluation/Num Paths                    24
evaluation/Average Returns           -1071.64
time/data storing (s)                    0.019785
time/evaluation sampling (s)            13.3678
time/exploration sampling (s)            5.19089
time/logging (s)                         0.0515813
time/sac training (s)                   32.4274
time/saving (s)                          0.275138
time/training (s)                        0.000155347
time/epoch (s)                          51.3328
time/total (s)                       54846.5
Epoch                                  374
----------------------------------  -----------------
2020-11-10 06:25:24.383377 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 375 finished
----------------------------------  ----------------
replay_buffer/size                  754000
trainer/num train calls             376000
trainer/QF1 Loss                       137.922
trainer/QF2 Loss                       128.937
trainer/Policy Loss                     58.0344
trainer/Q1 Predictions Mean            -57.5763
trainer/Q1 Predictions Std              82.9548
trainer/Q1 Predictions Max              40.8065
trainer/Q1 Predictions Min            -241.255
trainer/Q2 Predictions Mean            -57.7353
trainer/Q2 Predictions Std              83.0888
trainer/Q2 Predictions Max              41.0024
trainer/Q2 Predictions Min            -240.929
trainer/Q Targets Mean                 -56.7458
trainer/Q Targets Std                   82.7015
trainer/Q Targets Max                   40.7016
trainer/Q Targets Min                 -242.864
trainer/Log Pis Mean                     2.04245
trainer/Log Pis Std                      1.64885
trainer/Log Pis Max                      5.74044
trainer/Log Pis Min                     -3.33247
trainer/policy/mean Mean                -0.329902
trainer/policy/mean Std                  0.766446
trainer/policy/mean Max                  0.981923
trainer/policy/mean Min                 -0.991753
trainer/policy/normal/std Mean           0.556328
trainer/policy/normal/std Std            0.0834903
trainer/policy/normal/std Max            0.826865
trainer/policy/normal/std Min            0.270114
trainer/policy/normal/log_std Mean      -0.597116
trainer/policy/normal/log_std Std        0.145327
trainer/policy/normal/log_std Max       -0.190114
trainer/policy/normal/log_std Min       -1.30891
trainer/Alpha                            0.0253496
trainer/Alpha Loss                       0.156004
exploration/num steps total         754000
exploration/num paths total           3770
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.31992
exploration/Rewards Std                  1.55622
exploration/Rewards Max                 -1.3864e-101
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -263.984
exploration/Returns Std                128.6
exploration/Returns Max               -131.481
exploration/Returns Min               -470.357
exploration/Actions Mean                -0.369539
exploration/Actions Std                  0.745521
exploration/Actions Max                  0.999016
exploration/Actions Min                 -0.998823
exploration/Num Paths                   10
exploration/Average Returns           -263.984
evaluation/num steps total               1.81382e+06
evaluation/num paths total            9024
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.60475
evaluation/Rewards Std                   0.881761
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1126.55
evaluation/Returns Std                 176.131
evaluation/Returns Max                -660.555
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.282628
evaluation/Actions Std                   0.701899
evaluation/Actions Max                   0.873903
evaluation/Actions Min                  -0.975932
evaluation/Num Paths                    24
evaluation/Average Returns           -1126.55
time/data storing (s)                    0.0207039
time/evaluation sampling (s)            12.606
time/exploration sampling (s)            4.84057
time/logging (s)                         0.0771839
time/sac training (s)                   32.2691
time/saving (s)                          0.448409
time/training (s)                        0.000256272
time/epoch (s)                          50.2622
time/total (s)                       55082.6
Epoch                                  375
----------------------------------  ----------------
2020-11-10 06:29:18.978892 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 376 finished
----------------------------------  -----------------
replay_buffer/size                  756000
trainer/num train calls             377000
trainer/QF1 Loss                       339.881
trainer/QF2 Loss                       342.197
trainer/Policy Loss                     58.2783
trainer/Q1 Predictions Mean            -57.7884
trainer/Q1 Predictions Std              81.7583
trainer/Q1 Predictions Max              29.8173
trainer/Q1 Predictions Min            -232.922
trainer/Q2 Predictions Mean            -57.8744
trainer/Q2 Predictions Std              81.9177
trainer/Q2 Predictions Max              29.8405
trainer/Q2 Predictions Min            -233.5
trainer/Q Targets Mean                 -55.9154
trainer/Q Targets Std                   80.9266
trainer/Q Targets Max                   29.533
trainer/Q Targets Min                 -237.023
trainer/Log Pis Mean                     1.84463
trainer/Log Pis Std                      1.79672
trainer/Log Pis Max                      6.55533
trainer/Log Pis Min                     -5.94632
trainer/policy/mean Mean                -0.542078
trainer/policy/mean Std                  0.617898
trainer/policy/mean Max                  0.935365
trainer/policy/mean Min                 -0.991772
trainer/policy/normal/std Mean           0.569432
trainer/policy/normal/std Std            0.106135
trainer/policy/normal/std Max            0.895949
trainer/policy/normal/std Min            0.250777
trainer/policy/normal/log_std Mean      -0.580187
trainer/policy/normal/log_std Std        0.185512
trainer/policy/normal/log_std Max       -0.109871
trainer/policy/normal/log_std Min       -1.38319
trainer/Alpha                            0.0248767
trainer/Alpha Loss                      -0.573923
exploration/num steps total         756000
exploration/num paths total           3780
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.931172
exploration/Rewards Std                  1.43238
exploration/Rewards Max                 -2.23684e-189
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -186.234
exploration/Returns Std                113.536
exploration/Returns Max                -37.3738
exploration/Returns Min               -390.951
exploration/Actions Mean                -0.38414
exploration/Actions Std                  0.75092
exploration/Actions Max                  0.998798
exploration/Actions Min                 -0.999411
exploration/Num Paths                   10
exploration/Average Returns           -186.234
evaluation/num steps total               1.81865e+06
evaluation/num paths total            9048
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.44206
evaluation/Rewards Std                   0.945895
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1093.85
evaluation/Returns Std                 189.249
evaluation/Returns Max                -647.51
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.58412
evaluation/Actions Std                   0.411875
evaluation/Actions Max                   0.461858
evaluation/Actions Min                  -0.981692
evaluation/Num Paths                    24
evaluation/Average Returns           -1093.85
time/data storing (s)                    0.0206628
time/evaluation sampling (s)            12.6335
time/exploration sampling (s)            5.07546
time/logging (s)                         0.0656869
time/sac training (s)                   32.5806
time/saving (s)                          0.505839
time/training (s)                        0.000161933
time/epoch (s)                          50.8819
time/total (s)                       55317.1
Epoch                                  376
----------------------------------  -----------------
2020-11-10 06:33:07.699729 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 377 finished
----------------------------------  -----------------
replay_buffer/size                  758000
trainer/num train calls             378000
trainer/QF1 Loss                       147.166
trainer/QF2 Loss                       148.515
trainer/Policy Loss                     50.1308
trainer/Q1 Predictions Mean            -49.5577
trainer/Q1 Predictions Std              77.9967
trainer/Q1 Predictions Max              34.2286
trainer/Q1 Predictions Min            -232.513
trainer/Q2 Predictions Mean            -49.8724
trainer/Q2 Predictions Std              78.4252
trainer/Q2 Predictions Max              34.4901
trainer/Q2 Predictions Min            -232.492
trainer/Q Targets Mean                 -49.2742
trainer/Q Targets Std                   78.6089
trainer/Q Targets Max                   34.3994
trainer/Q Targets Min                 -236.852
trainer/Log Pis Mean                     2.07329
trainer/Log Pis Std                      1.75837
trainer/Log Pis Max                      5.82253
trainer/Log Pis Min                     -4.22695
trainer/policy/mean Mean                -0.305684
trainer/policy/mean Std                  0.780017
trainer/policy/mean Max                  0.96814
trainer/policy/mean Min                 -0.989659
trainer/policy/normal/std Mean           0.555961
trainer/policy/normal/std Std            0.086439
trainer/policy/normal/std Max            0.883326
trainer/policy/normal/std Min            0.282477
trainer/policy/normal/log_std Mean      -0.598441
trainer/policy/normal/log_std Std        0.149584
trainer/policy/normal/log_std Max       -0.124061
trainer/policy/normal/log_std Min       -1.26416
trainer/Alpha                            0.0250062
trainer/Alpha Loss                       0.270337
exploration/num steps total         758000
exploration/num paths total           3790
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.861935
exploration/Rewards Std                  1.48578
exploration/Rewards Max                 -5.06941e-165
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -172.387
exploration/Returns Std                133.434
exploration/Returns Max                -16.7638
exploration/Returns Min               -499.153
exploration/Actions Mean                -0.290857
exploration/Actions Std                  0.781757
exploration/Actions Max                  0.998803
exploration/Actions Min                 -0.999445
exploration/Num Paths                   10
exploration/Average Returns           -172.387
evaluation/num steps total               1.82347e+06
evaluation/num paths total            9072
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   2.04162e-12
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.368889
evaluation/Actions Std                   0.609836
evaluation/Actions Max                   0.301398
evaluation/Actions Min                  -0.979132
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.0213967
time/evaluation sampling (s)            12.4996
time/exploration sampling (s)            4.86838
time/logging (s)                         0.0525988
time/sac training (s)                   32.4962
time/saving (s)                          0.173253
time/training (s)                        0.000166942
time/epoch (s)                          50.1117
time/total (s)                       55545.8
Epoch                                  377
----------------------------------  -----------------
2020-11-10 06:37:09.003195 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 378 finished
----------------------------------  -----------------
replay_buffer/size                  760000
trainer/num train calls             379000
trainer/QF1 Loss                        14.4512
trainer/QF2 Loss                        15.5414
trainer/Policy Loss                     65.4624
trainer/Q1 Predictions Mean            -64.8924
trainer/Q1 Predictions Std              84.5962
trainer/Q1 Predictions Max              48.2917
trainer/Q1 Predictions Min            -235.055
trainer/Q2 Predictions Mean            -64.9728
trainer/Q2 Predictions Std              84.6364
trainer/Q2 Predictions Max              48.3621
trainer/Q2 Predictions Min            -236.178
trainer/Q Targets Mean                 -65.578
trainer/Q Targets Std                   85.3633
trainer/Q Targets Max                   48.1204
trainer/Q Targets Min                 -237.575
trainer/Log Pis Mean                     1.46593
trainer/Log Pis Std                      1.74704
trainer/Log Pis Max                      6.1077
trainer/Log Pis Min                     -4.60916
trainer/policy/mean Mean                -0.447309
trainer/policy/mean Std                  0.671762
trainer/policy/mean Max                  0.954433
trainer/policy/mean Min                 -0.986874
trainer/policy/normal/std Mean           0.567882
trainer/policy/normal/std Std            0.0877184
trainer/policy/normal/std Max            0.837097
trainer/policy/normal/std Min            0.275156
trainer/policy/normal/log_std Mean      -0.577653
trainer/policy/normal/log_std Std        0.154383
trainer/policy/normal/log_std Max       -0.177815
trainer/policy/normal/log_std Min       -1.29042
trainer/Alpha                            0.0247645
trainer/Alpha Loss                      -1.97517
exploration/num steps total         760000
exploration/num paths total           3800
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.947441
exploration/Rewards Std                  1.48028
exploration/Rewards Max                 -8.39542e-193
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -189.488
exploration/Returns Std                141.168
exploration/Returns Max                 -9.44264
exploration/Returns Min               -433.188
exploration/Actions Mean                -0.459337
exploration/Actions Std                  0.683624
exploration/Actions Max                  0.999063
exploration/Actions Min                 -0.99939
exploration/Num Paths                   10
exploration/Average Returns           -189.488
evaluation/num steps total               1.8283e+06
evaluation/num paths total            9096
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.66446
evaluation/Rewards Std                   0.907309
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1138.56
evaluation/Returns Std                 182.002
evaluation/Returns Max                -655.242
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.531274
evaluation/Actions Std                   0.443687
evaluation/Actions Max                   0.266409
evaluation/Actions Min                  -0.971757
evaluation/Num Paths                    24
evaluation/Average Returns           -1138.56
time/data storing (s)                    0.0209132
time/evaluation sampling (s)            12.5947
time/exploration sampling (s)            5.17438
time/logging (s)                         0.0681696
time/sac training (s)                   32.5968
time/saving (s)                          0.253807
time/training (s)                        0.000176692
time/epoch (s)                          50.7089
time/total (s)                       55787
Epoch                                  378
----------------------------------  -----------------
2020-11-10 06:41:17.379710 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 379 finished
----------------------------------  ----------------
replay_buffer/size                  762000
trainer/num train calls             380000
trainer/QF1 Loss                       168.414
trainer/QF2 Loss                       166.145
trainer/Policy Loss                     62.1628
trainer/Q1 Predictions Mean            -61.4987
trainer/Q1 Predictions Std              86.5269
trainer/Q1 Predictions Max              32.7221
trainer/Q1 Predictions Min            -234.346
trainer/Q2 Predictions Mean            -61.8351
trainer/Q2 Predictions Std              86.8525
trainer/Q2 Predictions Max              32.6627
trainer/Q2 Predictions Min            -235.226
trainer/Q Targets Mean                 -60.9096
trainer/Q Targets Std                   86.933
trainer/Q Targets Max                   33.5784
trainer/Q Targets Min                 -237.751
trainer/Log Pis Mean                     1.77204
trainer/Log Pis Std                      1.68227
trainer/Log Pis Max                      6.05853
trainer/Log Pis Min                     -4.81765
trainer/policy/mean Mean                -0.546058
trainer/policy/mean Std                  0.608312
trainer/policy/mean Max                  0.945892
trainer/policy/mean Min                 -0.991842
trainer/policy/normal/std Mean           0.593163
trainer/policy/normal/std Std            0.119783
trainer/policy/normal/std Max            0.918425
trainer/policy/normal/std Min            0.207517
trainer/policy/normal/log_std Mean      -0.542897
trainer/policy/normal/log_std Std        0.206006
trainer/policy/normal/log_std Max       -0.0850947
trainer/policy/normal/log_std Min       -1.57254
trainer/Alpha                            0.0246561
trainer/Alpha Loss                      -0.844088
exploration/num steps total         762000
exploration/num paths total           3810
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.84624
exploration/Rewards Std                  1.54524
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -169.248
exploration/Returns Std                103.293
exploration/Returns Max                -23.0005
exploration/Returns Min               -324.235
exploration/Actions Mean                -0.565545
exploration/Actions Std                  0.571973
exploration/Actions Max                  0.998385
exploration/Actions Min                 -0.99934
exploration/Num Paths                   10
exploration/Average Returns           -169.248
evaluation/num steps total               1.83312e+06
evaluation/num paths total            9120
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.07475
evaluation/Rewards Std                   1.38082
evaluation/Rewards Max                  -1.20002e-18
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -819.024
evaluation/Returns Std                 267.106
evaluation/Returns Max                 -39.1936
evaluation/Returns Min               -1078.61
evaluation/Actions Mean                 -0.486253
evaluation/Actions Std                   0.523622
evaluation/Actions Max                   0.564535
evaluation/Actions Min                  -0.97425
evaluation/Num Paths                    24
evaluation/Average Returns            -819.024
time/data storing (s)                    0.0241286
time/evaluation sampling (s)            13.2984
time/exploration sampling (s)            4.89633
time/logging (s)                         0.0568857
time/sac training (s)                   32.9314
time/saving (s)                          0.176803
time/training (s)                        0.000158922
time/epoch (s)                          51.3841
time/total (s)                       56035.4
Epoch                                  379
----------------------------------  ----------------
2020-11-10 06:45:36.757639 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 380 finished
----------------------------------  -----------------
replay_buffer/size                  764000
trainer/num train calls             381000
trainer/QF1 Loss                        40.9816
trainer/QF2 Loss                        43.4267
trainer/Policy Loss                     64.6902
trainer/Q1 Predictions Mean            -64.1212
trainer/Q1 Predictions Std              86.1096
trainer/Q1 Predictions Max              26.0857
trainer/Q1 Predictions Min            -240.253
trainer/Q2 Predictions Mean            -64.1004
trainer/Q2 Predictions Std              86.0751
trainer/Q2 Predictions Max              26.4962
trainer/Q2 Predictions Min            -239.858
trainer/Q Targets Mean                 -64.6324
trainer/Q Targets Std                   86.4232
trainer/Q Targets Max                   26.0819
trainer/Q Targets Min                 -241.988
trainer/Log Pis Mean                     1.65181
trainer/Log Pis Std                      1.84875
trainer/Log Pis Max                      6.26619
trainer/Log Pis Min                     -4.22007
trainer/policy/mean Mean                -0.562865
trainer/policy/mean Std                  0.590915
trainer/policy/mean Max                  0.950838
trainer/policy/mean Min                 -0.99185
trainer/policy/normal/std Mean           0.57708
trainer/policy/normal/std Std            0.102789
trainer/policy/normal/std Max            0.850389
trainer/policy/normal/std Min            0.193643
trainer/policy/normal/log_std Mean      -0.566164
trainer/policy/normal/log_std Std        0.184965
trainer/policy/normal/log_std Max       -0.162062
trainer/policy/normal/log_std Min       -1.64174
trainer/Alpha                            0.0241562
trainer/Alpha Loss                      -1.29639
exploration/num steps total         764000
exploration/num paths total           3820
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.774917
exploration/Rewards Std                  1.48424
exploration/Rewards Max                 -1.95369e-109
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -154.983
exploration/Returns Std                105.28
exploration/Returns Max                -36.6152
exploration/Returns Min               -400.742
exploration/Actions Mean                -0.48203
exploration/Actions Std                  0.604309
exploration/Actions Max                  0.996176
exploration/Actions Min                 -0.998987
exploration/Num Paths                   10
exploration/Average Returns           -154.983
evaluation/num steps total               1.83794e+06
evaluation/num paths total            9144
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.53058
evaluation/Rewards Std                   1.37445
evaluation/Rewards Max                  -9.70763e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1111.65
evaluation/Returns Std                 275.297
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.782455
evaluation/Actions Std                   0.215524
evaluation/Actions Max                   0.0732629
evaluation/Actions Min                  -0.976923
evaluation/Num Paths                    24
evaluation/Average Returns           -1111.65
time/data storing (s)                    0.0197889
time/evaluation sampling (s)            12.5919
time/exploration sampling (s)            5.04681
time/logging (s)                         0.074903
time/sac training (s)                   32.473
time/saving (s)                          0.319153
time/training (s)                        0.000184714
time/epoch (s)                          50.5257
time/total (s)                       56294.7
Epoch                                  380
----------------------------------  -----------------
2020-11-10 06:49:41.401416 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 381 finished
----------------------------------  -----------------
replay_buffer/size                  766000
trainer/num train calls             382000
trainer/QF1 Loss                       265.983
trainer/QF2 Loss                       261.901
trainer/Policy Loss                     61.9985
trainer/Q1 Predictions Mean            -61.6102
trainer/Q1 Predictions Std              83.6088
trainer/Q1 Predictions Max              26.6918
trainer/Q1 Predictions Min            -231.978
trainer/Q2 Predictions Mean            -61.4754
trainer/Q2 Predictions Std              83.6457
trainer/Q2 Predictions Max              26.8067
trainer/Q2 Predictions Min            -232.505
trainer/Q Targets Mean                 -60.8578
trainer/Q Targets Std                   84.0575
trainer/Q Targets Max                   26.7524
trainer/Q Targets Min                 -236.287
trainer/Log Pis Mean                     2.05652
trainer/Log Pis Std                      1.78222
trainer/Log Pis Max                      7.15922
trainer/Log Pis Min                     -4.40486
trainer/policy/mean Mean                -0.579844
trainer/policy/mean Std                  0.597973
trainer/policy/mean Max                  0.9379
trainer/policy/mean Min                 -0.990449
trainer/policy/normal/std Mean           0.572334
trainer/policy/normal/std Std            0.104047
trainer/policy/normal/std Max            0.857724
trainer/policy/normal/std Min            0.25302
trainer/policy/normal/log_std Mean      -0.574229
trainer/policy/normal/log_std Std        0.180475
trainer/policy/normal/log_std Max       -0.153473
trainer/policy/normal/log_std Min       -1.37429
trainer/Alpha                            0.023987
trainer/Alpha Loss                       0.210831
exploration/num steps total         766000
exploration/num paths total           3830
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.743168
exploration/Rewards Std                  1.59278
exploration/Rewards Max                 -1.81715e-167
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -148.634
exploration/Returns Std                 46.8124
exploration/Returns Max                -72.1387
exploration/Returns Min               -217.826
exploration/Actions Mean                -0.422308
exploration/Actions Std                  0.729551
exploration/Actions Max                  0.992606
exploration/Actions Min                 -0.999169
exploration/Num Paths                   10
exploration/Average Returns           -148.634
evaluation/num steps total               1.84277e+06
evaluation/num paths total            9168
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.42374
evaluation/Rewards Std                   1.43144
evaluation/Rewards Max                  -3.56314e-14
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1090.17
evaluation/Returns Std                 286.803
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.731696
evaluation/Actions Std                   0.363668
evaluation/Actions Max                   0.756055
evaluation/Actions Min                  -0.978974
evaluation/Num Paths                    24
evaluation/Average Returns           -1090.17
time/data storing (s)                    0.0210174
time/evaluation sampling (s)            12.5135
time/exploration sampling (s)            5.07245
time/logging (s)                         0.0438232
time/sac training (s)                   32.2204
time/saving (s)                          0.0818537
time/training (s)                        0.000173027
time/epoch (s)                          49.9532
time/total (s)                       56539.3
Epoch                                  381
----------------------------------  -----------------
2020-11-10 06:53:35.810260 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 382 finished
----------------------------------  -----------------
replay_buffer/size                  768000
trainer/num train calls             383000
trainer/QF1 Loss                       183.368
trainer/QF2 Loss                       180.311
trainer/Policy Loss                     68.009
trainer/Q1 Predictions Mean            -67.3436
trainer/Q1 Predictions Std              87.1592
trainer/Q1 Predictions Max              48.0377
trainer/Q1 Predictions Min            -232.725
trainer/Q2 Predictions Mean            -67.4686
trainer/Q2 Predictions Std              87.2309
trainer/Q2 Predictions Max              47.9864
trainer/Q2 Predictions Min            -232.616
trainer/Q Targets Mean                 -67.1872
trainer/Q Targets Std                   87.3539
trainer/Q Targets Max                   47.3089
trainer/Q Targets Min                 -235.661
trainer/Log Pis Mean                     2.05536
trainer/Log Pis Std                      1.8092
trainer/Log Pis Max                      6.86099
trainer/Log Pis Min                     -5.66138
trainer/policy/mean Mean                -0.628383
trainer/policy/mean Std                  0.548023
trainer/policy/mean Max                  0.922961
trainer/policy/mean Min                 -0.9908
trainer/policy/normal/std Mean           0.575846
trainer/policy/normal/std Std            0.0987524
trainer/policy/normal/std Max            0.865074
trainer/policy/normal/std Min            0.191194
trainer/policy/normal/log_std Mean      -0.567012
trainer/policy/normal/log_std Std        0.176875
trainer/policy/normal/log_std Max       -0.144941
trainer/policy/normal/log_std Min       -1.65447
trainer/Alpha                            0.0243998
trainer/Alpha Loss                       0.20555
exploration/num steps total         768000
exploration/num paths total           3840
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.594968
exploration/Rewards Std                  1.48732
exploration/Rewards Max                 -1.93033e-242
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -118.994
exploration/Returns Std                 58.8447
exploration/Returns Max                -39.1936
exploration/Returns Min               -238.333
exploration/Actions Mean                -0.414748
exploration/Actions Std                  0.673303
exploration/Actions Max                  0.997493
exploration/Actions Min                 -0.999092
exploration/Num Paths                   10
exploration/Average Returns           -118.994
evaluation/num steps total               1.84759e+06
evaluation/num paths total            9192
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.05264
evaluation/Rewards Std                   1.15567
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1015.58
evaluation/Returns Std                 230.301
evaluation/Returns Max                -641.818
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.552762
evaluation/Actions Std                   0.442632
evaluation/Actions Max                   0.436211
evaluation/Actions Min                  -0.98157
evaluation/Num Paths                    24
evaluation/Average Returns           -1015.58
time/data storing (s)                    0.020753
time/evaluation sampling (s)            12.7977
time/exploration sampling (s)            5.13999
time/logging (s)                         0.0625441
time/sac training (s)                   32.3101
time/saving (s)                          0.374463
time/training (s)                        0.000263654
time/epoch (s)                          50.7058
time/total (s)                       56773.7
Epoch                                  382
----------------------------------  -----------------
2020-11-10 06:57:37.550222 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 383 finished
----------------------------------  -----------------
replay_buffer/size                  770000
trainer/num train calls             384000
trainer/QF1 Loss                       159.307
trainer/QF2 Loss                       157.234
trainer/Policy Loss                     55.8274
trainer/Q1 Predictions Mean            -55.3575
trainer/Q1 Predictions Std              80.4335
trainer/Q1 Predictions Max              41.7366
trainer/Q1 Predictions Min            -239.78
trainer/Q2 Predictions Mean            -55.4665
trainer/Q2 Predictions Std              80.4281
trainer/Q2 Predictions Max              41.3901
trainer/Q2 Predictions Min            -240.629
trainer/Q Targets Mean                 -55.2831
trainer/Q Targets Std                   81.0017
trainer/Q Targets Max                   41.297
trainer/Q Targets Min                 -244.536
trainer/Log Pis Mean                     2.00804
trainer/Log Pis Std                      1.73249
trainer/Log Pis Max                      6.84598
trainer/Log Pis Min                     -6.58933
trainer/policy/mean Mean                -0.570279
trainer/policy/mean Std                  0.601032
trainer/policy/mean Max                  0.925059
trainer/policy/mean Min                 -0.988009
trainer/policy/normal/std Mean           0.566829
trainer/policy/normal/std Std            0.083638
trainer/policy/normal/std Max            0.81423
trainer/policy/normal/std Min            0.311074
trainer/policy/normal/log_std Mean      -0.578651
trainer/policy/normal/log_std Std        0.149204
trainer/policy/normal/log_std Max       -0.205512
trainer/policy/normal/log_std Min       -1.16772
trainer/Alpha                            0.024579
trainer/Alpha Loss                       0.0297826
exploration/num steps total         770000
exploration/num paths total           3850
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.809792
exploration/Rewards Std                  1.34345
exploration/Rewards Max                 -1.88864e-227
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -161.958
exploration/Returns Std                140.503
exploration/Returns Max                -19.5615
exploration/Returns Min               -384.837
exploration/Actions Mean                -0.618681
exploration/Actions Std                  0.547575
exploration/Actions Max                  0.982406
exploration/Actions Min                 -0.999603
exploration/Num Paths                   10
exploration/Average Returns           -161.958
evaluation/num steps total               1.85242e+06
evaluation/num paths total            9216
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78676
evaluation/Rewards Std                   0.72946
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1163.14
evaluation/Returns Std                 146.618
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.818745
evaluation/Actions Std                   0.168047
evaluation/Actions Max                  -0.63565
evaluation/Actions Min                  -0.976788
evaluation/Num Paths                    24
evaluation/Average Returns           -1163.14
time/data storing (s)                    0.019764
time/evaluation sampling (s)            12.7553
time/exploration sampling (s)            4.90516
time/logging (s)                         0.0359365
time/sac training (s)                   33.1784
time/saving (s)                          0.118741
time/training (s)                        0.000170406
time/epoch (s)                          51.0135
time/total (s)                       57015.4
Epoch                                  383
----------------------------------  -----------------
2020-11-10 07:02:10.931354 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 384 finished
----------------------------------  -----------------
replay_buffer/size                  772000
trainer/num train calls             385000
trainer/QF1 Loss                       106.315
trainer/QF2 Loss                       115.905
trainer/Policy Loss                     64.8957
trainer/Q1 Predictions Mean            -64.2828
trainer/Q1 Predictions Std              83.5563
trainer/Q1 Predictions Max              42.7347
trainer/Q1 Predictions Min            -234.956
trainer/Q2 Predictions Mean            -64.547
trainer/Q2 Predictions Std              83.7571
trainer/Q2 Predictions Max              42.8224
trainer/Q2 Predictions Min            -235.944
trainer/Q Targets Mean                 -64.2257
trainer/Q Targets Std                   84.036
trainer/Q Targets Max                   42.196
trainer/Q Targets Min                 -237.089
trainer/Log Pis Mean                     2.23271
trainer/Log Pis Std                      1.64146
trainer/Log Pis Max                      7.0539
trainer/Log Pis Min                     -3.14685
trainer/policy/mean Mean                -0.620026
trainer/policy/mean Std                  0.562251
trainer/policy/mean Max                  0.942784
trainer/policy/mean Min                 -0.996426
trainer/policy/normal/std Mean           0.57909
trainer/policy/normal/std Std            0.0997168
trainer/policy/normal/std Max            0.858404
trainer/policy/normal/std Min            0.256096
trainer/policy/normal/log_std Mean      -0.560442
trainer/policy/normal/log_std Std        0.167072
trainer/policy/normal/log_std Max       -0.152681
trainer/policy/normal/log_std Min       -1.3622
trainer/Alpha                            0.0247949
trainer/Alpha Loss                       0.860339
exploration/num steps total         772000
exploration/num paths total           3860
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.05653
exploration/Rewards Std                  1.55786
exploration/Rewards Max                 -1.27811e-270
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -211.307
exploration/Returns Std                169.148
exploration/Returns Max                -10.1007
exploration/Returns Min               -618.606
exploration/Actions Mean                -0.59959
exploration/Actions Std                  0.587086
exploration/Actions Max                  0.998834
exploration/Actions Min                 -0.999107
exploration/Num Paths                   10
exploration/Average Returns           -211.307
evaluation/num steps total               1.85724e+06
evaluation/num paths total            9240
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.7899
evaluation/Rewards Std                   1.75439
evaluation/Rewards Max                  -1.56997e-21
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -962.769
evaluation/Returns Std                 351.176
evaluation/Returns Max                  -6.76849
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.587599
evaluation/Actions Std                   0.447374
evaluation/Actions Max                   0.603446
evaluation/Actions Min                  -0.989791
evaluation/Num Paths                    24
evaluation/Average Returns            -962.769
time/data storing (s)                    0.0213016
time/evaluation sampling (s)            13.2988
time/exploration sampling (s)            5.45124
time/logging (s)                         0.0567752
time/sac training (s)                   33.4339
time/saving (s)                          0.171154
time/training (s)                        0.000182322
time/epoch (s)                          52.4333
time/total (s)                       57288.7
Epoch                                  384
----------------------------------  -----------------
2020-11-10 07:06:38.605202 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 385 finished
----------------------------------  ----------------
replay_buffer/size                  774000
trainer/num train calls             386000
trainer/QF1 Loss                        64.3969
trainer/QF2 Loss                        58.5856
trainer/Policy Loss                     58.8672
trainer/Q1 Predictions Mean            -58.1693
trainer/Q1 Predictions Std              80.7618
trainer/Q1 Predictions Max              40.3741
trainer/Q1 Predictions Min            -233.216
trainer/Q2 Predictions Mean            -58.5542
trainer/Q2 Predictions Std              81.2118
trainer/Q2 Predictions Max              41.4129
trainer/Q2 Predictions Min            -233.554
trainer/Q Targets Mean                 -58.6161
trainer/Q Targets Std                   81.3066
trainer/Q Targets Max                   42.2066
trainer/Q Targets Min                 -237.503
trainer/Log Pis Mean                     2.63892
trainer/Log Pis Std                      1.7559
trainer/Log Pis Max                      7.75983
trainer/Log Pis Min                     -2.26136
trainer/policy/mean Mean                -0.678869
trainer/policy/mean Std                  0.520297
trainer/policy/mean Max                  0.932633
trainer/policy/mean Min                 -0.99855
trainer/policy/normal/std Mean           0.578822
trainer/policy/normal/std Std            0.103986
trainer/policy/normal/std Max            0.882451
trainer/policy/normal/std Min            0.218143
trainer/policy/normal/log_std Mean      -0.562739
trainer/policy/normal/log_std Std        0.179665
trainer/policy/normal/log_std Max       -0.125052
trainer/policy/normal/log_std Min       -1.52261
trainer/Alpha                            0.0254586
trainer/Alpha Loss                       2.3453
exploration/num steps total         774000
exploration/num paths total           3870
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.69097
exploration/Rewards Std                  1.69219
exploration/Rewards Max                 -1.21971e-99
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -338.194
exploration/Returns Std                193.864
exploration/Returns Max                -41.5934
exploration/Returns Min               -606.924
exploration/Actions Mean                -0.67496
exploration/Actions Std                  0.510857
exploration/Actions Max                  0.994427
exploration/Actions Min                 -0.999469
exploration/Num Paths                   10
exploration/Average Returns           -338.194
evaluation/num steps total               1.86206e+06
evaluation/num paths total            9264
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.46332
evaluation/Rewards Std                   1.4783
evaluation/Rewards Max                  -9.08235e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1098.13
evaluation/Returns Std                 296.512
evaluation/Returns Max                 -13.3965
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.91868
evaluation/Actions Std                   0.136414
evaluation/Actions Max                  -0.383016
evaluation/Actions Min                  -0.986594
evaluation/Num Paths                    24
evaluation/Average Returns           -1098.13
time/data storing (s)                    0.0241136
time/evaluation sampling (s)            15.8262
time/exploration sampling (s)            5.45775
time/logging (s)                         0.0537832
time/sac training (s)                   33.1281
time/saving (s)                          0.193299
time/training (s)                        0.000152757
time/epoch (s)                          54.6834
time/total (s)                       57556.4
Epoch                                  385
----------------------------------  ----------------
2020-11-10 07:11:39.124683 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 386 finished
----------------------------------  -----------------
replay_buffer/size                  776000
trainer/num train calls             387000
trainer/QF1 Loss                        92.2466
trainer/QF2 Loss                        90.0412
trainer/Policy Loss                     60.0532
trainer/Q1 Predictions Mean            -59.518
trainer/Q1 Predictions Std              82.86
trainer/Q1 Predictions Max              31.2837
trainer/Q1 Predictions Min            -232.166
trainer/Q2 Predictions Mean            -59.6741
trainer/Q2 Predictions Std              83.0415
trainer/Q2 Predictions Max              31.3846
trainer/Q2 Predictions Min            -231.458
trainer/Q Targets Mean                 -59.6267
trainer/Q Targets Std                   84.1587
trainer/Q Targets Max                   31.4248
trainer/Q Targets Min                 -235.526
trainer/Log Pis Mean                     2.03579
trainer/Log Pis Std                      1.72915
trainer/Log Pis Max                      6.70952
trainer/Log Pis Min                     -4.07929
trainer/policy/mean Mean                -0.671762
trainer/policy/mean Std                  0.483299
trainer/policy/mean Max                  0.900244
trainer/policy/mean Min                 -0.992541
trainer/policy/normal/std Mean           0.575133
trainer/policy/normal/std Std            0.0928586
trainer/policy/normal/std Max            0.830553
trainer/policy/normal/std Min            0.213898
trainer/policy/normal/log_std Mean      -0.566047
trainer/policy/normal/log_std Std        0.161294
trainer/policy/normal/log_std Max       -0.185663
trainer/policy/normal/log_std Min       -1.54226
trainer/Alpha                            0.0258403
trainer/Alpha Loss                       0.13084
exploration/num steps total         776000
exploration/num paths total           3880
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12789
exploration/Rewards Std                  1.65316
exploration/Rewards Max                 -4.21613e-255
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -225.579
exploration/Returns Std                152.27
exploration/Returns Max                -47.3431
exploration/Returns Min               -511.564
exploration/Actions Mean                -0.723702
exploration/Actions Std                  0.453067
exploration/Actions Max                  0.971327
exploration/Actions Min                 -0.999448
exploration/Num Paths                   10
exploration/Average Returns           -225.579
evaluation/num steps total               1.86689e+06
evaluation/num paths total            9288
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.63317e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.945562
evaluation/Actions Std                   0.0332485
evaluation/Actions Max                  -0.912312
evaluation/Actions Min                  -0.978946
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0245619
time/evaluation sampling (s)            12.6522
time/exploration sampling (s)            4.97424
time/logging (s)                         0.145903
time/sac training (s)                   42.7907
time/saving (s)                          0.523525
time/training (s)                        0.000163453
time/epoch (s)                          61.1112
time/total (s)                       57856.9
Epoch                                  386
----------------------------------  -----------------
2020-11-10 07:16:39.926160 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 387 finished
----------------------------------  ----------------
replay_buffer/size                  778000
trainer/num train calls             388000
trainer/QF1 Loss                       136.662
trainer/QF2 Loss                       147.229
trainer/Policy Loss                     62.4311
trainer/Q1 Predictions Mean            -61.8707
trainer/Q1 Predictions Std              83.5713
trainer/Q1 Predictions Max              41.7995
trainer/Q1 Predictions Min            -235.534
trainer/Q2 Predictions Mean            -62.0301
trainer/Q2 Predictions Std              83.7633
trainer/Q2 Predictions Max              41.9065
trainer/Q2 Predictions Min            -237.117
trainer/Q Targets Mean                 -61.6997
trainer/Q Targets Std                   84.8292
trainer/Q Targets Max                   42.249
trainer/Q Targets Min                 -241.947
trainer/Log Pis Mean                     2.32985
trainer/Log Pis Std                      1.87813
trainer/Log Pis Max                      7.11691
trainer/Log Pis Min                     -3.02275
trainer/policy/mean Mean                -0.657431
trainer/policy/mean Std                  0.52718
trainer/policy/mean Max                  0.941928
trainer/policy/mean Min                 -0.991024
trainer/policy/normal/std Mean           0.565664
trainer/policy/normal/std Std            0.0899399
trainer/policy/normal/std Max            0.815674
trainer/policy/normal/std Min            0.243461
trainer/policy/normal/log_std Mean      -0.58249
trainer/policy/normal/log_std Std        0.16114
trainer/policy/normal/log_std Max       -0.20374
trainer/policy/normal/log_std Min       -1.4128
trainer/Alpha                            0.0258026
trainer/Alpha Loss                       1.20635
exploration/num steps total         778000
exploration/num paths total           3890
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.917343
exploration/Rewards Std                  1.56064
exploration/Rewards Max                 -6.36958e-76
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -183.469
exploration/Returns Std                155.588
exploration/Returns Max                -62.299
exploration/Returns Min               -495.317
exploration/Actions Mean                -0.636385
exploration/Actions Std                  0.533949
exploration/Actions Max                  0.992081
exploration/Actions Min                 -0.999371
exploration/Num Paths                   10
exploration/Average Returns           -183.469
evaluation/num steps total               1.87171e+06
evaluation/num paths total            9312
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.07535
evaluation/Rewards Std                   2.67324e-16
evaluation/Rewards Max                  -6.07535
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1221.14
evaluation/Returns Std                   0
evaluation/Returns Max               -1221.14
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.926223
evaluation/Actions Std                   0.0537062
evaluation/Actions Max                  -0.872462
evaluation/Actions Min                  -0.980181
evaluation/Num Paths                    24
evaluation/Average Returns           -1221.14
time/data storing (s)                    0.0265929
time/evaluation sampling (s)            12.907
time/exploration sampling (s)            5.12843
time/logging (s)                         0.0725429
time/sac training (s)                   32.5096
time/saving (s)                          0.401882
time/training (s)                        0.000147614
time/epoch (s)                          51.0462
time/total (s)                       58157.6
Epoch                                  387
----------------------------------  ----------------
2020-11-10 07:21:19.580533 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 388 finished
----------------------------------  -----------------
replay_buffer/size                  780000
trainer/num train calls             389000
trainer/QF1 Loss                       333.4
trainer/QF2 Loss                       331.157
trainer/Policy Loss                     57.2864
trainer/Q1 Predictions Mean            -56.915
trainer/Q1 Predictions Std              83.6794
trainer/Q1 Predictions Max              29.853
trainer/Q1 Predictions Min            -238.312
trainer/Q2 Predictions Mean            -56.7774
trainer/Q2 Predictions Std              83.5156
trainer/Q2 Predictions Max              29.8531
trainer/Q2 Predictions Min            -238.044
trainer/Q Targets Mean                 -56.1768
trainer/Q Targets Std                   83.8094
trainer/Q Targets Max                   29.765
trainer/Q Targets Min                 -239.802
trainer/Log Pis Mean                     2.09392
trainer/Log Pis Std                      1.57934
trainer/Log Pis Max                      7.0223
trainer/Log Pis Min                     -3.15523
trainer/policy/mean Mean                -0.39479
trainer/policy/mean Std                  0.721342
trainer/policy/mean Max                  0.960949
trainer/policy/mean Min                 -0.991558
trainer/policy/normal/std Mean           0.56996
trainer/policy/normal/std Std            0.0940134
trainer/policy/normal/std Max            0.857252
trainer/policy/normal/std Min            0.256453
trainer/policy/normal/log_std Mean      -0.575
trainer/policy/normal/log_std Std        0.158454
trainer/policy/normal/log_std Max       -0.154023
trainer/policy/normal/log_std Min       -1.36081
trainer/Alpha                            0.0254047
trainer/Alpha Loss                       0.344969
exploration/num steps total         780000
exploration/num paths total           3900
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.868163
exploration/Rewards Std                  1.4912
exploration/Rewards Max                 -6.89515e-182
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -173.633
exploration/Returns Std                 81.5468
exploration/Returns Max                -91.933
exploration/Returns Min               -376.188
exploration/Actions Mean                -0.348414
exploration/Actions Std                  0.755871
exploration/Actions Max                  0.996961
exploration/Actions Min                 -0.999016
exploration/Num Paths                   10
exploration/Average Returns           -173.633
evaluation/num steps total               1.87654e+06
evaluation/num paths total            9336
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.5613
evaluation/Rewards Std                   0.997062
evaluation/Rewards Max                  -3.21888
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1117.82
evaluation/Returns Std                 200.237
evaluation/Returns Max                -650.228
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.607211
evaluation/Actions Std                   0.377949
evaluation/Actions Max                   0.240597
evaluation/Actions Min                  -0.978665
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.82
time/data storing (s)                    0.0195097
time/evaluation sampling (s)            12.661
time/exploration sampling (s)            5.15404
time/logging (s)                         0.0454283
time/sac training (s)                   32.5619
time/saving (s)                          0.0817261
time/training (s)                        0.000193325
time/epoch (s)                          50.5238
time/total (s)                       58437.2
Epoch                                  388
----------------------------------  -----------------
2020-11-10 07:25:43.912730 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 389 finished
----------------------------------  -----------------
replay_buffer/size                  782000
trainer/num train calls             390000
trainer/QF1 Loss                        50.8134
trainer/QF2 Loss                        44.399
trainer/Policy Loss                     57.8607
trainer/Q1 Predictions Mean            -57.2302
trainer/Q1 Predictions Std              82.9231
trainer/Q1 Predictions Max              40.6889
trainer/Q1 Predictions Min            -233.209
trainer/Q2 Predictions Mean            -57.5065
trainer/Q2 Predictions Std              83.1585
trainer/Q2 Predictions Max              40.4354
trainer/Q2 Predictions Min            -232.566
trainer/Q Targets Mean                 -57.6061
trainer/Q Targets Std                   83.9015
trainer/Q Targets Max                   40.7641
trainer/Q Targets Min                 -237.293
trainer/Log Pis Mean                     2.05382
trainer/Log Pis Std                      1.71218
trainer/Log Pis Max                      5.94658
trainer/Log Pis Min                     -5.67717
trainer/policy/mean Mean                -0.474456
trainer/policy/mean Std                  0.665533
trainer/policy/mean Max                  0.957761
trainer/policy/mean Min                 -0.988692
trainer/policy/normal/std Mean           0.570975
trainer/policy/normal/std Std            0.101198
trainer/policy/normal/std Max            0.887974
trainer/policy/normal/std Min            0.214262
trainer/policy/normal/log_std Mean      -0.576101
trainer/policy/normal/log_std Std        0.179007
trainer/policy/normal/log_std Max       -0.118813
trainer/policy/normal/log_std Min       -1.54055
trainer/Alpha                            0.0253656
trainer/Alpha Loss                       0.197769
exploration/num steps total         782000
exploration/num paths total           3910
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.855217
exploration/Rewards Std                  1.46396
exploration/Rewards Max                 -8.64927e-292
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -171.043
exploration/Returns Std                114.187
exploration/Returns Max                -64.0242
exploration/Returns Min               -414.522
exploration/Actions Mean                -0.510351
exploration/Actions Std                  0.670019
exploration/Actions Max                  0.998389
exploration/Actions Min                 -0.999559
exploration/Num Paths                   10
exploration/Average Returns           -171.043
evaluation/num steps total               1.88136e+06
evaluation/num paths total            9360
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78283
evaluation/Rewards Std                   0.743713
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.35
evaluation/Returns Std                 149.262
evaluation/Returns Max                -657.916
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.563364
evaluation/Actions Std                   0.422781
evaluation/Actions Max                   0.636379
evaluation/Actions Min                  -0.986498
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.35
time/data storing (s)                    0.021588
time/evaluation sampling (s)            13.0054
time/exploration sampling (s)            5.08529
time/logging (s)                         0.0587538
time/sac training (s)                   32.3405
time/saving (s)                          0.381304
time/training (s)                        0.000146442
time/epoch (s)                          50.893
time/total (s)                       58701.5
Epoch                                  389
----------------------------------  -----------------
2020-11-10 07:30:02.333647 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 390 finished
----------------------------------  -----------------
replay_buffer/size                  784000
trainer/num train calls             391000
trainer/QF1 Loss                        82.7054
trainer/QF2 Loss                        87.675
trainer/Policy Loss                     61.6637
trainer/Q1 Predictions Mean            -61.0034
trainer/Q1 Predictions Std              80.3453
trainer/Q1 Predictions Max              26.7114
trainer/Q1 Predictions Min            -237.948
trainer/Q2 Predictions Mean            -61.138
trainer/Q2 Predictions Std              80.3918
trainer/Q2 Predictions Max              26.6789
trainer/Q2 Predictions Min            -238.222
trainer/Q Targets Mean                 -61.8159
trainer/Q Targets Std                   81.7669
trainer/Q Targets Max                   26.6205
trainer/Q Targets Min                 -238.445
trainer/Log Pis Mean                     1.7761
trainer/Log Pis Std                      1.61675
trainer/Log Pis Max                      6.08783
trainer/Log Pis Min                     -5.60037
trainer/policy/mean Mean                -0.386781
trainer/policy/mean Std                  0.714394
trainer/policy/mean Max                  0.971264
trainer/policy/mean Min                 -0.983922
trainer/policy/normal/std Mean           0.573006
trainer/policy/normal/std Std            0.0954645
trainer/policy/normal/std Max            0.846907
trainer/policy/normal/std Min            0.205055
trainer/policy/normal/log_std Mean      -0.571027
trainer/policy/normal/log_std Std        0.171206
trainer/policy/normal/log_std Max       -0.166165
trainer/policy/normal/log_std Min       -1.58447
trainer/Alpha                            0.0250046
trainer/Alpha Loss                      -0.825887
exploration/num steps total         784000
exploration/num paths total           3920
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.90471
exploration/Rewards Std                  1.47623
exploration/Rewards Max                 -9.92939e-139
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -180.942
exploration/Returns Std                 95.6196
exploration/Returns Max                -62.1496
exploration/Returns Min               -398.798
exploration/Actions Mean                -0.439255
exploration/Actions Std                  0.684619
exploration/Actions Max                  0.998263
exploration/Actions Min                 -0.999149
exploration/Num Paths                   10
exploration/Average Returns           -180.942
evaluation/num steps total               1.88618e+06
evaluation/num paths total            9384
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.84679
evaluation/Rewards Std                   0.758023
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1175.21
evaluation/Returns Std                 152.362
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.548867
evaluation/Actions Std                   0.43562
evaluation/Actions Max                  -0.0791925
evaluation/Actions Min                  -0.968959
evaluation/Num Paths                    24
evaluation/Average Returns           -1175.21
time/data storing (s)                    0.0231698
time/evaluation sampling (s)            12.6207
time/exploration sampling (s)            5.00569
time/logging (s)                         0.0599065
time/sac training (s)                   31.9542
time/saving (s)                          0.289172
time/training (s)                        0.000173576
time/epoch (s)                          49.953
time/total (s)                       58959.9
Epoch                                  390
----------------------------------  -----------------
2020-11-10 07:34:28.382579 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 391 finished
----------------------------------  -----------------
replay_buffer/size                  786000
trainer/num train calls             392000
trainer/QF1 Loss                       153.798
trainer/QF2 Loss                       159.878
trainer/Policy Loss                     68.8531
trainer/Q1 Predictions Mean            -68.3549
trainer/Q1 Predictions Std              85.1756
trainer/Q1 Predictions Max              46.6802
trainer/Q1 Predictions Min            -233.346
trainer/Q2 Predictions Mean            -68.2839
trainer/Q2 Predictions Std              85.2887
trainer/Q2 Predictions Max              46.2639
trainer/Q2 Predictions Min            -232.402
trainer/Q Targets Mean                 -67.8979
trainer/Q Targets Std                   86.4856
trainer/Q Targets Max                   45.7999
trainer/Q Targets Min                 -237.622
trainer/Log Pis Mean                     2.29995
trainer/Log Pis Std                      1.77888
trainer/Log Pis Max                      6.18476
trainer/Log Pis Min                     -3.29215
trainer/policy/mean Mean                -0.335138
trainer/policy/mean Std                  0.768781
trainer/policy/mean Max                  0.970948
trainer/policy/mean Min                 -0.99161
trainer/policy/normal/std Mean           0.545491
trainer/policy/normal/std Std            0.0850836
trainer/policy/normal/std Max            0.798863
trainer/policy/normal/std Min            0.261368
trainer/policy/normal/log_std Mean      -0.61856
trainer/policy/normal/log_std Std        0.160432
trainer/policy/normal/log_std Max       -0.224566
trainer/policy/normal/log_std Min       -1.34183
trainer/Alpha                            0.0249194
trainer/Alpha Loss                       1.10745
exploration/num steps total         786000
exploration/num paths total           3930
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.18958
exploration/Rewards Std                  1.55564
exploration/Rewards Max                 -2.03099e-141
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -237.917
exploration/Returns Std                161.795
exploration/Returns Max                -55.7596
exploration/Returns Min               -573.021
exploration/Actions Mean                -0.379741
exploration/Actions Std                  0.729733
exploration/Actions Max                  0.998055
exploration/Actions Min                 -0.999664
exploration/Num Paths                   10
exploration/Average Returns           -237.917
evaluation/num steps total               1.89101e+06
evaluation/num paths total            9408
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.6759
evaluation/Rewards Std                   0.876113
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.86
evaluation/Returns Std                 175.918
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.304058
evaluation/Actions Std                   0.685054
evaluation/Actions Max                   0.760555
evaluation/Actions Min                  -0.983577
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.86
time/data storing (s)                    0.020573
time/evaluation sampling (s)            12.7168
time/exploration sampling (s)            5.10564
time/logging (s)                         0.0493421
time/sac training (s)                   32.2417
time/saving (s)                          0.217854
time/training (s)                        0.000170968
time/epoch (s)                          50.3521
time/total (s)                       59225.9
Epoch                                  391
----------------------------------  -----------------
2020-11-10 07:39:05.473262 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 392 finished
----------------------------------  -----------------
replay_buffer/size                  788000
trainer/num train calls             393000
trainer/QF1 Loss                        30.3947
trainer/QF2 Loss                        30.3666
trainer/Policy Loss                     63.9395
trainer/Q1 Predictions Mean            -63.4904
trainer/Q1 Predictions Std              84.3931
trainer/Q1 Predictions Max              27.7888
trainer/Q1 Predictions Min            -233.951
trainer/Q2 Predictions Mean            -63.4041
trainer/Q2 Predictions Std              84.4511
trainer/Q2 Predictions Max              27.9753
trainer/Q2 Predictions Min            -234.32
trainer/Q Targets Mean                 -64.0143
trainer/Q Targets Std                   84.9211
trainer/Q Targets Max                   28.3456
trainer/Q Targets Min                 -239.475
trainer/Log Pis Mean                     1.921
trainer/Log Pis Std                      1.94049
trainer/Log Pis Max                      7.05417
trainer/Log Pis Min                     -8.75169
trainer/policy/mean Mean                -0.451789
trainer/policy/mean Std                  0.6913
trainer/policy/mean Max                  0.976319
trainer/policy/mean Min                 -0.990235
trainer/policy/normal/std Mean           0.581718
trainer/policy/normal/std Std            0.107106
trainer/policy/normal/std Max            0.906609
trainer/policy/normal/std Min            0.202496
trainer/policy/normal/log_std Mean      -0.559811
trainer/policy/normal/log_std Std        0.195542
trainer/policy/normal/log_std Max       -0.0980442
trainer/policy/normal/log_std Min       -1.59704
trainer/Alpha                            0.0252601
trainer/Alpha Loss                      -0.290588
exploration/num steps total         788000
exploration/num paths total           3940
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.946735
exploration/Rewards Std                  1.47586
exploration/Rewards Max                 -5.49781e-139
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -189.347
exploration/Returns Std                150.113
exploration/Returns Max                -21.3124
exploration/Returns Min               -457.294
exploration/Actions Mean                -0.35067
exploration/Actions Std                  0.770586
exploration/Actions Max                  0.999293
exploration/Actions Min                 -0.999098
exploration/Num Paths                   10
exploration/Average Returns           -189.347
evaluation/num steps total               1.89583e+06
evaluation/num paths total            9432
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.95959
evaluation/Rewards Std                   0.555173
evaluation/Rewards Max                  -3.29602
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.88
evaluation/Returns Std                 111.589
evaluation/Returns Max                -662.714
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.547886
evaluation/Actions Std                   0.431006
evaluation/Actions Max                  -0.108867
evaluation/Actions Min                  -0.977961
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.88
time/data storing (s)                    0.0199862
time/evaluation sampling (s)            12.6727
time/exploration sampling (s)            5.04982
time/logging (s)                         0.0771894
time/sac training (s)                   32.4747
time/saving (s)                          0.283821
time/training (s)                        0.000157593
time/epoch (s)                          50.5783
time/total (s)                       59503
Epoch                                  392
----------------------------------  -----------------
2020-11-10 07:43:54.815273 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 393 finished
----------------------------------  ----------------
replay_buffer/size                  790000
trainer/num train calls             394000
trainer/QF1 Loss                         8.71044
trainer/QF2 Loss                         9.67155
trainer/Policy Loss                     61.8672
trainer/Q1 Predictions Mean            -61.363
trainer/Q1 Predictions Std              84.7271
trainer/Q1 Predictions Max              25.915
trainer/Q1 Predictions Min            -231.99
trainer/Q2 Predictions Mean            -61.4177
trainer/Q2 Predictions Std              84.7794
trainer/Q2 Predictions Max              26.3278
trainer/Q2 Predictions Min            -231.257
trainer/Q Targets Mean                 -62.0194
trainer/Q Targets Std                   86.1373
trainer/Q Targets Max                   26.3183
trainer/Q Targets Min                 -236.362
trainer/Log Pis Mean                     2.14702
trainer/Log Pis Std                      1.57801
trainer/Log Pis Max                      7.35961
trainer/Log Pis Min                     -3.222
trainer/policy/mean Mean                -0.537307
trainer/policy/mean Std                  0.635698
trainer/policy/mean Max                  0.955058
trainer/policy/mean Min                 -0.989191
trainer/policy/normal/std Mean           0.593432
trainer/policy/normal/std Std            0.11665
trainer/policy/normal/std Max            0.913686
trainer/policy/normal/std Min            0.228658
trainer/policy/normal/log_std Mean      -0.540664
trainer/policy/normal/log_std Std        0.194211
trainer/policy/normal/log_std Max       -0.0902688
trainer/policy/normal/log_std Min       -1.47553
trainer/Alpha                            0.0253389
trainer/Alpha Loss                       0.540348
exploration/num steps total         790000
exploration/num paths total           3950
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.819342
exploration/Rewards Std                  1.6019
exploration/Rewards Max                 -2.17504e-97
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -163.868
exploration/Returns Std                 94.9693
exploration/Returns Max                -31.9786
exploration/Returns Min               -348.385
exploration/Actions Mean                -0.366359
exploration/Actions Std                  0.717215
exploration/Actions Max                  0.998502
exploration/Actions Min                 -0.9996
exploration/Num Paths                   10
exploration/Average Returns           -163.868
evaluation/num steps total               1.90066e+06
evaluation/num paths total            9456
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.61165
evaluation/Rewards Std                   0.859876
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1127.94
evaluation/Returns Std                 172.459
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.57775
evaluation/Actions Std                   0.409078
evaluation/Actions Max                  -0.134014
evaluation/Actions Min                  -0.981008
evaluation/Num Paths                    24
evaluation/Average Returns           -1127.94
time/data storing (s)                    0.0250425
time/evaluation sampling (s)            12.5689
time/exploration sampling (s)            4.96328
time/logging (s)                         0.0643183
time/sac training (s)                   32.4864
time/saving (s)                          0.289421
time/training (s)                        0.000180586
time/epoch (s)                          50.3975
time/total (s)                       59792.3
Epoch                                  393
----------------------------------  ----------------
2020-11-10 07:48:27.553895 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 394 finished
----------------------------------  ----------------
replay_buffer/size                  792000
trainer/num train calls             395000
trainer/QF1 Loss                        41.4721
trainer/QF2 Loss                        41.0966
trainer/Policy Loss                     51.4676
trainer/Q1 Predictions Mean            -51.204
trainer/Q1 Predictions Std              80.2517
trainer/Q1 Predictions Max              35.3593
trainer/Q1 Predictions Min            -234.234
trainer/Q2 Predictions Mean            -51.0571
trainer/Q2 Predictions Std              80.1832
trainer/Q2 Predictions Max              34.9155
trainer/Q2 Predictions Min            -234.964
trainer/Q Targets Mean                 -51.2552
trainer/Q Targets Std                   80.9024
trainer/Q Targets Max                   34.618
trainer/Q Targets Min                 -238.497
trainer/Log Pis Mean                     2.0151
trainer/Log Pis Std                      1.74546
trainer/Log Pis Max                      6.1081
trainer/Log Pis Min                     -4.41199
trainer/policy/mean Mean                -0.260783
trainer/policy/mean Std                  0.793125
trainer/policy/mean Max                  0.980767
trainer/policy/mean Min                 -0.986243
trainer/policy/normal/std Mean           0.564547
trainer/policy/normal/std Std            0.0887576
trainer/policy/normal/std Max            0.832221
trainer/policy/normal/std Min            0.211475
trainer/policy/normal/log_std Mean      -0.584488
trainer/policy/normal/log_std Std        0.162805
trainer/policy/normal/log_std Max       -0.183658
trainer/policy/normal/log_std Min       -1.55365
trainer/Alpha                            0.0253058
trainer/Alpha Loss                       0.0555051
exploration/num steps total         792000
exploration/num paths total           3960
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.939233
exploration/Rewards Std                  1.59379
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -187.847
exploration/Returns Std                112.059
exploration/Returns Max                -18.7097
exploration/Returns Min               -424.186
exploration/Actions Mean                -0.378893
exploration/Actions Std                  0.713794
exploration/Actions Max                  0.999353
exploration/Actions Min                 -0.999205
exploration/Num Paths                   10
exploration/Average Returns           -187.847
evaluation/num steps total               1.90548e+06
evaluation/num paths total            9480
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.67501
evaluation/Rewards Std                   0.879357
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1140.68
evaluation/Returns Std                 176.393
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.272286
evaluation/Actions Std                   0.712902
evaluation/Actions Max                   0.923143
evaluation/Actions Min                  -0.978206
evaluation/Num Paths                    24
evaluation/Average Returns           -1140.68
time/data storing (s)                    0.0301195
time/evaluation sampling (s)            12.6172
time/exploration sampling (s)            4.75095
time/logging (s)                         0.0520188
time/sac training (s)                   32.491
time/saving (s)                          0.381008
time/training (s)                        0.000143159
time/epoch (s)                          50.3224
time/total (s)                       60065
Epoch                                  394
----------------------------------  ----------------
2020-11-10 07:52:53.829354 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 395 finished
----------------------------------  -----------------
replay_buffer/size                  794000
trainer/num train calls             396000
trainer/QF1 Loss                        36.8715
trainer/QF2 Loss                        38.5878
trainer/Policy Loss                     55.6077
trainer/Q1 Predictions Mean            -54.9205
trainer/Q1 Predictions Std              78.1892
trainer/Q1 Predictions Max              30.8689
trainer/Q1 Predictions Min            -236.938
trainer/Q2 Predictions Mean            -55.1005
trainer/Q2 Predictions Std              78.4907
trainer/Q2 Predictions Max              31.7042
trainer/Q2 Predictions Min            -236.597
trainer/Q Targets Mean                 -55.0821
trainer/Q Targets Std                   78.8954
trainer/Q Targets Max                   30.6844
trainer/Q Targets Min                 -238.412
trainer/Log Pis Mean                     2.0464
trainer/Log Pis Std                      1.68025
trainer/Log Pis Max                      5.63804
trainer/Log Pis Min                     -5.305
trainer/policy/mean Mean                -0.448889
trainer/policy/mean Std                  0.693954
trainer/policy/mean Max                  0.961753
trainer/policy/mean Min                 -0.988236
trainer/policy/normal/std Mean           0.573609
trainer/policy/normal/std Std            0.102626
trainer/policy/normal/std Max            0.883059
trainer/policy/normal/std Min            0.201716
trainer/policy/normal/log_std Mean      -0.571614
trainer/policy/normal/log_std Std        0.179407
trainer/policy/normal/log_std Max       -0.124363
trainer/policy/normal/log_std Min       -1.6009
trainer/Alpha                            0.0247979
trainer/Alpha Loss                       0.171556
exploration/num steps total         794000
exploration/num paths total           3970
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.75542
exploration/Rewards Std                  1.48396
exploration/Rewards Max                 -2.83633e-116
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -151.084
exploration/Returns Std                 78.3849
exploration/Returns Max                -26.2296
exploration/Returns Min               -296.375
exploration/Actions Mean                -0.304694
exploration/Actions Std                  0.797409
exploration/Actions Max                  0.999239
exploration/Actions Min                 -0.999344
exploration/Num Paths                   10
exploration/Average Returns           -151.084
evaluation/num steps total               1.9103e+06
evaluation/num paths total            9504
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.89665
evaluation/Rewards Std                   1.81064
evaluation/Rewards Max                  -1.40986e-16
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -984.227
evaluation/Returns Std                 362.157
evaluation/Returns Max                  -9.44264
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.519852
evaluation/Actions Std                   0.510615
evaluation/Actions Max                   0.599692
evaluation/Actions Min                  -0.986905
evaluation/Num Paths                    24
evaluation/Average Returns            -984.227
time/data storing (s)                    0.0245513
time/evaluation sampling (s)            12.6398
time/exploration sampling (s)            5.93359
time/logging (s)                         0.0403714
time/sac training (s)                   32.2937
time/saving (s)                          0.268344
time/training (s)                        0.000152624
time/epoch (s)                          51.2005
time/total (s)                       60331.2
Epoch                                  395
----------------------------------  -----------------
2020-11-10 07:57:35.485667 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 396 finished
----------------------------------  -----------------
replay_buffer/size                  796000
trainer/num train calls             397000
trainer/QF1 Loss                       301.711
trainer/QF2 Loss                       294.239
trainer/Policy Loss                     64.9284
trainer/Q1 Predictions Mean            -64.4066
trainer/Q1 Predictions Std              83.1455
trainer/Q1 Predictions Max              25.7774
trainer/Q1 Predictions Min            -232.316
trainer/Q2 Predictions Mean            -64.5101
trainer/Q2 Predictions Std              83.2059
trainer/Q2 Predictions Max              25.5593
trainer/Q2 Predictions Min            -231.776
trainer/Q Targets Mean                 -63.5786
trainer/Q Targets Std                   84.0349
trainer/Q Targets Max                   25.1419
trainer/Q Targets Min                 -237.455
trainer/Log Pis Mean                     1.68244
trainer/Log Pis Std                      1.78232
trainer/Log Pis Max                      6.07978
trainer/Log Pis Min                     -4.31553
trainer/policy/mean Mean                -0.405005
trainer/policy/mean Std                  0.701882
trainer/policy/mean Max                  0.967865
trainer/policy/mean Min                 -0.989429
trainer/policy/normal/std Mean           0.583883
trainer/policy/normal/std Std            0.103364
trainer/policy/normal/std Max            0.909809
trainer/policy/normal/std Min            0.204663
trainer/policy/normal/log_std Mean      -0.553443
trainer/policy/normal/log_std Std        0.176541
trainer/policy/normal/log_std Max       -0.0945202
trainer/policy/normal/log_std Min       -1.58639
trainer/Alpha                            0.0244158
trainer/Alpha Loss                      -1.17896
exploration/num steps total         796000
exploration/num paths total           3980
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.678451
exploration/Rewards Std                  1.46822
exploration/Rewards Max                 -2.36092e-165
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -135.69
exploration/Returns Std                116.393
exploration/Returns Max                -30.3141
exploration/Returns Min               -458.407
exploration/Actions Mean                -0.486031
exploration/Actions Std                  0.637151
exploration/Actions Max                  0.996807
exploration/Actions Min                 -0.998976
exploration/Num Paths                   10
exploration/Average Returns           -135.69
evaluation/num steps total               1.91513e+06
evaluation/num paths total            9528
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.66963
evaluation/Rewards Std                   0.894471
evaluation/Rewards Max                  -3.29584
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1139.6
evaluation/Returns Std                 179.248
evaluation/Returns Max                -665.351
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.555825
evaluation/Actions Std                   0.422211
evaluation/Actions Max                  -0.107109
evaluation/Actions Min                  -0.975571
evaluation/Num Paths                    24
evaluation/Average Returns           -1139.6
time/data storing (s)                    0.0202376
time/evaluation sampling (s)            12.7035
time/exploration sampling (s)            5.07079
time/logging (s)                         0.0624051
time/sac training (s)                   33.0163
time/saving (s)                          0.390157
time/training (s)                        0.000169573
time/epoch (s)                          51.2636
time/total (s)                       60612.8
Epoch                                  396
----------------------------------  -----------------
2020-11-10 08:02:04.830606 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 397 finished
----------------------------------  -----------------
replay_buffer/size                  798000
trainer/num train calls             398000
trainer/QF1 Loss                       111.87
trainer/QF2 Loss                       110.631
trainer/Policy Loss                     58.9097
trainer/Q1 Predictions Mean            -58.2867
trainer/Q1 Predictions Std              80.6091
trainer/Q1 Predictions Max              27.2293
trainer/Q1 Predictions Min            -234.23
trainer/Q2 Predictions Mean            -58.3894
trainer/Q2 Predictions Std              80.6848
trainer/Q2 Predictions Max              26.1062
trainer/Q2 Predictions Min            -235.391
trainer/Q Targets Mean                 -58.2343
trainer/Q Targets Std                   81.3647
trainer/Q Targets Max                   25.6683
trainer/Q Targets Min                 -239.405
trainer/Log Pis Mean                     2.21365
trainer/Log Pis Std                      1.72948
trainer/Log Pis Max                      7.04821
trainer/Log Pis Min                     -4.23296
trainer/policy/mean Mean                -0.534199
trainer/policy/mean Std                  0.634727
trainer/policy/mean Max                  0.947896
trainer/policy/mean Min                 -0.992633
trainer/policy/normal/std Mean           0.590681
trainer/policy/normal/std Std            0.108996
trainer/policy/normal/std Max            0.899766
trainer/policy/normal/std Min            0.264952
trainer/policy/normal/log_std Mean      -0.542503
trainer/policy/normal/log_std Std        0.176975
trainer/policy/normal/log_std Max       -0.105621
trainer/policy/normal/log_std Min       -1.32821
trainer/Alpha                            0.0244693
trainer/Alpha Loss                       0.792732
exploration/num steps total         798000
exploration/num paths total           3990
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.876361
exploration/Rewards Std                  1.51872
exploration/Rewards Max                 -1.35712e-107
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -175.272
exploration/Returns Std                 86.9488
exploration/Returns Max                -72.3823
exploration/Returns Min               -329.577
exploration/Actions Mean                -0.53672
exploration/Actions Std                  0.604915
exploration/Actions Max                  0.998753
exploration/Actions Min                 -0.999216
exploration/Num Paths                   10
exploration/Average Returns           -175.272
evaluation/num steps total               1.91995e+06
evaluation/num paths total            9552
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96107
evaluation/Rewards Std                   0.54805
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.18
evaluation/Returns Std                 110.158
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.784785
evaluation/Actions Std                   0.245997
evaluation/Actions Max                   0.422641
evaluation/Actions Min                  -0.981499
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.18
time/data storing (s)                    0.0241979
time/evaluation sampling (s)            12.5482
time/exploration sampling (s)            5.53533
time/logging (s)                         0.0777004
time/sac training (s)                   32.7234
time/saving (s)                          0.207671
time/training (s)                        0.000163946
time/epoch (s)                          51.1166
time/total (s)                       60882.2
Epoch                                  397
----------------------------------  -----------------
2020-11-10 08:06:36.644296 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 398 finished
----------------------------------  ----------------
replay_buffer/size                  800000
trainer/num train calls             399000
trainer/QF1 Loss                       164.209
trainer/QF2 Loss                       185.487
trainer/Policy Loss                     67.1795
trainer/Q1 Predictions Mean            -66.6972
trainer/Q1 Predictions Std              85.6104
trainer/Q1 Predictions Max              29.2178
trainer/Q1 Predictions Min            -234.957
trainer/Q2 Predictions Mean            -66.6176
trainer/Q2 Predictions Std              85.5774
trainer/Q2 Predictions Max              29.0377
trainer/Q2 Predictions Min            -234.339
trainer/Q Targets Mean                 -66.3949
trainer/Q Targets Std                   86.3683
trainer/Q Targets Max                   28.3747
trainer/Q Targets Min                 -239.671
trainer/Log Pis Mean                     1.83151
trainer/Log Pis Std                      1.68185
trainer/Log Pis Max                      6.68502
trainer/Log Pis Min                     -3.65982
trainer/policy/mean Mean                -0.469118
trainer/policy/mean Std                  0.647671
trainer/policy/mean Max                  0.930226
trainer/policy/mean Min                 -0.990842
trainer/policy/normal/std Mean           0.587063
trainer/policy/normal/std Std            0.101276
trainer/policy/normal/std Max            0.888798
trainer/policy/normal/std Min            0.206263
trainer/policy/normal/log_std Mean      -0.54722
trainer/policy/normal/log_std Std        0.1717
trainer/policy/normal/log_std Max       -0.117885
trainer/policy/normal/log_std Min       -1.5786
trainer/Alpha                            0.0245998
trainer/Alpha Loss                      -0.624276
exploration/num steps total         800000
exploration/num paths total           4000
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.888098
exploration/Rewards Std                  1.41955
exploration/Rewards Max                 -2.19543e-59
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -177.62
exploration/Returns Std                 90.8456
exploration/Returns Max                 -3.4012
exploration/Returns Min               -329
exploration/Actions Mean                -0.512818
exploration/Actions Std                  0.662035
exploration/Actions Max                  0.998287
exploration/Actions Min                 -0.99912
exploration/Num Paths                   10
exploration/Average Returns           -177.62
evaluation/num steps total               1.92478e+06
evaluation/num paths total            9576
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.78587
evaluation/Rewards Std                   0.733488
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1162.96
evaluation/Returns Std                 147.215
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.636762
evaluation/Actions Std                   0.347465
evaluation/Actions Max                  -0.274309
evaluation/Actions Min                  -0.979787
evaluation/Num Paths                    24
evaluation/Average Returns           -1162.96
time/data storing (s)                    0.0219528
time/evaluation sampling (s)            12.5548
time/exploration sampling (s)            4.95361
time/logging (s)                         0.0601737
time/sac training (s)                   32.1877
time/saving (s)                          0.291744
time/training (s)                        0.000171394
time/epoch (s)                          50.0702
time/total (s)                       61153.9
Epoch                                  398
----------------------------------  ----------------
2020-11-10 08:11:06.405614 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 399 finished
----------------------------------  -----------------
replay_buffer/size                  802000
trainer/num train calls             400000
trainer/QF1 Loss                         6.50578
trainer/QF2 Loss                         5.44211
trainer/Policy Loss                     48.8494
trainer/Q1 Predictions Mean            -48.2655
trainer/Q1 Predictions Std              76.3403
trainer/Q1 Predictions Max              27.2178
trainer/Q1 Predictions Min            -232.346
trainer/Q2 Predictions Mean            -48.4939
trainer/Q2 Predictions Std              76.6009
trainer/Q2 Predictions Max              27.4803
trainer/Q2 Predictions Min            -231.683
trainer/Q Targets Mean                 -49.2246
trainer/Q Targets Std                   77.6578
trainer/Q Targets Max                   27.5453
trainer/Q Targets Min                 -236.946
trainer/Log Pis Mean                     2.0962
trainer/Log Pis Std                      1.83243
trainer/Log Pis Max                      7.50466
trainer/Log Pis Min                     -3.39894
trainer/policy/mean Mean                -0.481341
trainer/policy/mean Std                  0.666114
trainer/policy/mean Max                  0.94594
trainer/policy/mean Min                 -0.990991
trainer/policy/normal/std Mean           0.572353
trainer/policy/normal/std Std            0.0945191
trainer/policy/normal/std Max            0.869613
trainer/policy/normal/std Min            0.218377
trainer/policy/normal/log_std Mean      -0.571348
trainer/policy/normal/log_std Std        0.163902
trainer/policy/normal/log_std Max       -0.139707
trainer/policy/normal/log_std Min       -1.52153
trainer/Alpha                            0.0244369
trainer/Alpha Loss                       0.357066
exploration/num steps total         802000
exploration/num paths total           4010
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.12081
exploration/Rewards Std                  1.54072
exploration/Rewards Max                 -8.62381e-230
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -224.161
exploration/Returns Std                153.596
exploration/Returns Max                -44.7158
exploration/Returns Min               -493.823
exploration/Actions Mean                -0.388211
exploration/Actions Std                  0.722382
exploration/Actions Max                  0.998716
exploration/Actions Min                 -0.999231
exploration/Num Paths                   10
exploration/Average Returns           -224.161
evaluation/num steps total               1.9296e+06
evaluation/num paths total            9600
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.9071
evaluation/Rewards Std                   1.14754
evaluation/Rewards Max                  -3.17805
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -986.326
evaluation/Returns Std                 228.108
evaluation/Returns Max                -652.601
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.521196
evaluation/Actions Std                   0.476232
evaluation/Actions Max                   0.716127
evaluation/Actions Min                  -0.979422
evaluation/Num Paths                    24
evaluation/Average Returns            -986.326
time/data storing (s)                    0.0244828
time/evaluation sampling (s)            12.884
time/exploration sampling (s)            5.01131
time/logging (s)                         0.0667139
time/sac training (s)                   32.786
time/saving (s)                          0.248256
time/training (s)                        0.000145068
time/epoch (s)                          51.0209
time/total (s)                       61423.6
Epoch                                  399
----------------------------------  -----------------
2020-11-10 08:15:35.804648 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 400 finished
----------------------------------  -----------------
replay_buffer/size                  804000
trainer/num train calls             401000
trainer/QF1 Loss                        42.1469
trainer/QF2 Loss                        42.7992
trainer/Policy Loss                     61.1213
trainer/Q1 Predictions Mean            -60.7547
trainer/Q1 Predictions Std              86.3776
trainer/Q1 Predictions Max              40.4948
trainer/Q1 Predictions Min            -233.057
trainer/Q2 Predictions Mean            -60.5241
trainer/Q2 Predictions Std              86.1138
trainer/Q2 Predictions Max              40.4631
trainer/Q2 Predictions Min            -232.735
trainer/Q Targets Mean                 -60.7466
trainer/Q Targets Std                   87.0915
trainer/Q Targets Max                   39.9301
trainer/Q Targets Min                 -237.831
trainer/Log Pis Mean                     1.91565
trainer/Log Pis Std                      1.67737
trainer/Log Pis Max                      5.65823
trainer/Log Pis Min                     -4.19472
trainer/policy/mean Mean                -0.434231
trainer/policy/mean Std                  0.700044
trainer/policy/mean Max                  0.966998
trainer/policy/mean Min                 -0.984936
trainer/policy/normal/std Mean           0.581402
trainer/policy/normal/std Std            0.0909006
trainer/policy/normal/std Max            0.879333
trainer/policy/normal/std Min            0.250975
trainer/policy/normal/log_std Mean      -0.554391
trainer/policy/normal/log_std Std        0.15616
trainer/policy/normal/log_std Max       -0.128592
trainer/policy/normal/log_std Min       -1.3824
trainer/Alpha                            0.0243674
trainer/Alpha Loss                      -0.313314
exploration/num steps total         804000
exploration/num paths total           4020
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.764186
exploration/Rewards Std                  1.43303
exploration/Rewards Max                 -1.20085e-117
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -152.837
exploration/Returns Std                 76.1364
exploration/Returns Max                -79.3396
exploration/Returns Min               -324.621
exploration/Actions Mean                -0.561046
exploration/Actions Std                  0.5836
exploration/Actions Max                  0.992378
exploration/Actions Min                 -0.999115
exploration/Num Paths                   10
exploration/Average Returns           -152.837
evaluation/num steps total               1.93442e+06
evaluation/num paths total            9624
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.89528
evaluation/Rewards Std                   0.534353
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1184.95
evaluation/Returns Std                 107.4
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.599853
evaluation/Actions Std                   0.378124
evaluation/Actions Max                   0.185752
evaluation/Actions Min                  -0.974957
evaluation/Num Paths                    24
evaluation/Average Returns           -1184.95
time/data storing (s)                    0.0206539
time/evaluation sampling (s)            12.6527
time/exploration sampling (s)            4.96518
time/logging (s)                         0.0541909
time/sac training (s)                   31.9484
time/saving (s)                          0.187772
time/training (s)                        0.000342292
time/epoch (s)                          49.8293
time/total (s)                       61693
Epoch                                  400
----------------------------------  -----------------
2020-11-10 08:20:01.623769 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 401 finished
----------------------------------  ----------------
replay_buffer/size                  806000
trainer/num train calls             402000
trainer/QF1 Loss                        76.8837
trainer/QF2 Loss                        81.1551
trainer/Policy Loss                     61.8215
trainer/Q1 Predictions Mean            -61.5104
trainer/Q1 Predictions Std              81.3313
trainer/Q1 Predictions Max              27.7756
trainer/Q1 Predictions Min            -233.557
trainer/Q2 Predictions Mean            -61.0727
trainer/Q2 Predictions Std              80.8696
trainer/Q2 Predictions Max              28.0322
trainer/Q2 Predictions Min            -232.691
trainer/Q Targets Mean                 -61.5237
trainer/Q Targets Std                   82.2985
trainer/Q Targets Max                   27.4357
trainer/Q Targets Min                 -237.781
trainer/Log Pis Mean                     2.11747
trainer/Log Pis Std                      1.81874
trainer/Log Pis Max                      7.12811
trainer/Log Pis Min                     -3.98413
trainer/policy/mean Mean                -0.506826
trainer/policy/mean Std                  0.673338
trainer/policy/mean Max                  0.966867
trainer/policy/mean Min                 -0.989134
trainer/policy/normal/std Mean           0.579553
trainer/policy/normal/std Std            0.0916334
trainer/policy/normal/std Max            0.845864
trainer/policy/normal/std Min            0.197298
trainer/policy/normal/log_std Mean      -0.558874
trainer/policy/normal/log_std Std        0.168762
trainer/policy/normal/log_std Max       -0.167397
trainer/policy/normal/log_std Min       -1.62304
trainer/Alpha                            0.0248633
trainer/Alpha Loss                       0.43399
exploration/num steps total         806000
exploration/num paths total           4030
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.04038
exploration/Rewards Std                  1.47236
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -208.075
exploration/Returns Std                152.228
exploration/Returns Max                -35.1512
exploration/Returns Min               -467.498
exploration/Actions Mean                -0.382063
exploration/Actions Std                  0.767299
exploration/Actions Max                  0.998778
exploration/Actions Min                 -0.9994
exploration/Num Paths                   10
exploration/Average Returns           -208.075
evaluation/num steps total               1.93925e+06
evaluation/num paths total            9648
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.36221
evaluation/Rewards Std                   1.41119
evaluation/Rewards Max                  -1.02805e-14
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1077.8
evaluation/Returns Std                 281.903
evaluation/Returns Max                 -18.7097
evaluation/Returns Min               -1193.13
evaluation/Actions Mean                 -0.578645
evaluation/Actions Std                   0.415748
evaluation/Actions Max                   0.63464
evaluation/Actions Min                  -0.985465
evaluation/Num Paths                    24
evaluation/Average Returns           -1077.8
time/data storing (s)                    0.0206828
time/evaluation sampling (s)            12.6827
time/exploration sampling (s)            4.95254
time/logging (s)                         0.0583161
time/sac training (s)                   32.1733
time/saving (s)                          0.380077
time/training (s)                        0.000135554
time/epoch (s)                          50.2678
time/total (s)                       61958.8
Epoch                                  401
----------------------------------  ----------------
2020-11-10 08:24:30.235236 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 402 finished
----------------------------------  -----------------
replay_buffer/size                  808000
trainer/num train calls             403000
trainer/QF1 Loss                        59.8516
trainer/QF2 Loss                        58.161
trainer/Policy Loss                     64.0896
trainer/Q1 Predictions Mean            -63.5205
trainer/Q1 Predictions Std              85.8967
trainer/Q1 Predictions Max              39.2498
trainer/Q1 Predictions Min            -232.29
trainer/Q2 Predictions Mean            -63.6229
trainer/Q2 Predictions Std              85.9748
trainer/Q2 Predictions Max              39.2315
trainer/Q2 Predictions Min            -233.821
trainer/Q Targets Mean                 -64.223
trainer/Q Targets Std                   87.2025
trainer/Q Targets Max                   39.1333
trainer/Q Targets Min                 -237.708
trainer/Log Pis Mean                     1.81807
trainer/Log Pis Std                      1.70684
trainer/Log Pis Max                      6.62599
trainer/Log Pis Min                     -3.66194
trainer/policy/mean Mean                -0.485182
trainer/policy/mean Std                  0.664589
trainer/policy/mean Max                  0.950454
trainer/policy/mean Min                 -0.994922
trainer/policy/normal/std Mean           0.566706
trainer/policy/normal/std Std            0.0925312
trainer/policy/normal/std Max            0.829141
trainer/policy/normal/std Min            0.22001
trainer/policy/normal/log_std Mean      -0.581218
trainer/policy/normal/log_std Std        0.164639
trainer/policy/normal/log_std Max       -0.187365
trainer/policy/normal/log_std Min       -1.51408
trainer/Alpha                            0.0247408
trainer/Alpha Loss                      -0.673021
exploration/num steps total         808000
exploration/num paths total           4040
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15566
exploration/Rewards Std                  1.32571
exploration/Rewards Max                 -7.80558e-147
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -231.132
exploration/Returns Std                168.581
exploration/Returns Max                -32.0393
exploration/Returns Min               -510.159
exploration/Actions Mean                -0.473344
exploration/Actions Std                  0.690163
exploration/Actions Max                  0.99763
exploration/Actions Min                 -0.999034
exploration/Num Paths                   10
exploration/Average Returns           -231.132
evaluation/num steps total               1.94407e+06
evaluation/num paths total            9672
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.29788
evaluation/Rewards Std                   1.10822
evaluation/Rewards Max                  -2.99573
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1064.87
evaluation/Returns Std                 221.888
evaluation/Returns Max                -607.182
evaluation/Returns Min               -1178.45
evaluation/Actions Mean                 -0.480107
evaluation/Actions Std                   0.517082
evaluation/Actions Max                   0.570659
evaluation/Actions Min                  -0.97431
evaluation/Num Paths                    24
evaluation/Average Returns           -1064.87
time/data storing (s)                    0.020999
time/evaluation sampling (s)            12.7113
time/exploration sampling (s)            4.9761
time/logging (s)                         0.0528337
time/sac training (s)                   32.4984
time/saving (s)                          0.391305
time/training (s)                        0.00016174
time/epoch (s)                          50.6511
time/total (s)                       62227.4
Epoch                                  402
----------------------------------  -----------------
2020-11-10 08:28:56.933761 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 403 finished
----------------------------------  ----------------
replay_buffer/size                  810000
trainer/num train calls             404000
trainer/QF1 Loss                       106.66
trainer/QF2 Loss                       110.799
trainer/Policy Loss                     63.6836
trainer/Q1 Predictions Mean            -63.2453
trainer/Q1 Predictions Std              85.0059
trainer/Q1 Predictions Max              26.8364
trainer/Q1 Predictions Min            -232.995
trainer/Q2 Predictions Mean            -63.0745
trainer/Q2 Predictions Std              84.858
trainer/Q2 Predictions Max              26.4735
trainer/Q2 Predictions Min            -235.182
trainer/Q Targets Mean                 -63.5799
trainer/Q Targets Std                   85.8259
trainer/Q Targets Max                   26.1944
trainer/Q Targets Min                 -237.802
trainer/Log Pis Mean                     2.17434
trainer/Log Pis Std                      1.80274
trainer/Log Pis Max                      7.627
trainer/Log Pis Min                     -4.40704
trainer/policy/mean Mean                -0.553089
trainer/policy/mean Std                  0.625174
trainer/policy/mean Max                  0.970627
trainer/policy/mean Min                 -0.993058
trainer/policy/normal/std Mean           0.582332
trainer/policy/normal/std Std            0.104821
trainer/policy/normal/std Max            0.909495
trainer/policy/normal/std Min            0.20261
trainer/policy/normal/log_std Mean      -0.557334
trainer/policy/normal/log_std Std        0.185644
trainer/policy/normal/log_std Max       -0.094866
trainer/policy/normal/log_std Min       -1.59647
trainer/Alpha                            0.0249871
trainer/Alpha Loss                       0.6432
exploration/num steps total         810000
exploration/num paths total           4050
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15922
exploration/Rewards Std                  1.64082
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -231.844
exploration/Returns Std                183.489
exploration/Returns Max                -60.8347
exploration/Returns Min               -636.535
exploration/Actions Mean                -0.505319
exploration/Actions Std                  0.691276
exploration/Actions Max                  0.998156
exploration/Actions Min                 -0.999793
exploration/Num Paths                   10
exploration/Average Returns           -231.844
evaluation/num steps total               1.9489e+06
evaluation/num paths total            9696
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.49748
evaluation/Rewards Std                   1.55047
evaluation/Rewards Max                  -4.43843e-20
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -903.993
evaluation/Returns Std                 307.701
evaluation/Returns Max                 -21.9678
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.56868
evaluation/Actions Std                   0.477983
evaluation/Actions Max                   0.739254
evaluation/Actions Min                  -0.97959
evaluation/Num Paths                    24
evaluation/Average Returns            -903.993
time/data storing (s)                    0.0200828
time/evaluation sampling (s)            12.7312
time/exploration sampling (s)            4.92575
time/logging (s)                         0.0550567
time/sac training (s)                   32.4174
time/saving (s)                          0.225269
time/training (s)                        0.000166974
time/epoch (s)                          50.3749
time/total (s)                       62494
Epoch                                  403
----------------------------------  ----------------
2020-11-10 08:45:24.179441 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 404 finished
----------------------------------  -----------------
replay_buffer/size                  812000
trainer/num train calls             405000
trainer/QF1 Loss                       137.788
trainer/QF2 Loss                       145.827
trainer/Policy Loss                     64.2211
trainer/Q1 Predictions Mean            -63.7124
trainer/Q1 Predictions Std              82.7513
trainer/Q1 Predictions Max              22.8274
trainer/Q1 Predictions Min            -231.985
trainer/Q2 Predictions Mean            -63.7089
trainer/Q2 Predictions Std              82.5758
trainer/Q2 Predictions Max              22.4
trainer/Q2 Predictions Min            -231.6
trainer/Q Targets Mean                 -63.429
trainer/Q Targets Std                   83.8036
trainer/Q Targets Max                   22.588
trainer/Q Targets Min                 -233.94
trainer/Log Pis Mean                     1.78627
trainer/Log Pis Std                      1.91344
trainer/Log Pis Max                      5.98903
trainer/Log Pis Min                     -5.18075
trainer/policy/mean Mean                -0.544954
trainer/policy/mean Std                  0.624816
trainer/policy/mean Max                  0.932997
trainer/policy/mean Min                 -0.993481
trainer/policy/normal/std Mean           0.604138
trainer/policy/normal/std Std            0.10978
trainer/policy/normal/std Max            0.946937
trainer/policy/normal/std Min            0.277216
trainer/policy/normal/log_std Mean      -0.519935
trainer/policy/normal/log_std Std        0.178273
trainer/policy/normal/log_std Max       -0.0545229
trainer/policy/normal/log_std Min       -1.28296
trainer/Alpha                            0.0252466
trainer/Alpha Loss                      -0.786329
exploration/num steps total         812000
exploration/num paths total           4060
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.955745
exploration/Rewards Std                  1.54422
exploration/Rewards Max                 -4.51419e-127
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -191.149
exploration/Returns Std                113.609
exploration/Returns Max                -31.4659
exploration/Returns Min               -375.089
exploration/Actions Mean                -0.474301
exploration/Actions Std                  0.695839
exploration/Actions Max                  0.996659
exploration/Actions Min                 -0.99981
exploration/Num Paths                   10
exploration/Average Returns           -191.149
evaluation/num steps total               1.95372e+06
evaluation/num paths total            9720
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.73181
evaluation/Rewards Std                   1.26011
evaluation/Rewards Max                  -3.09104
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean               -951.094
evaluation/Returns Std                 251.254
evaluation/Returns Max                -628.071
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.5745
evaluation/Actions Std                   0.467512
evaluation/Actions Max                   0.516451
evaluation/Actions Min                  -0.975281
evaluation/Num Paths                    24
evaluation/Average Returns            -951.094
time/data storing (s)                    0.0204137
time/evaluation sampling (s)            12.7394
time/exploration sampling (s)            5.22144
time/logging (s)                         0.126697
time/sac training (s)                   45.6576
time/saving (s)                          0.253295
time/training (s)                        0.000175978
time/epoch (s)                          64.019
time/total (s)                       62911.4
Epoch                                  404
----------------------------------  -----------------
2020-11-10 08:58:38.050961 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 405 finished
----------------------------------  -----------------
replay_buffer/size                  814000
trainer/num train calls             406000
trainer/QF1 Loss                       221.583
trainer/QF2 Loss                       231.598
trainer/Policy Loss                     60.057
trainer/Q1 Predictions Mean            -59.5384
trainer/Q1 Predictions Std              79.9905
trainer/Q1 Predictions Max              20.8229
trainer/Q1 Predictions Min            -232.227
trainer/Q2 Predictions Mean            -59.63
trainer/Q2 Predictions Std              80.1155
trainer/Q2 Predictions Max              21.2163
trainer/Q2 Predictions Min            -232.151
trainer/Q Targets Mean                 -59.2577
trainer/Q Targets Std                   80.436
trainer/Q Targets Max                   20.918
trainer/Q Targets Min                 -237.557
trainer/Log Pis Mean                     2.10973
trainer/Log Pis Std                      1.77407
trainer/Log Pis Max                      6.44273
trainer/Log Pis Min                     -6.74318
trainer/policy/mean Mean                -0.561237
trainer/policy/mean Std                  0.618667
trainer/policy/mean Max                  0.943485
trainer/policy/mean Min                 -0.993012
trainer/policy/normal/std Mean           0.584074
trainer/policy/normal/std Std            0.105749
trainer/policy/normal/std Max            0.887532
trainer/policy/normal/std Min            0.239353
trainer/policy/normal/log_std Mean      -0.553782
trainer/policy/normal/log_std Std        0.179648
trainer/policy/normal/log_std Max       -0.119311
trainer/policy/normal/log_std Min       -1.42981
trainer/Alpha                            0.0248676
trainer/Alpha Loss                       0.405363
exploration/num steps total         814000
exploration/num paths total           4070
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.04521
exploration/Rewards Std                  1.56363
exploration/Rewards Max                 -1.25243e-157
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -209.041
exploration/Returns Std                110.689
exploration/Returns Max                -39.7948
exploration/Returns Min               -421.506
exploration/Actions Mean                -0.670792
exploration/Actions Std                  0.465989
exploration/Actions Max                  0.991686
exploration/Actions Min                 -0.999267
exploration/Num Paths                   10
exploration/Average Returns           -209.041
evaluation/num steps total               1.95854e+06
evaluation/num paths total            9744
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -4.99611
evaluation/Rewards Std                   1.12308
evaluation/Rewards Max                  -3.13549
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1004.22
evaluation/Returns Std                 223.527
evaluation/Returns Max                -644.344
evaluation/Returns Min               -1147.6
evaluation/Actions Mean                 -0.564556
evaluation/Actions Std                   0.465344
evaluation/Actions Max                   0.705976
evaluation/Actions Min                  -0.979113
evaluation/Num Paths                    24
evaluation/Average Returns           -1004.22
time/data storing (s)                    0.0319503
time/evaluation sampling (s)            15.5137
time/exploration sampling (s)            5.18353
time/logging (s)                         0.0730263
time/sac training (s)                   35.679
time/saving (s)                          0.339131
time/training (s)                        0.000161343
time/epoch (s)                          56.8206
time/total (s)                       63321.7
Epoch                                  405
----------------------------------  -----------------
2020-11-10 09:04:46.803786 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 406 finished
----------------------------------  ----------------
replay_buffer/size                  816000
trainer/num train calls             407000
trainer/QF1 Loss                       106.377
trainer/QF2 Loss                       115.475
trainer/Policy Loss                     56.4064
trainer/Q1 Predictions Mean            -55.9214
trainer/Q1 Predictions Std              81.5692
trainer/Q1 Predictions Max              44.2271
trainer/Q1 Predictions Min            -238.2
trainer/Q2 Predictions Mean            -56.0024
trainer/Q2 Predictions Std              81.7163
trainer/Q2 Predictions Max              44.0427
trainer/Q2 Predictions Min            -237.427
trainer/Q Targets Mean                 -55.9305
trainer/Q Targets Std                   82.5504
trainer/Q Targets Max                   44.0086
trainer/Q Targets Min                 -240.722
trainer/Log Pis Mean                     1.97391
trainer/Log Pis Std                      1.63458
trainer/Log Pis Max                      5.23329
trainer/Log Pis Min                     -4.02564
trainer/policy/mean Mean                -0.539482
trainer/policy/mean Std                  0.633763
trainer/policy/mean Max                  0.941324
trainer/policy/mean Min                 -0.987305
trainer/policy/normal/std Mean           0.592522
trainer/policy/normal/std Std            0.104411
trainer/policy/normal/std Max            0.92689
trainer/policy/normal/std Min            0.26228
trainer/policy/normal/log_std Mean      -0.538111
trainer/policy/normal/log_std Std        0.170374
trainer/policy/normal/log_std Max       -0.0759201
trainer/policy/normal/log_std Min       -1.33834
trainer/Alpha                            0.0253248
trainer/Alpha Loss                      -0.0959043
exploration/num steps total         816000
exploration/num paths total           4080
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.880691
exploration/Rewards Std                  1.47762
exploration/Rewards Max                 -2.31204e-93
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -176.138
exploration/Returns Std                114.063
exploration/Returns Max                -45.6189
exploration/Returns Min               -448.225
exploration/Actions Mean                -0.574106
exploration/Actions Std                  0.592483
exploration/Actions Max                  0.994634
exploration/Actions Min                 -0.99984
exploration/Num Paths                   10
exploration/Average Returns           -176.138
evaluation/num steps total               1.96337e+06
evaluation/num paths total            9768
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -6.0067
evaluation/Rewards Std                   0.00485426
evaluation/Rewards Max                  -6.00635
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1207.35
evaluation/Returns Std                   2.70795e-08
evaluation/Returns Max               -1207.35
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.592409
evaluation/Actions Std                   0.38724
evaluation/Actions Max                  -0.204176
evaluation/Actions Min                  -0.980502
evaluation/Num Paths                    24
evaluation/Average Returns           -1207.35
time/data storing (s)                    0.02123
time/evaluation sampling (s)            13.3335
time/exploration sampling (s)            5.4244
time/logging (s)                         0.0514666
time/sac training (s)                   37.5422
time/saving (s)                          0.19172
time/training (s)                        0.000166919
time/epoch (s)                          56.5646
time/total (s)                       63690.4
Epoch                                  406
----------------------------------  ----------------
2020-11-10 09:10:29.300229 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 407 finished
----------------------------------  ----------------
replay_buffer/size                  818000
trainer/num train calls             408000
trainer/QF1 Loss                       165.51
trainer/QF2 Loss                       168.07
trainer/Policy Loss                     56.6049
trainer/Q1 Predictions Mean            -56.0672
trainer/Q1 Predictions Std              78.4244
trainer/Q1 Predictions Max              29.1355
trainer/Q1 Predictions Min            -231.952
trainer/Q2 Predictions Mean            -56.0438
trainer/Q2 Predictions Std              78.3961
trainer/Q2 Predictions Max              29.3589
trainer/Q2 Predictions Min            -231.8
trainer/Q Targets Mean                 -55.2749
trainer/Q Targets Std                   78.1612
trainer/Q Targets Max                   29.3495
trainer/Q Targets Min                 -236.843
trainer/Log Pis Mean                     1.61687
trainer/Log Pis Std                      1.76298
trainer/Log Pis Max                      5.59689
trainer/Log Pis Min                     -5.48928
trainer/policy/mean Mean                -0.508819
trainer/policy/mean Std                  0.639921
trainer/policy/mean Max                  0.945998
trainer/policy/mean Min                 -0.986994
trainer/policy/normal/std Mean           0.585675
trainer/policy/normal/std Std            0.095545
trainer/policy/normal/std Max            0.873656
trainer/policy/normal/std Min            0.246158
trainer/policy/normal/log_std Mean      -0.548212
trainer/policy/normal/log_std Std        0.163646
trainer/policy/normal/log_std Max       -0.135069
trainer/policy/normal/log_std Min       -1.40178
trainer/Alpha                            0.025721
trainer/Alpha Loss                      -1.40244
exploration/num steps total         818000
exploration/num paths total           4090
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.811683
exploration/Rewards Std                  1.40623
exploration/Rewards Max                 -8.15906e-77
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -162.337
exploration/Returns Std                145.406
exploration/Returns Max                 -9.44264
exploration/Returns Min               -502.981
exploration/Actions Mean                -0.527128
exploration/Actions Std                  0.636915
exploration/Actions Max                  0.99802
exploration/Actions Min                 -0.999714
exploration/Num Paths                   10
exploration/Average Returns           -162.337
evaluation/num steps total               1.96819e+06
evaluation/num paths total            9792
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56214
evaluation/Rewards Std                   0.995627
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1117.99
evaluation/Returns Std                 199.805
evaluation/Returns Max                -669.877
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.591091
evaluation/Actions Std                   0.383939
evaluation/Actions Max                   0.0600465
evaluation/Actions Min                  -0.973769
evaluation/Num Paths                    24
evaluation/Average Returns           -1117.99
time/data storing (s)                    0.0202901
time/evaluation sampling (s)            15.9933
time/exploration sampling (s)            5.53864
time/logging (s)                         0.0468711
time/sac training (s)                   36.2298
time/saving (s)                          0.0827036
time/training (s)                        0.000153668
time/epoch (s)                          57.9118
time/total (s)                       64032.8
Epoch                                  407
----------------------------------  ----------------
2020-11-10 09:15:57.056020 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 408 finished
----------------------------------  -----------------
replay_buffer/size                  820000
trainer/num train calls             409000
trainer/QF1 Loss                        21.3442
trainer/QF2 Loss                        18.2627
trainer/Policy Loss                     46.7998
trainer/Q1 Predictions Mean            -46.4094
trainer/Q1 Predictions Std              74.679
trainer/Q1 Predictions Max              26.3701
trainer/Q1 Predictions Min            -231.201
trainer/Q2 Predictions Mean            -46.4527
trainer/Q2 Predictions Std              74.6097
trainer/Q2 Predictions Max              25.4051
trainer/Q2 Predictions Min            -230.977
trainer/Q Targets Mean                 -46.8471
trainer/Q Targets Std                   75.4234
trainer/Q Targets Max                   24.8371
trainer/Q Targets Min                 -237.401
trainer/Log Pis Mean                     1.67896
trainer/Log Pis Std                      1.53795
trainer/Log Pis Max                      5.16704
trainer/Log Pis Min                     -2.46722
trainer/policy/mean Mean                -0.360027
trainer/policy/mean Std                  0.721455
trainer/policy/mean Max                  0.977245
trainer/policy/mean Min                 -0.984735
trainer/policy/normal/std Mean           0.581631
trainer/policy/normal/std Std            0.100713
trainer/policy/normal/std Max            0.917186
trainer/policy/normal/std Min            0.248472
trainer/policy/normal/log_std Mean      -0.557072
trainer/policy/normal/log_std Std        0.176242
trainer/policy/normal/log_std Max       -0.0864448
trainer/policy/normal/log_std Min       -1.39243
trainer/Alpha                            0.0254264
trainer/Alpha Loss                      -1.17883
exploration/num steps total         820000
exploration/num paths total           4100
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.15103
exploration/Rewards Std                  1.59671
exploration/Rewards Max                 -1.04508e-103
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -230.206
exploration/Returns Std                 82.42
exploration/Returns Max                -62.7061
exploration/Returns Min               -347.671
exploration/Actions Mean                -0.571415
exploration/Actions Std                  0.57079
exploration/Actions Max                  0.996132
exploration/Actions Min                 -0.998951
exploration/Num Paths                   10
exploration/Average Returns           -230.206
evaluation/num steps total               1.97302e+06
evaluation/num paths total            9816
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.8341
evaluation/Rewards Std                   0.800146
evaluation/Rewards Max                  -3.17806
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1172.65
evaluation/Returns Std                 160.825
evaluation/Returns Max                -639.246
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.433358
evaluation/Actions Std                   0.536093
evaluation/Actions Max                   0.330527
evaluation/Actions Min                  -0.977528
evaluation/Num Paths                    24
evaluation/Average Returns           -1172.65
time/data storing (s)                    0.0239745
time/evaluation sampling (s)            13.2907
time/exploration sampling (s)            5.05982
time/logging (s)                         0.0848929
time/sac training (s)                   33.9972
time/saving (s)                          0.176277
time/training (s)                        0.000175706
time/epoch (s)                          52.633
time/total (s)                       64360.6
Epoch                                  408
----------------------------------  -----------------
2020-11-10 09:21:21.504029 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 409 finished
----------------------------------  -----------------
replay_buffer/size                  822000
trainer/num train calls             410000
trainer/QF1 Loss                        54.3454
trainer/QF2 Loss                        55.1133
trainer/Policy Loss                     54.5219
trainer/Q1 Predictions Mean            -54.0492
trainer/Q1 Predictions Std              79.0941
trainer/Q1 Predictions Max              25.9083
trainer/Q1 Predictions Min            -232.208
trainer/Q2 Predictions Mean            -54.0705
trainer/Q2 Predictions Std              79.0402
trainer/Q2 Predictions Max              25.9755
trainer/Q2 Predictions Min            -231.586
trainer/Q Targets Mean                 -54.1425
trainer/Q Targets Std                   79.9517
trainer/Q Targets Max                   25.9126
trainer/Q Targets Min                 -236.187
trainer/Log Pis Mean                     1.67614
trainer/Log Pis Std                      1.65903
trainer/Log Pis Max                      5.16974
trainer/Log Pis Min                     -4.99442
trainer/policy/mean Mean                -0.432229
trainer/policy/mean Std                  0.684105
trainer/policy/mean Max                  0.942993
trainer/policy/mean Min                 -0.985236
trainer/policy/normal/std Mean           0.575701
trainer/policy/normal/std Std            0.0874203
trainer/policy/normal/std Max            0.862931
trainer/policy/normal/std Min            0.205372
trainer/policy/normal/log_std Mean      -0.56426
trainer/policy/normal/log_std Std        0.159302
trainer/policy/normal/log_std Max       -0.147421
trainer/policy/normal/log_std Min       -1.58293
trainer/Alpha                            0.0251694
trainer/Alpha Loss                      -1.1925
exploration/num steps total         822000
exploration/num paths total           4110
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.546554
exploration/Rewards Std                  1.25007
exploration/Rewards Max                 -1.09574e-207
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -109.311
exploration/Returns Std                 60.9626
exploration/Returns Max                -44.6564
exploration/Returns Min               -249.961
exploration/Actions Mean                -0.358498
exploration/Actions Std                  0.703833
exploration/Actions Max                  0.99702
exploration/Actions Min                 -0.999801
exploration/Num Paths                   10
exploration/Average Returns           -109.311
evaluation/num steps total               1.97784e+06
evaluation/num paths total            9840
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.9564
evaluation/Rewards Std                   0.570471
evaluation/Rewards Max                  -3.21889
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1197.24
evaluation/Returns Std                 114.663
evaluation/Returns Max                -647.332
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.435804
evaluation/Actions Std                   0.531342
evaluation/Actions Max                   0.288551
evaluation/Actions Min                  -0.971084
evaluation/Num Paths                    24
evaluation/Average Returns           -1197.24
time/data storing (s)                    0.0212951
time/evaluation sampling (s)            14.0406
time/exploration sampling (s)            4.99205
time/logging (s)                         0.0555637
time/sac training (s)                   33.0413
time/saving (s)                          0.144019
time/training (s)                        0.000147348
time/epoch (s)                          52.295
time/total (s)                       64685
Epoch                                  409
----------------------------------  -----------------
2020-11-10 09:26:38.480851 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 410 finished
----------------------------------  -----------------
replay_buffer/size                  824000
trainer/num train calls             411000
trainer/QF1 Loss                       235.508
trainer/QF2 Loss                       246.581
trainer/Policy Loss                     66.367
trainer/Q1 Predictions Mean            -65.7812
trainer/Q1 Predictions Std              84.2979
trainer/Q1 Predictions Max              41.1434
trainer/Q1 Predictions Min            -231.399
trainer/Q2 Predictions Mean            -65.764
trainer/Q2 Predictions Std              84.0915
trainer/Q2 Predictions Max              40.6068
trainer/Q2 Predictions Min            -230.917
trainer/Q Targets Mean                 -64.558
trainer/Q Targets Std                   84.815
trainer/Q Targets Max                   41.1862
trainer/Q Targets Min                 -234.918
trainer/Log Pis Mean                     2.18009
trainer/Log Pis Std                      1.51601
trainer/Log Pis Max                      6.39051
trainer/Log Pis Min                     -2.42228
trainer/policy/mean Mean                -0.364868
trainer/policy/mean Std                  0.742839
trainer/policy/mean Max                  0.962297
trainer/policy/mean Min                 -0.99514
trainer/policy/normal/std Mean           0.583613
trainer/policy/normal/std Std            0.0953829
trainer/policy/normal/std Max            0.881477
trainer/policy/normal/std Min            0.303896
trainer/policy/normal/log_std Mean      -0.551378
trainer/policy/normal/log_std Std        0.159736
trainer/policy/normal/log_std Max       -0.126156
trainer/policy/normal/log_std Min       -1.19107
trainer/Alpha                            0.0250507
trainer/Alpha Loss                       0.663955
exploration/num steps total         824000
exploration/num paths total           4120
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.838986
exploration/Rewards Std                  1.5238
exploration/Rewards Max                 -2.07898e-276
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -167.797
exploration/Returns Std                105.956
exploration/Returns Max                -73.3488
exploration/Returns Min               -370.014
exploration/Actions Mean                -0.330468
exploration/Actions Std                  0.768741
exploration/Actions Max                  0.998359
exploration/Actions Min                 -0.999418
exploration/Num Paths                   10
exploration/Average Returns           -167.797
evaluation/num steps total               1.98266e+06
evaluation/num paths total            9864
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.56504
evaluation/Rewards Std                   0.989169
evaluation/Rewards Max                  -3.3322
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1118.57
evaluation/Returns Std                 198.505
evaluation/Returns Max                -672.551
evaluation/Returns Min               -1207.35
evaluation/Actions Mean                 -0.332818
evaluation/Actions Std                   0.650574
evaluation/Actions Max                   0.581266
evaluation/Actions Min                  -0.98061
evaluation/Num Paths                    24
evaluation/Average Returns           -1118.57
time/data storing (s)                    0.0203676
time/evaluation sampling (s)            12.8012
time/exploration sampling (s)            4.97027
time/logging (s)                         0.0683195
time/sac training (s)                   32.687
time/saving (s)                          0.182875
time/training (s)                        0.000165831
time/epoch (s)                          50.7302
time/total (s)                       65001.9
Epoch                                  410
----------------------------------  -----------------
2020-11-10 09:32:01.995150 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 411 finished
----------------------------------  -----------------
replay_buffer/size                  826000
trainer/num train calls             412000
trainer/QF1 Loss                       464.592
trainer/QF2 Loss                       451.533
trainer/Policy Loss                     63.4105
trainer/Q1 Predictions Mean            -62.9808
trainer/Q1 Predictions Std              82.3994
trainer/Q1 Predictions Max              27.8697
trainer/Q1 Predictions Min            -232.967
trainer/Q2 Predictions Mean            -62.7085
trainer/Q2 Predictions Std              81.9948
trainer/Q2 Predictions Max              28.0609
trainer/Q2 Predictions Min            -239.329
trainer/Q Targets Mean                 -60.939
trainer/Q Targets Std                   82.0938
trainer/Q Targets Max                   27.8153
trainer/Q Targets Min                 -240.395
trainer/Log Pis Mean                     2.17541
trainer/Log Pis Std                      1.47461
trainer/Log Pis Max                      5.55582
trainer/Log Pis Min                     -3.00605
trainer/policy/mean Mean                -0.323022
trainer/policy/mean Std                  0.7614
trainer/policy/mean Max                  0.971088
trainer/policy/mean Min                 -0.99342
trainer/policy/normal/std Mean           0.572992
trainer/policy/normal/std Std            0.0897771
trainer/policy/normal/std Max            0.904961
trainer/policy/normal/std Min            0.290309
trainer/policy/normal/log_std Mean      -0.568696
trainer/policy/normal/log_std Std        0.153004
trainer/policy/normal/log_std Max       -0.0998635
trainer/policy/normal/log_std Min       -1.23681
trainer/Alpha                            0.025244
trainer/Alpha Loss                       0.645352
exploration/num steps total         826000
exploration/num paths total           4130
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -1.62965
exploration/Rewards Std                  1.58099
exploration/Rewards Max                 -5.69672e-194
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -325.929
exploration/Returns Std                212.339
exploration/Returns Max                -62.1743
exploration/Returns Min               -595.301
exploration/Actions Mean                -0.253028
exploration/Actions Std                  0.800779
exploration/Actions Max                  0.998721
exploration/Actions Min                 -0.999435
exploration/Num Paths                   10
exploration/Average Returns           -325.929
evaluation/num steps total               1.98749e+06
evaluation/num paths total            9888
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.17136
evaluation/Rewards Std                   1.07619
evaluation/Rewards Max                  -3.2581
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1039.44
evaluation/Returns Std                 214.519
evaluation/Returns Max                -663.157
evaluation/Returns Min               -1163.29
evaluation/Actions Mean                 -0.257392
evaluation/Actions Std                   0.729517
evaluation/Actions Max                   0.912407
evaluation/Actions Min                  -0.980748
evaluation/Num Paths                    24
evaluation/Average Returns           -1039.44
time/data storing (s)                    0.0203852
time/evaluation sampling (s)            13.0016
time/exploration sampling (s)            5.09188
time/logging (s)                         0.0483791
time/sac training (s)                   33.1446
time/saving (s)                          0.170542
time/training (s)                        0.000144807
time/epoch (s)                          51.4775
time/total (s)                       65325.4
Epoch                                  411
----------------------------------  -----------------
2020-11-10 09:37:22.607600 EST | [tabular_active_search_neg_entropy_low_noise_2020_11_09_15_07_08_0000--s-0] Epoch 412 finished
----------------------------------  ----------------
replay_buffer/size                  828000
trainer/num train calls             413000
trainer/QF1 Loss                         5.46991
trainer/QF2 Loss                         4.86891
trainer/Policy Loss                     46.386
trainer/Q1 Predictions Mean            -46.1105
trainer/Q1 Predictions Std              74.6171
trainer/Q1 Predictions Max              41.0286
trainer/Q1 Predictions Min            -230.93
trainer/Q2 Predictions Mean            -45.881
trainer/Q2 Predictions Std              74.4602
trainer/Q2 Predictions Max              40.8023
trainer/Q2 Predictions Min            -230.456
trainer/Q Targets Mean                 -46.7532
trainer/Q Targets Std                   75.5213
trainer/Q Targets Max                   40.4692
trainer/Q Targets Min                 -234.952
trainer/Log Pis Mean                     1.47812
trainer/Log Pis Std                      1.62484
trainer/Log Pis Max                      5.26046
trainer/Log Pis Min                     -5.70327
trainer/policy/mean Mean                -0.443576
trainer/policy/mean Std                  0.673216
trainer/policy/mean Max                  0.944509
trainer/policy/mean Min                 -0.983517
trainer/policy/normal/std Mean           0.594653
trainer/policy/normal/std Std            0.0897717
trainer/policy/normal/std Max            0.893537
trainer/policy/normal/std Min            0.274957
trainer/policy/normal/log_std Mean      -0.531142
trainer/policy/normal/log_std Std        0.151868
trainer/policy/normal/log_std Max       -0.112568
trainer/policy/normal/log_std Min       -1.29114
trainer/Alpha                            0.0249944
trainer/Alpha Loss                      -1.92525
exploration/num steps total         828000
exploration/num paths total           4140
exploration/path length Mean           200
exploration/path length Std              3
exploration/path length Max            201
exploration/path length Min            191
exploration/Rewards Mean                -0.782355
exploration/Rewards Std                  1.42356
exploration/Rewards Max                 -0
exploration/Rewards Min                 -6.07535
exploration/Returns Mean              -156.471
exploration/Returns Std                114.984
exploration/Returns Max                -16.0707
exploration/Returns Min               -368.349
exploration/Actions Mean                -0.492709
exploration/Actions Std                  0.67813
exploration/Actions Max                  0.999756
exploration/Actions Min                 -0.999298
exploration/Num Paths                   10
exploration/Average Returns           -156.471
evaluation/num steps total               1.99231e+06
evaluation/num paths total            9912
evaluation/path length Mean            201
evaluation/path length Std               0
evaluation/path length Max             201
evaluation/path length Min             201
evaluation/Rewards Mean                 -5.96252
evaluation/Rewards Std                   0.541106
evaluation/Rewards Max                  -3.3673
evaluation/Rewards Min                  -6.07535
evaluation/Returns Mean              -1198.47
evaluation/Returns Std                 108.762
evaluation/Returns Max                -676.86
evaluation/Returns Min               -1221.14
evaluation/Actions Mean                 -0.452881
evaluation/Actions Std                   0.513929
evaluation/Actions Max                   0.062509
evaluation/Actions Min                  -0.972933
evaluation/Num Paths                    24
evaluation/Average Returns           -1198.47
time/data storing (s)                    0.024442
time/evaluation sampling (s)            13.9404
time/exploration sampling (s)            5.7809
time/logging (s)                         0.13008
time/sac training (s)                   33.2143
time/saving (s)                          0.211879
time/training (s)                        0.000183419
time/epoch (s)                          53.3022
time/total (s)                       65646
Epoch                                  412
----------------------------------  ----------------
